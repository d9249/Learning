{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f158486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import os, json, PIL\n",
    "\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e86d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "694ffa6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=157, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Baseline(model='resnet18', num_classes=157)\n",
    "model.model.load_state_dict(torch.load('./3_60.pt'))\n",
    "model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c1d053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b1822e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256), transforms.CenterCrop((224, 400)),\n",
    "    transforms.ToTensor(), transforms.Normalize(mean=[0.3005, 0.3035, 0.2712], std=[0.1519, 0.1252, 0.0996])])\n",
    "\n",
    "\n",
    "data_dir = './test/'\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for num in sorted(os.listdir(data_dir)):\n",
    "        with open(data_dir + '{}/{}.json'.format(num, num), 'r') as j:\n",
    "            temp = json.load(j)\n",
    "            imgs = []\n",
    "            for info in temp['annotations']:\n",
    "                img_dir = data_dir + '{}/{}.png'.format(num, info['image_id'])\n",
    "                img = PIL.Image.open(img_dir).convert('RGB')\n",
    "                img = test_transform(img)\n",
    "                imgs.append(img)\n",
    "            imgs = torch.stack(imgs).cuda()\n",
    "            prediction = torch.nn.Softmax(dim=1)(model.model(imgs))\n",
    "            prediction = torch.mean(prediction, dim=0)\n",
    "            #if torch.max(prediction) > 0.9:\n",
    "            #    prediction[torch.argmax(prediction)] = 1\n",
    "            #    prediction[prediction < 1] = 0\n",
    "            \n",
    "            if torch.sum(prediction) != 1: print(torch.sum(prediction))\n",
    "            predictions.append(prediction.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26e0b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Label_0</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_4</th>\n",
       "      <th>Label_5</th>\n",
       "      <th>Label_6</th>\n",
       "      <th>Label_7</th>\n",
       "      <th>Label_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Label_177</th>\n",
       "      <th>Label_186</th>\n",
       "      <th>Label_188</th>\n",
       "      <th>Label_189</th>\n",
       "      <th>Label_190</th>\n",
       "      <th>Label_191</th>\n",
       "      <th>Label_192</th>\n",
       "      <th>Label_193</th>\n",
       "      <th>Label_194</th>\n",
       "      <th>Label_195</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./test\\649</td>\n",
       "      <td>0.376913</td>\n",
       "      <td>0.012219</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.040370</td>\n",
       "      <td>0.073867</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./test\\650</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./test\\651</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./test\\652</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./test\\653</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image_Path   Label_0   Label_1   Label_2   Label_3   Label_4   Label_5  \\\n",
       "0  ./test\\649  0.376913  0.012219  0.001310  0.003247  0.002306  0.040370   \n",
       "1  ./test\\650  0.001238  0.000254  0.000076  0.000129  0.000070  0.000432   \n",
       "2  ./test\\651  0.000418  0.003243  0.000857  0.000739  0.000273  0.000266   \n",
       "3  ./test\\652  0.000226  0.003610  0.000718  0.000315  0.000112  0.000101   \n",
       "4  ./test\\653  0.000025  0.000240  0.004319  0.000414  0.000030  0.000019   \n",
       "\n",
       "    Label_6   Label_7   Label_8  ...  Label_177  Label_186  Label_188  \\\n",
       "0  0.073867  0.001822  0.001012  ...   0.000436   0.000302   0.000323   \n",
       "1  0.000272  0.000108  0.000188  ...   0.000039   0.000026   0.000010   \n",
       "2  0.000065  0.000447  0.000553  ...   0.000114   0.000128   0.000066   \n",
       "3  0.000022  0.000264  0.000339  ...   0.000059   0.000046   0.000026   \n",
       "4  0.000006  0.000028  0.000565  ...   0.000005   0.000020   0.000014   \n",
       "\n",
       "   Label_189  Label_190  Label_191  Label_192  Label_193  Label_194  Label_195  \n",
       "0   0.000377   0.000568   0.001132   0.000931   0.000200   0.000401   0.000488  \n",
       "1   0.000041   0.000094   0.000073   0.000015   0.000033   0.000073   0.000029  \n",
       "2   0.000311   0.000138   0.000247   0.000089   0.000041   0.000086   0.000045  \n",
       "3   0.000115   0.000057   0.000091   0.000034   0.000011   0.000023   0.000020  \n",
       "4   0.000019   0.000011   0.000009   0.000010   0.000004   0.000005   0.000006  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "sample_submission.iloc[:,1:] = predictions\n",
    "display(sample_submission.head())\n",
    "sample_submission.to_csv('./DatasetStat_3_60_threshno.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
