{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/3model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6xK_IvouKib"
      },
      "source": [
        "# DACON : 컴퓨터 비전 학습 경진대회\n",
        "\n",
        "https://dacon.io/competitions/official/235626/overview\n",
        "\n",
        "팀명 : 지비\n",
        "\n",
        "Public : 0.95588 (2위)\n",
        "\n",
        "Private : 0.93134 (6위)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQh2_dzt7arn"
      },
      "source": [
        "모든 코드는 코랩(Colab) 상에서 작성 및 실행되었습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYaBdU_2v9A3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11bb6f91-5263-465f-b8e6-7db974b970f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AX4XfWiu-86qj_9WSQ1EuNPZaVz3ZdPCPydcJehmi8pKS2tsbfxR0-39mxo\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P6WzJY1sv7B"
      },
      "source": [
        "### 제공받은 data.zip을 불러와서 이미지 파일들을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHkfaJbVq51_"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "csv_test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbhE79B3q54r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "3d06e600-4d54-4ede-8524-21e408dc480e"
      },
      "source": [
        "csv_train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "      <th>letter</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>L</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>B</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>L</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 787 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  digit letter  0  1  2  3  4  ...  776  777  778  779  780  781  782  783\n",
              "0   1      5      L  1  1  1  4  3  ...    0    1    2    4    4    4    3    4\n",
              "1   2      0      B  0  4  0  0  4  ...    0    1    4    1    4    2    1    2\n",
              "2   3      4      L  1  1  2  2  1  ...    3    0    2    0    3    0    2    2\n",
              "3   4      9      D  1  2  0  2  0  ...    2    0    1    4    0    0    1    1\n",
              "4   5      6      A  3  0  2  4  0  ...    3    2    1    3    4    3    1    2\n",
              "\n",
              "[5 rows x 787 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "# train 이미지들과 test 이미지들을 저장해놓을 폴더를 생성합니다.\n",
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(csv_train)) :\n",
        "    img = csv_train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = csv_train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{csv_train[\"id\"][idx]}.png', img)\n",
        "\n",
        "for idx in range(len(csv_test)) :\n",
        "    img = csv_test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{csv_test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnkFSU-aste_"
      },
      "source": [
        "### 폴더에 저장되어있는 이미지들을 사용하여 학습할 모델을 생성합니다.\n",
        "\n",
        "모델은 3가지이며, 최종 예측값은 최빈값(most frequent value)으로 결정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACO-d4DhwS4g"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model_1 = tf.keras.applications.InceptionResNetV2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)\n",
        "\n",
        "model_2 = tf.keras.Sequential([\n",
        "                               tf.keras.applications.InceptionV3(weights=None, include_top=False, input_shape=(224, 224, 1)),\n",
        "                               tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                               tf.keras.layers.Dense(1024, kernel_initializer='he_normal'),\n",
        "                               tf.keras.layers.BatchNormalization(),\n",
        "                               tf.keras.layers.Activation('relu'),\n",
        "                               tf.keras.layers.Dense(512, kernel_initializer='he_normal'),\n",
        "                               tf.keras.layers.BatchNormalization(),\n",
        "                               tf.keras.layers.Activation('relu'),\n",
        "                               tf.keras.layers.Dense(256, kernel_initializer='he_normal'),\n",
        "                               tf.keras.layers.BatchNormalization(),\n",
        "                               tf.keras.layers.Activation('relu'),\n",
        "                               tf.keras.layers.Dense(10, kernel_initializer='he_normal', activation='softmax', name='predictions')\n",
        "                               ])\n",
        "\n",
        "model_3 = tf.keras.Sequential([\n",
        "                               tf.keras.applications.Xception(weights=None, include_top=False, input_shape=(224, 224, 1)),\n",
        "                               tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                               tf.keras.layers.Dense(1024, kernel_initializer='he_normal'),\n",
        "                               tf.keras.layers.BatchNormalization(),\n",
        "                               tf.keras.layers.Activation('relu'),\n",
        "                               tf.keras.layers.Dense(512, kernel_initializer='he_normal'),\n",
        "                               tf.keras.layers.BatchNormalization(),\n",
        "                               tf.keras.layers.Activation('relu'),\n",
        "                               tf.keras.layers.Dense(256, kernel_initializer='he_normal'),\n",
        "                               tf.keras.layers.BatchNormalization(),\n",
        "                               tf.keras.layers.Activation('relu'),\n",
        "                               tf.keras.layers.Dense(10, kernel_initializer='he_normal', activation='softmax', name='predictions')\n",
        "                               ])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_vZLSC7wv1I"
      },
      "source": [
        "model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZozlvPQTtrvN"
      },
      "source": [
        "ImageDataGenerator은 이미지에 대한 회전이나 이동 등의 전처리를 정말 쉽게 수행하게 해줍니다.\n",
        "\n",
        "전체 2048개의 train 이미지 중에 20%(406개)는 validation으로 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFfY3blSw62V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e135fd6-96f1-41ed-e707-baca63b76c59"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq3bjZpswphU"
      },
      "source": [
        "ModelCheckpoint를 통해 val_accuracy가 가장 좋게 나온 epoch에서 모델을 저장할 수 있습니다.\n",
        "\n",
        "h5 파일으로 구글 드라이브에 저장하므로 Colab의 연결이 끊겨도 다음에 저장된 모델을 다시 불러올 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih_pVNUqyQDE"
      },
      "source": [
        "checkpoint_1 = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "checkpoint_2 = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "checkpoint_3 = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld9FJheyxD95"
      },
      "source": [
        "# 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BsFym7MwYeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8930154-49f7-4c4a-c635-ee5064c45970"
      },
      "source": [
        "model_1.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint_1])\n",
        "model_2.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint_2])\n",
        "model_3.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint_3])\n",
        "# 출력 결과를 보여드리기 위해서 임시로 epochs=20 으로 설정하고 실행하였습니다.\n",
        "# 실제로는 epochs=500 으로 설정하고 실행해야 하며, 많은 시간이 소요됩니다."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 53s 422ms/step - loss: 1.8219 - accuracy: 0.3660 - val_loss: 3.2700 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09606, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.9981 - accuracy: 0.6480 - val_loss: 3.3983 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.09606\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.7601 - accuracy: 0.7460 - val_loss: 3.9461 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.09606\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.5935 - accuracy: 0.8021 - val_loss: 6.2084 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.09606 to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.5415 - accuracy: 0.8155 - val_loss: 8.0997 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.09852\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.4350 - accuracy: 0.8544 - val_loss: 3.6408 - val_accuracy: 0.0764\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.09852\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.3782 - accuracy: 0.8800 - val_loss: 4.9533 - val_accuracy: 0.1108\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.09852 to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.3271 - accuracy: 0.8861 - val_loss: 9.1463 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.11084\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.3531 - accuracy: 0.8849 - val_loss: 5.6676 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.11084\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.2912 - accuracy: 0.9038 - val_loss: 4.0630 - val_accuracy: 0.2488\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.11084 to 0.24877, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.3196 - accuracy: 0.8922 - val_loss: 3.2074 - val_accuracy: 0.4039\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.24877 to 0.40394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 18s 354ms/step - loss: 0.3147 - accuracy: 0.8873 - val_loss: 1.2047 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.40394 to 0.61576, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.2249 - accuracy: 0.9257 - val_loss: 0.8745 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.61576 to 0.77833, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.1953 - accuracy: 0.9330 - val_loss: 0.7334 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.77833 to 0.78571, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.2057 - accuracy: 0.9336 - val_loss: 1.5009 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.78571\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.2067 - accuracy: 0.9330 - val_loss: 0.6739 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.78571 to 0.79064, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.1921 - accuracy: 0.9330 - val_loss: 1.1714 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.79064\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.1899 - accuracy: 0.9379 - val_loss: 0.6036 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.79064 to 0.85468, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.1461 - accuracy: 0.9501 - val_loss: 0.6243 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.85468\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.1479 - accuracy: 0.9525 - val_loss: 1.3894 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.85468\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.1058 - accuracy: 0.9622 - val_loss: 0.5600 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.85468\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.1015 - accuracy: 0.9616 - val_loss: 0.8213 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.85468\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.1314 - accuracy: 0.9622 - val_loss: 0.6515 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.85468 to 0.85961, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.1541 - accuracy: 0.9470 - val_loss: 0.6703 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.85961\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.1550 - accuracy: 0.9415 - val_loss: 0.9057 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.85961\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.1052 - accuracy: 0.9610 - val_loss: 0.5050 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.85961\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.1446 - accuracy: 0.9537 - val_loss: 0.7616 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.85961\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.1137 - accuracy: 0.9531 - val_loss: 0.6587 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.85961\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.1193 - accuracy: 0.9568 - val_loss: 0.6730 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.85961\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0871 - accuracy: 0.9732 - val_loss: 0.6196 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.85961\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0757 - accuracy: 0.9720 - val_loss: 0.5400 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.85961\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0654 - accuracy: 0.9762 - val_loss: 0.6404 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.85961\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0408 - accuracy: 0.9860 - val_loss: 0.4476 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.85961 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0572 - accuracy: 0.9811 - val_loss: 0.6089 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.88424\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0963 - accuracy: 0.9641 - val_loss: 1.0399 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.88424\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.1280 - accuracy: 0.9592 - val_loss: 1.1003 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.88424\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.1178 - accuracy: 0.9622 - val_loss: 0.9160 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.88424\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0887 - accuracy: 0.9689 - val_loss: 0.5002 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.88424\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0594 - accuracy: 0.9805 - val_loss: 0.6014 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.88424\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0931 - accuracy: 0.9683 - val_loss: 0.4789 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.88424\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0536 - accuracy: 0.9793 - val_loss: 0.7165 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.88424\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0677 - accuracy: 0.9775 - val_loss: 0.6376 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.88424\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.1099 - accuracy: 0.9659 - val_loss: 0.7478 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.88424\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0948 - accuracy: 0.9659 - val_loss: 0.6839 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.88424\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0640 - accuracy: 0.9787 - val_loss: 0.6847 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.88424\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 18s 347ms/step - loss: 0.0833 - accuracy: 0.9726 - val_loss: 0.8715 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.88424\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0463 - accuracy: 0.9915 - val_loss: 0.3952 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.88424 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 0.4443 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89655\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.3367 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.89655 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.4118 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91379\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.5520 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91379\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0475 - accuracy: 0.9823 - val_loss: 1.6245 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91379\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0704 - accuracy: 0.9750 - val_loss: 0.5074 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91379\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0422 - accuracy: 0.9878 - val_loss: 0.6521 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91379\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0673 - accuracy: 0.9817 - val_loss: 1.1153 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91379\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.1136 - accuracy: 0.9604 - val_loss: 0.9071 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91379\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0516 - accuracy: 0.9848 - val_loss: 0.5215 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91379\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.6358 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91379\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0710 - accuracy: 0.9756 - val_loss: 0.8508 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91379\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 18s 347ms/step - loss: 0.0633 - accuracy: 0.9781 - val_loss: 0.5134 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91379\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.4853 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91379\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 0.4089 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91379\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0640 - accuracy: 0.9805 - val_loss: 1.1311 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91379\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0972 - accuracy: 0.9677 - val_loss: 1.2758 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91379\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0849 - accuracy: 0.9720 - val_loss: 0.7947 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91379\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 18s 347ms/step - loss: 0.0587 - accuracy: 0.9787 - val_loss: 0.6903 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91379\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0460 - accuracy: 0.9866 - val_loss: 0.5277 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91379\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0859 - accuracy: 0.9677 - val_loss: 0.7386 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91379\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0322 - accuracy: 0.9903 - val_loss: 0.4465 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91379\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0230 - accuracy: 0.9915 - val_loss: 0.4588 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91379\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0302 - accuracy: 0.9884 - val_loss: 0.6873 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91379\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0811 - accuracy: 0.9781 - val_loss: 0.6730 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91379\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0322 - accuracy: 0.9872 - val_loss: 0.4770 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91379\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0215 - accuracy: 0.9945 - val_loss: 0.5203 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91379\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.3320 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91379\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0250 - accuracy: 0.9896 - val_loss: 0.5685 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91379\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 18s 347ms/step - loss: 0.0401 - accuracy: 0.9860 - val_loss: 1.0032 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91379\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0650 - accuracy: 0.9781 - val_loss: 0.6623 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91379\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0579 - accuracy: 0.9811 - val_loss: 0.6887 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91379\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0571 - accuracy: 0.9775 - val_loss: 0.4794 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91379\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 0.5061 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91379\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0274 - accuracy: 0.9939 - val_loss: 0.5657 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91379\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.7723 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91379\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 1.1204 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91379\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 18s 347ms/step - loss: 0.0279 - accuracy: 0.9933 - val_loss: 0.4860 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91379\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.5571 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91379\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.4888 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91379\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.4214 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91379\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0161 - accuracy: 0.9909 - val_loss: 0.7137 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91379\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0286 - accuracy: 0.9878 - val_loss: 0.5633 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91379\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 0.6580 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91379\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.1359 - accuracy: 0.9604 - val_loss: 2.4417 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91379\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 18s 347ms/step - loss: 0.1162 - accuracy: 0.9622 - val_loss: 1.4499 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91379\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0816 - accuracy: 0.9738 - val_loss: 1.7327 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91379\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 0.6756 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91379\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0284 - accuracy: 0.9884 - val_loss: 0.4919 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91379\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 0.5500 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91379\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.4659 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91379\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.7080 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91379\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0441 - accuracy: 0.9829 - val_loss: 0.6650 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91379\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0478 - accuracy: 0.9854 - val_loss: 1.0442 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91379\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 18s 347ms/step - loss: 0.0526 - accuracy: 0.9842 - val_loss: 0.5638 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.91379\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0437 - accuracy: 0.9848 - val_loss: 0.8418 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.91379\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0178 - accuracy: 0.9933 - val_loss: 0.8406 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.91379\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0540 - accuracy: 0.9811 - val_loss: 0.7375 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91379\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 18s 347ms/step - loss: 0.0532 - accuracy: 0.9817 - val_loss: 0.4301 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91379\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0857 - accuracy: 0.9714 - val_loss: 0.9603 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91379\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0427 - accuracy: 0.9805 - val_loss: 0.5192 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91379\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0477 - accuracy: 0.9823 - val_loss: 1.0868 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91379\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0294 - accuracy: 0.9927 - val_loss: 0.5450 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91379\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 0.4721 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91379\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.4552 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91379\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0123 - accuracy: 0.9939 - val_loss: 0.5945 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91379\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.4360 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00114: val_accuracy improved from 0.91379 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 18s 354ms/step - loss: 0.0288 - accuracy: 0.9896 - val_loss: 1.3095 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.92365\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0608 - accuracy: 0.9805 - val_loss: 0.6995 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.92365\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0376 - accuracy: 0.9878 - val_loss: 0.6990 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.92365\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.6934 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.92365\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0318 - accuracy: 0.9890 - val_loss: 0.8335 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.92365\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0570 - accuracy: 0.9781 - val_loss: 1.1680 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.92365\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0453 - accuracy: 0.9842 - val_loss: 0.9296 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.92365\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0389 - accuracy: 0.9890 - val_loss: 0.6591 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.92365\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0660 - accuracy: 0.9823 - val_loss: 0.9455 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.92365\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0507 - accuracy: 0.9848 - val_loss: 0.6431 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.92365\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0172 - accuracy: 0.9933 - val_loss: 0.6699 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.92365\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.6106 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.92365\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 1.3039 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.92365\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0352 - accuracy: 0.9909 - val_loss: 0.7301 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.92365\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0138 - accuracy: 0.9945 - val_loss: 0.5404 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.92365\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.8200 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.92365\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0235 - accuracy: 0.9951 - val_loss: 0.7383 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.92365\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.5168 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.92365\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 1.0297 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.92365\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 0.6535 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.92365\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0680 - accuracy: 0.9823 - val_loss: 1.2993 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.92365\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0465 - accuracy: 0.9842 - val_loss: 0.7705 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.92365\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0793 - accuracy: 0.9781 - val_loss: 2.2843 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.92365\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0651 - accuracy: 0.9787 - val_loss: 0.7715 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.92365\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.5052 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.92365\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0333 - accuracy: 0.9890 - val_loss: 0.8113 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.92365\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0448 - accuracy: 0.9860 - val_loss: 0.5336 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.92365\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0501 - accuracy: 0.9836 - val_loss: 0.8058 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.92365\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0270 - accuracy: 0.9927 - val_loss: 0.4666 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.92365\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.6010 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.92365\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.5030 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.92365\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.5175 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.92365\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4755 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.92365\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4942 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.92365\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4437 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.92365\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4638 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.92365\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 9.4233e-04 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.92365\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.3545 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.92365\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.4899 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.92365\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4062 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00154: val_accuracy improved from 0.92365 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.6514 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92857\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.9161 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92857\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0385 - accuracy: 0.9915 - val_loss: 0.9205 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92857\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.8607 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92857\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.9745 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92857\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0293 - accuracy: 0.9896 - val_loss: 0.6741 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92857\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.5721 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92857\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0146 - accuracy: 0.9933 - val_loss: 0.8447 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92857\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.6392 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92857\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.8046 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92857\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 0.6809 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92857\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0190 - accuracy: 0.9921 - val_loss: 0.8300 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92857\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0672 - accuracy: 0.9793 - val_loss: 1.1627 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92857\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0738 - accuracy: 0.9781 - val_loss: 0.9956 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92857\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0220 - accuracy: 0.9903 - val_loss: 0.8386 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92857\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.5735 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92857\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.5917 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92857\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0332 - accuracy: 0.9909 - val_loss: 0.6359 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92857\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0310 - accuracy: 0.9909 - val_loss: 0.4217 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92857\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.4604 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92857\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.4306 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00175: val_accuracy improved from 0.92857 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.4317 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.93350\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4322 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.93350\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4290 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.93350\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 9.4758e-04 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93350\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 5.3004e-04 - accuracy: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93350\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.4633 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93350\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.7402 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93350\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.6305 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93350\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.6160 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93350\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.4506 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93350\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0111 - accuracy: 0.9945 - val_loss: 0.4814 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93350\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.4517 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93350\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.4873 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93350\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0357 - accuracy: 0.9909 - val_loss: 1.0511 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93350\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0425 - accuracy: 0.9872 - val_loss: 1.4366 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93350\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0535 - accuracy: 0.9829 - val_loss: 1.0447 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93350\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0260 - accuracy: 0.9903 - val_loss: 1.1234 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93350\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.7183 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93350\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.9905 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93350\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0297 - accuracy: 0.9927 - val_loss: 1.2552 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93350\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0208 - accuracy: 0.9957 - val_loss: 0.7163 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93350\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0548 - accuracy: 0.9836 - val_loss: 0.7339 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93350\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0312 - accuracy: 0.9890 - val_loss: 0.7293 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93350\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.6493 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93350\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0184 - accuracy: 0.9927 - val_loss: 0.6848 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93350\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0386 - accuracy: 0.9903 - val_loss: 1.0030 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93350\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 18s 347ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.9989 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93350\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0294 - accuracy: 0.9878 - val_loss: 0.7480 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93350\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.5755 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93350\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0178 - accuracy: 0.9933 - val_loss: 0.5022 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93350\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.5404 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93350\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 18s 346ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.5357 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93350\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5714 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93350\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.5324 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93350\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5354 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93350\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5995 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93350\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0443 - accuracy: 0.9854 - val_loss: 0.9167 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93350\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0422 - accuracy: 0.9884 - val_loss: 1.4637 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93350\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0356 - accuracy: 0.9866 - val_loss: 1.0824 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93350\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.9491 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93350\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0254 - accuracy: 0.9939 - val_loss: 0.6580 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93350\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0067 - accuracy: 0.9963 - val_loss: 0.6126 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93350\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.6000 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93350\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5701 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93350\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4855 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93350\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 5.0127e-04 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93350\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 8.7340e-04 - accuracy: 1.0000 - val_loss: 0.4547 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93350\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.5826 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93350\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.8160 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93350\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0413 - accuracy: 0.9890 - val_loss: 0.4795 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93350\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.7335 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93350\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.6026 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93350\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.5427 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93350\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0169 - accuracy: 0.9933 - val_loss: 0.8969 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93350\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0323 - accuracy: 0.9903 - val_loss: 0.7137 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93350\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 18s 347ms/step - loss: 0.0159 - accuracy: 0.9927 - val_loss: 1.0133 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93350\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0212 - accuracy: 0.9915 - val_loss: 1.1486 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93350\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.6373 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93350\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0216 - accuracy: 0.9957 - val_loss: 0.5645 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93350\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0328 - accuracy: 0.9921 - val_loss: 0.7483 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93350\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0583 - accuracy: 0.9854 - val_loss: 0.7609 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93350\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.5222 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93350\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.3990 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93350\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.6484 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93350\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0062 - accuracy: 0.9970 - val_loss: 0.7051 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93350\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.6025 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93350\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.8603 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93350\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0371 - accuracy: 0.9915 - val_loss: 0.7591 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93350\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0235 - accuracy: 0.9939 - val_loss: 0.5774 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93350\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.6956 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93350\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.6942 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93350\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0150 - accuracy: 0.9933 - val_loss: 0.6074 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93350\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.7813 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93350\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.6495 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93350\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.6679 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93350\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.6350 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93350\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 0.5880 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93350\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 0.6432 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93350\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5301 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93350\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 6.8370e-04 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93350\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4598 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93350\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 7.0252e-04 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93350\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 3.2101e-04 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93350\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 5.5787e-04 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93350\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 1.4197e-04 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93350\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 6.4468e-04 - accuracy: 0.9994 - val_loss: 0.4121 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93350\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 8.0253e-04 - accuracy: 0.9994 - val_loss: 0.4319 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93350\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.4734 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93350\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0201 - accuracy: 0.9976 - val_loss: 0.5480 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93350\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 1.2215 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93350\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0216 - accuracy: 0.9951 - val_loss: 1.1478 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93350\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 1.4459 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93350\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.1008 - accuracy: 0.9738 - val_loss: 1.0881 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93350\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0812 - accuracy: 0.9775 - val_loss: 1.5669 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93350\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0434 - accuracy: 0.9884 - val_loss: 0.7551 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93350\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 18s 354ms/step - loss: 0.0167 - accuracy: 0.9963 - val_loss: 0.5432 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93350\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4465 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93350\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4696 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93350\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.4732 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93350\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.6165 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93350\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.3991 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93350\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0063 - accuracy: 0.9963 - val_loss: 0.5334 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93350\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.6619 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93350\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.5283 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93350\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4296 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93350\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5025 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93350\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.5710 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93350\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.5763 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93350\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.5096 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93350\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 0.5141 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93350\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0166 - accuracy: 0.9933 - val_loss: 0.7511 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93350\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0181 - accuracy: 0.9933 - val_loss: 0.7176 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93350\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5434 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93350\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5128 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93350\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.6664 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93350\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.7260 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93350\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.6296 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93350\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0137 - accuracy: 0.9939 - val_loss: 0.8588 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93350\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 1.7865 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93350\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0344 - accuracy: 0.9927 - val_loss: 0.9202 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93350\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0302 - accuracy: 0.9921 - val_loss: 0.9527 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93350\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0424 - accuracy: 0.9903 - val_loss: 0.8120 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93350\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0225 - accuracy: 0.9915 - val_loss: 0.7121 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93350\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.6498 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93350\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.8390 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93350\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.7619 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93350\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.6958 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93350\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0380 - accuracy: 0.9896 - val_loss: 0.7534 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93350\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0504 - accuracy: 0.9878 - val_loss: 0.8441 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93350\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 0.6967 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93350\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0350 - accuracy: 0.9939 - val_loss: 1.6672 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93350\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0610 - accuracy: 0.9823 - val_loss: 0.9121 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93350\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0217 - accuracy: 0.9915 - val_loss: 0.6309 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93350\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4812 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93350\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 9.9278e-04 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93350\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5137 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93350\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.8128 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93350\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0208 - accuracy: 0.9951 - val_loss: 0.7676 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93350\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0094 - accuracy: 0.9957 - val_loss: 0.7854 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93350\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.5814 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93350\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93350\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.6290 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93350\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5738 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93350\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.6182 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93350\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.5844 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93350\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4092 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93350\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 8.0703e-04 - accuracy: 1.0000 - val_loss: 0.4775 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93350\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.4601 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93350\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.4280 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93350\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.8743 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93350\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0317 - accuracy: 0.9915 - val_loss: 0.7060 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93350\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.7793 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93350\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 18s 354ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6308 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93350\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5791 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93350\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.5611 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93350\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 9.5506e-04 - accuracy: 1.0000 - val_loss: 0.6613 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93350\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5541 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93350\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.5399 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93350\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.6700 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93350\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0057 - accuracy: 0.9970 - val_loss: 0.6834 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93350\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5408 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93350\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5327 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93350\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 0.7064 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93350\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0241 - accuracy: 0.9945 - val_loss: 0.5277 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93350\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.6074 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93350\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.6783 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93350\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 1.1691 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93350\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.8871 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93350\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0418 - accuracy: 0.9890 - val_loss: 0.8209 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93350\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.9938 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93350\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0314 - accuracy: 0.9933 - val_loss: 0.6877 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93350\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0189 - accuracy: 0.9963 - val_loss: 0.7012 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93350\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.6382 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93350\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5954 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93350\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 7.7631e-04 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93350\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 6.8389e-04 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93350\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 18s 354ms/step - loss: 9.2164e-04 - accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93350\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 4.8933e-04 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93350\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 2.5498e-04 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93350\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.6574 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93350\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0294 - accuracy: 0.9927 - val_loss: 0.9155 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93350\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.8730 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93350\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.6689 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93350\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5230 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93350\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.5436 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93350\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.6717 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93350\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.6756 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93350\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.4995 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93350\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5248 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93350\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.6638 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93350\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.6561 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93350\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 3.8496e-04 - accuracy: 1.0000 - val_loss: 0.5528 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93350\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 3.6363e-04 - accuracy: 1.0000 - val_loss: 0.5827 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93350\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 1.9226e-04 - accuracy: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93350\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 1.9868e-04 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93350\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 4.4413e-04 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93350\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 1.7671 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93350\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.8454 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93350\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.7427 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93350\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.7754 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93350\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0451 - accuracy: 0.9878 - val_loss: 1.2481 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93350\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.6888 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93350\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.7974 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93350\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.6180 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93350\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0437 - accuracy: 0.9872 - val_loss: 0.8572 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93350\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0176 - accuracy: 0.9915 - val_loss: 0.6571 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93350\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.6463 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93350\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 1.8534 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93350\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.7178 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93350\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0135 - accuracy: 0.9945 - val_loss: 0.9766 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93350\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.5864 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93350\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.6413 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93350\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93350\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 6.1595e-04 - accuracy: 1.0000 - val_loss: 0.6250 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93350\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.6185 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93350\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6143 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93350\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 5.8159e-04 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93350\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 2.8009e-04 - accuracy: 1.0000 - val_loss: 0.6054 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93350\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 2.1627e-04 - accuracy: 1.0000 - val_loss: 0.5015 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93350\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 1.9355e-04 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93350\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 1.4088e-04 - accuracy: 1.0000 - val_loss: 0.5168 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93350\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4317 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93350\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.8931 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93350\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0613 - accuracy: 0.9860 - val_loss: 1.0208 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93350\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0396 - accuracy: 0.9909 - val_loss: 0.7816 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93350\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.6059 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93350\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 0.6042 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93350\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.5116 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93350\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.8342 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93350\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.6022 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93350\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4813 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93350\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 6.1041e-04 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93350\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 0.5012 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93350\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.5360 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93350\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 7.7465e-04 - accuracy: 1.0000 - val_loss: 0.5343 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.93350\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.6959 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.93350\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.9621 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.93350\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 0.5869 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.93350\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 9.4353e-04 - accuracy: 0.9994 - val_loss: 0.5715 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.93350\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 9.4334e-04 - accuracy: 1.0000 - val_loss: 0.5980 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.93350\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 5.5475e-04 - accuracy: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93350\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 9.9648e-05 - accuracy: 1.0000 - val_loss: 0.5380 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93350\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 1.9872e-04 - accuracy: 1.0000 - val_loss: 0.6141 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93350\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 3.5252e-04 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93350\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 1.3596e-04 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00420: val_accuracy improved from 0.93350 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 5.1885e-05 - accuracy: 1.0000 - val_loss: 0.5416 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.93842\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.5001 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93842\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5648 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93842\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 6.7161e-04 - accuracy: 1.0000 - val_loss: 0.5201 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93842\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0353 - accuracy: 0.9933 - val_loss: 0.8768 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93842\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0634 - accuracy: 0.9842 - val_loss: 1.2035 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93842\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0523 - accuracy: 0.9903 - val_loss: 1.0315 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93842\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0418 - accuracy: 0.9903 - val_loss: 1.1727 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93842\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.5113 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.93842\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0259 - accuracy: 0.9945 - val_loss: 1.2325 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.93842\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.9210 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.93842\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4984 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.93842\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.93842\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 7.2993e-04 - accuracy: 1.0000 - val_loss: 0.4748 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.93842\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 3.3502e-04 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.93842\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 3.6133e-04 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.93842\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 5.1565e-04 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.93842\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 2.7187e-04 - accuracy: 1.0000 - val_loss: 0.3845 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.93842\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 4.1925e-04 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.93842\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 18s 354ms/step - loss: 1.1517e-04 - accuracy: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.93842\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 7.3373e-05 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.93842\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 5.3630e-04 - accuracy: 1.0000 - val_loss: 0.4068 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.93842\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 4.0374e-04 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.93842\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 2.8455e-04 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.93842\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 5.0889e-04 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.93842\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 1.0597e-04 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.93842\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4796 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.93842\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.7274 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.93842\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 6.5247e-04 - accuracy: 1.0000 - val_loss: 0.5138 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.93842\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 9.0469e-04 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.93842\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 1.0810 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.93842\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0432 - accuracy: 0.9866 - val_loss: 1.9036 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.93842\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0304 - accuracy: 0.9903 - val_loss: 1.2793 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.93842\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0272 - accuracy: 0.9933 - val_loss: 0.5993 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.93842\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.8444 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.93842\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.6159 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.93842\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4995 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.93842\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0240 - accuracy: 0.9939 - val_loss: 0.6248 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.93842\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0275 - accuracy: 0.9951 - val_loss: 1.0666 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.93842\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.8668 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.93842\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.8652 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.93842\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4974 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.93842\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.5750 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.93842\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.7469 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.93842\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5872 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.93842\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.7450 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.93842\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.4996 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.93842\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.6107 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.93842\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.6027 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.93842\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.6282 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.93842\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0038 - accuracy: 0.9976 - val_loss: 0.6301 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.93842\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.6020 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.93842\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.5989 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.93842\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 1.0242 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.93842\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.6629 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.93842\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.7353 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.93842\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 18s 347ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.9769 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.93842\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.8051 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.93842\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 5.4426e-04 - accuracy: 1.0000 - val_loss: 0.7715 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.93842\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.9124 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.93842\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.6415 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.93842\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.7164 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.93842\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.6703 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.93842\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0055 - accuracy: 0.9970 - val_loss: 0.6853 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.93842\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.8532 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.93842\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.8098 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.93842\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.8770 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.93842\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 0.0171 - accuracy: 0.9970 - val_loss: 0.9812 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.93842\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.6193 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.93842\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.7866 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.93842\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 18s 355ms/step - loss: 0.0310 - accuracy: 0.9939 - val_loss: 0.8150 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.93842\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.5583 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.93842\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 18s 349ms/step - loss: 8.0765e-04 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.93842\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 18s 348ms/step - loss: 9.4705e-04 - accuracy: 1.0000 - val_loss: 0.5609 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.93842\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.6646 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.93842\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.6886 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.93842\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 18s 350ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.6075 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.93842\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 18s 352ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.6315 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.93842\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 2.3982e-04 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.93842\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 18s 351ms/step - loss: 3.0533e-04 - accuracy: 1.0000 - val_loss: 0.5376 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.93842\n",
            "Epoch 1/500\n",
            "52/52 [==============================] - 17s 202ms/step - loss: 2.2688 - accuracy: 0.1705 - val_loss: 2.8433 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 1.9414 - accuracy: 0.3106 - val_loss: 4.0023 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.09852\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 9s 173ms/step - loss: 1.6748 - accuracy: 0.4135 - val_loss: 4.7931 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.09852\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 1.3516 - accuracy: 0.5505 - val_loss: 4.2169 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.09852\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 1.1631 - accuracy: 0.6230 - val_loss: 6.6000 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.09852\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.9196 - accuracy: 0.6937 - val_loss: 11.2939 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.09852\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.8011 - accuracy: 0.7454 - val_loss: 3.0390 - val_accuracy: 0.0690\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.09852\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.6190 - accuracy: 0.8082 - val_loss: 4.4237 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.09852\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.6980 - accuracy: 0.7728 - val_loss: 4.7870 - val_accuracy: 0.1158\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.09852 to 0.11576, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.5645 - accuracy: 0.8161 - val_loss: 3.0277 - val_accuracy: 0.2167\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.11576 to 0.21675, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.4561 - accuracy: 0.8551 - val_loss: 2.6858 - val_accuracy: 0.3350\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.21675 to 0.33498, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.5071 - accuracy: 0.8380 - val_loss: 1.6282 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.33498 to 0.54680, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.3726 - accuracy: 0.8727 - val_loss: 1.6210 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.54680 to 0.65025, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.4545 - accuracy: 0.8618 - val_loss: 0.8292 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.65025 to 0.74138, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.4124 - accuracy: 0.8739 - val_loss: 0.9145 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.74138 to 0.74877, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.2565 - accuracy: 0.9214 - val_loss: 0.6637 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.74877 to 0.78325, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.3048 - accuracy: 0.9032 - val_loss: 0.9257 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.78325\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.3352 - accuracy: 0.8916 - val_loss: 0.4967 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.78325 to 0.83990, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.2929 - accuracy: 0.9099 - val_loss: 0.6261 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.83990\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 9s 175ms/step - loss: 0.2417 - accuracy: 0.9275 - val_loss: 0.8497 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.83990\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 9s 172ms/step - loss: 0.3826 - accuracy: 0.8819 - val_loss: 1.2319 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.83990\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.2115 - accuracy: 0.9367 - val_loss: 0.7321 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.83990\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.2660 - accuracy: 0.9190 - val_loss: 1.0263 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.83990\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.2634 - accuracy: 0.9208 - val_loss: 0.9336 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.83990\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.2035 - accuracy: 0.9330 - val_loss: 0.7085 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.83990\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.3165 - accuracy: 0.9086 - val_loss: 1.0940 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.83990\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.2405 - accuracy: 0.9220 - val_loss: 0.9002 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.83990\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.1454 - accuracy: 0.9549 - val_loss: 0.5322 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.83990 to 0.85222, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.2640 - accuracy: 0.9172 - val_loss: 0.7692 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.85222\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.2122 - accuracy: 0.9318 - val_loss: 0.6521 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.85222\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.2328 - accuracy: 0.9196 - val_loss: 0.9218 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.85222\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.2082 - accuracy: 0.9379 - val_loss: 0.4609 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.85222 to 0.85961, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 9s 173ms/step - loss: 0.1746 - accuracy: 0.9428 - val_loss: 1.0050 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.85961\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.1176 - accuracy: 0.9586 - val_loss: 0.8728 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.85961\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1274 - accuracy: 0.9592 - val_loss: 0.8260 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.85961\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.2139 - accuracy: 0.9361 - val_loss: 0.6957 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.85961\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.1570 - accuracy: 0.9476 - val_loss: 0.6283 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.85961\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.2002 - accuracy: 0.9434 - val_loss: 0.8300 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.85961\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.1230 - accuracy: 0.9592 - val_loss: 0.6909 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.85961\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.1145 - accuracy: 0.9641 - val_loss: 0.4417 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.85961 to 0.89901, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 9s 172ms/step - loss: 0.2700 - accuracy: 0.9153 - val_loss: 1.5190 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.89901\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 9s 173ms/step - loss: 0.2755 - accuracy: 0.9160 - val_loss: 1.0907 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89901\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.2001 - accuracy: 0.9367 - val_loss: 0.8648 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89901\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1443 - accuracy: 0.9537 - val_loss: 0.5191 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89901\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1120 - accuracy: 0.9653 - val_loss: 0.9014 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89901\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.1696 - accuracy: 0.9531 - val_loss: 0.9890 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89901\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.1631 - accuracy: 0.9470 - val_loss: 0.5002 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89901\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.1673 - accuracy: 0.9476 - val_loss: 0.6157 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89901\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0774 - accuracy: 0.9756 - val_loss: 0.4590 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89901\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.1155 - accuracy: 0.9641 - val_loss: 0.6026 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89901\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1040 - accuracy: 0.9677 - val_loss: 0.8608 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89901\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.1475 - accuracy: 0.9531 - val_loss: 0.6080 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.89901\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0831 - accuracy: 0.9702 - val_loss: 0.7064 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.89901\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.2435 - accuracy: 0.9397 - val_loss: 2.3420 - val_accuracy: 0.5665\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.89901\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.1514 - accuracy: 0.9610 - val_loss: 1.1245 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.89901\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.1067 - accuracy: 0.9689 - val_loss: 0.6473 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.89901\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.1714 - accuracy: 0.9452 - val_loss: 1.0968 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.89901\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.2327 - accuracy: 0.9281 - val_loss: 0.9290 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.89901\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1369 - accuracy: 0.9641 - val_loss: 0.4502 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.89901\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0888 - accuracy: 0.9702 - val_loss: 0.6968 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.89901\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0808 - accuracy: 0.9775 - val_loss: 0.4210 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.89901\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0761 - accuracy: 0.9732 - val_loss: 0.5419 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.89901\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0871 - accuracy: 0.9732 - val_loss: 0.4254 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.89901\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0822 - accuracy: 0.9726 - val_loss: 0.5153 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.89901\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0920 - accuracy: 0.9738 - val_loss: 0.7248 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.89901\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0722 - accuracy: 0.9799 - val_loss: 0.4403 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.89901\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0716 - accuracy: 0.9750 - val_loss: 0.4232 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.89901\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0957 - accuracy: 0.9683 - val_loss: 0.6797 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.89901\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.1145 - accuracy: 0.9671 - val_loss: 0.8203 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.89901\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1173 - accuracy: 0.9677 - val_loss: 0.7612 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.89901\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0916 - accuracy: 0.9677 - val_loss: 0.6356 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.89901\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.1232 - accuracy: 0.9616 - val_loss: 0.4759 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.89901\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.1160 - accuracy: 0.9647 - val_loss: 0.4371 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.89901\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1345 - accuracy: 0.9629 - val_loss: 0.7096 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.89901\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0634 - accuracy: 0.9842 - val_loss: 0.3816 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.89901\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0727 - accuracy: 0.9769 - val_loss: 0.7170 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.89901\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1437 - accuracy: 0.9531 - val_loss: 0.9299 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.89901\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 9s 172ms/step - loss: 0.1407 - accuracy: 0.9543 - val_loss: 1.2964 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.89901\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0457 - accuracy: 0.9866 - val_loss: 0.7243 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.89901\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0622 - accuracy: 0.9793 - val_loss: 0.5128 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.89901\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0646 - accuracy: 0.9842 - val_loss: 0.3657 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.89901\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0387 - accuracy: 0.9860 - val_loss: 0.5074 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.89901\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 9s 166ms/step - loss: 0.0771 - accuracy: 0.9781 - val_loss: 0.5838 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.89901\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0864 - accuracy: 0.9732 - val_loss: 0.7232 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.89901\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1704 - accuracy: 0.9531 - val_loss: 0.7832 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.89901\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0897 - accuracy: 0.9732 - val_loss: 0.5263 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.89901\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.1223 - accuracy: 0.9622 - val_loss: 0.6286 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.89901\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 0.4106 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.89901\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0433 - accuracy: 0.9872 - val_loss: 0.4656 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.89901\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0892 - accuracy: 0.9689 - val_loss: 0.9271 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.89901\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.1248 - accuracy: 0.9598 - val_loss: 0.7977 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.89901\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1000 - accuracy: 0.9671 - val_loss: 0.5697 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.89901\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.1065 - accuracy: 0.9708 - val_loss: 0.8496 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.89901\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1092 - accuracy: 0.9641 - val_loss: 0.8958 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.89901\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0683 - accuracy: 0.9817 - val_loss: 0.5376 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.89901\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0605 - accuracy: 0.9823 - val_loss: 0.5194 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.89901\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0665 - accuracy: 0.9769 - val_loss: 0.6304 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.89901\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0673 - accuracy: 0.9793 - val_loss: 0.5498 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.89901\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1868 - accuracy: 0.9488 - val_loss: 0.7962 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.89901\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0715 - accuracy: 0.9732 - val_loss: 0.6218 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.89901\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0436 - accuracy: 0.9872 - val_loss: 0.3465 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.89901\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.1150 - accuracy: 0.9695 - val_loss: 0.6569 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.89901\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.1079 - accuracy: 0.9683 - val_loss: 0.7225 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.89901\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0597 - accuracy: 0.9799 - val_loss: 0.5949 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.89901\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0661 - accuracy: 0.9762 - val_loss: 0.6501 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.89901\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0687 - accuracy: 0.9811 - val_loss: 0.4531 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.89901\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0554 - accuracy: 0.9829 - val_loss: 0.4700 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.89901\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0732 - accuracy: 0.9744 - val_loss: 0.6746 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.89901\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0854 - accuracy: 0.9695 - val_loss: 0.6635 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.89901\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1093 - accuracy: 0.9689 - val_loss: 0.6457 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.89901\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0682 - accuracy: 0.9769 - val_loss: 0.5688 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.89901\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0693 - accuracy: 0.9805 - val_loss: 0.8941 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.89901\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0664 - accuracy: 0.9781 - val_loss: 0.6983 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.89901\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0435 - accuracy: 0.9878 - val_loss: 0.4101 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.89901\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.1299 - accuracy: 0.9598 - val_loss: 0.6150 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.89901\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0774 - accuracy: 0.9756 - val_loss: 0.5535 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.89901\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.1146 - accuracy: 0.9641 - val_loss: 0.8651 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.89901\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.1609 - accuracy: 0.9519 - val_loss: 0.8977 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.89901\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0532 - accuracy: 0.9829 - val_loss: 0.3696 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00119: val_accuracy improved from 0.89901 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0412 - accuracy: 0.9890 - val_loss: 0.6077 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.90394\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0843 - accuracy: 0.9708 - val_loss: 0.5062 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.90394\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0562 - accuracy: 0.9842 - val_loss: 0.3404 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.90394\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0717 - accuracy: 0.9811 - val_loss: 0.3498 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.90394\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0404 - accuracy: 0.9878 - val_loss: 0.3002 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00124: val_accuracy improved from 0.90394 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 9s 172ms/step - loss: 0.0640 - accuracy: 0.9829 - val_loss: 5.2894 - val_accuracy: 0.2956\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91133\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 9s 172ms/step - loss: 0.0824 - accuracy: 0.9787 - val_loss: 2.7082 - val_accuracy: 0.5148\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91133\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 9s 172ms/step - loss: 0.0700 - accuracy: 0.9793 - val_loss: 0.5669 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91133\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0690 - accuracy: 0.9793 - val_loss: 0.5262 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91133\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0461 - accuracy: 0.9860 - val_loss: 0.5523 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91133\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0756 - accuracy: 0.9793 - val_loss: 0.6259 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91133\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0456 - accuracy: 0.9878 - val_loss: 0.4763 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91133\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0484 - accuracy: 0.9872 - val_loss: 0.5246 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91133\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0423 - accuracy: 0.9860 - val_loss: 0.5263 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91133\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 9s 173ms/step - loss: 0.0678 - accuracy: 0.9793 - val_loss: 0.8639 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91133\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0895 - accuracy: 0.9702 - val_loss: 0.7256 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91133\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0731 - accuracy: 0.9781 - val_loss: 0.6391 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91133\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0610 - accuracy: 0.9781 - val_loss: 0.5810 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91133\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0391 - accuracy: 0.9903 - val_loss: 0.4255 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91133\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0406 - accuracy: 0.9860 - val_loss: 0.5611 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91133\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0429 - accuracy: 0.9848 - val_loss: 0.8958 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91133\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0522 - accuracy: 0.9842 - val_loss: 0.7980 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.91133\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0441 - accuracy: 0.9884 - val_loss: 0.4263 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.91133\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.3921 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.91133\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0528 - accuracy: 0.9854 - val_loss: 0.6563 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.91133\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 0.7013 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.91133\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0454 - accuracy: 0.9866 - val_loss: 0.8054 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.91133\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.5768 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.91133\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0541 - accuracy: 0.9787 - val_loss: 0.4407 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.91133\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0371 - accuracy: 0.9890 - val_loss: 0.7159 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.91133\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0769 - accuracy: 0.9805 - val_loss: 0.5705 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.91133\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.1425 - accuracy: 0.9549 - val_loss: 0.8470 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.91133\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0802 - accuracy: 0.9787 - val_loss: 0.4949 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.91133\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0321 - accuracy: 0.9921 - val_loss: 0.5186 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.91133\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.3845 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.91133\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 0.3699 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.91133\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0390 - accuracy: 0.9854 - val_loss: 0.7493 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.91133\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0557 - accuracy: 0.9836 - val_loss: 0.5196 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.91133\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0858 - accuracy: 0.9726 - val_loss: 0.6635 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.91133\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.1056 - accuracy: 0.9677 - val_loss: 0.8746 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.91133\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.1092 - accuracy: 0.9756 - val_loss: 0.4361 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.91133\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0262 - accuracy: 0.9933 - val_loss: 0.3821 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.91133\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0173 - accuracy: 0.9970 - val_loss: 0.3622 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.91133\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.3041 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.91133\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0209 - accuracy: 0.9951 - val_loss: 0.3743 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.91133\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.4801 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.91133\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0602 - accuracy: 0.9836 - val_loss: 0.6301 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.91133\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0406 - accuracy: 0.9866 - val_loss: 0.5769 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.91133\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0319 - accuracy: 0.9909 - val_loss: 0.6753 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.91133\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0752 - accuracy: 0.9756 - val_loss: 0.6252 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.91133\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0550 - accuracy: 0.9842 - val_loss: 0.6689 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.91133\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0519 - accuracy: 0.9842 - val_loss: 0.6835 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.91133\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0503 - accuracy: 0.9866 - val_loss: 0.7505 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.91133\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0193 - accuracy: 0.9957 - val_loss: 0.4125 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.91133\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0321 - accuracy: 0.9933 - val_loss: 0.4908 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.91133\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0370 - accuracy: 0.9909 - val_loss: 0.6473 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.91133\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0507 - accuracy: 0.9854 - val_loss: 0.4862 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.91133\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0269 - accuracy: 0.9890 - val_loss: 0.4167 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.91133\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 0.4971 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.91133\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0500 - accuracy: 0.9854 - val_loss: 0.5434 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.91133\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0657 - accuracy: 0.9732 - val_loss: 0.8974 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.91133\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0700 - accuracy: 0.9811 - val_loss: 1.1796 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.91133\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0464 - accuracy: 0.9872 - val_loss: 0.5345 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.91133\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 0.4864 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.91133\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0422 - accuracy: 0.9909 - val_loss: 0.3587 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00184: val_accuracy improved from 0.91133 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.4333 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92857\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0548 - accuracy: 0.9903 - val_loss: 0.4195 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92857\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0432 - accuracy: 0.9896 - val_loss: 0.5025 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92857\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0715 - accuracy: 0.9799 - val_loss: 0.6361 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92857\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0776 - accuracy: 0.9793 - val_loss: 0.6128 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92857\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0636 - accuracy: 0.9848 - val_loss: 0.4355 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92857\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.3996 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92857\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0318 - accuracy: 0.9890 - val_loss: 0.4889 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92857\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 0.4063 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92857\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.5544 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92857\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 0.5115 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92857\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.5909 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92857\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.3747 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92857\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0201 - accuracy: 0.9951 - val_loss: 0.4941 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92857\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 0.9717 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92857\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0416 - accuracy: 0.9872 - val_loss: 0.5617 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92857\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.6350 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92857\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 0.5151 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92857\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0498 - accuracy: 0.9878 - val_loss: 0.6161 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92857\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 0.5315 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92857\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0280 - accuracy: 0.9896 - val_loss: 0.4612 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92857\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.4461 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92857\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0611 - accuracy: 0.9842 - val_loss: 0.9316 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92857\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0621 - accuracy: 0.9817 - val_loss: 0.5027 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92857\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0495 - accuracy: 0.9860 - val_loss: 0.6151 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92857\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0649 - accuracy: 0.9793 - val_loss: 0.6452 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92857\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0293 - accuracy: 0.9890 - val_loss: 0.5408 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92857\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0809 - accuracy: 0.9775 - val_loss: 0.8694 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92857\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0308 - accuracy: 0.9903 - val_loss: 0.5391 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92857\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0705 - accuracy: 0.9829 - val_loss: 0.6235 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92857\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0299 - accuracy: 0.9890 - val_loss: 0.4452 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92857\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0472 - accuracy: 0.9866 - val_loss: 0.4917 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.92857\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.4511 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92857\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0302 - accuracy: 0.9921 - val_loss: 0.4248 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92857\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0220 - accuracy: 0.9945 - val_loss: 0.4570 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92857\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.4649 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92857\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.3695 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.92857\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.92857\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.92857\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.4282 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.92857\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.7854 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.92857\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0836 - accuracy: 0.9787 - val_loss: 0.9224 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.92857\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0793 - accuracy: 0.9744 - val_loss: 0.8502 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92857\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0484 - accuracy: 0.9848 - val_loss: 0.6858 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92857\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.6532 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92857\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.4893 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92857\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.5795 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92857\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 10s 192ms/step - loss: 0.0296 - accuracy: 0.9933 - val_loss: 0.5420 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92857\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0533 - accuracy: 0.9817 - val_loss: 0.9673 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92857\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0753 - accuracy: 0.9744 - val_loss: 0.7021 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92857\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0424 - accuracy: 0.9903 - val_loss: 0.5875 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92857\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0365 - accuracy: 0.9927 - val_loss: 2.0185 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92857\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0251 - accuracy: 0.9909 - val_loss: 0.5772 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92857\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.6972 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92857\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0356 - accuracy: 0.9890 - val_loss: 0.4688 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92857\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0496 - accuracy: 0.9848 - val_loss: 1.1034 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92857\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0650 - accuracy: 0.9817 - val_loss: 0.6957 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.92857\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0773 - accuracy: 0.9781 - val_loss: 0.5612 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.92857\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.3673 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.92857\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.3613 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.92857\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.4329 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.92857\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.3946 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.92857\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.4809 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.92857\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 9s 172ms/step - loss: 0.0191 - accuracy: 0.9957 - val_loss: 0.3864 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.92857\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.3716 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.92857\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0236 - accuracy: 0.9951 - val_loss: 0.4178 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.92857\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.4504 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.92857\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.7623 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92857\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.5215 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.92857\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.3643 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.92857\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.3072 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.92857\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 0.4684 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.92857\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.3953 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.92857\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.4262 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.92857\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.3994 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.92857\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0105 - accuracy: 0.9957 - val_loss: 0.4912 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.92857\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.6446 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.92857\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.4583 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.92857\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.4660 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.92857\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.5476 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.92857\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 9s 172ms/step - loss: 0.0407 - accuracy: 0.9860 - val_loss: 0.5941 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.92857\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0695 - accuracy: 0.9811 - val_loss: 0.5535 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.92857\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0541 - accuracy: 0.9854 - val_loss: 0.6375 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.92857\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0517 - accuracy: 0.9866 - val_loss: 0.6330 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.92857\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0411 - accuracy: 0.9896 - val_loss: 0.4040 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.92857\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.5933 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.92857\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0112 - accuracy: 0.9939 - val_loss: 0.4551 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.92857\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.4414 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.92857\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.4214 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.92857\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.4258 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.92857\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.4359 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.92857\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0312 - accuracy: 0.9921 - val_loss: 0.6387 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.92857\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.4687 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.92857\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.4603 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.92857\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.5030 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.92857\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4283 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.92857\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0418 - accuracy: 0.9890 - val_loss: 1.0838 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.92857\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.1526 - accuracy: 0.9525 - val_loss: 2.0937 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.92857\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0443 - accuracy: 0.9872 - val_loss: 0.8957 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.92857\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.4170 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.92857\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0090 - accuracy: 0.9957 - val_loss: 0.4854 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.92857\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.5229 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.92857\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4372 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.92857\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 0.4237 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.92857\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0338 - accuracy: 0.9878 - val_loss: 0.9956 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.92857\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0284 - accuracy: 0.9890 - val_loss: 0.6623 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.92857\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0274 - accuracy: 0.9927 - val_loss: 0.6081 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.92857\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.4479 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.92857\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.4792 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.92857\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5176 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.92857\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.5032 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.92857\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0350 - accuracy: 0.9921 - val_loss: 0.4432 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.92857\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.6231 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.92857\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0199 - accuracy: 0.9970 - val_loss: 0.4257 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.92857\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.5536 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.92857\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0837 - accuracy: 0.9811 - val_loss: 1.0090 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.92857\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.1290 - accuracy: 0.9641 - val_loss: 1.4040 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.92857\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0734 - accuracy: 0.9811 - val_loss: 0.6893 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.92857\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.4596 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.92857\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.3777 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.92857\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.3584 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.92857\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.4026 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.92857\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.3970 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.92857\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.3150 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.92857\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.4717 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.92857\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.3728 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.92857\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.3942 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.92857\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4656 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.92857\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5182 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.92857\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4392 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.92857\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4168 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.92857\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.92857\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0313 - accuracy: 0.9933 - val_loss: 0.7677 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.92857\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0276 - accuracy: 0.9921 - val_loss: 0.7380 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.92857\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.6277 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.92857\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.6514 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.92857\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.5004 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.92857\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.5247 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.92857\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.4973 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.92857\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.5465 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.92857\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0305 - accuracy: 0.9915 - val_loss: 0.5835 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.92857\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.3891 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.92857\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0137 - accuracy: 0.9939 - val_loss: 0.5304 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.92857\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.8133 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.92857\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0920 - accuracy: 0.9720 - val_loss: 0.6961 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.92857\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0654 - accuracy: 0.9842 - val_loss: 0.8342 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.92857\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0552 - accuracy: 0.9848 - val_loss: 0.5687 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.92857\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0172 - accuracy: 0.9933 - val_loss: 0.4691 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.92857\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.4070 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.92857\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.3622 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.92857\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.3863 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.92857\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.3930 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.92857\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.3182 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.92857\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3267 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.92857\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.92857\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3475 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.92857\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 8.1490e-04 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.92857\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 5.6373e-04 - accuracy: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00342: val_accuracy improved from 0.92857 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 6.5324e-04 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93350\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 6.1431e-04 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93350\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 7.2189e-04 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93350\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 4.4868e-04 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93350\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4981 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93350\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.5248 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93350\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0198 - accuracy: 0.9951 - val_loss: 0.5308 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93350\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0620 - accuracy: 0.9823 - val_loss: 2.1204 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93350\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0767 - accuracy: 0.9762 - val_loss: 0.9842 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93350\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.5481 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93350\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0301 - accuracy: 0.9921 - val_loss: 0.4200 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93350\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.4015 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93350\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.4882 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93350\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.5094 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93350\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.3344 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93350\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93350\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0375 - accuracy: 0.9872 - val_loss: 0.6574 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93350\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 9s 172ms/step - loss: 0.0471 - accuracy: 0.9884 - val_loss: 0.7561 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93350\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0163 - accuracy: 0.9976 - val_loss: 0.4853 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93350\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.5653 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93350\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.4485 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93350\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0731 - accuracy: 0.9817 - val_loss: 0.7598 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93350\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0525 - accuracy: 0.9829 - val_loss: 0.7659 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93350\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0371 - accuracy: 0.9909 - val_loss: 0.4613 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93350\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.5053 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93350\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.5764 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93350\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.4017 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93350\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.4662 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93350\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.4393 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93350\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.3784 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93350\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.4120 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93350\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.3924 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93350\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.4013 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93350\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4405 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93350\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.4652 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93350\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.5343 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93350\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.4507 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93350\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.5223 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93350\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.5520 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93350\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.4596 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93350\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.5195 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93350\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.5050 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93350\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0539 - accuracy: 0.9866 - val_loss: 0.9121 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93350\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0576 - accuracy: 0.9817 - val_loss: 0.5620 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93350\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.4913 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93350\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5334 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93350\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0459 - accuracy: 0.9866 - val_loss: 0.5529 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93350\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.5242 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93350\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.4962 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93350\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4185 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93350\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.4085 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93350\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93350\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3576 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93350\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0309 - accuracy: 0.9939 - val_loss: 0.8387 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93350\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0641 - accuracy: 0.9842 - val_loss: 0.4021 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93350\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.4091 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93350\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3453 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93350\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4572 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93350\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.3696 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93350\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.4626 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93350\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.4085 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93350\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.5390 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93350\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.4940 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93350\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0085 - accuracy: 0.9957 - val_loss: 0.4593 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93350\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.4805 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93350\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4499 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93350\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0348 - accuracy: 0.9909 - val_loss: 1.1579 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93350\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 0.7192 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.93350\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0510 - accuracy: 0.9866 - val_loss: 0.4510 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.93350\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 9s 172ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.4338 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.93350\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.4490 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.93350\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.4482 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.93350\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0239 - accuracy: 0.9957 - val_loss: 0.4247 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.93350\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.5630 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93350\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.4131 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93350\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3917 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93350\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93350\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4565 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.93350\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.4358 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.93350\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0191 - accuracy: 0.9957 - val_loss: 0.4658 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93350\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.4684 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93350\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.4513 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93350\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 9s 166ms/step - loss: 0.0172 - accuracy: 0.9921 - val_loss: 0.5557 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93350\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.6917 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93350\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.5364 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93350\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.5442 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93350\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.4634 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.93350\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.4636 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.93350\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0190 - accuracy: 0.9951 - val_loss: 0.5680 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.93350\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.4474 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.93350\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.6688 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.93350\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.6893 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.93350\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.4793 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.93350\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4811 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.93350\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.4890 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.93350\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 1.1005 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.93350\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0142 - accuracy: 0.9945 - val_loss: 0.4755 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.93350\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.7624 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.93350\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0282 - accuracy: 0.9927 - val_loss: 0.6122 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.93350\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.5064 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.93350\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4752 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.93350\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4620 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.93350\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4909 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.93350\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 5.9222e-04 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.93350\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4892 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.93350\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4741 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.93350\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 7.6433e-04 - accuracy: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.93350\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 5.3682e-04 - accuracy: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.93350\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.5488 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.93350\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0113 - accuracy: 0.9982 - val_loss: 0.5855 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.93350\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.4905 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.93350\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.6205 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.93350\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 9s 171ms/step - loss: 0.0470 - accuracy: 0.9890 - val_loss: 0.7558 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.93350\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0441 - accuracy: 0.9884 - val_loss: 0.8793 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.93350\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.6319 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.93350\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.4723 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.93350\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.3647 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.93350\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.3508 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.93350\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.4738 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.93350\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0806 - accuracy: 0.9848 - val_loss: 0.7593 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.93350\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 0.0354 - accuracy: 0.9903 - val_loss: 0.7067 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.93350\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0338 - accuracy: 0.9927 - val_loss: 0.5141 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.93350\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.4385 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.93350\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.3533 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.93350\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0248 - accuracy: 0.9939 - val_loss: 0.7306 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.93350\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 0.6055 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.93350\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.5504 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.93350\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.4663 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.93350\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.6493 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.93350\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.3500 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.93350\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.3920 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.93350\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.3477 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.93350\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.3965 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.93350\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.4327 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.93350\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.4615 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.93350\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.93350\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.93350\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.93350\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.4293 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.93350\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 0.5113 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.93350\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.5672 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.93350\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4770 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.93350\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4192 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.93350\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 5.0059e-04 - accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.93350\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 4.0242e-04 - accuracy: 1.0000 - val_loss: 0.4561 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.93350\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 6.7365e-04 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.93350\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 3.2609e-04 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.93350\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 7.4088e-04 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.93350\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 2.9168e-04 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.93350\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 3.0974e-04 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.93350\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 2.8722e-04 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.93350\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 2.2368e-04 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.93350\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 2.4930e-04 - accuracy: 1.0000 - val_loss: 0.4775 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.93350\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 9s 169ms/step - loss: 2.2008e-04 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.93350\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 9s 166ms/step - loss: 2.1758e-04 - accuracy: 1.0000 - val_loss: 0.3840 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00497: val_accuracy improved from 0.93350 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 9s 167ms/step - loss: 4.7290e-04 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.93842\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 9s 170ms/step - loss: 1.7192e-04 - accuracy: 1.0000 - val_loss: 0.4777 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.93842\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 9s 168ms/step - loss: 1.9496e-04 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.93842\n",
            "Epoch 1/500\n",
            "52/52 [==============================] - 27s 430ms/step - loss: 2.1719 - accuracy: 0.2290 - val_loss: 2.7025 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09360, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 1.4813 - accuracy: 0.4683 - val_loss: 4.4777 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.09360\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 1.0040 - accuracy: 0.6687 - val_loss: 6.7675 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.09360\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.8472 - accuracy: 0.7320 - val_loss: 6.0255 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.09360\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.6495 - accuracy: 0.7777 - val_loss: 8.5997 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.09360\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.5945 - accuracy: 0.8039 - val_loss: 8.4241 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.09360\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.6142 - accuracy: 0.7996 - val_loss: 5.5528 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.09360 to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.4786 - accuracy: 0.8471 - val_loss: 4.5212 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.09852\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.4709 - accuracy: 0.8398 - val_loss: 4.8015 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.09852\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.4492 - accuracy: 0.8575 - val_loss: 2.9611 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.09852\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.3649 - accuracy: 0.8721 - val_loss: 3.5510 - val_accuracy: 0.1675\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.09852 to 0.16749, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.3984 - accuracy: 0.8697 - val_loss: 2.1292 - val_accuracy: 0.3695\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.16749 to 0.36946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.3531 - accuracy: 0.8806 - val_loss: 1.0171 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.36946 to 0.68719, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.3441 - accuracy: 0.8922 - val_loss: 2.2730 - val_accuracy: 0.4828\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.68719\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.3154 - accuracy: 0.8867 - val_loss: 0.7150 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.68719 to 0.76108, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.2626 - accuracy: 0.9099 - val_loss: 0.7118 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.76108 to 0.78325, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.2817 - accuracy: 0.9111 - val_loss: 1.5493 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.78325\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.2565 - accuracy: 0.9105 - val_loss: 0.8414 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.78325\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.2453 - accuracy: 0.9202 - val_loss: 1.2030 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.78325\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.2067 - accuracy: 0.9336 - val_loss: 1.0658 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.78325\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.2181 - accuracy: 0.9269 - val_loss: 0.5882 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.78325 to 0.84975, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.2367 - accuracy: 0.9263 - val_loss: 0.8769 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.84975\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.1915 - accuracy: 0.9385 - val_loss: 2.5703 - val_accuracy: 0.5345\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.84975\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.1921 - accuracy: 0.9367 - val_loss: 0.7809 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.84975\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.1737 - accuracy: 0.9403 - val_loss: 1.1163 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.84975\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.1972 - accuracy: 0.9324 - val_loss: 1.2197 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.84975\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.1728 - accuracy: 0.9385 - val_loss: 1.6427 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.84975\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.2237 - accuracy: 0.9281 - val_loss: 1.2120 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.84975\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.2292 - accuracy: 0.9269 - val_loss: 1.1096 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.84975\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.1604 - accuracy: 0.9440 - val_loss: 0.6094 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.84975\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.1699 - accuracy: 0.9421 - val_loss: 0.9650 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.84975\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.1742 - accuracy: 0.9446 - val_loss: 2.4727 - val_accuracy: 0.4852\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.84975\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.1532 - accuracy: 0.9464 - val_loss: 0.5751 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.84975\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.1266 - accuracy: 0.9598 - val_loss: 0.8780 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.84975\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.1832 - accuracy: 0.9354 - val_loss: 1.4080 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.84975\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.1706 - accuracy: 0.9482 - val_loss: 0.7949 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.84975\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.1728 - accuracy: 0.9409 - val_loss: 1.0410 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.84975\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.1352 - accuracy: 0.9562 - val_loss: 0.8774 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.84975\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.1259 - accuracy: 0.9616 - val_loss: 0.7754 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.84975\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0899 - accuracy: 0.9762 - val_loss: 1.1014 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.84975\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.1178 - accuracy: 0.9622 - val_loss: 0.8714 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.84975\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0977 - accuracy: 0.9695 - val_loss: 0.7226 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.84975\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0713 - accuracy: 0.9769 - val_loss: 0.4815 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.84975 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.1190 - accuracy: 0.9537 - val_loss: 0.8676 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.86946\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.1138 - accuracy: 0.9622 - val_loss: 1.0843 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.86946\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0986 - accuracy: 0.9689 - val_loss: 1.0036 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.86946\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.2497 - accuracy: 0.9160 - val_loss: 0.6707 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.86946\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.1270 - accuracy: 0.9610 - val_loss: 1.6458 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.86946\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.1019 - accuracy: 0.9622 - val_loss: 0.7994 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.86946\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.1010 - accuracy: 0.9683 - val_loss: 0.8418 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.86946\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0913 - accuracy: 0.9677 - val_loss: 1.4795 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.86946\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.1073 - accuracy: 0.9610 - val_loss: 1.1427 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.86946\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.2472 - accuracy: 0.9208 - val_loss: 1.5624 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.86946\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0873 - accuracy: 0.9769 - val_loss: 0.5120 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.86946\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0625 - accuracy: 0.9823 - val_loss: 0.6035 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.86946\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0450 - accuracy: 0.9884 - val_loss: 0.4407 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.86946 to 0.87931, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0624 - accuracy: 0.9799 - val_loss: 0.4264 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.87931\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.1377 - accuracy: 0.9574 - val_loss: 1.7214 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.87931\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.1213 - accuracy: 0.9629 - val_loss: 0.7403 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.87931\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0600 - accuracy: 0.9811 - val_loss: 0.5615 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.87931\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.1092 - accuracy: 0.9677 - val_loss: 0.7474 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.87931\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0910 - accuracy: 0.9708 - val_loss: 0.5076 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.87931\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0769 - accuracy: 0.9732 - val_loss: 0.6028 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.87931\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0564 - accuracy: 0.9811 - val_loss: 0.9285 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.87931\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.1030 - accuracy: 0.9598 - val_loss: 0.7309 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.87931\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0910 - accuracy: 0.9750 - val_loss: 1.2140 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.87931\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0633 - accuracy: 0.9775 - val_loss: 0.5849 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.87931\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0611 - accuracy: 0.9817 - val_loss: 0.6838 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.87931\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.1279 - accuracy: 0.9610 - val_loss: 0.6397 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.87931\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0672 - accuracy: 0.9811 - val_loss: 0.8744 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.87931\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0645 - accuracy: 0.9811 - val_loss: 1.8398 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.87931\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0792 - accuracy: 0.9750 - val_loss: 1.0093 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.87931\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.1110 - accuracy: 0.9586 - val_loss: 1.5512 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.87931\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0735 - accuracy: 0.9793 - val_loss: 0.5136 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.87931\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0540 - accuracy: 0.9854 - val_loss: 0.5921 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.87931\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0416 - accuracy: 0.9872 - val_loss: 0.4742 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.87931\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0493 - accuracy: 0.9848 - val_loss: 0.5943 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.87931\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0560 - accuracy: 0.9823 - val_loss: 0.8857 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.87931\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0459 - accuracy: 0.9836 - val_loss: 0.5880 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.87931\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0335 - accuracy: 0.9896 - val_loss: 0.5807 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.87931\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0449 - accuracy: 0.9860 - val_loss: 0.6596 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.87931\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0464 - accuracy: 0.9872 - val_loss: 0.3978 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.87931 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0349 - accuracy: 0.9909 - val_loss: 0.4497 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.90887\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.1037 - accuracy: 0.9732 - val_loss: 1.3883 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.90887\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0918 - accuracy: 0.9708 - val_loss: 0.4706 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.90887\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0786 - accuracy: 0.9714 - val_loss: 0.7676 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.90887\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0667 - accuracy: 0.9775 - val_loss: 0.6240 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.90887\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0498 - accuracy: 0.9817 - val_loss: 0.9950 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.90887\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0679 - accuracy: 0.9793 - val_loss: 1.0472 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.90887\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0467 - accuracy: 0.9842 - val_loss: 0.4711 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.90887\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0390 - accuracy: 0.9860 - val_loss: 0.5092 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.90887\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0450 - accuracy: 0.9836 - val_loss: 1.0788 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.90887\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0672 - accuracy: 0.9750 - val_loss: 1.0849 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.90887\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0890 - accuracy: 0.9677 - val_loss: 1.0183 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.90887\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0527 - accuracy: 0.9817 - val_loss: 0.6478 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.90887\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0337 - accuracy: 0.9915 - val_loss: 0.6013 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.90887\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0541 - accuracy: 0.9823 - val_loss: 0.9902 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.90887\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0204 - accuracy: 0.9945 - val_loss: 0.4393 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.90887\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.4385 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00099: val_accuracy improved from 0.90887 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0407 - accuracy: 0.9878 - val_loss: 0.6451 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91379\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0612 - accuracy: 0.9823 - val_loss: 1.0364 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91379\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0495 - accuracy: 0.9848 - val_loss: 0.8249 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.91379\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.5353 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.91379\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0415 - accuracy: 0.9872 - val_loss: 0.6290 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.91379\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0351 - accuracy: 0.9884 - val_loss: 0.6502 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91379\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0416 - accuracy: 0.9842 - val_loss: 0.6896 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91379\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0667 - accuracy: 0.9732 - val_loss: 0.8334 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91379\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0922 - accuracy: 0.9695 - val_loss: 1.7160 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91379\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 21s 404ms/step - loss: 0.1504 - accuracy: 0.9488 - val_loss: 0.7232 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91379\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0632 - accuracy: 0.9829 - val_loss: 0.9373 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91379\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0578 - accuracy: 0.9787 - val_loss: 0.5559 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91379\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.1104 - accuracy: 0.9622 - val_loss: 0.8192 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91379\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0727 - accuracy: 0.9793 - val_loss: 0.5732 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91379\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0341 - accuracy: 0.9872 - val_loss: 0.4494 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91379\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.4364 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91379\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0306 - accuracy: 0.9909 - val_loss: 0.4072 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91379\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0254 - accuracy: 0.9903 - val_loss: 0.3942 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91379\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0540 - accuracy: 0.9842 - val_loss: 1.0458 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91379\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.1543 - accuracy: 0.9476 - val_loss: 0.7729 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91379\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0594 - accuracy: 0.9799 - val_loss: 1.1931 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91379\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0354 - accuracy: 0.9909 - val_loss: 0.6301 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91379\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0464 - accuracy: 0.9836 - val_loss: 0.8602 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91379\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0449 - accuracy: 0.9860 - val_loss: 0.5211 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91379\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0479 - accuracy: 0.9860 - val_loss: 0.4348 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91379\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0174 - accuracy: 0.9957 - val_loss: 0.3460 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00125: val_accuracy improved from 0.91379 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0115 - accuracy: 0.9951 - val_loss: 0.3537 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91872\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.4515 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91872\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.5246 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91872\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.4765 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91872\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0558 - accuracy: 0.9769 - val_loss: 0.9179 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91872\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0520 - accuracy: 0.9842 - val_loss: 1.5183 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91872\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.1002 - accuracy: 0.9665 - val_loss: 0.6738 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91872\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0820 - accuracy: 0.9726 - val_loss: 1.4636 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91872\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0516 - accuracy: 0.9823 - val_loss: 0.6510 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91872\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.6194 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91872\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.4335 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91872\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0184 - accuracy: 0.9957 - val_loss: 0.4089 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91872\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.4474 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91872\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0209 - accuracy: 0.9963 - val_loss: 0.4274 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91872\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.4045 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91872\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.4960 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.91872\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.3639 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.91872\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.3670 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00143: val_accuracy improved from 0.91872 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.5373 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.92365\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 0.5719 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.92365\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0372 - accuracy: 0.9903 - val_loss: 0.8148 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.92365\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0535 - accuracy: 0.9787 - val_loss: 1.7664 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.92365\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0662 - accuracy: 0.9799 - val_loss: 1.0248 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.92365\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0990 - accuracy: 0.9702 - val_loss: 1.5364 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.92365\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0369 - accuracy: 0.9848 - val_loss: 0.6716 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.92365\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.1045 - accuracy: 0.9677 - val_loss: 0.7223 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.92365\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0575 - accuracy: 0.9775 - val_loss: 0.6234 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.92365\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0323 - accuracy: 0.9909 - val_loss: 0.6271 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.92365\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 0.4856 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92365\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.4061 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92365\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 0.5141 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92365\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0608 - accuracy: 0.9781 - val_loss: 0.6730 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92365\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0583 - accuracy: 0.9848 - val_loss: 0.7171 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92365\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 0.7037 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92365\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0466 - accuracy: 0.9866 - val_loss: 0.9548 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92365\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 0.5831 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92365\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0946 - accuracy: 0.9732 - val_loss: 1.3570 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92365\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0428 - accuracy: 0.9836 - val_loss: 0.4539 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92365\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 21s 405ms/step - loss: 0.0172 - accuracy: 0.9933 - val_loss: 0.4294 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92365\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.4304 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92365\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.4441 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92365\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.4069 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92365\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 2.2256 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92365\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0573 - accuracy: 0.9805 - val_loss: 0.7745 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92365\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0661 - accuracy: 0.9799 - val_loss: 0.5422 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92365\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 0.9234 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92365\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.4612 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92365\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3868 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92365\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.4419 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92365\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.3542 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92365\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.5156 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92365\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.5805 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92365\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0377 - accuracy: 0.9909 - val_loss: 0.7665 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92365\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0796 - accuracy: 0.9775 - val_loss: 1.1674 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92365\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0887 - accuracy: 0.9726 - val_loss: 0.5285 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92365\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.5524 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92365\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0375 - accuracy: 0.9860 - val_loss: 0.5249 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92365\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.5139 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92365\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0371 - accuracy: 0.9860 - val_loss: 0.7961 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92365\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0521 - accuracy: 0.9854 - val_loss: 0.5860 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92365\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.4386 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92365\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0291 - accuracy: 0.9927 - val_loss: 0.4105 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92365\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0155 - accuracy: 0.9939 - val_loss: 0.5745 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92365\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.4124 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92365\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4159 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92365\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.5150 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92365\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0436 - accuracy: 0.9915 - val_loss: 0.7977 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92365\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 21s 405ms/step - loss: 0.0695 - accuracy: 0.9805 - val_loss: 1.2389 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92365\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.5642 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92365\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 21s 407ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.3857 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92365\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.3715 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92365\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.3658 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92365\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.4275 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92365\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.3701 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92365\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3643 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00200: val_accuracy improved from 0.92365 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.5886 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92611\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0353 - accuracy: 0.9903 - val_loss: 0.7678 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92611\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0465 - accuracy: 0.9854 - val_loss: 0.8794 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92611\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0734 - accuracy: 0.9738 - val_loss: 0.7434 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92611\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0750 - accuracy: 0.9714 - val_loss: 1.5255 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92611\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0589 - accuracy: 0.9799 - val_loss: 1.5681 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92611\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0647 - accuracy: 0.9775 - val_loss: 0.8033 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92611\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.5170 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92611\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 2.8389 - val_accuracy: 0.5911\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92611\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0930 - accuracy: 0.9708 - val_loss: 1.1694 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92611\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0505 - accuracy: 0.9848 - val_loss: 0.4695 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92611\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 0.4549 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92611\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.5828 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92611\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0260 - accuracy: 0.9903 - val_loss: 0.5358 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92611\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.4223 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92611\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.4989 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.92611\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0120 - accuracy: 0.9976 - val_loss: 0.3724 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92611\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 1.5078 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92611\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0591 - accuracy: 0.9866 - val_loss: 0.5328 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92611\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0304 - accuracy: 0.9921 - val_loss: 0.4602 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92611\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.5739 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.92611\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 0.5605 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.92611\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0275 - accuracy: 0.9896 - val_loss: 0.5738 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.92611\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.5107 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.92611\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0219 - accuracy: 0.9915 - val_loss: 0.5563 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.92611\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.5206 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.92611\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0202 - accuracy: 0.9927 - val_loss: 0.5274 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92611\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.5877 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92611\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.4955 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92611\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.4143 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92611\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.6163 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92611\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0697 - accuracy: 0.9836 - val_loss: 0.6297 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92611\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 0.6610 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92611\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0313 - accuracy: 0.9927 - val_loss: 0.5915 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92611\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.4062 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92611\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.4057 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92611\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0357 - accuracy: 0.9903 - val_loss: 0.5378 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92611\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 0.5957 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92611\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.3833 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92611\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0312 - accuracy: 0.9933 - val_loss: 1.6712 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92611\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.1006 - accuracy: 0.9756 - val_loss: 1.6756 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.92611\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0331 - accuracy: 0.9878 - val_loss: 0.5519 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.92611\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.3632 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.92611\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 0.6301 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.92611\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.3967 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.92611\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.3366 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.92611\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 0.5741 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.92611\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.4884 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.92611\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.4600 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.92611\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.4814 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.92611\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.4874 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.92611\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.5327 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92611\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0189 - accuracy: 0.9963 - val_loss: 0.5166 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.92611\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.5146 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.92611\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.4690 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.92611\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.3708 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.92611\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00257: val_accuracy improved from 0.92611 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93103\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 7.2650e-04 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93103\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 5.9383e-04 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00260: val_accuracy improved from 0.93103 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 21s 404ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.3313 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93350\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93350\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 6.0592e-04 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93350\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 4.5901e-04 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93350\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3770 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93350\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 9.6581e-04 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93350\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.3726 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00267: val_accuracy improved from 0.93350 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0285 - accuracy: 0.9951 - val_loss: 1.0676 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93596\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0361 - accuracy: 0.9884 - val_loss: 1.0270 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93596\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0426 - accuracy: 0.9842 - val_loss: 0.7619 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93596\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0598 - accuracy: 0.9860 - val_loss: 0.9334 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93596\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.5432 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93596\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0177 - accuracy: 0.9963 - val_loss: 0.5580 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93596\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.4601 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93596\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.4784 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93596\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.4281 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93596\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.3887 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93596\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0184 - accuracy: 0.9957 - val_loss: 0.4289 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93596\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.3242 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93596\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.5614 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93596\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.4223 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93596\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0126 - accuracy: 0.9939 - val_loss: 0.4625 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93596\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.6585 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93596\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.9457 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93596\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0324 - accuracy: 0.9872 - val_loss: 0.5963 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93596\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0243 - accuracy: 0.9909 - val_loss: 0.6351 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93596\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0496 - accuracy: 0.9890 - val_loss: 0.6285 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93596\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0425 - accuracy: 0.9878 - val_loss: 0.8545 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93596\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0181 - accuracy: 0.9957 - val_loss: 0.5108 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93596\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.4654 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93596\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4000 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93596\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.4139 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93596\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.3868 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93596\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93596\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 9.9723e-04 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93596\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 8.1635e-04 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93596\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 3.3595e-04 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93596\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4112 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93596\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3845 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93596\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.4689 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93596\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0303 - accuracy: 0.9921 - val_loss: 0.8625 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93596\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 0.4658 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93596\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0621 - accuracy: 0.9836 - val_loss: 0.9945 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93596\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0562 - accuracy: 0.9799 - val_loss: 0.9748 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93596\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0424 - accuracy: 0.9878 - val_loss: 1.2852 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93596\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0462 - accuracy: 0.9842 - val_loss: 0.5987 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93596\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.5336 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93596\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.5083 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93596\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0196 - accuracy: 0.9927 - val_loss: 0.3675 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93596\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.3320 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93596\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.3609 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93596\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5271 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93596\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.3740 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93596\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93596\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.3245 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93596\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3207 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00316: val_accuracy improved from 0.93596 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3242 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00317: val_accuracy improved from 0.93842 to 0.94089, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3480 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.94089\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3878 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.94089\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4351 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.94089\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.94089\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.4551 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.94089\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3415 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.94089\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.3374 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.94089\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 0.5926 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.94089\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0528 - accuracy: 0.9848 - val_loss: 0.6918 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.94089\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 21s 407ms/step - loss: 0.0601 - accuracy: 0.9829 - val_loss: 1.5838 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.94089\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0399 - accuracy: 0.9878 - val_loss: 1.0509 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.94089\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0140 - accuracy: 0.9970 - val_loss: 0.6763 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.94089\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.4759 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.94089\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.6044 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.94089\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.5198 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.94089\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.8529 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.94089\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0389 - accuracy: 0.9884 - val_loss: 0.6900 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.94089\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0229 - accuracy: 0.9890 - val_loss: 0.6066 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.94089\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 0.6797 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.94089\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0174 - accuracy: 0.9963 - val_loss: 0.4664 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.94089\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.4227 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.94089\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.4932 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.94089\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.4554 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.94089\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.3704 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.94089\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3866 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.94089\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.94089\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.94089\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 1.1268 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.94089\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.4941 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.94089\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5378 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.94089\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.5969 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.94089\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.8053 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.94089\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5340 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.94089\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4442 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.94089\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.94089\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 9.1606e-04 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.94089\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.7929 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.94089\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0644 - accuracy: 0.9817 - val_loss: 1.4394 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.94089\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0687 - accuracy: 0.9769 - val_loss: 2.9725 - val_accuracy: 0.5419\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.94089\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0433 - accuracy: 0.9866 - val_loss: 0.7046 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.94089\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 21s 404ms/step - loss: 0.0191 - accuracy: 0.9927 - val_loss: 0.5638 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.94089\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0103 - accuracy: 0.9951 - val_loss: 0.5275 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.94089\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4232 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.94089\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4430 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.94089\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4045 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.94089\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0233 - accuracy: 0.9939 - val_loss: 0.4358 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.94089\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.4534 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.94089\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0101 - accuracy: 0.9951 - val_loss: 0.5243 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.94089\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4261 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.94089\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.4667 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.94089\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.4909 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.94089\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.4752 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.94089\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.5259 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.94089\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 21s 405ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.6053 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.94089\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0222 - accuracy: 0.9945 - val_loss: 0.3720 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.94089\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4192 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.94089\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.3977 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.94089\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.4876 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.94089\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.4945 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.94089\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.4791 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.94089\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0213 - accuracy: 0.9951 - val_loss: 0.5442 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.94089\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.4408 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.94089\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.4733 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.94089\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.94089\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3414 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.94089\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.7298 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.94089\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.5597 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.94089\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.3885 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.94089\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.3876 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94089\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.7322 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94089\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.4704 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94089\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 0.5842 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94089\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.3749 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94089\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0264 - accuracy: 0.9945 - val_loss: 0.4275 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94089\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0131 - accuracy: 0.9982 - val_loss: 0.5310 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94089\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0513 - accuracy: 0.9842 - val_loss: 0.5925 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94089\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.5253 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94089\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.4864 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94089\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.7032 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94089\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.6151 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94089\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.4769 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94089\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.4185 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.94089\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.3500 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94089\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3317 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94089\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.3562 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94089\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 21s 407ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.3761 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94089\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.4566 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94089\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0073 - accuracy: 0.9963 - val_loss: 0.3835 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94089\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.3313 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94089\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.3770 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94089\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0196 - accuracy: 0.9927 - val_loss: 0.9071 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94089\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0286 - accuracy: 0.9927 - val_loss: 0.7411 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94089\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.5194 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94089\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.4051 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94089\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.3361 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94089\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.3701 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94089\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.3671 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94089\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.6565 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94089\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.4626 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94089\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0163 - accuracy: 0.9933 - val_loss: 0.5687 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94089\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.5013 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94089\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.5593 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94089\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4080 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94089\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 8.6025e-04 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94089\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94089\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 9.3308e-04 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94089\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 21s 404ms/step - loss: 6.6166e-04 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94089\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 6.1549e-04 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94089\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0148 - accuracy: 0.9976 - val_loss: 0.4463 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94089\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.4965 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94089\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.4084 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94089\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.4507 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94089\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.4653 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94089\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.4705 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94089\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5338 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94089\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4696 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94089\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.4463 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94089\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94089\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4894 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94089\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4986 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94089\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0093 - accuracy: 0.9945 - val_loss: 0.7483 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94089\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0522 - accuracy: 0.9878 - val_loss: 0.8629 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94089\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0151 - accuracy: 0.9933 - val_loss: 0.5135 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94089\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0399 - accuracy: 0.9866 - val_loss: 0.9244 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94089\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0427 - accuracy: 0.9860 - val_loss: 0.6548 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94089\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0207 - accuracy: 0.9957 - val_loss: 0.5609 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94089\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.5596 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94089\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0219 - accuracy: 0.9957 - val_loss: 0.4887 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94089\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.4325 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94089\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0080 - accuracy: 0.9963 - val_loss: 0.3874 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94089\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.3575 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94089\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.3233 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94089\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.2843 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94089\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.3523 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94089\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.2854 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94089\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.3797 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94089\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.3761 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94089\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.3984 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94089\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4648 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94089\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.3888 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94089\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94089\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.4333 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94089\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.3498 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94089\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3964 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94089\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.3401 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94089\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4756 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94089\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.5397 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94089\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.6569 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94089\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0260 - accuracy: 0.9896 - val_loss: 2.3730 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94089\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.5151 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94089\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.5584 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94089\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.3881 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94089\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.5599 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94089\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4725 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94089\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.5257 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94089\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.4392 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94089\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.4098 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94089\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.4969 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94089\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 0.7142 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94089\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94089\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.8261 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94089\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4618 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94089\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5023 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94089\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 9.2640e-04 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94089\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 2.3194e-04 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94089\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.3728 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94089\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 21s 407ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.4830 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94089\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.5331 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94089\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.4886 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94089\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.6244 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94089\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.5546 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94089\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 21s 404ms/step - loss: 0.0214 - accuracy: 0.9921 - val_loss: 0.6405 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94089\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 21s 406ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.8302 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94089\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.8136 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94089\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.5840 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94089\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.5659 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94089\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0161 - accuracy: 0.9939 - val_loss: 0.6395 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94089\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.5029 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94089\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.5457 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94089\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0198 - accuracy: 0.9927 - val_loss: 0.5064 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94089\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5538 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94089\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0091 - accuracy: 0.9957 - val_loss: 0.4726 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94089\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.4789 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb4a5ed4090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPRsEv-ZxgFw"
      },
      "source": [
        "학습한 모델의 accuracy와 val_accuracy를 시각화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKw8NPyflIbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7e32d198-faa3-409d-d78e-08c3ef0efb9b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(model_1.history.history[\"accuracy\"], label='m1_acc')\n",
        "plt.plot(model_1.history.history[\"val_accuracy\"], label='m1_vacc')\n",
        "\n",
        "plt.plot(model_2.history.history[\"accuracy\"], label='m2_acc')\n",
        "plt.plot(model_2.history.history[\"val_accuracy\"], label='m2_vacc')\n",
        "\n",
        "plt.plot(model_3.history.history[\"accuracy\"], label='m3_acc')\n",
        "plt.plot(model_3.history.history[\"val_accuracy\"], label='m3_acc')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYecHTAxxDgB"
      },
      "source": [
        "# 결과(예측값) 확인\n",
        "\n",
        "checkpoint를 통해 저장했던 h5 파일들을 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUxHcaWl0z30"
      },
      "source": [
        "model_1 = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/model_1.h5', compile=False)\n",
        "model_2 = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/model_2.h5', compile=False)\n",
        "model_3 = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/model_3.h5', compile=False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXid_wrA2Hd3"
      },
      "source": [
        "test 이미지들에 대해 ImageDataGenerator를 사용하기 위해 가상의 클래스인 none 폴더를 생성하여 모든 png 파일들을 none 폴더로 이동합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh6zt68w12-Q"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O3HCJC21Act",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d494385-f51a-481b-c4fb-88b9499f0010"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNcRHVsg1Ale",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97f4818-42ca-402d-b0f3-056d30d23578"
      },
      "source": [
        "predict_1 = model_1.predict_generator(test_generator).argmax(axis=1)\n",
        "predict_2 = model_2.predict_generator(test_generator).argmax(axis=1)\n",
        "predict_3 = model_3.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhtL-syp351o"
      },
      "source": [
        "# 제출용 csv 파일 생성하기\n",
        "\n",
        "3가지 예측값 중에서 최빈값(most frequent value)을 최종 예측값으로 제출합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "258b0b5a-8030-4eaa-ba72-54d1da743202"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')\n",
        "submission.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2049</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2050</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2051</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2052</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2053</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  digit\n",
              "0  2049      0\n",
              "1  2050      0\n",
              "2  2051      0\n",
              "3  2052      0\n",
              "4  2053      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSjwhrzw4SJD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8963e133-fd6c-4300-d391-8ea906ac2da8"
      },
      "source": [
        "submission[\"predict_1\"] = predict_1\n",
        "submission[\"predict_2\"] = predict_2\n",
        "submission[\"predict_3\"] = predict_3\n",
        "submission.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "      <th>predict_1</th>\n",
              "      <th>predict_2</th>\n",
              "      <th>predict_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2049</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2050</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2051</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2052</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2053</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  digit  predict_1  predict_2  predict_3\n",
              "0  2049      0          4          4          4\n",
              "1  2050      0          4          4          4\n",
              "2  2051      0          6          6          6\n",
              "3  2052      0          9          9          9\n",
              "4  2053      0          5          5          5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b15fee30-1c85-465a-b781-5a3ae9ed7bd1"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['predict_1','predict_2','predict_3']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]\n",
        "\n",
        "submission.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "      <th>predict_1</th>\n",
              "      <th>predict_2</th>\n",
              "      <th>predict_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2049</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2050</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2051</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2052</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2053</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  digit  predict_1  predict_2  predict_3\n",
              "0  2049      4          4          4          4\n",
              "1  2050      4          4          4          4\n",
              "2  2051      6          6          6          6\n",
              "3  2052      9          9          9          9\n",
              "4  2053      5          5          5          5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "cab5bd54-34e0-454c-d4ed-e4c5ccc2c041"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2049</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2050</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2051</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2052</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2053</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  digit\n",
              "0  2049      4\n",
              "1  2050      4\n",
              "2  2051      6\n",
              "3  2052      9\n",
              "4  2053      5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8fcd2c92-0c16-4d2f-de57-60c5edd8e037"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/submission_ensemble_3.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/submission_ensemble_3.csv')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a3e9d2f9-6173-4d34-9652-18281645559f\", \"submission_ensemble_3.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}