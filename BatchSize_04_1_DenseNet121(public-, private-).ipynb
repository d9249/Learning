{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BatchSize_04_1_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+S9PCugRA++PA1etNoJ7Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/BatchSize_04_1_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c4a497-d5fe-4faa-a0fe-7b6eb53a8279"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep  3 13:23:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffcdc856-6691-4b94-b8c3-0d40dc51c9b8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed34590-cee6-48e6-cdbc-3637510da3df"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d481b3c3-ab1d-4195-ba34-1117f38aad32"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "batch_size = 4\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size,  color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be71d89d-91c5-4503-da49-d00dc85ab446"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "411/411 [==============================] - 67s 96ms/step - loss: 2.4363 - accuracy: 0.1352 - val_loss: 6.1949 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11330, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 2/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 2.3022 - accuracy: 0.1657 - val_loss: 17.6874 - val_accuracy: 0.1059\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.11330\n",
            "Epoch 3/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 2.1141 - accuracy: 0.2339 - val_loss: 2.4292 - val_accuracy: 0.2291\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.11330 to 0.22906, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 4/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 1.8800 - accuracy: 0.3331 - val_loss: 8.7600 - val_accuracy: 0.2094\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.22906\n",
            "Epoch 5/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 1.5598 - accuracy: 0.4549 - val_loss: 5.6190 - val_accuracy: 0.3399\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.22906 to 0.33990, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 6/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 1.3210 - accuracy: 0.5481 - val_loss: 2.0033 - val_accuracy: 0.4507\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.33990 to 0.45074, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 7/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 1.2229 - accuracy: 0.5853 - val_loss: 2.1586 - val_accuracy: 0.4729\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.45074 to 0.47291, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 8/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 1.0490 - accuracy: 0.6504 - val_loss: 1.6544 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.47291 to 0.62808, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 9/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.9465 - accuracy: 0.6931 - val_loss: 3.1615 - val_accuracy: 0.5222\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.62808\n",
            "Epoch 10/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.8389 - accuracy: 0.7406 - val_loss: 0.6521 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.62808 to 0.78325, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 11/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.7684 - accuracy: 0.7509 - val_loss: 0.7441 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.78325\n",
            "Epoch 12/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.7347 - accuracy: 0.7686 - val_loss: 1.2799 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.78325\n",
            "Epoch 13/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.6676 - accuracy: 0.7826 - val_loss: 0.5808 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.78325 to 0.82266, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 14/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.6214 - accuracy: 0.8015 - val_loss: 0.7441 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.82266\n",
            "Epoch 15/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.6171 - accuracy: 0.8039 - val_loss: 0.7427 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.82266\n",
            "Epoch 16/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.5716 - accuracy: 0.8234 - val_loss: 0.4599 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.82266 to 0.84483, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 17/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.4743 - accuracy: 0.8502 - val_loss: 0.4873 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.84483 to 0.84729, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 18/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.4617 - accuracy: 0.8459 - val_loss: 0.5598 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.84729\n",
            "Epoch 19/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.4401 - accuracy: 0.8599 - val_loss: 0.4870 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.84729 to 0.85468, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 20/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.4269 - accuracy: 0.8544 - val_loss: 0.5656 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.85468\n",
            "Epoch 21/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.3728 - accuracy: 0.8837 - val_loss: 0.3484 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.85468 to 0.87931, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 22/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.3630 - accuracy: 0.8812 - val_loss: 0.4936 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.87931\n",
            "Epoch 23/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.3709 - accuracy: 0.8733 - val_loss: 0.5245 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.87931\n",
            "Epoch 24/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.3074 - accuracy: 0.8952 - val_loss: 0.7099 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.87931\n",
            "Epoch 25/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.3164 - accuracy: 0.8977 - val_loss: 0.3801 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.87931\n",
            "Epoch 26/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.3066 - accuracy: 0.9086 - val_loss: 0.4048 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.87931\n",
            "Epoch 27/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.3022 - accuracy: 0.8983 - val_loss: 0.4146 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.87931\n",
            "Epoch 28/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.2813 - accuracy: 0.9074 - val_loss: 0.4164 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.87931 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 29/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.2682 - accuracy: 0.9160 - val_loss: 0.3893 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.88424\n",
            "Epoch 30/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.2329 - accuracy: 0.9160 - val_loss: 0.4812 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.88424\n",
            "Epoch 31/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.2285 - accuracy: 0.9257 - val_loss: 0.3472 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.88424\n",
            "Epoch 32/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.1828 - accuracy: 0.9434 - val_loss: 0.4950 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.88424\n",
            "Epoch 33/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.2235 - accuracy: 0.9257 - val_loss: 0.5920 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.88424\n",
            "Epoch 34/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.1772 - accuracy: 0.9397 - val_loss: 0.5173 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.88424\n",
            "Epoch 35/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.2263 - accuracy: 0.9300 - val_loss: 0.5453 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.88424\n",
            "Epoch 36/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.1824 - accuracy: 0.9367 - val_loss: 0.4809 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.88424\n",
            "Epoch 37/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.1817 - accuracy: 0.9403 - val_loss: 0.3805 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.88424\n",
            "Epoch 38/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.1690 - accuracy: 0.9464 - val_loss: 0.4626 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.88424\n",
            "Epoch 39/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.1662 - accuracy: 0.9452 - val_loss: 0.3585 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.88424\n",
            "Epoch 40/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.1748 - accuracy: 0.9373 - val_loss: 0.4271 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.88424\n",
            "Epoch 41/500\n",
            "411/411 [==============================] - 34s 84ms/step - loss: 0.1601 - accuracy: 0.9482 - val_loss: 0.4687 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.88424\n",
            "Epoch 42/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.1318 - accuracy: 0.9543 - val_loss: 0.6309 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.88424\n",
            "Epoch 43/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.1442 - accuracy: 0.9549 - val_loss: 4.0525 - val_accuracy: 0.5345\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.88424\n",
            "Epoch 44/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.1492 - accuracy: 0.9507 - val_loss: 0.4267 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.88424\n",
            "Epoch 45/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.1411 - accuracy: 0.9555 - val_loss: 0.4700 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.88424\n",
            "Epoch 46/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.1245 - accuracy: 0.9641 - val_loss: 0.3642 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.88424 to 0.89901, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 47/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0986 - accuracy: 0.9708 - val_loss: 0.4146 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89901\n",
            "Epoch 48/500\n",
            "411/411 [==============================] - 34s 83ms/step - loss: 0.1371 - accuracy: 0.9598 - val_loss: 0.4535 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89901\n",
            "Epoch 49/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.1164 - accuracy: 0.9616 - val_loss: 0.4962 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89901\n",
            "Epoch 50/500\n",
            "411/411 [==============================] - 34s 84ms/step - loss: 0.1219 - accuracy: 0.9574 - val_loss: 0.3145 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.89901 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 51/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0963 - accuracy: 0.9695 - val_loss: 0.6611 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.90394\n",
            "Epoch 52/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.1083 - accuracy: 0.9659 - val_loss: 0.3450 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.90394\n",
            "Epoch 53/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.1174 - accuracy: 0.9629 - val_loss: 0.3815 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.90394\n",
            "Epoch 54/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.1652 - accuracy: 0.9470 - val_loss: 0.9071 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.90394\n",
            "Epoch 55/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0914 - accuracy: 0.9695 - val_loss: 0.5045 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.90394\n",
            "Epoch 56/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.1158 - accuracy: 0.9641 - val_loss: 0.4526 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.90394\n",
            "Epoch 57/500\n",
            "411/411 [==============================] - 34s 83ms/step - loss: 0.0921 - accuracy: 0.9732 - val_loss: 0.4134 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.90394\n",
            "Epoch 58/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0613 - accuracy: 0.9805 - val_loss: 0.5843 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.90394\n",
            "Epoch 59/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.1077 - accuracy: 0.9653 - val_loss: 0.4844 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.90394\n",
            "Epoch 60/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0869 - accuracy: 0.9720 - val_loss: 0.4770 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.90394\n",
            "Epoch 61/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0891 - accuracy: 0.9695 - val_loss: 0.6717 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.90394\n",
            "Epoch 62/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.1193 - accuracy: 0.9616 - val_loss: 0.4844 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.90394\n",
            "Epoch 63/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0880 - accuracy: 0.9689 - val_loss: 0.4916 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.90394\n",
            "Epoch 64/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0962 - accuracy: 0.9677 - val_loss: 0.3386 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.90394\n",
            "Epoch 65/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.1016 - accuracy: 0.9683 - val_loss: 0.5674 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.90394\n",
            "Epoch 66/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0764 - accuracy: 0.9732 - val_loss: 0.3536 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.90394\n",
            "Epoch 67/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0447 - accuracy: 0.9848 - val_loss: 0.4278 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.90394\n",
            "Epoch 68/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0503 - accuracy: 0.9829 - val_loss: 0.4143 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.90394\n",
            "Epoch 69/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0511 - accuracy: 0.9854 - val_loss: 0.3663 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.90394\n",
            "Epoch 70/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0837 - accuracy: 0.9720 - val_loss: 0.5069 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.90394\n",
            "Epoch 71/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0610 - accuracy: 0.9805 - val_loss: 0.4517 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.90394\n",
            "Epoch 72/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0538 - accuracy: 0.9836 - val_loss: 0.4536 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.90394\n",
            "Epoch 73/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0967 - accuracy: 0.9635 - val_loss: 0.7607 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90394\n",
            "Epoch 74/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0860 - accuracy: 0.9720 - val_loss: 0.4179 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.90394\n",
            "Epoch 75/500\n",
            "411/411 [==============================] - 36s 86ms/step - loss: 0.0406 - accuracy: 0.9872 - val_loss: 0.3971 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.90394\n",
            "Epoch 76/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0833 - accuracy: 0.9769 - val_loss: 0.4046 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.90394\n",
            "Epoch 77/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0492 - accuracy: 0.9866 - val_loss: 0.3960 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.90394\n",
            "Epoch 78/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0594 - accuracy: 0.9793 - val_loss: 0.4714 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.90394\n",
            "Epoch 79/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0517 - accuracy: 0.9829 - val_loss: 0.4927 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.90394\n",
            "Epoch 80/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0764 - accuracy: 0.9793 - val_loss: 0.6630 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.90394\n",
            "Epoch 81/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.3726 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.90394\n",
            "Epoch 82/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0295 - accuracy: 0.9890 - val_loss: 0.7676 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.90394\n",
            "Epoch 83/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0777 - accuracy: 0.9744 - val_loss: 0.6749 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.90394\n",
            "Epoch 84/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0633 - accuracy: 0.9823 - val_loss: 0.4688 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.90394\n",
            "Epoch 85/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.5059 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.90394\n",
            "Epoch 86/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 0.6973 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.90394\n",
            "Epoch 87/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0702 - accuracy: 0.9714 - val_loss: 0.5469 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.90394\n",
            "Epoch 88/500\n",
            "411/411 [==============================] - 34s 83ms/step - loss: 0.0600 - accuracy: 0.9781 - val_loss: 0.6181 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.90394\n",
            "Epoch 89/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0451 - accuracy: 0.9884 - val_loss: 0.3748 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.90394\n",
            "Epoch 90/500\n",
            "411/411 [==============================] - 34s 84ms/step - loss: 0.0254 - accuracy: 0.9927 - val_loss: 0.4343 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.90394\n",
            "Epoch 91/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0458 - accuracy: 0.9890 - val_loss: 0.4522 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.90394\n",
            "Epoch 92/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0405 - accuracy: 0.9872 - val_loss: 0.4875 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.90394\n",
            "Epoch 93/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0573 - accuracy: 0.9799 - val_loss: 0.5962 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.90394\n",
            "Epoch 94/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0727 - accuracy: 0.9775 - val_loss: 0.6596 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.90394\n",
            "Epoch 95/500\n",
            "411/411 [==============================] - 36s 86ms/step - loss: 0.0370 - accuracy: 0.9890 - val_loss: 1.9088 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.90394\n",
            "Epoch 96/500\n",
            "411/411 [==============================] - 34s 84ms/step - loss: 0.0392 - accuracy: 0.9878 - val_loss: 0.5927 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.90394\n",
            "Epoch 97/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0362 - accuracy: 0.9878 - val_loss: 0.8392 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.90394\n",
            "Epoch 98/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.4582 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00098: val_accuracy improved from 0.90394 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 99/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0576 - accuracy: 0.9854 - val_loss: 0.6522 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91133\n",
            "Epoch 100/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0324 - accuracy: 0.9903 - val_loss: 0.4859 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91133\n",
            "Epoch 101/500\n",
            "411/411 [==============================] - 34s 83ms/step - loss: 0.0566 - accuracy: 0.9817 - val_loss: 2.8189 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91133\n",
            "Epoch 102/500\n",
            "411/411 [==============================] - 34s 84ms/step - loss: 0.0424 - accuracy: 0.9848 - val_loss: 0.5518 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.91133\n",
            "Epoch 103/500\n",
            "411/411 [==============================] - 34s 84ms/step - loss: 0.0357 - accuracy: 0.9896 - val_loss: 0.6123 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.91133\n",
            "Epoch 104/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0415 - accuracy: 0.9860 - val_loss: 0.5428 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.91133\n",
            "Epoch 105/500\n",
            "411/411 [==============================] - 34s 83ms/step - loss: 0.0402 - accuracy: 0.9848 - val_loss: 0.5130 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91133\n",
            "Epoch 106/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0326 - accuracy: 0.9878 - val_loss: 0.5034 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91133\n",
            "Epoch 107/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 0.7444 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91133\n",
            "Epoch 108/500\n",
            "411/411 [==============================] - 34s 83ms/step - loss: 0.0512 - accuracy: 0.9829 - val_loss: 0.4126 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91133\n",
            "Epoch 109/500\n",
            "411/411 [==============================] - 34s 83ms/step - loss: 0.0820 - accuracy: 0.9744 - val_loss: 0.7535 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91133\n",
            "Epoch 110/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0429 - accuracy: 0.9848 - val_loss: 0.6383 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91133\n",
            "Epoch 111/500\n",
            "411/411 [==============================] - 34s 84ms/step - loss: 0.0413 - accuracy: 0.9848 - val_loss: 0.9810 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91133\n",
            "Epoch 112/500\n",
            "411/411 [==============================] - 34s 83ms/step - loss: 0.0316 - accuracy: 0.9896 - val_loss: 0.6135 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91133\n",
            "Epoch 113/500\n",
            "411/411 [==============================] - 34s 84ms/step - loss: 0.0675 - accuracy: 0.9793 - val_loss: 0.5404 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91133\n",
            "Epoch 114/500\n",
            "411/411 [==============================] - 34s 84ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.4526 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91133\n",
            "Epoch 115/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 0.5552 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91133\n",
            "Epoch 116/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 0.5102 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91133\n",
            "Epoch 117/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.5879 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91133\n",
            "Epoch 118/500\n",
            "411/411 [==============================] - 34s 83ms/step - loss: 0.0576 - accuracy: 0.9769 - val_loss: 0.7606 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91133\n",
            "Epoch 119/500\n",
            "411/411 [==============================] - 34s 83ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.4710 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91133\n",
            "Epoch 120/500\n",
            "411/411 [==============================] - 34s 83ms/step - loss: 0.0252 - accuracy: 0.9945 - val_loss: 0.4263 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91133\n",
            "Epoch 121/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0531 - accuracy: 0.9823 - val_loss: 0.4632 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91133\n",
            "Epoch 122/500\n",
            "411/411 [==============================] - 34s 83ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.6034 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91133\n",
            "Epoch 123/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0380 - accuracy: 0.9884 - val_loss: 0.5450 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91133\n",
            "Epoch 124/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0301 - accuracy: 0.9890 - val_loss: 0.5473 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91133\n",
            "Epoch 125/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0216 - accuracy: 0.9951 - val_loss: 0.4270 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91133\n",
            "Epoch 126/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0317 - accuracy: 0.9860 - val_loss: 0.4709 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91133\n",
            "Epoch 127/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0579 - accuracy: 0.9842 - val_loss: 0.4650 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91133\n",
            "Epoch 128/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.4219 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91133\n",
            "Epoch 129/500\n",
            "411/411 [==============================] - 34s 83ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.4577 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91133\n",
            "Epoch 130/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.6742 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91133\n",
            "Epoch 131/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 1.6774 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91133\n",
            "Epoch 132/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0497 - accuracy: 0.9836 - val_loss: 0.7894 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91133\n",
            "Epoch 133/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0234 - accuracy: 0.9903 - val_loss: 0.6263 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91133\n",
            "Epoch 134/500\n",
            "411/411 [==============================] - 34s 84ms/step - loss: 0.0549 - accuracy: 0.9854 - val_loss: 0.5746 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91133\n",
            "Epoch 135/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.6561 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91133\n",
            "Epoch 136/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 0.5426 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91133\n",
            "Epoch 137/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0354 - accuracy: 0.9927 - val_loss: 0.5166 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91133\n",
            "Epoch 138/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.5262 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91133\n",
            "Epoch 139/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.5287 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91133\n",
            "Epoch 140/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.7420 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91133\n",
            "Epoch 141/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0389 - accuracy: 0.9890 - val_loss: 0.7940 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.91133\n",
            "Epoch 142/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.3712 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00142: val_accuracy improved from 0.91133 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 143/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.5127 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.91626\n",
            "Epoch 144/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.6685 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.91626\n",
            "Epoch 145/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0320 - accuracy: 0.9909 - val_loss: 0.8842 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.91626\n",
            "Epoch 146/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0499 - accuracy: 0.9848 - val_loss: 0.6964 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.91626\n",
            "Epoch 147/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.6260 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.91626\n",
            "Epoch 148/500\n",
            "411/411 [==============================] - 35s 84ms/step - loss: 0.0119 - accuracy: 0.9939 - val_loss: 0.4396 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.91626\n",
            "Epoch 149/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0382 - accuracy: 0.9896 - val_loss: 0.4447 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.91626\n",
            "Epoch 150/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0307 - accuracy: 0.9884 - val_loss: 0.4107 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.91626\n",
            "Epoch 151/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.3463 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.91626\n",
            "Epoch 152/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.4749 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.91626\n",
            "Epoch 153/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0483 - accuracy: 0.9854 - val_loss: 0.4215 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.91626\n",
            "Epoch 154/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 0.6803 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.91626\n",
            "Epoch 155/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0211 - accuracy: 0.9951 - val_loss: 0.6049 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.91626\n",
            "Epoch 156/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.4608 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.91626\n",
            "Epoch 157/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0307 - accuracy: 0.9896 - val_loss: 0.4597 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.91626\n",
            "Epoch 158/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.3954 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00158: val_accuracy improved from 0.91626 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 159/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.5257 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.91872\n",
            "Epoch 160/500\n",
            "411/411 [==============================] - 36s 86ms/step - loss: 0.0387 - accuracy: 0.9854 - val_loss: 0.4909 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.91872\n",
            "Epoch 161/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0317 - accuracy: 0.9890 - val_loss: 0.4843 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.91872\n",
            "Epoch 162/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 0.4628 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.91872\n",
            "Epoch 163/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0351 - accuracy: 0.9860 - val_loss: 0.5461 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.91872\n",
            "Epoch 164/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.5800 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.91872\n",
            "Epoch 165/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.5105 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.91872\n",
            "Epoch 166/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0253 - accuracy: 0.9951 - val_loss: 0.4677 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.91872\n",
            "Epoch 167/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0361 - accuracy: 0.9866 - val_loss: 0.6598 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.91872\n",
            "Epoch 168/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.5100 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.91872\n",
            "Epoch 169/500\n",
            "411/411 [==============================] - 36s 86ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.4416 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.91872\n",
            "Epoch 170/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.4384 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.91872\n",
            "Epoch 171/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.4892 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.91872\n",
            "Epoch 172/500\n",
            "411/411 [==============================] - 36s 86ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.9478 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.91872\n",
            "Epoch 173/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0481 - accuracy: 0.9860 - val_loss: 0.6568 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.91872\n",
            "Epoch 174/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0166 - accuracy: 0.9957 - val_loss: 0.5490 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.91872\n",
            "Epoch 175/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0268 - accuracy: 0.9890 - val_loss: 0.9003 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.91872\n",
            "Epoch 176/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 1.0318 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.91872\n",
            "Epoch 177/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.5786 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.91872\n",
            "Epoch 178/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0179 - accuracy: 0.9927 - val_loss: 0.6401 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.91872\n",
            "Epoch 179/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.6346 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.91872\n",
            "Epoch 180/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.4864 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.91872\n",
            "Epoch 181/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.91872\n",
            "Epoch 182/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0173 - accuracy: 0.9970 - val_loss: 0.5093 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.91872\n",
            "Epoch 183/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0645 - accuracy: 0.9811 - val_loss: 0.5733 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.91872\n",
            "Epoch 184/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.4144 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.91872\n",
            "Epoch 185/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.6106 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.91872\n",
            "Epoch 186/500\n",
            "411/411 [==============================] - 36s 86ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 1.4559 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.91872\n",
            "Epoch 187/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.5030 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.91872\n",
            "Epoch 188/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.4299 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.91872\n",
            "Epoch 189/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0226 - accuracy: 0.9909 - val_loss: 0.5418 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.91872\n",
            "Epoch 190/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.5116 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.91872\n",
            "Epoch 191/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0405 - accuracy: 0.9884 - val_loss: 0.5445 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.91872\n",
            "Epoch 192/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0238 - accuracy: 0.9909 - val_loss: 0.4890 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.91872\n",
            "Epoch 193/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0199 - accuracy: 0.9915 - val_loss: 0.5318 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.91872\n",
            "Epoch 194/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0303 - accuracy: 0.9903 - val_loss: 0.8289 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.91872\n",
            "Epoch 195/500\n",
            "411/411 [==============================] - 36s 86ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.5437 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.91872\n",
            "Epoch 196/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.4972 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.91872\n",
            "Epoch 197/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.5091 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.91872\n",
            "Epoch 198/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0288 - accuracy: 0.9884 - val_loss: 0.4253 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.91872\n",
            "Epoch 199/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0327 - accuracy: 0.9903 - val_loss: 0.7025 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.91872\n",
            "Epoch 200/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.5004 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.91872\n",
            "Epoch 201/500\n",
            "411/411 [==============================] - 36s 86ms/step - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.5257 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.91872\n",
            "Epoch 202/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.3761 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.91872\n",
            "Epoch 203/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.4331 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.91872\n",
            "Epoch 204/500\n",
            "411/411 [==============================] - 36s 86ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.6274 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.91872\n",
            "Epoch 205/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0629 - accuracy: 0.9805 - val_loss: 0.5067 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.91872\n",
            "Epoch 206/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.5351 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.91872\n",
            "Epoch 207/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.6395 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.91872\n",
            "Epoch 208/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0540 - accuracy: 0.9817 - val_loss: 5.9822 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.91872\n",
            "Epoch 209/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0230 - accuracy: 0.9909 - val_loss: 0.6380 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.91872\n",
            "Epoch 210/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0309 - accuracy: 0.9927 - val_loss: 0.6870 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.91872\n",
            "Epoch 211/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.7429 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.91872\n",
            "Epoch 212/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0293 - accuracy: 0.9884 - val_loss: 0.5959 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.91872\n",
            "Epoch 213/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.5358 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.91872\n",
            "Epoch 214/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0207 - accuracy: 0.9921 - val_loss: 0.4737 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.91872\n",
            "Epoch 215/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.4047 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.91872\n",
            "Epoch 216/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.5248 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.91872\n",
            "Epoch 217/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5660 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.91872\n",
            "Epoch 218/500\n",
            "411/411 [==============================] - 36s 86ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.4891 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.91872\n",
            "Epoch 219/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0390 - accuracy: 0.9909 - val_loss: 9.9238 - val_accuracy: 0.4458\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.91872\n",
            "Epoch 220/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 0.4951 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.91872\n",
            "Epoch 221/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4025 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.91872\n",
            "Epoch 222/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0284 - accuracy: 0.9927 - val_loss: 0.4401 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.91872\n",
            "Epoch 223/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.5341 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.91872\n",
            "Epoch 224/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 15.0868 - val_accuracy: 0.2882\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.91872\n",
            "Epoch 225/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 2.4378 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.91872\n",
            "Epoch 226/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.5980 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.91872\n",
            "Epoch 227/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4973 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.91872\n",
            "Epoch 228/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.91872\n",
            "Epoch 229/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5661 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.91872\n",
            "Epoch 230/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0565 - accuracy: 0.9799 - val_loss: 0.4899 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.91872\n",
            "Epoch 231/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0280 - accuracy: 0.9890 - val_loss: 0.7595 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.91872\n",
            "Epoch 232/500\n",
            "411/411 [==============================] - 36s 86ms/step - loss: 0.0209 - accuracy: 0.9951 - val_loss: 0.5321 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.91872\n",
            "Epoch 233/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.5406 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.91872\n",
            "Epoch 234/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.4506 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.91872\n",
            "Epoch 235/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4684 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.91872\n",
            "Epoch 236/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.91872\n",
            "Epoch 237/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.91872\n",
            "Epoch 238/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0341 - accuracy: 0.9909 - val_loss: 0.8575 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.91872\n",
            "Epoch 239/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.5656 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.91872\n",
            "Epoch 240/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0325 - accuracy: 0.9909 - val_loss: 0.5468 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.91872\n",
            "Epoch 241/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5819 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.91872\n",
            "Epoch 242/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.4673 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.91872\n",
            "Epoch 243/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 0.6763 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.91872\n",
            "Epoch 244/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.5289 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.91872\n",
            "Epoch 245/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.5510 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.91872\n",
            "Epoch 246/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0207 - accuracy: 0.9921 - val_loss: 0.6586 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.91872\n",
            "Epoch 247/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0207 - accuracy: 0.9921 - val_loss: 0.7452 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.91872\n",
            "Epoch 248/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.5829 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.91872\n",
            "Epoch 249/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.7236 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.91872\n",
            "Epoch 250/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0301 - accuracy: 0.9890 - val_loss: 0.5620 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.91872\n",
            "Epoch 251/500\n",
            "411/411 [==============================] - 36s 86ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.5054 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.91872\n",
            "Epoch 252/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.91872\n",
            "Epoch 253/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5313 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.91872\n",
            "Epoch 254/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.5692 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.91872\n",
            "Epoch 255/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.5966 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.91872\n",
            "Epoch 256/500\n",
            "411/411 [==============================] - 35s 85ms/step - loss: 0.0276 - accuracy: 0.9921 - val_loss: 0.5672 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.91872\n",
            "Epoch 257/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0271 - accuracy: 0.9890 - val_loss: 0.4378 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.91872\n",
            "Epoch 258/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4774 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00258: val_accuracy improved from 0.91872 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 259/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.5455 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.92611\n",
            "Epoch 260/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.5327 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.92611\n",
            "Epoch 261/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.5134 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.92611\n",
            "Epoch 262/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0204 - accuracy: 0.9945 - val_loss: 0.7728 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.92611\n",
            "Epoch 263/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.5727 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.92611\n",
            "Epoch 264/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0103 - accuracy: 0.9988 - val_loss: 2.1333 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.92611\n",
            "Epoch 265/500\n",
            "411/411 [==============================] - 35s 86ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 159.9914 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.92611\n",
            "Epoch 266/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 1.2760 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.92611\n",
            "Epoch 267/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.3059 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00267: val_accuracy improved from 0.92611 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 268/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.4754 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93596\n",
            "Epoch 269/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.3810 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93596\n",
            "Epoch 270/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4183 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93596\n",
            "Epoch 271/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93596\n",
            "Epoch 272/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 7.5621e-04 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93596\n",
            "Epoch 273/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.4852 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93596\n",
            "Epoch 274/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0402 - accuracy: 0.9878 - val_loss: 0.6466 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93596\n",
            "Epoch 275/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.6068 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93596\n",
            "Epoch 276/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0155 - accuracy: 0.9970 - val_loss: 0.4854 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93596\n",
            "Epoch 277/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 8.2429 - val_accuracy: 0.4236\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93596\n",
            "Epoch 278/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.9898 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93596\n",
            "Epoch 279/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 0.5774 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93596\n",
            "Epoch 280/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.5529 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93596\n",
            "Epoch 281/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.7668 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93596\n",
            "Epoch 282/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.3546 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93596\n",
            "Epoch 283/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.5122 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93596\n",
            "Epoch 284/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0284 - accuracy: 0.9921 - val_loss: 0.5945 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93596\n",
            "Epoch 285/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0121 - accuracy: 0.9933 - val_loss: 0.5859 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93596\n",
            "Epoch 286/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.4424 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93596\n",
            "Epoch 287/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.4968 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93596\n",
            "Epoch 288/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0232 - accuracy: 0.9915 - val_loss: 0.5520 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93596\n",
            "Epoch 289/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0107 - accuracy: 0.9988 - val_loss: 0.4815 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93596\n",
            "Epoch 290/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.6224 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93596\n",
            "Epoch 291/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.6991 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93596\n",
            "Epoch 292/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.4494 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93596\n",
            "Epoch 293/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.5330 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93596\n",
            "Epoch 294/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.4693 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93596\n",
            "Epoch 295/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.7818 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93596\n",
            "Epoch 296/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.5514 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93596\n",
            "Epoch 297/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.4803 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93596\n",
            "Epoch 298/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.5057 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93596\n",
            "Epoch 299/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4695 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93596\n",
            "Epoch 300/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 1.4330 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93596\n",
            "Epoch 301/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0286 - accuracy: 0.9933 - val_loss: 0.4611 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93596\n",
            "Epoch 302/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.4801 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93596\n",
            "Epoch 303/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 0.5501 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93596\n",
            "Epoch 304/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93596\n",
            "Epoch 305/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 0.6793 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93596\n",
            "Epoch 306/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.5315 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93596\n",
            "Epoch 307/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.4695 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93596\n",
            "Epoch 308/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0204 - accuracy: 0.9915 - val_loss: 1.0164 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93596\n",
            "Epoch 309/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.4279 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93596\n",
            "Epoch 310/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93596\n",
            "Epoch 311/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.6889 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93596\n",
            "Epoch 312/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0123 - accuracy: 0.9945 - val_loss: 0.4427 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93596\n",
            "Epoch 313/500\n",
            "411/411 [==============================] - 36s 86ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.4622 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93596\n",
            "Epoch 314/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4599 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93596\n",
            "Epoch 315/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0055 - accuracy: 0.9970 - val_loss: 0.5562 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93596\n",
            "Epoch 316/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0439 - accuracy: 0.9872 - val_loss: 0.6766 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93596\n",
            "Epoch 317/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.4051 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93596\n",
            "Epoch 318/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4303 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93596\n",
            "Epoch 319/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 8.9950e-04 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93596\n",
            "Epoch 320/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.5139 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93596\n",
            "Epoch 321/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0322 - accuracy: 0.9878 - val_loss: 1.0364 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93596\n",
            "Epoch 322/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.4418 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93596\n",
            "Epoch 323/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.5144 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93596\n",
            "Epoch 324/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93596\n",
            "Epoch 325/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.4857 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93596\n",
            "Epoch 326/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.8247 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93596\n",
            "Epoch 327/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 1.0374 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93596\n",
            "Epoch 328/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0271 - accuracy: 0.9890 - val_loss: 0.5623 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93596\n",
            "Epoch 329/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.4746 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93596\n",
            "Epoch 330/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.4149 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93596\n",
            "Epoch 331/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4197 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93596\n",
            "Epoch 332/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.4688 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93596\n",
            "Epoch 333/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93596\n",
            "Epoch 334/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 1.3972 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93596\n",
            "Epoch 335/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0219 - accuracy: 0.9951 - val_loss: 0.4676 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93596\n",
            "Epoch 336/500\n",
            "411/411 [==============================] - 36s 87ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4591 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93596\n",
            "Epoch 337/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.4770 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93596\n",
            "Epoch 338/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.3932 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93596\n",
            "Epoch 339/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0311 - accuracy: 0.9884 - val_loss: 13.0536 - val_accuracy: 0.3645\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93596\n",
            "Epoch 340/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0341 - accuracy: 0.9896 - val_loss: 0.5667 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93596\n",
            "Epoch 341/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.5941 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93596\n",
            "Epoch 342/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.8799 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93596\n",
            "Epoch 343/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93596\n",
            "Epoch 344/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.5307 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93596\n",
            "Epoch 345/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.6576 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93596\n",
            "Epoch 346/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0327 - accuracy: 0.9921 - val_loss: 0.5546 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93596\n",
            "Epoch 347/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0204 - accuracy: 0.9951 - val_loss: 12.7159 - val_accuracy: 0.5320\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93596\n",
            "Epoch 348/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.5429 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93596\n",
            "Epoch 349/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4763 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93596\n",
            "Epoch 350/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93596\n",
            "Epoch 351/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 9.0749e-04 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93596\n",
            "Epoch 352/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 7.9973e-04 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93596\n",
            "Epoch 353/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0393 - accuracy: 0.9909 - val_loss: 0.4293 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93596\n",
            "Epoch 354/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.5076 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93596\n",
            "Epoch 355/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.5343 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93596\n",
            "Epoch 356/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4364 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93596\n",
            "Epoch 357/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0141 - accuracy: 0.9982 - val_loss: 1.7707 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93596\n",
            "Epoch 358/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.6382 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93596\n",
            "Epoch 359/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 1.0605 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93596\n",
            "Epoch 360/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 2.9489 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93596\n",
            "Epoch 361/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5527 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93596\n",
            "Epoch 362/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0315 - accuracy: 0.9915 - val_loss: 0.4821 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93596\n",
            "Epoch 363/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.5950 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93596\n",
            "Epoch 364/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 8.1221 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93596\n",
            "Epoch 365/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.5941 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93596\n",
            "Epoch 366/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5002 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93596\n",
            "Epoch 367/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0411 - accuracy: 0.9878 - val_loss: 0.5315 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93596\n",
            "Epoch 368/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.4179 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93596\n",
            "Epoch 369/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93596\n",
            "Epoch 370/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4570 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93596\n",
            "Epoch 371/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.9349 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93596\n",
            "Epoch 372/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.4769 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93596\n",
            "Epoch 373/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4280 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93596\n",
            "Epoch 374/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93596\n",
            "Epoch 375/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93596\n",
            "Epoch 376/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 5.0783e-04 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93596\n",
            "Epoch 377/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0057 - accuracy: 0.9970 - val_loss: 0.5235 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93596\n",
            "Epoch 378/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0252 - accuracy: 0.9896 - val_loss: 0.5915 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93596\n",
            "Epoch 379/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0184 - accuracy: 0.9963 - val_loss: 0.5589 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93596\n",
            "Epoch 380/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0098 - accuracy: 0.9957 - val_loss: 0.5218 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93596\n",
            "Epoch 381/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0222 - accuracy: 0.9957 - val_loss: 0.5345 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93596\n",
            "Epoch 382/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3983 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93596\n",
            "Epoch 383/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.4376 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93596\n",
            "Epoch 384/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.7043 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93596\n",
            "Epoch 385/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.5453 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93596\n",
            "Epoch 386/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.6577 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93596\n",
            "Epoch 387/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.4768 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93596\n",
            "Epoch 388/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.5052 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93596\n",
            "Epoch 389/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.5428 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93596\n",
            "Epoch 390/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0212 - accuracy: 0.9957 - val_loss: 0.4841 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93596\n",
            "Epoch 391/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.5183 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93596\n",
            "Epoch 392/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.5185 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93596\n",
            "Epoch 393/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.5977 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93596\n",
            "Epoch 394/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.5068 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93596\n",
            "Epoch 395/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4319 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93596\n",
            "Epoch 396/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.5666 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93596\n",
            "Epoch 397/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.8095 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93596\n",
            "Epoch 398/500\n",
            "411/411 [==============================] - 36s 89ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.5553 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93596\n",
            "Epoch 399/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.5246 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93596\n",
            "Epoch 400/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 8.1162e-04 - accuracy: 1.0000 - val_loss: 0.5274 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93596\n",
            "Epoch 401/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 2.8974e-04 - accuracy: 1.0000 - val_loss: 0.5675 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93596\n",
            "Epoch 402/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 2.9602e-04 - accuracy: 1.0000 - val_loss: 0.5729 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93596\n",
            "Epoch 403/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 1.4637 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93596\n",
            "Epoch 404/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0405 - accuracy: 0.9896 - val_loss: 0.6536 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93596\n",
            "Epoch 405/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.5095 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93596\n",
            "Epoch 406/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5831 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93596\n",
            "Epoch 407/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.6235 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93596\n",
            "Epoch 408/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.5002 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93596\n",
            "Epoch 409/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.5357 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93596\n",
            "Epoch 410/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.6577 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.93596\n",
            "Epoch 411/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.93596\n",
            "Epoch 412/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 6.2466e-04 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.93596\n",
            "Epoch 413/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.6283 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.93596\n",
            "Epoch 414/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0248 - accuracy: 0.9963 - val_loss: 0.5026 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.93596\n",
            "Epoch 415/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.6314 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.93596\n",
            "Epoch 416/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0350 - accuracy: 0.9921 - val_loss: 0.5457 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93596\n",
            "Epoch 417/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.6760 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93596\n",
            "Epoch 418/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.5380 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93596\n",
            "Epoch 419/500\n",
            "411/411 [==============================] - 36s 88ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.5431 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93596\n",
            "Epoch 420/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.93596\n",
            "Epoch 421/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.9451 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.93596\n",
            "Epoch 422/500\n",
            "411/411 [==============================] - 37s 89ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 1.1867 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93596\n",
            "Epoch 423/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.5538 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93596\n",
            "Epoch 424/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5948 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93596\n",
            "Epoch 425/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.4731 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93596\n",
            "Epoch 426/500\n",
            "411/411 [==============================] - 37s 90ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.6527 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93596\n",
            "Epoch 427/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.6272 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93596\n",
            "Epoch 428/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.5610 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93596\n",
            "Epoch 429/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.6479 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.93596\n",
            "Epoch 430/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 8.0328e-04 - accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.93596\n",
            "Epoch 431/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 7.5159e-04 - accuracy: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.93596\n",
            "Epoch 432/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5199 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.93596\n",
            "Epoch 433/500\n",
            "411/411 [==============================] - 37s 91ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 1.2127 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.93596\n",
            "Epoch 434/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0576 - accuracy: 0.9854 - val_loss: 0.5030 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.93596\n",
            "Epoch 435/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.4744 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.93596\n",
            "Epoch 436/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.93596\n",
            "Epoch 437/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4943 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.93596\n",
            "Epoch 438/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 4.6642e-04 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.93596\n",
            "Epoch 439/500\n",
            "411/411 [==============================] - 38s 94ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.4383 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.93596\n",
            "Epoch 440/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.93596\n",
            "Epoch 441/500\n",
            "411/411 [==============================] - 38s 91ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4368 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.93596\n",
            "Epoch 442/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.5919 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.93596\n",
            "Epoch 443/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.5060 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.93596\n",
            "Epoch 444/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.6210 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.93596\n",
            "Epoch 445/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.9993 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.93596\n",
            "Epoch 446/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.8241 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.93596\n",
            "Epoch 447/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 7.3970e-04 - accuracy: 1.0000 - val_loss: 0.5389 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.93596\n",
            "Epoch 448/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.6683 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.93596\n",
            "Epoch 449/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.6114 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.93596\n",
            "Epoch 450/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0059 - accuracy: 0.9970 - val_loss: 0.6670 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.93596\n",
            "Epoch 451/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 3.5037 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.93596\n",
            "Epoch 452/500\n",
            "411/411 [==============================] - 39s 95ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.7896 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.93596\n",
            "Epoch 453/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 9.6577e-04 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.93596\n",
            "Epoch 454/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5578 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.93596\n",
            "Epoch 455/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4403 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.93596\n",
            "Epoch 456/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0324 - accuracy: 0.9933 - val_loss: 1.3377 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.93596\n",
            "Epoch 457/500\n",
            "411/411 [==============================] - 39s 95ms/step - loss: 0.0343 - accuracy: 0.9915 - val_loss: 5.0570 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.93596\n",
            "Epoch 458/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 112.3420 - val_accuracy: 0.1453\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.93596\n",
            "Epoch 459/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.6023 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.93596\n",
            "Epoch 460/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.6781 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.93596\n",
            "Epoch 461/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 7.8971e-04 - accuracy: 1.0000 - val_loss: 0.5677 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.93596\n",
            "Epoch 462/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 5.2899e-04 - accuracy: 1.0000 - val_loss: 0.5366 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.93596\n",
            "Epoch 463/500\n",
            "411/411 [==============================] - 38s 94ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.6744 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.93596\n",
            "Epoch 464/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.6091 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.93596\n",
            "Epoch 465/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 1.5291 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.93596\n",
            "Epoch 466/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.93596\n",
            "Epoch 467/500\n",
            "411/411 [==============================] - 39s 95ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 7.5631 - val_accuracy: 0.5739\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.93596\n",
            "Epoch 468/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.8503 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.93596\n",
            "Epoch 469/500\n",
            "411/411 [==============================] - 39s 95ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 9.7167 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.93596\n",
            "Epoch 470/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 10.3370 - val_accuracy: 0.5591\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.93596\n",
            "Epoch 471/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.5568 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.93596\n",
            "Epoch 472/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.93596\n",
            "Epoch 473/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5331 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.93596\n",
            "Epoch 474/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0023 - accuracy: 0.9982 - val_loss: 0.7405 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.93596\n",
            "Epoch 475/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.93596\n",
            "Epoch 476/500\n",
            "411/411 [==============================] - 39s 95ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5560 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.93596\n",
            "Epoch 477/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0207 - accuracy: 0.9951 - val_loss: 0.8062 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.93596\n",
            "Epoch 478/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0235 - accuracy: 0.9939 - val_loss: 0.5149 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.93596\n",
            "Epoch 479/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 0.6095 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.93596\n",
            "Epoch 480/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.5070 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.93596\n",
            "Epoch 481/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5234 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.93596\n",
            "Epoch 482/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.6010 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.93596\n",
            "Epoch 483/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.5966 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.93596\n",
            "Epoch 484/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.6206 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.93596\n",
            "Epoch 485/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.4075 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.93596\n",
            "Epoch 486/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.6857 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.93596\n",
            "Epoch 487/500\n",
            "411/411 [==============================] - 38s 92ms/step - loss: 0.0160 - accuracy: 0.9976 - val_loss: 0.7289 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.93596\n",
            "Epoch 488/500\n",
            "411/411 [==============================] - 39s 96ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.5812 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.93596\n",
            "Epoch 489/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.6325 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.93596\n",
            "Epoch 490/500\n",
            "411/411 [==============================] - 38s 94ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.93596\n",
            "Epoch 491/500\n",
            "411/411 [==============================] - 39s 95ms/step - loss: 3.5623e-04 - accuracy: 1.0000 - val_loss: 0.5267 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.93596\n",
            "Epoch 492/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 1.0548 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.93596\n",
            "Epoch 493/500\n",
            "411/411 [==============================] - 39s 95ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 3.6831 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.93596\n",
            "Epoch 494/500\n",
            "411/411 [==============================] - 39s 95ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 1.3037 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.93596\n",
            "Epoch 495/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.5493 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.93596\n",
            "Epoch 496/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4515 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.93596\n",
            "Epoch 497/500\n",
            "411/411 [==============================] - 38s 93ms/step - loss: 7.3153e-04 - accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00497: val_accuracy improved from 0.93596 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5\n",
            "Epoch 498/500\n",
            "411/411 [==============================] - 39s 95ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5174 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.93842\n",
            "Epoch 499/500\n",
            "411/411 [==============================] - 38s 94ms/step - loss: 0.0270 - accuracy: 0.9909 - val_loss: 928.5251 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.93842\n",
            "Epoch 500/500\n",
            "411/411 [==============================] - 39s 94ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.5454 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.93842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f202038bf10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3a639ae1-6107-429d-be50-f088d1508de5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_04_1_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864c5ba5-a7d9-41f9-d7cb-14f483e800ea"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc404628-5641-4826-db31-cf0ef8622d1a"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d51923e9-dbcc-4f4d-9faf-feb3ebe92cef"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "31b0cc0b-48b4-47c5-b69c-79d3489107f0"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/BatchSize_04_1_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/BatchSize_04_1_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bea3f384-296f-4f5a-8068-1b3c007bc1b4\", \"BatchSize_04_1_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}