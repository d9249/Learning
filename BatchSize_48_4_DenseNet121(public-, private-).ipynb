{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BatchSize_48_4_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+sFJYgO8tU2KpctxqqOhg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/BatchSize_48_4_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca8772a-928a-43a9-f6b2-17f2e62eaed5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep  6 17:47:58 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a206bc8c-56d6-4f57-fdf3-e4b2965e2a7f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37272cad-6cc1-43ed-9ff0-abb0dc27f809"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1adc9acd-5db5-437e-b360-889e45962598"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "batch_size = 48\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size,  color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be19706d-6ca5-4e5e-8e6c-4d038fbc4e73"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "35/35 [==============================] - 54s 690ms/step - loss: 1.9216 - accuracy: 0.3155 - val_loss: 4.7607 - val_accuracy: 0.1158\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11576, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 2/500\n",
            "35/35 [==============================] - 19s 539ms/step - loss: 1.2220 - accuracy: 0.5926 - val_loss: 60.7185 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.11576\n",
            "Epoch 3/500\n",
            "35/35 [==============================] - 19s 546ms/step - loss: 0.9838 - accuracy: 0.6596 - val_loss: 5.5822 - val_accuracy: 0.1355\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.11576 to 0.13547, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 4/500\n",
            "35/35 [==============================] - 20s 555ms/step - loss: 0.7976 - accuracy: 0.7320 - val_loss: 58.7449 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.13547\n",
            "Epoch 5/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.7558 - accuracy: 0.7576 - val_loss: 10.3753 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.13547\n",
            "Epoch 6/500\n",
            "35/35 [==============================] - 20s 570ms/step - loss: 0.6897 - accuracy: 0.7704 - val_loss: 19.6325 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.13547\n",
            "Epoch 7/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.5697 - accuracy: 0.8088 - val_loss: 12.7882 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.13547\n",
            "Epoch 8/500\n",
            "35/35 [==============================] - 20s 561ms/step - loss: 0.5038 - accuracy: 0.8210 - val_loss: 7.5872 - val_accuracy: 0.1305\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.13547\n",
            "Epoch 9/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.6244 - accuracy: 0.7917 - val_loss: 11.1950 - val_accuracy: 0.2143\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.13547 to 0.21429, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 10/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.4865 - accuracy: 0.8356 - val_loss: 6.4317 - val_accuracy: 0.2365\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.21429 to 0.23645, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 11/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.4073 - accuracy: 0.8611 - val_loss: 5.4050 - val_accuracy: 0.2192\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.23645\n",
            "Epoch 12/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.6200 - accuracy: 0.7868 - val_loss: 3.2225 - val_accuracy: 0.3892\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.23645 to 0.38916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 13/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.3771 - accuracy: 0.8812 - val_loss: 3.9668 - val_accuracy: 0.4089\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.38916 to 0.40887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 14/500\n",
            "35/35 [==============================] - 20s 574ms/step - loss: 0.3438 - accuracy: 0.8770 - val_loss: 1.4107 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.40887 to 0.65271, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 15/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.4473 - accuracy: 0.8484 - val_loss: 4.9017 - val_accuracy: 0.3670\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.65271\n",
            "Epoch 16/500\n",
            "35/35 [==============================] - 20s 562ms/step - loss: 0.3164 - accuracy: 0.8946 - val_loss: 1.1474 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.65271 to 0.72167, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 17/500\n",
            "35/35 [==============================] - 20s 561ms/step - loss: 0.2933 - accuracy: 0.9007 - val_loss: 0.7617 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.72167 to 0.79803, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 18/500\n",
            "35/35 [==============================] - 20s 572ms/step - loss: 0.2916 - accuracy: 0.8983 - val_loss: 0.9109 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.79803\n",
            "Epoch 19/500\n",
            "35/35 [==============================] - 20s 571ms/step - loss: 0.3004 - accuracy: 0.8995 - val_loss: 0.8139 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.79803\n",
            "Epoch 20/500\n",
            "35/35 [==============================] - 20s 574ms/step - loss: 0.2277 - accuracy: 0.9306 - val_loss: 0.8053 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.79803\n",
            "Epoch 21/500\n",
            "35/35 [==============================] - 20s 561ms/step - loss: 0.2719 - accuracy: 0.9056 - val_loss: 0.4843 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.79803 to 0.84975, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 22/500\n",
            "35/35 [==============================] - 20s 562ms/step - loss: 0.2016 - accuracy: 0.9306 - val_loss: 0.5662 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.84975\n",
            "Epoch 23/500\n",
            "35/35 [==============================] - 20s 574ms/step - loss: 0.2465 - accuracy: 0.9214 - val_loss: 1.1337 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.84975\n",
            "Epoch 24/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.3372 - accuracy: 0.8873 - val_loss: 1.3037 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.84975\n",
            "Epoch 25/500\n",
            "35/35 [==============================] - 20s 562ms/step - loss: 0.2429 - accuracy: 0.9147 - val_loss: 0.5582 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.84975\n",
            "Epoch 26/500\n",
            "35/35 [==============================] - 20s 562ms/step - loss: 0.1668 - accuracy: 0.9446 - val_loss: 0.3923 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.84975 to 0.88177, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 27/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1383 - accuracy: 0.9568 - val_loss: 0.5936 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.88177\n",
            "Epoch 28/500\n",
            "35/35 [==============================] - 20s 575ms/step - loss: 0.1828 - accuracy: 0.9361 - val_loss: 1.9487 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.88177\n",
            "Epoch 29/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.1848 - accuracy: 0.9354 - val_loss: 0.9264 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.88177\n",
            "Epoch 30/500\n",
            "35/35 [==============================] - 20s 561ms/step - loss: 0.2108 - accuracy: 0.9269 - val_loss: 0.9296 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.88177\n",
            "Epoch 31/500\n",
            "35/35 [==============================] - 20s 562ms/step - loss: 0.1742 - accuracy: 0.9330 - val_loss: 1.0132 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.88177\n",
            "Epoch 32/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.1614 - accuracy: 0.9507 - val_loss: 0.6024 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.88177\n",
            "Epoch 33/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.1497 - accuracy: 0.9470 - val_loss: 0.6634 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.88177\n",
            "Epoch 34/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0942 - accuracy: 0.9714 - val_loss: 0.4724 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.88177\n",
            "Epoch 35/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.1108 - accuracy: 0.9616 - val_loss: 0.6484 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.88177\n",
            "Epoch 36/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1110 - accuracy: 0.9629 - val_loss: 0.3547 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.88177\n",
            "Epoch 37/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0655 - accuracy: 0.9811 - val_loss: 0.4030 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.88177 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 38/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.1129 - accuracy: 0.9616 - val_loss: 0.7274 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.88670\n",
            "Epoch 39/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1570 - accuracy: 0.9452 - val_loss: 0.6000 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.88670\n",
            "Epoch 40/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1596 - accuracy: 0.9470 - val_loss: 0.6461 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.88670\n",
            "Epoch 41/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1175 - accuracy: 0.9629 - val_loss: 0.6010 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.88670\n",
            "Epoch 42/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1040 - accuracy: 0.9616 - val_loss: 0.6165 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.88670\n",
            "Epoch 43/500\n",
            "35/35 [==============================] - 20s 562ms/step - loss: 0.1011 - accuracy: 0.9635 - val_loss: 0.7115 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.88670\n",
            "Epoch 44/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.1084 - accuracy: 0.9622 - val_loss: 0.4811 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.88670\n",
            "Epoch 45/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.1074 - accuracy: 0.9671 - val_loss: 1.4182 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.88670\n",
            "Epoch 46/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.2617 - accuracy: 0.9220 - val_loss: 1.7071 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.88670\n",
            "Epoch 47/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.2131 - accuracy: 0.9275 - val_loss: 2.3881 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.88670\n",
            "Epoch 48/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1238 - accuracy: 0.9549 - val_loss: 0.6137 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.88670\n",
            "Epoch 49/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.1159 - accuracy: 0.9604 - val_loss: 1.7935 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.88670\n",
            "Epoch 50/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1535 - accuracy: 0.9507 - val_loss: 1.0179 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.88670\n",
            "Epoch 51/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0916 - accuracy: 0.9702 - val_loss: 0.4324 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.88670 to 0.88916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 52/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0519 - accuracy: 0.9854 - val_loss: 0.4079 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.88916\n",
            "Epoch 53/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0453 - accuracy: 0.9872 - val_loss: 0.3308 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.88916 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 54/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.0746 - accuracy: 0.9726 - val_loss: 0.4374 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.89655\n",
            "Epoch 55/500\n",
            "35/35 [==============================] - 20s 573ms/step - loss: 0.0727 - accuracy: 0.9744 - val_loss: 0.4594 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.89655\n",
            "Epoch 56/500\n",
            "35/35 [==============================] - 20s 569ms/step - loss: 0.0613 - accuracy: 0.9787 - val_loss: 0.4894 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.89655\n",
            "Epoch 57/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.0623 - accuracy: 0.9799 - val_loss: 0.4104 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.89655\n",
            "Epoch 58/500\n",
            "35/35 [==============================] - 20s 562ms/step - loss: 0.1089 - accuracy: 0.9616 - val_loss: 0.8050 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.89655\n",
            "Epoch 59/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0917 - accuracy: 0.9702 - val_loss: 0.5727 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.89655\n",
            "Epoch 60/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0648 - accuracy: 0.9775 - val_loss: 1.0132 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.89655\n",
            "Epoch 61/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1481 - accuracy: 0.9531 - val_loss: 0.9548 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.89655\n",
            "Epoch 62/500\n",
            "35/35 [==============================] - 20s 575ms/step - loss: 0.1332 - accuracy: 0.9501 - val_loss: 0.6566 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.89655\n",
            "Epoch 63/500\n",
            "35/35 [==============================] - 20s 561ms/step - loss: 0.0616 - accuracy: 0.9799 - val_loss: 0.4364 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.89655\n",
            "Epoch 64/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.0773 - accuracy: 0.9689 - val_loss: 0.4982 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.89655\n",
            "Epoch 65/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0589 - accuracy: 0.9775 - val_loss: 0.3946 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.89655\n",
            "Epoch 66/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0515 - accuracy: 0.9866 - val_loss: 0.4989 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.89655\n",
            "Epoch 67/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0941 - accuracy: 0.9695 - val_loss: 0.7143 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.89655\n",
            "Epoch 68/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0668 - accuracy: 0.9750 - val_loss: 0.4379 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.89655\n",
            "Epoch 69/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0626 - accuracy: 0.9793 - val_loss: 0.4018 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.89655\n",
            "Epoch 70/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0714 - accuracy: 0.9726 - val_loss: 0.8346 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.89655\n",
            "Epoch 71/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0498 - accuracy: 0.9848 - val_loss: 0.6284 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.89655\n",
            "Epoch 72/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0874 - accuracy: 0.9665 - val_loss: 0.9099 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.89655\n",
            "Epoch 73/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.1852 - accuracy: 0.9348 - val_loss: 1.0750 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.89655\n",
            "Epoch 74/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1933 - accuracy: 0.9446 - val_loss: 1.4185 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.89655\n",
            "Epoch 75/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0768 - accuracy: 0.9744 - val_loss: 0.4471 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.89655\n",
            "Epoch 76/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0494 - accuracy: 0.9848 - val_loss: 0.8837 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.89655\n",
            "Epoch 77/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0617 - accuracy: 0.9854 - val_loss: 0.3954 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.89655\n",
            "Epoch 78/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0248 - accuracy: 0.9951 - val_loss: 0.3398 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.89655 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 79/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0132 - accuracy: 0.9982 - val_loss: 0.4441 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.92118\n",
            "Epoch 80/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.3680 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.92118\n",
            "Epoch 81/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0249 - accuracy: 0.9896 - val_loss: 0.4298 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.92118\n",
            "Epoch 82/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0147 - accuracy: 0.9976 - val_loss: 0.5102 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.92118\n",
            "Epoch 83/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.0818 - accuracy: 0.9738 - val_loss: 0.8922 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.92118\n",
            "Epoch 84/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0990 - accuracy: 0.9671 - val_loss: 0.9395 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.92118\n",
            "Epoch 85/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0713 - accuracy: 0.9714 - val_loss: 0.8115 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.92118\n",
            "Epoch 86/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0315 - accuracy: 0.9909 - val_loss: 0.4773 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.92118\n",
            "Epoch 87/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.3908 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.92118\n",
            "Epoch 88/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0473 - accuracy: 0.9860 - val_loss: 0.7488 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.92118\n",
            "Epoch 89/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1828 - accuracy: 0.9452 - val_loss: 1.3863 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.92118\n",
            "Epoch 90/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.1287 - accuracy: 0.9562 - val_loss: 0.5965 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.92118\n",
            "Epoch 91/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0458 - accuracy: 0.9823 - val_loss: 0.6290 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.92118\n",
            "Epoch 92/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 0.3937 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.92118\n",
            "Epoch 93/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0311 - accuracy: 0.9878 - val_loss: 0.4527 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.92118\n",
            "Epoch 94/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0430 - accuracy: 0.9890 - val_loss: 0.4297 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.92118\n",
            "Epoch 95/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.4592 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.92118\n",
            "Epoch 96/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.3513 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.92118\n",
            "Epoch 97/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 0.3619 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.92118\n",
            "Epoch 98/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.3333 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.92118\n",
            "Epoch 99/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 0.4387 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.92118\n",
            "Epoch 100/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0099 - accuracy: 0.9988 - val_loss: 0.3146 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00100: val_accuracy improved from 0.92118 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 101/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.92365\n",
            "Epoch 102/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.8788 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.92365\n",
            "Epoch 103/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0680 - accuracy: 0.9732 - val_loss: 1.0115 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.92365\n",
            "Epoch 104/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0453 - accuracy: 0.9866 - val_loss: 0.4052 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.92365\n",
            "Epoch 105/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0845 - accuracy: 0.9720 - val_loss: 0.7416 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.92365\n",
            "Epoch 106/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0806 - accuracy: 0.9744 - val_loss: 0.9886 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.92365\n",
            "Epoch 107/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0497 - accuracy: 0.9817 - val_loss: 0.9485 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.92365\n",
            "Epoch 108/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0469 - accuracy: 0.9829 - val_loss: 0.9191 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.92365\n",
            "Epoch 109/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0494 - accuracy: 0.9860 - val_loss: 0.4286 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.92365\n",
            "Epoch 110/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.3698 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.92365\n",
            "Epoch 111/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.5006 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.92365\n",
            "Epoch 112/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0150 - accuracy: 0.9939 - val_loss: 0.3466 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.92365\n",
            "Epoch 113/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.3704 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.92365\n",
            "Epoch 114/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.3435 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.92365\n",
            "Epoch 115/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0326 - accuracy: 0.9909 - val_loss: 0.7832 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.92365\n",
            "Epoch 116/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0930 - accuracy: 0.9769 - val_loss: 1.1755 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.92365\n",
            "Epoch 117/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0826 - accuracy: 0.9750 - val_loss: 0.8710 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.92365\n",
            "Epoch 118/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0484 - accuracy: 0.9829 - val_loss: 0.7566 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.92365\n",
            "Epoch 119/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0296 - accuracy: 0.9890 - val_loss: 0.7258 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.92365\n",
            "Epoch 120/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0207 - accuracy: 0.9915 - val_loss: 0.4583 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.92365\n",
            "Epoch 121/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.4048 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.92365\n",
            "Epoch 122/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.4529 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.92365\n",
            "Epoch 123/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.3843 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.92365\n",
            "Epoch 124/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0633 - accuracy: 0.9811 - val_loss: 0.8298 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.92365\n",
            "Epoch 125/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0389 - accuracy: 0.9909 - val_loss: 0.5518 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.92365\n",
            "Epoch 126/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.6195 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.92365\n",
            "Epoch 127/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.4065 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.92365\n",
            "Epoch 128/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.3561 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.92365\n",
            "Epoch 129/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0330 - accuracy: 0.9915 - val_loss: 0.8613 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.92365\n",
            "Epoch 130/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0321 - accuracy: 0.9884 - val_loss: 0.4660 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.92365\n",
            "Epoch 131/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.5093 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.92365\n",
            "Epoch 132/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.4025 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.92365\n",
            "Epoch 133/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.92365\n",
            "Epoch 134/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.92365\n",
            "Epoch 135/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 1.1425 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.92365\n",
            "Epoch 136/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0496 - accuracy: 0.9878 - val_loss: 0.8672 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.92365\n",
            "Epoch 137/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0458 - accuracy: 0.9866 - val_loss: 1.2479 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.92365\n",
            "Epoch 138/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.1701 - accuracy: 0.9464 - val_loss: 2.6245 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.92365\n",
            "Epoch 139/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.1703 - accuracy: 0.9470 - val_loss: 0.8580 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.92365\n",
            "Epoch 140/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1352 - accuracy: 0.9586 - val_loss: 0.7425 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.92365\n",
            "Epoch 141/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1099 - accuracy: 0.9629 - val_loss: 0.6172 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.92365\n",
            "Epoch 142/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0402 - accuracy: 0.9872 - val_loss: 0.4940 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.92365\n",
            "Epoch 143/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.4081 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.92365\n",
            "Epoch 144/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.4321 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.92365\n",
            "Epoch 145/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.3469 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.92365\n",
            "Epoch 146/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.3422 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.92365\n",
            "Epoch 147/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.4051 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.92365\n",
            "Epoch 148/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.3595 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.92365\n",
            "Epoch 149/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.3856 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.92365\n",
            "Epoch 150/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.3964 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.92365\n",
            "Epoch 151/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.92365\n",
            "Epoch 152/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.92365\n",
            "Epoch 153/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.4278 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.92365\n",
            "Epoch 154/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4261 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92365\n",
            "Epoch 155/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4563 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92365\n",
            "Epoch 156/500\n",
            "35/35 [==============================] - 20s 577ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.6498 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92365\n",
            "Epoch 157/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.6481 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92365\n",
            "Epoch 158/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0601 - accuracy: 0.9805 - val_loss: 0.8326 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92365\n",
            "Epoch 159/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.0341 - accuracy: 0.9872 - val_loss: 0.6603 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92365\n",
            "Epoch 160/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.7483 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92365\n",
            "Epoch 161/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0732 - accuracy: 0.9775 - val_loss: 2.7400 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92365\n",
            "Epoch 162/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0788 - accuracy: 0.9726 - val_loss: 0.9631 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92365\n",
            "Epoch 163/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0569 - accuracy: 0.9799 - val_loss: 2.7671 - val_accuracy: 0.5985\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92365\n",
            "Epoch 164/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1943 - accuracy: 0.9434 - val_loss: 1.8356 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92365\n",
            "Epoch 165/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.1093 - accuracy: 0.9641 - val_loss: 1.6469 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92365\n",
            "Epoch 166/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0622 - accuracy: 0.9848 - val_loss: 0.7757 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92365\n",
            "Epoch 167/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0302 - accuracy: 0.9915 - val_loss: 0.5268 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92365\n",
            "Epoch 168/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.3419 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92365\n",
            "Epoch 169/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.3963 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92365\n",
            "Epoch 170/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.3304 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92365\n",
            "Epoch 171/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.3583 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92365\n",
            "Epoch 172/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.3601 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92365\n",
            "Epoch 173/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3602 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92365\n",
            "Epoch 174/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00174: val_accuracy improved from 0.92365 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 175/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92611\n",
            "Epoch 176/500\n",
            "35/35 [==============================] - 20s 562ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3822 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92611\n",
            "Epoch 177/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92611\n",
            "Epoch 178/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00178: val_accuracy improved from 0.92611 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5\n",
            "Epoch 179/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.3858 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93842\n",
            "Epoch 180/500\n",
            "35/35 [==============================] - 20s 575ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4898 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93842\n",
            "Epoch 181/500\n",
            "35/35 [==============================] - 20s 570ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.5610 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93842\n",
            "Epoch 182/500\n",
            "35/35 [==============================] - 20s 562ms/step - loss: 0.0323 - accuracy: 0.9915 - val_loss: 0.7105 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93842\n",
            "Epoch 183/500\n",
            "35/35 [==============================] - 20s 562ms/step - loss: 0.0242 - accuracy: 0.9945 - val_loss: 0.5259 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93842\n",
            "Epoch 184/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.4556 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93842\n",
            "Epoch 185/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.4761 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93842\n",
            "Epoch 186/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.3732 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93842\n",
            "Epoch 187/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.3833 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93842\n",
            "Epoch 188/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0171 - accuracy: 0.9957 - val_loss: 0.6675 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93842\n",
            "Epoch 189/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0182 - accuracy: 0.9927 - val_loss: 0.6379 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93842\n",
            "Epoch 190/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.5292 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93842\n",
            "Epoch 191/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.3455 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93842\n",
            "Epoch 192/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0485 - accuracy: 0.9854 - val_loss: 0.7744 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93842\n",
            "Epoch 193/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0965 - accuracy: 0.9708 - val_loss: 2.0647 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93842\n",
            "Epoch 194/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.1285 - accuracy: 0.9635 - val_loss: 1.1983 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93842\n",
            "Epoch 195/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0781 - accuracy: 0.9726 - val_loss: 3.3875 - val_accuracy: 0.6084\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93842\n",
            "Epoch 196/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0708 - accuracy: 0.9781 - val_loss: 0.4947 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93842\n",
            "Epoch 197/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0253 - accuracy: 0.9896 - val_loss: 1.2353 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93842\n",
            "Epoch 198/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.6422 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93842\n",
            "Epoch 199/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.4829 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93842\n",
            "Epoch 200/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.5274 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93842\n",
            "Epoch 201/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.5097 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93842\n",
            "Epoch 202/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0256 - accuracy: 0.9896 - val_loss: 0.4959 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93842\n",
            "Epoch 203/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.4413 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93842\n",
            "Epoch 204/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.5517 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93842\n",
            "Epoch 205/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.5754 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93842\n",
            "Epoch 206/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.4075 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93842\n",
            "Epoch 207/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.4477 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93842\n",
            "Epoch 208/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.4034 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93842\n",
            "Epoch 209/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.3640 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93842\n",
            "Epoch 210/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.6325 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93842\n",
            "Epoch 211/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0124 - accuracy: 0.9945 - val_loss: 0.4404 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93842\n",
            "Epoch 212/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.5397 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93842\n",
            "Epoch 213/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.3670 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93842\n",
            "Epoch 214/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4014 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93842\n",
            "Epoch 215/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93842\n",
            "Epoch 216/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 5.3012e-04 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93842\n",
            "Epoch 217/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 7.9284e-04 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93842\n",
            "Epoch 218/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0046 - accuracy: 0.9976 - val_loss: 0.3895 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93842\n",
            "Epoch 219/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0170 - accuracy: 0.9933 - val_loss: 0.5548 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93842\n",
            "Epoch 220/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.7769 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93842\n",
            "Epoch 221/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.5835 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93842\n",
            "Epoch 222/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0811 - accuracy: 0.9756 - val_loss: 1.0252 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93842\n",
            "Epoch 223/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0385 - accuracy: 0.9866 - val_loss: 1.1796 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93842\n",
            "Epoch 224/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0359 - accuracy: 0.9903 - val_loss: 1.1373 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93842\n",
            "Epoch 225/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.9498 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93842\n",
            "Epoch 226/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0638 - accuracy: 0.9823 - val_loss: 1.2809 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93842\n",
            "Epoch 227/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0403 - accuracy: 0.9866 - val_loss: 0.5559 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93842\n",
            "Epoch 228/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0227 - accuracy: 0.9896 - val_loss: 0.5372 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93842\n",
            "Epoch 229/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.4607 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93842\n",
            "Epoch 230/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.5609 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93842\n",
            "Epoch 231/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.4428 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93842\n",
            "Epoch 232/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.9642 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93842\n",
            "Epoch 233/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0371 - accuracy: 0.9890 - val_loss: 0.6911 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93842\n",
            "Epoch 234/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.6550 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93842\n",
            "Epoch 235/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.5876 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93842\n",
            "Epoch 236/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.3915 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93842\n",
            "Epoch 237/500\n",
            "35/35 [==============================] - 20s 576ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.4110 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93842\n",
            "Epoch 238/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.3899 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93842\n",
            "Epoch 239/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.5147 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93842\n",
            "Epoch 240/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.3835 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93842\n",
            "Epoch 241/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93842\n",
            "Epoch 242/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93842\n",
            "Epoch 243/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 5.8896e-04 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93842\n",
            "Epoch 244/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 6.8470e-04 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93842\n",
            "Epoch 245/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4133 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93842\n",
            "Epoch 246/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.3654 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93842\n",
            "Epoch 247/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 7.0237e-04 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93842\n",
            "Epoch 248/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 7.7043e-04 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93842\n",
            "Epoch 249/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4209 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93842\n",
            "Epoch 250/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4313 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93842\n",
            "Epoch 251/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.5756 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93842\n",
            "Epoch 252/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0375 - accuracy: 0.9896 - val_loss: 0.7313 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93842\n",
            "Epoch 253/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0848 - accuracy: 0.9738 - val_loss: 1.4318 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93842\n",
            "Epoch 254/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0621 - accuracy: 0.9793 - val_loss: 0.9693 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93842\n",
            "Epoch 255/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.6495 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93842\n",
            "Epoch 256/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0325 - accuracy: 0.9890 - val_loss: 1.0279 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93842\n",
            "Epoch 257/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0282 - accuracy: 0.9890 - val_loss: 0.6309 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93842\n",
            "Epoch 258/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0745 - accuracy: 0.9799 - val_loss: 0.7157 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93842\n",
            "Epoch 259/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.7484 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93842\n",
            "Epoch 260/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.9637 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93842\n",
            "Epoch 261/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.0212 - accuracy: 0.9915 - val_loss: 0.6054 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93842\n",
            "Epoch 262/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0281 - accuracy: 0.9933 - val_loss: 0.5736 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93842\n",
            "Epoch 263/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.7089 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93842\n",
            "Epoch 264/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.4778 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93842\n",
            "Epoch 265/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.5370 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93842\n",
            "Epoch 266/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.5685 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93842\n",
            "Epoch 267/500\n",
            "35/35 [==============================] - 20s 578ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.5395 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93842\n",
            "Epoch 268/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.5514 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93842\n",
            "Epoch 269/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.4947 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93842\n",
            "Epoch 270/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5019 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93842\n",
            "Epoch 271/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4451 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93842\n",
            "Epoch 272/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5140 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93842\n",
            "Epoch 273/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93842\n",
            "Epoch 274/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 9.8596e-04 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93842\n",
            "Epoch 275/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5692 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93842\n",
            "Epoch 276/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 8.0520e-04 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93842\n",
            "Epoch 277/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 4.2727e-04 - accuracy: 1.0000 - val_loss: 0.5543 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93842\n",
            "Epoch 278/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4964 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93842\n",
            "Epoch 279/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4700 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93842\n",
            "Epoch 280/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4389 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93842\n",
            "Epoch 281/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 6.6984e-04 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93842\n",
            "Epoch 282/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 5.4449e-04 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93842\n",
            "Epoch 283/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5158 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93842\n",
            "Epoch 284/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.7181 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93842\n",
            "Epoch 285/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4516 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93842\n",
            "Epoch 286/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5127 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93842\n",
            "Epoch 287/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5252 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93842\n",
            "Epoch 288/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 7.2080e-04 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93842\n",
            "Epoch 289/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4264 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93842\n",
            "Epoch 290/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 8.2052e-04 - accuracy: 1.0000 - val_loss: 0.4116 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93842\n",
            "Epoch 291/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 4.4129e-04 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93842\n",
            "Epoch 292/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 3.1876e-04 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93842\n",
            "Epoch 293/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 2.4051e-04 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93842\n",
            "Epoch 294/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0594 - accuracy: 0.9823 - val_loss: 1.5310 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93842\n",
            "Epoch 295/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0626 - accuracy: 0.9805 - val_loss: 0.8607 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93842\n",
            "Epoch 296/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0637 - accuracy: 0.9762 - val_loss: 1.1459 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93842\n",
            "Epoch 297/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0337 - accuracy: 0.9884 - val_loss: 0.8016 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93842\n",
            "Epoch 298/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 0.6265 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93842\n",
            "Epoch 299/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0270 - accuracy: 0.9927 - val_loss: 0.5350 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93842\n",
            "Epoch 300/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.5396 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93842\n",
            "Epoch 301/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.5615 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93842\n",
            "Epoch 302/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.4844 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93842\n",
            "Epoch 303/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.4744 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93842\n",
            "Epoch 304/500\n",
            "35/35 [==============================] - 20s 577ms/step - loss: 0.0760 - accuracy: 0.9756 - val_loss: 1.9095 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93842\n",
            "Epoch 305/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.1004 - accuracy: 0.9695 - val_loss: 1.1292 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93842\n",
            "Epoch 306/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0312 - accuracy: 0.9878 - val_loss: 1.0735 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93842\n",
            "Epoch 307/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0723 - accuracy: 0.9793 - val_loss: 0.4683 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93842\n",
            "Epoch 308/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0198 - accuracy: 0.9927 - val_loss: 0.4184 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93842\n",
            "Epoch 309/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.5410 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93842\n",
            "Epoch 310/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.3606 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93842\n",
            "Epoch 311/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.3625 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93842\n",
            "Epoch 312/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.6708 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93842\n",
            "Epoch 313/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.5032 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93842\n",
            "Epoch 314/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0314 - accuracy: 0.9903 - val_loss: 0.7892 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93842\n",
            "Epoch 315/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.4359 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93842\n",
            "Epoch 316/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.5673 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93842\n",
            "Epoch 317/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0251 - accuracy: 0.9903 - val_loss: 0.7095 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93842\n",
            "Epoch 318/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 0.7201 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93842\n",
            "Epoch 319/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.7491 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93842\n",
            "Epoch 320/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 0.6045 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93842\n",
            "Epoch 321/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0321 - accuracy: 0.9915 - val_loss: 0.8784 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93842\n",
            "Epoch 322/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0326 - accuracy: 0.9921 - val_loss: 0.6897 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93842\n",
            "Epoch 323/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0190 - accuracy: 0.9963 - val_loss: 0.6459 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93842\n",
            "Epoch 324/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.5282 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93842\n",
            "Epoch 325/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.4750 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93842\n",
            "Epoch 326/500\n",
            "35/35 [==============================] - 20s 569ms/step - loss: 0.0150 - accuracy: 0.9933 - val_loss: 0.5677 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93842\n",
            "Epoch 327/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4866 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93842\n",
            "Epoch 328/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4285 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93842\n",
            "Epoch 329/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4269 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93842\n",
            "Epoch 330/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93842\n",
            "Epoch 331/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.3844 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93842\n",
            "Epoch 332/500\n",
            "35/35 [==============================] - 20s 569ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93842\n",
            "Epoch 333/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4168 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93842\n",
            "Epoch 334/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 7.2361e-04 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93842\n",
            "Epoch 335/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.3396 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93842\n",
            "Epoch 336/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 4.6786e-04 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93842\n",
            "Epoch 337/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 7.0681e-04 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93842\n",
            "Epoch 338/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 6.2339e-04 - accuracy: 1.0000 - val_loss: 0.3878 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93842\n",
            "Epoch 339/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 7.0917e-04 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93842\n",
            "Epoch 340/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 4.9273e-04 - accuracy: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93842\n",
            "Epoch 341/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.5764 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93842\n",
            "Epoch 342/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.6285 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93842\n",
            "Epoch 343/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0665 - accuracy: 0.9823 - val_loss: 1.1775 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93842\n",
            "Epoch 344/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.7832 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93842\n",
            "Epoch 345/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.5338 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93842\n",
            "Epoch 346/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5514 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93842\n",
            "Epoch 347/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93842\n",
            "Epoch 348/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4693 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93842\n",
            "Epoch 349/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.4580 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93842\n",
            "Epoch 350/500\n",
            "35/35 [==============================] - 20s 577ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.6827 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93842\n",
            "Epoch 351/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.5801 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93842\n",
            "Epoch 352/500\n",
            "35/35 [==============================] - 20s 577ms/step - loss: 0.0525 - accuracy: 0.9836 - val_loss: 1.7458 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93842\n",
            "Epoch 353/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.9468 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93842\n",
            "Epoch 354/500\n",
            "35/35 [==============================] - 20s 569ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.7006 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93842\n",
            "Epoch 355/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0835 - accuracy: 0.9708 - val_loss: 3.1144 - val_accuracy: 0.5640\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93842\n",
            "Epoch 356/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0456 - accuracy: 0.9829 - val_loss: 7.8312 - val_accuracy: 0.4089\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93842\n",
            "Epoch 357/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0348 - accuracy: 0.9890 - val_loss: 1.3585 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93842\n",
            "Epoch 358/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.7976 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93842\n",
            "Epoch 359/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0087 - accuracy: 0.9957 - val_loss: 0.6153 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93842\n",
            "Epoch 360/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.5740 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93842\n",
            "Epoch 361/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4868 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93842\n",
            "Epoch 362/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93842\n",
            "Epoch 363/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 5.0563e-04 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93842\n",
            "Epoch 364/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5185 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93842\n",
            "Epoch 365/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 9.9046e-04 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93842\n",
            "Epoch 366/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4698 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93842\n",
            "Epoch 367/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4262 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93842\n",
            "Epoch 368/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5171 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93842\n",
            "Epoch 369/500\n",
            "35/35 [==============================] - 20s 576ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93842\n",
            "Epoch 370/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 7.8979e-04 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93842\n",
            "Epoch 371/500\n",
            "35/35 [==============================] - 20s 577ms/step - loss: 3.6005e-04 - accuracy: 1.0000 - val_loss: 0.4884 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93842\n",
            "Epoch 372/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5201 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93842\n",
            "Epoch 373/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4417 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93842\n",
            "Epoch 374/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93842\n",
            "Epoch 375/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 4.9943e-04 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93842\n",
            "Epoch 376/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93842\n",
            "Epoch 377/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 2.6302e-04 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93842\n",
            "Epoch 378/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 2.8439e-04 - accuracy: 1.0000 - val_loss: 0.3816 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93842\n",
            "Epoch 379/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5299 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93842\n",
            "Epoch 380/500\n",
            "35/35 [==============================] - 20s 563ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.4140 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93842\n",
            "Epoch 381/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0458 - accuracy: 0.9866 - val_loss: 2.0264 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93842\n",
            "Epoch 382/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0621 - accuracy: 0.9787 - val_loss: 1.2644 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93842\n",
            "Epoch 383/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.6534 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93842\n",
            "Epoch 384/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.5838 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93842\n",
            "Epoch 385/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.4598 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93842\n",
            "Epoch 386/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0097 - accuracy: 0.9957 - val_loss: 0.6017 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93842\n",
            "Epoch 387/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.4866 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93842\n",
            "Epoch 388/500\n",
            "35/35 [==============================] - 20s 569ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.3729 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93842\n",
            "Epoch 389/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 6.8378e-04 - accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93842\n",
            "Epoch 390/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 8.2583e-04 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93842\n",
            "Epoch 391/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4252 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93842\n",
            "Epoch 392/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.3417 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93842\n",
            "Epoch 393/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.4124 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93842\n",
            "Epoch 394/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.4654 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93842\n",
            "Epoch 395/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5504 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93842\n",
            "Epoch 396/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5194 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93842\n",
            "Epoch 397/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.5645 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93842\n",
            "Epoch 398/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.6402 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93842\n",
            "Epoch 399/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.6728 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93842\n",
            "Epoch 400/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4876 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93842\n",
            "Epoch 401/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5263 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93842\n",
            "Epoch 402/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4083 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93842\n",
            "Epoch 403/500\n",
            "35/35 [==============================] - 20s 569ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3822 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93842\n",
            "Epoch 404/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93842\n",
            "Epoch 405/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 7.7908e-04 - accuracy: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93842\n",
            "Epoch 406/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.6139 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93842\n",
            "Epoch 407/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.4887 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93842\n",
            "Epoch 408/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.4333 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93842\n",
            "Epoch 409/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4823 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93842\n",
            "Epoch 410/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4564 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.93842\n",
            "Epoch 411/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 8.0249e-04 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.93842\n",
            "Epoch 412/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 5.0036e-04 - accuracy: 1.0000 - val_loss: 0.4197 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.93842\n",
            "Epoch 413/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.5916 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.93842\n",
            "Epoch 414/500\n",
            "35/35 [==============================] - 20s 578ms/step - loss: 0.1083 - accuracy: 0.9708 - val_loss: 1.1359 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.93842\n",
            "Epoch 415/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0365 - accuracy: 0.9854 - val_loss: 1.0065 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.93842\n",
            "Epoch 416/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 1.4403 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93842\n",
            "Epoch 417/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.7588 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93842\n",
            "Epoch 418/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.5827 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93842\n",
            "Epoch 419/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.5911 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93842\n",
            "Epoch 420/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.5538 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.93842\n",
            "Epoch 421/500\n",
            "35/35 [==============================] - 20s 569ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.6150 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.93842\n",
            "Epoch 422/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.5225 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93842\n",
            "Epoch 423/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0370 - accuracy: 0.9890 - val_loss: 0.7251 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93842\n",
            "Epoch 424/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.6598 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93842\n",
            "Epoch 425/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5194 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93842\n",
            "Epoch 426/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0074 - accuracy: 0.9957 - val_loss: 0.4715 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93842\n",
            "Epoch 427/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93842\n",
            "Epoch 428/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93842\n",
            "Epoch 429/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.5696 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.93842\n",
            "Epoch 430/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.4311 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.93842\n",
            "Epoch 431/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.3991 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.93842\n",
            "Epoch 432/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4335 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.93842\n",
            "Epoch 433/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 5.1941e-04 - accuracy: 1.0000 - val_loss: 0.4540 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.93842\n",
            "Epoch 434/500\n",
            "35/35 [==============================] - 20s 570ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.93842\n",
            "Epoch 435/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 6.4119e-04 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.93842\n",
            "Epoch 436/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 6.4484e-04 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.93842\n",
            "Epoch 437/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 4.6681e-04 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.93842\n",
            "Epoch 438/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 3.9376e-04 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.93842\n",
            "Epoch 439/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 5.0967e-04 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.93842\n",
            "Epoch 440/500\n",
            "35/35 [==============================] - 20s 569ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4253 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.93842\n",
            "Epoch 441/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5218 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.93842\n",
            "Epoch 442/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5131 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.93842\n",
            "Epoch 443/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 6.3853e-04 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.93842\n",
            "Epoch 444/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4800 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.93842\n",
            "Epoch 445/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 4.4641e-04 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.93842\n",
            "Epoch 446/500\n",
            "35/35 [==============================] - 20s 576ms/step - loss: 4.5779e-04 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.93842\n",
            "Epoch 447/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 3.8002e-04 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.93842\n",
            "Epoch 448/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 1.4570e-04 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.93842\n",
            "Epoch 449/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 1.3501e-04 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.93842\n",
            "Epoch 450/500\n",
            "35/35 [==============================] - 20s 569ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.5590 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.93842\n",
            "Epoch 451/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.5868 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.93842\n",
            "Epoch 452/500\n",
            "35/35 [==============================] - 20s 579ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4982 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.93842\n",
            "Epoch 453/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.5168 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.93842\n",
            "Epoch 454/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.4831 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.93842\n",
            "Epoch 455/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4498 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.93842\n",
            "Epoch 456/500\n",
            "35/35 [==============================] - 20s 576ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.4536 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.93842\n",
            "Epoch 457/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.7946 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.93842\n",
            "Epoch 458/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0155 - accuracy: 0.9939 - val_loss: 0.8476 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.93842\n",
            "Epoch 459/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.6408 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.93842\n",
            "Epoch 460/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.6135 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.93842\n",
            "Epoch 461/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4330 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.93842\n",
            "Epoch 462/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.5166 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.93842\n",
            "Epoch 463/500\n",
            "35/35 [==============================] - 20s 564ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4342 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.93842\n",
            "Epoch 464/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 4.8269e-04 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.93842\n",
            "Epoch 465/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 2.9793e-04 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.93842\n",
            "Epoch 466/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 5.0029e-04 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.93842\n",
            "Epoch 467/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 9.3181e-04 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.93842\n",
            "Epoch 468/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 6.9663e-04 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.93842\n",
            "Epoch 469/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 6.2299e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.93842\n",
            "Epoch 470/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.1018 - accuracy: 0.9732 - val_loss: 1.7925 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.93842\n",
            "Epoch 471/500\n",
            "35/35 [==============================] - 20s 565ms/step - loss: 0.0844 - accuracy: 0.9744 - val_loss: 1.5032 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.93842\n",
            "Epoch 472/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0358 - accuracy: 0.9860 - val_loss: 0.8860 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.93842\n",
            "Epoch 473/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0237 - accuracy: 0.9896 - val_loss: 0.6373 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.93842\n",
            "Epoch 474/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.8866 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.93842\n",
            "Epoch 475/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.7051 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.93842\n",
            "Epoch 476/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0427 - accuracy: 0.9890 - val_loss: 0.7090 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.93842\n",
            "Epoch 477/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.4867 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.93842\n",
            "Epoch 478/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4813 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.93842\n",
            "Epoch 479/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.93842\n",
            "Epoch 480/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.93842\n",
            "Epoch 481/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.4879 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.93842\n",
            "Epoch 482/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.93842\n",
            "Epoch 483/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.93842\n",
            "Epoch 484/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5566 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.93842\n",
            "Epoch 485/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5732 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.93842\n",
            "Epoch 486/500\n",
            "35/35 [==============================] - 20s 569ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.93842\n",
            "Epoch 487/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4836 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.93842\n",
            "Epoch 488/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 8.4712e-04 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.93842\n",
            "Epoch 489/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 3.1816e-04 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.93842\n",
            "Epoch 490/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4623 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.93842\n",
            "Epoch 491/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 8.4403e-04 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.93842\n",
            "Epoch 492/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 2.2393e-04 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.93842\n",
            "Epoch 493/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 7.1264e-04 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.93842\n",
            "Epoch 494/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 2.7568e-04 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.93842\n",
            "Epoch 495/500\n",
            "35/35 [==============================] - 20s 568ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.5044 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.93842\n",
            "Epoch 496/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 5.9916e-04 - accuracy: 1.0000 - val_loss: 0.5851 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.93842\n",
            "Epoch 497/500\n",
            "35/35 [==============================] - 20s 566ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4644 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.93842\n",
            "Epoch 498/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 4.8032e-04 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.93842\n",
            "Epoch 499/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4183 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.93842\n",
            "Epoch 500/500\n",
            "35/35 [==============================] - 20s 567ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4488 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.93842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f02b035c310>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "01b434c0-2bff-412a-c2ee-84c32455261e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_48_4_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35caa736-e44a-4944-8bea-beb2ad888bf5"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8aa3c1f-35a0-491a-f2d8-3998c0d3e42f"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "14388075-28bb-4957-9c4d-37122fd628ef"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3ea2e261-1588-4f5f-da7e-c8ce86d6e84c"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/BatchSize_48_4_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/BatchSize_48_4_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e5ddfc3c-dbd1-4d51-8028-b0c9ec4c704d\", \"BatchSize_48_4_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}