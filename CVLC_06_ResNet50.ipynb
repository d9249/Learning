{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVLC_06_ResNet50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNDsMeUwIyKTqLi4I7LLJbV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/CVLC_06_ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb7f643f-37a3-40d2-f255-429074e76782"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')\n",
        "sub = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhxQt2hlphSW"
      },
      "source": [
        "# !mkdir /content/drive/MyDrive/DACON_CVLC/data/images_train\n",
        "# !mkdir /content/drive/MyDrive/DACON_CVLC/data/images_train/0\n",
        "# !mkdir /content/drive/MyDrive/DACON_CVLC/data/images_train/1\n",
        "# !mkdir /content/drive/MyDrive/DACON_CVLC/data/images_train/2\n",
        "# !mkdir /content/drive/MyDrive/DACON_CVLC/data/images_train/3\n",
        "# !mkdir /content/drive/MyDrive/DACON_CVLC/data/images_train/4\n",
        "# !mkdir /content/drive/MyDrive/DACON_CVLC/data/images_train/5\n",
        "# !mkdir /content/drive/MyDrive/DACON_CVLC/data/images_train/6\n",
        "# !mkdir /content/drive/MyDrive/DACON_CVLC/data/images_train/7\n",
        "# !mkdir /content/drive/MyDrive/DACON_CVLC/data/images_train/8\n",
        "# !mkdir /content/drive/MyDrive/DACON_CVLC/data/images_train/9\n",
        "# !mkdir /content/drive/MyDrive/DACON_CVLC/data/images_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMWI-_1Up21E"
      },
      "source": [
        "# import cv2\n",
        "\n",
        "# for idx in range(len(train)) :\n",
        "#     img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "#     digit = train.loc[idx, 'digit']\n",
        "#     cv2.imwrite(f'/content/drive/MyDrive/DACON_CVLC/data/images_train/{digit}/{train[\"id\"][idx]}.png', img)\n",
        "\n",
        "# for idx in range(len(test)) :\n",
        "#     img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "#     cv2.imwrite(f'/content/drive/MyDrive/DACON_CVLC/data/images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "model =  tf.keras.applications.ResNet50(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlVMd30ZxUMQ",
        "outputId": "61090372-d98c-4a1f-bfaa-6781ceda2e78"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1haI0Zjxa74",
        "outputId": "b01a0b6a-7217-49d0-addc-b58fbb93eaf9"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('/content/drive/MyDrive/DACON_CVLC/data/images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('/content/drive/MyDrive/DACON_CVLC/data/images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKMJhbFnxotA",
        "outputId": "de2da441-4d20-418c-fe06-f03550af581a"
      },
      "source": [
        "model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 513s 10s/step - loss: 3.1435 - accuracy: 0.2010 - val_loss: 16.4930 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09606, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 1.7496 - accuracy: 0.4379 - val_loss: 5.5127 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.09606\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 1.2450 - accuracy: 0.5895 - val_loss: 5.1030 - val_accuracy: 0.0640\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.09606\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 1.1781 - accuracy: 0.6181 - val_loss: 4.9117 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.09606 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 1.1101 - accuracy: 0.6510 - val_loss: 5.1380 - val_accuracy: 0.1158\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.10099 to 0.11576, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 1.0658 - accuracy: 0.6778 - val_loss: 8.1314 - val_accuracy: 0.1108\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.11576\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.7757 - accuracy: 0.7424 - val_loss: 4.8095 - val_accuracy: 0.1453\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.11576 to 0.14532, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.7861 - accuracy: 0.7381 - val_loss: 4.1852 - val_accuracy: 0.2365\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.14532 to 0.23645, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.7706 - accuracy: 0.7558 - val_loss: 3.7935 - val_accuracy: 0.2980\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.23645 to 0.29803, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.5964 - accuracy: 0.8033 - val_loss: 1.5380 - val_accuracy: 0.5862\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.29803 to 0.58621, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.6501 - accuracy: 0.7832 - val_loss: 1.1266 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.58621 to 0.69951, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.5893 - accuracy: 0.8197 - val_loss: 1.3959 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.69951 to 0.70197, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 13s 207ms/step - loss: 0.5134 - accuracy: 0.8234 - val_loss: 1.0821 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.70197 to 0.73153, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.5110 - accuracy: 0.8276 - val_loss: 1.5238 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.73153\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.4629 - accuracy: 0.8544 - val_loss: 6.2475 - val_accuracy: 0.3079\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.73153\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.5916 - accuracy: 0.8057 - val_loss: 11.3563 - val_accuracy: 0.1724\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.73153\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.4513 - accuracy: 0.8453 - val_loss: 9.2480 - val_accuracy: 0.2759\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.73153\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.4617 - accuracy: 0.8410 - val_loss: 1.8558 - val_accuracy: 0.6133\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.73153\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.3933 - accuracy: 0.8642 - val_loss: 0.8541 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.73153 to 0.79557, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3737 - accuracy: 0.8776 - val_loss: 2.9813 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.79557\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.3936 - accuracy: 0.8752 - val_loss: 0.9548 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.79557\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3485 - accuracy: 0.8837 - val_loss: 19.7084 - val_accuracy: 0.2241\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.79557\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.4193 - accuracy: 0.8581 - val_loss: 2.6926 - val_accuracy: 0.6084\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.79557\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.3491 - accuracy: 0.8770 - val_loss: 0.7512 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.79557 to 0.80542, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3899 - accuracy: 0.8733 - val_loss: 1.2023 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.80542\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.3285 - accuracy: 0.8965 - val_loss: 0.8585 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.80542\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.2566 - accuracy: 0.9099 - val_loss: 0.5926 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.80542 to 0.84236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.2412 - accuracy: 0.9214 - val_loss: 0.8175 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.84236\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2708 - accuracy: 0.9117 - val_loss: 0.8678 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.84236\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.2881 - accuracy: 0.9026 - val_loss: 0.9153 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.84236\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.2759 - accuracy: 0.9093 - val_loss: 0.6040 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.84236\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.2479 - accuracy: 0.9178 - val_loss: 0.9263 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.84236\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.1885 - accuracy: 0.9415 - val_loss: 1.5415 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.84236\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.2795 - accuracy: 0.9074 - val_loss: 1.4835 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.84236\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2087 - accuracy: 0.9306 - val_loss: 0.6260 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.84236\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.2640 - accuracy: 0.9208 - val_loss: 1.7456 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.84236\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.2279 - accuracy: 0.9263 - val_loss: 3.8937 - val_accuracy: 0.4951\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.84236\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.2228 - accuracy: 0.9306 - val_loss: 1.2421 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.84236\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.2123 - accuracy: 0.9373 - val_loss: 0.6211 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.84236\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1657 - accuracy: 0.9409 - val_loss: 0.8138 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.84236\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1741 - accuracy: 0.9434 - val_loss: 0.5827 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.84236 to 0.86207, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2135 - accuracy: 0.9294 - val_loss: 1.3770 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.86207\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.2328 - accuracy: 0.9239 - val_loss: 0.8047 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.86207\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.2448 - accuracy: 0.9184 - val_loss: 0.8341 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.86207\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 10s 203ms/step - loss: 0.3366 - accuracy: 0.8934 - val_loss: 7.1817 - val_accuracy: 0.3744\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.86207\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.2218 - accuracy: 0.9257 - val_loss: 12.2589 - val_accuracy: 0.2143\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.86207\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1219 - accuracy: 0.9580 - val_loss: 0.5145 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.86207 to 0.86700, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.2100 - accuracy: 0.9281 - val_loss: 1.5642 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.86700\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1928 - accuracy: 0.9379 - val_loss: 0.5888 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.86700\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.1497 - accuracy: 0.9440 - val_loss: 8.5204 - val_accuracy: 0.3473\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.86700\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0771 - accuracy: 0.9738 - val_loss: 0.7248 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.86700\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.1683 - accuracy: 0.9482 - val_loss: 0.5113 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.86700 to 0.87685, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1056 - accuracy: 0.9604 - val_loss: 0.6322 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.87685\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.1158 - accuracy: 0.9629 - val_loss: 1.2025 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.87685\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1280 - accuracy: 0.9543 - val_loss: 0.9480 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.87685\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1740 - accuracy: 0.9391 - val_loss: 2.2614 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.87685\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.2539 - accuracy: 0.9251 - val_loss: 3.1708 - val_accuracy: 0.5394\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.87685\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.2427 - accuracy: 0.9220 - val_loss: 0.8278 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.87685\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.1253 - accuracy: 0.9580 - val_loss: 0.5854 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.87685\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.1135 - accuracy: 0.9586 - val_loss: 0.6058 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.87685\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1557 - accuracy: 0.9440 - val_loss: 18.4537 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.87685\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1442 - accuracy: 0.9476 - val_loss: 3.5703 - val_accuracy: 0.5369\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.87685\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.2355 - accuracy: 0.9196 - val_loss: 1.5050 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.87685\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.1603 - accuracy: 0.9354 - val_loss: 1.4586 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.87685\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.2212 - accuracy: 0.9227 - val_loss: 1.0899 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.87685\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.1338 - accuracy: 0.9519 - val_loss: 0.9172 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.87685\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1044 - accuracy: 0.9641 - val_loss: 0.6876 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.87685\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0879 - accuracy: 0.9683 - val_loss: 0.8005 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.87685\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.1019 - accuracy: 0.9708 - val_loss: 0.5952 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.87685\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.1265 - accuracy: 0.9580 - val_loss: 0.9185 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.87685\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0737 - accuracy: 0.9689 - val_loss: 0.5743 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.87685\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0730 - accuracy: 0.9744 - val_loss: 0.5292 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.87685 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0742 - accuracy: 0.9787 - val_loss: 0.4167 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.88670\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0358 - accuracy: 0.9872 - val_loss: 0.5093 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.88670\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0646 - accuracy: 0.9793 - val_loss: 0.5191 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.88670\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0964 - accuracy: 0.9641 - val_loss: 0.7592 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.88670\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.1213 - accuracy: 0.9604 - val_loss: 0.9277 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.88670\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.1221 - accuracy: 0.9629 - val_loss: 0.9085 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.88670\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 10s 202ms/step - loss: 0.1388 - accuracy: 0.9495 - val_loss: 0.9960 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.88670\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.1761 - accuracy: 0.9446 - val_loss: 1.7507 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.88670\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1674 - accuracy: 0.9458 - val_loss: 0.8978 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.88670\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1170 - accuracy: 0.9598 - val_loss: 0.6013 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.88670\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0738 - accuracy: 0.9756 - val_loss: 0.8319 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.88670\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0567 - accuracy: 0.9799 - val_loss: 0.6304 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.88670\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0632 - accuracy: 0.9805 - val_loss: 4.4625 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.88670\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 10s 200ms/step - loss: 0.0754 - accuracy: 0.9720 - val_loss: 1.0405 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.88670\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0671 - accuracy: 0.9793 - val_loss: 0.5790 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.88670\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0899 - accuracy: 0.9677 - val_loss: 0.5524 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.88670\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1554 - accuracy: 0.9531 - val_loss: 0.9935 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.88670\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.1038 - accuracy: 0.9689 - val_loss: 0.8688 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.88670\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 10s 199ms/step - loss: 0.0578 - accuracy: 0.9805 - val_loss: 0.4605 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.88670\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0609 - accuracy: 0.9829 - val_loss: 0.7903 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.88670\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 10s 200ms/step - loss: 0.1102 - accuracy: 0.9659 - val_loss: 1.0060 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.88670\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0917 - accuracy: 0.9689 - val_loss: 1.2642 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.88670\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.1303 - accuracy: 0.9616 - val_loss: 1.1812 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.88670\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.1181 - accuracy: 0.9665 - val_loss: 1.3512 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.88670\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0972 - accuracy: 0.9647 - val_loss: 0.4995 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.88670\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 10s 200ms/step - loss: 0.0631 - accuracy: 0.9769 - val_loss: 0.6646 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.88670\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0513 - accuracy: 0.9805 - val_loss: 0.4735 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00099: val_accuracy improved from 0.88670 to 0.89409, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0799 - accuracy: 0.9750 - val_loss: 3.8426 - val_accuracy: 0.5591\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.89409\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0908 - accuracy: 0.9689 - val_loss: 0.9149 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.89409\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0847 - accuracy: 0.9738 - val_loss: 0.8900 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.89409\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.1041 - accuracy: 0.9647 - val_loss: 1.4587 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.89409\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0689 - accuracy: 0.9750 - val_loss: 0.7991 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.89409\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0405 - accuracy: 0.9854 - val_loss: 0.7339 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.89409\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0211 - accuracy: 0.9915 - val_loss: 0.6724 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.89409\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0503 - accuracy: 0.9811 - val_loss: 1.1985 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.89409\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0931 - accuracy: 0.9689 - val_loss: 0.8632 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.89409\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0645 - accuracy: 0.9775 - val_loss: 0.4558 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.89409\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0696 - accuracy: 0.9775 - val_loss: 1.3233 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.89409\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0508 - accuracy: 0.9805 - val_loss: 0.5842 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.89409\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0622 - accuracy: 0.9775 - val_loss: 0.5511 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.89409\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0646 - accuracy: 0.9775 - val_loss: 0.5949 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.89409\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0381 - accuracy: 0.9896 - val_loss: 5.8053 - val_accuracy: 0.4852\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.89409\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1819 - accuracy: 0.9525 - val_loss: 0.8724 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.89409\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1494 - accuracy: 0.9495 - val_loss: 1.1117 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.89409\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.1077 - accuracy: 0.9659 - val_loss: 18.6682 - val_accuracy: 0.1305\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.89409\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0498 - accuracy: 0.9811 - val_loss: 0.7712 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.89409\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0332 - accuracy: 0.9903 - val_loss: 0.4781 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.89409\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0519 - accuracy: 0.9842 - val_loss: 1.0168 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.89409\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0674 - accuracy: 0.9769 - val_loss: 0.8455 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.89409\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1545 - accuracy: 0.9537 - val_loss: 2.0297 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.89409\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0716 - accuracy: 0.9762 - val_loss: 0.5547 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.89409\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0599 - accuracy: 0.9805 - val_loss: 0.3827 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00124: val_accuracy improved from 0.89409 to 0.89901, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0618 - accuracy: 0.9781 - val_loss: 0.6224 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.89901\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0341 - accuracy: 0.9866 - val_loss: 0.3759 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00126: val_accuracy improved from 0.89901 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0357 - accuracy: 0.9866 - val_loss: 0.7356 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.90394\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.1733 - accuracy: 0.9458 - val_loss: 1.9326 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.90394\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0592 - accuracy: 0.9805 - val_loss: 0.5663 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.90394\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 10s 200ms/step - loss: 0.0743 - accuracy: 0.9769 - val_loss: 1.2270 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.90394\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 10s 200ms/step - loss: 0.0508 - accuracy: 0.9878 - val_loss: 0.5110 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.90394\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0408 - accuracy: 0.9866 - val_loss: 0.5337 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.90394\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0554 - accuracy: 0.9836 - val_loss: 0.5532 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.90394\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0300 - accuracy: 0.9896 - val_loss: 0.4384 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.90394\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0389 - accuracy: 0.9854 - val_loss: 0.5330 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.90394\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0278 - accuracy: 0.9896 - val_loss: 0.5623 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.90394\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 0.6459 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.90394\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0591 - accuracy: 0.9817 - val_loss: 0.6706 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.90394\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 10s 202ms/step - loss: 0.0727 - accuracy: 0.9756 - val_loss: 0.7305 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.90394\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 10s 203ms/step - loss: 0.0979 - accuracy: 0.9702 - val_loss: 2.1227 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.90394\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0707 - accuracy: 0.9769 - val_loss: 0.8690 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.90394\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0436 - accuracy: 0.9866 - val_loss: 9.7330 - val_accuracy: 0.3768\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.90394\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0522 - accuracy: 0.9805 - val_loss: 0.4864 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00143: val_accuracy improved from 0.90394 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 0.5130 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.90887\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 1.3850 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.90887\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0765 - accuracy: 0.9738 - val_loss: 0.5700 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.90887\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0555 - accuracy: 0.9787 - val_loss: 0.5001 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.90887\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0173 - accuracy: 0.9963 - val_loss: 0.3906 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00148: val_accuracy improved from 0.90887 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 12s 208ms/step - loss: 0.0237 - accuracy: 0.9939 - val_loss: 0.6902 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.91626\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.6355 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.91626\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0569 - accuracy: 0.9811 - val_loss: 0.6817 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.91626\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0557 - accuracy: 0.9842 - val_loss: 6.0377 - val_accuracy: 0.4754\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.91626\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0613 - accuracy: 0.9836 - val_loss: 1.0610 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.91626\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0985 - accuracy: 0.9744 - val_loss: 0.6501 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.91626\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0972 - accuracy: 0.9726 - val_loss: 0.6823 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.91626\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0573 - accuracy: 0.9787 - val_loss: 0.4866 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.91626\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0511 - accuracy: 0.9799 - val_loss: 0.6315 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.91626\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0283 - accuracy: 0.9866 - val_loss: 0.5657 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.91626\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.5341 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.91626\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 11.3937 - val_accuracy: 0.3498\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.91626\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.7506 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.91626\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0494 - accuracy: 0.9823 - val_loss: 0.6403 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.91626\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0299 - accuracy: 0.9896 - val_loss: 0.6078 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.91626\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0803 - accuracy: 0.9744 - val_loss: 0.6935 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.91626\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.1099 - accuracy: 0.9689 - val_loss: 0.9632 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.91626\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0517 - accuracy: 0.9829 - val_loss: 0.7015 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.91626\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0471 - accuracy: 0.9836 - val_loss: 0.6953 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.91626\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0406 - accuracy: 0.9872 - val_loss: 0.5957 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.91626\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.7163 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.91626\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.4742 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.91626\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 0.3939 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.91626\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.4519 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.91626\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0185 - accuracy: 0.9921 - val_loss: 4.6873 - val_accuracy: 0.5739\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.91626\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0373 - accuracy: 0.9854 - val_loss: 1.2915 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.91626\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0612 - accuracy: 0.9860 - val_loss: 0.6964 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.91626\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0879 - accuracy: 0.9726 - val_loss: 1.0263 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.91626\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0438 - accuracy: 0.9829 - val_loss: 7.4650 - val_accuracy: 0.4335\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.91626\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0732 - accuracy: 0.9799 - val_loss: 1.0621 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.91626\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 0.4232 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.91626\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0219 - accuracy: 0.9903 - val_loss: 0.4578 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.91626\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.5021 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.91626\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.4633 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.91626\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0782 - accuracy: 0.9726 - val_loss: 6.4032 - val_accuracy: 0.4458\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.91626\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0416 - accuracy: 0.9860 - val_loss: 5.3925 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.91626\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0268 - accuracy: 0.9890 - val_loss: 0.5788 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.91626\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 10s 200ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.5575 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.91626\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 0.5465 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.91626\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.5912 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.91626\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.4841 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.91626\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0218 - accuracy: 0.9909 - val_loss: 0.5621 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.91626\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.8730 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.91626\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0328 - accuracy: 0.9872 - val_loss: 0.7901 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.91626\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 10s 200ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.6963 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.91626\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.6365 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.91626\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0473 - accuracy: 0.9848 - val_loss: 0.9563 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.91626\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 0.7404 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.91626\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0188 - accuracy: 0.9957 - val_loss: 0.5789 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.91626\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0378 - accuracy: 0.9896 - val_loss: 0.8851 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.91626\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0933 - accuracy: 0.9702 - val_loss: 0.7267 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.91626\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0455 - accuracy: 0.9866 - val_loss: 0.5099 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.91626\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0501 - accuracy: 0.9823 - val_loss: 12.3679 - val_accuracy: 0.2635\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.91626\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0950 - accuracy: 0.9738 - val_loss: 0.6165 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.91626\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.5331 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.91626\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0294 - accuracy: 0.9939 - val_loss: 0.9597 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.91626\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.5588 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.91626\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0331 - accuracy: 0.9909 - val_loss: 0.6161 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.91626\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.4788 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.91626\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0117 - accuracy: 0.9939 - val_loss: 0.4734 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.91626\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4371 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.91626\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00210: val_accuracy improved from 0.91626 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4715 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92611\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4187 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92611\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.3858 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92611\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0191 - accuracy: 0.9951 - val_loss: 0.4837 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92611\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0437 - accuracy: 0.9884 - val_loss: 0.7829 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92611\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.4526 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.92611\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.5931 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92611\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0259 - accuracy: 0.9903 - val_loss: 0.5573 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92611\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0831 - accuracy: 0.9726 - val_loss: 1.2516 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92611\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 10s 200ms/step - loss: 0.0429 - accuracy: 0.9848 - val_loss: 0.6290 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92611\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0913 - accuracy: 0.9726 - val_loss: 20.3258 - val_accuracy: 0.1478\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.92611\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0374 - accuracy: 0.9866 - val_loss: 1.4793 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.92611\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 1.2326 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.92611\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0895 - accuracy: 0.9738 - val_loss: 1.8075 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.92611\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0874 - accuracy: 0.9732 - val_loss: 0.9501 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.92611\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0411 - accuracy: 0.9848 - val_loss: 0.4589 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.92611\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.5766 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92611\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.4485 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92611\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.5180 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92611\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.4697 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92611\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5768 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92611\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.5637 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92611\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.5999 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92611\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.5416 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92611\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0533 - accuracy: 0.9890 - val_loss: 8.6004 - val_accuracy: 0.4236\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92611\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0605 - accuracy: 0.9829 - val_loss: 0.9081 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92611\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0274 - accuracy: 0.9896 - val_loss: 0.9079 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92611\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0639 - accuracy: 0.9829 - val_loss: 0.5706 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92611\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.5020 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92611\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0081 - accuracy: 0.9988 - val_loss: 0.4367 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92611\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 10s 200ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.3888 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.92611\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.3428 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.92611\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.5001 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.92611\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.92611\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.6261 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.92611\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0173 - accuracy: 0.9915 - val_loss: 0.4481 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.92611\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.4942 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.92611\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.5216 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.92611\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0234 - accuracy: 0.9951 - val_loss: 0.5009 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.92611\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.3743 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.92611\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.3254 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.92611\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4400 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92611\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.5777 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.92611\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0799 - accuracy: 0.9738 - val_loss: 8.7728 - val_accuracy: 0.4089\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.92611\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0664 - accuracy: 0.9793 - val_loss: 1.0540 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.92611\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0531 - accuracy: 0.9799 - val_loss: 1.0895 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.92611\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0232 - accuracy: 0.9945 - val_loss: 0.5682 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.92611\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.5591 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.92611\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.5759 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.92611\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.4007 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.92611\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.5772 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.92611\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.6010 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.92611\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5403 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.92611\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4320 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.92611\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.92611\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 6.7568e-04 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.92611\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0222 - accuracy: 0.9945 - val_loss: 0.6509 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.92611\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0379 - accuracy: 0.9903 - val_loss: 1.9425 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.92611\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 10s 202ms/step - loss: 0.1029 - accuracy: 0.9689 - val_loss: 11.7686 - val_accuracy: 0.3645\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.92611\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0384 - accuracy: 0.9860 - val_loss: 0.5728 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.92611\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0468 - accuracy: 0.9896 - val_loss: 0.7012 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.92611\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0249 - accuracy: 0.9903 - val_loss: 0.5532 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.92611\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0184 - accuracy: 0.9963 - val_loss: 0.5720 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.92611\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.6359 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.92611\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 0.9894 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.92611\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 11s 200ms/step - loss: 0.0339 - accuracy: 0.9915 - val_loss: 0.5433 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.92611\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.5334 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.92611\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0233 - accuracy: 0.9909 - val_loss: 0.5129 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.92611\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0388 - accuracy: 0.9878 - val_loss: 0.5716 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.92611\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0585 - accuracy: 0.9823 - val_loss: 1.3456 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.92611\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0282 - accuracy: 0.9878 - val_loss: 0.6219 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.92611\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.5432 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.92611\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.4468 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.92611\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.4626 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.92611\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.4261 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.92611\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.5121 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.92611\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.4898 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.92611\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.8802 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.92611\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0478 - accuracy: 0.9872 - val_loss: 0.8371 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.92611\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0361 - accuracy: 0.9896 - val_loss: 0.6314 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.92611\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0405 - accuracy: 0.9903 - val_loss: 0.7230 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.92611\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.5018 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.92611\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.5187 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.92611\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.5592 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.92611\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.4532 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.92611\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.3810 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00296: val_accuracy improved from 0.92611 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0148 - accuracy: 0.9939 - val_loss: 0.6368 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.92857\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0292 - accuracy: 0.9939 - val_loss: 0.7421 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.92857\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.8573 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.92857\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.6475 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.92857\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4429 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.92857\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4637 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.92857\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.4779 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.92857\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5373 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.92857\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0076 - accuracy: 0.9957 - val_loss: 0.6799 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.92857\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.6246 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.92857\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.8370 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.92857\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.5865 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.92857\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.6371 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.92857\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.5875 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.92857\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.5867 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.92857\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 4.2318 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.92857\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.9206 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.92857\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0287 - accuracy: 0.9890 - val_loss: 0.8343 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.92857\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0631 - accuracy: 0.9799 - val_loss: 1.0354 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.92857\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0473 - accuracy: 0.9823 - val_loss: 0.5562 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.92857\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.5946 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.92857\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.6967 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.92857\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.6413 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.92857\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0372 - accuracy: 0.9945 - val_loss: 0.5176 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.92857\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 11.9639 - val_accuracy: 0.3990\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.92857\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0216 - accuracy: 0.9951 - val_loss: 0.5212 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.92857\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0190 - accuracy: 0.9927 - val_loss: 7.4218 - val_accuracy: 0.4409\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.92857\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.5077 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.92857\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0067 - accuracy: 0.9963 - val_loss: 0.4652 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.92857\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4597 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.92857\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4658 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.92857\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.92857\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4325 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.92857\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4725 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.92857\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.92857\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4701 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.92857\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.6126 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.92857\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.6105 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.92857\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5763 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.92857\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0272 - accuracy: 0.9939 - val_loss: 0.5833 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.92857\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.6029 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.92857\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.5771 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.92857\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0161 - accuracy: 0.9939 - val_loss: 0.7961 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.92857\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.6663 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.92857\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.6927 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.92857\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0152 - accuracy: 0.9939 - val_loss: 0.5664 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.92857\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.7650 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.92857\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0449 - accuracy: 0.9860 - val_loss: 0.7119 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.92857\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0322 - accuracy: 0.9909 - val_loss: 0.6534 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.92857\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 10.4437 - val_accuracy: 0.4360\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.92857\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0215 - accuracy: 0.9909 - val_loss: 0.5716 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.92857\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.5346 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.92857\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0213 - accuracy: 0.9951 - val_loss: 0.7212 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.92857\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.5855 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.92857\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0150 - accuracy: 0.9976 - val_loss: 0.4206 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.92857\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4398 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.92857\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4732 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.92857\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.5374 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.92857\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.5567 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.92857\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0177 - accuracy: 0.9933 - val_loss: 0.5423 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.92857\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.6040 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.92857\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.6517 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.92857\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0206 - accuracy: 0.9963 - val_loss: 0.5796 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.92857\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.92857\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5328 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.92857\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.5051 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.92857\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.7664 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.92857\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 0.8407 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.92857\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.5263 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.92857\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4785 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.92857\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.5889 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.92857\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.6275 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.92857\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.5151 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.92857\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.8441 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.92857\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.7199 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.92857\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0286 - accuracy: 0.9933 - val_loss: 0.7456 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.92857\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.6969 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.92857\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0295 - accuracy: 0.9915 - val_loss: 0.7461 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.92857\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.5045 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.92857\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0203 - accuracy: 0.9921 - val_loss: 0.5608 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.92857\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.6648 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.92857\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0282 - accuracy: 0.9884 - val_loss: 0.5664 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.92857\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0148 - accuracy: 0.9939 - val_loss: 0.6605 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.92857\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.4805 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.92857\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5529 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.92857\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5039 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.92857\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.4943 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.92857\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.6260 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.92857\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5530 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.92857\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4535 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.92857\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.6120 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.92857\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.5976 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.92857\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0473 - accuracy: 0.9872 - val_loss: 0.9195 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.92857\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 0.5779 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.92857\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0323 - accuracy: 0.9915 - val_loss: 0.5776 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.92857\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 10s 203ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.4929 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.92857\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.7517 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.92857\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.5285 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.92857\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0211 - accuracy: 0.9945 - val_loss: 0.7222 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.92857\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.6153 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.92857\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0122 - accuracy: 0.9945 - val_loss: 0.7997 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.92857\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.7291 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.92857\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0076 - accuracy: 0.9963 - val_loss: 0.7733 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.92857\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.5299 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.92857\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5045 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.92857\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.6884 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.92857\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.6963 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.92857\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0412 - accuracy: 0.9884 - val_loss: 1.3918 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.92857\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 6.1136 - val_accuracy: 0.5764\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.92857\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 10.4181 - val_accuracy: 0.3892\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.92857\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0459 - accuracy: 0.9872 - val_loss: 0.5026 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.92857\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0505 - accuracy: 0.9909 - val_loss: 8.9716 - val_accuracy: 0.4507\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.92857\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.7712 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.92857\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4929 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.92857\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4101 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.92857\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.5923 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.92857\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.5748 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.92857\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.6287 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.92857\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.5857 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.92857\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5218 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.92857\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.9219 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.92857\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4843 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.92857\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.6826 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.92857\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4145 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.92857\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 7.1561e-04 - accuracy: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.92857\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 0.9982 - val_loss: 0.6276 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.92857\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.6421 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.92857\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.7986 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.92857\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.6411 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.92857\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.5178 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.92857\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.92857\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4494 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.92857\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4095 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.92857\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.9471 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.92857\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0380 - accuracy: 0.9866 - val_loss: 0.6727 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.92857\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0446 - accuracy: 0.9890 - val_loss: 0.9754 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.92857\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.6937 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.92857\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6184 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.92857\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.6081 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.92857\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.6354 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.92857\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.4914 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.92857\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.92857\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.3908 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.92857\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 0.4583 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.92857\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 5.1563e-04 - accuracy: 1.0000 - val_loss: 0.4500 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.92857\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4809 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.92857\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.8279 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.92857\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0176 - accuracy: 0.9933 - val_loss: 1.2438 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.92857\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.6308 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.92857\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.4712 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.92857\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.5929 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.92857\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5253 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.92857\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4920 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.92857\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.6407 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.92857\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0213 - accuracy: 0.9963 - val_loss: 0.6223 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.92857\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.5570 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.92857\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5736 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.92857\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4715 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.92857\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5307 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.92857\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 5.9171e-04 - accuracy: 1.0000 - val_loss: 0.5335 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.92857\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.6594 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.92857\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0438 - accuracy: 0.9872 - val_loss: 0.8081 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.92857\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0210 - accuracy: 0.9921 - val_loss: 0.6537 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.92857\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.7149 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.92857\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.5427 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.92857\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5801 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.92857\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.5812 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.92857\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.5867 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.92857\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5998 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.92857\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.5699 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.92857\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.6553 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.92857\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.4764 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.92857\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.5025 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.92857\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.9173 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.92857\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.6693 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.92857\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.5711 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.92857\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0071 - accuracy: 0.9963 - val_loss: 0.7608 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.92857\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.7481 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.92857\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 0.9178 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.92857\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.5994 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.92857\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 1.1174 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.92857\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.9864 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.92857\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.8549 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.92857\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0313 - accuracy: 0.9933 - val_loss: 1.3087 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.92857\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0371 - accuracy: 0.9903 - val_loss: 0.6740 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.92857\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0194 - accuracy: 0.9957 - val_loss: 0.6803 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.92857\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.6684 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.92857\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.7459 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.92857\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0266 - accuracy: 0.9896 - val_loss: 0.8729 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.92857\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 0.0307 - accuracy: 0.9915 - val_loss: 1.0348 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.92857\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0270 - accuracy: 0.9945 - val_loss: 0.5495 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.92857\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 0.5659 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.92857\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6037 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.92857\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.7077 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.92857\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.6473 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.92857\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0082 - accuracy: 0.9957 - val_loss: 0.5235 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.92857\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.3952 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00493: val_accuracy improved from 0.92857 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.5815 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.93103\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4520 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.93103\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.93103\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 11s 202ms/step - loss: 6.1061e-04 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.93103\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 4.9678e-04 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.93103\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 5.0878e-04 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.93103\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 11s 201ms/step - loss: 4.6663e-04 - accuracy: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.93103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f77e0222e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e1ab6c8c-8230-4e6c-f6b6-3a396eadff37"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(model.history.history[\"accuracy\"], label='accuracy')\n",
        "plt.plot(model.history.history[\"val_accuracy\"], label='valid_accuracy')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5', compile=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dff4a30-4510-4717-cb6e-d8e2d1587795"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/DACON_CVLC/data/images_test/none\n",
        "!mv /content/drive/MyDrive/DACON_CVLC/data/images_test/*.png /content/drive/MyDrive/DACON_CVLC/data/images_test/none"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/DACON_CVLC/data/images_test/none’: Input/output error\n",
            "mv: cannot stat '/content/drive/MyDrive/DACON_CVLC/data/images_test/none/10000.png': Input/output error\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50544e75-3056-4a11-f695-9dac25f19264"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('/content/drive/MyDrive/DACON_CVLC/data/images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxxxMnN3y2Wb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e27504d-fc89-4995-ea4e-c6c5b47a6a0e"
      },
      "source": [
        "test_generator.reset()\n",
        "predict = model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NH-xmmay9Hd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3eacc13c-d5dc-4fbe-f008-df0a199d4714"
      },
      "source": [
        "from google.colab import files\n",
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')\n",
        "submission['digit'] = predict\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/submission.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/submission.csv')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bc373a27-94c0-4a10-a7a7-566df728f703\", \"submission.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3DyXzh1pbDH"
      },
      "source": [
        "import numpy as np\n",
        "sub['digit'] = np.argmax(model.predict(test_generator), axis=1)\n",
        "sub.head()\n",
        "sub.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/CVLC_06_ResNet50.csv', index=False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_KfitazNsE-2",
        "outputId": "04f26c3d-c21c-48f4-baee-017d96bf1808"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_ResNet50.h5')\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/CVLC_06_ResNet50.csv')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b4776cde-d9fc-4f84-af1c-0d2e4e674db9\", \"CVLC_06_ResNet50.h5\", 283826408)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d98764f6-11e0-4e0e-9b20-33c46c8e30be\", \"CVLC_06_ResNet50.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}