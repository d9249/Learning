{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "million-monaco",
   "metadata": {
    "id": "million-monaco",
    "papermill": {
     "duration": 0.026241,
     "end_time": "2021-05-30T18:39:28.019714",
     "exception": false,
     "start_time": "2021-05-30T18:39:27.993473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 처음부터 끝까지 곧바로 실행하시면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddaadda",
   "metadata": {
    "id": "million-monaco",
    "papermill": {
     "duration": 0.026241,
     "end_time": "2021-05-30T18:39:28.019714",
     "exception": false,
     "start_time": "2021-05-30T18:39:27.993473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbbf0c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.10.0\r\n",
      "alembic==1.4.1\r\n",
      "argon2-cffi==20.1.0\r\n",
      "asn1crypto==0.24.0\r\n",
      "astunparse==1.6.3\r\n",
      "async-generator==1.10\r\n",
      "attrs==20.3.0\r\n",
      "backcall==0.2.0\r\n",
      "beautifulsoup4==4.6.0\r\n",
      "bleach==3.3.0\r\n",
      "blis==0.7.4\r\n",
      "Boruta==0.3\r\n",
      "cachetools==4.2.0\r\n",
      "catalogue==1.0.0\r\n",
      "catboost==0.24.4\r\n",
      "certifi==2020.12.5\r\n",
      "cffi==1.14.5\r\n",
      "chardet==4.0.0\r\n",
      "click==7.1.2\r\n",
      "cloudpickle==1.6.0\r\n",
      "colorama==0.4.4\r\n",
      "colorlover==0.3.0\r\n",
      "confuse==1.4.0\r\n",
      "cryptography==2.1.4\r\n",
      "cufflinks==0.17.3\r\n",
      "cycler==0.10.0\r\n",
      "cymem==2.0.5\r\n",
      "databricks-cli==0.14.2\r\n",
      "dataclasses==0.8\r\n",
      "decorator==4.4.2\r\n",
      "defusedxml==0.6.0\r\n",
      "dill==0.3.3\r\n",
      "docker==4.4.4\r\n",
      "entrypoints==0.3\r\n",
      "et-xmlfile==1.0.1\r\n",
      "filelock==3.4.1\r\n",
      "Flask==1.1.2\r\n",
      "flatbuffers==1.12\r\n",
      "funcy==1.15\r\n",
      "future==0.18.2\r\n",
      "gast==0.3.3\r\n",
      "gaussian==0.1\r\n",
      "gdown==4.4.0\r\n",
      "gensim==3.8.3\r\n",
      "gitdb==4.0.5\r\n",
      "GitPython==3.1.13\r\n",
      "google-auth==1.24.0\r\n",
      "google-auth-oauthlib==0.4.2\r\n",
      "google-pasta==0.2.0\r\n",
      "googleapis-common-protos==1.53.0\r\n",
      "graphviz==0.16\r\n",
      "grpcio==1.32.0\r\n",
      "gunicorn==20.0.4\r\n",
      "h5py==2.10.0\r\n",
      "htmlmin==0.1.12\r\n",
      "hyperopt==0.2.5\r\n",
      "idna==2.6\r\n",
      "ImageHash==4.2.0\r\n",
      "imbalanced-learn==0.7.0\r\n",
      "importlib-metadata==3.4.0\r\n",
      "importlib-resources==5.1.0\r\n",
      "ipykernel==5.5.0\r\n",
      "ipython==7.16.1\r\n",
      "ipython-genutils==0.2.0\r\n",
      "ipywidgets==7.6.3\r\n",
      "itsdangerous==1.1.0\r\n",
      "jdcal==1.4.1\r\n",
      "jedi==0.18.0\r\n",
      "Jinja2==2.11.3\r\n",
      "joblib==1.0.1\r\n",
      "JPype1==1.2.1\r\n",
      "jsonschema==3.2.0\r\n",
      "jupyter==1.0.0\r\n",
      "jupyter-client==6.1.11\r\n",
      "jupyter-console==6.2.0\r\n",
      "jupyter-core==4.7.1\r\n",
      "jupyterlab-pygments==0.1.2\r\n",
      "jupyterlab-widgets==1.0.0\r\n",
      "kaggle==1.5.10\r\n",
      "Keras==2.4.3\r\n",
      "Keras-Preprocessing==1.1.2\r\n",
      "keyring==10.6.0\r\n",
      "keyrings.alt==3.0\r\n",
      "kiwisolver==1.3.1\r\n",
      "kmodes==0.11.0\r\n",
      "konlpy==0.5.2\r\n",
      "lab==6.3\r\n",
      "lightgbm==3.1.1\r\n",
      "llvmlite==0.35.0\r\n",
      "lxml==4.6.2\r\n",
      "Mako==1.1.4\r\n",
      "Markdown==3.3.3\r\n",
      "MarkupSafe==1.1.1\r\n",
      "matplotlib==3.3.4\r\n",
      "mecab-python===0.996-ko-0.9.2\r\n",
      "missingno==0.4.2\r\n",
      "mistune==0.8.4\r\n",
      "mlflow==1.14.0\r\n",
      "mlxtend==0.18.0\r\n",
      "murmurhash==1.0.5\r\n",
      "nbclient==0.5.3\r\n",
      "nbconvert==6.0.7\r\n",
      "nbformat==5.1.2\r\n",
      "nest-asyncio==1.5.1\r\n",
      "networkx==2.5\r\n",
      "nltk==3.5\r\n",
      "notebook==6.2.0\r\n",
      "numba==0.52.0\r\n",
      "numexpr==2.7.2\r\n",
      "numpy==1.19.5\r\n",
      "oauthlib==3.1.0\r\n",
      "opencv-python==4.5.5.64\r\n",
      "openpyxl==3.0.6\r\n",
      "opt-einsum==3.3.0\r\n",
      "packaging==20.9\r\n",
      "pandas==1.1.5\r\n",
      "pandas-profiling==2.11.0\r\n",
      "pandocfilters==1.4.3\r\n",
      "parso==0.8.1\r\n",
      "patsy==0.5.1\r\n",
      "pexpect==4.8.0\r\n",
      "phik==0.11.0\r\n",
      "pickle5==0.0.11\r\n",
      "pickleshare==0.7.5\r\n",
      "Pillow==8.1.0\r\n",
      "plac==1.1.3\r\n",
      "plotly==4.14.3\r\n",
      "preshed==3.0.5\r\n",
      "prometheus-client==0.9.0\r\n",
      "prometheus-flask-exporter==0.18.1\r\n",
      "promise==2.3\r\n",
      "prompt-toolkit==3.0.16\r\n",
      "protobuf==3.14.0\r\n",
      "ptyprocess==0.7.0\r\n",
      "py4j==0.10.9\r\n",
      "pyasn1==0.4.8\r\n",
      "pyasn1-modules==0.2.8\r\n",
      "pycaret==2.3.0\r\n",
      "pycparser==2.20\r\n",
      "pycrypto==2.6.1\r\n",
      "Pygments==2.8.0\r\n",
      "pygobject==3.26.1\r\n",
      "pykospacing @ git+https://github.com/haven-jeon/PyKoSpacing.git@1a36be492cc396559e7dce7825843af020ea231f\r\n",
      "pyLDAvis==3.2.2\r\n",
      "pynndescent==0.5.2\r\n",
      "pyod==0.8.7\r\n",
      "pyparsing==2.4.7\r\n",
      "pyrsistent==0.17.3\r\n",
      "PySocks==1.7.1\r\n",
      "pyspark==3.1.1\r\n",
      "python-apt==1.6.5+ubuntu0.5\r\n",
      "python-dateutil==2.8.1\r\n",
      "python-editor==1.0.4\r\n",
      "python-slugify==4.0.1\r\n",
      "pytz==2021.1\r\n",
      "PyWavelets==1.1.1\r\n",
      "pyxdg==0.25\r\n",
      "PyYAML==5.4.1\r\n",
      "pyzmq==22.0.3\r\n",
      "qtconsole==5.0.2\r\n",
      "QtPy==1.9.0\r\n",
      "querystring-parser==1.2.4\r\n",
      "regex==2020.11.13\r\n",
      "requests==2.25.1\r\n",
      "requests-oauthlib==1.3.0\r\n",
      "retrying==1.3.3\r\n",
      "rsa==4.7\r\n",
      "scikit-learn==0.23.2\r\n",
      "scikit-plot==0.3.7\r\n",
      "scikit-surprise==1.1.1\r\n",
      "scipy==1.5.4\r\n",
      "seaborn==0.11.1\r\n",
      "SecretStorage==2.3.1\r\n",
      "Send2Trash==1.5.0\r\n",
      "shap==0.38.1\r\n",
      "simplejson==3.17.2\r\n",
      "six==1.15.0\r\n",
      "slicer==0.0.7\r\n",
      "smart-open==4.2.0\r\n",
      "smmap==3.0.5\r\n",
      "spacy==2.3.5\r\n",
      "SQLAlchemy==1.3.23\r\n",
      "sqlparse==0.4.1\r\n",
      "srsly==1.0.5\r\n",
      "ssh-import-id==5.7\r\n",
      "statsmodels==0.12.2\r\n",
      "surprise==0.1\r\n",
      "tabulate==0.8.9\r\n",
      "tangled-up-in-unicode==0.0.6\r\n",
      "tensorboard==2.4.1\r\n",
      "tensorboard-plugin-wit==1.8.0\r\n",
      "tensorflow==2.4.0\r\n",
      "tensorflow-datasets==4.2.0\r\n",
      "tensorflow-estimator==2.4.0\r\n",
      "tensorflow-examples===c3bf7340c5002d62f4d51da21d7b01a884082472-\r\n",
      "tensorflow-gpu==2.4.1\r\n",
      "tensorflow-metadata==0.28.0\r\n",
      "termcolor==1.1.0\r\n",
      "terminado==0.9.2\r\n",
      "testpath==0.4.4\r\n",
      "text-unidecode==1.3\r\n",
      "textblob==0.15.3\r\n",
      "thinc==7.4.5\r\n",
      "threadpoolctl==2.1.0\r\n",
      "timm==0.5.4\r\n",
      "torch==1.7.1+cu110\r\n",
      "torchaudio==0.7.2\r\n",
      "torchvision==0.8.2+cu110\r\n",
      "tornado==6.1\r\n",
      "tqdm==4.58.0\r\n",
      "traitlets==4.3.3\r\n",
      "tweepy==3.10.0\r\n",
      "txt2tags==3.7\r\n",
      "typing-extensions==3.7.4.3\r\n",
      "ufw==0.36\r\n",
      "umap-learn==0.5.1\r\n",
      "urllib3==1.26.2\r\n",
      "visions==0.6.0\r\n",
      "wasabi==0.8.2\r\n",
      "wcwidth==0.2.5\r\n",
      "webencodings==0.5.1\r\n",
      "websocket-client==0.57.0\r\n",
      "Werkzeug==1.0.1\r\n",
      "widgetsnbextension==3.5.1\r\n",
      "wordcloud==1.8.1\r\n",
      "wrapt==1.12.1\r\n",
      "xgboost==1.3.3\r\n",
      "xlrd==2.0.1\r\n",
      "yellowbrick==1.3.post1\r\n",
      "zipp==3.4.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcba341f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae6cd0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pykospacing@ git+https://github.com/haven-jeon/PyKoSpacing.git@1a36be492cc396559e7dce7825843af020ea231f\r\n",
      "  Cloning https://github.com/haven-jeon/PyKoSpacing.git (to revision 1a36be492cc396559e7dce7825843af020ea231f) to /tmp/pip-install-vr52qn77/pykospacing_b6f8ad74f14e44358783685a3f8afe6e\r\n",
      "  Running command git clone -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-install-vr52qn77/pykospacing_b6f8ad74f14e44358783685a3f8afe6e\r\n",
      "  Running command git rev-parse -q --verify 'sha^1a36be492cc396559e7dce7825843af020ea231f'\r\n",
      "  Running command git fetch -q https://github.com/haven-jeon/PyKoSpacing.git 1a36be492cc396559e7dce7825843af020ea231f\r\n",
      "  Running command git checkout -q 1a36be492cc396559e7dce7825843af020ea231f\r\n",
      "Requirement already satisfied: absl-py==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.10.0)\r\n",
      "Requirement already satisfied: alembic==1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.4.1)\r\n",
      "Requirement already satisfied: argon2-cffi==20.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (20.1.0)\r\n",
      "Requirement already satisfied: asn1crypto==0.24.0 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 4)) (0.24.0)\r\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.6.3)\r\n",
      "Requirement already satisfied: async-generator==1.10 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (1.10)\r\n",
      "Requirement already satisfied: attrs==20.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (20.3.0)\r\n",
      "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.2.0)\r\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (4.6.0)\r\n",
      "Requirement already satisfied: bleach==3.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (3.3.0)\r\n",
      "Requirement already satisfied: blis==0.7.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.7.4)\r\n",
      "Requirement already satisfied: Boruta==0.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (0.3)\r\n",
      "Requirement already satisfied: cachetools==4.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (4.2.0)\r\n",
      "Requirement already satisfied: catalogue==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 14)) (1.0.0)\r\n",
      "Requirement already satisfied: catboost==0.24.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (0.24.4)\r\n",
      "Requirement already satisfied: certifi==2020.12.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 16)) (2020.12.5)\r\n",
      "Requirement already satisfied: cffi==1.14.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 17)) (1.14.5)\r\n",
      "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 18)) (4.0.0)\r\n",
      "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 19)) (7.1.2)\r\n",
      "Requirement already satisfied: cloudpickle==1.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (1.6.0)\r\n",
      "Requirement already satisfied: colorama==0.4.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 21)) (0.4.4)\r\n",
      "Requirement already satisfied: colorlover==0.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 22)) (0.3.0)\r\n",
      "Requirement already satisfied: confuse==1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 23)) (1.4.0)\r\n",
      "Requirement already satisfied: cryptography==2.1.4 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 24)) (2.1.4)\r\n",
      "Requirement already satisfied: cufflinks==0.17.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 25)) (0.17.3)\r\n",
      "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 26)) (0.10.0)\r\n",
      "Requirement already satisfied: cymem==2.0.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 27)) (2.0.5)\r\n",
      "Requirement already satisfied: databricks-cli==0.14.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 28)) (0.14.2)\r\n",
      "Requirement already satisfied: dataclasses==0.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 29)) (0.8)\r\n",
      "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 30)) (4.4.2)\r\n",
      "Requirement already satisfied: defusedxml==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 31)) (0.6.0)\r\n",
      "Requirement already satisfied: dill==0.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 32)) (0.3.3)\r\n",
      "Requirement already satisfied: docker==4.4.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 33)) (4.4.4)\r\n",
      "Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 34)) (0.3)\r\n",
      "Requirement already satisfied: et-xmlfile==1.0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 35)) (1.0.1)\r\n",
      "Requirement already satisfied: filelock==3.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 36)) (3.4.1)\r\n",
      "Requirement already satisfied: Flask==1.1.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 37)) (1.1.2)\r\n",
      "Requirement already satisfied: flatbuffers==1.12 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 38)) (1.12)\r\n",
      "Requirement already satisfied: funcy==1.15 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 39)) (1.15)\r\n",
      "Requirement already satisfied: future==0.18.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 40)) (0.18.2)\r\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 41)) (0.3.3)\r\n",
      "Requirement already satisfied: gaussian==0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 42)) (0.1)\r\n",
      "Requirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 43)) (4.4.0)\r\n",
      "Requirement already satisfied: gensim==3.8.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 44)) (3.8.3)\r\n",
      "Requirement already satisfied: gitdb==4.0.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 45)) (4.0.5)\r\n",
      "Requirement already satisfied: GitPython==3.1.13 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 46)) (3.1.13)\r\n",
      "Requirement already satisfied: google-auth==1.24.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 47)) (1.24.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib==0.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 48)) (0.4.2)\r\n",
      "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 49)) (0.2.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos==1.53.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 50)) (1.53.0)\r\n",
      "Requirement already satisfied: graphviz==0.16 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 51)) (0.16)\r\n",
      "Requirement already satisfied: grpcio==1.32.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 52)) (1.32.0)\r\n",
      "Requirement already satisfied: gunicorn==20.0.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 53)) (20.0.4)\r\n",
      "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 54)) (2.10.0)\r\n",
      "Requirement already satisfied: htmlmin==0.1.12 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 55)) (0.1.12)\r\n",
      "Requirement already satisfied: hyperopt==0.2.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 56)) (0.2.5)\r\n",
      "Requirement already satisfied: idna==2.6 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 57)) (2.6)\r\n",
      "Requirement already satisfied: ImageHash==4.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 58)) (4.2.0)\r\n",
      "Requirement already satisfied: imbalanced-learn==0.7.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 59)) (0.7.0)\r\n",
      "Requirement already satisfied: importlib-metadata==3.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 60)) (3.4.0)\r\n",
      "Requirement already satisfied: importlib-resources==5.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 61)) (5.1.0)\r\n",
      "Requirement already satisfied: ipykernel==5.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 62)) (5.5.0)\r\n",
      "Requirement already satisfied: ipython==7.16.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 63)) (7.16.1)\r\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 64)) (0.2.0)\r\n",
      "Requirement already satisfied: ipywidgets==7.6.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 65)) (7.6.3)\r\n",
      "Requirement already satisfied: itsdangerous==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 66)) (1.1.0)\r\n",
      "Requirement already satisfied: jdcal==1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 67)) (1.4.1)\r\n",
      "Requirement already satisfied: jedi==0.18.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 68)) (0.18.0)\r\n",
      "Requirement already satisfied: Jinja2==2.11.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 69)) (2.11.3)\r\n",
      "Requirement already satisfied: joblib==1.0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 70)) (1.0.1)\r\n",
      "Requirement already satisfied: JPype1==1.2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 71)) (1.2.1)\r\n",
      "Requirement already satisfied: jsonschema==3.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 72)) (3.2.0)\r\n",
      "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 73)) (1.0.0)\r\n",
      "Requirement already satisfied: jupyter-client==6.1.11 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 74)) (6.1.11)\r\n",
      "Requirement already satisfied: jupyter-console==6.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 75)) (6.2.0)\r\n",
      "Requirement already satisfied: jupyter-core==4.7.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 76)) (4.7.1)\r\n",
      "Requirement already satisfied: jupyterlab-pygments==0.1.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 77)) (0.1.2)\r\n",
      "Requirement already satisfied: jupyterlab-widgets==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 78)) (1.0.0)\r\n",
      "Requirement already satisfied: kaggle==1.5.10 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 79)) (1.5.10)\r\n",
      "Requirement already satisfied: Keras==2.4.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 80)) (2.4.3)\r\n",
      "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 81)) (1.1.2)\r\n",
      "Requirement already satisfied: keyring==10.6.0 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 82)) (10.6.0)\r\n",
      "Requirement already satisfied: keyrings.alt==3.0 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 83)) (3.0)\r\n",
      "Requirement already satisfied: kiwisolver==1.3.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 84)) (1.3.1)\r\n",
      "Requirement already satisfied: kmodes==0.11.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 85)) (0.11.0)\r\n",
      "Requirement already satisfied: konlpy==0.5.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 86)) (0.5.2)\r\n",
      "Requirement already satisfied: lab==6.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 87)) (6.3)\r\n",
      "Requirement already satisfied: lightgbm==3.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 88)) (3.1.1)\r\n",
      "Requirement already satisfied: llvmlite==0.35.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 89)) (0.35.0)\r\n",
      "Requirement already satisfied: lxml==4.6.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 90)) (4.6.2)\r\n",
      "Requirement already satisfied: Mako==1.1.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 91)) (1.1.4)\r\n",
      "Requirement already satisfied: Markdown==3.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 92)) (3.3.3)\r\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 93)) (1.1.1)\r\n",
      "Requirement already satisfied: matplotlib==3.3.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 94)) (3.3.4)\r\n",
      "Requirement already satisfied: mecab-python===0.996-ko-0.9.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 95)) (0.996-ko-0.9.2)\r\n",
      "Requirement already satisfied: missingno==0.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 96)) (0.4.2)\r\n",
      "Requirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 97)) (0.8.4)\r\n",
      "Requirement already satisfied: mlflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 98)) (1.14.0)\r\n",
      "Requirement already satisfied: mlxtend==0.18.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 99)) (0.18.0)\r\n",
      "Requirement already satisfied: murmurhash==1.0.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 100)) (1.0.5)\r\n",
      "Requirement already satisfied: nbclient==0.5.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 101)) (0.5.3)\r\n",
      "Requirement already satisfied: nbconvert==6.0.7 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 102)) (6.0.7)\r\n",
      "Requirement already satisfied: nbformat==5.1.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 103)) (5.1.2)\r\n",
      "Requirement already satisfied: nest-asyncio==1.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 104)) (1.5.1)\r\n",
      "Requirement already satisfied: networkx==2.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 105)) (2.5)\r\n",
      "Requirement already satisfied: nltk==3.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 106)) (3.5)\r\n",
      "Requirement already satisfied: notebook==6.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 107)) (6.2.0)\r\n",
      "Requirement already satisfied: numba==0.52.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 108)) (0.52.0)\r\n",
      "Requirement already satisfied: numexpr==2.7.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 109)) (2.7.2)\r\n",
      "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 110)) (1.19.5)\r\n",
      "Requirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 111)) (3.1.0)\r\n",
      "Requirement already satisfied: opencv-python==4.5.5.64 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 112)) (4.5.5.64)\r\n",
      "Requirement already satisfied: openpyxl==3.0.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 113)) (3.0.6)\r\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 114)) (3.3.0)\r\n",
      "Requirement already satisfied: packaging==20.9 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 115)) (20.9)\r\n",
      "Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 116)) (1.1.5)\r\n",
      "Requirement already satisfied: pandas-profiling==2.11.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 117)) (2.11.0)\r\n",
      "Requirement already satisfied: pandocfilters==1.4.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 118)) (1.4.3)\r\n",
      "Requirement already satisfied: parso==0.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 119)) (0.8.1)\r\n",
      "Requirement already satisfied: patsy==0.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 120)) (0.5.1)\r\n",
      "Requirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 121)) (4.8.0)\r\n",
      "Requirement already satisfied: phik==0.11.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 122)) (0.11.0)\r\n",
      "Requirement already satisfied: pickle5==0.0.11 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 123)) (0.0.11)\r\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 124)) (0.7.5)\r\n",
      "Requirement already satisfied: Pillow==8.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 125)) (8.1.0)\r\n",
      "Requirement already satisfied: plac==1.1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 126)) (1.1.3)\r\n",
      "Requirement already satisfied: plotly==4.14.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 127)) (4.14.3)\r\n",
      "Requirement already satisfied: preshed==3.0.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 128)) (3.0.5)\r\n",
      "Requirement already satisfied: prometheus-client==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 129)) (0.9.0)\r\n",
      "Requirement already satisfied: prometheus-flask-exporter==0.18.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 130)) (0.18.1)\r\n",
      "Requirement already satisfied: promise==2.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 131)) (2.3)\r\n",
      "Requirement already satisfied: prompt-toolkit==3.0.16 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 132)) (3.0.16)\r\n",
      "Requirement already satisfied: protobuf==3.14.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 133)) (3.14.0)\r\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 134)) (0.7.0)\r\n",
      "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 135)) (0.10.9)\r\n",
      "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 136)) (0.4.8)\r\n",
      "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 137)) (0.2.8)\r\n",
      "Requirement already satisfied: pycaret==2.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 138)) (2.3.0)\r\n",
      "Requirement already satisfied: pycparser==2.20 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 139)) (2.20)\r\n",
      "Requirement already satisfied: pycrypto==2.6.1 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 140)) (2.6.1)\r\n",
      "Requirement already satisfied: Pygments==2.8.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 141)) (2.8.0)\r\n",
      "Requirement already satisfied: pygobject==3.26.1 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 142)) (3.26.1)\r\n",
      "Requirement already satisfied: pyLDAvis==3.2.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 144)) (3.2.2)\r\n",
      "Requirement already satisfied: pynndescent==0.5.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 145)) (0.5.2)\r\n",
      "Requirement already satisfied: pyod==0.8.7 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 146)) (0.8.7)\r\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 147)) (2.4.7)\r\n",
      "Requirement already satisfied: pyrsistent==0.17.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 148)) (0.17.3)\r\n",
      "Requirement already satisfied: PySocks==1.7.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 149)) (1.7.1)\r\n",
      "Requirement already satisfied: pyspark==3.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 150)) (3.1.1)\r\n",
      "Requirement already satisfied: python-apt==1.6.5+ubuntu0.5 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 151)) (1.6.5+ubuntu0.5)\r\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 152)) (2.8.1)\r\n",
      "Requirement already satisfied: python-editor==1.0.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 153)) (1.0.4)\r\n",
      "Requirement already satisfied: python-slugify==4.0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 154)) (4.0.1)\r\n",
      "Requirement already satisfied: pytz==2021.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 155)) (2021.1)\r\n",
      "Requirement already satisfied: PyWavelets==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 156)) (1.1.1)\r\n",
      "Requirement already satisfied: pyxdg==0.25 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 157)) (0.25)\r\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 158)) (5.4.1)\r\n",
      "Requirement already satisfied: pyzmq==22.0.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 159)) (22.0.3)\r\n",
      "Requirement already satisfied: qtconsole==5.0.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 160)) (5.0.2)\r\n",
      "Requirement already satisfied: QtPy==1.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 161)) (1.9.0)\r\n",
      "Requirement already satisfied: querystring-parser==1.2.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 162)) (1.2.4)\r\n",
      "Requirement already satisfied: regex==2020.11.13 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 163)) (2020.11.13)\r\n",
      "Requirement already satisfied: requests==2.25.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 164)) (2.25.1)\r\n",
      "Requirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 165)) (1.3.0)\r\n",
      "Requirement already satisfied: retrying==1.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 166)) (1.3.3)\r\n",
      "Requirement already satisfied: rsa==4.7 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 167)) (4.7)\r\n",
      "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 168)) (0.23.2)\r\n",
      "Requirement already satisfied: scikit-plot==0.3.7 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 169)) (0.3.7)\r\n",
      "Requirement already satisfied: scikit-surprise==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 170)) (1.1.1)\r\n",
      "Requirement already satisfied: scipy==1.5.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 171)) (1.5.4)\r\n",
      "Requirement already satisfied: seaborn==0.11.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 172)) (0.11.1)\r\n",
      "Requirement already satisfied: SecretStorage==2.3.1 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 173)) (2.3.1)\r\n",
      "Requirement already satisfied: Send2Trash==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 174)) (1.5.0)\r\n",
      "Requirement already satisfied: shap==0.38.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 175)) (0.38.1)\r\n",
      "Requirement already satisfied: simplejson==3.17.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 176)) (3.17.2)\r\n",
      "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 177)) (1.15.0)\r\n",
      "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 178)) (0.0.7)\r\n",
      "Requirement already satisfied: smart-open==4.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 179)) (4.2.0)\r\n",
      "Requirement already satisfied: smmap==3.0.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 180)) (3.0.5)\r\n",
      "Requirement already satisfied: spacy==2.3.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 181)) (2.3.5)\r\n",
      "Requirement already satisfied: SQLAlchemy==1.3.23 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 182)) (1.3.23)\r\n",
      "Requirement already satisfied: sqlparse==0.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 183)) (0.4.1)\r\n",
      "Requirement already satisfied: srsly==1.0.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 184)) (1.0.5)\r\n",
      "Requirement already satisfied: ssh-import-id==5.7 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 185)) (5.7)\r\n",
      "Requirement already satisfied: statsmodels==0.12.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 186)) (0.12.2)\r\n",
      "Requirement already satisfied: surprise==0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 187)) (0.1)\r\n",
      "Requirement already satisfied: tabulate==0.8.9 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 188)) (0.8.9)\r\n",
      "Requirement already satisfied: tangled-up-in-unicode==0.0.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 189)) (0.0.6)\r\n",
      "Requirement already satisfied: tensorboard==2.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 190)) (2.4.1)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit==1.8.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 191)) (1.8.0)\r\n",
      "Requirement already satisfied: tensorflow==2.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 192)) (2.4.0)\r\n",
      "Requirement already satisfied: tensorflow-datasets==4.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 193)) (4.2.0)\r\n",
      "Requirement already satisfied: tensorflow-estimator==2.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 194)) (2.4.0)\r\n",
      "Requirement already satisfied: tensorflow-examples===c3bf7340c5002d62f4d51da21d7b01a884082472- in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 195)) (c3bf7340c5002d62f4d51da21d7b01a884082472-)\r\n",
      "Requirement already satisfied: tensorflow-gpu==2.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 196)) (2.4.1)\r\n",
      "Requirement already satisfied: tensorflow-metadata==0.28.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 197)) (0.28.0)\r\n",
      "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 198)) (1.1.0)\r\n",
      "Requirement already satisfied: terminado==0.9.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 199)) (0.9.2)\r\n",
      "Requirement already satisfied: testpath==0.4.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 200)) (0.4.4)\r\n",
      "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 201)) (1.3)\r\n",
      "Requirement already satisfied: textblob==0.15.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 202)) (0.15.3)\r\n",
      "Requirement already satisfied: thinc==7.4.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 203)) (7.4.5)\r\n",
      "Requirement already satisfied: threadpoolctl==2.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 204)) (2.1.0)\r\n",
      "Requirement already satisfied: timm==0.5.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 205)) (0.5.4)\r\n",
      "Requirement already satisfied: torch==1.7.1+cu110 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 206)) (1.7.1+cu110)\r\n",
      "Requirement already satisfied: torchaudio==0.7.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 207)) (0.7.2)\r\n",
      "Requirement already satisfied: torchvision==0.8.2+cu110 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 208)) (0.8.2+cu110)\r\n",
      "Requirement already satisfied: tornado==6.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 209)) (6.1)\r\n",
      "Requirement already satisfied: tqdm==4.58.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 210)) (4.58.0)\r\n",
      "Requirement already satisfied: traitlets==4.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 211)) (4.3.3)\r\n",
      "Requirement already satisfied: tweepy==3.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 212)) (3.10.0)\r\n",
      "Requirement already satisfied: txt2tags==3.7 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 213)) (3.7)\r\n",
      "Requirement already satisfied: typing-extensions==3.7.4.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 214)) (3.7.4.3)\r\n",
      "Requirement already satisfied: ufw==0.36 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 215)) (0.36)\r\n",
      "Requirement already satisfied: umap-learn==0.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 216)) (0.5.1)\r\n",
      "Requirement already satisfied: urllib3==1.26.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 217)) (1.26.2)\r\n",
      "Requirement already satisfied: visions==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 218)) (0.6.0)\r\n",
      "Requirement already satisfied: wasabi==0.8.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 219)) (0.8.2)\r\n",
      "Requirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 220)) (0.2.5)\r\n",
      "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 221)) (0.5.1)\r\n",
      "Requirement already satisfied: websocket-client==0.57.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 222)) (0.57.0)\r\n",
      "Requirement already satisfied: Werkzeug==1.0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 223)) (1.0.1)\r\n",
      "Requirement already satisfied: widgetsnbextension==3.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 224)) (3.5.1)\r\n",
      "Requirement already satisfied: wordcloud==1.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 225)) (1.8.1)\r\n",
      "Requirement already satisfied: wrapt==1.12.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 226)) (1.12.1)\r\n",
      "Requirement already satisfied: xgboost==1.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 227)) (1.3.3)\r\n",
      "Requirement already satisfied: xlrd==2.0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 228)) (2.0.1)\r\n",
      "Requirement already satisfied: yellowbrick==1.3.post1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 229)) (1.3.post1)\r\n",
      "Requirement already satisfied: zipp==3.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 230)) (3.4.0)\r\n",
      "Collecting argparse>=1.4.0\r\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from astunparse==1.6.3->-r requirements.txt (line 5)) (0.36.2)\r\n",
      "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks==0.17.3->-r requirements.txt (line 25)) (51.3.3)\r\n",
      "Installing collected packages: argparse\r\n",
      "Successfully installed argparse-1.4.0\r\n",
      "\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ts26D3gLnyLd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ts26D3gLnyLd",
    "outputId": "cb1a0caa-c636-4e9b-ed3d-5ca4a9a576c2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr  9 19:15:25 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\r\n",
      "| N/A   39C    P0    41W / 300W |      0MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22446e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5220111676656271200\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 31592913408\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1284816759157068178\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:06.0, compute capability: 7.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "floating-cincinnati",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:28.086573Z",
     "iopub.status.busy": "2021-05-30T18:39:28.085923Z",
     "iopub.status.idle": "2021-05-30T18:39:32.847126Z",
     "shell.execute_reply": "2021-05-30T18:39:32.846068Z",
     "shell.execute_reply.started": "2021-05-30T09:28:36.967323Z"
    },
    "id": "floating-cincinnati",
    "papermill": {
     "duration": 4.80129,
     "end_time": "2021-05-30T18:39:32.847355",
     "exception": false,
     "start_time": "2021-05-30T18:39:28.046065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aff51ab",
   "metadata": {
    "id": "million-monaco",
    "papermill": {
     "duration": 0.026241,
     "end_time": "2021-05-30T18:39:28.019714",
     "exception": false,
     "start_time": "2021-05-30T18:39:27.993473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 데이터 세트 다운로드, 압축 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf77f93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (4.4.0)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.15.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from gdown) (4.6.0)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.58.0)\r\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.6/dist-packages (from gdown) (2.25.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from gdown) (3.4.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (1.26.2)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (4.0.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (2020.12.5)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2.6)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (1.7.1)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "/usr/local/lib/python3.6/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\r\n",
      "  category=FutureWarning,\r\n",
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=1TOHms3kqGonSayOTse0MXiOc4zGSdtsI\r\n",
      "To: /home/ClsKLData.zip\r\n",
      "100%|████████████████████████████████████████| 591M/591M [00:07<00:00, 81.3MB/s]\r\n",
      "/usr/local/lib/python3.6/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\r\n",
      "  category=FutureWarning,\r\n",
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=1lR_B5LSrtUg273ADJQswDHxpjzDfFxIR\r\n",
      "To: /home/KneeXray.zip\r\n",
      "100%|████████████████████████████████████████| 120M/120M [00:11<00:00, 10.8MB/s]\r\n",
      "/usr/local/lib/python3.6/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\r\n",
      "  category=FutureWarning,\r\n",
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=1pI08Cs48tp9NXhuRMt7tssITx4-_PqH1\r\n",
      "To: /home/Lee_KneeData.zip\r\n",
      "100%|██████████████████████████████████████| 3.68M/3.68M [00:00<00:00, 12.8MB/s]\r\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "\n",
    "# train 데이터 세트_ClsKLData\n",
    "!gdown --id \"1TOHms3kqGonSayOTse0MXiOc4zGSdtsI\"\n",
    "\n",
    "# validation & test 데이터 세트_KneeXray\n",
    "!gdown --id \"1lR_B5LSrtUg273ADJQswDHxpjzDfFxIR\"\n",
    "\n",
    "# 추가 test 데이터 세트_Lee_kneeData\n",
    "!gdown --id \"1pI08Cs48tp9NXhuRMt7tssITx4-_PqH1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "763af922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "         \n",
    "fantasy_zip = zipfile.ZipFile('./ClsKLData.zip')\n",
    "fantasy_zip.extractall('./ClsKLData')\n",
    "fantasy_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d94a16bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "fantasy_zip = zipfile.ZipFile('./KneeXray.zip')\n",
    "fantasy_zip.extractall('./KneeXray') \n",
    "fantasy_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8202f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "fantasy_zip = zipfile.ZipFile('./Lee_KneeData.zip')\n",
    "fantasy_zip.extractall('./Lee_KneeData')\n",
    "fantasy_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "encouraging-novel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:36.090553Z",
     "iopub.status.busy": "2021-05-30T18:39:36.089729Z",
     "iopub.status.idle": "2021-05-30T18:39:36.092340Z",
     "shell.execute_reply": "2021-05-30T18:39:36.091828Z",
     "shell.execute_reply.started": "2021-05-30T09:28:44.189248Z"
    },
    "id": "encouraging-novel",
    "papermill": {
     "duration": 0.035021,
     "end_time": "2021-05-30T18:39:36.092447",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.057426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_aug = ImageDataGenerator(rescale=1./255)\n",
    "valid_aug = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1793e",
   "metadata": {
    "id": "million-monaco",
    "papermill": {
     "duration": 0.026241,
     "end_time": "2021-05-30T18:39:28.019714",
     "exception": false,
     "start_time": "2021-05-30T18:39:27.993473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 학습 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "emotional-valuable",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:33.012157Z",
     "iopub.status.busy": "2021-05-30T18:39:33.011596Z",
     "iopub.status.idle": "2021-05-30T18:39:35.556063Z",
     "shell.execute_reply": "2021-05-30T18:39:35.555555Z",
     "shell.execute_reply.started": "2021-05-30T09:28:38.947982Z"
    },
    "id": "emotional-valuable",
    "papermill": {
     "duration": 2.57776,
     "end_time": "2021-05-30T18:39:35.556225",
     "exception": false,
     "start_time": "2021-05-30T18:39:32.978465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_class = 5\n",
    "\n",
    "root_path = \"./ClsKLData//kneeKL224//\"\n",
    "\n",
    "folder_list = os.listdir(root_path)\n",
    "image_path_list = []\n",
    "label_list = []\n",
    "\n",
    "for folder in folder_list:\n",
    "    for label in range(n_class):\n",
    "        image_list = os.listdir(f\"{root_path}{folder}/{label}\")\n",
    "        image_path_list += [ f\"{root_path}{folder}/{label}/\"+ path for path in image_list]\n",
    "        label_list += [label] * len(image_list)\n",
    "\n",
    "df_train_kaggle = pd.DataFrame({\"filepath\" : image_path_list, \"label\": label_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "signal-responsibility",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:35.618734Z",
     "iopub.status.busy": "2021-05-30T18:39:35.617931Z",
     "iopub.status.idle": "2021-05-30T18:39:35.621117Z",
     "shell.execute_reply": "2021-05-30T18:39:35.621576Z",
     "shell.execute_reply.started": "2021-05-30T09:28:40.244589Z"
    },
    "id": "signal-responsibility",
    "outputId": "dfd8ae1d-71d1-424c-e0af-c2e831cd3514",
    "papermill": {
     "duration": 0.03629,
     "end_time": "2021-05-30T18:39:35.621716",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.585426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(9786, 2)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_kaggle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-greene",
   "metadata": {
    "id": "hairy-greene",
    "papermill": {
     "duration": 0.030406,
     "end_time": "2021-05-30T18:39:35.680660",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.650254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 학습 데이터 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "therapeutic-spending",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:35.750000Z",
     "iopub.status.busy": "2021-05-30T18:39:35.749277Z",
     "iopub.status.idle": "2021-05-30T18:39:35.918362Z",
     "shell.execute_reply": "2021-05-30T18:39:35.918766Z",
     "shell.execute_reply.started": "2021-05-30T09:28:41.597346Z"
    },
    "id": "therapeutic-spending",
    "outputId": "9f2e2be5-47ca-48db-9250-e83add5b2f95",
    "papermill": {
     "duration": 0.208649,
     "end_time": "2021-05-30T18:39:35.918905",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.710256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'count')"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_kaggle.label.value_counts().plot.bar()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "geological-philadelphia",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:36.172890Z",
     "iopub.status.busy": "2021-05-30T18:39:36.167698Z",
     "iopub.status.idle": "2021-05-30T18:39:39.954054Z",
     "shell.execute_reply": "2021-05-30T18:39:39.954888Z",
     "shell.execute_reply.started": "2021-05-30T09:28:47.478488Z"
    },
    "id": "geological-philadelphia",
    "outputId": "5a67acba-6da1-4b7b-c63c-db74aa3f3ab5",
    "papermill": {
     "duration": 3.835127,
     "end_time": "2021-05-30T18:39:39.955083",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.119956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9786 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_aug.flow_from_dataframe(\n",
    "    dataframe = df_train_kaggle,\n",
    "    directory = None,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    batch_size = 8,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-chest",
   "metadata": {
    "id": "asian-chest",
    "papermill": {
     "duration": 0.027295,
     "end_time": "2021-05-30T18:39:40.011354",
     "exception": false,
     "start_time": "2021-05-30T18:39:39.984059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 검증, 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "threaded-characterization",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.229132Z",
     "iopub.status.busy": "2021-05-30T18:40:02.228400Z",
     "iopub.status.idle": "2021-05-30T18:40:02.250117Z",
     "shell.execute_reply": "2021-05-30T18:40:02.250642Z",
     "shell.execute_reply.started": "2021-05-30T08:33:23.833280Z"
    },
    "id": "threaded-characterization",
    "outputId": "f6fc6702-0a3d-4689-ce71-a698cbea485e",
    "papermill": {
     "duration": 0.059732,
     "end_time": "2021-05-30T18:40:02.250775",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.191043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                  filename  label\n0  ./KneeXray//KneeXray//train/Image_1.jpg      0\n1  ./KneeXray//KneeXray//train/Image_2.jpg      1\n2  ./KneeXray//KneeXray//train/Image_3.jpg      0\n3  ./KneeXray//KneeXray//train/Image_4.jpg      1\n4  ./KneeXray//KneeXray//train/Image_5.jpg      2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>./KneeXray//KneeXray//train/Image_1.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>./KneeXray//KneeXray//train/Image_2.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>./KneeXray//KneeXray//train/Image_3.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>./KneeXray//KneeXray//train/Image_4.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>./KneeXray//KneeXray//train/Image_5.jpg</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compi_root_path= \"./KneeXray//KneeXray//\"\n",
    "df_val_compi = pd.read_csv(compi_root_path + \"Train.csv\")\n",
    "df_val_compi[\"filename\"] = df_val_compi.filename.apply(lambda x: compi_root_path+\"train/\" + x)\n",
    "df_val_compi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c720bcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(7828, 2)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_compi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2810ec",
   "metadata": {
    "id": "hairy-greene",
    "papermill": {
     "duration": 0.030406,
     "end_time": "2021-05-30T18:39:35.680660",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.650254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 검증 데이터 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "suburban-shareware",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.339459Z",
     "iopub.status.busy": "2021-05-30T18:40:02.324109Z",
     "iopub.status.idle": "2021-05-30T18:40:02.442504Z",
     "shell.execute_reply": "2021-05-30T18:40:02.442056Z",
     "shell.execute_reply.started": "2021-05-30T08:33:23.865039Z"
    },
    "id": "suburban-shareware",
    "outputId": "0daca1fb-c665-4a25-8da7-9250f7756ff1",
    "papermill": {
     "duration": 0.158988,
     "end_time": "2021-05-30T18:40:02.442618",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.283630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'count')"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val_compi.label.value_counts().plot.bar()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "saving-homework",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.529039Z",
     "iopub.status.busy": "2021-05-30T18:40:02.528305Z",
     "iopub.status.idle": "2021-05-30T18:40:02.574290Z",
     "shell.execute_reply": "2021-05-30T18:40:02.574903Z",
     "shell.execute_reply.started": "2021-05-30T08:54:21.600981Z"
    },
    "id": "saving-homework",
    "outputId": "21b896d0-bceb-4621-efb3-33908214d2d6",
    "papermill": {
     "duration": 0.098388,
     "end_time": "2021-05-30T18:40:02.575081",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.476693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7828 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = valid_aug.flow_from_dataframe( \n",
    "    dataframe= df_val_compi,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 8,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-belarus",
   "metadata": {
    "id": "marked-belarus",
    "papermill": {
     "duration": 0.033792,
     "end_time": "2021-05-30T18:40:02.643887",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.610095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 모델 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "buried-tablet",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.724467Z",
     "iopub.status.busy": "2021-05-30T18:40:02.723830Z",
     "iopub.status.idle": "2021-05-30T18:40:08.132744Z",
     "shell.execute_reply": "2021-05-30T18:40:08.131632Z",
     "shell.execute_reply.started": "2021-05-30T09:28:56.068101Z"
    },
    "id": "buried-tablet",
    "outputId": "da82c4ac-8660-4b77-94f7-5e1342b4b10e",
    "papermill": {
     "duration": 5.455093,
     "end_time": "2021-05-30T18:40:08.132878",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.677785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "# xception = MobileNet(weights=\"imagenet\")\n",
    "# x =  xception.layers[-3].output\n",
    "# #\n",
    "# x = tf.keras.layers.Conv2D(filters = n_class, kernel_size = 3, padding = \"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "# #\n",
    "# GAP = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# pred = tf.keras.activations.softmax(GAP)\n",
    "\n",
    "xception_model = DenseNet121(weights=None, classes=5)\n",
    "\n",
    "    # Model(inputs=xception.input,outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb92055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet121\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 5)            5125        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,042,629\n",
      "Trainable params: 6,958,981\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "norman-detector",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:08.391663Z",
     "iopub.status.busy": "2021-05-30T18:40:08.385701Z",
     "iopub.status.idle": "2021-05-30T18:40:08.398432Z",
     "shell.execute_reply": "2021-05-30T18:40:08.397997Z",
     "shell.execute_reply.started": "2021-05-30T09:28:58.465217Z"
    },
    "id": "norman-detector",
    "papermill": {
     "duration": 0.226948,
     "end_time": "2021-05-30T18:40:08.398547",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.171599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xception_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001,decay=0.0001),\n",
    "                 metrics=[\"acc\"],\n",
    "                 loss= tf.keras.losses.sparse_categorical_crossentropy)\n",
    "\n",
    "checkpoint_path = \"xception_best.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "my_callbacks = [\n",
    "               ModelCheckpoint(\n",
    "                   checkpoint_path,\n",
    "                   monitor = 'val_acc',\n",
    "                   verbose = 1,\n",
    "                   save_weights_only=True,\n",
    "                   save_best_only = True,\n",
    "                   mode=\"max\"\n",
    "               ),\n",
    "               EarlyStopping(\n",
    "                   monitor='val_loss', \n",
    "                   patience=10,\n",
    "                   verbose=0\n",
    "               ),\n",
    "               ReduceLROnPlateau(\n",
    "                   monitor='val_loss', \n",
    "                   patience=10,\n",
    "                   verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-administration",
   "metadata": {
    "id": "crucial-administration",
    "papermill": {
     "duration": 0.038495,
     "end_time": "2021-05-30T18:40:08.475329",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.436834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 가중치 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "regional-indie",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:08.558435Z",
     "iopub.status.busy": "2021-05-30T18:40:08.557616Z",
     "iopub.status.idle": "2021-05-30T18:40:09.060821Z",
     "shell.execute_reply": "2021-05-30T18:40:09.060357Z",
     "shell.execute_reply.started": "2021-05-30T09:30:11.007618Z"
    },
    "id": "regional-indie",
    "papermill": {
     "duration": 0.546357,
     "end_time": "2021-05-30T18:40:09.060960",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.514603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes= np.unique(df_train_kaggle.label.values),\n",
    "    y= df_train_kaggle.label.values\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-better",
   "metadata": {
    "id": "square-better",
    "papermill": {
     "duration": 0.037503,
     "end_time": "2021-05-30T18:40:09.136492",
     "exception": false,
     "start_time": "2021-05-30T18:40:09.098989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "hidden-stephen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:09.218272Z",
     "iopub.status.busy": "2021-05-30T18:40:09.217728Z",
     "iopub.status.idle": "2021-05-30T20:12:12.156502Z",
     "shell.execute_reply": "2021-05-30T20:12:12.154537Z",
     "shell.execute_reply.started": "2021-05-26T18:49:57.904339Z"
    },
    "id": "hidden-stephen",
    "outputId": "e45b2b3b-c166-43eb-962b-f6c613220558",
    "papermill": {
     "duration": 5522.981999,
     "end_time": "2021-05-30T20:12:12.156678",
     "exception": false,
     "start_time": "2021-05-30T18:40:09.174679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "979/979 [==============================] - 99s 84ms/step - loss: 1.6602 - acc: 0.2424 - val_loss: 1.5397 - val_acc: 0.2750\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.27498, saving model to xception_best.ckpt\n",
      "Epoch 2/300\n",
      "979/979 [==============================] - 80s 81ms/step - loss: 1.5751 - acc: 0.2572 - val_loss: 1.6358 - val_acc: 0.1966\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.27498\n",
      "Epoch 3/300\n",
      "979/979 [==============================] - 80s 81ms/step - loss: 1.5215 - acc: 0.2769 - val_loss: 1.6690 - val_acc: 0.2441\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.27498\n",
      "Epoch 4/300\n",
      "979/979 [==============================] - 79s 81ms/step - loss: 1.4898 - acc: 0.2851 - val_loss: 1.4614 - val_acc: 0.3221\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.27498 to 0.32209, saving model to xception_best.ckpt\n",
      "Epoch 5/300\n",
      "979/979 [==============================] - 80s 81ms/step - loss: 1.3897 - acc: 0.3376 - val_loss: 1.4152 - val_acc: 0.3696\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.32209 to 0.36961, saving model to xception_best.ckpt\n",
      "Epoch 6/300\n",
      "979/979 [==============================] - 80s 82ms/step - loss: 1.3378 - acc: 0.3543 - val_loss: 1.9201 - val_acc: 0.1764\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.36961\n",
      "Epoch 7/300\n",
      "979/979 [==============================] - 80s 82ms/step - loss: 1.2595 - acc: 0.3630 - val_loss: 1.5788 - val_acc: 0.2822\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.36961\n",
      "Epoch 8/300\n",
      "979/979 [==============================] - 79s 81ms/step - loss: 1.2181 - acc: 0.3968 - val_loss: 1.5658 - val_acc: 0.2659\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.36961\n",
      "Epoch 9/300\n",
      "979/979 [==============================] - 79s 80ms/step - loss: 1.1787 - acc: 0.3960 - val_loss: 1.2676 - val_acc: 0.4429\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.36961 to 0.44288, saving model to xception_best.ckpt\n",
      "Epoch 10/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 1.1332 - acc: 0.4326 - val_loss: 1.2369 - val_acc: 0.4481\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.44288 to 0.44809, saving model to xception_best.ckpt\n",
      "Epoch 11/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 1.1165 - acc: 0.4380 - val_loss: 1.6797 - val_acc: 0.4270\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.44809\n",
      "Epoch 12/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 1.0849 - acc: 0.4577 - val_loss: 1.3567 - val_acc: 0.3858\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.44809\n",
      "Epoch 13/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 1.0608 - acc: 0.4623 - val_loss: 1.1851 - val_acc: 0.4892\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.44809 to 0.48917, saving model to xception_best.ckpt\n",
      "Epoch 14/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 1.0376 - acc: 0.4794 - val_loss: 1.4284 - val_acc: 0.3611\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.48917\n",
      "Epoch 15/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 1.0258 - acc: 0.4951 - val_loss: 1.6417 - val_acc: 0.3491\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.48917\n",
      "Epoch 16/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.9884 - acc: 0.5044 - val_loss: 1.5738 - val_acc: 0.3187\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.48917\n",
      "Epoch 17/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 1.0037 - acc: 0.4772 - val_loss: 2.0815 - val_acc: 0.3304\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.48917\n",
      "Epoch 18/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.9454 - acc: 0.5173 - val_loss: 1.5463 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.48917\n",
      "Epoch 19/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.9672 - acc: 0.5102 - val_loss: 1.0619 - val_acc: 0.5593\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.48917 to 0.55927, saving model to xception_best.ckpt\n",
      "Epoch 20/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.9273 - acc: 0.5209 - val_loss: 1.5768 - val_acc: 0.4572\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.55927\n",
      "Epoch 21/300\n",
      "979/979 [==============================] - 78s 80ms/step - loss: 0.9287 - acc: 0.5189 - val_loss: 1.3700 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.55927\n",
      "Epoch 22/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.9053 - acc: 0.5396 - val_loss: 1.2970 - val_acc: 0.4825\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.55927\n",
      "Epoch 23/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.9008 - acc: 0.5356 - val_loss: 1.1773 - val_acc: 0.5307\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.55927\n",
      "Epoch 24/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.8761 - acc: 0.5521 - val_loss: 1.1512 - val_acc: 0.5048\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.55927\n",
      "Epoch 25/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.8671 - acc: 0.5387 - val_loss: 1.0500 - val_acc: 0.5677\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.55927 to 0.56775, saving model to xception_best.ckpt\n",
      "Epoch 26/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.8626 - acc: 0.5508 - val_loss: 1.1068 - val_acc: 0.5612\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.56775\n",
      "Epoch 27/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.8762 - acc: 0.5451 - val_loss: 1.1588 - val_acc: 0.5048\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.56775\n",
      "Epoch 28/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.8341 - acc: 0.5641 - val_loss: 1.0187 - val_acc: 0.5774\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.56775 to 0.57736, saving model to xception_best.ckpt\n",
      "Epoch 29/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.8402 - acc: 0.5606 - val_loss: 0.9852 - val_acc: 0.5831\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.57736 to 0.58308, saving model to xception_best.ckpt\n",
      "Epoch 30/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.8166 - acc: 0.5754 - val_loss: 0.9644 - val_acc: 0.6063\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.58308 to 0.60627, saving model to xception_best.ckpt\n",
      "Epoch 31/300\n",
      "979/979 [==============================] - 76s 78ms/step - loss: 0.8060 - acc: 0.5609 - val_loss: 1.7538 - val_acc: 0.4203\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.60627\n",
      "Epoch 32/300\n",
      "979/979 [==============================] - 76s 77ms/step - loss: 0.8027 - acc: 0.5685 - val_loss: 1.1685 - val_acc: 0.5447\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.60627\n",
      "Epoch 33/300\n",
      "979/979 [==============================] - 77s 78ms/step - loss: 0.8085 - acc: 0.5771 - val_loss: 1.0186 - val_acc: 0.5676\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.60627\n",
      "Epoch 34/300\n",
      "979/979 [==============================] - 78s 80ms/step - loss: 0.7991 - acc: 0.5754 - val_loss: 1.0440 - val_acc: 0.5691\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.60627\n",
      "Epoch 35/300\n",
      "979/979 [==============================] - 78s 79ms/step - loss: 0.7863 - acc: 0.5788 - val_loss: 1.0422 - val_acc: 0.5765\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.60627\n",
      "Epoch 36/300\n",
      "979/979 [==============================] - 78s 80ms/step - loss: 0.7769 - acc: 0.5881 - val_loss: 0.9202 - val_acc: 0.6338\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.60627 to 0.63376, saving model to xception_best.ckpt\n",
      "Epoch 37/300\n",
      "979/979 [==============================] - 82s 84ms/step - loss: 0.7577 - acc: 0.5942 - val_loss: 1.1418 - val_acc: 0.5364\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.63376\n",
      "Epoch 38/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.7731 - acc: 0.6039 - val_loss: 1.0005 - val_acc: 0.5880\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.63376\n",
      "Epoch 39/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.7733 - acc: 0.5824 - val_loss: 1.0007 - val_acc: 0.6076\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.63376\n",
      "Epoch 40/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.7408 - acc: 0.6152 - val_loss: 0.9816 - val_acc: 0.6024\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.63376\n",
      "Epoch 41/300\n",
      "979/979 [==============================] - 81s 82ms/step - loss: 0.7542 - acc: 0.5966 - val_loss: 1.0047 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.63376\n",
      "Epoch 42/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.7475 - acc: 0.5960 - val_loss: 0.9755 - val_acc: 0.6110\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.63376\n",
      "Epoch 43/300\n",
      "979/979 [==============================] - 81s 82ms/step - loss: 0.7327 - acc: 0.6158 - val_loss: 0.9628 - val_acc: 0.6165\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.63376\n",
      "Epoch 44/300\n",
      "979/979 [==============================] - 80s 81ms/step - loss: 0.7447 - acc: 0.5955 - val_loss: 0.9689 - val_acc: 0.6073\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.63376\n",
      "Epoch 45/300\n",
      "979/979 [==============================] - 80s 82ms/step - loss: 0.7270 - acc: 0.6209 - val_loss: 0.9011 - val_acc: 0.6428\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.63376 to 0.64275, saving model to xception_best.ckpt\n",
      "Epoch 46/300\n",
      "979/979 [==============================] - 83s 84ms/step - loss: 0.7226 - acc: 0.6181 - val_loss: 0.9408 - val_acc: 0.6121\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.64275\n",
      "Epoch 47/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.7037 - acc: 0.6201 - val_loss: 0.9106 - val_acc: 0.6243\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.64275\n",
      "Epoch 48/300\n",
      "979/979 [==============================] - 80s 82ms/step - loss: 0.7087 - acc: 0.6171 - val_loss: 0.9203 - val_acc: 0.6229\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.64275\n",
      "Epoch 49/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.7158 - acc: 0.6256 - val_loss: 1.0280 - val_acc: 0.5653\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.64275\n",
      "Epoch 50/300\n",
      "979/979 [==============================] - 81s 82ms/step - loss: 0.7070 - acc: 0.6208 - val_loss: 0.8904 - val_acc: 0.6716\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.64275 to 0.67157, saving model to xception_best.ckpt\n",
      "Epoch 51/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.7040 - acc: 0.6167 - val_loss: 0.8939 - val_acc: 0.6446\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.67157\n",
      "Epoch 52/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.6885 - acc: 0.6321 - val_loss: 0.8350 - val_acc: 0.6868\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.67157 to 0.68680, saving model to xception_best.ckpt\n",
      "Epoch 53/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.7008 - acc: 0.6419 - val_loss: 0.8948 - val_acc: 0.6494\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.68680\n",
      "Epoch 54/300\n",
      "979/979 [==============================] - 81s 82ms/step - loss: 0.6814 - acc: 0.6452 - val_loss: 0.9836 - val_acc: 0.6081\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.68680\n",
      "Epoch 55/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.6972 - acc: 0.6248 - val_loss: 0.8775 - val_acc: 0.6731\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.68680\n",
      "Epoch 56/300\n",
      "979/979 [==============================] - 81s 82ms/step - loss: 0.6742 - acc: 0.6471 - val_loss: 0.8633 - val_acc: 0.6663\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.68680\n",
      "Epoch 57/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.6684 - acc: 0.6510 - val_loss: 0.8567 - val_acc: 0.6705\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.68680\n",
      "Epoch 58/300\n",
      "979/979 [==============================] - 83s 85ms/step - loss: 0.6652 - acc: 0.6486 - val_loss: 0.8447 - val_acc: 0.6861\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.68680\n",
      "Epoch 59/300\n",
      "979/979 [==============================] - 86s 88ms/step - loss: 0.6577 - acc: 0.6488 - val_loss: 0.8328 - val_acc: 0.6888\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.68680 to 0.68884, saving model to xception_best.ckpt\n",
      "Epoch 60/300\n",
      "979/979 [==============================] - 87s 89ms/step - loss: 0.6437 - acc: 0.6540 - val_loss: 0.9100 - val_acc: 0.6407\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.68884\n",
      "Epoch 61/300\n",
      "979/979 [==============================] - 86s 88ms/step - loss: 0.6612 - acc: 0.6560 - val_loss: 0.8855 - val_acc: 0.6724\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.68884\n",
      "Epoch 62/300\n",
      "979/979 [==============================] - 87s 89ms/step - loss: 0.6403 - acc: 0.6569 - val_loss: 0.9017 - val_acc: 0.6516\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.68884\n",
      "Epoch 63/300\n",
      "979/979 [==============================] - 86s 88ms/step - loss: 0.6513 - acc: 0.6547 - val_loss: 0.8241 - val_acc: 0.6751\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.68884\n",
      "Epoch 64/300\n",
      "979/979 [==============================] - 83s 85ms/step - loss: 0.6362 - acc: 0.6593 - val_loss: 0.8576 - val_acc: 0.6636\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.68884\n",
      "Epoch 65/300\n",
      "979/979 [==============================] - 83s 85ms/step - loss: 0.6300 - acc: 0.6624 - val_loss: 0.8639 - val_acc: 0.6691\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.68884\n",
      "Epoch 66/300\n",
      "979/979 [==============================] - 83s 85ms/step - loss: 0.6497 - acc: 0.6480 - val_loss: 0.7872 - val_acc: 0.7044\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.68884 to 0.70437, saving model to xception_best.ckpt\n",
      "Epoch 67/300\n",
      "979/979 [==============================] - 83s 85ms/step - loss: 0.6356 - acc: 0.6623 - val_loss: 0.7980 - val_acc: 0.7135\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.70437 to 0.71347, saving model to xception_best.ckpt\n",
      "Epoch 68/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.6380 - acc: 0.6665 - val_loss: 0.7614 - val_acc: 0.7265\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.71347 to 0.72655, saving model to xception_best.ckpt\n",
      "Epoch 69/300\n",
      "979/979 [==============================] - 80s 82ms/step - loss: 0.6400 - acc: 0.6756 - val_loss: 0.8082 - val_acc: 0.7014\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.72655\n",
      "Epoch 70/300\n",
      "979/979 [==============================] - 82s 84ms/step - loss: 0.6210 - acc: 0.6719 - val_loss: 0.8349 - val_acc: 0.6953\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.72655\n",
      "Epoch 71/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.6033 - acc: 0.6855 - val_loss: 0.8054 - val_acc: 0.7093\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.72655\n",
      "Epoch 72/300\n",
      "979/979 [==============================] - 82s 84ms/step - loss: 0.6069 - acc: 0.6679 - val_loss: 0.8110 - val_acc: 0.6856\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.72655\n",
      "Epoch 73/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.6189 - acc: 0.6762 - val_loss: 0.8386 - val_acc: 0.6636\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.72655\n",
      "Epoch 74/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.6229 - acc: 0.6730 - val_loss: 0.8494 - val_acc: 0.6982\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.72655\n",
      "Epoch 75/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.6059 - acc: 0.6812 - val_loss: 0.7493 - val_acc: 0.7368\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.72655 to 0.73677, saving model to xception_best.ckpt\n",
      "Epoch 76/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5931 - acc: 0.6761 - val_loss: 0.8030 - val_acc: 0.6836\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.73677\n",
      "Epoch 77/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.6003 - acc: 0.6865 - val_loss: 0.7619 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.73677\n",
      "Epoch 78/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5790 - acc: 0.6942 - val_loss: 0.8204 - val_acc: 0.6975\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.73677\n",
      "Epoch 79/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5909 - acc: 0.6893 - val_loss: 0.8091 - val_acc: 0.7046\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.73677\n",
      "Epoch 80/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.6054 - acc: 0.6777 - val_loss: 0.8264 - val_acc: 0.6838\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.73677\n",
      "Epoch 81/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.5725 - acc: 0.6964 - val_loss: 0.7680 - val_acc: 0.7176\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.73677\n",
      "Epoch 82/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5848 - acc: 0.6915 - val_loss: 0.8070 - val_acc: 0.7144\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.73677\n",
      "Epoch 83/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5866 - acc: 0.6989 - val_loss: 0.7939 - val_acc: 0.7050\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.73677\n",
      "Epoch 84/300\n",
      "979/979 [==============================] - 82s 84ms/step - loss: 0.5844 - acc: 0.7020 - val_loss: 0.7616 - val_acc: 0.7281\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.73677\n",
      "Epoch 85/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5717 - acc: 0.7034 - val_loss: 0.7453 - val_acc: 0.7340\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.73677\n",
      "Epoch 86/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5617 - acc: 0.7021 - val_loss: 0.7301 - val_acc: 0.7419\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.73677 to 0.74188, saving model to xception_best.ckpt\n",
      "Epoch 87/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5791 - acc: 0.6888 - val_loss: 0.7066 - val_acc: 0.7530\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.74188 to 0.75301, saving model to xception_best.ckpt\n",
      "Epoch 88/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.5762 - acc: 0.7022 - val_loss: 0.7528 - val_acc: 0.7304\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.75301\n",
      "Epoch 89/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5567 - acc: 0.7094 - val_loss: 0.7688 - val_acc: 0.7282\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.75301\n",
      "Epoch 90/300\n",
      "979/979 [==============================] - 82s 84ms/step - loss: 0.5515 - acc: 0.7189 - val_loss: 0.7359 - val_acc: 0.7386\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.75301\n",
      "Epoch 91/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.5681 - acc: 0.7058 - val_loss: 0.7468 - val_acc: 0.7435\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.75301\n",
      "Epoch 92/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5583 - acc: 0.7001 - val_loss: 0.8337 - val_acc: 0.7102\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.75301\n",
      "Epoch 93/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5741 - acc: 0.7080 - val_loss: 0.7235 - val_acc: 0.7609\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.75301 to 0.76088, saving model to xception_best.ckpt\n",
      "Epoch 94/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5417 - acc: 0.7181 - val_loss: 0.7679 - val_acc: 0.7417\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.76088\n",
      "Epoch 95/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.5499 - acc: 0.7191 - val_loss: 0.7035 - val_acc: 0.7663\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.76088 to 0.76630, saving model to xception_best.ckpt\n",
      "Epoch 96/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.5476 - acc: 0.7083 - val_loss: 0.7282 - val_acc: 0.7540\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.76630\n",
      "Epoch 97/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5259 - acc: 0.7284 - val_loss: 0.7616 - val_acc: 0.7142\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.76630\n",
      "Epoch 98/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5437 - acc: 0.7174 - val_loss: 0.7238 - val_acc: 0.7381\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.76630\n",
      "Epoch 99/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.5347 - acc: 0.7219 - val_loss: 0.8731 - val_acc: 0.6698\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.76630\n",
      "Epoch 100/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5323 - acc: 0.7226 - val_loss: 0.7182 - val_acc: 0.7431\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.76630\n",
      "Epoch 101/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5391 - acc: 0.7257 - val_loss: 0.7509 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.76630\n",
      "Epoch 102/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5248 - acc: 0.7241 - val_loss: 0.7850 - val_acc: 0.7102\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.76630\n",
      "Epoch 103/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5245 - acc: 0.7286 - val_loss: 0.7321 - val_acc: 0.7548\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.76630\n",
      "Epoch 104/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.5222 - acc: 0.7280 - val_loss: 0.6762 - val_acc: 0.7862\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.76630 to 0.78623, saving model to xception_best.ckpt\n",
      "Epoch 105/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5310 - acc: 0.7325 - val_loss: 0.7152 - val_acc: 0.7502\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.78623\n",
      "Epoch 106/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.5113 - acc: 0.7394 - val_loss: 0.7124 - val_acc: 0.7566\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.78623\n",
      "Epoch 107/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5140 - acc: 0.7423 - val_loss: 0.6554 - val_acc: 0.7847\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.78623\n",
      "Epoch 108/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.5124 - acc: 0.7280 - val_loss: 0.6792 - val_acc: 0.7661\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.78623\n",
      "Epoch 109/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5024 - acc: 0.7419 - val_loss: 0.6740 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.78623\n",
      "Epoch 110/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5168 - acc: 0.7331 - val_loss: 0.6679 - val_acc: 0.7818\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.78623\n",
      "Epoch 111/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5049 - acc: 0.7365 - val_loss: 0.6564 - val_acc: 0.7785\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.78623\n",
      "Epoch 112/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.4974 - acc: 0.7387 - val_loss: 0.6544 - val_acc: 0.7839\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.78623\n",
      "Epoch 113/300\n",
      "979/979 [==============================] - 81s 82ms/step - loss: 0.5091 - acc: 0.7370 - val_loss: 0.6806 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.78623\n",
      "Epoch 114/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4977 - acc: 0.7566 - val_loss: 0.6349 - val_acc: 0.7843\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.78623\n",
      "Epoch 115/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4894 - acc: 0.7462 - val_loss: 0.6889 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.78623\n",
      "Epoch 116/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4909 - acc: 0.7394 - val_loss: 0.6595 - val_acc: 0.7859\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.78623\n",
      "Epoch 117/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5033 - acc: 0.7308 - val_loss: 0.6931 - val_acc: 0.7789\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.78623\n",
      "Epoch 118/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.5076 - acc: 0.7449 - val_loss: 0.6752 - val_acc: 0.7776\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.78623\n",
      "Epoch 119/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4836 - acc: 0.7599 - val_loss: 0.6808 - val_acc: 0.7750\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.78623\n",
      "Epoch 120/300\n",
      "979/979 [==============================] - 82s 84ms/step - loss: 0.4815 - acc: 0.7544 - val_loss: 0.6382 - val_acc: 0.8004\n",
      "\n",
      "Epoch 00120: val_acc improved from 0.78623 to 0.80043, saving model to xception_best.ckpt\n",
      "Epoch 121/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.4857 - acc: 0.7542 - val_loss: 0.6424 - val_acc: 0.8003\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.80043\n",
      "Epoch 122/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4921 - acc: 0.7385 - val_loss: 0.6624 - val_acc: 0.7862\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.80043\n",
      "Epoch 123/300\n",
      "979/979 [==============================] - 82s 84ms/step - loss: 0.4803 - acc: 0.7590 - val_loss: 0.6302 - val_acc: 0.8051\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.80043 to 0.80513, saving model to xception_best.ckpt\n",
      "Epoch 124/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4843 - acc: 0.7529 - val_loss: 0.6546 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.80513\n",
      "Epoch 125/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4847 - acc: 0.7511 - val_loss: 0.6504 - val_acc: 0.8033\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.80513\n",
      "Epoch 126/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4689 - acc: 0.7527 - val_loss: 0.6849 - val_acc: 0.7764\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.80513\n",
      "Epoch 127/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4813 - acc: 0.7551 - val_loss: 0.6287 - val_acc: 0.7993\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.80513\n",
      "Epoch 128/300\n",
      "979/979 [==============================] - 82s 84ms/step - loss: 0.4737 - acc: 0.7534 - val_loss: 0.6571 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.80513\n",
      "Epoch 129/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.4721 - acc: 0.7593 - val_loss: 0.6326 - val_acc: 0.7966\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.80513\n",
      "Epoch 130/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.4585 - acc: 0.7647 - val_loss: 0.6681 - val_acc: 0.7933\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.80513\n",
      "Epoch 131/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4767 - acc: 0.7531 - val_loss: 0.6484 - val_acc: 0.7954\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.80513\n",
      "Epoch 132/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4625 - acc: 0.7687 - val_loss: 0.6627 - val_acc: 0.7936\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.80513\n",
      "Epoch 133/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4643 - acc: 0.7549 - val_loss: 0.6693 - val_acc: 0.7786\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.80513\n",
      "Epoch 134/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.4542 - acc: 0.7695 - val_loss: 0.6250 - val_acc: 0.8036\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.80513\n",
      "Epoch 135/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4546 - acc: 0.7723 - val_loss: 0.6533 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.80513\n",
      "Epoch 136/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.4635 - acc: 0.7668 - val_loss: 0.6378 - val_acc: 0.7918\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.80513\n",
      "Epoch 137/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4709 - acc: 0.7584 - val_loss: 0.6475 - val_acc: 0.8076\n",
      "\n",
      "Epoch 00137: val_acc improved from 0.80513 to 0.80758, saving model to xception_best.ckpt\n",
      "Epoch 138/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4627 - acc: 0.7697 - val_loss: 0.6446 - val_acc: 0.8182\n",
      "\n",
      "Epoch 00138: val_acc improved from 0.80758 to 0.81821, saving model to xception_best.ckpt\n",
      "Epoch 139/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4302 - acc: 0.7814 - val_loss: 0.6339 - val_acc: 0.8182\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.81821\n",
      "Epoch 140/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.4475 - acc: 0.7753 - val_loss: 0.7267 - val_acc: 0.7609\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.81821\n",
      "Epoch 141/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4346 - acc: 0.7776 - val_loss: 0.6054 - val_acc: 0.8146\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.81821\n",
      "Epoch 142/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4437 - acc: 0.7795 - val_loss: 0.6325 - val_acc: 0.7750\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.81821\n",
      "Epoch 143/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.4377 - acc: 0.7808 - val_loss: 0.6038 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00143: val_acc improved from 0.81821 to 0.82138, saving model to xception_best.ckpt\n",
      "Epoch 144/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4365 - acc: 0.7762 - val_loss: 0.6461 - val_acc: 0.8108\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.82138\n",
      "Epoch 145/300\n",
      "979/979 [==============================] - 82s 84ms/step - loss: 0.4466 - acc: 0.7694 - val_loss: 0.6089 - val_acc: 0.8185\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.82138\n",
      "Epoch 146/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4385 - acc: 0.7865 - val_loss: 0.6437 - val_acc: 0.8002\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.82138\n",
      "Epoch 147/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.4383 - acc: 0.7772 - val_loss: 0.6088 - val_acc: 0.8185\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.82138\n",
      "Epoch 148/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.4423 - acc: 0.7762 - val_loss: 0.5946 - val_acc: 0.8203\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.82138\n",
      "Epoch 149/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4315 - acc: 0.7821 - val_loss: 0.6201 - val_acc: 0.8206\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.82138\n",
      "Epoch 150/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.4406 - acc: 0.7814 - val_loss: 0.6084 - val_acc: 0.8189\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.82138\n",
      "Epoch 151/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4273 - acc: 0.7924 - val_loss: 0.5777 - val_acc: 0.8273\n",
      "\n",
      "Epoch 00151: val_acc improved from 0.82138 to 0.82730, saving model to xception_best.ckpt\n",
      "Epoch 152/300\n",
      "979/979 [==============================] - 82s 84ms/step - loss: 0.4214 - acc: 0.7885 - val_loss: 0.6416 - val_acc: 0.8006\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.82730\n",
      "Epoch 153/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4142 - acc: 0.7933 - val_loss: 0.6262 - val_acc: 0.8096\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.82730\n",
      "Epoch 154/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4300 - acc: 0.7899 - val_loss: 0.6482 - val_acc: 0.7996\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.82730\n",
      "Epoch 155/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4300 - acc: 0.7872 - val_loss: 0.5864 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.82730\n",
      "Epoch 156/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4132 - acc: 0.7923 - val_loss: 0.5913 - val_acc: 0.8338\n",
      "\n",
      "Epoch 00156: val_acc improved from 0.82730 to 0.83384, saving model to xception_best.ckpt\n",
      "Epoch 157/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4133 - acc: 0.7960 - val_loss: 0.6108 - val_acc: 0.8178\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.83384\n",
      "Epoch 158/300\n",
      "979/979 [==============================] - 82s 83ms/step - loss: 0.4185 - acc: 0.7837 - val_loss: 0.5919 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.83384\n",
      "Epoch 159/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4070 - acc: 0.8015 - val_loss: 0.5962 - val_acc: 0.8348\n",
      "\n",
      "Epoch 00159: val_acc improved from 0.83384 to 0.83476, saving model to xception_best.ckpt\n",
      "Epoch 160/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.3980 - acc: 0.8095 - val_loss: 0.6215 - val_acc: 0.8073\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.83476\n",
      "Epoch 161/300\n",
      "979/979 [==============================] - 81s 83ms/step - loss: 0.4351 - acc: 0.7834 - val_loss: 0.5940 - val_acc: 0.8224\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.83476\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f99386835f8>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xception_model.fit(\n",
    "        valid_generator,\n",
    "        epochs = 300,\n",
    "        validation_data = train_generator,\n",
    "        callbacks = [my_callbacks],\n",
    "        class_weight = class_weights\n",
    ")\n",
    "\n",
    "xception_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-morris",
   "metadata": {
    "id": "pretty-morris",
    "papermill": {
     "duration": 3.201635,
     "end_time": "2021-05-30T20:12:18.344310",
     "exception": false,
     "start_time": "2021-05-30T20:12:15.142675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 위의 학습에서 사용하였던 검증 데이터 세트에 대한 추가 학습\n",
    "\n",
    "### 검증 데이터 세트를 학습, 검증 데이터 세트로 재구성하여 추가 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cloudy-idaho",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:24.238372Z",
     "iopub.status.busy": "2021-05-30T20:12:24.237660Z",
     "iopub.status.idle": "2021-05-30T20:12:24.305208Z",
     "shell.execute_reply": "2021-05-30T20:12:24.305579Z",
     "shell.execute_reply.started": "2021-05-30T09:30:16.948040Z"
    },
    "id": "cloudy-idaho",
    "papermill": {
     "duration": 3.027306,
     "end_time": "2021-05-30T20:12:24.305720",
     "exception": false,
     "start_time": "2021-05-30T20:12:21.278414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(\n",
    "    df_train_kaggle, \n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify= df_train_kaggle.label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "nervous-crisis",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:30.429807Z",
     "iopub.status.busy": "2021-05-30T20:12:30.429001Z",
     "iopub.status.idle": "2021-05-30T20:12:30.472297Z",
     "shell.execute_reply": "2021-05-30T20:12:30.471634Z",
     "shell.execute_reply.started": "2021-05-30T09:30:18.098841Z"
    },
    "id": "nervous-crisis",
    "outputId": "4e7db473-44a8-44a1-aead-472c63d3370c",
    "papermill": {
     "duration": 3.239148,
     "end_time": "2021-05-30T20:12:30.472465",
     "exception": false,
     "start_time": "2021-05-30T20:12:27.233317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8807 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_aug.flow_from_dataframe(\n",
    "    dataframe = X_train,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 8,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "instrumental-indie",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:36.309467Z",
     "iopub.status.busy": "2021-05-30T20:12:36.308631Z",
     "iopub.status.idle": "2021-05-30T20:12:36.318017Z",
     "shell.execute_reply": "2021-05-30T20:12:36.317530Z",
     "shell.execute_reply.started": "2021-05-30T09:30:23.206485Z"
    },
    "id": "instrumental-indie",
    "outputId": "aaa9c990-6529-4f11-8bef-cd7be0713256",
    "papermill": {
     "duration": 2.927421,
     "end_time": "2021-05-30T20:12:36.318129",
     "exception": false,
     "start_time": "2021-05-30T20:12:33.390708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 979 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = valid_aug.flow_from_dataframe( \n",
    "    dataframe=X_test,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 8,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dedicated-chapel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:42.897491Z",
     "iopub.status.busy": "2021-05-30T20:12:42.895853Z",
     "iopub.status.idle": "2021-05-30T20:12:42.898202Z",
     "shell.execute_reply": "2021-05-30T20:12:42.898602Z",
     "shell.execute_reply.started": "2021-05-30T09:30:26.966513Z"
    },
    "id": "dedicated-chapel",
    "papermill": {
     "duration": 3.108025,
     "end_time": "2021-05-30T20:12:42.898739",
     "exception": false,
     "start_time": "2021-05-30T20:12:39.790714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID =valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sized-norfolk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:48.820785Z",
     "iopub.status.busy": "2021-05-30T20:12:48.819337Z",
     "iopub.status.idle": "2021-05-30T20:25:26.371458Z",
     "shell.execute_reply": "2021-05-30T20:25:26.371941Z",
     "shell.execute_reply.started": "2021-05-30T09:30:36.962285Z"
    },
    "id": "sized-norfolk",
    "outputId": "20071e30-0a6e-43e4-8acc-543ff61f89ec",
    "papermill": {
     "duration": 760.527609,
     "end_time": "2021-05-30T20:25:26.372105",
     "exception": false,
     "start_time": "2021-05-30T20:12:45.844496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1100/1100 [==============================] - 79s 64ms/step - loss: 0.6703 - acc: 0.7401 - val_loss: 0.5841 - val_acc: 0.8453\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.83476 to 0.84529, saving model to xception_best.ckpt\n",
      "Epoch 2/50\n",
      "1100/1100 [==============================] - 70s 63ms/step - loss: 0.6577 - acc: 0.7477 - val_loss: 0.5951 - val_acc: 0.8402\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.84529\n",
      "Epoch 3/50\n",
      "1100/1100 [==============================] - 70s 63ms/step - loss: 0.6500 - acc: 0.7478 - val_loss: 0.5844 - val_acc: 0.8258\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.84529\n",
      "Epoch 4/50\n",
      "1100/1100 [==============================] - 70s 63ms/step - loss: 0.6497 - acc: 0.7460 - val_loss: 0.5519 - val_acc: 0.8289\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.84529\n",
      "Epoch 5/50\n",
      "1100/1100 [==============================] - 70s 63ms/step - loss: 0.6379 - acc: 0.7530 - val_loss: 0.6849 - val_acc: 0.8279\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.84529\n",
      "Epoch 6/50\n",
      "1100/1100 [==============================] - 70s 64ms/step - loss: 0.6220 - acc: 0.7626 - val_loss: 0.6200 - val_acc: 0.8381\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.84529\n",
      "Epoch 7/50\n",
      "1100/1100 [==============================] - 70s 63ms/step - loss: 0.6186 - acc: 0.7627 - val_loss: 0.6238 - val_acc: 0.8258\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.84529\n",
      "Epoch 8/50\n",
      "1100/1100 [==============================] - 70s 63ms/step - loss: 0.6232 - acc: 0.7652 - val_loss: 0.6269 - val_acc: 0.8422\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.84529\n",
      "Epoch 9/50\n",
      "1100/1100 [==============================] - 70s 63ms/step - loss: 0.6208 - acc: 0.7616 - val_loss: 0.5832 - val_acc: 0.8217\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.84529\n",
      "Epoch 10/50\n",
      "1100/1100 [==============================] - 69s 63ms/step - loss: 0.6207 - acc: 0.7586 - val_loss: 0.6231 - val_acc: 0.8279\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.84529\n",
      "Epoch 11/50\n",
      "1100/1100 [==============================] - 70s 63ms/step - loss: 0.6192 - acc: 0.7582 - val_loss: 0.6352 - val_acc: 0.8217\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.84529\n",
      "Epoch 12/50\n",
      "1100/1100 [==============================] - 70s 64ms/step - loss: 0.6077 - acc: 0.7601 - val_loss: 0.5904 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.84529\n",
      "Epoch 13/50\n",
      "1100/1100 [==============================] - 70s 63ms/step - loss: 0.6164 - acc: 0.7635 - val_loss: 0.6056 - val_acc: 0.8166\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.84529\n",
      "Epoch 14/50\n",
      "1100/1100 [==============================] - 70s 64ms/step - loss: 0.6086 - acc: 0.7647 - val_loss: 0.5980 - val_acc: 0.8268\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.84529\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f993869a7b8>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xception_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "    epochs=50,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=STEP_SIZE_VALID,callbacks=[my_callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "complete-spelling",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:33.497837Z",
     "iopub.status.busy": "2021-05-30T20:25:33.496999Z",
     "iopub.status.idle": "2021-05-30T20:25:34.695800Z",
     "shell.execute_reply": "2021-05-30T20:25:34.695365Z",
     "shell.execute_reply.started": "2021-05-24T16:41:06.725854Z"
    },
    "id": "complete-spelling",
    "outputId": "7f0049d7-bedf-4255-c346-481788903f41",
    "papermill": {
     "duration": 4.566888,
     "end_time": "2021-05-30T20:25:34.695951",
     "exception": false,
     "start_time": "2021-05-30T20:25:30.129063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f991d237d68>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xception_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-cylinder",
   "metadata": {
    "id": "intended-cylinder",
    "papermill": {
     "duration": 3.633537,
     "end_time": "2021-05-30T20:25:41.743104",
     "exception": false,
     "start_time": "2021-05-30T20:25:38.109567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 검증 데이터 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "equivalent-album",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:48.625234Z",
     "iopub.status.busy": "2021-05-30T20:25:48.624438Z",
     "iopub.status.idle": "2021-05-30T20:25:48.634216Z",
     "shell.execute_reply": "2021-05-30T20:25:48.633804Z",
     "shell.execute_reply.started": "2021-05-27T05:35:10.161826Z"
    },
    "id": "equivalent-album",
    "outputId": "388c9b93-9c21-4130-d864-0f4678592fdd",
    "papermill": {
     "duration": 3.430239,
     "end_time": "2021-05-30T20:25:48.634343",
     "exception": false,
     "start_time": "2021-05-30T20:25:45.204104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 979 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "target_shape = 224\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "compi_gen = valid_aug.flow_from_dataframe(\n",
    "    dataframe= X_test, \n",
    "    x_col= \"filepath\",\n",
    "    class_mode=None,\n",
    "    target_size= (target_shape, target_shape),\n",
    "    shuffle= False,\n",
    "    batch_size= BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "preceding-delight",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:56.117007Z",
     "iopub.status.busy": "2021-05-30T20:25:56.116264Z",
     "iopub.status.idle": "2021-05-30T20:26:05.659358Z",
     "shell.execute_reply": "2021-05-30T20:26:05.658569Z",
     "shell.execute_reply.started": "2021-05-27T05:35:17.324361Z"
    },
    "id": "preceding-delight",
    "outputId": "711df68f-54a2-471c-eb7d-7e14d128c91a",
    "papermill": {
     "duration": 12.914933,
     "end_time": "2021-05-30T20:26:05.659489",
     "exception": false,
     "start_time": "2021-05-30T20:25:52.744556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979/979 [==============================] - 17s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "predicition_compi = xception_model.predict(compi_gen, steps= compi_gen.n/ BATCH_SIZE, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "distinguished-midwest",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:12.667940Z",
     "iopub.status.busy": "2021-05-30T20:26:12.649791Z",
     "iopub.status.idle": "2021-05-30T20:26:13.051891Z",
     "shell.execute_reply": "2021-05-30T20:26:13.051413Z",
     "shell.execute_reply.started": "2021-05-27T05:43:44.837052Z"
    },
    "id": "distinguished-midwest",
    "outputId": "ff29bab3-ae02-4987-c865-2a296b9c582b",
    "papermill": {
     "duration": 3.832152,
     "end_time": "2021-05-30T20:26:13.052010",
     "exception": false,
     "start_time": "2021-05-30T20:26:09.219858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f991d221278>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "class_prediction_compi =  np.argmax(predicition_compi, axis= 1)\n",
    "cm = confusion_matrix(X_test.label, class_prediction_compi, labels=[0, 1, 2, 3, 4])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83914daf",
   "metadata": {
    "id": "intended-cylinder",
    "papermill": {
     "duration": 3.633537,
     "end_time": "2021-05-30T20:25:41.743104",
     "exception": false,
     "start_time": "2021-05-30T20:25:38.109567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 추가 테스트 데이터 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11cf8fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                              filepath  label\n0    /home/Lee_KneeData//0/5a21060fe4b0f1e9e5622e32...      0\n1    /home/Lee_KneeData//0/5a21060fe4b0f1e9e5622e32...      0\n2    /home/Lee_KneeData//0/5a21112ee4b09b69e603db16...      0\n3    /home/Lee_KneeData//0/5a21112ee4b09b69e603db16...      0\n4    /home/Lee_KneeData//0/5a28d27ae4b028f6846ae00a...      0\n..                                                 ...    ...\n526  /home/Lee_KneeData//4/5b0e3cede4b07f99d60ee44d...      4\n527  /home/Lee_KneeData//4/5b0f64cde4b0b80049bd1e8e...      4\n528  /home/Lee_KneeData//4/5b10dab8e4b07f99d61002a5...      4\n529  /home/Lee_KneeData//4/5b10dab8e4b07f99d61002a5...      4\n530  /home/Lee_KneeData//4/5b1f54b4e4b099a4cf79f0ae...      4\n\n[531 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepath</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/home/Lee_KneeData//0/5a21060fe4b0f1e9e5622e32...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/home/Lee_KneeData//0/5a21060fe4b0f1e9e5622e32...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/home/Lee_KneeData//0/5a21112ee4b09b69e603db16...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/home/Lee_KneeData//0/5a21112ee4b09b69e603db16...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/home/Lee_KneeData//0/5a28d27ae4b028f6846ae00a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>526</th>\n      <td>/home/Lee_KneeData//4/5b0e3cede4b07f99d60ee44d...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>527</th>\n      <td>/home/Lee_KneeData//4/5b0f64cde4b0b80049bd1e8e...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>528</th>\n      <td>/home/Lee_KneeData//4/5b10dab8e4b07f99d61002a5...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>529</th>\n      <td>/home/Lee_KneeData//4/5b10dab8e4b07f99d61002a5...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>530</th>\n      <td>/home/Lee_KneeData//4/5b1f54b4e4b099a4cf79f0ae...</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>531 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class = 5\n",
    "test_root_path = \"/home/Lee_KneeData/\"\n",
    "test_image_path_list = []\n",
    "test_label_list = []\n",
    "\n",
    "for label in range(n_class):\n",
    "    test_image_list = os.listdir(f\"{test_root_path}/{label}\")\n",
    "    test_image_path_list += [ f\"{test_root_path}/{label}/\"+ path for path in test_image_list]\n",
    "    test_label_list += [label] * len(test_image_list)\n",
    "\n",
    "df_test = pd.DataFrame({\"filepath\" : test_image_path_list, \"label\": test_label_list})\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8563088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(531, 2)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6223be",
   "metadata": {
    "id": "intended-cylinder",
    "papermill": {
     "duration": 3.633537,
     "end_time": "2021-05-30T20:25:41.743104",
     "exception": false,
     "start_time": "2021-05-30T20:25:38.109567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 추가 테스트 데이터 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6f6a6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'count')"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test.label.value_counts().plot.bar()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "469679e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "test_da = train_test_split(\n",
    "    df_test,\n",
    "    test_size = 0.1,\n",
    "    random_state = seed,\n",
    "    stratify = df_test.label\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ddf19c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 531 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "BS = 1\n",
    "image_size = 224\n",
    "seed = 42\n",
    "\n",
    "da_test_generator = valid_aug.flow_from_dataframe(\n",
    "    dataframe = df_test,\n",
    "    directory = test_root_path,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = 'label',\n",
    "    batch_size = 1,\n",
    "    seed = seed,\n",
    "    shuffle = False,\n",
    "    class_mode = None,\n",
    "    target_size = (image_size, image_size)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "499563c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531/531 [==============================] - 8s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "predicition_test = xception_model.predict(da_test_generator, steps= da_test_generator.n/ BS, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7d6147e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f991ce58710>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "class_prediction_test =  np.argmax(predicition_test, axis= 1)\n",
    "cm_test = confusion_matrix(df_test.label, class_prediction_test, labels=[0, 1, 2, 3, 4])\n",
    "disp_test = ConfusionMatrixDisplay(confusion_matrix = cm_test, display_labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "disp_test.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-wilson",
   "metadata": {
    "id": "positive-wilson",
    "papermill": {
     "duration": 3.5306,
     "end_time": "2021-05-30T20:26:20.277590",
     "exception": false,
     "start_time": "2021-05-30T20:26:16.746990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DPhi에서 제공한 테스트 데이터 세트에 대한 예측 및 .csv파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "constitutional-catholic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:28.031789Z",
     "iopub.status.busy": "2021-05-30T20:26:28.031111Z",
     "iopub.status.idle": "2021-05-30T20:26:28.058944Z",
     "shell.execute_reply": "2021-05-30T20:26:28.058161Z",
     "shell.execute_reply.started": "2021-05-27T09:08:20.550041Z"
    },
    "id": "constitutional-catholic",
    "outputId": "5f5f47f4-62db-4337-c3f4-043cc4d7d398",
    "papermill": {
     "duration": 4.034446,
     "end_time": "2021-05-30T20:26:28.059074",
     "exception": false,
     "start_time": "2021-05-30T20:26:24.024628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1958 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(compi_root_path + \"Test.csv\")\n",
    "\n",
    "test_generator = valid_aug.flow_from_dataframe(\n",
    "    dataframe= test,\n",
    "    directory= compi_root_path + \"test\",\n",
    "    x_col= \"filename\",\n",
    "    y_col= None,\n",
    "    batch_size= 1,\n",
    "    seed= 42,\n",
    "    shuffle= False,\n",
    "    class_mode= None,\n",
    "    target_size= (224,224)\n",
    ")\n",
    "\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "blocked-niagara",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:34.994605Z",
     "iopub.status.busy": "2021-05-30T20:26:34.994000Z",
     "iopub.status.idle": "2021-05-30T20:26:56.340759Z",
     "shell.execute_reply": "2021-05-30T20:26:56.341118Z",
     "shell.execute_reply.started": "2021-05-27T05:51:39.116529Z"
    },
    "id": "blocked-niagara",
    "outputId": "77c22b06-e93f-4228-8b21-57554d52e207",
    "papermill": {
     "duration": 24.791614,
     "end_time": "2021-05-30T20:26:56.341303",
     "exception": false,
     "start_time": "2021-05-30T20:26:31.549689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958/1958 [==============================] - 28s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "0    775\n2    515\n1    346\n3    257\n4     65\nName: label, dtype: int64"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = xception_model.predict(test_generator,steps=STEP_SIZE_TEST,verbose=1)\n",
    "df_submit = pd.DataFrame({\"label\":np.argmax(pred, axis= 1)})\n",
    "df_submit[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "liquid-tsunami",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:27:26.290338Z",
     "iopub.status.busy": "2021-05-30T20:27:26.289493Z",
     "iopub.status.idle": "2021-05-30T20:27:26.809425Z",
     "shell.execute_reply": "2021-05-30T20:27:26.808879Z",
     "shell.execute_reply.started": "2021-05-27T05:51:46.57395Z"
    },
    "id": "liquid-tsunami",
    "papermill": {
     "duration": 4.073647,
     "end_time": "2021-05-30T20:27:26.809566",
     "exception": false,
     "start_time": "2021-05-30T20:27:22.735919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xception_model.save_weights(\"knee_xray_Xceptionnet_GPA.h5\")\n",
    "df_submit.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "million-monaco",
    "rotary-prague",
    "hairy-greene",
    "dense-enzyme",
    "asian-chest",
    "marked-belarus",
    "pretty-morris",
    "intended-cylinder"
   ],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "[MDL]KLGrade.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6499.620651,
   "end_time": "2021-05-30T20:27:40.898205",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-30T18:39:21.277554",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}