{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18af0544",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/d9249/MDL/blob/main/KLGrade_DenseNet121-91.83.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33568de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd D:\\MDL\\model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74860ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b90db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13207697567511015629\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22727688192\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 961278791707233112\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ts26D3gLnyLd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ts26D3gLnyLd",
    "outputId": "f4f6fa8d-223f-4028-b18f-b8da4113b6d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov  6 19:22:55 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 461.72       Driver Version: 461.72       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3090   WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   34C    P2    37W / 350W |    599MiB / 24576MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     12188      C   ...gkim\\anaconda3\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-picnic",
   "metadata": {
    "id": "decreased-picnic",
    "papermill": {
     "duration": 0.028073,
     "end_time": "2021-05-30T18:39:27.966668",
     "exception": false,
     "start_time": "2021-05-30T18:39:27.938595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Short description\n",
    "This notebook is a part of [Data Sprint #35: Osteoarthritis Knee X-ray](https://dphi.tech/challenges/data-sprint-35-osteoarthritis-knee-x-ray/81/leaderboard/datathon/) challenge hosted on [dphi.tech](https://dphi.tech/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-monaco",
   "metadata": {
    "id": "million-monaco",
    "papermill": {
     "duration": 0.026241,
     "end_time": "2021-05-30T18:39:28.019714",
     "exception": false,
     "start_time": "2021-05-30T18:39:27.993473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing dependencies\n",
    "\n",
    "## 종속성을 가져오는 중 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "floating-cincinnati",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:28.086573Z",
     "iopub.status.busy": "2021-05-30T18:39:28.085923Z",
     "iopub.status.idle": "2021-05-30T18:39:32.847126Z",
     "shell.execute_reply": "2021-05-30T18:39:32.846068Z",
     "shell.execute_reply.started": "2021-05-30T09:28:36.967323Z"
    },
    "id": "floating-cincinnati",
    "papermill": {
     "duration": 4.80129,
     "end_time": "2021-05-30T18:39:32.847355",
     "exception": false,
     "start_time": "2021-05-30T18:39:28.046065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-discipline",
   "metadata": {
    "id": "express-discipline",
    "papermill": {
     "duration": 0.026573,
     "end_time": "2021-05-30T18:39:32.900510",
     "exception": false,
     "start_time": "2021-05-30T18:39:32.873937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Basic Idea\n",
    "The Basic idea is to use external data present in kaggle here: [Kaggle: Knee Osteoarthritis Dataset with KL Grading - 2018](https://www.kaggle.com/tommyngx/kneeoa)\n",
    "\n",
    "As we have labels for train, validation and test, we will combine all splits into one and test it on dataset provided by the compitition team, this will make sure kaggle dataset and compitition dataset has same data distribution.\n",
    "\n",
    "If train(kaggle dataset) and test (compition dataset) data has same distribution then their metric score should be roughy be the same (accuracy score in our case).\n",
    "\n",
    "# 기본 아이디어\n",
    "기본 아이디어는 여기 카글에 있는 외부 데이터를 사용하는 것이다. [Kaggle: KL Grading이 있는 무릎 골관절염 데이터 세트 - 2018](https://www.kaggle.com/tommyngx/kneeoa)\n",
    "\n",
    "교육, 검증 및 테스트를 위한 레이블이 있으므로 모든 분할을 하나로 결합하고 구성 팀에서 제공하는 데이터 세트에서 테스트합니다. 이렇게 하면 Kaggle 데이터 세트와 구성 데이터 세트가 동일한 데이터 분포를 갖출 수 있습니다.\n",
    "\n",
    "열차(카글 데이터 세트)와 테스트(컴포지션 데이터 세트) 데이터의 분포가 동일하면 메트릭 점수가 대략 같아야 한다(우리의 경우 정확도 점수)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-prague",
   "metadata": {
    "id": "rotary-prague",
    "papermill": {
     "duration": 0.025647,
     "end_time": "2021-05-30T18:39:32.952047",
     "exception": false,
     "start_time": "2021-05-30T18:39:32.926400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read And Combining train dataset (kaggle dataset)\n",
    "\n",
    "# 열차 데이터 세트 읽기 및 결합 (Kaggle 데이터 세트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "emotional-valuable",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:33.012157Z",
     "iopub.status.busy": "2021-05-30T18:39:33.011596Z",
     "iopub.status.idle": "2021-05-30T18:39:35.556063Z",
     "shell.execute_reply": "2021-05-30T18:39:35.555555Z",
     "shell.execute_reply.started": "2021-05-30T09:28:38.947982Z"
    },
    "id": "emotional-valuable",
    "papermill": {
     "duration": 2.57776,
     "end_time": "2021-05-30T18:39:35.556225",
     "exception": false,
     "start_time": "2021-05-30T18:39:32.978465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of class\n",
    "n_class = 5\n",
    "\n",
    "# path to kaggle dataset\n",
    "root_path = \"C:\\\\Users\\\\ngkim\\\\Downloads\\\\ClsKLData\\\\kneeKL224\\\\\"\n",
    "\n",
    "# list of folders\n",
    "folder_list = os.listdir(root_path)\n",
    "image_path_list = []\n",
    "label_list = []\n",
    "\n",
    "# for each folder, get the image path and labels\n",
    "for folder in folder_list:\n",
    "    for label in range(n_class):\n",
    "        \n",
    "        # get all the images path inside the current folder\n",
    "        image_list = os.listdir(f\"{root_path}{folder}/{label}\")\n",
    "        # add to the image path list\n",
    "        image_path_list += [ f\"{root_path}{folder}/{label}/\"+ path for path in image_list]\n",
    "        \n",
    "        # add labels to the label list\n",
    "        label_list += [label] * len(image_list)\n",
    "\n",
    "# convert to dataframe\n",
    "df_train_kaggle = pd.DataFrame({\"filepath\" : image_path_list, \"label\": label_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "signal-responsibility",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:35.618734Z",
     "iopub.status.busy": "2021-05-30T18:39:35.617931Z",
     "iopub.status.idle": "2021-05-30T18:39:35.621117Z",
     "shell.execute_reply": "2021-05-30T18:39:35.621576Z",
     "shell.execute_reply.started": "2021-05-30T09:28:40.244589Z"
    },
    "id": "signal-responsibility",
    "outputId": "9be7a788-1c7a-498d-a3e9-7b2c5e8455ab",
    "papermill": {
     "duration": 0.03629,
     "end_time": "2021-05-30T18:39:35.621716",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.585426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9786, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_kaggle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-greene",
   "metadata": {
    "id": "hairy-greene",
    "papermill": {
     "duration": 0.030406,
     "end_time": "2021-05-30T18:39:35.680660",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.650254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Observation\n",
    "we have total of 9786 images in kaggle dataset. We will use data to train the deep learning model\n",
    "# Lets look at class distribution\n",
    "\n",
    "## 관찰\n",
    "우리는 카글 데이터 세트에 총 9786개의 이미지를 가지고 있다. 우리는 딥 러닝 모델을 훈련시키기 위해 데이터를 사용할 것이다.\n",
    "# 학급분포를 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "therapeutic-spending",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:35.750000Z",
     "iopub.status.busy": "2021-05-30T18:39:35.749277Z",
     "iopub.status.idle": "2021-05-30T18:39:35.918362Z",
     "shell.execute_reply": "2021-05-30T18:39:35.918766Z",
     "shell.execute_reply.started": "2021-05-30T09:28:41.597346Z"
    },
    "id": "therapeutic-spending",
    "outputId": "0e179822-cb9f-4a56-b0c3-1f99705e882b",
    "papermill": {
     "duration": 0.208649,
     "end_time": "2021-05-30T18:39:35.918905",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.710256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEECAYAAADZBhiGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWTUlEQVR4nO3df6zdd33f8ecLk4YwSJsoN5nxTXDETLcka81y5aZFqvi5eITh0JHK0SBWx2SUJSuo1Yaz/QHV5Cmb+DHCSjRTQhwKRB6UxYIEZtxCxRowN6mJ4wQvbuMSYxMbaJVEbU3tvPfH+dz5yD6+3xtyzznXvs+H9NX5nvf3+/me9z0Cv/L9eVJVSJI0mxeMuwFJ0sJnWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoNPSySLEnyp0m+2N6fn2Rbksfa63l9696SZG+SPUmu7qtfmWRXW3Zbkgy7b0nScRn2fRZJfguYAs6tqjcn+a/Aj6vq1iQbgPOq6r1JLgM+C6wCXgZ8FXhlVR1LsgN4N/BN4F7gtqq6b7bPveCCC2r58uXD+8Mk6Qz0wAMP/LCqJk6sv3CYH5pkErgG2Aj8ViuvAV7T5jcDXwPe2+p3V9UR4PEke4FVSfbRC5r72zbvAq4FZg2L5cuXMz09PY9/jSSd+ZL8xaD6sA9D/Tfg3wPP9tUuqqqDAO31wlZfBjzRt97+VlvW5k+sS5JGZGhhkeTNwKGqemCuQwbUapb6oM9cn2Q6yfThw4fn+LGSpC7D3LN4NfCWdhjpbuB1SX4feDLJUoD2eqitvx+4uG/8JHCg1ScH1E9SVZuqaqqqpiYmTjrkJkn6KQ0tLKrqlqqarKrlwFrgD6vq7cBWYF1bbR1wT5vfCqxNcnaSS4EVwI52qOrpJFe1q6Bu6BsjSRqBoZ7gPoVbgS1J3gl8D7gOoKp2J9kCPAIcBW6qqmNtzI3AncA59E5sz3pyW5I0v4Z+6ey4TE1NlVdDSdJzk+SBqpo6se4d3JKkToaFJKnTOM5ZnBaWb/jSuFsAYN+t14y7BUlyz0KS1M2wkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ2GFhZJXpRkR5LvJNmd5Hda/f1Jvp9kZ5ve1DfmliR7k+xJcnVf/coku9qy25JkWH1Lkk42zB8/OgK8rqqeSXIW8I0k97VlH66qD/SvnOQyYC1wOfAy4KtJXllVx4DbgfXAN4F7gdXAfUiSRmJoexbV80x7e1abapYha4C7q+pIVT0O7AVWJVkKnFtV91dVAXcB1w6rb0nSyYZ6ziLJkiQ7gUPAtqr6Vlt0c5KHktyR5LxWWwY80Td8f6sta/Mn1iVJIzLUsKiqY1W1Epikt5dwBb1DSq8AVgIHgQ+21Qedh6hZ6idJsj7JdJLpw4cPP8/uJUkzRnI1VFX9FfA1YHVVPdlC5Fng48Cqttp+4OK+YZPAgVafHFAf9DmbqmqqqqYmJibm94+QpEVsmFdDTST5uTZ/DvAG4LvtHMSMtwIPt/mtwNokZye5FFgB7Kiqg8DTSa5qV0HdANwzrL4lSScb5tVQS4HNSZbQC6UtVfXFJJ9KspLeoaR9wLsAqmp3ki3AI8BR4KZ2JRTAjcCdwDn0roLySihJGqGhhUVVPQS8akD9HbOM2QhsHFCfBq6Y1wYlSXPmHdySpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqdPQwiLJi5LsSPKdJLuT/E6rn59kW5LH2ut5fWNuSbI3yZ4kV/fVr0yyqy27LUmG1bck6WTD3LM4Aryuqn4RWAmsTnIVsAHYXlUrgO3tPUkuA9YClwOrgY8lWdK2dTuwHljRptVD7FuSdIKhhUX1PNPentWmAtYAm1t9M3Btm18D3F1VR6rqcWAvsCrJUuDcqrq/qgq4q2+MJGkEhnrOIsmSJDuBQ8C2qvoWcFFVHQRorxe21ZcBT/QN399qy9r8ifVBn7c+yXSS6cOHD8/r3yJJi9lQw6KqjlXVSmCS3l7CFbOsPug8RM1SH/R5m6pqqqqmJiYmnnO/kqTBRnI1VFX9FfA1eucanmyHlmivh9pq+4GL+4ZNAgdafXJAXZI0IsO8Gmoiyc+1+XOANwDfBbYC69pq64B72vxWYG2Ss5NcSu9E9o52qOrpJFe1q6Bu6BsjSRqBFw5x20uBze2KphcAW6rqi0nuB7YkeSfwPeA6gKranWQL8AhwFLipqo61bd0I3AmcA9zXJknSiAwtLKrqIeBVA+o/Al5/ijEbgY0D6tPAbOc7JElD5B3ckqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkTsP8WVWdIZZv+NK4WwBg363XjLsFadEa2p5FkouT/FGSR5PsTvLuVn9/ku8n2dmmN/WNuSXJ3iR7klzdV78yya627LYkGVbfkqSTDXPP4ijw21X1YJKXAg8k2daWfbiqPtC/cpLLgLXA5cDLgK8meWVVHQNuB9YD3wTuBVYD9w2xd0lSn6HtWVTVwap6sM0/DTwKLJtlyBrg7qo6UlWPA3uBVUmWAudW1f1VVcBdwLXD6luSdLKRnOBOshx4FfCtVro5yUNJ7khyXqstA57oG7a/1Za1+RPrgz5nfZLpJNOHDx+ezz9Bkha1oYdFkpcAnwfeU1VP0Tuk9ApgJXAQ+ODMqgOG1yz1k4tVm6pqqqqmJiYmnm/rkqRmqGGR5Cx6QfHpqvoDgKp6sqqOVdWzwMeBVW31/cDFfcMngQOtPjmgLkkakWFeDRXgE8CjVfWhvvrSvtXeCjzc5rcCa5OcneRSYAWwo6oOAk8nuapt8wbgnmH1LUk62TCvhno18A5gV5KdrfYfgOuTrKR3KGkf8C6AqtqdZAvwCL0rqW5qV0IB3AjcCZxD7yoor4SSpBEaWlhU1TcYfL7h3lnGbAQ2DqhPA1fMX3eSpOfCx31IkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSeo0p7BIsn0uNUnSmWnWO7iTvAh4MXBBe5T4zB3Z59L7gSJJ0iLQ9biPdwHvoRcMD3A8LJ4Cfnd4bUmSFpJZw6KqPgJ8JMm/raqPjqgnSdICM6cHCVbVR5P8CrC8f0xV3TWkviRJC8icwiLJp+j9ut1OYOax4TO/hy1JOsPN9RHlU8BlVTXw50wlSWe2ud5n8TDw94fZiCRp4ZrrnsUFwCNJdgBHZopV9ZahdCVJWlDmGhbvH2YTkqSFbU6Hoarq64Om2cYkuTjJHyV5NMnuJO9u9fOTbEvyWHs9r2/MLUn2JtmT5Oq++pVJdrVltyUZ9HOtkqQhmevjPp5O8lSb/jbJsSRPdQw7Cvx2Vf0j4CrgpiSXARuA7VW1Atje3tOWrQUuB1YDH0uypG3rdmA9sKJNq5/TXylJel7mumfx0qo6t00vAv4F8N87xhysqgfb/NPAo8AyYA2wua22Gbi2za8B7q6qI1X1OLAXWJVkKXBuVd3frsa6q2+MJGkEfqqnzlbV/wJeN9f1kywHXgV8C7ioqg627RwELmyrLQOe6Bu2v9WWtfkT64M+Z32S6STThw8fnmt7kqQOc70p79f63r6A3n0Xc7rnIslLgM8D76mqp2Y53TBoQc1SP7lYtQnYBDA1NeU9IZI0T+Z6NdQ/75s/Cuyjd9hoVknOohcUn66qP2jlJ5MsraqD7RDToVbfD1zcN3wSONDqkwPqkqQRmeuzoX7juW64XbH0CeDRqvpQ36KtwDrg1vZ6T1/9M0k+RO8ptyuAHVV1rJ1gv4reYawbAB9qKEkjNNeroSaTfCHJoSRPJvl8ksmOYa8G3gG8LsnONr2JXki8McljwBvbe6pqN7AFeAT4MnBTVc08h+pG4PfonfT+M+C+5/ZnSpKej7kehvok8Bnguvb+7a32xlMNqKpvMPh8A8DrTzFmI7BxQH0auGKOvUqS5tlcr4aaqKpPVtXRNt0JTAyxL0nSAjLXsPhhkrcnWdKmtwM/GmZjkqSFY65h8a+AXwd+ABwE3gY855PekqTT01zPWfwnYF1V/SX0nu8EfIBeiEiSznBz3bP4hZmgAKiqH9O7I1uStAjMNSxecMLTYc9n7nslkqTT3Fz/wf8g8CdJPkfvURu/zoBLXKUz3fINXxp3CwDsu/WacbegRWaud3DflWSa3sMDA/xaVT0y1M4kSQvGnA8ltXAwICRpEfqpHlEuSVpcDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1GlpYJLmj/Qzrw3219yf5/gk/szqz7JYke5PsSXJ1X/3KJLvastvab3tLkkZomHsWdwKrB9Q/XFUr23QvQJLLgLXA5W3Mx5IsaevfDqwHVrRp0DYlSUM0tLCoqj8GfjzH1dcAd1fVkap6HNgLrEqyFDi3qu6vqgLuAq4dSsOSpFMaxzmLm5M81A5TzTz2fBnwRN86+1ttWZs/sS5JGqFRh8XtwCuAlfR+nvWDrT7oPETNUh8oyfok00mmDx8+/DxblSTNGGlYVNWTVXWsqp4FPg6saov2Axf3rToJHGj1yQH1U21/U1VNVdXUxMTE/DYvSYvYSMOinYOY8VZg5kqprcDaJGcnuZTeiewdVXUQeDrJVe0qqBuAe0bZsyRpiD+NmuSzwGuAC5LsB94HvCbJSnqHkvYB7wKoqt1JttD7vYyjwE1Vdaxt6kZ6V1adA9zXJknSCA0tLKrq+gHlT8yy/kYG/FRrVU0DV8xja5Kk58g7uCVJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSp6FdOivpzLZ8w5fG3QIA+269ZtwtLAruWUiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSp09DCIskdSQ4lebivdn6SbUkea6/n9S27JcneJHuSXN1XvzLJrrbstiQZVs+SpMGGuWdxJ7D6hNoGYHtVrQC2t/ckuQxYC1zexnwsyZI25nZgPbCiTSduU5I0ZEMLi6r6Y+DHJ5TXAJvb/Gbg2r763VV1pKoeB/YCq5IsBc6tqvurqoC7+sZIkkZk1OcsLqqqgwDt9cJWXwY80bfe/lZb1uZPrEuSRmihnOAedB6iZqkP3kiyPsl0kunDhw/PW3OStNiNOiyebIeWaK+HWn0/cHHfepPAgVafHFAfqKo2VdVUVU1NTEzMa+OStJiNOiy2Auva/Drgnr762iRnJ7mU3onsHe1Q1dNJrmpXQd3QN0aSNCJD+1nVJJ8FXgNckGQ/8D7gVmBLkncC3wOuA6iq3Um2AI8AR4GbqupY29SN9K6sOge4r02SpBEaWlhU1fWnWPT6U6y/Edg4oD4NXDGPrUmSnqOFcoJbkrSAGRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROYwmLJPuS7EqyM8l0q52fZFuSx9rreX3r35Jkb5I9Sa4eR8+StJiNc8/itVW1sqqm2vsNwPaqWgFsb+9JchmwFrgcWA18LMmScTQsSYvVQjoMtQbY3OY3A9f21e+uqiNV9TiwF1g1+vYkafEaV1gU8L+TPJBkfatdVFUHAdrrha2+DHiib+z+VpMkjcgLx/S5r66qA0kuBLYl+e4s62ZArQau2Aue9QCXXHLJ8+9SkgSMac+iqg6010PAF+gdVnoyyVKA9nqorb4fuLhv+CRw4BTb3VRVU1U1NTExMaz2JWnRGXlYJPl7SV46Mw/8U+BhYCuwrq22DrinzW8F1iY5O8mlwApgx2i7lqTFbRyHoS4CvpBk5vM/U1VfTvJtYEuSdwLfA64DqKrdSbYAjwBHgZuq6tgY+pakRWvkYVFVfw784oD6j4DXn2LMRmDjkFuTJJ3CQrp0VpK0QBkWkqROhoUkqZNhIUnqZFhIkjoZFpKkTuN63IcknTGWb/jSuFsAYN+t1wxt2+5ZSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKnTaRMWSVYn2ZNkb5IN4+5HkhaT0yIskiwBfhf4Z8BlwPVJLhtvV5K0eJwWYQGsAvZW1Z9X1U+Au4E1Y+5JkhaNVNW4e+iU5G3A6qr61+39O4BfqqqbT1hvPbC+vf15YM9IGz3ZBcAPx9zDQuF3cZzfxXF+F8ctlO/i5VU1cWLxdPk9iwyonZRyVbUJ2DT8duYmyXRVTY27j4XA7+I4v4vj/C6OW+jfxelyGGo/cHHf+0ngwJh6kaRF53QJi28DK5JcmuRngLXA1jH3JEmLxmlxGKqqjia5GfgKsAS4o6p2j7mtuVgwh8QWAL+L4/wujvO7OG5BfxenxQluSdJ4nS6HoSRJY2RYSJI6GRaSpE6nxQnu00WSf0jvzvJl9O4DOQBsrapHx9rYGLTvYhnwrap6pq++uqq+PL7ONE5JVgFVVd9uj+xZDXy3qu4dc2tjleSuqrph3H3MxhPc8yTJe4Hr6T2KZH8rT9K7zPfuqrp1XL2NWpLfBG4CHgVWAu+uqnvasger6p+Msb0FI8lvVNUnx93HqCR5H73nu70Q2Ab8EvA14A3AV6pq4/i6G50kJ172H+C1wB8CVNVbRt7UHBgW8yTJ/wUur6q/O6H+M8Duqloxns5GL8ku4Jer6pkky4HPAZ+qqo8k+dOqetV4O1wYknyvqi4Zdx+j0v53sRI4G/gBMFlVTyU5h94e6C+Ms79RSfIg8Ajwe/SOQAT4LL3/sKSqvj6+7k7Nw1Dz51ngZcBfnFBf2pYtJktmDj1V1b4krwE+l+TlDH50yxkryUOnWgRcNMpeFoCjVXUM+Oskf1ZVTwFU1d8kWUz/H5kC3g38R+DfVdXOJH+zUENihmExf94DbE/yGPBEq10C/APg5lMNOkP9IMnKqtoJ0PYw3gzcAfzjsXY2ehcBVwN/eUI9wJ+Mvp2x+kmSF1fVXwNXzhST/CyL6D+oqupZ4MNJ/md7fZLT4N/iBd/g6aKqvpzklfQep76M3j8G+4Fvt/+aWkxuAI72F6rqKHBDkv8xnpbG5ovAS2aCs1+Sr428m/H61ao6Av//H8wZZwHrxtPS+FTVfuC6JNcAT427ny6es5AkdfI+C0lSJ8NCktTJsJDmQZJnOpYvT/Lwc9zmne1XIqWxMywkSZ0MC2keJXlJku1JHkyyK8mavsUvTLI5yUNJPpfkxW3MlUm+nuSBJF9JsnRM7UunZFhI8+tvgbe2R5q8FvhgkpkbEX8e2NTuVH4K+DdJzgI+Crytqq6kdy/KonjshU4v3mchza8A/znJr9K70WwZx+/UfqKq/k+b/33gN4EvA1cA21qmLAEOjrRjaQ4MC2l+/UtgAriyqv4uyT7gRW3ZiTc1zTwXaHdV/fLoWpSeOw9DSfPrZ4FDLSheC7y8b9klSWZC4XrgG8AeYGKmnuSsJJePtGNpDgwLaX59GphKMk1vL+O7fcseBda1hwueD9xeVT8B3gb8lyTfAXYCvzLalqVuPu5DktTJPQtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ3+H7bhq4hJWvs6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_kaggle.label.value_counts().plot.bar()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-calendar",
   "metadata": {
    "id": "cognitive-calendar",
    "papermill": {
     "duration": 0.027966,
     "end_time": "2021-05-30T18:39:35.973791",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.945825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Observation\n",
    "As our dataset is imbalanced, we will balance our class by weighting majority class less and minoiry class more\n",
    "\n",
    "## 관찰\n",
    "데이터 세트가 불균형적이므로 다수 클래스는 덜 가중치 부여하고 소수 클래스는 더 가중치를 부여하여 클래스 균형을 맞출 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-enzyme",
   "metadata": {
    "id": "dense-enzyme",
    "papermill": {
     "duration": 0.028255,
     "end_time": "2021-05-30T18:39:36.030250",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.001995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DataGenerator train and validation\n",
    "We will use kaggle dataset as train set and compitition dataset as validation set. If train and validation metric is similar, it shows their distribution is similar and hence we can use kaggle dataset as well.\n",
    "\n",
    "# 데이터 생성기 교육 및 검증\n",
    "우리는 캐글 데이터 세트를 열차 세트로, 컴포지션 데이터 세트를 검증 세트로 사용할 것이다. 열차와 검증 메트릭이 유사한 경우 분포가 유사함을 보여주므로 캐글 데이터 세트도 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "encouraging-novel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:36.090553Z",
     "iopub.status.busy": "2021-05-30T18:39:36.089729Z",
     "iopub.status.idle": "2021-05-30T18:39:36.092340Z",
     "shell.execute_reply": "2021-05-30T18:39:36.091828Z",
     "shell.execute_reply.started": "2021-05-30T09:28:44.189248Z"
    },
    "id": "encouraging-novel",
    "papermill": {
     "duration": 0.035021,
     "end_time": "2021-05-30T18:39:36.092447",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.057426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train data generator object\n",
    "train_aug = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    "  )\n",
    "\n",
    "# validation data generator object\n",
    "valid_aug = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "geological-philadelphia",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:36.172890Z",
     "iopub.status.busy": "2021-05-30T18:39:36.167698Z",
     "iopub.status.idle": "2021-05-30T18:39:39.954054Z",
     "shell.execute_reply": "2021-05-30T18:39:39.954888Z",
     "shell.execute_reply.started": "2021-05-30T09:28:47.478488Z"
    },
    "id": "geological-philadelphia",
    "outputId": "358f5e4e-a7b9-4d32-d0be-5a08a4e27ace",
    "papermill": {
     "duration": 3.835127,
     "end_time": "2021-05-30T18:39:39.955083",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.119956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9786 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# create train generator\n",
    "train_generator = train_aug.flow_from_dataframe(\n",
    "    dataframe = df_train_kaggle,\n",
    "    directory = None,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 16,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-chest",
   "metadata": {
    "id": "asian-chest",
    "papermill": {
     "duration": 0.027295,
     "end_time": "2021-05-30T18:39:40.011354",
     "exception": false,
     "start_time": "2021-05-30T18:39:39.984059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create validation dataframe using compitition dataset.\n",
    "We will download compition dataset from gdrive and use it as validation set to validated against kaggle dataset\n",
    "\n",
    "# composition dataset을 이용하여 검증 데이터 프레임을 생성합니다.\n",
    "gdrive에서 컴포지션 데이터 세트를 다운로드하여 Kaggle 데이터 세트에 대해 검증된 검증 세트로 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "threaded-characterization",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.229132Z",
     "iopub.status.busy": "2021-05-30T18:40:02.228400Z",
     "iopub.status.idle": "2021-05-30T18:40:02.250117Z",
     "shell.execute_reply": "2021-05-30T18:40:02.250642Z",
     "shell.execute_reply.started": "2021-05-30T08:33:23.833280Z"
    },
    "id": "threaded-characterization",
    "outputId": "283093ce-0819-4542-9ff8-555713912e62",
    "papermill": {
     "duration": 0.059732,
     "end_time": "2021-05-30T18:40:02.250775",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.191043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  label\n",
       "0  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      0\n",
       "1  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      1\n",
       "2  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      0\n",
       "3  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      1\n",
       "4  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read Train.csv file which contains image names and labels and preprocess them\n",
    "compi_root_path = \"C:\\\\Users\\\\ngkim\\\\Downloads\\\\KneeXray\\\\\"\n",
    "df_val_compi = pd.read_csv(compi_root_path + \"Train.csv\")\n",
    "\n",
    "# add absolute path to the image names\n",
    "df_val_compi[\"filename\"] = df_val_compi.filename.apply(lambda x: compi_root_path+\"train/\" + x)\n",
    "df_val_compi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suburban-shareware",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.339459Z",
     "iopub.status.busy": "2021-05-30T18:40:02.324109Z",
     "iopub.status.idle": "2021-05-30T18:40:02.442504Z",
     "shell.execute_reply": "2021-05-30T18:40:02.442056Z",
     "shell.execute_reply.started": "2021-05-30T08:33:23.865039Z"
    },
    "id": "suburban-shareware",
    "outputId": "8fb91f05-54a6-4bc7-d95f-68ea55748335",
    "papermill": {
     "duration": 0.158988,
     "end_time": "2021-05-30T18:40:02.442618",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.283630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class count of compitition dataset\n",
    "df_val_compi.label.value_counts().plot.bar()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "saving-homework",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.529039Z",
     "iopub.status.busy": "2021-05-30T18:40:02.528305Z",
     "iopub.status.idle": "2021-05-30T18:40:02.574290Z",
     "shell.execute_reply": "2021-05-30T18:40:02.574903Z",
     "shell.execute_reply.started": "2021-05-30T08:54:21.600981Z"
    },
    "id": "saving-homework",
    "outputId": "178977a9-4413-4d38-b7f0-de8a9904b0e0",
    "papermill": {
     "duration": 0.098388,
     "end_time": "2021-05-30T18:40:02.575081",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.476693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7828 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# create validation generator\n",
    "valid_generator = valid_aug.flow_from_dataframe( \n",
    "    dataframe = df_val_compi,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 16,\n",
    "    seed = 42,\n",
    "    shuffle= True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-belarus",
   "metadata": {
    "id": "marked-belarus",
    "papermill": {
     "duration": 0.033792,
     "end_time": "2021-05-30T18:40:02.643887",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.610095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Architecture\n",
    "Here we will be using Xception by google. (I encourage you to try different architectures)\n",
    "\n",
    "## 모델 아키텍처\n",
    "여기서는 구글의 Xception을 사용할 것입니다. (다양한 아키텍처를 사용해 보십시오)\n",
    "\n",
    "## CheXNet - DenseNet121 + Sigmoid\n",
    "https://github.com/arnoweng/CheXNet/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "buried-tablet",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.724467Z",
     "iopub.status.busy": "2021-05-30T18:40:02.723830Z",
     "iopub.status.idle": "2021-05-30T18:40:08.132744Z",
     "shell.execute_reply": "2021-05-30T18:40:08.131632Z",
     "shell.execute_reply.started": "2021-05-30T09:28:56.068101Z"
    },
    "id": "buried-tablet",
    "outputId": "2be7f5dd-25c9-49e7-fce8-f3e1fbe9c6a1",
    "papermill": {
     "duration": 5.455093,
     "end_time": "2021-05-30T18:40:08.132878",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.677785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "xception = Xception(weights = \"imagenet\",)\n",
    "x =  xception.layers[-9].output\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 768, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 384, kernel_size= 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size= 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size= 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size= 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = n_class, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "GAP = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "pred = tf.keras.activations.softmax(GAP)\n",
    "\n",
    "xception_model = Model(inputs=xception.input,outputs = pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "DYVqXESmD_Fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYVqXESmD_Fd",
    "outputId": "88696012-6f00-42ba-d016-645743054fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 1024) 9438208     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10, 10, 1024) 4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 10, 10, 1024) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 10, 10, 768)  7078656     activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 10, 10, 768)  3072        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 10, 768)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 10, 10, 512)  3539456     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 10, 10, 512)  2048        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 10, 512)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 10, 10, 384)  1769856     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 10, 10, 384)  1536        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 10, 384)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 10, 10, 256)  884992      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 10, 10, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 10, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 10, 10, 128)  295040      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 10, 10, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 10, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 10, 10, 64)   73792       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 10, 10, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 10, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 10, 10, 32)   18464       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 10, 10, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 10, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 10, 10, 16)   4624        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 10, 10, 16)   64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 10, 16)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 10, 10, 5)    725         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 10, 10, 5)    20          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 10, 10, 5)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 5)            0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.softmax (TFOpLambda)      (None, 5)            0           global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 39,222,081\n",
      "Trainable params: 39,168,343\n",
      "Non-trainable params: 53,738\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "norman-detector",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:08.391663Z",
     "iopub.status.busy": "2021-05-30T18:40:08.385701Z",
     "iopub.status.idle": "2021-05-30T18:40:08.398432Z",
     "shell.execute_reply": "2021-05-30T18:40:08.397997Z",
     "shell.execute_reply.started": "2021-05-30T09:28:58.465217Z"
    },
    "id": "norman-detector",
    "papermill": {
     "duration": 0.226948,
     "end_time": "2021-05-30T18:40:08.398547",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.171599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "xception_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001, decay = 0.0001),\n",
    "    metrics = [\"acc\"],\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy)\n",
    "\n",
    "# callbacks and checkpoints\n",
    "checkpoint_path = \"xception_best.ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "my_callbacks = [\n",
    "              ModelCheckpoint(\n",
    "                   checkpoint_path,\n",
    "                   monitor = 'val_acc',\n",
    "                   verbose = 1,\n",
    "                   save_weights_only = True,\n",
    "                   save_best_only = True,\n",
    "                   mode = \"max\"\n",
    "                  ),\n",
    "              EarlyStopping(\n",
    "                   monitor = 'val_loss',\n",
    "                   patience = 10,\n",
    "                   verbose = 0\n",
    "                  ),\n",
    "              ReduceLROnPlateau(\n",
    "                   monitor = 'val_loss',\n",
    "                   patience = 10,\n",
    "                   verbose = 1\n",
    "                  )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-administration",
   "metadata": {
    "id": "crucial-administration",
    "papermill": {
     "duration": 0.038495,
     "end_time": "2021-05-30T18:40:08.475329",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.436834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Weighting classes\n",
    "As we have unevenly class distibution, we will weight them based on the number of samples\n",
    "\n",
    "### 가중치 클래스\n",
    "우리는 등급 차이가 일정하지 않기 때문에 샘플 수에 따라 무게를 재도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regional-indie",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:08.558435Z",
     "iopub.status.busy": "2021-05-30T18:40:08.557616Z",
     "iopub.status.idle": "2021-05-30T18:40:09.060821Z",
     "shell.execute_reply": "2021-05-30T18:40:09.060357Z",
     "shell.execute_reply.started": "2021-05-30T09:30:11.007618Z"
    },
    "id": "regional-indie",
    "papermill": {
     "duration": 0.546357,
     "end_time": "2021-05-30T18:40:09.060960",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.514603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes = np.unique(df_train_kaggle.label.values),\n",
    "    y = df_train_kaggle.label.values\n",
    "  )\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-better",
   "metadata": {
    "id": "square-better",
    "papermill": {
     "duration": 0.037503,
     "end_time": "2021-05-30T18:40:09.136492",
     "exception": false,
     "start_time": "2021-05-30T18:40:09.098989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train\n",
    "Lets roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hidden-stephen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:09.218272Z",
     "iopub.status.busy": "2021-05-30T18:40:09.217728Z",
     "iopub.status.idle": "2021-05-30T20:12:12.156502Z",
     "shell.execute_reply": "2021-05-30T20:12:12.154537Z",
     "shell.execute_reply.started": "2021-05-26T18:49:57.904339Z"
    },
    "id": "hidden-stephen",
    "outputId": "1432984b-6c8d-4523-de45-b163a07ed120",
    "papermill": {
     "duration": 5522.981999,
     "end_time": "2021-05-30T20:12:12.156678",
     "exception": false,
     "start_time": "2021-05-30T18:40:09.174679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "612/612 [==============================] - 93s 142ms/step - loss: 1.4920 - acc: 0.2710 - val_loss: 1.6534 - val_acc: 0.2664\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.26635, saving model to xception_best.ckpt\n",
      "Epoch 2/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 1.2904 - acc: 0.4235 - val_loss: 1.3378 - val_acc: 0.5255\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.26635 to 0.52555, saving model to xception_best.ckpt\n",
      "Epoch 3/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 1.1721 - acc: 0.5173 - val_loss: 1.2374 - val_acc: 0.5846\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.52555 to 0.58457, saving model to xception_best.ckpt\n",
      "Epoch 4/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 1.0816 - acc: 0.5666 - val_loss: 1.2290 - val_acc: 0.5766\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.58457\n",
      "Epoch 5/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.9941 - acc: 0.6315 - val_loss: 1.0970 - val_acc: 0.6803\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.58457 to 0.68025, saving model to xception_best.ckpt\n",
      "Epoch 6/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.9179 - acc: 0.6682 - val_loss: 1.1133 - val_acc: 0.6578\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.68025\n",
      "Epoch 7/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.8591 - acc: 0.7256 - val_loss: 0.9281 - val_acc: 0.7945\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.68025 to 0.79446, saving model to xception_best.ckpt\n",
      "Epoch 8/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.7844 - acc: 0.7797 - val_loss: 0.9457 - val_acc: 0.7804\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.79446\n",
      "Epoch 9/300\n",
      "612/612 [==============================] - 85s 139ms/step - loss: 0.7243 - acc: 0.8305 - val_loss: 0.8819 - val_acc: 0.8265\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.79446 to 0.82652, saving model to xception_best.ckpt\n",
      "Epoch 10/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.6749 - acc: 0.8655 - val_loss: 0.8472 - val_acc: 0.8398\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.82652 to 0.83981, saving model to xception_best.ckpt\n",
      "Epoch 11/300\n",
      "612/612 [==============================] - 85s 139ms/step - loss: 0.6297 - acc: 0.9004 - val_loss: 0.8100 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.83981 to 0.87877, saving model to xception_best.ckpt\n",
      "Epoch 12/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.6077 - acc: 0.9157 - val_loss: 0.8062 - val_acc: 0.8471\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.87877\n",
      "Epoch 13/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.5841 - acc: 0.9291 - val_loss: 0.7496 - val_acc: 0.9044\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.87877 to 0.90445, saving model to xception_best.ckpt\n",
      "Epoch 14/300\n",
      "612/612 [==============================] - 85s 139ms/step - loss: 0.5758 - acc: 0.9330 - val_loss: 0.6963 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.90445 to 0.93485, saving model to xception_best.ckpt\n",
      "Epoch 15/300\n",
      "612/612 [==============================] - 85s 139ms/step - loss: 0.5477 - acc: 0.9525 - val_loss: 0.6837 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.93485 to 0.94890, saving model to xception_best.ckpt\n",
      "Epoch 16/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.5395 - acc: 0.9541 - val_loss: 0.6740 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.94890 to 0.95031, saving model to xception_best.ckpt\n",
      "Epoch 17/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.5399 - acc: 0.9614 - val_loss: 0.7271 - val_acc: 0.9096\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95031\n",
      "Epoch 18/300\n",
      "612/612 [==============================] - 85s 140ms/step - loss: 0.5241 - acc: 0.9610 - val_loss: 0.6759 - val_acc: 0.9463\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.95031\n",
      "Epoch 19/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.5225 - acc: 0.9684 - val_loss: 0.6588 - val_acc: 0.9555\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.95031 to 0.95554, saving model to xception_best.ckpt\n",
      "Epoch 20/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.5097 - acc: 0.9708 - val_loss: 0.6519 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.95554 to 0.96180, saving model to xception_best.ckpt\n",
      "Epoch 21/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.5008 - acc: 0.9757 - val_loss: 0.6400 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.96180 to 0.96206, saving model to xception_best.ckpt\n",
      "Epoch 22/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4998 - acc: 0.9760 - val_loss: 0.6147 - val_acc: 0.9702\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.96206 to 0.97024, saving model to xception_best.ckpt\n",
      "Epoch 23/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4904 - acc: 0.9793 - val_loss: 0.6348 - val_acc: 0.9575\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.97024\n",
      "Epoch 24/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4901 - acc: 0.9798 - val_loss: 0.6256 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.97024\n",
      "Epoch 25/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4924 - acc: 0.9800 - val_loss: 0.5869 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.97024 to 0.97241, saving model to xception_best.ckpt\n",
      "Epoch 26/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4799 - acc: 0.9794 - val_loss: 0.6231 - val_acc: 0.9663\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.97241\n",
      "Epoch 27/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4758 - acc: 0.9815 - val_loss: 0.6312 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.97241\n",
      "Epoch 28/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4771 - acc: 0.9824 - val_loss: 0.6180 - val_acc: 0.9614\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.97241\n",
      "Epoch 29/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4754 - acc: 0.9847 - val_loss: 0.6490 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.97241\n",
      "Epoch 30/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4752 - acc: 0.9830 - val_loss: 0.5949 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.97241\n",
      "Epoch 31/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.4656 - acc: 0.9873 - val_loss: 0.5968 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.97241\n",
      "Epoch 32/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4642 - acc: 0.9857 - val_loss: 0.5635 - val_acc: 0.9785\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.97241 to 0.97854, saving model to xception_best.ckpt\n",
      "Epoch 33/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4638 - acc: 0.9877 - val_loss: 0.5668 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.97854\n",
      "Epoch 34/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4576 - acc: 0.9888 - val_loss: 0.5550 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.97854 to 0.98314, saving model to xception_best.ckpt\n",
      "Epoch 35/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4592 - acc: 0.9873 - val_loss: 0.5895 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.98314\n",
      "Epoch 36/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4535 - acc: 0.9884 - val_loss: 0.5560 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.98314 to 0.98403, saving model to xception_best.ckpt\n",
      "Epoch 37/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4533 - acc: 0.9902 - val_loss: 0.5530 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.98403\n",
      "Epoch 38/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4501 - acc: 0.9879 - val_loss: 0.5568 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.98403\n",
      "Epoch 39/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4505 - acc: 0.9899 - val_loss: 0.5840 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.98403\n",
      "Epoch 40/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4492 - acc: 0.9897 - val_loss: 0.5616 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.98403\n",
      "Epoch 41/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.4457 - acc: 0.9922 - val_loss: 0.5414 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.98403\n",
      "Epoch 42/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4462 - acc: 0.9919 - val_loss: 0.5932 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.98403\n",
      "Epoch 43/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4426 - acc: 0.9916 - val_loss: 0.5368 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.98403\n",
      "Epoch 44/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4440 - acc: 0.9911 - val_loss: 0.5526 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.98403\n",
      "Epoch 45/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4458 - acc: 0.9909 - val_loss: 0.5884 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.98403\n",
      "Epoch 46/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.4406 - acc: 0.9912 - val_loss: 0.5455 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.98403\n",
      "Epoch 47/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4357 - acc: 0.9931 - val_loss: 0.5200 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.98403 to 0.98697, saving model to xception_best.ckpt\n",
      "Epoch 48/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4361 - acc: 0.9916 - val_loss: 0.5314 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.98697\n",
      "Epoch 49/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4363 - acc: 0.9932 - val_loss: 0.5259 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.98697\n",
      "Epoch 50/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4287 - acc: 0.9942 - val_loss: 0.5302 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.98697\n",
      "Epoch 51/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4349 - acc: 0.9929 - val_loss: 0.5050 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.98697\n",
      "Epoch 52/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4250 - acc: 0.9944 - val_loss: 0.5091 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.98697\n",
      "Epoch 53/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4310 - acc: 0.9946 - val_loss: 0.5287 - val_acc: 0.9762\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.98697\n",
      "Epoch 54/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4216 - acc: 0.9956 - val_loss: 0.5285 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.98697\n",
      "Epoch 55/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4228 - acc: 0.9949 - val_loss: 0.5114 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.98697\n",
      "Epoch 56/300\n",
      "612/612 [==============================] - 87s 143ms/step - loss: 0.4294 - acc: 0.9944 - val_loss: 0.4965 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.98697 to 0.98838, saving model to xception_best.ckpt\n",
      "Epoch 57/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4193 - acc: 0.9951 - val_loss: 0.5065 - val_acc: 0.9847\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.98838\n",
      "Epoch 58/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4278 - acc: 0.9933 - val_loss: 0.4968 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.98838\n",
      "Epoch 59/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4246 - acc: 0.9944 - val_loss: 0.5088 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.98838\n",
      "Epoch 60/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4192 - acc: 0.9947 - val_loss: 0.4982 - val_acc: 0.9858\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.98838\n",
      "Epoch 61/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4165 - acc: 0.9954 - val_loss: 0.4971 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.98838\n",
      "Epoch 62/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4179 - acc: 0.9964 - val_loss: 0.4991 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.98838\n",
      "Epoch 63/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4140 - acc: 0.9940 - val_loss: 0.5367 - val_acc: 0.9696\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.98838\n",
      "Epoch 64/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4140 - acc: 0.9953 - val_loss: 0.5061 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.98838\n",
      "Epoch 65/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4175 - acc: 0.9954 - val_loss: 0.4940 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.98838\n",
      "Epoch 66/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4153 - acc: 0.9960 - val_loss: 0.4782 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.98838 to 0.98952, saving model to xception_best.ckpt\n",
      "Epoch 67/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4151 - acc: 0.9961 - val_loss: 0.5377 - val_acc: 0.9660\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.98952\n",
      "Epoch 68/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4154 - acc: 0.9959 - val_loss: 0.4902 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.98952\n",
      "Epoch 69/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4119 - acc: 0.9964 - val_loss: 0.4813 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.98952 to 0.98965, saving model to xception_best.ckpt\n",
      "Epoch 70/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4137 - acc: 0.9968 - val_loss: 0.5223 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.98965\n",
      "Epoch 71/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4099 - acc: 0.9967 - val_loss: 0.4938 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.98965\n",
      "Epoch 72/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4065 - acc: 0.9969 - val_loss: 0.4774 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.98965\n",
      "Epoch 73/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4062 - acc: 0.9979 - val_loss: 0.4890 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.98965\n",
      "Epoch 74/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4105 - acc: 0.9957 - val_loss: 0.4691 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.98965 to 0.99067, saving model to xception_best.ckpt\n",
      "Epoch 75/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4080 - acc: 0.9965 - val_loss: 0.4877 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.99067\n",
      "Epoch 76/300\n",
      "612/612 [==============================] - 85s 140ms/step - loss: 0.4076 - acc: 0.9974 - val_loss: 0.4756 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.99067\n",
      "Epoch 77/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4076 - acc: 0.9967 - val_loss: 0.4625 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.99067 to 0.99080, saving model to xception_best.ckpt\n",
      "Epoch 78/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4037 - acc: 0.9978 - val_loss: 0.4706 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.99080\n",
      "Epoch 79/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3978 - acc: 0.9976 - val_loss: 0.4671 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.99080 to 0.99182, saving model to xception_best.ckpt\n",
      "Epoch 80/300\n",
      "612/612 [==============================] - 85s 140ms/step - loss: 0.3985 - acc: 0.9971 - val_loss: 0.4681 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.99182\n",
      "Epoch 81/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4030 - acc: 0.9974 - val_loss: 0.4897 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.99182\n",
      "Epoch 82/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3985 - acc: 0.9967 - val_loss: 0.4665 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.99182\n",
      "Epoch 83/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4028 - acc: 0.9970 - val_loss: 0.4668 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.99182\n",
      "Epoch 84/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4039 - acc: 0.9962 - val_loss: 0.4712 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.99182\n",
      "Epoch 85/300\n",
      "612/612 [==============================] - 85s 140ms/step - loss: 0.3968 - acc: 0.9986 - val_loss: 0.4618 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.99182\n",
      "Epoch 86/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3985 - acc: 0.9954 - val_loss: 0.4643 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.99182\n",
      "Epoch 87/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4025 - acc: 0.9971 - val_loss: 0.4600 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.99182\n",
      "Epoch 88/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4005 - acc: 0.9959 - val_loss: 0.4664 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.99182\n",
      "Epoch 89/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3940 - acc: 0.9984 - val_loss: 0.4586 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.99182\n",
      "Epoch 90/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4037 - acc: 0.9975 - val_loss: 0.4596 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.99182\n",
      "Epoch 91/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3903 - acc: 0.9975 - val_loss: 0.4547 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.99182\n",
      "Epoch 92/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3964 - acc: 0.9981 - val_loss: 0.4560 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.99182\n",
      "Epoch 93/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3950 - acc: 0.9983 - val_loss: 0.4486 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.99182 to 0.99285, saving model to xception_best.ckpt\n",
      "Epoch 94/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3938 - acc: 0.9979 - val_loss: 0.4556 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.99285\n",
      "Epoch 95/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3950 - acc: 0.9975 - val_loss: 0.4514 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.99285\n",
      "Epoch 96/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3946 - acc: 0.9980 - val_loss: 0.4515 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.99285\n",
      "Epoch 97/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3909 - acc: 0.9979 - val_loss: 0.4517 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.99285\n",
      "Epoch 98/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3891 - acc: 0.9976 - val_loss: 0.4495 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.99285\n",
      "Epoch 99/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3923 - acc: 0.9979 - val_loss: 0.4509 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.99285\n",
      "Epoch 100/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3897 - acc: 0.9985 - val_loss: 0.4492 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.99285\n",
      "Epoch 101/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3882 - acc: 0.9993 - val_loss: 0.4429 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.99285\n",
      "Epoch 102/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3900 - acc: 0.9984 - val_loss: 0.4440 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.99285\n",
      "Epoch 103/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3876 - acc: 0.9979 - val_loss: 0.4487 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.99285\n",
      "Epoch 104/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3887 - acc: 0.9985 - val_loss: 0.4630 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.99285\n",
      "Epoch 105/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.3892 - acc: 0.9976 - val_loss: 0.4408 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.99285\n",
      "Epoch 106/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3851 - acc: 0.9976 - val_loss: 0.4494 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.99285\n",
      "Epoch 107/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3926 - acc: 0.9976 - val_loss: 0.4434 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.99285\n",
      "Epoch 108/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3840 - acc: 0.9978 - val_loss: 0.4404 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.99285\n",
      "Epoch 109/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3824 - acc: 0.9981 - val_loss: 0.4453 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.99285\n",
      "Epoch 110/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3883 - acc: 0.9982 - val_loss: 0.4564 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.99285\n",
      "Epoch 111/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3827 - acc: 0.9988 - val_loss: 0.4364 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00111: val_acc improved from 0.99285 to 0.99336, saving model to xception_best.ckpt\n",
      "Epoch 112/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3830 - acc: 0.9988 - val_loss: 0.4362 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00112: val_acc improved from 0.99336 to 0.99387, saving model to xception_best.ckpt\n",
      "Epoch 113/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3823 - acc: 0.9981 - val_loss: 0.4349 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.99387\n",
      "Epoch 114/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3794 - acc: 0.9987 - val_loss: 0.4476 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.99387\n",
      "Epoch 115/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3815 - acc: 0.9989 - val_loss: 0.4401 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.99387\n",
      "Epoch 116/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3824 - acc: 0.9989 - val_loss: 0.4331 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.99387\n",
      "Epoch 117/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3823 - acc: 0.9997 - val_loss: 0.4860 - val_acc: 0.9759\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.99387\n",
      "Epoch 118/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3798 - acc: 0.9989 - val_loss: 0.4378 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.99387\n",
      "Epoch 119/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3802 - acc: 0.9991 - val_loss: 0.4460 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.99387\n",
      "Epoch 120/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3840 - acc: 0.9972 - val_loss: 0.4386 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.99387\n",
      "Epoch 121/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3770 - acc: 0.9993 - val_loss: 0.4349 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.99387\n",
      "Epoch 122/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3776 - acc: 0.9993 - val_loss: 0.4293 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.99387\n",
      "Epoch 123/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3786 - acc: 0.9988 - val_loss: 0.4309 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.99387\n",
      "Epoch 124/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3792 - acc: 0.9990 - val_loss: 0.4297 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.99387\n",
      "Epoch 125/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3760 - acc: 0.9991 - val_loss: 0.4287 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.99387\n",
      "Epoch 126/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3728 - acc: 0.9996 - val_loss: 0.4400 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.99387\n",
      "Epoch 127/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3737 - acc: 0.9990 - val_loss: 0.4365 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.99387\n",
      "Epoch 128/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3718 - acc: 0.9985 - val_loss: 0.4283 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.99387\n",
      "Epoch 129/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3761 - acc: 0.9983 - val_loss: 0.4262 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.99387\n",
      "Epoch 130/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3750 - acc: 0.9990 - val_loss: 0.4258 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.99387\n",
      "Epoch 131/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3727 - acc: 0.9991 - val_loss: 0.4311 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.99387\n",
      "Epoch 132/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3715 - acc: 0.9991 - val_loss: 0.4304 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.99387\n",
      "Epoch 133/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3735 - acc: 0.9988 - val_loss: 0.4280 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.99387\n",
      "Epoch 134/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3673 - acc: 0.9990 - val_loss: 0.4451 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.99387\n",
      "Epoch 135/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3731 - acc: 0.9980 - val_loss: 0.4276 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.99387\n",
      "Epoch 136/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3739 - acc: 0.9992 - val_loss: 0.4270 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.99387\n",
      "Epoch 137/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3738 - acc: 0.9992 - val_loss: 0.4254 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.99387\n",
      "Epoch 138/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3710 - acc: 0.9992 - val_loss: 0.4272 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.99387\n",
      "Epoch 139/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3722 - acc: 0.9991 - val_loss: 0.4272 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.99387\n",
      "Epoch 140/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3714 - acc: 0.9987 - val_loss: 0.4257 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.99387\n",
      "Epoch 141/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3643 - acc: 0.9993 - val_loss: 0.4326 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.99387\n",
      "Epoch 142/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3658 - acc: 0.9987 - val_loss: 0.4275 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.99387\n",
      "Epoch 143/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3695 - acc: 0.9990 - val_loss: 0.4358 - val_acc: 0.9856\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.99387\n",
      "Epoch 144/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3687 - acc: 0.9986 - val_loss: 0.4134 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.99387\n",
      "Epoch 145/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3689 - acc: 0.9989 - val_loss: 0.4202 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.99387\n",
      "Epoch 146/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3687 - acc: 0.9988 - val_loss: 0.4153 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.99387\n",
      "Epoch 147/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3674 - acc: 0.9988 - val_loss: 0.4113 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.99387\n",
      "Epoch 148/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3668 - acc: 0.9995 - val_loss: 0.4115 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00148: val_acc improved from 0.99387 to 0.99476, saving model to xception_best.ckpt\n",
      "Epoch 149/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3675 - acc: 0.9991 - val_loss: 0.4194 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.99476\n",
      "Epoch 150/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3624 - acc: 0.9993 - val_loss: 0.4155 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.99476\n",
      "Epoch 151/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3686 - acc: 0.9992 - val_loss: 0.4158 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.99476\n",
      "Epoch 152/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3653 - acc: 0.9988 - val_loss: 0.4201 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.99476\n",
      "Epoch 153/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3655 - acc: 0.9989 - val_loss: 0.4102 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.99476\n",
      "Epoch 154/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3648 - acc: 0.9991 - val_loss: 0.4162 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.99476\n",
      "Epoch 155/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3660 - acc: 0.9993 - val_loss: 0.4144 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.99476\n",
      "Epoch 156/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3610 - acc: 0.9986 - val_loss: 0.4127 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.99476\n",
      "Epoch 157/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3635 - acc: 0.9996 - val_loss: 0.4104 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.99476\n",
      "Epoch 158/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3662 - acc: 0.9980 - val_loss: 0.4152 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.99476\n",
      "Epoch 159/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3680 - acc: 0.9992 - val_loss: 0.4135 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.99476\n",
      "Epoch 160/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3635 - acc: 0.9995 - val_loss: 0.4204 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.99476\n",
      "Epoch 161/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3639 - acc: 0.9990 - val_loss: 0.4094 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.99476\n",
      "Epoch 162/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3601 - acc: 0.9992 - val_loss: 0.4131 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.99476\n",
      "Epoch 163/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3625 - acc: 0.9996 - val_loss: 0.4081 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.99476\n",
      "Epoch 164/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3645 - acc: 0.9986 - val_loss: 0.4067 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.99476\n",
      "Epoch 165/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3647 - acc: 0.9990 - val_loss: 0.4080 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.99476\n",
      "Epoch 166/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3625 - acc: 0.9993 - val_loss: 0.4045 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.99476\n",
      "Epoch 167/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3592 - acc: 0.9990 - val_loss: 0.4177 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.99476\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3586 - acc: 0.9992 - val_loss: 0.4112 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.99476\n",
      "Epoch 169/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3554 - acc: 0.9994 - val_loss: 0.4042 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.99476\n",
      "Epoch 170/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3612 - acc: 0.9994 - val_loss: 0.4070 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.99476\n",
      "Epoch 171/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3596 - acc: 0.9995 - val_loss: 0.4251 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.99476\n",
      "Epoch 172/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3578 - acc: 0.9990 - val_loss: 0.4069 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.99476\n",
      "Epoch 173/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3590 - acc: 0.9993 - val_loss: 0.4025 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.99476\n",
      "Epoch 174/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3557 - acc: 0.9995 - val_loss: 0.4139 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.99476\n",
      "Epoch 175/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3567 - acc: 0.9991 - val_loss: 0.4290 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.99476\n",
      "Epoch 176/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3584 - acc: 0.9995 - val_loss: 0.4099 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.99476\n",
      "Epoch 177/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3597 - acc: 0.9992 - val_loss: 0.4057 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.99476\n",
      "Epoch 178/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3636 - acc: 0.9985 - val_loss: 0.4030 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.99476\n",
      "Epoch 179/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3544 - acc: 0.9997 - val_loss: 0.4052 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.99476\n",
      "Epoch 180/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3596 - acc: 0.9989 - val_loss: 0.4037 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.99476\n",
      "Epoch 181/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3577 - acc: 0.9993 - val_loss: 0.4049 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00181: val_acc improved from 0.99476 to 0.99502, saving model to xception_best.ckpt\n",
      "Epoch 182/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3554 - acc: 0.9992 - val_loss: 0.4061 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.99502\n",
      "Epoch 183/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3587 - acc: 0.9993 - val_loss: 0.4071 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.99502\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1b003534e20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "xception_model.fit(\n",
    "        train_generator,\n",
    "        epochs = 300,\n",
    "        validation_data = valid_generator,\n",
    "        callbacks = [my_callbacks],\n",
    "        class_weight = class_weights\n",
    "      )\n",
    "\n",
    "# load best saved weights\n",
    "xception_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-morris",
   "metadata": {
    "id": "pretty-morris",
    "papermill": {
     "duration": 3.201635,
     "end_time": "2021-05-30T20:12:18.344310",
     "exception": false,
     "start_time": "2021-05-30T20:12:15.142675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Observation\n",
    "As we can see train and validation accuracy is pretty close, which proves kaggle and competition data has come from the same distribution and we can freely use it to experiment with.\n",
    "\n",
    "## Retraining last trained model on competition data\n",
    "As we have used competition data as validation set previously, we will use it as train set now (and some part of it as validation set) hoping this additional training would give our model new information to perform better.\n",
    "\n",
    "## 관찰\n",
    "보시다시피 열차와 검증 정확도는 매우 가까우며, 이는 카글과 경쟁 데이터가 동일한 분포에서 나왔다는 것을 증명하며, 이를 실험하는 데 자유롭게 사용할 수 있습니다.\n",
    "\n",
    "## 경기 데이터에 대해 마지막으로 훈련된 모델 재교육\n",
    "이전에 경쟁 데이터를 검증 세트로 사용했으므로, 이제 열차 세트로 사용할 것이며(그리고 그 중 일부는 검증 세트로) 이 추가 교육을 통해 모델이 더 나은 성능을 발휘할 수 있는 새로운 정보를 얻을 수 있기를 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cloudy-idaho",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:24.238372Z",
     "iopub.status.busy": "2021-05-30T20:12:24.237660Z",
     "iopub.status.idle": "2021-05-30T20:12:24.305208Z",
     "shell.execute_reply": "2021-05-30T20:12:24.305579Z",
     "shell.execute_reply.started": "2021-05-30T09:30:16.948040Z"
    },
    "id": "cloudy-idaho",
    "papermill": {
     "duration": 3.027306,
     "end_time": "2021-05-30T20:12:24.305720",
     "exception": false,
     "start_time": "2021-05-30T20:12:21.278414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train and validation split on competition data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(\n",
    "    df_val_compi,\n",
    "    test_size = 0.1,\n",
    "    random_state = 42,\n",
    "    stratify = df_val_compi.label\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "nervous-crisis",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:30.429807Z",
     "iopub.status.busy": "2021-05-30T20:12:30.429001Z",
     "iopub.status.idle": "2021-05-30T20:12:30.472297Z",
     "shell.execute_reply": "2021-05-30T20:12:30.471634Z",
     "shell.execute_reply.started": "2021-05-30T09:30:18.098841Z"
    },
    "id": "nervous-crisis",
    "outputId": "bf1114cc-1f2d-4777-cef4-bd4eb24d75dd",
    "papermill": {
     "duration": 3.239148,
     "end_time": "2021-05-30T20:12:30.472465",
     "exception": false,
     "start_time": "2021-05-30T20:12:27.233317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7045 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_aug.flow_from_dataframe(\n",
    "    dataframe = X_train,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 16,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "instrumental-indie",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:36.309467Z",
     "iopub.status.busy": "2021-05-30T20:12:36.308631Z",
     "iopub.status.idle": "2021-05-30T20:12:36.318017Z",
     "shell.execute_reply": "2021-05-30T20:12:36.317530Z",
     "shell.execute_reply.started": "2021-05-30T09:30:23.206485Z"
    },
    "id": "instrumental-indie",
    "outputId": "dceb0588-b8e8-4658-a8e4-9c7f11fc65a0",
    "papermill": {
     "duration": 2.927421,
     "end_time": "2021-05-30T20:12:36.318129",
     "exception": false,
     "start_time": "2021-05-30T20:12:33.390708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 783 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = valid_aug.flow_from_dataframe( \n",
    "    dataframe = X_test,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 16,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dedicated-chapel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:42.897491Z",
     "iopub.status.busy": "2021-05-30T20:12:42.895853Z",
     "iopub.status.idle": "2021-05-30T20:12:42.898202Z",
     "shell.execute_reply": "2021-05-30T20:12:42.898602Z",
     "shell.execute_reply.started": "2021-05-30T09:30:26.966513Z"
    },
    "id": "dedicated-chapel",
    "papermill": {
     "duration": 3.108025,
     "end_time": "2021-05-30T20:12:42.898739",
     "exception": false,
     "start_time": "2021-05-30T20:12:39.790714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of steps to consider 1 as  epoch\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sized-norfolk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:48.820785Z",
     "iopub.status.busy": "2021-05-30T20:12:48.819337Z",
     "iopub.status.idle": "2021-05-30T20:25:26.371458Z",
     "shell.execute_reply": "2021-05-30T20:25:26.371941Z",
     "shell.execute_reply.started": "2021-05-30T09:30:36.962285Z"
    },
    "id": "sized-norfolk",
    "outputId": "fc9b987c-a11c-49f1-b98c-d4879cee12f6",
    "papermill": {
     "duration": 760.527609,
     "end_time": "2021-05-30T20:25:26.372105",
     "exception": false,
     "start_time": "2021-05-30T20:12:45.844496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "440/440 [==============================] - 57s 126ms/step - loss: 0.4918 - acc: 0.9819 - val_loss: 0.3723 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.99502 to 0.99870, saving model to xception_best.ckpt\n",
      "Epoch 2/50\n",
      "440/440 [==============================] - 55s 124ms/step - loss: 0.4784 - acc: 0.9886 - val_loss: 0.3782 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.99870\n",
      "Epoch 3/50\n",
      "440/440 [==============================] - 56s 126ms/step - loss: 0.4748 - acc: 0.9902 - val_loss: 0.3738 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99870\n",
      "Epoch 4/50\n",
      "440/440 [==============================] - 55s 125ms/step - loss: 0.4714 - acc: 0.9912 - val_loss: 0.3737 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99870\n",
      "Epoch 5/50\n",
      "440/440 [==============================] - 55s 125ms/step - loss: 0.4656 - acc: 0.9927 - val_loss: 0.3774 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99870\n",
      "Epoch 6/50\n",
      "440/440 [==============================] - 55s 124ms/step - loss: 0.4695 - acc: 0.9923 - val_loss: 0.3783 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99870\n",
      "Epoch 7/50\n",
      "440/440 [==============================] - 55s 124ms/step - loss: 0.4648 - acc: 0.9940 - val_loss: 0.3751 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99870\n",
      "Epoch 8/50\n",
      "440/440 [==============================] - 55s 125ms/step - loss: 0.4657 - acc: 0.9953 - val_loss: 0.3810 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99870\n",
      "Epoch 9/50\n",
      "440/440 [==============================] - 55s 125ms/step - loss: 0.4641 - acc: 0.9964 - val_loss: 0.3764 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.99870 to 1.00000, saving model to xception_best.ckpt\n",
      "Epoch 10/50\n",
      "440/440 [==============================] - 55s 125ms/step - loss: 0.4652 - acc: 0.9967 - val_loss: 0.3771 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 1.00000\n",
      "Epoch 11/50\n",
      "440/440 [==============================] - 55s 126ms/step - loss: 0.4672 - acc: 0.9950 - val_loss: 0.3782 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b04c42bb20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kick off training\n",
    "xception_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "        epochs = 50,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = STEP_SIZE_VALID,callbacks = [my_callbacks]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "complete-spelling",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:33.497837Z",
     "iopub.status.busy": "2021-05-30T20:25:33.496999Z",
     "iopub.status.idle": "2021-05-30T20:25:34.695800Z",
     "shell.execute_reply": "2021-05-30T20:25:34.695365Z",
     "shell.execute_reply.started": "2021-05-24T16:41:06.725854Z"
    },
    "id": "complete-spelling",
    "outputId": "10521e37-45bc-43e8-eae3-62b233e07b14",
    "papermill": {
     "duration": 4.566888,
     "end_time": "2021-05-30T20:25:34.695951",
     "exception": false,
     "start_time": "2021-05-30T20:25:30.129063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1b04c8c0fa0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best saved weights\n",
    "xception_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-cylinder",
   "metadata": {
    "id": "intended-cylinder",
    "papermill": {
     "duration": 3.633537,
     "end_time": "2021-05-30T20:25:41.743104",
     "exception": false,
     "start_time": "2021-05-30T20:25:38.109567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Confusion Matrix\n",
    "As our data set is imbalaned, lets see where is our model making mistakes. I encourage to you to take initative for bringing FPs and FNs down.\n",
    "\n",
    "# 혼란 매트릭스\n",
    "데이터 세트가 불균형 상태이므로 모델이 어디에서 실수를 하는지 살펴보자. FP와 FN을 끌어내리는데 솔선수범하길 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "equivalent-album",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:48.625234Z",
     "iopub.status.busy": "2021-05-30T20:25:48.624438Z",
     "iopub.status.idle": "2021-05-30T20:25:48.634216Z",
     "shell.execute_reply": "2021-05-30T20:25:48.633804Z",
     "shell.execute_reply.started": "2021-05-27T05:35:10.161826Z"
    },
    "id": "equivalent-album",
    "outputId": "2ed00c4a-4fd3-4d76-9ce5-6249f0da4489",
    "papermill": {
     "duration": 3.430239,
     "end_time": "2021-05-30T20:25:48.634343",
     "exception": false,
     "start_time": "2021-05-30T20:25:45.204104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 783 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "target_shape = 224\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# test generator\n",
    "compi_gen = valid_aug.flow_from_dataframe(\n",
    "    dataframe = X_test,\n",
    "    x_col = \"filename\",\n",
    "    class_mode = None,\n",
    "    target_size = (target_shape, target_shape),\n",
    "    shuffle = False,\n",
    "    batch_size = BATCH_SIZE\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "preceding-delight",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:56.117007Z",
     "iopub.status.busy": "2021-05-30T20:25:56.116264Z",
     "iopub.status.idle": "2021-05-30T20:26:05.659358Z",
     "shell.execute_reply": "2021-05-30T20:26:05.658569Z",
     "shell.execute_reply.started": "2021-05-27T05:35:17.324361Z"
    },
    "id": "preceding-delight",
    "outputId": "21817dd8-602c-4242-8998-5e3ae34e14e3",
    "papermill": {
     "duration": 12.914933,
     "end_time": "2021-05-30T20:26:05.659489",
     "exception": false,
     "start_time": "2021-05-30T20:25:52.744556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 6s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# prediction on train data\n",
    "predicition_compi = xception_model.predict(compi_gen, steps = compi_gen.n/ BATCH_SIZE, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "distinguished-midwest",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:12.667940Z",
     "iopub.status.busy": "2021-05-30T20:26:12.649791Z",
     "iopub.status.idle": "2021-05-30T20:26:13.051891Z",
     "shell.execute_reply": "2021-05-30T20:26:13.051413Z",
     "shell.execute_reply.started": "2021-05-27T05:43:44.837052Z"
    },
    "id": "distinguished-midwest",
    "outputId": "07a44daf-1bcd-454d-aa10-3c479b130443",
    "papermill": {
     "duration": 3.832152,
     "end_time": "2021-05-30T20:26:13.052010",
     "exception": false,
     "start_time": "2021-05-30T20:26:09.219858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1b5d1a46070>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "class_prediction_compi = np.argmax(predicition_compi, axis = 1)\n",
    "cm = confusion_matrix(X_test.label, class_prediction_compi, labels = [0, 1, 2, 3, 4])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix = cm,\n",
    "    display_labels = [0, 1, 2, 3, 4]\n",
    "  )\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-wilson",
   "metadata": {
    "id": "positive-wilson",
    "papermill": {
     "duration": 3.5306,
     "end_time": "2021-05-30T20:26:20.277590",
     "exception": false,
     "start_time": "2021-05-30T20:26:16.746990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Making prediction on test set (to make submission)\n",
    "Finally we save the predictions on disk in CSV format\n",
    "\n",
    "## 시험세트 예측하기 (제출하기)\n",
    "마지막으로 예측 내용을 CSV 형식으로 디스크에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "constitutional-catholic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:28.031789Z",
     "iopub.status.busy": "2021-05-30T20:26:28.031111Z",
     "iopub.status.idle": "2021-05-30T20:26:28.058944Z",
     "shell.execute_reply": "2021-05-30T20:26:28.058161Z",
     "shell.execute_reply.started": "2021-05-27T09:08:20.550041Z"
    },
    "id": "constitutional-catholic",
    "outputId": "91b6393c-4cdf-45ff-f39e-2eb2a0d17012",
    "papermill": {
     "duration": 4.034446,
     "end_time": "2021-05-30T20:26:28.059074",
     "exception": false,
     "start_time": "2021-05-30T20:26:24.024628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1958 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# read the csv file\n",
    "test = pd.read_csv(compi_root_path + \"Test.csv\")\n",
    "\n",
    "# create test generator\n",
    "test_generator = valid_aug.flow_from_dataframe(\n",
    "    dataframe = test,\n",
    "    directory = compi_root_path + \"test\",\n",
    "    x_col = \"filename\",\n",
    "    y_col = None,\n",
    "    batch_size = 1,\n",
    "    seed = 42,\n",
    "    shuffle = False,\n",
    "    class_mode = None,\n",
    "    target_size = (224,224)\n",
    "  )\n",
    "\n",
    "# number of steps to consider 1 epoch\n",
    "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "blocked-niagara",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:34.994605Z",
     "iopub.status.busy": "2021-05-30T20:26:34.994000Z",
     "iopub.status.idle": "2021-05-30T20:26:56.340759Z",
     "shell.execute_reply": "2021-05-30T20:26:56.341118Z",
     "shell.execute_reply.started": "2021-05-27T05:51:39.116529Z"
    },
    "id": "blocked-niagara",
    "outputId": "e8ed2e21-e61a-40ca-9976-0c87f7f7e9fa",
    "papermill": {
     "duration": 24.791614,
     "end_time": "2021-05-30T20:26:56.341303",
     "exception": false,
     "start_time": "2021-05-30T20:26:31.549689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958/1958 [==============================] - 13s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    767\n",
       "2    519\n",
       "1    356\n",
       "3    257\n",
       "4     59\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction and create dataframe out of it\n",
    "pred = xception_model.predict(test_generator,steps=STEP_SIZE_TEST,verbose=1)\n",
    "df_submit = pd.DataFrame({\"label\":np.argmax(pred, axis= 1)})\n",
    "df_submit[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-arthur",
   "metadata": {
    "id": "still-arthur",
    "papermill": {
     "duration": 3.549425,
     "end_time": "2021-05-30T20:27:04.148458",
     "exception": false,
     "start_time": "2021-05-30T20:27:00.599033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Clearing the working directory\n",
    "Because if don't, \"output\" tabl will show only images\n",
    "\n",
    "### 작업 디렉토리 지우기\n",
    "그렇지 않으면 \"출력\" 탭이 이미지만 표시되기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "decimal-hampshire",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:27:11.522864Z",
     "iopub.status.busy": "2021-05-30T20:27:11.522085Z",
     "iopub.status.idle": "2021-05-30T20:27:11.842332Z",
     "shell.execute_reply": "2021-05-30T20:27:11.842916Z",
     "shell.execute_reply.started": "2021-05-27T05:51:43.875589Z"
    },
    "id": "decimal-hampshire",
    "outputId": "bba496cf-d002-4106-cb8c-29be6b8078d2",
    "papermill": {
     "duration": 4.080149,
     "end_time": "2021-05-30T20:27:11.843118",
     "exception": false,
     "start_time": "2021-05-30T20:27:07.762969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: /kaggle/working - 지정된 경로를 찾을 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import shutil\n",
    "\n",
    "# Get directory name\n",
    "mydir = \"/kaggle/working\"\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(mydir)\n",
    "except OSError as e:\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-yacht",
   "metadata": {
    "id": "portable-yacht",
    "papermill": {
     "duration": 3.504245,
     "end_time": "2021-05-30T20:27:18.913681",
     "exception": false,
     "start_time": "2021-05-30T20:27:15.409436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Save best weights and output prediction file\n",
    "\n",
    "### 최적의 가중치 및 출력 예측 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "liquid-tsunami",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:27:26.290338Z",
     "iopub.status.busy": "2021-05-30T20:27:26.289493Z",
     "iopub.status.idle": "2021-05-30T20:27:26.809425Z",
     "shell.execute_reply": "2021-05-30T20:27:26.808879Z",
     "shell.execute_reply.started": "2021-05-27T05:51:46.57395Z"
    },
    "id": "liquid-tsunami",
    "papermill": {
     "duration": 4.073647,
     "end_time": "2021-05-30T20:27:26.809566",
     "exception": false,
     "start_time": "2021-05-30T20:27:22.735919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xception_model.save_weights(\"knee_xray_Xceptionnet_GPA.h5\")\n",
    "df_submit.to_csv(\"submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-baptist",
   "metadata": {
    "id": "sustainable-baptist",
    "papermill": {
     "duration": 3.563445,
     "end_time": "2021-05-30T20:27:34.549379",
     "exception": false,
     "start_time": "2021-05-30T20:27:30.985934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The submission results in 96.8% on public leaderboard.\n",
    "\n",
    "**Suggestion to improve the score**\n",
    "* Using right data augmentations\n",
    "* Using different model architecture\n",
    "* Ensembling and stacking\n",
    "* Using pretrained model trained on xray images\n",
    "\n",
    "제출 결과 공개 리더보드에서 96.8%의 결과가 나왔습니다.\n",
    "\n",
    "**점수 향상을 위한 제안*\n",
    "* 올바른 데이터 확대 사용\n",
    "* 다른 모델 아키텍처 사용\n",
    "* 조립 및 쌓기\n",
    "* X선 영상에 대해 사전 훈련된 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dcc9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "KLGrade-DenseNet121-91.83.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6499.620651,
   "end_time": "2021-05-30T20:27:40.898205",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-30T18:39:21.277554",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
