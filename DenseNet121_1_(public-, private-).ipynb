{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet121_1_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/DenseNet121_1_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb246ab-a598-4ed2-ca4f-ecc4f3cc2122"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 27 18:10:16 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3812354-8192-42f3-cfb4-3a0564ab79a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "model_save = 'DenseNet121_1'\n",
        "Target_model = 'DenseNet121_model'\n",
        "Target_predict = 'DenseNet121_predict'\n",
        "Target_acc = 'DenseNet121_acc'\n",
        "Target_val = 'DenseNet121_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.InceptionV3(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06f2e3d-cad3-4a6e-91f8-83c68b49d0d8"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7161d1a1-bbf6-4588-d6ed-36484c1dad52"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 40s 72ms/step - loss: 2.0190 - accuracy: 0.3516 - val_loss: 6.4301 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 2/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 1.1711 - accuracy: 0.6179 - val_loss: 6.8407 - val_accuracy: 0.0946\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10135\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.8741 - accuracy: 0.7284 - val_loss: 1.3579 - val_accuracy: 0.6419\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.10135 to 0.64189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.7962 - accuracy: 0.7589 - val_loss: 1.7880 - val_accuracy: 0.4865\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.64189\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.7276 - accuracy: 0.7795 - val_loss: 1.0323 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.64189 to 0.75676, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.6819 - accuracy: 0.7879 - val_loss: 0.8670 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.75676 to 0.76351, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.5562 - accuracy: 0.8263 - val_loss: 1.6760 - val_accuracy: 0.6486\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.76351\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.5529 - accuracy: 0.8200 - val_loss: 1.2691 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.76351\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.4902 - accuracy: 0.8389 - val_loss: 0.7275 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.76351 to 0.77027, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.4514 - accuracy: 0.8537 - val_loss: 0.7302 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.77027 to 0.79054, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.4623 - accuracy: 0.8511 - val_loss: 0.8500 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.79054\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.4372 - accuracy: 0.8611 - val_loss: 0.6834 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.79054 to 0.81757, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.4064 - accuracy: 0.8632 - val_loss: 0.5117 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.81757 to 0.83784, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.3361 - accuracy: 0.8974 - val_loss: 0.7074 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.83784\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.3481 - accuracy: 0.8832 - val_loss: 0.6099 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.83784\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.4148 - accuracy: 0.8679 - val_loss: 0.5207 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.83784 to 0.84459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.3531 - accuracy: 0.8821 - val_loss: 0.7222 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.84459\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.3191 - accuracy: 0.9005 - val_loss: 0.4739 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.84459\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.2987 - accuracy: 0.9053 - val_loss: 0.5063 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.84459 to 0.86486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.2717 - accuracy: 0.9084 - val_loss: 0.5946 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.86486\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.3338 - accuracy: 0.8974 - val_loss: 0.4100 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.86486 to 0.88514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.2299 - accuracy: 0.9258 - val_loss: 0.4116 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.88514 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.2997 - accuracy: 0.9047 - val_loss: 0.5462 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.90541\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2472 - accuracy: 0.9179 - val_loss: 0.6302 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.90541\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.2158 - accuracy: 0.9284 - val_loss: 0.5209 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.90541\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2105 - accuracy: 0.9321 - val_loss: 0.6405 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.90541\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2785 - accuracy: 0.9163 - val_loss: 0.4126 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.90541\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2473 - accuracy: 0.9263 - val_loss: 0.3594 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.90541\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1880 - accuracy: 0.9421 - val_loss: 0.8087 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.90541\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.2126 - accuracy: 0.9289 - val_loss: 0.4961 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.90541\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1864 - accuracy: 0.9379 - val_loss: 0.4944 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.90541\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1903 - accuracy: 0.9384 - val_loss: 0.6053 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.90541\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1550 - accuracy: 0.9474 - val_loss: 0.5203 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.90541\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1725 - accuracy: 0.9442 - val_loss: 0.4209 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.90541\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1522 - accuracy: 0.9495 - val_loss: 0.4096 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.90541\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.2095 - accuracy: 0.9384 - val_loss: 0.5436 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.90541\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1464 - accuracy: 0.9489 - val_loss: 0.6416 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.90541\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1473 - accuracy: 0.9463 - val_loss: 0.5061 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.90541\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1470 - accuracy: 0.9558 - val_loss: 0.4236 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.1416 - accuracy: 0.9532 - val_loss: 0.4561 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91216\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1847 - accuracy: 0.9453 - val_loss: 0.6340 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91216\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1557 - accuracy: 0.9489 - val_loss: 0.4048 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91216\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1260 - accuracy: 0.9568 - val_loss: 0.5149 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91216\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.0999 - accuracy: 0.9679 - val_loss: 0.3114 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91216\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1043 - accuracy: 0.9647 - val_loss: 0.6762 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91216\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1198 - accuracy: 0.9637 - val_loss: 0.4572 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91216\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0809 - accuracy: 0.9700 - val_loss: 0.5607 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91216\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1718 - accuracy: 0.9447 - val_loss: 0.4771 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91216\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.0951 - accuracy: 0.9679 - val_loss: 0.5578 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91216\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1068 - accuracy: 0.9684 - val_loss: 0.6504 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91216\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.0783 - accuracy: 0.9763 - val_loss: 0.5879 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91216\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0906 - accuracy: 0.9721 - val_loss: 0.4350 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91216\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1101 - accuracy: 0.9626 - val_loss: 0.6103 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91216\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0786 - accuracy: 0.9758 - val_loss: 0.3760 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91216\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0705 - accuracy: 0.9768 - val_loss: 0.5389 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91216\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1121 - accuracy: 0.9689 - val_loss: 0.4608 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91216\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1183 - accuracy: 0.9616 - val_loss: 0.3629 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91216\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0751 - accuracy: 0.9758 - val_loss: 0.4307 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91216\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0498 - accuracy: 0.9868 - val_loss: 0.5311 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91216\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0746 - accuracy: 0.9768 - val_loss: 0.7020 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91216\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0901 - accuracy: 0.9732 - val_loss: 0.9419 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91216\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1068 - accuracy: 0.9642 - val_loss: 0.7314 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91216\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0851 - accuracy: 0.9784 - val_loss: 0.6704 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91216\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0468 - accuracy: 0.9837 - val_loss: 0.5551 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91216\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0513 - accuracy: 0.9826 - val_loss: 0.7980 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91216\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0721 - accuracy: 0.9779 - val_loss: 0.6367 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91216\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1005 - accuracy: 0.9679 - val_loss: 0.5370 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91216\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0889 - accuracy: 0.9732 - val_loss: 0.4040 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91216\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0595 - accuracy: 0.9800 - val_loss: 0.5353 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91216\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0630 - accuracy: 0.9805 - val_loss: 0.3648 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91216\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.0467 - accuracy: 0.9879 - val_loss: 0.5019 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91216\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0606 - accuracy: 0.9768 - val_loss: 0.6228 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91216\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0688 - accuracy: 0.9784 - val_loss: 0.5326 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91216\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0804 - accuracy: 0.9726 - val_loss: 0.4984 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91216\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0405 - accuracy: 0.9858 - val_loss: 0.4578 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91216\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.0333 - accuracy: 0.9916 - val_loss: 0.5673 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91216\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0534 - accuracy: 0.9832 - val_loss: 0.5850 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91216\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0569 - accuracy: 0.9805 - val_loss: 0.6137 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91216\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0420 - accuracy: 0.9853 - val_loss: 0.6642 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91216\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0519 - accuracy: 0.9832 - val_loss: 0.4333 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91216\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0675 - accuracy: 0.9768 - val_loss: 0.5086 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00081: val_accuracy improved from 0.91216 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0731 - accuracy: 0.9747 - val_loss: 0.4940 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.92568\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0745 - accuracy: 0.9784 - val_loss: 0.5483 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.92568\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0460 - accuracy: 0.9863 - val_loss: 0.6376 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.92568\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.0344 - accuracy: 0.9889 - val_loss: 0.4804 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.92568\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.5122 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.92568\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0310 - accuracy: 0.9889 - val_loss: 0.4438 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.92568\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0464 - accuracy: 0.9837 - val_loss: 0.4435 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.92568\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0628 - accuracy: 0.9800 - val_loss: 0.5970 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.92568\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.0691 - accuracy: 0.9768 - val_loss: 0.5242 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.92568\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.4171 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.92568\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0484 - accuracy: 0.9853 - val_loss: 0.2696 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.92568\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0288 - accuracy: 0.9889 - val_loss: 0.4044 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.92568\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0371 - accuracy: 0.9879 - val_loss: 0.5506 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.92568\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0545 - accuracy: 0.9816 - val_loss: 0.4394 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.92568\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0665 - accuracy: 0.9774 - val_loss: 0.8180 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.92568\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0466 - accuracy: 0.9816 - val_loss: 0.5101 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.92568\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0283 - accuracy: 0.9905 - val_loss: 0.6098 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.92568\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0495 - accuracy: 0.9847 - val_loss: 0.4513 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.92568\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0361 - accuracy: 0.9842 - val_loss: 0.4311 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.92568\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0424 - accuracy: 0.9853 - val_loss: 0.5272 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.92568\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.0292 - accuracy: 0.9895 - val_loss: 0.4340 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.92568\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 0.3265 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.92568\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0547 - accuracy: 0.9821 - val_loss: 0.4844 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.92568\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0337 - accuracy: 0.9895 - val_loss: 0.4005 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.92568\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0239 - accuracy: 0.9900 - val_loss: 0.4066 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.92568\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0609 - accuracy: 0.9826 - val_loss: 0.4715 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.92568\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0325 - accuracy: 0.9874 - val_loss: 0.5879 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.92568\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0296 - accuracy: 0.9916 - val_loss: 0.4922 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.92568\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.5884 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.92568\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.5182 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.92568\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0466 - accuracy: 0.9853 - val_loss: 0.8766 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.92568\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0469 - accuracy: 0.9863 - val_loss: 0.6251 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.92568\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0310 - accuracy: 0.9879 - val_loss: 0.5233 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.92568\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 0.3775 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.92568\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.5054 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.92568\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0504 - accuracy: 0.9847 - val_loss: 0.6402 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.92568\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0339 - accuracy: 0.9874 - val_loss: 0.8036 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.92568\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.5562 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.92568\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0222 - accuracy: 0.9916 - val_loss: 0.3558 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.92568\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0147 - accuracy: 0.9926 - val_loss: 0.4340 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.92568\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0335 - accuracy: 0.9911 - val_loss: 0.4195 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.92568\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.4832 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.92568\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.3659 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.92568\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0546 - accuracy: 0.9863 - val_loss: 0.9462 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.92568\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0511 - accuracy: 0.9832 - val_loss: 0.5103 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.92568\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0288 - accuracy: 0.9921 - val_loss: 0.4991 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.92568\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0313 - accuracy: 0.9889 - val_loss: 0.5434 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.92568\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0285 - accuracy: 0.9895 - val_loss: 0.4536 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.92568\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.5461 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.92568\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.5937 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.92568\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0240 - accuracy: 0.9911 - val_loss: 0.5268 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.92568\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 0.5993 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.92568\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0527 - accuracy: 0.9826 - val_loss: 0.3742 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.92568\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.4593 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.92568\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0180 - accuracy: 0.9921 - val_loss: 0.5564 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.92568\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0387 - accuracy: 0.9905 - val_loss: 0.4724 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.92568\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0356 - accuracy: 0.9895 - val_loss: 0.3590 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.92568\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.5926 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.92568\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0346 - accuracy: 0.9921 - val_loss: 0.5657 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.92568\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.0337 - accuracy: 0.9884 - val_loss: 0.8638 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.92568\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0297 - accuracy: 0.9932 - val_loss: 0.4341 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.92568\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.5246 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.92568\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.3076 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.92568\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.5959 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.92568\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.5588 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.92568\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.6343 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.92568\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0339 - accuracy: 0.9900 - val_loss: 0.5146 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.92568\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0588 - accuracy: 0.9853 - val_loss: 0.4161 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.92568\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0179 - accuracy: 0.9926 - val_loss: 0.4889 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.92568\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.2969 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.92568\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.4886 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.92568\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.3623 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.92568\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 0.5860 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92568\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0421 - accuracy: 0.9895 - val_loss: 0.5753 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92568\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.4428 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92568\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 0.4595 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92568\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.5883 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92568\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0087 - accuracy: 0.9953 - val_loss: 0.3383 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92568\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0278 - accuracy: 0.9911 - val_loss: 0.3186 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92568\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0441 - accuracy: 0.9858 - val_loss: 0.5455 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92568\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.3874 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92568\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 0.6719 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92568\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.3935 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92568\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.7107 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92568\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.6420 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92568\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.6112 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92568\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0391 - accuracy: 0.9905 - val_loss: 0.6477 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92568\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0344 - accuracy: 0.9905 - val_loss: 0.5828 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92568\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.8544 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92568\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0150 - accuracy: 0.9937 - val_loss: 0.6416 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92568\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.6730 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92568\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.6014 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92568\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.6787 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92568\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 0.5023 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92568\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0323 - accuracy: 0.9911 - val_loss: 0.7304 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92568\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0276 - accuracy: 0.9895 - val_loss: 0.3376 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00177: val_accuracy improved from 0.92568 to 0.95946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_1.h5\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.4316 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.95946\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.4867 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.95946\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 0.5259 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.95946\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 0.5228 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.95946\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0327 - accuracy: 0.9916 - val_loss: 0.6679 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.95946\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.8085 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.95946\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.4751 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.95946\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.5086 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.95946\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.4238 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.95946\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.4273 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.95946\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.4551 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.95946\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.4318 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.95946\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.4095 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.95946\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0143 - accuracy: 0.9937 - val_loss: 0.5397 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.95946\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0302 - accuracy: 0.9900 - val_loss: 0.5238 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.95946\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0475 - accuracy: 0.9868 - val_loss: 0.6715 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.95946\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.5460 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.95946\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.5459 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.95946\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.5479 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.95946\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0327 - accuracy: 0.9895 - val_loss: 0.4451 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.95946\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.7935 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.95946\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 0.7614 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.95946\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 0.6368 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.95946\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.6422 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.95946\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.8126 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.95946\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0216 - accuracy: 0.9916 - val_loss: 0.7043 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.95946\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.7468 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.95946\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0126 - accuracy: 0.9947 - val_loss: 0.6441 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.95946\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.5662 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.95946\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.5172 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.95946\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.5977 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.95946\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0112 - accuracy: 0.9942 - val_loss: 0.5396 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.95946\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0108 - accuracy: 0.9953 - val_loss: 0.6454 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.95946\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0317 - accuracy: 0.9889 - val_loss: 0.5622 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.95946\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.3538 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.95946\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4745 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.95946\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.5784 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.95946\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.7966 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.95946\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0354 - accuracy: 0.9921 - val_loss: 0.4778 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.95946\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0175 - accuracy: 0.9932 - val_loss: 0.5766 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.95946\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0206 - accuracy: 0.9926 - val_loss: 0.4938 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.95946\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.4393 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.95946\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.4489 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.95946\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.8055 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.95946\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0223 - accuracy: 0.9947 - val_loss: 0.9135 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.95946\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.9591 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.95946\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0235 - accuracy: 0.9953 - val_loss: 0.5753 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.95946\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.7625 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.95946\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.6470 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.95946\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0100 - accuracy: 0.9953 - val_loss: 0.5239 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.95946\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.3555 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.95946\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.4144 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.95946\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.6850 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.95946\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.6169 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.95946\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0047 - accuracy: 0.9974 - val_loss: 0.3326 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.95946\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.5513 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.95946\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.95946\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 3.7494e-04 - accuracy: 1.0000 - val_loss: 0.4809 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.95946\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 2.9686e-04 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.95946\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 3.5913e-04 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.95946\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 1.6193e-04 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.95946\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0604 - accuracy: 0.9879 - val_loss: 0.7285 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.95946\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0759 - accuracy: 0.9789 - val_loss: 0.5398 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.95946\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0328 - accuracy: 0.9905 - val_loss: 0.4631 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.95946\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.2925 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.95946\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.3890 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.95946\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.6046 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.95946\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 0.5973 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.95946\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.4858 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.95946\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0302 - accuracy: 0.9921 - val_loss: 0.5039 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.95946\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.4207 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.95946\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.4906 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.95946\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.4178 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.95946\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4290 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.95946\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.5101 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.95946\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0439 - accuracy: 0.9874 - val_loss: 0.7197 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.95946\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.9361 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.95946\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.6622 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.95946\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.7344 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.95946\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.7720 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.95946\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.8074 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.95946\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.7018 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.95946\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.5382 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.95946\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4899 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.95946\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.5193 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.95946\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0345 - accuracy: 0.9921 - val_loss: 0.7668 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.95946\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0069 - accuracy: 0.9968 - val_loss: 0.4483 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.95946\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.6927 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.95946\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.7141 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.95946\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0167 - accuracy: 0.9968 - val_loss: 0.6540 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.95946\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0264 - accuracy: 0.9932 - val_loss: 0.6553 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.95946\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0394 - accuracy: 0.9889 - val_loss: 0.5959 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.95946\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0118 - accuracy: 0.9947 - val_loss: 0.3884 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.95946\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.95946\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 6.9874e-04 - accuracy: 1.0000 - val_loss: 0.4582 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.95946\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 4.8028e-04 - accuracy: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.95946\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.2950 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.95946\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.5074 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.95946\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.7188 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.95946\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.8571 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.95946\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0161 - accuracy: 0.9968 - val_loss: 0.5868 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.95946\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.7745 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.95946\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.7256 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.95946\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.6171 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.95946\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0032 - accuracy: 0.9979 - val_loss: 0.6019 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.95946\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0278 - accuracy: 0.9947 - val_loss: 0.6609 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.95946\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5338 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.95946\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.8858 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.95946\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.7247 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.95946\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.5747 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.95946\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0248 - accuracy: 0.9947 - val_loss: 0.6392 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.95946\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.7185 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.95946\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.5807 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.95946\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0196 - accuracy: 0.9916 - val_loss: 0.5620 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.95946\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.5210 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.95946\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.6119 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.95946\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.6864 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.95946\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.6422 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.95946\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.6658 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.95946\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 3.9951e-04 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.95946\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.9350 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.95946\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0216 - accuracy: 0.9905 - val_loss: 0.6053 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.95946\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.6297 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.95946\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0125 - accuracy: 0.9947 - val_loss: 0.5930 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.95946\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.4494 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.95946\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.6076 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.95946\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 6.9327e-04 - accuracy: 1.0000 - val_loss: 0.6209 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.95946\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.5270 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.95946\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.7497 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.95946\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.7054 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.95946\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0275 - accuracy: 0.9932 - val_loss: 0.6779 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.95946\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.6505 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.95946\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.5062 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.95946\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0014 - accuracy: 0.9989 - val_loss: 0.4179 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.95946\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.7356 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.95946\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0384 - accuracy: 0.9916 - val_loss: 0.6771 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.95946\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.4755 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.95946\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4303 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.95946\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.6693 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.95946\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.7198 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.95946\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0094 - accuracy: 0.9984 - val_loss: 0.5598 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.95946\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.7456 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.95946\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.7718 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.95946\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5489 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.95946\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0195 - accuracy: 0.9926 - val_loss: 0.7028 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.95946\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.6785 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.95946\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.6542 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.95946\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0210 - accuracy: 0.9947 - val_loss: 0.7263 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.95946\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.5291 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.95946\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0051 - accuracy: 0.9974 - val_loss: 0.4800 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.95946\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.3901 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.95946\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4541 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.95946\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.8484 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.95946\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.5588 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.95946\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.6078 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.95946\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 0.4952 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.95946\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.6236 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.95946\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.5164 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.95946\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.6697 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.95946\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.5625 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.95946\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.7996 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.95946\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.4512 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.95946\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0167 - accuracy: 0.9937 - val_loss: 0.6172 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.95946\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.4645 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95946\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.3786 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95946\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.5294 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95946\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0366 - accuracy: 0.9905 - val_loss: 0.5532 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95946\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.5905 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95946\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.4384 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95946\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.5936 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95946\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 9.2499e-04 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95946\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 0.7567 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95946\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.6766 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95946\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.7067 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95946\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.4253 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95946\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.5935 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95946\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.6182 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95946\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.5508 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95946\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.5298 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95946\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 0.5546 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95946\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.4328 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95946\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0077 - accuracy: 0.9963 - val_loss: 0.6141 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95946\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.5446 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95946\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.5260 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95946\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.5111 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95946\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.7974 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95946\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.4701 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95946\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.4807 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95946\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.6724 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95946\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 0.8621 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95946\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.4453 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95946\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.5979 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95946\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.6347 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95946\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.5347 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95946\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 7.7218e-04 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95946\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 3.2723e-04 - accuracy: 1.0000 - val_loss: 0.6523 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95946\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 3.2086e-04 - accuracy: 1.0000 - val_loss: 0.5365 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95946\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0120 - accuracy: 0.9984 - val_loss: 0.5207 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95946\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0053 - accuracy: 0.9974 - val_loss: 0.6907 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95946\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.7021 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95946\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0070 - accuracy: 0.9958 - val_loss: 0.7997 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95946\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6073 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95946\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5905 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95946\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.7419 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95946\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.9410 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95946\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0155 - accuracy: 0.9974 - val_loss: 0.7111 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95946\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.5462 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95946\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.4440 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95946\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.3481 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95946\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.4157 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95946\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.5870 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95946\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0146 - accuracy: 0.9974 - val_loss: 0.6089 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95946\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0026 - accuracy: 0.9984 - val_loss: 0.5591 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95946\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.5633 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95946\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.5368 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95946\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.2985 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95946\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0026 - accuracy: 0.9979 - val_loss: 0.7699 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95946\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.5772 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95946\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 8.6103e-04 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95946\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 9.0947e-04 - accuracy: 1.0000 - val_loss: 0.6170 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95946\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 5.2550e-04 - accuracy: 1.0000 - val_loss: 0.6400 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95946\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0016 - accuracy: 0.9989 - val_loss: 0.4913 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95946\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0223 - accuracy: 0.9963 - val_loss: 0.9204 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95946\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0315 - accuracy: 0.9926 - val_loss: 0.5435 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95946\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.6410 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95946\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.5655 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95946\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5990 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95946\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0129 - accuracy: 0.9974 - val_loss: 0.6243 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95946\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.6525 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95946\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.6855 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95946\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 6.8764e-04 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95946\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.6590 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95946\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.6764 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95946\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.5471 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95946\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 3.4327e-04 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95946\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 1.8913e-04 - accuracy: 1.0000 - val_loss: 0.6741 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95946\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 1.4515e-04 - accuracy: 1.0000 - val_loss: 0.4618 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95946\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 1.3876e-04 - accuracy: 1.0000 - val_loss: 0.4916 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95946\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.7657 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95946\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0304 - accuracy: 0.9895 - val_loss: 0.8245 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95946\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0110 - accuracy: 0.9953 - val_loss: 0.6699 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95946\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.5553 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95946\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 7.2403e-04 - accuracy: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95946\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 4.1142e-04 - accuracy: 1.0000 - val_loss: 0.6057 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95946\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.5660 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95946\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0282 - accuracy: 0.9916 - val_loss: 0.5482 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95946\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.6052 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95946\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 7.5806e-04 - accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95946\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.5925 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95946\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.5295 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95946\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.6474 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95946\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 8.6337e-04 - accuracy: 1.0000 - val_loss: 0.5695 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95946\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.4981 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95946\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0199 - accuracy: 0.9958 - val_loss: 1.1753 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95946\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.5579 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95946\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0096 - accuracy: 0.9953 - val_loss: 0.5572 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95946\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0197 - accuracy: 0.9953 - val_loss: 0.8725 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95946\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.6269 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95946\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 0.6939 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95946\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 3.9376e-04 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95946\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.7495 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95946\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.6779 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95946\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0227 - accuracy: 0.9947 - val_loss: 0.5842 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95946\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.7009 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95946\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.7130 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95946\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.5833 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95946\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.5443 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95946\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.6240 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95946\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0187 - accuracy: 0.9974 - val_loss: 0.7487 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95946\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.6526 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95946\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.5581 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95946\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.6147 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95946\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.4868 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95946\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95946\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 5.1499e-04 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95946\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 3.4762e-04 - accuracy: 1.0000 - val_loss: 0.5742 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95946\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 18s 75ms/step - loss: 4.9785e-04 - accuracy: 1.0000 - val_loss: 0.5334 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95946\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 1.7230e-04 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95946\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 4.1342e-04 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95946\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 2.3884e-04 - accuracy: 1.0000 - val_loss: 0.5944 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95946\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 2.7375e-04 - accuracy: 1.0000 - val_loss: 0.4567 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95946\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 6.8911e-04 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95946\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.7576 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95946\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0503 - accuracy: 0.9889 - val_loss: 1.0175 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95946\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.8377 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95946\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.7053 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95946\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.8705 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95946\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.8751 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95946\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.7632 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95946\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.9204 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95946\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.5578 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95946\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 4.6080e-04 - accuracy: 1.0000 - val_loss: 0.5647 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95946\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.6551 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95946\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 5.3152e-04 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95946\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 8.9713e-05 - accuracy: 1.0000 - val_loss: 0.6216 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95946\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.6493 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95946\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.6684 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95946\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 4.2780e-04 - accuracy: 1.0000 - val_loss: 0.6098 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95946\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.6698 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95946\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0072 - accuracy: 0.9963 - val_loss: 0.8900 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95946\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.7845 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95946\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.8242 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95946\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.5573 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95946\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.6937 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95946\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.6624 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95946\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 1.0520 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95946\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.7497 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95946\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.5634 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95946\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.6844 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95946\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.5245 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95946\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.5589 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95946\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.6505 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95946\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.5837 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95946\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0165 - accuracy: 0.9968 - val_loss: 0.5790 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95946\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.5086 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95946\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.6388 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95946\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 0.5200 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95946\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0174 - accuracy: 0.9974 - val_loss: 0.5802 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95946\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.7231 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95946\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.6293 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95946\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0160 - accuracy: 0.9942 - val_loss: 0.7737 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95946\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.7815 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95946\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.5268 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95946\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f628043f790>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "54b72e60-f3cc-4c7f-b235-1e32442e8a98"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde2b5c5-e375-4fb0-8d73-cc09b096d934"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e224830-f4eb-4efb-8eb5-2f576874a07e"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d18b4279-0ad1-4105-ccf7-3be8b626a515"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a17074bd-fede-4502-8d29-99e85a163bd3\", \"DenseNet121_1.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZ06MWjdN2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889edc72-14eb-457f-fd61-c358651f198a"
      },
      "source": [
        "!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: dacon-submit-api\n",
            "Successfully installed dacon-submit-api-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKDp3mdOZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36636486-7761-47c7-e4f7-cbc0ebc03572"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    # \n",
        "    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n",
        "    # d9249@kyonggi.ac.kr\n",
        "    #  ID\n",
        "    '235626',\n",
        "    # d9249@kyonggi.ac.kr \n",
        "    # 'iDeal9',\n",
        "    # dodo9249@gmail.com \n",
        "    # 'iDeal96',\n",
        "    # d9249.acc001@gmail.com\n",
        "    # 'iDeal01',\n",
        "    # meanideal96@gamil.com\n",
        "    'iDeal02',\n",
        "    # dodo402298@gmail.com\n",
        "    # 'mean01',\n",
        "    # d9249.acc002@gmail.com\n",
        "    # 'mean02',\n",
        "    # memo\n",
        "    'd9249_kyonggi_ac_kr' )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'isSubmitted': True, 'detail': 'Success'}\n"
          ]
        }
      ]
    }
  ]
}