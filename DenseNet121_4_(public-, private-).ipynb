{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet121_4_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/DenseNet121_4_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89fb095a-194c-4dc4-c0b5-684cbc0c1090"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 29 23:06:29 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001ab26c-cb67-44e2-9bee-b5ff52ceb395"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "model_save = 'DenseNet121_4'\n",
        "Target_model = 'DenseNet121_model'\n",
        "Target_predict = 'DenseNet121_predict'\n",
        "Target_acc = 'DenseNet121_acc'\n",
        "Target_val = 'DenseNet121_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d71082c-c604-4974-d8a1-4edf7cb1a1b9"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb329038-f230-424f-e5a1-77f53286b165"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 53s 100ms/step - loss: 1.8024 - accuracy: 0.3626 - val_loss: 13.6484 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 2/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 1.2002 - accuracy: 0.6063 - val_loss: 2.5215 - val_accuracy: 0.2770\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.10135 to 0.27703, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.9582 - accuracy: 0.6868 - val_loss: 2.0754 - val_accuracy: 0.4932\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.27703 to 0.49324, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.8615 - accuracy: 0.7179 - val_loss: 0.6257 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.49324 to 0.76351, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.7548 - accuracy: 0.7505 - val_loss: 0.9434 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.76351\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.6697 - accuracy: 0.7737 - val_loss: 1.9548 - val_accuracy: 0.5270\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.76351\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.6086 - accuracy: 0.7958 - val_loss: 1.1461 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.76351\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.5482 - accuracy: 0.8179 - val_loss: 0.5277 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.76351 to 0.80405, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.5552 - accuracy: 0.8137 - val_loss: 0.7517 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.80405\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.4486 - accuracy: 0.8521 - val_loss: 0.7413 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.80405\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.4676 - accuracy: 0.8405 - val_loss: 0.6268 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.80405\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.3997 - accuracy: 0.8653 - val_loss: 0.7194 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.80405\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.4133 - accuracy: 0.8605 - val_loss: 0.5069 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.80405 to 0.83784, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.3932 - accuracy: 0.8621 - val_loss: 0.5301 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.83784 to 0.85135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.3602 - accuracy: 0.8816 - val_loss: 0.4998 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.85135 to 0.86486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.3411 - accuracy: 0.8900 - val_loss: 0.3799 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.86486 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.3023 - accuracy: 0.9005 - val_loss: 0.4042 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.87162\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.2978 - accuracy: 0.8963 - val_loss: 0.7324 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.87162\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.3208 - accuracy: 0.8926 - val_loss: 0.6547 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.87162\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.2661 - accuracy: 0.9126 - val_loss: 0.3759 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.87162\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.3289 - accuracy: 0.8942 - val_loss: 0.4793 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.87162 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.2466 - accuracy: 0.9132 - val_loss: 0.4579 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.89189\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.2588 - accuracy: 0.9095 - val_loss: 0.5726 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.89189\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.2183 - accuracy: 0.9242 - val_loss: 0.5971 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.89189\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.2513 - accuracy: 0.9137 - val_loss: 0.4140 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.89189\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.2349 - accuracy: 0.9189 - val_loss: 0.2893 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.89189 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.2105 - accuracy: 0.9305 - val_loss: 0.4002 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.90541\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.2063 - accuracy: 0.9300 - val_loss: 0.4140 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.90541\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.2099 - accuracy: 0.9258 - val_loss: 0.5305 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.90541\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.2039 - accuracy: 0.9263 - val_loss: 0.3000 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.90541\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.1825 - accuracy: 0.9384 - val_loss: 0.4938 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.90541\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.1745 - accuracy: 0.9437 - val_loss: 0.2635 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.90541\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.1531 - accuracy: 0.9511 - val_loss: 0.4050 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.90541\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.1385 - accuracy: 0.9500 - val_loss: 0.3389 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.1634 - accuracy: 0.9400 - val_loss: 0.3970 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91216\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.1896 - accuracy: 0.9384 - val_loss: 0.4406 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91216\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.1446 - accuracy: 0.9542 - val_loss: 0.3845 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91216\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.1353 - accuracy: 0.9505 - val_loss: 0.3124 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91216\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.1352 - accuracy: 0.9526 - val_loss: 0.4871 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91216\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.1423 - accuracy: 0.9537 - val_loss: 0.2558 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.91216 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.1266 - accuracy: 0.9526 - val_loss: 0.3641 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.93243\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.1286 - accuracy: 0.9589 - val_loss: 0.6986 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.93243\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.1013 - accuracy: 0.9705 - val_loss: 0.3091 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.93243\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.1072 - accuracy: 0.9632 - val_loss: 0.4509 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.93243\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.1016 - accuracy: 0.9668 - val_loss: 0.4120 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.93243\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.1098 - accuracy: 0.9600 - val_loss: 0.4933 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.93243\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.1272 - accuracy: 0.9516 - val_loss: 0.5525 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.93243\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.1110 - accuracy: 0.9605 - val_loss: 0.4175 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.93243\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.1017 - accuracy: 0.9658 - val_loss: 0.2398 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.93243 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0655 - accuracy: 0.9768 - val_loss: 0.3998 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.94595\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.1062 - accuracy: 0.9674 - val_loss: 0.4120 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.94595\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.1218 - accuracy: 0.9647 - val_loss: 0.4497 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.94595\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0848 - accuracy: 0.9679 - val_loss: 0.3834 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.94595\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.1050 - accuracy: 0.9653 - val_loss: 0.4684 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.94595\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.1110 - accuracy: 0.9626 - val_loss: 0.3314 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.94595\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.1023 - accuracy: 0.9689 - val_loss: 0.3757 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.94595\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0588 - accuracy: 0.9800 - val_loss: 0.3356 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.94595\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0676 - accuracy: 0.9779 - val_loss: 0.6586 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.94595\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.1059 - accuracy: 0.9658 - val_loss: 0.2869 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.94595\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0608 - accuracy: 0.9795 - val_loss: 0.2739 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.94595\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0693 - accuracy: 0.9747 - val_loss: 0.4652 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.94595\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0888 - accuracy: 0.9684 - val_loss: 0.5263 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.94595\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.1185 - accuracy: 0.9658 - val_loss: 0.2965 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.94595\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0628 - accuracy: 0.9784 - val_loss: 0.3308 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.94595\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0495 - accuracy: 0.9837 - val_loss: 0.3028 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.94595\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0506 - accuracy: 0.9847 - val_loss: 0.3697 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.94595\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0673 - accuracy: 0.9784 - val_loss: 0.5815 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.94595\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0535 - accuracy: 0.9811 - val_loss: 0.5138 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.94595\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0942 - accuracy: 0.9658 - val_loss: 0.5825 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.94595\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0591 - accuracy: 0.9816 - val_loss: 0.3060 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.94595\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0628 - accuracy: 0.9768 - val_loss: 0.3261 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.94595\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0517 - accuracy: 0.9811 - val_loss: 0.3597 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.94595\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0690 - accuracy: 0.9811 - val_loss: 0.4533 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.94595\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0665 - accuracy: 0.9795 - val_loss: 0.4988 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.94595\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0729 - accuracy: 0.9753 - val_loss: 0.2886 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.94595\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0283 - accuracy: 0.9900 - val_loss: 0.3078 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.94595\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0555 - accuracy: 0.9826 - val_loss: 0.4764 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.94595\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0421 - accuracy: 0.9884 - val_loss: 0.7085 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.94595\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0243 - accuracy: 0.9942 - val_loss: 0.3190 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.94595\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0628 - accuracy: 0.9784 - val_loss: 0.4453 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.94595\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0660 - accuracy: 0.9726 - val_loss: 0.5759 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.94595\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0878 - accuracy: 0.9711 - val_loss: 0.4720 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.94595\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0639 - accuracy: 0.9816 - val_loss: 0.3481 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.94595\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0259 - accuracy: 0.9911 - val_loss: 0.2768 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.94595\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.4302 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.94595\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0540 - accuracy: 0.9837 - val_loss: 0.5289 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.94595\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0817 - accuracy: 0.9768 - val_loss: 0.5301 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.94595\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0761 - accuracy: 0.9768 - val_loss: 0.3617 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.94595\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.3329 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.94595\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0406 - accuracy: 0.9879 - val_loss: 0.3086 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.94595\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0415 - accuracy: 0.9879 - val_loss: 0.6235 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.94595\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0350 - accuracy: 0.9868 - val_loss: 0.5696 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.94595\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.3262 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.94595\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0378 - accuracy: 0.9874 - val_loss: 0.3907 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.94595\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0302 - accuracy: 0.9911 - val_loss: 0.5904 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.94595\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0549 - accuracy: 0.9842 - val_loss: 0.5715 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.94595\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0494 - accuracy: 0.9853 - val_loss: 0.5831 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.94595\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0728 - accuracy: 0.9784 - val_loss: 0.6630 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.94595\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0678 - accuracy: 0.9779 - val_loss: 0.3749 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.94595\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0401 - accuracy: 0.9895 - val_loss: 0.4307 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.94595\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0453 - accuracy: 0.9837 - val_loss: 0.4565 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.94595\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0351 - accuracy: 0.9889 - val_loss: 0.5016 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.94595\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0214 - accuracy: 0.9953 - val_loss: 0.4906 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.94595\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0283 - accuracy: 0.9905 - val_loss: 0.4442 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.94595\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0340 - accuracy: 0.9879 - val_loss: 0.5003 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.94595\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0395 - accuracy: 0.9895 - val_loss: 0.3492 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.94595\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 0.4420 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.94595\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0436 - accuracy: 0.9879 - val_loss: 0.6106 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.94595\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0554 - accuracy: 0.9826 - val_loss: 0.4084 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.94595\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0456 - accuracy: 0.9863 - val_loss: 0.3800 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.94595\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0504 - accuracy: 0.9826 - val_loss: 0.6630 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.94595\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0463 - accuracy: 0.9868 - val_loss: 0.3556 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.94595\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0227 - accuracy: 0.9905 - val_loss: 0.4713 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.94595\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0281 - accuracy: 0.9889 - val_loss: 0.4712 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.94595\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 0.4352 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.94595\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0396 - accuracy: 0.9853 - val_loss: 0.4000 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.94595\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.4287 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.94595\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0452 - accuracy: 0.9842 - val_loss: 0.4724 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.94595\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0543 - accuracy: 0.9847 - val_loss: 0.5146 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.94595\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0281 - accuracy: 0.9911 - val_loss: 0.2585 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.94595\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0499 - accuracy: 0.9874 - val_loss: 0.4958 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.94595\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0228 - accuracy: 0.9947 - val_loss: 0.4560 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.94595\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.4413 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.94595\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 0.4344 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.94595\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0324 - accuracy: 0.9879 - val_loss: 0.5404 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.94595\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0284 - accuracy: 0.9905 - val_loss: 0.4819 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.94595\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0325 - accuracy: 0.9889 - val_loss: 0.3966 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.94595\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.4794 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.94595\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.6747 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.94595\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 0.6403 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.94595\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0597 - accuracy: 0.9832 - val_loss: 0.6677 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.94595\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0236 - accuracy: 0.9905 - val_loss: 0.4331 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.94595\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.3950 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.94595\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0311 - accuracy: 0.9895 - val_loss: 0.5184 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.94595\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0469 - accuracy: 0.9847 - val_loss: 0.3902 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.94595\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0325 - accuracy: 0.9911 - val_loss: 0.3705 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.94595\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0189 - accuracy: 0.9921 - val_loss: 0.4368 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.94595\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.4338 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.94595\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.3383 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.94595\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0191 - accuracy: 0.9926 - val_loss: 0.3850 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.94595\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0466 - accuracy: 0.9842 - val_loss: 0.5788 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.94595\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.3668 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.94595\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.3333 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.94595\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 0.3386 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.94595\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.3556 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.94595\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0068 - accuracy: 0.9968 - val_loss: 0.2920 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.94595\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0492 - accuracy: 0.9832 - val_loss: 0.9186 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.94595\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0281 - accuracy: 0.9889 - val_loss: 0.4061 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.94595\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.4597 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.94595\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.4436 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.94595\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.4366 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.94595\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0215 - accuracy: 0.9916 - val_loss: 0.6624 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.94595\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0272 - accuracy: 0.9905 - val_loss: 0.5055 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.94595\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0179 - accuracy: 0.9926 - val_loss: 0.3859 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.94595\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0250 - accuracy: 0.9900 - val_loss: 0.5486 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.94595\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0267 - accuracy: 0.9905 - val_loss: 0.4474 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.94595\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0227 - accuracy: 0.9921 - val_loss: 0.4649 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.94595\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.4475 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.94595\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0194 - accuracy: 0.9921 - val_loss: 0.4895 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.94595\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0431 - accuracy: 0.9874 - val_loss: 0.5092 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.94595\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.2256 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.94595\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0060 - accuracy: 0.9968 - val_loss: 0.2386 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.94595\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.2818 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.94595\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.3843 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.94595\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0520 - accuracy: 0.9805 - val_loss: 0.4679 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.94595\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0456 - accuracy: 0.9853 - val_loss: 0.4523 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.94595\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0727 - accuracy: 0.9800 - val_loss: 0.3995 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.94595\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0210 - accuracy: 0.9916 - val_loss: 0.4072 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.94595\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0089 - accuracy: 0.9958 - val_loss: 0.4901 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.94595\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.3608 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.94595\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0274 - accuracy: 0.9916 - val_loss: 0.5045 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.94595\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.4257 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.94595\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.2878 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.94595\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.3470 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.94595\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.3174 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.94595\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 0.4337 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.94595\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.2743 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.94595\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0308 - accuracy: 0.9889 - val_loss: 0.4186 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.94595\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0218 - accuracy: 0.9958 - val_loss: 0.6354 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.94595\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0130 - accuracy: 0.9947 - val_loss: 0.4105 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.94595\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.3579 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.94595\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0186 - accuracy: 0.9958 - val_loss: 0.3627 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.94595\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.4670 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.94595\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.5918 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.94595\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.3879 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.94595\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0186 - accuracy: 0.9958 - val_loss: 0.5319 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.94595\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.3572 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.94595\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.5026 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.94595\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.5402 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.94595\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0097 - accuracy: 0.9958 - val_loss: 0.4074 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.94595\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.3010 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.94595\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.4681 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.94595\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0476 - accuracy: 0.9900 - val_loss: 0.4199 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.94595\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.5041 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.94595\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.4268 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.94595\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.4516 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.94595\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.4075 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.94595\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.5515 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.94595\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0222 - accuracy: 0.9916 - val_loss: 0.5794 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.94595\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.3483 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.94595\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0272 - accuracy: 0.9953 - val_loss: 0.5496 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.94595\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0370 - accuracy: 0.9921 - val_loss: 0.4232 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.94595\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.3789 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.94595\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.3161 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.94595\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.4124 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.94595\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.8829 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.94595\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.7196 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.94595\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0295 - accuracy: 0.9889 - val_loss: 0.7102 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.94595\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.4972 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.94595\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0193 - accuracy: 0.9911 - val_loss: 0.4027 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.94595\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.4939 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.94595\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0237 - accuracy: 0.9953 - val_loss: 0.9866 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.94595\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0265 - accuracy: 0.9937 - val_loss: 0.4172 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.94595\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0268 - accuracy: 0.9926 - val_loss: 0.6307 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.94595\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0296 - accuracy: 0.9916 - val_loss: 0.4798 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.94595\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.2320 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.94595\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.2672 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.94595\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.2695 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.94595\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.4176 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.94595\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.2697 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.94595\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.4765 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.94595\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.3406 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.94595\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0224 - accuracy: 0.9895 - val_loss: 0.7018 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.94595\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0391 - accuracy: 0.9868 - val_loss: 0.4539 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.94595\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0269 - accuracy: 0.9916 - val_loss: 0.6415 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.94595\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.3517 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.94595\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.3967 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.94595\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.3188 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.94595\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.5166 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.94595\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.3547 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.94595\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.5688 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.94595\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0265 - accuracy: 0.9937 - val_loss: 0.7698 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.94595\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0202 - accuracy: 0.9921 - val_loss: 0.5777 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.94595\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0232 - accuracy: 0.9916 - val_loss: 0.4752 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.94595\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0333 - accuracy: 0.9884 - val_loss: 0.4668 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.94595\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.5383 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.94595\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.4118 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.94595\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.4124 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.94595\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.2609 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.94595\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.4394 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.94595\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.3983 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.94595\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.3417 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.94595\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.2918 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.94595\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.9079 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.94595\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.5972 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.94595\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.6112 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.94595\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.5454 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.94595\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0078 - accuracy: 0.9958 - val_loss: 0.3037 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.94595\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.6433 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.94595\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.5281 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.94595\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.5666 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.94595\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.3178 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.94595\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.5707 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.94595\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.5935 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.94595\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.5144 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.94595\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0353 - accuracy: 0.9942 - val_loss: 0.6268 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.94595\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.6326 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.94595\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0239 - accuracy: 0.9942 - val_loss: 0.4308 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.94595\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.4983 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.94595\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.7304 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.94595\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0255 - accuracy: 0.9900 - val_loss: 0.6599 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.94595\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0097 - accuracy: 0.9953 - val_loss: 0.3504 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.94595\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.3731 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.94595\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.4435 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.94595\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.3281 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.94595\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.5670 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.94595\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.5064 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.94595\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.5035 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.94595\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 0.4815 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.94595\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 0.4451 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.94595\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.8288 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.94595\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.5975 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.94595\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0288 - accuracy: 0.9926 - val_loss: 0.3798 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.94595\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0068 - accuracy: 0.9968 - val_loss: 0.4084 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.94595\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.3655 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.94595\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.3328 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.94595\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0095 - accuracy: 0.9953 - val_loss: 0.5494 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.94595\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0190 - accuracy: 0.9958 - val_loss: 0.5521 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.94595\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.6462 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.94595\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.5698 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.94595\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.4221 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.94595\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.4128 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.94595\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.3288 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.94595\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.3988 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.94595\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0255 - accuracy: 0.9942 - val_loss: 0.4954 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.94595\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.3979 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.94595\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.5110 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.94595\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.4493 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.94595\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.5804 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.94595\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 0.4427 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.94595\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0151 - accuracy: 0.9942 - val_loss: 0.5297 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.94595\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.4629 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.94595\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.4347 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.94595\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.5896 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.94595\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.5619 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.94595\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.5003 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.94595\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.3374 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.94595\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0137 - accuracy: 0.9947 - val_loss: 0.4791 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.94595\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.4975 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.94595\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.3709 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.94595\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.4082 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.94595\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.5197 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.94595\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.3451 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.94595\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.6913 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.94595\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0178 - accuracy: 0.9911 - val_loss: 0.4494 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.94595\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.4860 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.94595\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.5143 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.94595\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5185 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.94595\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.5172 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.94595\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.5197 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.94595\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0158 - accuracy: 0.9937 - val_loss: 0.5404 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.94595\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.3767 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.94595\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0294 - accuracy: 0.9932 - val_loss: 0.5064 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.94595\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.4922 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.94595\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.5085 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.94595\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.5142 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.94595\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0101 - accuracy: 0.9958 - val_loss: 0.5604 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.94595\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0387 - accuracy: 0.9900 - val_loss: 0.5362 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.94595\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0114 - accuracy: 0.9947 - val_loss: 0.4840 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.94595\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.3591 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.94595\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.3384 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.94595\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.4095 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.94595\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.4420 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.94595\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.4199 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.94595\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.4661 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.94595\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.3537 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00326: val_accuracy improved from 0.94595 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.95270\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.4831 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.95270\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.5614 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.95270\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0245 - accuracy: 0.9942 - val_loss: 0.5631 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.95270\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.4723 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.95270\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.5179 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.95270\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.5727 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.95270\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5158 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.95270\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0063 - accuracy: 0.9968 - val_loss: 0.6269 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.95270\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.4787 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.95270\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.4202 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.95270\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.4799 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.95270\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.3775 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.95270\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4445 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.95270\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4088 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95270\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.4748 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95270\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.5450 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95270\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.6102 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95270\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0272 - accuracy: 0.9895 - val_loss: 0.5655 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95270\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.4165 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95270\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.4215 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95270\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 8.9643e-04 - accuracy: 1.0000 - val_loss: 0.3251 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95270\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.4046 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95270\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 23s 98ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4259 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95270\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 9.5549e-04 - accuracy: 0.9995 - val_loss: 0.4196 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95270\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0145 - accuracy: 0.9942 - val_loss: 0.6401 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95270\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.3285 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95270\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.6303 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95270\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.6763 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95270\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.3561 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95270\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.5796 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95270\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.7663 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95270\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.6532 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95270\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0342 - accuracy: 0.9911 - val_loss: 0.4351 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95270\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.3930 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95270\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.5313 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95270\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.6241 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95270\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0365 - accuracy: 0.9895 - val_loss: 0.9238 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95270\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0109 - accuracy: 0.9953 - val_loss: 0.6269 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95270\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.4735 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95270\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.7293 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95270\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95270\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.6039 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95270\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.4874 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95270\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.4326 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95270\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.4816 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95270\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.4516 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95270\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.3900 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95270\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.4574 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95270\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.4289 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95270\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.5306 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95270\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0072 - accuracy: 0.9968 - val_loss: 0.4704 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95270\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.6144 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95270\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.5205 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95270\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 1.1089 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95270\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0323 - accuracy: 0.9895 - val_loss: 0.5500 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95270\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 0.5181 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95270\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.4327 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95270\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.3538 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95270\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.5366 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95270\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.5306 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95270\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5230 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95270\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.5894 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95270\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5028 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95270\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0128 - accuracy: 0.9942 - val_loss: 0.5553 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95270\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0107 - accuracy: 0.9947 - val_loss: 0.5019 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95270\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0292 - accuracy: 0.9921 - val_loss: 0.6204 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95270\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.3299 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95270\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.5257 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95270\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.5701 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95270\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.3988 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95270\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 7.7892e-04 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95270\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.3966 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95270\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0053 - accuracy: 0.9974 - val_loss: 0.8146 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95270\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0202 - accuracy: 0.9921 - val_loss: 0.6255 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95270\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.3843 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95270\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0173 - accuracy: 0.9932 - val_loss: 0.5133 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95270\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.4111 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95270\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.4668 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95270\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.4432 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95270\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.4260 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95270\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.5609 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95270\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.5808 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95270\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.6992 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95270\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0033 - accuracy: 0.9979 - val_loss: 0.6438 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95270\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.5691 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95270\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0196 - accuracy: 0.9963 - val_loss: 0.5142 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95270\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0099 - accuracy: 0.9958 - val_loss: 0.4681 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95270\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.4753 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95270\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.4890 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95270\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.5949 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95270\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4449 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95270\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.3890 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95270\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3205 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95270\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 2.3790e-04 - accuracy: 1.0000 - val_loss: 0.4164 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95270\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 0.3777 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95270\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.4025 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95270\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0308 - accuracy: 0.9942 - val_loss: 0.4840 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95270\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.3672 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95270\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.4097 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95270\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0042 - accuracy: 0.9974 - val_loss: 0.6164 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95270\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.4064 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95270\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.4229 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95270\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.3639 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95270\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.6959 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95270\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.4689 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95270\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.2681 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95270\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95270\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.4395 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95270\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.5404 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95270\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0262 - accuracy: 0.9932 - val_loss: 0.5840 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95270\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.4172 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95270\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 7.3410e-04 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95270\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.4910 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95270\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.8671 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95270\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.4666 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95270\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 23s 97ms/step - loss: 8.6051e-04 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95270\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0152 - accuracy: 0.9989 - val_loss: 0.3352 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95270\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.3347 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95270\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.4379 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95270\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.4049 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95270\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.5057 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95270\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.4008 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95270\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 0.4642 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95270\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.5011 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95270\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.3196 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95270\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.3965 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95270\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.4037 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95270\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.8057 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95270\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.3064 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95270\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.4972 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95270\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95270\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.5773 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95270\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4360 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95270\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 2.9832e-04 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95270\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.4099 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95270\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0273 - accuracy: 0.9932 - val_loss: 0.5302 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95270\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0201 - accuracy: 0.9926 - val_loss: 0.7003 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95270\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.4939 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95270\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.3415 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95270\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5140 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95270\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.4021 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95270\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.3428 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95270\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.4386 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95270\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4760 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95270\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.4129 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95270\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.4986 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95270\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.5018 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95270\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.4366 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95270\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95270\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0120 - accuracy: 0.9953 - val_loss: 0.4927 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95270\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.3191 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95270\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.5659 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95270\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0225 - accuracy: 0.9963 - val_loss: 0.6521 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95270\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.5431 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95270\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.5300 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95270\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 0.6989 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95270\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.5047 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95270\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 5.2402e-04 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95270\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.6481 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95270\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0088 - accuracy: 0.9958 - val_loss: 0.5172 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95270\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.5369 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95270\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0072 - accuracy: 0.9963 - val_loss: 0.4825 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95270\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0088 - accuracy: 0.9958 - val_loss: 0.4695 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95270\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.4463 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95270\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0016 - accuracy: 0.9989 - val_loss: 0.4252 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95270\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.4449 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95270\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.4104 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95270\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.6194 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95270\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4668 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95270\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.7354 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95270\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.4390 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95270\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.5835 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95270\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0095 - accuracy: 0.9953 - val_loss: 0.7906 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9cd65fad10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "4f92d16a-de0e-451e-cfcb-6f22f2f9f383"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad76e085-50a0-4ef6-b4ab-9e85c9cced96"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b51443f-f48a-47e9-c48c-da624b763e26"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "32a00c8b-f0ec-4995-a884-ef94b2c34343"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_153636d0-fb5b-4232-bcc0-cad09380af1f\", \"DenseNet121_4.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZ06MWjdN2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afef3945-1eea-4566-ac6b-46890ce2b31b"
      },
      "source": [
        "!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: dacon-submit-api\n",
            "Successfully installed dacon-submit-api-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKDp3mdOZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e741564-2448-4122-b73d-af7a2e9fde27"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    # 파일경로\n",
        "    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n",
        "    # d9249@kyonggi.ac.kr\n",
        "    # 대회 ID\n",
        "    '235626',\n",
        "    # d9249@kyonggi.ac.kr 팀이릉\n",
        "    # 'iDeal9',\n",
        "    # dodo9249@gmail.com 팀이름\n",
        "    # 'iDeal96',\n",
        "    # d9249.acc001@gmail.com\n",
        "    # 'iDeal01',\n",
        "    # meanideal96@gamil.com\n",
        "    # 'iDeal02',\n",
        "    # dodo402298@gmail.com\n",
        "    'mean01',\n",
        "    # d9249.acc002@gmail.com\n",
        "    # 'mean02',\n",
        "    # memo\n",
        "    'd9249_kyonggi_ac_kr' )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exception occurs. 예외가 발생했습니다 403\n"
          ]
        }
      ]
    }
  ]
}