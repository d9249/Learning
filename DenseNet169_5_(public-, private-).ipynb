{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet169_5_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/DenseNet169_5_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfcd3b6f-488c-49b1-f143-12730983e7ca"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 28 15:45:32 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb835f81-1d6c-450c-f2a0-7361f6297677"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "model_save = 'DenseNet169_5'\n",
        "Target_model = 'DenseNet169_model'\n",
        "Target_predict = 'DenseNet169_predict'\n",
        "Target_acc = 'DenseNet169_acc'\n",
        "Target_val = 'DenseNet169_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.InceptionV3(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9df00b3-cf31-477c-9c1d-f562325785f3"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa9c1df-66e2-4a16-bd08-be24fb5d544c"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 48s 97ms/step - loss: 2.0212 - accuracy: 0.3447 - val_loss: 3.9324 - val_accuracy: 0.0541\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.05405, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet169_5.h5\n",
            "Epoch 2/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 1.1963 - accuracy: 0.6168 - val_loss: 10.5829 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.05405 to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet169_5.h5\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.9469 - accuracy: 0.7005 - val_loss: 0.8626 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.10135 to 0.72973, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet169_5.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.8287 - accuracy: 0.7326 - val_loss: 1.3149 - val_accuracy: 0.6419\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.72973\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.6918 - accuracy: 0.7774 - val_loss: 0.9083 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.72973 to 0.73649, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet169_5.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.6086 - accuracy: 0.8126 - val_loss: 0.6129 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.73649 to 0.81081, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet169_5.h5\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.5455 - accuracy: 0.8279 - val_loss: 0.7382 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.81081\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.5103 - accuracy: 0.8347 - val_loss: 0.3497 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.81081 to 0.84459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet169_5.h5\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.5235 - accuracy: 0.8289 - val_loss: 1.2223 - val_accuracy: 0.7095\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.84459\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.5049 - accuracy: 0.8363 - val_loss: 1.9954 - val_accuracy: 0.4662\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.84459\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.3987 - accuracy: 0.8647 - val_loss: 0.5775 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.84459\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.4111 - accuracy: 0.8611 - val_loss: 2.2213 - val_accuracy: 0.5811\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.84459\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.3840 - accuracy: 0.8758 - val_loss: 0.6954 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.84459\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.3743 - accuracy: 0.8842 - val_loss: 0.6151 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.84459\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.3623 - accuracy: 0.8795 - val_loss: 0.5440 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.84459\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.3392 - accuracy: 0.8874 - val_loss: 0.9390 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.84459\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.2896 - accuracy: 0.9021 - val_loss: 1.0190 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.84459\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.3535 - accuracy: 0.8842 - val_loss: 2.0997 - val_accuracy: 0.5473\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.84459\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.3092 - accuracy: 0.8953 - val_loss: 0.4491 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.84459\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.2825 - accuracy: 0.9079 - val_loss: 0.6404 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.84459\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.2500 - accuracy: 0.9158 - val_loss: 0.5495 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.84459\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.2695 - accuracy: 0.9105 - val_loss: 0.3860 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.84459\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.2515 - accuracy: 0.9205 - val_loss: 0.5523 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.84459\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.2540 - accuracy: 0.9147 - val_loss: 0.6191 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.84459\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.2309 - accuracy: 0.9263 - val_loss: 0.4287 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.84459 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet169_5.h5\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.2030 - accuracy: 0.9289 - val_loss: 0.7081 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.89189\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.1989 - accuracy: 0.9316 - val_loss: 0.4703 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.89189\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.2539 - accuracy: 0.9179 - val_loss: 0.5173 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.89189\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.1889 - accuracy: 0.9316 - val_loss: 0.3298 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.89189 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet169_5.h5\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.1634 - accuracy: 0.9432 - val_loss: 0.2920 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.90541\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.1852 - accuracy: 0.9347 - val_loss: 0.2599 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.90541 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet169_5.h5\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.1906 - accuracy: 0.9379 - val_loss: 0.5347 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91892\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.1825 - accuracy: 0.9442 - val_loss: 0.3358 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91892\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.1337 - accuracy: 0.9500 - val_loss: 0.5148 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91892\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.1284 - accuracy: 0.9563 - val_loss: 0.4918 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91892\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.1819 - accuracy: 0.9453 - val_loss: 0.4800 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91892\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.2006 - accuracy: 0.9395 - val_loss: 0.6754 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91892\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.1432 - accuracy: 0.9447 - val_loss: 0.5775 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91892\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.1646 - accuracy: 0.9463 - val_loss: 0.6435 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91892\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.1254 - accuracy: 0.9663 - val_loss: 0.4646 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91892\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0971 - accuracy: 0.9689 - val_loss: 0.3623 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91892\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.1046 - accuracy: 0.9668 - val_loss: 0.5265 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91892\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.1791 - accuracy: 0.9411 - val_loss: 0.6668 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91892\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.1406 - accuracy: 0.9542 - val_loss: 0.8624 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91892\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.1165 - accuracy: 0.9595 - val_loss: 0.3739 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91892\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0776 - accuracy: 0.9800 - val_loss: 0.5411 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91892\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0963 - accuracy: 0.9658 - val_loss: 0.4674 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91892\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.1196 - accuracy: 0.9595 - val_loss: 0.4750 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91892\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0924 - accuracy: 0.9732 - val_loss: 0.4366 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91892\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0996 - accuracy: 0.9626 - val_loss: 0.4647 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91892\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0890 - accuracy: 0.9732 - val_loss: 0.5280 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91892\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.1022 - accuracy: 0.9668 - val_loss: 0.5253 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91892\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.1025 - accuracy: 0.9626 - val_loss: 0.4188 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91892\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0771 - accuracy: 0.9774 - val_loss: 0.6672 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91892\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.1297 - accuracy: 0.9568 - val_loss: 0.6242 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91892\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.1238 - accuracy: 0.9626 - val_loss: 0.5216 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91892\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0607 - accuracy: 0.9816 - val_loss: 0.4366 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91892\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.1099 - accuracy: 0.9695 - val_loss: 0.5493 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91892\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0697 - accuracy: 0.9795 - val_loss: 0.4216 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91892\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0474 - accuracy: 0.9874 - val_loss: 0.4793 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91892\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0764 - accuracy: 0.9721 - val_loss: 0.6931 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91892\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0803 - accuracy: 0.9721 - val_loss: 0.4415 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91892\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0733 - accuracy: 0.9805 - val_loss: 0.5621 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91892\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0766 - accuracy: 0.9742 - val_loss: 0.7299 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91892\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0598 - accuracy: 0.9842 - val_loss: 0.4575 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91892\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.4424 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91892\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0621 - accuracy: 0.9784 - val_loss: 0.5241 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91892\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0920 - accuracy: 0.9721 - val_loss: 0.5623 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91892\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0594 - accuracy: 0.9837 - val_loss: 0.3141 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91892\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.4164 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91892\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0628 - accuracy: 0.9805 - val_loss: 0.3239 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91892\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0758 - accuracy: 0.9753 - val_loss: 0.4646 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91892\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0457 - accuracy: 0.9847 - val_loss: 0.5098 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91892\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0629 - accuracy: 0.9784 - val_loss: 0.5564 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91892\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0460 - accuracy: 0.9853 - val_loss: 0.5259 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91892\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0426 - accuracy: 0.9853 - val_loss: 0.4974 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91892\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0547 - accuracy: 0.9853 - val_loss: 0.4411 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91892\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0728 - accuracy: 0.9758 - val_loss: 0.4238 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91892\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0525 - accuracy: 0.9842 - val_loss: 0.4651 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91892\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0725 - accuracy: 0.9774 - val_loss: 0.6142 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91892\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0769 - accuracy: 0.9721 - val_loss: 0.7572 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91892\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.3254 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91892\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0531 - accuracy: 0.9847 - val_loss: 0.3058 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91892\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0678 - accuracy: 0.9805 - val_loss: 0.4897 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91892\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 0.3751 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91892\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.4725 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91892\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0305 - accuracy: 0.9879 - val_loss: 0.4981 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91892\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0512 - accuracy: 0.9826 - val_loss: 0.6363 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91892\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0644 - accuracy: 0.9789 - val_loss: 0.6137 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91892\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0857 - accuracy: 0.9774 - val_loss: 0.5861 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91892\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.6297 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91892\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0432 - accuracy: 0.9874 - val_loss: 0.4095 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91892\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0387 - accuracy: 0.9884 - val_loss: 0.4902 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91892\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0378 - accuracy: 0.9853 - val_loss: 0.2960 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91892\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0458 - accuracy: 0.9874 - val_loss: 0.4223 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91892\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.4874 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91892\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0337 - accuracy: 0.9868 - val_loss: 0.6170 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91892\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0688 - accuracy: 0.9805 - val_loss: 0.4172 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91892\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0543 - accuracy: 0.9821 - val_loss: 0.2757 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91892\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0383 - accuracy: 0.9868 - val_loss: 0.3477 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91892\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0237 - accuracy: 0.9900 - val_loss: 0.3830 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00101: val_accuracy improved from 0.91892 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet169_5.h5\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0282 - accuracy: 0.9932 - val_loss: 0.5587 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.92568\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0450 - accuracy: 0.9842 - val_loss: 0.5477 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.92568\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0454 - accuracy: 0.9868 - val_loss: 0.3464 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.92568\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0324 - accuracy: 0.9905 - val_loss: 0.2742 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.92568\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 0.3031 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00106: val_accuracy improved from 0.92568 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet169_5.h5\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.4057 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.94595\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 0.4925 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.94595\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.6431 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.94595\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0870 - accuracy: 0.9668 - val_loss: 0.4905 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.94595\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0522 - accuracy: 0.9858 - val_loss: 0.7307 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.94595\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0414 - accuracy: 0.9900 - val_loss: 0.5632 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.94595\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0363 - accuracy: 0.9905 - val_loss: 0.3795 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.94595\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.3872 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.94595\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.5900 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.94595\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.6380 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.94595\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.6704 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.94595\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0552 - accuracy: 0.9837 - val_loss: 0.8853 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.94595\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0718 - accuracy: 0.9768 - val_loss: 0.5779 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.94595\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0334 - accuracy: 0.9889 - val_loss: 0.5817 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.94595\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.5795 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.94595\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.3574 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.94595\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.7338 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.94595\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0537 - accuracy: 0.9847 - val_loss: 0.5091 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.94595\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.4476 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.94595\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.4635 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.94595\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0288 - accuracy: 0.9926 - val_loss: 0.7668 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.94595\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.5443 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.94595\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.4410 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.94595\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0323 - accuracy: 0.9895 - val_loss: 0.4314 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.94595\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.4076 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.94595\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 0.4759 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.94595\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0162 - accuracy: 0.9963 - val_loss: 0.5821 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.94595\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0518 - accuracy: 0.9800 - val_loss: 0.7255 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.94595\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 0.5556 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.94595\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.4857 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.94595\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.4740 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.94595\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.4220 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.94595\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0466 - accuracy: 0.9879 - val_loss: 0.4775 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.94595\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.3542 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.94595\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0304 - accuracy: 0.9916 - val_loss: 0.5109 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.94595\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0470 - accuracy: 0.9847 - val_loss: 0.7875 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.94595\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.4406 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.94595\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.5224 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.94595\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0161 - accuracy: 0.9968 - val_loss: 0.4660 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.94595\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0087 - accuracy: 0.9984 - val_loss: 0.3887 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.94595\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.6665 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.94595\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0454 - accuracy: 0.9884 - val_loss: 0.6453 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.94595\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0379 - accuracy: 0.9932 - val_loss: 0.4400 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.94595\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.5156 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.94595\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 0.4707 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.94595\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.4710 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.94595\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6034 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.94595\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.6160 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.94595\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 0.7911 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.94595\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0281 - accuracy: 0.9895 - val_loss: 1.0091 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.94595\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0523 - accuracy: 0.9842 - val_loss: 0.6310 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.94595\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0239 - accuracy: 0.9932 - val_loss: 0.5352 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.94595\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0291 - accuracy: 0.9916 - val_loss: 0.4630 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.94595\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0129 - accuracy: 0.9947 - val_loss: 0.5629 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.94595\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.4619 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.94595\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0196 - accuracy: 0.9916 - val_loss: 0.5234 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.94595\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.5728 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.94595\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0397 - accuracy: 0.9900 - val_loss: 0.6508 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.94595\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0178 - accuracy: 0.9926 - val_loss: 0.6533 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.94595\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.4655 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.94595\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0104 - accuracy: 0.9953 - val_loss: 0.8418 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.94595\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.5648 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.94595\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0209 - accuracy: 0.9916 - val_loss: 0.7629 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.94595\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.5746 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.94595\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0050 - accuracy: 0.9974 - val_loss: 0.5960 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.94595\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.7544 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.94595\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.4930 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.94595\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0298 - accuracy: 0.9937 - val_loss: 0.5389 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.94595\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0413 - accuracy: 0.9863 - val_loss: 0.6098 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.94595\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.4976 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.94595\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.6744 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.94595\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.5210 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.94595\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.5127 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.94595\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.6545 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.94595\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 1.0287 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.94595\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0349 - accuracy: 0.9879 - val_loss: 0.6665 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.94595\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 0.7574 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.94595\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.5872 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.94595\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.4463 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.94595\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0107 - accuracy: 0.9947 - val_loss: 0.5445 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.94595\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0143 - accuracy: 0.9942 - val_loss: 0.4737 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.94595\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.5454 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.94595\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.5116 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.94595\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4981 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.94595\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 7.0162e-04 - accuracy: 1.0000 - val_loss: 0.5182 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.94595\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 1.7329 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.94595\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0737 - accuracy: 0.9837 - val_loss: 0.6202 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.94595\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0375 - accuracy: 0.9911 - val_loss: 0.5742 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.94595\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.4842 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.94595\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.5429 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.94595\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0097 - accuracy: 0.9958 - val_loss: 0.3971 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.94595\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0069 - accuracy: 0.9968 - val_loss: 0.3689 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.94595\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.7258 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.94595\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.6817 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.94595\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.5798 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.94595\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.6176 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.94595\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.5419 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.94595\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.7333 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.94595\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.4825 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.94595\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.6165 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.94595\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.5696 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.94595\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0364 - accuracy: 0.9900 - val_loss: 0.6874 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.94595\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.5322 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.94595\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.6828 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.94595\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.6073 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.94595\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0064 - accuracy: 0.9968 - val_loss: 0.5508 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.94595\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0269 - accuracy: 0.9932 - val_loss: 0.6722 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.94595\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.6150 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.94595\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 0.6331 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.94595\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.5528 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.94595\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.94595\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0182 - accuracy: 0.9916 - val_loss: 0.7406 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.94595\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0112 - accuracy: 0.9942 - val_loss: 0.5522 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.94595\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.6502 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.94595\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0252 - accuracy: 0.9942 - val_loss: 0.6676 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.94595\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.5715 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.94595\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6982 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.94595\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0569 - accuracy: 0.9884 - val_loss: 0.5724 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.94595\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.6554 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.94595\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0140 - accuracy: 0.9926 - val_loss: 0.4834 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.94595\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.5913 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.94595\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.4267 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.94595\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.5726 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.94595\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0190 - accuracy: 0.9926 - val_loss: 0.6802 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.94595\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.5260 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.94595\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.7654 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.94595\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.8781 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.94595\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0236 - accuracy: 0.9942 - val_loss: 0.7423 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.94595\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0249 - accuracy: 0.9937 - val_loss: 0.7575 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.94595\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0204 - accuracy: 0.9953 - val_loss: 0.6836 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.94595\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.5915 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.94595\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 0.7109 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.94595\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.5756 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.94595\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.5900 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.94595\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.4913 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.94595\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.6125 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.94595\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0426 - accuracy: 0.9879 - val_loss: 0.9492 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.94595\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.4437 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.94595\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 0.5801 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.94595\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.6004 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.94595\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.5353 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.94595\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.6152 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.94595\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.6221 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.94595\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.6956 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.94595\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0179 - accuracy: 0.9958 - val_loss: 0.4423 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.94595\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.4848 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.94595\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.5826 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.94595\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.6031 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.94595\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0046 - accuracy: 0.9974 - val_loss: 0.4818 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.94595\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.5636 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.94595\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.3463 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.94595\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 0.5468 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.94595\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.3241 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.94595\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0122 - accuracy: 0.9942 - val_loss: 0.5539 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.94595\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.8991 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.94595\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0232 - accuracy: 0.9958 - val_loss: 0.6654 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.94595\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0423 - accuracy: 0.9911 - val_loss: 0.5504 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.94595\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.5350 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.94595\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.5470 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.94595\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.6861 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.94595\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.4239 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.94595\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.7600 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.94595\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0269 - accuracy: 0.9916 - val_loss: 1.0343 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.94595\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.4846 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.94595\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.5027 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.94595\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.6861 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.94595\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.4200 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.94595\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.6593 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.94595\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.6670 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.94595\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.5561 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.94595\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.5003 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.94595\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.94595\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4878 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.94595\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.94595\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 5.6466e-04 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.94595\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 5.9348e-04 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.94595\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 9.3274e-04 - accuracy: 0.9995 - val_loss: 0.4931 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.94595\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0174 - accuracy: 0.9968 - val_loss: 0.6381 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.94595\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0412 - accuracy: 0.9874 - val_loss: 0.5523 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.94595\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0338 - accuracy: 0.9900 - val_loss: 0.6762 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.94595\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.5279 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.94595\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5130 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.94595\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.6175 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.94595\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.4223 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.94595\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.6758 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.94595\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.7416 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.94595\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.4023 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.94595\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.94595\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.4881 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.94595\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5557 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.94595\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.5681 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.94595\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.4631 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.94595\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0482 - accuracy: 0.9905 - val_loss: 0.9001 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.94595\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.5259 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.94595\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.6289 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.94595\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4757 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.94595\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5893 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.94595\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 6.8388e-04 - accuracy: 1.0000 - val_loss: 0.6465 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.94595\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 5.4910e-04 - accuracy: 1.0000 - val_loss: 0.5721 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.94595\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 9.1830e-04 - accuracy: 0.9995 - val_loss: 0.5365 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.94595\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 1.7068e-04 - accuracy: 1.0000 - val_loss: 0.5901 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.94595\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 1.4952e-04 - accuracy: 1.0000 - val_loss: 0.4593 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.94595\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.94595\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0639 - accuracy: 0.9858 - val_loss: 0.3716 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.94595\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.3623 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.94595\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.5436 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.94595\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.5109 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.94595\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.4772 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.94595\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0234 - accuracy: 0.9947 - val_loss: 0.5274 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.94595\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0267 - accuracy: 0.9958 - val_loss: 0.5131 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.94595\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.3970 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.94595\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0256 - accuracy: 0.9947 - val_loss: 0.4719 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.94595\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4342 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.94595\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 7.1753e-04 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.94595\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.3629 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.94595\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.5859 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.94595\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.6729 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.94595\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.5212 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.94595\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.4693 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.94595\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 7.3733e-04 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.94595\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.7073 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.94595\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.5813 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.94595\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6038 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.94595\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.3673 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.94595\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.6284 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.94595\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.5218 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.94595\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.3918 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.94595\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0349 - accuracy: 0.9921 - val_loss: 0.3888 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.94595\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.5982 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.94595\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.6220 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.94595\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4361 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.94595\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.4914 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.94595\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0206 - accuracy: 0.9958 - val_loss: 0.4798 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.94595\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.6855 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.94595\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.6055 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.94595\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.6511 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.94595\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.4266 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.94595\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.5354 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.94595\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.6296 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.94595\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0116 - accuracy: 0.9984 - val_loss: 0.7876 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.94595\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.5083 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.94595\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6621 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.94595\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.7439 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.94595\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 8.4907e-04 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.94595\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.6358 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.94595\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.8590 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.94595\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.8894 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.94595\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0257 - accuracy: 0.9932 - val_loss: 0.5329 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.94595\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.6173 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.94595\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.5331 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.94595\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.7576 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.94595\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.5689 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.94595\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.5258 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.94595\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.6019 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.94595\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.5313 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.94595\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.4595 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.94595\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.3670 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.94595\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.5896 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.94595\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.5287 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.94595\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.4662 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.94595\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.9717 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.94595\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.6156 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.94595\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.6695 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.94595\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0089 - accuracy: 0.9953 - val_loss: 0.7413 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.94595\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.8401 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.94595\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.8816 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.94595\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.7545 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.94595\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.6929 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.94595\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.6811 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.94595\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.6676 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.94595\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.7422 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.94595\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.94595\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.4181 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.94595\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 8.1549e-04 - accuracy: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.94595\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.9485 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.94595\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.6842 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.94595\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0214 - accuracy: 0.9947 - val_loss: 0.8354 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.94595\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.7225 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.94595\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.5462 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.94595\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.5440 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94595\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.5531 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94595\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.7194 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94595\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.8358 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94595\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.8729 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94595\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94595\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 6.8893e-04 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94595\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 5.0073e-04 - accuracy: 1.0000 - val_loss: 0.6064 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94595\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.5390 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94595\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 2.4614e-04 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94595\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 1.0769e-04 - accuracy: 1.0000 - val_loss: 0.6963 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94595\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 3.3093e-04 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94595\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0185 - accuracy: 0.9968 - val_loss: 1.3621 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94595\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 0.6302 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.94595\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.5157 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94595\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.7468 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94595\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.6813 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94595\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.8648 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94595\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.7137 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94595\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.6459 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94595\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 3.3857e-04 - accuracy: 1.0000 - val_loss: 0.6618 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94595\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 9.8536e-04 - accuracy: 0.9995 - val_loss: 0.8940 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94595\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 8.3152e-04 - accuracy: 1.0000 - val_loss: 0.7536 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94595\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.8010 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94595\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 0.6602 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94595\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.5387 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94595\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6647 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94595\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.8103 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94595\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 0.7101 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94595\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.8374 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94595\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.8672 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94595\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.5057 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94595\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.5896 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94595\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.8424 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94595\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.6528 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94595\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 0.5438 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94595\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.6643 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94595\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.6976 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94595\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.5445 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94595\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 8.5749e-04 - accuracy: 0.9995 - val_loss: 0.7306 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94595\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 2.7091e-04 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94595\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.8441 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94595\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.7174 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94595\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.9899 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94595\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.8154 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94595\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0190 - accuracy: 0.9958 - val_loss: 0.5393 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94595\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.5407 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94595\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.5462 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94595\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.6878 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94595\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.4291 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94595\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 1.7674e-04 - accuracy: 1.0000 - val_loss: 0.4392 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94595\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 5.2521e-04 - accuracy: 1.0000 - val_loss: 0.4695 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94595\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 4.3103e-04 - accuracy: 1.0000 - val_loss: 0.5537 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94595\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.3767 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94595\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.6493 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94595\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0240 - accuracy: 0.9953 - val_loss: 0.7663 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94595\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.5870 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94595\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.4497 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94595\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.4681 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94595\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.5935 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94595\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.4402 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00446: val_accuracy improved from 0.94595 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet169_5.h5\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.6043 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95270\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 4.8628e-04 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95270\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.5297 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95270\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.9059 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95270\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.6708 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95270\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.5646 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95270\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.6983 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95270\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0052 - accuracy: 0.9974 - val_loss: 0.6725 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95270\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.7006 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95270\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0200 - accuracy: 0.9953 - val_loss: 0.8754 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95270\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.5769 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95270\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.6759 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95270\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.6246 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95270\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.5738 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95270\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 5.6483e-04 - accuracy: 1.0000 - val_loss: 0.6834 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95270\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.5674 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95270\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.7250 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95270\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.5318 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95270\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.7069 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95270\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.5833 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95270\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.6940 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95270\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.6169 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95270\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.6530 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95270\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.7215 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95270\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.7869 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95270\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 7.4527e-04 - accuracy: 1.0000 - val_loss: 0.7977 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95270\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 2.2559e-04 - accuracy: 1.0000 - val_loss: 0.7679 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95270\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 3.1723e-04 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95270\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 7.4486e-04 - accuracy: 0.9995 - val_loss: 0.7586 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95270\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 23s 94ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.5177 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95270\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.8809 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95270\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.8464 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95270\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.5014 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95270\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.5834 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95270\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0035 - accuracy: 0.9979 - val_loss: 0.7275 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95270\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5782 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95270\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.5860 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95270\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.8555 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95270\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0273 - accuracy: 0.9926 - val_loss: 0.7053 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95270\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.5740 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95270\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.3816 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95270\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.7109 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95270\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.6478 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95270\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.6816 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95270\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.7447 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95270\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.5970 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95270\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 8.1777e-04 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95270\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.5534 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95270\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.8037 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95270\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 6.2701e-04 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95270\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 2.1996e-04 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95270\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 1.0382e-04 - accuracy: 1.0000 - val_loss: 0.7694 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95270\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 1.1242e-04 - accuracy: 1.0000 - val_loss: 0.5534 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95270\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.5166 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fab741574d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "17ca7840-15ce-4322-92d0-b4ab68e75247"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06466d9-b36a-4eee-82f9-cfe9ef6f67c5"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d120a839-ec8a-46e9-a034-c60521fc43c9"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "25b5c6f4-393a-4854-b408-cee06248ee11"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_dbbdf327-a0f9-441e-a2ce-36762fa11697\", \"DenseNet169_5.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZ06MWjdN2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e10c97-7721-4d82-e571-907389292df4"
      },
      "source": [
        "!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: dacon-submit-api\n",
            "Successfully installed dacon-submit-api-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKDp3mdOZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e53c83-6389-4d6e-bf99-e2f8e4989eea"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    # 파일경로\n",
        "    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n",
        "    # d9249@kyonggi.ac.kr\n",
        "    # 대회 ID\n",
        "    '235626',\n",
        "    # d9249@kyonggi.ac.kr 팀이릉\n",
        "    # 'iDeal9',\n",
        "    # dodo9249@gmail.com 팀이름\n",
        "    # 'iDeal96',\n",
        "    # d9249.acc001@gmail.com\n",
        "    # 'iDeal01',\n",
        "    # meanideal96@gamil.com\n",
        "    # 'iDeal02',\n",
        "    # dodo402298@gmail.com\n",
        "    'mean01',\n",
        "    # d9249.acc002@gmail.com\n",
        "    # 'mean02',\n",
        "    # memo\n",
        "    'd9249_kyonggi_ac_kr' )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"
          ]
        }
      ]
    }
  ]
}