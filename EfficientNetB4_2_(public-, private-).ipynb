{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB4_2_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/EfficientNetB4_2_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5004d6e7-6eeb-43d6-cfff-89b589066254"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 29 05:14:15 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c855c55f-a8ec-4640-c570-5e07e41777a2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "nunbering = '4'\n",
        "model_save = 'EfficientNetB' + nunbering + '_2'\n",
        "Target_model = 'EfficientNetB' + nunbering + '_model'\n",
        "Target_predict = 'EfficientNetB' + nunbering + '_predict'\n",
        "Target_acc = 'EfficientNetB' + nunbering + '_acc'\n",
        "Target_val = 'EfficientNetB' + nunbering + '_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.EfficientNetB2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d085e139-45dc-4bea-a66c-6aef65bcb719"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc215e8-8c46-49ee-982f-ab6799ea0414"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 67s 155ms/step - loss: 3.3474 - accuracy: 0.1474 - val_loss: 2.7195 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_2.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 2.2575 - accuracy: 0.2374 - val_loss: 2.5336 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10135\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 1.8627 - accuracy: 0.3589 - val_loss: 2.6326 - val_accuracy: 0.1216\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.10135 to 0.12162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_2.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 1.4849 - accuracy: 0.4853 - val_loss: 1.3303 - val_accuracy: 0.5743\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.12162 to 0.57432, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_2.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 1.1681 - accuracy: 0.6089 - val_loss: 0.9478 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.57432 to 0.67568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_2.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 1.0176 - accuracy: 0.6684 - val_loss: 1.1137 - val_accuracy: 0.6419\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.67568\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.8477 - accuracy: 0.7211 - val_loss: 1.1783 - val_accuracy: 0.6689\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.67568\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.7722 - accuracy: 0.7511 - val_loss: 0.5702 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.67568 to 0.81757, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_2.h5\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.6985 - accuracy: 0.7753 - val_loss: 0.6352 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.81757\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 34s 141ms/step - loss: 0.6244 - accuracy: 0.8026 - val_loss: 0.7702 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.81757\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.6098 - accuracy: 0.7932 - val_loss: 0.4620 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.81757 to 0.85135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_2.h5\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.5830 - accuracy: 0.8168 - val_loss: 0.6915 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.85135\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 0.5420 - accuracy: 0.8253 - val_loss: 0.5864 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.85135\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.4885 - accuracy: 0.8442 - val_loss: 0.6398 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.85135\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.4323 - accuracy: 0.8600 - val_loss: 0.6459 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.85135\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 34s 145ms/step - loss: 0.5097 - accuracy: 0.8421 - val_loss: 0.6451 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.85135\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 0.4455 - accuracy: 0.8605 - val_loss: 0.4253 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.85135\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.4211 - accuracy: 0.8726 - val_loss: 0.6063 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.85135\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.3533 - accuracy: 0.8863 - val_loss: 1.2706 - val_accuracy: 0.6284\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.85135\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 34s 145ms/step - loss: 0.4143 - accuracy: 0.8595 - val_loss: 0.6455 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.85135\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.3739 - accuracy: 0.8874 - val_loss: 0.4211 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.85135 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_2.h5\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.3984 - accuracy: 0.8742 - val_loss: 0.3361 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.87162\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 0.3226 - accuracy: 0.8874 - val_loss: 0.7472 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.87162\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.3791 - accuracy: 0.8789 - val_loss: 0.7450 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.87162\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.3083 - accuracy: 0.8958 - val_loss: 1.1577 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.87162\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.3112 - accuracy: 0.9011 - val_loss: 0.4652 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.87162 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_2.h5\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.2822 - accuracy: 0.9063 - val_loss: 0.4255 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.89865\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.3141 - accuracy: 0.8995 - val_loss: 0.6326 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.89865\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.2408 - accuracy: 0.9189 - val_loss: 2.1364 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.89865\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.2680 - accuracy: 0.9189 - val_loss: 0.3942 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.89865\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.2772 - accuracy: 0.9079 - val_loss: 1.2445 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.89865\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.2482 - accuracy: 0.9174 - val_loss: 0.5858 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.89865\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.2704 - accuracy: 0.9163 - val_loss: 0.6952 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.89865\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 34s 141ms/step - loss: 0.1833 - accuracy: 0.9405 - val_loss: 0.4810 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.89865\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 33s 140ms/step - loss: 0.2310 - accuracy: 0.9258 - val_loss: 0.5884 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.89865\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 33s 139ms/step - loss: 0.2279 - accuracy: 0.9221 - val_loss: 5.9645 - val_accuracy: 0.1284\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.89865\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.2361 - accuracy: 0.9195 - val_loss: 0.5604 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.89865\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.2163 - accuracy: 0.9316 - val_loss: 0.3292 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.89865\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 0.2239 - accuracy: 0.9242 - val_loss: 0.4153 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.89865\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 0.2024 - accuracy: 0.9474 - val_loss: 1.3319 - val_accuracy: 0.6351\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.89865\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 0.1822 - accuracy: 0.9453 - val_loss: 4.0061 - val_accuracy: 0.1419\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.89865\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.2057 - accuracy: 0.9389 - val_loss: 0.5543 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89865\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.1366 - accuracy: 0.9553 - val_loss: 0.6596 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89865\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.1895 - accuracy: 0.9416 - val_loss: 0.4430 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89865\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.1808 - accuracy: 0.9411 - val_loss: 0.7112 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89865\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.1721 - accuracy: 0.9458 - val_loss: 0.3952 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89865\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.1203 - accuracy: 0.9574 - val_loss: 0.5394 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89865\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.1551 - accuracy: 0.9563 - val_loss: 0.5494 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89865\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 0.1432 - accuracy: 0.9532 - val_loss: 3.8362 - val_accuracy: 0.3514\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89865\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 0.1793 - accuracy: 0.9484 - val_loss: 0.4477 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89865\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.1129 - accuracy: 0.9611 - val_loss: 0.3880 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.89865 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_2.h5\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.1195 - accuracy: 0.9600 - val_loss: 0.6935 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.90541\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.1679 - accuracy: 0.9426 - val_loss: 7.1876 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.90541\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.1337 - accuracy: 0.9589 - val_loss: 0.4348 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.90541\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.1357 - accuracy: 0.9595 - val_loss: 0.5957 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.90541\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 0.1138 - accuracy: 0.9626 - val_loss: 0.6085 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.90541\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.1071 - accuracy: 0.9663 - val_loss: 0.5839 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.90541\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.1698 - accuracy: 0.9479 - val_loss: 1.4269 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.90541\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 34s 142ms/step - loss: 0.1058 - accuracy: 0.9621 - val_loss: 0.6056 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.90541\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 34s 145ms/step - loss: 0.0776 - accuracy: 0.9737 - val_loss: 0.5010 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.90541\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.1455 - accuracy: 0.9526 - val_loss: 0.5980 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.90541\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 34s 145ms/step - loss: 0.1318 - accuracy: 0.9595 - val_loss: 0.5551 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.90541\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.1129 - accuracy: 0.9626 - val_loss: 0.9432 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.90541\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.1201 - accuracy: 0.9626 - val_loss: 1.0109 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.90541\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 0.0882 - accuracy: 0.9684 - val_loss: 1.1583 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.90541\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 34s 143ms/step - loss: 0.0918 - accuracy: 0.9668 - val_loss: 0.3901 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.90541 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_2.h5\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.1243 - accuracy: 0.9558 - val_loss: 0.4559 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.92568\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.0879 - accuracy: 0.9695 - val_loss: 0.4857 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.92568\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.1089 - accuracy: 0.9668 - val_loss: 0.4030 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.92568\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0570 - accuracy: 0.9826 - val_loss: 0.2617 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.92568\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0798 - accuracy: 0.9732 - val_loss: 0.4712 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.92568\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.1218 - accuracy: 0.9563 - val_loss: 1.2325 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.92568\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.1055 - accuracy: 0.9658 - val_loss: 1.1118 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.92568\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.1042 - accuracy: 0.9632 - val_loss: 0.4297 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.92568\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0851 - accuracy: 0.9732 - val_loss: 0.5131 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.92568\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0756 - accuracy: 0.9742 - val_loss: 1.0362 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.92568\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0889 - accuracy: 0.9711 - val_loss: 0.6825 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.92568\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0813 - accuracy: 0.9716 - val_loss: 0.7198 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.92568\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0814 - accuracy: 0.9742 - val_loss: 0.5807 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.92568\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0848 - accuracy: 0.9747 - val_loss: 0.4387 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.92568\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0835 - accuracy: 0.9753 - val_loss: 0.4911 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.92568\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0607 - accuracy: 0.9784 - val_loss: 0.7922 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.92568\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0865 - accuracy: 0.9726 - val_loss: 0.4342 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.92568\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.1162 - accuracy: 0.9626 - val_loss: 2.1538 - val_accuracy: 0.5473\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.92568\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 34s 145ms/step - loss: 0.0797 - accuracy: 0.9774 - val_loss: 1.5096 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.92568\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 34s 145ms/step - loss: 0.0666 - accuracy: 0.9779 - val_loss: 0.4034 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.92568\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.0794 - accuracy: 0.9737 - val_loss: 0.5916 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.92568\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0721 - accuracy: 0.9763 - val_loss: 0.4188 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.92568\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0622 - accuracy: 0.9795 - val_loss: 0.6476 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.92568\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0619 - accuracy: 0.9805 - val_loss: 0.5013 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.92568\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0542 - accuracy: 0.9816 - val_loss: 4.6110 - val_accuracy: 0.3716\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.92568\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0786 - accuracy: 0.9753 - val_loss: 0.6390 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.92568\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0825 - accuracy: 0.9716 - val_loss: 0.4573 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.92568\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0630 - accuracy: 0.9816 - val_loss: 0.5039 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.92568\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0802 - accuracy: 0.9758 - val_loss: 0.5371 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.92568\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0441 - accuracy: 0.9874 - val_loss: 2.0487 - val_accuracy: 0.5541\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.92568\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0458 - accuracy: 0.9863 - val_loss: 7.1119 - val_accuracy: 0.2095\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.92568\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0541 - accuracy: 0.9821 - val_loss: 0.5247 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.92568\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0787 - accuracy: 0.9732 - val_loss: 0.5672 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.92568\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0933 - accuracy: 0.9726 - val_loss: 0.6950 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.92568\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0595 - accuracy: 0.9774 - val_loss: 0.3648 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.92568\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0657 - accuracy: 0.9800 - val_loss: 1.5178 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.92568\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0513 - accuracy: 0.9832 - val_loss: 0.5177 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.92568\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0601 - accuracy: 0.9816 - val_loss: 0.4037 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.92568\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0715 - accuracy: 0.9763 - val_loss: 0.5170 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.92568\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0529 - accuracy: 0.9821 - val_loss: 0.4729 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.92568\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0548 - accuracy: 0.9837 - val_loss: 0.4460 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.92568\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.3613 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00108: val_accuracy improved from 0.92568 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_2.h5\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0631 - accuracy: 0.9826 - val_loss: 4.0212 - val_accuracy: 0.3514\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.93243\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 0.8991 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.93243\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0436 - accuracy: 0.9821 - val_loss: 0.4795 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.93243\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0724 - accuracy: 0.9768 - val_loss: 0.8117 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.93243\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0448 - accuracy: 0.9837 - val_loss: 0.4948 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.93243\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.0747 - accuracy: 0.9811 - val_loss: 1.3019 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.93243\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.0356 - accuracy: 0.9905 - val_loss: 0.5855 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.93243\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0480 - accuracy: 0.9832 - val_loss: 0.6250 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.93243\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 34s 145ms/step - loss: 0.0673 - accuracy: 0.9816 - val_loss: 0.7812 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.93243\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0460 - accuracy: 0.9847 - val_loss: 0.4646 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.93243\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0511 - accuracy: 0.9826 - val_loss: 0.5334 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.93243\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0519 - accuracy: 0.9832 - val_loss: 3.6660 - val_accuracy: 0.3446\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.93243\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.0599 - accuracy: 0.9837 - val_loss: 0.5955 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.93243\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0505 - accuracy: 0.9837 - val_loss: 0.4623 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.93243\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0464 - accuracy: 0.9837 - val_loss: 0.8976 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.93243\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0515 - accuracy: 0.9847 - val_loss: 0.6499 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.93243\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 0.7949 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.93243\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.4666 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.93243\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0441 - accuracy: 0.9874 - val_loss: 0.4601 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.93243 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_2.h5\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0433 - accuracy: 0.9832 - val_loss: 1.0294 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.93919\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0494 - accuracy: 0.9868 - val_loss: 0.5897 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.93919\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0519 - accuracy: 0.9847 - val_loss: 3.7467 - val_accuracy: 0.5405\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.93919\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0657 - accuracy: 0.9805 - val_loss: 0.7132 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.93919\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 0.7375 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.93919\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0434 - accuracy: 0.9874 - val_loss: 0.5410 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.93919\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0533 - accuracy: 0.9868 - val_loss: 0.5410 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.93919\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0412 - accuracy: 0.9879 - val_loss: 0.4520 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.93919\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0328 - accuracy: 0.9889 - val_loss: 0.4885 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.93919\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.5654 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.93919\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0448 - accuracy: 0.9847 - val_loss: 0.6292 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.93919\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0435 - accuracy: 0.9858 - val_loss: 0.4940 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.93919\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.4327 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.93919\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0721 - accuracy: 0.9737 - val_loss: 0.5867 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.93919\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.0550 - accuracy: 0.9821 - val_loss: 0.6252 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.93919\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.0501 - accuracy: 0.9863 - val_loss: 0.6042 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.93919\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0333 - accuracy: 0.9895 - val_loss: 0.4470 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93919\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0378 - accuracy: 0.9874 - val_loss: 0.5650 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93919\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 34s 144ms/step - loss: 0.0389 - accuracy: 0.9847 - val_loss: 0.5912 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93919\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0224 - accuracy: 0.9916 - val_loss: 1.2624 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93919\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0362 - accuracy: 0.9895 - val_loss: 0.6831 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93919\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0649 - accuracy: 0.9811 - val_loss: 0.7156 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93919\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0369 - accuracy: 0.9905 - val_loss: 0.5613 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93919\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0350 - accuracy: 0.9863 - val_loss: 0.4257 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93919\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 34s 145ms/step - loss: 0.0393 - accuracy: 0.9853 - val_loss: 0.7906 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93919\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 0.6475 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93919\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0440 - accuracy: 0.9847 - val_loss: 0.7728 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.93919\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0253 - accuracy: 0.9900 - val_loss: 0.6715 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93919\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.0575 - accuracy: 0.9832 - val_loss: 0.6293 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93919\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0500 - accuracy: 0.9816 - val_loss: 0.7796 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93919\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.6317 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.93919\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0304 - accuracy: 0.9895 - val_loss: 0.8017 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.93919\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 0.5275 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.93919\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0616 - accuracy: 0.9811 - val_loss: 0.5747 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.93919\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 0.4055 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.93919\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.4586 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.93919\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0266 - accuracy: 0.9916 - val_loss: 0.5823 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.93919\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0537 - accuracy: 0.9842 - val_loss: 0.9155 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.93919\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0508 - accuracy: 0.9863 - val_loss: 0.2960 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.93919\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0418 - accuracy: 0.9842 - val_loss: 0.3195 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.93919\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0603 - accuracy: 0.9811 - val_loss: 0.4344 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.93919\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.4058 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.93919\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.3115 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.93919\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.4756 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.93919\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.4974 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.93919\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.5206 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.93919\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0474 - accuracy: 0.9816 - val_loss: 0.6137 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.93919\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0581 - accuracy: 0.9837 - val_loss: 0.8940 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.93919\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0248 - accuracy: 0.9905 - val_loss: 0.3994 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.93919\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0328 - accuracy: 0.9874 - val_loss: 0.6652 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.93919\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.6604 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.93919\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0351 - accuracy: 0.9879 - val_loss: 0.6891 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93919\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 1.5848 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93919\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0351 - accuracy: 0.9900 - val_loss: 0.4530 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93919\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0340 - accuracy: 0.9911 - val_loss: 0.3470 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93919\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0551 - accuracy: 0.9863 - val_loss: 2.0582 - val_accuracy: 0.7095\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93919\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0397 - accuracy: 0.9879 - val_loss: 0.8258 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93919\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.4664 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93919\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0424 - accuracy: 0.9826 - val_loss: 0.6384 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93919\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0374 - accuracy: 0.9847 - val_loss: 0.6028 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93919\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 1.1290 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93919\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.6508 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93919\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0443 - accuracy: 0.9895 - val_loss: 0.6668 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93919\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0339 - accuracy: 0.9905 - val_loss: 0.5090 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93919\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.0364 - accuracy: 0.9874 - val_loss: 0.3580 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93919\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 35s 145ms/step - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.7514 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93919\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0390 - accuracy: 0.9868 - val_loss: 0.4481 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93919\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0291 - accuracy: 0.9916 - val_loss: 0.6001 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93919\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0373 - accuracy: 0.9868 - val_loss: 0.3906 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93919\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.4404 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93919\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0229 - accuracy: 0.9947 - val_loss: 0.4358 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93919\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0281 - accuracy: 0.9926 - val_loss: 0.5168 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93919\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.4414 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93919\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.4906 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93919\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.5452 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93919\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0653 - accuracy: 0.9811 - val_loss: 0.4418 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93919\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0284 - accuracy: 0.9889 - val_loss: 0.6072 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93919\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0392 - accuracy: 0.9889 - val_loss: 0.6574 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93919\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.6169 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93919\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.7165 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93919\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0293 - accuracy: 0.9932 - val_loss: 0.3619 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93919\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.7196 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93919\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0434 - accuracy: 0.9889 - val_loss: 0.5659 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93919\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0393 - accuracy: 0.9858 - val_loss: 0.7296 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93919\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0371 - accuracy: 0.9900 - val_loss: 0.4843 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93919\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0385 - accuracy: 0.9884 - val_loss: 0.5674 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93919\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0146 - accuracy: 0.9942 - val_loss: 0.8193 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93919\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.5262 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93919\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.6887 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93919\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.5157 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93919\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0365 - accuracy: 0.9879 - val_loss: 0.8157 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93919\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0351 - accuracy: 0.9916 - val_loss: 0.6282 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93919\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.4471 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93919\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.5267 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93919\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.5594 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93919\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.6584 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93919\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0404 - accuracy: 0.9921 - val_loss: 0.6815 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93919\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0450 - accuracy: 0.9884 - val_loss: 0.4073 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93919\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.6644 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93919\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0336 - accuracy: 0.9911 - val_loss: 0.6587 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93919\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0426 - accuracy: 0.9889 - val_loss: 0.5646 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93919\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0435 - accuracy: 0.9879 - val_loss: 0.6549 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93919\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0296 - accuracy: 0.9895 - val_loss: 0.7895 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93919\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0165 - accuracy: 0.9932 - val_loss: 0.6319 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93919\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0165 - accuracy: 0.9963 - val_loss: 0.6391 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93919\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0425 - accuracy: 0.9889 - val_loss: 0.6669 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93919\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0336 - accuracy: 0.9895 - val_loss: 0.6079 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93919\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.5721 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93919\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.6673 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93919\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.6714 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93919\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0224 - accuracy: 0.9937 - val_loss: 0.7601 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93919\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.5893 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93919\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.8073 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93919\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.6037 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93919\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0513 - accuracy: 0.9847 - val_loss: 0.5596 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93919\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0345 - accuracy: 0.9900 - val_loss: 0.6160 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93919\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0245 - accuracy: 0.9911 - val_loss: 0.5337 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93919\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0277 - accuracy: 0.9937 - val_loss: 0.5122 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93919\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.3424 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93919\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0238 - accuracy: 0.9895 - val_loss: 0.5202 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93919\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.5630 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93919\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 3.0878 - val_accuracy: 0.6351\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93919\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0216 - accuracy: 0.9911 - val_loss: 0.5153 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93919\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.4137 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93919\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 0.4326 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93919\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.5817 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93919\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0510 - accuracy: 0.9863 - val_loss: 0.8860 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93919\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.8819 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93919\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.6121 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93919\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.6030 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93919\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.6821 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93919\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.6202 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93919\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.7784 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93919\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0100 - accuracy: 0.9942 - val_loss: 0.6616 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93919\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.9764 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93919\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0841 - accuracy: 0.9795 - val_loss: 0.4433 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93919\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.4371 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93919\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0478 - accuracy: 0.9874 - val_loss: 0.6255 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93919\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.6173 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93919\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0411 - accuracy: 0.9863 - val_loss: 0.4527 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93919\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.4906 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93919\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.4625 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93919\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.5485 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93919\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.4569 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93919\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.5669 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93919\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0346 - accuracy: 0.9900 - val_loss: 0.5361 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93919\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.6386 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93919\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0258 - accuracy: 0.9942 - val_loss: 0.6344 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93919\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.4673 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93919\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 0.5465 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93919\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 0.6304 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93919\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.4658 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93919\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.5713 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93919\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.4479 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93919\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0394 - accuracy: 0.9868 - val_loss: 0.3889 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93919\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0281 - accuracy: 0.9942 - val_loss: 0.6352 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93919\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0201 - accuracy: 0.9953 - val_loss: 0.7506 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93919\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.5030 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93919\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.5360 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93919\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.6827 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93919\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0328 - accuracy: 0.9889 - val_loss: 0.5854 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93919\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0155 - accuracy: 0.9942 - val_loss: 0.5237 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93919\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.4693 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93919\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.6338 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93919\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 0.7945 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93919\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 0.5259 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93919\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.8476 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93919\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0411 - accuracy: 0.9863 - val_loss: 0.6290 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93919\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0471 - accuracy: 0.9889 - val_loss: 0.6558 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93919\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0229 - accuracy: 0.9942 - val_loss: 0.6287 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93919\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.5404 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93919\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.6331 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93919\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.5464 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93919\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.6697 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93919\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.5629 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93919\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.6941 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93919\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0251 - accuracy: 0.9942 - val_loss: 0.5541 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93919\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.4911 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93919\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0348 - accuracy: 0.9905 - val_loss: 0.8111 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93919\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0402 - accuracy: 0.9905 - val_loss: 0.6324 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93919\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.4765 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93919\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.4421 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93919\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.5131 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93919\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0352 - accuracy: 0.9895 - val_loss: 0.5979 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93919\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 0.5955 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93919\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.3935 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93919\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 35s 146ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.5585 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93919\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 35s 147ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.6100 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93919\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 36s 149ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.7758 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93919\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 35s 149ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.7397 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93919\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 35s 148ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 0.6994 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93919\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.6292 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93919\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0194 - accuracy: 0.9926 - val_loss: 0.7518 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93919\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.3906 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93919\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.7523 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93919\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.6744 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93919\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 1.0043 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93919\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.5716 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93919\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.7075 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93919\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.4857 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93919\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.3351 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93919\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.4451 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93919\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0304 - accuracy: 0.9911 - val_loss: 0.4441 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93919\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0231 - accuracy: 0.9916 - val_loss: 0.5827 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93919\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.5189 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93919\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0250 - accuracy: 0.9895 - val_loss: 0.7977 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93919\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.3999 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93919\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 1.0141 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93919\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.6166 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93919\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0155 - accuracy: 0.9942 - val_loss: 0.7640 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93919\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.4416 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93919\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.4462 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93919\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.5179 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93919\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0342 - accuracy: 0.9889 - val_loss: 0.6053 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93919\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0258 - accuracy: 0.9895 - val_loss: 0.5822 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93919\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.5434 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93919\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.5942 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93919\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0205 - accuracy: 0.9926 - val_loss: 0.7723 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93919\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.6022 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93919\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 0.5369 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93919\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5664 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93919\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0231 - accuracy: 0.9937 - val_loss: 0.5545 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93919\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.4782 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93919\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0194 - accuracy: 0.9926 - val_loss: 0.6338 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93919\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0186 - accuracy: 0.9958 - val_loss: 0.6235 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93919\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.6264 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93919\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.7762 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93919\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0263 - accuracy: 0.9900 - val_loss: 0.6240 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93919\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0275 - accuracy: 0.9926 - val_loss: 0.7865 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93919\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0283 - accuracy: 0.9916 - val_loss: 0.5068 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93919\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.3781 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93919\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.4700 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93919\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0088 - accuracy: 0.9953 - val_loss: 0.6191 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93919\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.4574 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93919\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.5686 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93919\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.7387 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93919\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0303 - accuracy: 0.9916 - val_loss: 0.8310 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93919\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 1.2609 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93919\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.6684 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93919\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.6193 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93919\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.6528 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93919\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0351 - accuracy: 0.9932 - val_loss: 0.6407 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93919\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.3957 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93919\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.4981 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93919\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 0.6089 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93919\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.4275 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93919\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.4254 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93919\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.5827 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93919\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0401 - accuracy: 0.9911 - val_loss: 0.5224 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93919\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0223 - accuracy: 0.9953 - val_loss: 0.6005 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93919\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0304 - accuracy: 0.9921 - val_loss: 0.3335 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93919\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.5375 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93919\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.6696 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93919\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.4371 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93919\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.5312 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93919\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.4126 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93919\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.3830 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93919\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 0.3973 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93919\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.4839 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93919\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0307 - accuracy: 0.9942 - val_loss: 0.5343 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93919\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.5427 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93919\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.3755 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93919\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0053 - accuracy: 0.9974 - val_loss: 0.5148 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93919\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0138 - accuracy: 0.9942 - val_loss: 0.5762 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93919\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0292 - accuracy: 0.9916 - val_loss: 0.9869 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93919\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.5002 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93919\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.5560 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93919\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93919\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.5671 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93919\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0341 - accuracy: 0.9926 - val_loss: 0.6342 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93919\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.5005 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93919\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.6317 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93919\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0140 - accuracy: 0.9942 - val_loss: 0.6318 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93919\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.6860 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93919\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0362 - accuracy: 0.9937 - val_loss: 0.5906 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93919\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0239 - accuracy: 0.9916 - val_loss: 0.4926 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93919\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.8276 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93919\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0401 - accuracy: 0.9889 - val_loss: 0.4644 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93919\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.7181 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93919\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.5821 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93919\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.6200 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93919\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.6343 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93919\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.5991 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.93919\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.7059 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.93919\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0411 - accuracy: 0.9879 - val_loss: 0.7622 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.93919\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0293 - accuracy: 0.9921 - val_loss: 0.5533 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.93919\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.5385 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.93919\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.7443 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.93919\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.6204 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93919\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0180 - accuracy: 0.9932 - val_loss: 0.6663 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93919\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.7054 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93919\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.6631 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93919\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.5611 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.93919\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.6793 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.93919\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0354 - accuracy: 0.9916 - val_loss: 0.4780 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93919\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.5424 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93919\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.6603 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93919\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.6898 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93919\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.5591 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93919\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.5479 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93919\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0150 - accuracy: 0.9926 - val_loss: 0.6976 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93919\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.7715 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.93919\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.6906 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.93919\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 38s 157ms/step - loss: 0.0132 - accuracy: 0.9942 - val_loss: 0.9079 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.93919\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.9297 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.93919\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 3.0877 - val_accuracy: 0.6689\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.93919\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0337 - accuracy: 0.9921 - val_loss: 0.6408 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.93919\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.4778 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.93919\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.8152 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.93919\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0288 - accuracy: 0.9937 - val_loss: 1.1157 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.93919\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.7302 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.93919\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 1.0318 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.93919\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.6008 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.93919\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.8638 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.93919\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.5669 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.93919\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.9634 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.93919\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.7150 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.93919\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0333 - accuracy: 0.9932 - val_loss: 0.6789 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.93919\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.7512 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.93919\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.6229 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.93919\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.5017 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.93919\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 0.3790 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.93919\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.4412 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.93919\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.5289 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.93919\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.5749 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.93919\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.6393 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.93919\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.7875 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.93919\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0308 - accuracy: 0.9932 - val_loss: 0.3417 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00455: val_accuracy improved from 0.93919 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_2.h5\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0386 - accuracy: 0.9884 - val_loss: 0.4540 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94595\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.6201 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94595\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.4911 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94595\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4440 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94595\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.5221 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94595\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.5948 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94595\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.5518 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94595\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.5939 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94595\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.4940 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94595\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.4718 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94595\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.4449 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94595\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.4743 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94595\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.5074 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94595\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.3627 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94595\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0278 - accuracy: 0.9937 - val_loss: 0.5239 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94595\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0214 - accuracy: 0.9947 - val_loss: 0.5694 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94595\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.6138 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94595\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.6025 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94595\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.5957 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94595\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.8158 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94595\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0242 - accuracy: 0.9968 - val_loss: 0.7073 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94595\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.6729 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94595\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0181 - accuracy: 0.9926 - val_loss: 0.5221 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94595\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0079 - accuracy: 0.9963 - val_loss: 0.5354 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94595\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.6715 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94595\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0227 - accuracy: 0.9937 - val_loss: 0.6197 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94595\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0139 - accuracy: 0.9937 - val_loss: 0.4319 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94595\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.6271 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94595\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94595\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.6698 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94595\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.6470 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94595\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.6284 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94595\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0299 - accuracy: 0.9916 - val_loss: 0.7000 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94595\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0142 - accuracy: 0.9942 - val_loss: 0.9220 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94595\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0148 - accuracy: 0.9937 - val_loss: 0.8073 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94595\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0147 - accuracy: 0.9926 - val_loss: 0.5124 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94595\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.8514 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94595\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.7779 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94595\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.6563 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94595\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.8170 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94595\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.6328 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94595\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0192 - accuracy: 0.9926 - val_loss: 0.6282 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94595\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.8370 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94595\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.6194 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94595\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.5245 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94595\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3c900bf7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "62e21d6e-0408-4c62-fb5a-902809e5119e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c8f3c1-62be-4231-8c94-80c73a684890"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6ea27a4-9365-496f-9744-e6dedc78b5bc"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ae508965-a186-487c-efe5-3784cdd0f879"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b47ae9c3-613e-40dc-b5f2-8e03b07b994e\", \"EfficientNetB4_2.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}