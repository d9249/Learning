{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB4_4_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/EfficientNetB4_4_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "576b5e3e-379d-4395-9bee-bcfa1c1b0d50"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct  2 10:25:39 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c6dc0c-f3fb-445a-a853-d4a3f7df6d3a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "nunbering = '4'\n",
        "model_save = 'EfficientNetB' + nunbering + '_4'\n",
        "Target_model = 'EfficientNetB' + nunbering + '_model'\n",
        "Target_predict = 'EfficientNetB' + nunbering + '_predict'\n",
        "Target_acc = 'EfficientNetB' + nunbering + '_acc'\n",
        "Target_val = 'EfficientNetB' + nunbering + '_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.EfficientNetB4(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93203d6-c18a-4ca7-edf7-810e3a8c55a0"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3cb204b-2dc0-49fc-cb22-f02a99333925"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 73s 176ms/step - loss: 3.5038 - accuracy: 0.1395 - val_loss: 2.5535 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 2.1841 - accuracy: 0.2500 - val_loss: 2.5272 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10135\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 1.8747 - accuracy: 0.3468 - val_loss: 3.0306 - val_accuracy: 0.0878\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.10135\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 1.5085 - accuracy: 0.4953 - val_loss: 4.1896 - val_accuracy: 0.2027\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.10135 to 0.20270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 1.1397 - accuracy: 0.6263 - val_loss: 2.9736 - val_accuracy: 0.3176\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.20270 to 0.31757, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.9699 - accuracy: 0.6911 - val_loss: 1.9655 - val_accuracy: 0.4865\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.31757 to 0.48649, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.8366 - accuracy: 0.7363 - val_loss: 0.8254 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.48649 to 0.72297, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.7585 - accuracy: 0.7511 - val_loss: 1.4588 - val_accuracy: 0.5811\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.72297\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.7228 - accuracy: 0.7711 - val_loss: 0.5445 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.72297 to 0.79054, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.6112 - accuracy: 0.7942 - val_loss: 9.7976 - val_accuracy: 0.1351\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.79054\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.6078 - accuracy: 0.8095 - val_loss: 1.1996 - val_accuracy: 0.6892\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.79054\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.5984 - accuracy: 0.8163 - val_loss: 1.1415 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.79054\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.5555 - accuracy: 0.8232 - val_loss: 0.7165 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.79054\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.5153 - accuracy: 0.8395 - val_loss: 1.0378 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.79054\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.5236 - accuracy: 0.8353 - val_loss: 0.9150 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.79054\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.4760 - accuracy: 0.8521 - val_loss: 1.4381 - val_accuracy: 0.6216\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.79054\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.4654 - accuracy: 0.8453 - val_loss: 5.2292 - val_accuracy: 0.0946\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.79054\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.4364 - accuracy: 0.8558 - val_loss: 1.1052 - val_accuracy: 0.6824\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.79054\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.4127 - accuracy: 0.8732 - val_loss: 0.4563 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.79054 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.4145 - accuracy: 0.8763 - val_loss: 0.5423 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.87162\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.4135 - accuracy: 0.8684 - val_loss: 0.6276 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.87162\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.3956 - accuracy: 0.8758 - val_loss: 0.7011 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.87162\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.3511 - accuracy: 0.8895 - val_loss: 7.2911 - val_accuracy: 0.1622\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.87162\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.3876 - accuracy: 0.8795 - val_loss: 0.4248 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.87162\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.3596 - accuracy: 0.8884 - val_loss: 0.5364 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.87162\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.3659 - accuracy: 0.8853 - val_loss: 1.6096 - val_accuracy: 0.5743\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.87162\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.3362 - accuracy: 0.8858 - val_loss: 1.1413 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.87162\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.3278 - accuracy: 0.8963 - val_loss: 1.9599 - val_accuracy: 0.4932\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.87162\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.3250 - accuracy: 0.9021 - val_loss: 0.7306 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.87162\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2995 - accuracy: 0.9105 - val_loss: 2.5018 - val_accuracy: 0.5068\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.87162\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2777 - accuracy: 0.9063 - val_loss: 0.4536 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.87162\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2978 - accuracy: 0.9105 - val_loss: 1.3297 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.87162\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2831 - accuracy: 0.9121 - val_loss: 4.4613 - val_accuracy: 0.3176\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.87162\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2200 - accuracy: 0.9295 - val_loss: 1.5710 - val_accuracy: 0.6216\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.87162\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2443 - accuracy: 0.9226 - val_loss: 0.7112 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.87162\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2630 - accuracy: 0.9279 - val_loss: 0.5263 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.87162\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2661 - accuracy: 0.9242 - val_loss: 0.8333 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.87162\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.2586 - accuracy: 0.9258 - val_loss: 1.0320 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.87162\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2203 - accuracy: 0.9263 - val_loss: 7.8808 - val_accuracy: 0.1757\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.87162\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2195 - accuracy: 0.9295 - val_loss: 0.9265 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.87162\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2124 - accuracy: 0.9358 - val_loss: 0.9643 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.87162\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2317 - accuracy: 0.9195 - val_loss: 0.7329 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.87162\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2111 - accuracy: 0.9379 - val_loss: 1.1745 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.87162\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1950 - accuracy: 0.9316 - val_loss: 2.6228 - val_accuracy: 0.4595\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.87162\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2048 - accuracy: 0.9363 - val_loss: 0.6046 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.87162\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1703 - accuracy: 0.9421 - val_loss: 0.3518 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.87162 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2213 - accuracy: 0.9247 - val_loss: 0.2849 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.89189 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1592 - accuracy: 0.9505 - val_loss: 0.5464 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.92568\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1419 - accuracy: 0.9511 - val_loss: 1.6784 - val_accuracy: 0.6419\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.92568\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1370 - accuracy: 0.9563 - val_loss: 0.5865 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.92568\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1976 - accuracy: 0.9384 - val_loss: 0.5995 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.92568\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2052 - accuracy: 0.9368 - val_loss: 5.1068 - val_accuracy: 0.2365\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.92568\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1518 - accuracy: 0.9500 - val_loss: 0.4222 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.92568\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1239 - accuracy: 0.9568 - val_loss: 0.4817 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.92568\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1376 - accuracy: 0.9579 - val_loss: 0.4418 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.92568\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1472 - accuracy: 0.9542 - val_loss: 1.2606 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.92568\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1535 - accuracy: 0.9558 - val_loss: 0.2947 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.92568\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1293 - accuracy: 0.9595 - val_loss: 0.8619 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.92568\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1016 - accuracy: 0.9647 - val_loss: 1.5382 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.92568\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1280 - accuracy: 0.9589 - val_loss: 2.7462 - val_accuracy: 0.5676\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.92568\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1251 - accuracy: 0.9647 - val_loss: 1.1426 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.92568\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1377 - accuracy: 0.9532 - val_loss: 1.2280 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.92568\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1387 - accuracy: 0.9595 - val_loss: 0.3319 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.92568\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1279 - accuracy: 0.9605 - val_loss: 0.4661 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.92568\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0694 - accuracy: 0.9753 - val_loss: 0.6251 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.92568\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1164 - accuracy: 0.9637 - val_loss: 0.4693 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.92568\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1216 - accuracy: 0.9642 - val_loss: 0.6284 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.92568\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0919 - accuracy: 0.9684 - val_loss: 2.9570 - val_accuracy: 0.5541\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.92568\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1338 - accuracy: 0.9568 - val_loss: 0.4580 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.92568\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0741 - accuracy: 0.9737 - val_loss: 0.3517 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.92568\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1114 - accuracy: 0.9679 - val_loss: 0.4893 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.92568\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1003 - accuracy: 0.9679 - val_loss: 0.5444 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.92568\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1077 - accuracy: 0.9668 - val_loss: 1.8750 - val_accuracy: 0.6284\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.92568\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0859 - accuracy: 0.9679 - val_loss: 1.9815 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.92568\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1525 - accuracy: 0.9574 - val_loss: 3.2791 - val_accuracy: 0.3446\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.92568\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0782 - accuracy: 0.9800 - val_loss: 0.5862 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.92568\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0734 - accuracy: 0.9774 - val_loss: 0.4609 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.92568\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1241 - accuracy: 0.9616 - val_loss: 0.5095 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.92568\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0888 - accuracy: 0.9726 - val_loss: 2.8121 - val_accuracy: 0.4797\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.92568\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1048 - accuracy: 0.9716 - val_loss: 0.8842 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.92568\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0758 - accuracy: 0.9763 - val_loss: 0.3969 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.92568\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0678 - accuracy: 0.9789 - val_loss: 0.5766 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.92568\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1037 - accuracy: 0.9658 - val_loss: 0.5434 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.92568\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0885 - accuracy: 0.9711 - val_loss: 0.5613 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.92568\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1085 - accuracy: 0.9705 - val_loss: 0.7671 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.92568\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1110 - accuracy: 0.9705 - val_loss: 0.5269 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.92568\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0483 - accuracy: 0.9842 - val_loss: 0.6156 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.92568\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0731 - accuracy: 0.9768 - val_loss: 1.3378 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.92568\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0902 - accuracy: 0.9684 - val_loss: 0.4822 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.92568\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0596 - accuracy: 0.9832 - val_loss: 0.7226 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.92568\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0443 - accuracy: 0.9847 - val_loss: 0.5260 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.92568\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0703 - accuracy: 0.9763 - val_loss: 0.8922 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.92568\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1070 - accuracy: 0.9668 - val_loss: 0.6390 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.92568\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0667 - accuracy: 0.9774 - val_loss: 0.5732 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.92568\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0743 - accuracy: 0.9779 - val_loss: 0.6085 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.92568\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0673 - accuracy: 0.9779 - val_loss: 0.5414 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.92568\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0376 - accuracy: 0.9895 - val_loss: 0.4753 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.92568\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0676 - accuracy: 0.9816 - val_loss: 0.7386 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.92568\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1068 - accuracy: 0.9647 - val_loss: 0.3464 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.92568\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0484 - accuracy: 0.9847 - val_loss: 0.4918 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.92568\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0466 - accuracy: 0.9837 - val_loss: 0.5411 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.92568\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0519 - accuracy: 0.9826 - val_loss: 0.4433 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.92568\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1107 - accuracy: 0.9668 - val_loss: 0.5329 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.92568\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0691 - accuracy: 0.9800 - val_loss: 0.4399 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.92568\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0499 - accuracy: 0.9842 - val_loss: 0.4977 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.92568\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0550 - accuracy: 0.9837 - val_loss: 0.4939 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.92568\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0386 - accuracy: 0.9879 - val_loss: 0.4566 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.92568\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0421 - accuracy: 0.9868 - val_loss: 0.4794 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.92568\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0826 - accuracy: 0.9726 - val_loss: 0.5675 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.92568\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0479 - accuracy: 0.9853 - val_loss: 0.4745 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.92568\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0600 - accuracy: 0.9800 - val_loss: 0.5261 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.92568\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0568 - accuracy: 0.9779 - val_loss: 0.6421 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.92568\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0690 - accuracy: 0.9811 - val_loss: 0.8741 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.92568\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0678 - accuracy: 0.9784 - val_loss: 0.6010 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.92568\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0620 - accuracy: 0.9837 - val_loss: 0.5286 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.92568\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0322 - accuracy: 0.9911 - val_loss: 0.5542 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.92568\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0498 - accuracy: 0.9837 - val_loss: 0.7329 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.92568\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0543 - accuracy: 0.9826 - val_loss: 0.8839 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.92568\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0723 - accuracy: 0.9774 - val_loss: 0.4475 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.92568\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0507 - accuracy: 0.9858 - val_loss: 0.5341 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.92568\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0515 - accuracy: 0.9853 - val_loss: 0.5995 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.92568\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0534 - accuracy: 0.9811 - val_loss: 0.8686 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.92568\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0528 - accuracy: 0.9826 - val_loss: 1.7988 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.92568\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0630 - accuracy: 0.9816 - val_loss: 0.5702 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.92568\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0536 - accuracy: 0.9826 - val_loss: 0.5458 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.92568\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0499 - accuracy: 0.9832 - val_loss: 1.0602 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.92568\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0597 - accuracy: 0.9795 - val_loss: 0.6227 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.92568\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0597 - accuracy: 0.9811 - val_loss: 0.3538 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.92568\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0375 - accuracy: 0.9895 - val_loss: 0.3424 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.92568\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0352 - accuracy: 0.9889 - val_loss: 0.5089 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.92568\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0346 - accuracy: 0.9911 - val_loss: 0.4834 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.92568\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0433 - accuracy: 0.9874 - val_loss: 0.6486 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.92568\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.4488 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.92568\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0606 - accuracy: 0.9816 - val_loss: 0.7150 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.92568\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0518 - accuracy: 0.9842 - val_loss: 0.5200 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.92568\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.4767 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.92568\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0445 - accuracy: 0.9863 - val_loss: 0.5241 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.92568\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0319 - accuracy: 0.9911 - val_loss: 0.5529 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.92568\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0436 - accuracy: 0.9874 - val_loss: 0.5946 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.92568\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0428 - accuracy: 0.9884 - val_loss: 0.6180 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.92568\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0631 - accuracy: 0.9805 - val_loss: 0.4277 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.92568\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0453 - accuracy: 0.9868 - val_loss: 0.6037 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.92568\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0580 - accuracy: 0.9821 - val_loss: 1.0409 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.92568\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0436 - accuracy: 0.9853 - val_loss: 0.4384 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.92568\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 0.5900 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.92568\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0416 - accuracy: 0.9868 - val_loss: 0.6539 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.92568\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0479 - accuracy: 0.9853 - val_loss: 1.0874 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.92568\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 0.5607 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.92568\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0317 - accuracy: 0.9889 - val_loss: 0.5077 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.92568\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0516 - accuracy: 0.9842 - val_loss: 0.5484 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.92568\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0506 - accuracy: 0.9858 - val_loss: 0.9637 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.92568\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0435 - accuracy: 0.9884 - val_loss: 0.4983 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.92568\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0302 - accuracy: 0.9921 - val_loss: 0.5463 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.92568\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0679 - accuracy: 0.9795 - val_loss: 0.6549 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92568\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.7574 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92568\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0371 - accuracy: 0.9889 - val_loss: 0.5709 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92568\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.6677 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92568\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.8950 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92568\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.6535 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92568\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0499 - accuracy: 0.9805 - val_loss: 1.0092 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92568\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0799 - accuracy: 0.9768 - val_loss: 0.6435 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92568\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0510 - accuracy: 0.9832 - val_loss: 0.5996 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92568\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0281 - accuracy: 0.9926 - val_loss: 0.4554 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92568\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.6954 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92568\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0558 - accuracy: 0.9811 - val_loss: 0.6317 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92568\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0404 - accuracy: 0.9853 - val_loss: 0.7345 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92568\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0367 - accuracy: 0.9863 - val_loss: 0.8942 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92568\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0307 - accuracy: 0.9895 - val_loss: 0.5387 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92568\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.5853 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92568\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0450 - accuracy: 0.9853 - val_loss: 0.7198 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92568\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0455 - accuracy: 0.9889 - val_loss: 0.6255 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92568\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0461 - accuracy: 0.9868 - val_loss: 0.6476 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92568\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.5037 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92568\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.5279 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92568\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0326 - accuracy: 0.9889 - val_loss: 0.6356 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92568\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0244 - accuracy: 0.9937 - val_loss: 0.3651 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92568\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.6999 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92568\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.3603 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92568\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0658 - accuracy: 0.9832 - val_loss: 0.5798 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92568\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0371 - accuracy: 0.9874 - val_loss: 1.0362 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92568\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0357 - accuracy: 0.9905 - val_loss: 0.5408 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92568\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.6245 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92568\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.6297 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92568\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0367 - accuracy: 0.9900 - val_loss: 0.6408 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92568\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0296 - accuracy: 0.9879 - val_loss: 0.4445 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92568\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0222 - accuracy: 0.9947 - val_loss: 0.3718 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92568\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0187 - accuracy: 0.9926 - val_loss: 0.4459 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00187: val_accuracy improved from 0.92568 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0402 - accuracy: 0.9879 - val_loss: 0.7033 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93243\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.1119 - accuracy: 0.9663 - val_loss: 0.5122 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93243\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0213 - accuracy: 0.9911 - val_loss: 0.4259 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93243\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 0.4432 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93243\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0178 - accuracy: 0.9921 - val_loss: 0.4413 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93243\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0372 - accuracy: 0.9916 - val_loss: 0.6777 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93243\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0331 - accuracy: 0.9874 - val_loss: 0.6233 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93243\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 0.5800 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93243\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0208 - accuracy: 0.9926 - val_loss: 0.5532 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93243\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.6886 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93243\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0331 - accuracy: 0.9900 - val_loss: 0.7334 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93243\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.5932 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93243\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0349 - accuracy: 0.9937 - val_loss: 0.5730 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93243\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0328 - accuracy: 0.9900 - val_loss: 0.6384 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93243\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.4907 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93243\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0336 - accuracy: 0.9884 - val_loss: 0.5225 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93243\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.7030 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93243\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0307 - accuracy: 0.9895 - val_loss: 0.6222 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93243\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0594 - accuracy: 0.9868 - val_loss: 0.7393 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93243\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0578 - accuracy: 0.9863 - val_loss: 0.6747 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93243\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.5472 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93243\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0399 - accuracy: 0.9889 - val_loss: 0.5296 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93243\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.4331 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93243\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.4196 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93243\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0245 - accuracy: 0.9953 - val_loss: 1.4825 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93243\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.4444 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93243\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.5770 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93243\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0360 - accuracy: 0.9895 - val_loss: 0.6200 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93243\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0450 - accuracy: 0.9853 - val_loss: 0.7507 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93243\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0269 - accuracy: 0.9905 - val_loss: 0.6535 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93243\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 0.7131 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93243\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0302 - accuracy: 0.9900 - val_loss: 0.5609 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93243\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0375 - accuracy: 0.9905 - val_loss: 0.6260 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93243\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.5076 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93243\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.7244 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93243\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.5533 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93243\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0400 - accuracy: 0.9884 - val_loss: 0.7251 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93243\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0362 - accuracy: 0.9911 - val_loss: 0.5959 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93243\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0176 - accuracy: 0.9926 - val_loss: 0.7172 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93243\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0311 - accuracy: 0.9874 - val_loss: 0.7401 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93243\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0333 - accuracy: 0.9895 - val_loss: 0.5977 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93243\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.7604 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93243\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0104 - accuracy: 0.9958 - val_loss: 1.1873 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93243\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0273 - accuracy: 0.9937 - val_loss: 0.7254 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93243\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0283 - accuracy: 0.9905 - val_loss: 1.1115 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93243\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0405 - accuracy: 0.9879 - val_loss: 0.6655 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93243\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0292 - accuracy: 0.9921 - val_loss: 1.0068 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93243\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.4530 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93243\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0353 - accuracy: 0.9900 - val_loss: 0.5929 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93243\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.4462 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93243\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0476 - accuracy: 0.9879 - val_loss: 1.6592 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93243\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0327 - accuracy: 0.9911 - val_loss: 0.4254 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00239: val_accuracy improved from 0.93243 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.4441 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93919\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.6055 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93919\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.5478 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93919\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 0.5466 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93919\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0420 - accuracy: 0.9884 - val_loss: 0.7139 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93919\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0354 - accuracy: 0.9889 - val_loss: 0.6740 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93919\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.5697 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93919\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.6306 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93919\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0101 - accuracy: 0.9953 - val_loss: 0.5445 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93919\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.6646 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93919\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0306 - accuracy: 0.9932 - val_loss: 1.3717 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93919\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0416 - accuracy: 0.9874 - val_loss: 0.6518 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93919\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 0.5566 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93919\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.4045 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93919\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.5227 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93919\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.6370 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93919\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0582 - accuracy: 0.9858 - val_loss: 0.6835 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93919\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0296 - accuracy: 0.9895 - val_loss: 0.4573 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93919\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.5039 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93919\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.8038 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93919\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0525 - accuracy: 0.9863 - val_loss: 0.7281 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93919\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0209 - accuracy: 0.9947 - val_loss: 0.6184 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93919\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0348 - accuracy: 0.9911 - val_loss: 1.6557 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93919\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0253 - accuracy: 0.9900 - val_loss: 0.4274 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93919\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 0.6418 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93919\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.5312 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93919\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0415 - accuracy: 0.9884 - val_loss: 0.6335 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93919\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0223 - accuracy: 0.9916 - val_loss: 0.5679 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93919\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.5507 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93919\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0241 - accuracy: 0.9942 - val_loss: 0.5701 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93919\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.6154 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93919\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.5714 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93919\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0184 - accuracy: 0.9932 - val_loss: 0.4562 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93919\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.5628 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93919\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0126 - accuracy: 0.9942 - val_loss: 0.5604 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93919\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.8103 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93919\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.9962 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93919\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0543 - accuracy: 0.9853 - val_loss: 0.5799 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93919\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.5092 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93919\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0074 - accuracy: 0.9968 - val_loss: 0.4708 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93919\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0250 - accuracy: 0.9937 - val_loss: 0.7136 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93919\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.4608 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93919\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 0.6378 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93919\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0213 - accuracy: 0.9916 - val_loss: 0.6026 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93919\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.6192 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93919\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0298 - accuracy: 0.9895 - val_loss: 0.6345 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93919\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0302 - accuracy: 0.9942 - val_loss: 0.6240 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93919\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0223 - accuracy: 0.9947 - val_loss: 0.5527 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93919\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.6223 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93919\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0213 - accuracy: 0.9947 - val_loss: 0.4704 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93919\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.4057 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00290: val_accuracy improved from 0.93919 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.5162 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.94595\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.4248 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.94595\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.8698 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.94595\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.7651 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.94595\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.7826 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.94595\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.7043 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.94595\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.5450 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.94595\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.5907 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.94595\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0269 - accuracy: 0.9926 - val_loss: 0.5309 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.94595\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.6089 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.94595\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0262 - accuracy: 0.9926 - val_loss: 0.5668 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.94595\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.5045 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.94595\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0254 - accuracy: 0.9942 - val_loss: 0.7101 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.94595\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.7225 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.94595\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0555 - accuracy: 0.9826 - val_loss: 1.0397 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.94595\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0196 - accuracy: 0.9926 - val_loss: 0.7440 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.94595\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0311 - accuracy: 0.9884 - val_loss: 0.5613 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.94595\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 0.5555 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.94595\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.5572 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.94595\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.6125 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.94595\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0267 - accuracy: 0.9947 - val_loss: 0.6397 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.94595\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0133 - accuracy: 0.9947 - val_loss: 0.5279 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.94595\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.6866 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.94595\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.5460 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.94595\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.5298 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.94595\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0366 - accuracy: 0.9884 - val_loss: 2.9514 - val_accuracy: 0.6419\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.94595\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 0.9764 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.94595\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.8474 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.94595\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0159 - accuracy: 0.9932 - val_loss: 0.7015 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.94595\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.5605 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.94595\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0337 - accuracy: 0.9926 - val_loss: 0.7405 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.94595\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.8526 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.94595\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.4406 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.94595\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0154 - accuracy: 0.9937 - val_loss: 0.7009 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.94595\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0352 - accuracy: 0.9874 - val_loss: 0.6403 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.94595\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.6635 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.94595\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.5668 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.94595\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.4592 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.94595\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.5614 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.94595\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.6181 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.94595\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.7035 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.94595\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0132 - accuracy: 0.9942 - val_loss: 0.7975 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.94595\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.6732 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.94595\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0156 - accuracy: 0.9937 - val_loss: 0.7112 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.94595\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0280 - accuracy: 0.9916 - val_loss: 0.7269 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.94595\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.6584 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.94595\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.8514 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.94595\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0387 - accuracy: 0.9926 - val_loss: 0.5491 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.94595\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.6777 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.94595\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.6529 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.94595\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.6913 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.94595\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.6137 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.94595\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.5948 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.94595\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0228 - accuracy: 0.9953 - val_loss: 0.6172 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.94595\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0154 - accuracy: 0.9932 - val_loss: 0.7969 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.94595\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.6469 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.94595\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.6152 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.94595\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.6511 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.94595\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 0.9275 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.94595\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0287 - accuracy: 0.9932 - val_loss: 0.6176 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.94595\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.6563 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.94595\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0312 - accuracy: 0.9889 - val_loss: 0.6495 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.94595\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.6943 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.94595\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0217 - accuracy: 0.9916 - val_loss: 0.8816 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.94595\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0223 - accuracy: 0.9953 - val_loss: 0.7061 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.94595\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.5695 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.94595\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.7908 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.94595\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.7971 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.94595\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 1.0017 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.94595\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0398 - accuracy: 0.9937 - val_loss: 0.9125 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.94595\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.5871 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.94595\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.6733 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.94595\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.6668 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.94595\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0142 - accuracy: 0.9942 - val_loss: 0.8397 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.94595\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 1.0187 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.94595\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.6901 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.94595\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0049 - accuracy: 0.9974 - val_loss: 0.6351 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.94595\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0270 - accuracy: 0.9937 - val_loss: 0.6694 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.94595\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.7079 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.94595\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0074 - accuracy: 0.9968 - val_loss: 0.7089 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.94595\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.9352 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.94595\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0175 - accuracy: 0.9926 - val_loss: 0.6968 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.94595\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.5817 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.94595\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.8299 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.94595\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.6877 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.94595\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0109 - accuracy: 0.9953 - val_loss: 0.6614 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.94595\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 1.0432 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.94595\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0157 - accuracy: 0.9968 - val_loss: 0.8218 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.94595\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 0.8554 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.94595\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.7486 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.94595\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.8684 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.94595\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0279 - accuracy: 0.9932 - val_loss: 0.5235 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.94595\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0184 - accuracy: 0.9921 - val_loss: 0.5607 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.94595\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.6638 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.94595\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.7147 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.94595\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.5556 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94595\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.9443 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94595\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.9085 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94595\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 1.0446 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94595\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.6569 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94595\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0199 - accuracy: 0.9953 - val_loss: 0.7583 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94595\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0245 - accuracy: 0.9905 - val_loss: 0.8804 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94595\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.5628 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94595\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.7889 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94595\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.6299 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94595\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.6786 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94595\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0461 - accuracy: 0.9874 - val_loss: 0.8198 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94595\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0286 - accuracy: 0.9921 - val_loss: 1.1027 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94595\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.8372 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.94595\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.6759 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94595\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.7843 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94595\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.7802 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94595\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.7267 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94595\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0278 - accuracy: 0.9921 - val_loss: 0.7326 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94595\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.5682 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94595\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.9313 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94595\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.8257 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94595\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.7741 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94595\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.7835 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94595\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.7080 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94595\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0284 - accuracy: 0.9958 - val_loss: 2.0481 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94595\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.7204 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94595\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.5490 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94595\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0288 - accuracy: 0.9937 - val_loss: 0.7162 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94595\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.8559 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94595\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0288 - accuracy: 0.9926 - val_loss: 0.7238 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94595\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.8211 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94595\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.4948 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94595\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.7085 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94595\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0212 - accuracy: 0.9926 - val_loss: 0.8068 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94595\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.9254 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94595\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.7557 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94595\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.7440 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94595\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.9380 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94595\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0449 - accuracy: 0.9884 - val_loss: 1.1557 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94595\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0373 - accuracy: 0.9916 - val_loss: 0.8224 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94595\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.6913 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94595\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.7574 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94595\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.6914 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94595\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0079 - accuracy: 0.9963 - val_loss: 0.7819 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94595\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.6780 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94595\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0160 - accuracy: 0.9968 - val_loss: 1.0541 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94595\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0257 - accuracy: 0.9932 - val_loss: 0.6954 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94595\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.6722 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94595\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.6826 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94595\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 0.7431 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94595\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 1.0748 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94595\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0206 - accuracy: 0.9953 - val_loss: 1.1557 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94595\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0256 - accuracy: 0.9932 - val_loss: 0.9870 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94595\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.7812 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94595\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.7762 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94595\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 1.0557 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94595\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.8622 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94595\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.8141 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94595\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.6548 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94595\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.7015 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94595\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.9024 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94595\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.8031 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94595\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.9850 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94595\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 0.8583 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94595\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0153 - accuracy: 0.9937 - val_loss: 0.9728 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94595\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0321 - accuracy: 0.9921 - val_loss: 0.8060 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94595\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.8549 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94595\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0163 - accuracy: 0.9963 - val_loss: 0.7422 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94595\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0044 - accuracy: 0.9979 - val_loss: 0.8306 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94595\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0296 - accuracy: 0.9916 - val_loss: 0.8196 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94595\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.5839 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94595\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.7496 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94595\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.7160 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94595\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0248 - accuracy: 0.9942 - val_loss: 0.7236 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94595\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0237 - accuracy: 0.9958 - val_loss: 0.8690 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94595\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0208 - accuracy: 0.9953 - val_loss: 0.8555 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94595\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.8892 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94595\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.6144 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94595\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.7066 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94595\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0206 - accuracy: 0.9958 - val_loss: 0.5039 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94595\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.4692 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94595\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.6201 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94595\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.7952 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94595\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.6181 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94595\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.8486 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94595\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0420 - accuracy: 0.9884 - val_loss: 0.6554 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94595\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0154 - accuracy: 0.9942 - val_loss: 0.5992 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94595\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.5407 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94595\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.5859 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94595\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.4860 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94595\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.7287 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94595\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 0.5532 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94595\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.5585 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94595\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.6451 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94595\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.5271 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94595\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.6083 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94595\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.6859 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94595\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 1.0122 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94595\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.7090 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94595\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.7778 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94595\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.8468 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94595\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0313 - accuracy: 0.9932 - val_loss: 0.6890 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94595\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0320 - accuracy: 0.9905 - val_loss: 0.8088 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94595\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.5625 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94595\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.5541 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94595\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.5417 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94595\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.3259 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00493: val_accuracy improved from 0.94595 to 0.95946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.5725 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95946\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.8188 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95946\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0189 - accuracy: 0.9953 - val_loss: 0.6473 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95946\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.6532 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95946\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.7073 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95946\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0128 - accuracy: 0.9942 - val_loss: 0.5581 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95946\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0297 - accuracy: 0.9895 - val_loss: 0.7834 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95946\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff5e48efa10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f8a61012-37f3-4383-ba63-fbeaa3fc4db5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb86a8da-c1dd-4240-beca-d01eb7d30bf1"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d80eef2-aa32-427f-d91c-e7e11c6f24ce"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1636ddcf-a9ef-4a9f-b550-beb16162dae8"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a55d2ae6-431b-4188-9202-59917128b256\", \"EfficientNetB4_4.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}