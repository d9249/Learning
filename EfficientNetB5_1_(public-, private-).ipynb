{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB5_1_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/EfficientNetB5_1_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "407b5bda-06e7-4320-b4ed-5bdf9047b1e3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 29 05:18:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab15e658-60e8-4c70-a4e6-1ed7072f30e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "nunbering = '5'\n",
        "model_save = 'EfficientNetB' + nunbering + '_1'\n",
        "Target_model = 'EfficientNetB' + nunbering + '_model'\n",
        "Target_predict = 'EfficientNetB' + nunbering + '_predict'\n",
        "Target_acc = 'EfficientNetB' + nunbering + '_acc'\n",
        "Target_val = 'EfficientNetB' + nunbering + '_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.EfficientNetB2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38c625c-ea2c-438c-f843-09a93d8f6a23"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95bfb13-722b-448a-afc3-2a5dc462166b"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 56s 122ms/step - loss: 3.4053 - accuracy: 0.1353 - val_loss: 4.2393 - val_accuracy: 0.0946\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 2.2306 - accuracy: 0.2321 - val_loss: 3.6631 - val_accuracy: 0.0946\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.09459\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.8245 - accuracy: 0.3779 - val_loss: 2.5890 - val_accuracy: 0.1284\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.09459 to 0.12838, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.4145 - accuracy: 0.5274 - val_loss: 5.9008 - val_accuracy: 0.1149\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.12838\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.1431 - accuracy: 0.6079 - val_loss: 1.4527 - val_accuracy: 0.5338\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.12838 to 0.53378, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.9615 - accuracy: 0.6947 - val_loss: 12.9825 - val_accuracy: 0.1149\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.53378\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.8239 - accuracy: 0.7358 - val_loss: 6.5758 - val_accuracy: 0.1081\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.53378\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.7301 - accuracy: 0.7611 - val_loss: 6.5265 - val_accuracy: 0.1284\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.53378\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.6846 - accuracy: 0.7842 - val_loss: 3.1966 - val_accuracy: 0.3581\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.53378\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.5926 - accuracy: 0.8100 - val_loss: 11.0447 - val_accuracy: 0.0878\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.53378\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.6082 - accuracy: 0.7968 - val_loss: 0.6438 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.53378 to 0.79730, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.5550 - accuracy: 0.8316 - val_loss: 0.6912 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.79730\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.5074 - accuracy: 0.8289 - val_loss: 9.7839 - val_accuracy: 0.0811\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.79730\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.5028 - accuracy: 0.8411 - val_loss: 0.4873 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.79730 to 0.83784, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.4282 - accuracy: 0.8684 - val_loss: 0.8803 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.83784\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.4420 - accuracy: 0.8647 - val_loss: 1.4283 - val_accuracy: 0.5946\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.83784\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.4212 - accuracy: 0.8668 - val_loss: 4.7036 - val_accuracy: 0.3446\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.83784\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.3951 - accuracy: 0.8700 - val_loss: 0.5489 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.83784\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.4002 - accuracy: 0.8716 - val_loss: 0.4417 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.83784 to 0.84459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.3670 - accuracy: 0.8863 - val_loss: 0.6781 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.84459\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.3540 - accuracy: 0.8968 - val_loss: 2.6773 - val_accuracy: 0.4527\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.84459\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.3499 - accuracy: 0.8874 - val_loss: 2.7354 - val_accuracy: 0.4459\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.84459\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.3663 - accuracy: 0.8858 - val_loss: 1.0777 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.84459\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2875 - accuracy: 0.9068 - val_loss: 0.6700 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.84459\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.3381 - accuracy: 0.8874 - val_loss: 0.3517 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.84459 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.2969 - accuracy: 0.9042 - val_loss: 0.6113 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.87162\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2993 - accuracy: 0.9095 - val_loss: 4.0295 - val_accuracy: 0.2973\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.87162\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2599 - accuracy: 0.9100 - val_loss: 0.4278 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.87162 to 0.87838, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.3021 - accuracy: 0.9005 - val_loss: 0.4827 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.87838\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2592 - accuracy: 0.9158 - val_loss: 1.5401 - val_accuracy: 0.6216\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.87838\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2341 - accuracy: 0.9195 - val_loss: 3.5970 - val_accuracy: 0.4797\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.87838\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2625 - accuracy: 0.9105 - val_loss: 0.5997 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.87838\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2738 - accuracy: 0.9174 - val_loss: 1.2424 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.87838\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2236 - accuracy: 0.9332 - val_loss: 0.3289 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.87838 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2075 - accuracy: 0.9305 - val_loss: 4.4139 - val_accuracy: 0.1892\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.89189\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1999 - accuracy: 0.9400 - val_loss: 0.7553 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.89189\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2146 - accuracy: 0.9300 - val_loss: 0.5535 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.89189\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1896 - accuracy: 0.9426 - val_loss: 0.3954 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.89189\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1807 - accuracy: 0.9458 - val_loss: 0.5158 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.89189\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1721 - accuracy: 0.9500 - val_loss: 0.5807 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.89189\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2158 - accuracy: 0.9300 - val_loss: 1.1236 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.89189\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1961 - accuracy: 0.9363 - val_loss: 1.0901 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89189\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1524 - accuracy: 0.9500 - val_loss: 0.6611 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89189\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1814 - accuracy: 0.9416 - val_loss: 0.7799 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89189\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1730 - accuracy: 0.9358 - val_loss: 7.5879 - val_accuracy: 0.1284\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89189\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1593 - accuracy: 0.9489 - val_loss: 0.8015 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89189\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1505 - accuracy: 0.9553 - val_loss: 1.5808 - val_accuracy: 0.7095\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89189\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1528 - accuracy: 0.9547 - val_loss: 1.1529 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89189\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1730 - accuracy: 0.9405 - val_loss: 2.5653 - val_accuracy: 0.4459\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89189\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1631 - accuracy: 0.9458 - val_loss: 2.3367 - val_accuracy: 0.5473\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89189\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1271 - accuracy: 0.9563 - val_loss: 0.6305 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89189\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1291 - accuracy: 0.9595 - val_loss: 1.3491 - val_accuracy: 0.6689\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.89189\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1312 - accuracy: 0.9605 - val_loss: 0.4780 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.89189\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1048 - accuracy: 0.9679 - val_loss: 7.9117 - val_accuracy: 0.1892\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.89189\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1766 - accuracy: 0.9453 - val_loss: 3.8722 - val_accuracy: 0.3784\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.89189\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1226 - accuracy: 0.9647 - val_loss: 0.4885 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.89189\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1198 - accuracy: 0.9616 - val_loss: 3.4601 - val_accuracy: 0.3986\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.89189\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0980 - accuracy: 0.9700 - val_loss: 0.5348 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.89189\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1140 - accuracy: 0.9663 - val_loss: 1.8177 - val_accuracy: 0.5878\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.89189\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1212 - accuracy: 0.9632 - val_loss: 1.6145 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.89189\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1214 - accuracy: 0.9616 - val_loss: 0.3770 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.89189 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1102 - accuracy: 0.9647 - val_loss: 3.9545 - val_accuracy: 0.3446\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.90541\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0907 - accuracy: 0.9726 - val_loss: 0.2731 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1256 - accuracy: 0.9642 - val_loss: 0.7528 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91216\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0885 - accuracy: 0.9668 - val_loss: 0.5873 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91216\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1094 - accuracy: 0.9647 - val_loss: 6.9790 - val_accuracy: 0.2838\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91216\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0876 - accuracy: 0.9721 - val_loss: 0.5767 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91216\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0806 - accuracy: 0.9742 - val_loss: 0.4071 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91216\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0938 - accuracy: 0.9726 - val_loss: 0.3844 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91216\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0919 - accuracy: 0.9726 - val_loss: 3.6867 - val_accuracy: 0.4595\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91216\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1060 - accuracy: 0.9689 - val_loss: 0.4795 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.91216 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1025 - accuracy: 0.9716 - val_loss: 0.4196 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91892\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0678 - accuracy: 0.9805 - val_loss: 1.2478 - val_accuracy: 0.7095\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91892\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0843 - accuracy: 0.9705 - val_loss: 0.7348 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91892\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1290 - accuracy: 0.9589 - val_loss: 0.5390 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91892\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0766 - accuracy: 0.9742 - val_loss: 0.4085 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91892\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0660 - accuracy: 0.9784 - val_loss: 0.3344 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91892\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0602 - accuracy: 0.9816 - val_loss: 1.6098 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91892\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0758 - accuracy: 0.9763 - val_loss: 0.6201 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91892\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0829 - accuracy: 0.9758 - val_loss: 0.8626 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91892\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1260 - accuracy: 0.9611 - val_loss: 6.6965 - val_accuracy: 0.2230\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91892\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0905 - accuracy: 0.9705 - val_loss: 0.4286 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91892\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0891 - accuracy: 0.9700 - val_loss: 0.2965 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00083: val_accuracy improved from 0.91892 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0551 - accuracy: 0.9832 - val_loss: 0.4159 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.92568\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0695 - accuracy: 0.9779 - val_loss: 0.5586 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.92568\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0804 - accuracy: 0.9705 - val_loss: 1.2704 - val_accuracy: 0.6892\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.92568\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1123 - accuracy: 0.9663 - val_loss: 0.9500 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.92568\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0783 - accuracy: 0.9742 - val_loss: 0.4803 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.92568\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0480 - accuracy: 0.9863 - val_loss: 0.4339 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00089: val_accuracy improved from 0.92568 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0496 - accuracy: 0.9837 - val_loss: 1.1196 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.93243\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0507 - accuracy: 0.9837 - val_loss: 0.4768 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.93243\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0704 - accuracy: 0.9774 - val_loss: 0.4356 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.93243\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0604 - accuracy: 0.9779 - val_loss: 0.4668 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.93243\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0791 - accuracy: 0.9721 - val_loss: 0.5008 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.93243\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0882 - accuracy: 0.9758 - val_loss: 0.3724 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.93243\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0521 - accuracy: 0.9821 - val_loss: 0.5831 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.93243\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0634 - accuracy: 0.9768 - val_loss: 0.3948 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.93243\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0513 - accuracy: 0.9863 - val_loss: 0.3792 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.93243\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0763 - accuracy: 0.9747 - val_loss: 0.3572 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.93243\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0607 - accuracy: 0.9811 - val_loss: 1.9067 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.93243\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0571 - accuracy: 0.9800 - val_loss: 0.4497 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.93243\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0702 - accuracy: 0.9784 - val_loss: 0.4048 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.93243\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0501 - accuracy: 0.9832 - val_loss: 0.3851 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.93243\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0447 - accuracy: 0.9874 - val_loss: 0.2806 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.93243\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0686 - accuracy: 0.9768 - val_loss: 0.9331 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.93243\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0501 - accuracy: 0.9853 - val_loss: 3.9961 - val_accuracy: 0.4324\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.93243\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.2565 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.93243\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0344 - accuracy: 0.9926 - val_loss: 0.4641 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.93243\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0629 - accuracy: 0.9832 - val_loss: 0.4070 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.93243\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0691 - accuracy: 0.9811 - val_loss: 1.1679 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.93243\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0572 - accuracy: 0.9826 - val_loss: 6.0285 - val_accuracy: 0.2838\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.93243\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0444 - accuracy: 0.9858 - val_loss: 0.4895 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.93243\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0534 - accuracy: 0.9832 - val_loss: 0.4200 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.93243\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 0.4333 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.93243\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.8140 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.93243\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0525 - accuracy: 0.9832 - val_loss: 0.5620 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.93243\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0658 - accuracy: 0.9805 - val_loss: 0.5381 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.93243\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0350 - accuracy: 0.9879 - val_loss: 0.5936 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.93243\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0518 - accuracy: 0.9816 - val_loss: 0.5307 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.93243\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0469 - accuracy: 0.9821 - val_loss: 0.6829 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.93243\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0420 - accuracy: 0.9863 - val_loss: 0.4454 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.93243\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0265 - accuracy: 0.9874 - val_loss: 0.3996 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.93243\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0635 - accuracy: 0.9779 - val_loss: 0.8099 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.93243\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0655 - accuracy: 0.9811 - val_loss: 2.7083 - val_accuracy: 0.6081\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.93243\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0445 - accuracy: 0.9863 - val_loss: 0.5347 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.93243\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0717 - accuracy: 0.9800 - val_loss: 0.4833 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.93243\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0570 - accuracy: 0.9853 - val_loss: 0.6169 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.93243\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0314 - accuracy: 0.9916 - val_loss: 0.4392 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.93243\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0603 - accuracy: 0.9826 - val_loss: 0.6878 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.93243\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0326 - accuracy: 0.9889 - val_loss: 0.5185 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.93243\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0333 - accuracy: 0.9858 - val_loss: 0.5518 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.93243\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0514 - accuracy: 0.9821 - val_loss: 0.3757 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.93243\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0360 - accuracy: 0.9853 - val_loss: 0.5034 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.93243\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0459 - accuracy: 0.9879 - val_loss: 0.6450 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.93243\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0664 - accuracy: 0.9811 - val_loss: 0.4162 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.93243\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0364 - accuracy: 0.9879 - val_loss: 0.5579 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.93243\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0309 - accuracy: 0.9911 - val_loss: 0.4912 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.93243\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0531 - accuracy: 0.9847 - val_loss: 0.5281 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.93243\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0601 - accuracy: 0.9805 - val_loss: 2.1629 - val_accuracy: 0.6081\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.93243\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.4768 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.93243\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0342 - accuracy: 0.9879 - val_loss: 1.7094 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.93243\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0456 - accuracy: 0.9858 - val_loss: 0.4438 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.93243\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0285 - accuracy: 0.9889 - val_loss: 0.3661 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.93243\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0386 - accuracy: 0.9889 - val_loss: 0.4846 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93243\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0398 - accuracy: 0.9868 - val_loss: 0.9141 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93243\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.6266 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93243\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.4889 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93243\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0467 - accuracy: 0.9868 - val_loss: 0.3908 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93243\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0383 - accuracy: 0.9889 - val_loss: 0.9147 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93243\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0436 - accuracy: 0.9837 - val_loss: 0.6227 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93243\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.4874 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93243\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0440 - accuracy: 0.9853 - val_loss: 0.5187 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93243\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0574 - accuracy: 0.9821 - val_loss: 0.9200 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93243\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0477 - accuracy: 0.9832 - val_loss: 0.3341 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00154: val_accuracy improved from 0.93243 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 0.3690 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93919\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0352 - accuracy: 0.9879 - val_loss: 0.3882 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93919\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0388 - accuracy: 0.9884 - val_loss: 0.4906 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93919\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0454 - accuracy: 0.9868 - val_loss: 0.4654 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.93919\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0323 - accuracy: 0.9889 - val_loss: 0.3223 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.93919\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.6254 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.93919\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.4715 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.93919\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.5755 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.93919\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0554 - accuracy: 0.9784 - val_loss: 0.6700 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.93919\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0633 - accuracy: 0.9789 - val_loss: 2.6651 - val_accuracy: 0.6486\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.93919\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0451 - accuracy: 0.9842 - val_loss: 0.5358 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.93919\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0501 - accuracy: 0.9837 - val_loss: 0.4716 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.93919\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0285 - accuracy: 0.9895 - val_loss: 0.5588 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.93919\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.6392 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.93919\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0552 - accuracy: 0.9832 - val_loss: 0.4619 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.93919\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0511 - accuracy: 0.9847 - val_loss: 4.6176 - val_accuracy: 0.3581\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.93919\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.4521 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.93919\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0412 - accuracy: 0.9863 - val_loss: 0.4885 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.93919\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.7269 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.93919\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0322 - accuracy: 0.9911 - val_loss: 0.4941 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.93919\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.5941 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.93919\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.5897 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.93919\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0425 - accuracy: 0.9868 - val_loss: 0.4579 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.93919\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 0.5855 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.93919\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0328 - accuracy: 0.9874 - val_loss: 0.7378 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93919\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0342 - accuracy: 0.9879 - val_loss: 0.5887 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93919\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0442 - accuracy: 0.9874 - val_loss: 0.6662 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93919\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 0.4473 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93919\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0404 - accuracy: 0.9853 - val_loss: 0.8503 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93919\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.6409 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93919\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0181 - accuracy: 0.9958 - val_loss: 0.6624 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93919\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0243 - accuracy: 0.9911 - val_loss: 0.7455 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93919\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0349 - accuracy: 0.9879 - val_loss: 0.6600 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93919\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0453 - accuracy: 0.9837 - val_loss: 6.4860 - val_accuracy: 0.3243\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93919\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0394 - accuracy: 0.9858 - val_loss: 2.7496 - val_accuracy: 0.6419\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93919\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0457 - accuracy: 0.9868 - val_loss: 0.6675 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93919\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0260 - accuracy: 0.9942 - val_loss: 0.6661 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93919\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.4434 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93919\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0385 - accuracy: 0.9911 - val_loss: 0.3522 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93919\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.6007 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93919\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0336 - accuracy: 0.9905 - val_loss: 0.7259 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93919\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0233 - accuracy: 0.9911 - val_loss: 0.4727 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93919\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 1.7487 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93919\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0267 - accuracy: 0.9895 - val_loss: 0.5271 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93919\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0492 - accuracy: 0.9863 - val_loss: 0.6656 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93919\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.5927 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93919\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0225 - accuracy: 0.9916 - val_loss: 0.6445 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93919\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.5048 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93919\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0308 - accuracy: 0.9937 - val_loss: 0.8116 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93919\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0368 - accuracy: 0.9889 - val_loss: 0.4090 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93919\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0415 - accuracy: 0.9900 - val_loss: 0.8697 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93919\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.6551 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93919\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.5536 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93919\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0277 - accuracy: 0.9895 - val_loss: 2.0344 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93919\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0698 - accuracy: 0.9826 - val_loss: 0.4403 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93919\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0272 - accuracy: 0.9889 - val_loss: 0.4347 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93919\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.3515 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93919\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0529 - accuracy: 0.9842 - val_loss: 1.1094 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93919\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.4948 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93919\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0401 - accuracy: 0.9900 - val_loss: 0.7276 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93919\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0295 - accuracy: 0.9900 - val_loss: 0.4148 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93919\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 0.5168 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93919\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.4597 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93919\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.8009 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93919\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0129 - accuracy: 0.9942 - val_loss: 0.5204 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93919\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.4170 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93919\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.6067 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93919\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0481 - accuracy: 0.9853 - val_loss: 1.0491 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93919\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0398 - accuracy: 0.9879 - val_loss: 3.4779 - val_accuracy: 0.5270\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93919\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0420 - accuracy: 0.9853 - val_loss: 0.5659 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93919\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0197 - accuracy: 0.9926 - val_loss: 0.6054 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93919\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0328 - accuracy: 0.9911 - val_loss: 0.5687 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93919\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0282 - accuracy: 0.9895 - val_loss: 3.5974 - val_accuracy: 0.5541\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93919\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0397 - accuracy: 0.9884 - val_loss: 0.3764 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93919\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0254 - accuracy: 0.9911 - val_loss: 0.4600 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93919\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0265 - accuracy: 0.9905 - val_loss: 0.5927 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93919\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0284 - accuracy: 0.9905 - val_loss: 0.3383 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93919\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.2496 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93919\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0156 - accuracy: 0.9937 - val_loss: 0.4833 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93919\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.4599 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93919\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 0.4996 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93919\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0261 - accuracy: 0.9905 - val_loss: 1.5716 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93919\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0291 - accuracy: 0.9900 - val_loss: 0.4814 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93919\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.3305 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93919\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0435 - accuracy: 0.9863 - val_loss: 0.7488 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93919\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0395 - accuracy: 0.9879 - val_loss: 0.5758 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93919\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.4629 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93919\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.6938 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93919\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.4918 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93919\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 3.2116 - val_accuracy: 0.6081\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93919\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0186 - accuracy: 0.9958 - val_loss: 0.5833 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93919\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0206 - accuracy: 0.9926 - val_loss: 0.6001 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93919\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.5339 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93919\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0309 - accuracy: 0.9911 - val_loss: 0.9012 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93919\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.5509 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93919\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.7168 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93919\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.7663 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93919\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0340 - accuracy: 0.9884 - val_loss: 0.4458 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93919\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0260 - accuracy: 0.9953 - val_loss: 0.4802 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93919\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.5882 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93919\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0382 - accuracy: 0.9879 - val_loss: 0.5767 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93919\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.6313 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93919\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0353 - accuracy: 0.9879 - val_loss: 0.5729 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93919\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0188 - accuracy: 0.9953 - val_loss: 0.5163 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93919\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0142 - accuracy: 0.9942 - val_loss: 0.5098 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93919\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.5262 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93919\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.5886 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93919\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.5373 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93919\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.4266 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93919\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.7348 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93919\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.7445 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93919\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0294 - accuracy: 0.9911 - val_loss: 0.4656 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93919\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0318 - accuracy: 0.9916 - val_loss: 0.4953 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93919\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 0.3986 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93919\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 0.6682 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93919\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.6153 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93919\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.6554 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93919\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0390 - accuracy: 0.9895 - val_loss: 0.5909 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93919\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.8609 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93919\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.5667 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93919\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.5830 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93919\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.7406 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93919\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.5988 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93919\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0233 - accuracy: 0.9942 - val_loss: 0.4858 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93919\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0191 - accuracy: 0.9958 - val_loss: 0.8061 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93919\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0261 - accuracy: 0.9916 - val_loss: 1.3128 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93919\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0288 - accuracy: 0.9900 - val_loss: 0.4140 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93919\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.6286 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93919\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.4555 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93919\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.5950 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93919\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.4136 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93919\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0359 - accuracy: 0.9895 - val_loss: 0.4317 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93919\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0258 - accuracy: 0.9942 - val_loss: 0.4836 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93919\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.3799 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00288: val_accuracy improved from 0.93919 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_1.h5\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.4833 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.95270\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.3481 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.95270\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.3734 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.95270\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0287 - accuracy: 0.9916 - val_loss: 0.6675 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.95270\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.4958 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.95270\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.5456 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.95270\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.3912 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.95270\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.5943 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.95270\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.4314 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.95270\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.7062 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.95270\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 1.5861 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.95270\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0322 - accuracy: 0.9921 - val_loss: 0.8632 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.95270\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0329 - accuracy: 0.9884 - val_loss: 1.4024 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.95270\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0285 - accuracy: 0.9916 - val_loss: 0.7960 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.95270\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0370 - accuracy: 0.9889 - val_loss: 0.4899 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.95270\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 0.5469 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.95270\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.5729 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.95270\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0169 - accuracy: 0.9937 - val_loss: 0.6686 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.95270\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0152 - accuracy: 0.9937 - val_loss: 2.9071 - val_accuracy: 0.6486\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.95270\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.7920 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.95270\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0124 - accuracy: 0.9942 - val_loss: 0.5010 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.95270\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 0.4631 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.95270\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0392 - accuracy: 0.9900 - val_loss: 0.4825 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.95270\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.4647 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.95270\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.4229 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.95270\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.7964 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.95270\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0179 - accuracy: 0.9932 - val_loss: 0.6566 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.95270\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.6486 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.95270\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0266 - accuracy: 0.9884 - val_loss: 3.3271 - val_accuracy: 0.5743\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.95270\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.3419 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.95270\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.6549 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.95270\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 0.7011 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.95270\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.7363 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.95270\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.7467 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.95270\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.6492 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.95270\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0205 - accuracy: 0.9953 - val_loss: 1.0050 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.95270\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.7940 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.95270\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0267 - accuracy: 0.9942 - val_loss: 0.6208 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.95270\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.6669 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.95270\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0248 - accuracy: 0.9932 - val_loss: 0.5995 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.95270\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0293 - accuracy: 0.9937 - val_loss: 0.6736 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.95270\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.5485 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.95270\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.7157 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.95270\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.4557 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.95270\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.6383 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.95270\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.5643 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.95270\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0182 - accuracy: 0.9926 - val_loss: 0.8076 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.95270\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0225 - accuracy: 0.9937 - val_loss: 0.4880 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.95270\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0216 - accuracy: 0.9963 - val_loss: 0.9441 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.95270\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0310 - accuracy: 0.9911 - val_loss: 0.7906 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.95270\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.5322 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.95270\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.7412 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.95270\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.7175 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95270\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0185 - accuracy: 0.9926 - val_loss: 0.7848 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95270\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.6432 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95270\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.6413 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95270\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0266 - accuracy: 0.9916 - val_loss: 0.6033 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95270\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.5471 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95270\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 1.2533 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95270\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.5696 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95270\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.5006 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95270\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0151 - accuracy: 0.9942 - val_loss: 0.5709 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95270\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.5302 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95270\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0256 - accuracy: 0.9953 - val_loss: 0.4488 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95270\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.5478 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95270\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0351 - accuracy: 0.9911 - val_loss: 1.1774 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95270\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0122 - accuracy: 0.9947 - val_loss: 0.6098 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95270\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0038 - accuracy: 0.9979 - val_loss: 0.6065 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95270\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.5249 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95270\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.5236 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95270\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.4487 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95270\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0466 - accuracy: 0.9842 - val_loss: 0.5663 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95270\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0283 - accuracy: 0.9905 - val_loss: 0.5798 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95270\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.5299 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95270\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0082 - accuracy: 0.9958 - val_loss: 0.6875 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95270\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 0.6282 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95270\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.6524 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95270\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.5291 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95270\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0324 - accuracy: 0.9911 - val_loss: 0.5173 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95270\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.4944 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95270\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0079 - accuracy: 0.9958 - val_loss: 0.9609 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95270\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.6018 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95270\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0127 - accuracy: 0.9937 - val_loss: 0.4690 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95270\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.6309 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95270\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.6443 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95270\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.3906 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95270\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.5093 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95270\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0213 - accuracy: 0.9947 - val_loss: 0.5646 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95270\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.4295 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95270\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.6403 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95270\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.5325 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95270\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.7018 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95270\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 3.4378 - val_accuracy: 0.6216\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95270\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.4152 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95270\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0400 - accuracy: 0.9847 - val_loss: 0.7029 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95270\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0191 - accuracy: 0.9916 - val_loss: 0.6621 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95270\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.6292 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95270\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0315 - accuracy: 0.9942 - val_loss: 0.5012 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95270\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.6638 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95270\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.6777 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95270\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.7315 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95270\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0248 - accuracy: 0.9937 - val_loss: 0.6440 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95270\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.5323 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95270\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.4780 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95270\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.6354 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95270\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0092 - accuracy: 0.9958 - val_loss: 0.5912 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95270\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0163 - accuracy: 0.9963 - val_loss: 1.5725 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95270\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0475 - accuracy: 0.9863 - val_loss: 0.9388 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95270\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.7310 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95270\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.6254 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95270\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 4.4982 - val_accuracy: 0.5203\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95270\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0337 - accuracy: 0.9905 - val_loss: 0.6292 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95270\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0324 - accuracy: 0.9932 - val_loss: 0.6215 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95270\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.6044 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95270\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.5253 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95270\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0158 - accuracy: 0.9932 - val_loss: 0.6724 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95270\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.6228 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95270\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.6240 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95270\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.6737 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95270\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0184 - accuracy: 0.9926 - val_loss: 0.7118 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95270\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.7138 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95270\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.6100 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95270\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.6764 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95270\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.6259 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95270\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.5702 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95270\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0174 - accuracy: 0.9937 - val_loss: 0.5632 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95270\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0357 - accuracy: 0.9900 - val_loss: 0.6935 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95270\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.7875 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95270\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0283 - accuracy: 0.9942 - val_loss: 0.6904 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95270\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.4863 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95270\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.4703 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95270\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 0.6256 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95270\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.5353 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95270\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.5060 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95270\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.5135 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95270\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0109 - accuracy: 0.9947 - val_loss: 0.6064 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95270\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.6912 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95270\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.4163 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95270\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.5354 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95270\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.5373 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95270\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.6463 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95270\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0269 - accuracy: 0.9911 - val_loss: 0.5829 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95270\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.6170 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95270\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 1.1966 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95270\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.7265 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95270\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.7364 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95270\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0085 - accuracy: 0.9958 - val_loss: 0.9440 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95270\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0105 - accuracy: 0.9958 - val_loss: 0.5819 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95270\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 0.7257 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95270\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.5676 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95270\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0228 - accuracy: 0.9937 - val_loss: 0.3931 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95270\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.7656 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95270\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0259 - accuracy: 0.9947 - val_loss: 0.5358 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95270\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.6255 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95270\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0141 - accuracy: 0.9968 - val_loss: 0.7876 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95270\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.6105 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95270\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.8625 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95270\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.8982 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95270\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.7372 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95270\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.7004 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95270\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.6100 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95270\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.7350 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95270\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.7534 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95270\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0301 - accuracy: 0.9889 - val_loss: 1.1886 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95270\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.9466 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95270\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0214 - accuracy: 0.9953 - val_loss: 0.7429 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95270\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0154 - accuracy: 0.9926 - val_loss: 0.9487 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95270\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.7260 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95270\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.6971 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95270\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.6262 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95270\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.7421 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95270\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 0.8306 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95270\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.5490 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95270\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.6798 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95270\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.8889 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95270\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 0.7071 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95270\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.7502 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95270\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.7604 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95270\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.9542 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95270\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0164 - accuracy: 0.9926 - val_loss: 0.7518 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95270\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.7176 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95270\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0243 - accuracy: 0.9937 - val_loss: 1.4394 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95270\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.4294 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95270\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.5271 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95270\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0141 - accuracy: 0.9968 - val_loss: 0.7085 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95270\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.6579 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95270\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.6250 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95270\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.6404 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95270\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.4508 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95270\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0093 - accuracy: 0.9953 - val_loss: 0.7049 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95270\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.5495 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95270\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95270\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.7427 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95270\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.5888 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95270\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.7964 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95270\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0104 - accuracy: 0.9947 - val_loss: 0.6417 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95270\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.5770 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95270\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 28s 117ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.6454 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95270\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.6285 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95270\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.7923 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95270\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0229 - accuracy: 0.9937 - val_loss: 1.5151 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95270\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.5870 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95270\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.6919 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95270\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.5904 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95270\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 2.3504 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95270\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.6774 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95270\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.7291 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95270\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.8420 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95270\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.8280 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95270\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.6222 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95270\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.7452 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95270\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.5732 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f99404ef7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b686f297-bb56-4aa3-e390-6d311fd9f003"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d12d48b9-75a3-4aee-cfc9-859f05d8ef07"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1dc70d-8d07-4ee1-8058-bf8eeb222a51"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6b6498b6-d9c3-4522-fbb2-4d4dce7d720e"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4c443715-549e-4424-9f31-87be6278db66\", \"EfficientNetB5_1.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}