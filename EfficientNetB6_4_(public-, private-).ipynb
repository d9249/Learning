{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB6_4_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/EfficientNetB6_4_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4328736-243a-4648-d3de-c2268f0133c3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 29 20:40:00 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16096547-a87c-440c-9e44-615923b51031"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "nunbering = '6'\n",
        "model_save = 'EfficientNetB' + nunbering + '_4'\n",
        "Target_model = 'EfficientNetB' + nunbering + '_model'\n",
        "Target_predict = 'EfficientNetB' + nunbering + '_predict'\n",
        "Target_acc = 'EfficientNetB' + nunbering + '_acc'\n",
        "Target_val = 'EfficientNetB' + nunbering + '_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.EfficientNetB6(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125f53d4-3ccf-44d9-c37e-4e5f246f29f1"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "588e6b14-81fb-4e62-cc17-1ec0a1a07518"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 109s 301ms/step - loss: 3.9968 - accuracy: 0.1216 - val_loss: 2.3257 - val_accuracy: 0.1081\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 2.5650 - accuracy: 0.1374 - val_loss: 2.3431 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10811\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 2.3943 - accuracy: 0.1847 - val_loss: 6.8991 - val_accuracy: 0.1081\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.10811\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 2.3023 - accuracy: 0.2268 - val_loss: 2.0287 - val_accuracy: 0.3784\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.10811 to 0.37838, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 2.0822 - accuracy: 0.3105 - val_loss: 1.7946 - val_accuracy: 0.3784\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.37838\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 1.6317 - accuracy: 0.4563 - val_loss: 1.4154 - val_accuracy: 0.5135\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.37838 to 0.51351, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 1.3082 - accuracy: 0.5895 - val_loss: 4.3516 - val_accuracy: 0.1419\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.51351\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 1.1148 - accuracy: 0.6389 - val_loss: 0.8522 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.51351 to 0.71622, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.9548 - accuracy: 0.7037 - val_loss: 3.1690 - val_accuracy: 0.4257\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.71622\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.9021 - accuracy: 0.7147 - val_loss: 0.6766 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.71622 to 0.81081, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.8337 - accuracy: 0.7474 - val_loss: 0.5655 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.81081\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.7424 - accuracy: 0.7711 - val_loss: 0.5648 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.81081\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.6774 - accuracy: 0.7868 - val_loss: 0.6754 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.81081 to 0.81757, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.6521 - accuracy: 0.7937 - val_loss: 0.5249 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.81757 to 0.85811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.6296 - accuracy: 0.8058 - val_loss: 6.2443 - val_accuracy: 0.1622\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.85811\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.6010 - accuracy: 0.8179 - val_loss: 0.5611 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.85811\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.5518 - accuracy: 0.8316 - val_loss: 0.3975 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.85811\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.5378 - accuracy: 0.8379 - val_loss: 0.5248 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.85811\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.5367 - accuracy: 0.8258 - val_loss: 1.9828 - val_accuracy: 0.4932\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.85811\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.4951 - accuracy: 0.8537 - val_loss: 3.1450 - val_accuracy: 0.3378\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.85811\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.4964 - accuracy: 0.8395 - val_loss: 0.5193 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.85811\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.4884 - accuracy: 0.8479 - val_loss: 0.3589 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.85811 to 0.86486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 0.4558 - accuracy: 0.8484 - val_loss: 0.7847 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.86486\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.4289 - accuracy: 0.8674 - val_loss: 4.6304 - val_accuracy: 0.2297\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.86486\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 0.4338 - accuracy: 0.8689 - val_loss: 0.9558 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.86486\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.4482 - accuracy: 0.8579 - val_loss: 0.5891 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.86486\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.3944 - accuracy: 0.8863 - val_loss: 1.8502 - val_accuracy: 0.5338\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.86486\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.3814 - accuracy: 0.8811 - val_loss: 0.5754 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.86486\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.4141 - accuracy: 0.8732 - val_loss: 0.5831 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.86486\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.3809 - accuracy: 0.8811 - val_loss: 0.6922 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.86486\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.3340 - accuracy: 0.8984 - val_loss: 0.6963 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.86486\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.3100 - accuracy: 0.8968 - val_loss: 2.6509 - val_accuracy: 0.4122\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.86486\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 0.3326 - accuracy: 0.8963 - val_loss: 0.5748 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.86486\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.3409 - accuracy: 0.8874 - val_loss: 0.4411 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.86486 to 0.87838, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.3119 - accuracy: 0.9058 - val_loss: 0.5318 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.87838\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.2944 - accuracy: 0.9032 - val_loss: 0.4647 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.87838\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.2854 - accuracy: 0.9053 - val_loss: 0.3346 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.87838 to 0.88514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.3022 - accuracy: 0.9042 - val_loss: 0.8953 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.88514\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.3128 - accuracy: 0.8979 - val_loss: 1.4617 - val_accuracy: 0.6419\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.88514\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.2833 - accuracy: 0.9084 - val_loss: 0.6182 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.88514\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.2967 - accuracy: 0.9058 - val_loss: 5.0247 - val_accuracy: 0.2568\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.88514\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.2642 - accuracy: 0.9184 - val_loss: 0.5623 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.88514\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.2463 - accuracy: 0.9221 - val_loss: 0.3636 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.88514 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.2028 - accuracy: 0.9289 - val_loss: 0.5034 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89189\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.2882 - accuracy: 0.9058 - val_loss: 0.6441 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89189\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.2481 - accuracy: 0.9142 - val_loss: 7.3872 - val_accuracy: 0.1419\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89189\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.2387 - accuracy: 0.9268 - val_loss: 0.7829 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89189\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.2057 - accuracy: 0.9379 - val_loss: 0.4267 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89189\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.2275 - accuracy: 0.9316 - val_loss: 0.6154 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89189\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.1944 - accuracy: 0.9353 - val_loss: 0.3524 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.89189 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.1726 - accuracy: 0.9437 - val_loss: 0.4607 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91216\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.2008 - accuracy: 0.9337 - val_loss: 0.4971 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91216\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.2216 - accuracy: 0.9337 - val_loss: 0.9322 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91216\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1866 - accuracy: 0.9395 - val_loss: 0.4970 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91216\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.1649 - accuracy: 0.9468 - val_loss: 0.3438 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91216\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1583 - accuracy: 0.9468 - val_loss: 1.0636 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91216\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.2140 - accuracy: 0.9300 - val_loss: 1.9570 - val_accuracy: 0.5811\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91216\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.1623 - accuracy: 0.9474 - val_loss: 0.3684 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91216\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.1301 - accuracy: 0.9621 - val_loss: 0.3562 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91216\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.2178 - accuracy: 0.9379 - val_loss: 1.1630 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91216\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1330 - accuracy: 0.9642 - val_loss: 0.5422 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91216\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.1851 - accuracy: 0.9400 - val_loss: 0.3819 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.91216 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.1205 - accuracy: 0.9595 - val_loss: 2.2298 - val_accuracy: 0.4932\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91892\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1505 - accuracy: 0.9542 - val_loss: 0.5877 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91892\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1484 - accuracy: 0.9489 - val_loss: 3.2918 - val_accuracy: 0.4595\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91892\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1791 - accuracy: 0.9447 - val_loss: 0.2923 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.91892 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.1361 - accuracy: 0.9595 - val_loss: 0.3781 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.92568\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1305 - accuracy: 0.9600 - val_loss: 2.2020 - val_accuracy: 0.5743\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.92568\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1211 - accuracy: 0.9605 - val_loss: 0.3141 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.92568\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.1418 - accuracy: 0.9574 - val_loss: 0.3809 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.92568\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0945 - accuracy: 0.9711 - val_loss: 0.3664 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.92568\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 67s 284ms/step - loss: 0.1093 - accuracy: 0.9653 - val_loss: 0.5453 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.92568\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1428 - accuracy: 0.9589 - val_loss: 0.3226 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.92568 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.1111 - accuracy: 0.9695 - val_loss: 0.3405 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.93243\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0964 - accuracy: 0.9711 - val_loss: 0.4829 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.93243\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1005 - accuracy: 0.9668 - val_loss: 0.4053 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.93243\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1291 - accuracy: 0.9574 - val_loss: 0.5711 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.93243\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1354 - accuracy: 0.9547 - val_loss: 2.7978 - val_accuracy: 0.5338\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.93243\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1431 - accuracy: 0.9484 - val_loss: 0.5904 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.93243\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0922 - accuracy: 0.9711 - val_loss: 0.6836 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.93243\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0930 - accuracy: 0.9742 - val_loss: 5.6450 - val_accuracy: 0.1351\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.93243\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0866 - accuracy: 0.9721 - val_loss: 1.3651 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.93243\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1130 - accuracy: 0.9684 - val_loss: 0.2827 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.93243\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1279 - accuracy: 0.9589 - val_loss: 0.7098 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.93243\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1223 - accuracy: 0.9653 - val_loss: 0.5156 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.93243\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0844 - accuracy: 0.9711 - val_loss: 0.3585 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.93243\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0875 - accuracy: 0.9732 - val_loss: 0.4338 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.93243\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0721 - accuracy: 0.9768 - val_loss: 0.4179 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.93243\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0862 - accuracy: 0.9758 - val_loss: 0.4255 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.93243\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1114 - accuracy: 0.9679 - val_loss: 0.6238 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.93243\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.1028 - accuracy: 0.9689 - val_loss: 1.9088 - val_accuracy: 0.6486\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.93243\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0834 - accuracy: 0.9716 - val_loss: 0.3529 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.93243\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0836 - accuracy: 0.9784 - val_loss: 0.4541 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.93243\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0748 - accuracy: 0.9774 - val_loss: 0.3130 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.93243\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0794 - accuracy: 0.9768 - val_loss: 0.3792 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00095: val_accuracy improved from 0.93243 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0799 - accuracy: 0.9726 - val_loss: 0.8208 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.94595\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0556 - accuracy: 0.9800 - val_loss: 0.5117 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.94595\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0768 - accuracy: 0.9758 - val_loss: 0.5589 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.94595\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.1256 - accuracy: 0.9632 - val_loss: 0.4514 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.94595\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0894 - accuracy: 0.9695 - val_loss: 0.3783 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.94595\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0931 - accuracy: 0.9732 - val_loss: 0.3293 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.94595\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0859 - accuracy: 0.9758 - val_loss: 0.3856 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.94595\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0749 - accuracy: 0.9737 - val_loss: 0.7665 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.94595\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0720 - accuracy: 0.9763 - val_loss: 0.4614 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.94595\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0707 - accuracy: 0.9779 - val_loss: 0.3350 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.94595\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0682 - accuracy: 0.9753 - val_loss: 0.4589 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.94595\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0946 - accuracy: 0.9695 - val_loss: 0.6018 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.94595\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0761 - accuracy: 0.9742 - val_loss: 0.2363 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.94595\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0815 - accuracy: 0.9732 - val_loss: 0.4153 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.94595\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.0596 - accuracy: 0.9832 - val_loss: 0.4569 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.94595\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0481 - accuracy: 0.9826 - val_loss: 0.4828 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.94595\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0366 - accuracy: 0.9879 - val_loss: 0.3107 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.94595\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.0982 - accuracy: 0.9747 - val_loss: 0.5790 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.94595\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0539 - accuracy: 0.9868 - val_loss: 0.5815 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.94595\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.1002 - accuracy: 0.9705 - val_loss: 0.5415 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.94595\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0865 - accuracy: 0.9747 - val_loss: 0.4794 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.94595\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0505 - accuracy: 0.9821 - val_loss: 0.3764 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.94595\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0420 - accuracy: 0.9884 - val_loss: 0.5218 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.94595\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0673 - accuracy: 0.9758 - val_loss: 0.5364 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.94595\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.0641 - accuracy: 0.9768 - val_loss: 0.4085 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.94595\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.0748 - accuracy: 0.9747 - val_loss: 0.5409 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.94595\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0746 - accuracy: 0.9784 - val_loss: 0.3868 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.94595\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.0622 - accuracy: 0.9795 - val_loss: 0.4703 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.94595\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0453 - accuracy: 0.9832 - val_loss: 0.3511 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.94595\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0668 - accuracy: 0.9805 - val_loss: 0.5023 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.94595\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0825 - accuracy: 0.9747 - val_loss: 0.9224 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.94595\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.5127 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.94595\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0521 - accuracy: 0.9847 - val_loss: 0.4124 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.94595\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.0494 - accuracy: 0.9826 - val_loss: 0.5274 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.94595\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.0922 - accuracy: 0.9716 - val_loss: 0.4512 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.94595\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0473 - accuracy: 0.9863 - val_loss: 0.4381 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.94595\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 0.4517 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.94595\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 68s 285ms/step - loss: 0.0457 - accuracy: 0.9842 - val_loss: 0.4538 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.94595\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 0.0594 - accuracy: 0.9847 - val_loss: 0.7598 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.94595\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0624 - accuracy: 0.9795 - val_loss: 1.1937 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.94595\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0731 - accuracy: 0.9768 - val_loss: 1.0108 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.94595\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 0.0647 - accuracy: 0.9789 - val_loss: 0.5709 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.94595\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0682 - accuracy: 0.9768 - val_loss: 0.4815 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.94595\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0723 - accuracy: 0.9779 - val_loss: 0.4326 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.94595\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0719 - accuracy: 0.9837 - val_loss: 0.3660 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.94595\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 0.0472 - accuracy: 0.9832 - val_loss: 0.4029 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.94595\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0349 - accuracy: 0.9916 - val_loss: 0.3379 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.94595\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 0.0367 - accuracy: 0.9911 - val_loss: 0.5990 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.94595\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0641 - accuracy: 0.9779 - val_loss: 0.5159 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.94595\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0407 - accuracy: 0.9863 - val_loss: 0.8601 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.94595\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0718 - accuracy: 0.9826 - val_loss: 0.6684 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.94595\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0411 - accuracy: 0.9879 - val_loss: 0.4806 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.94595\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0328 - accuracy: 0.9911 - val_loss: 0.4902 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.94595\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0572 - accuracy: 0.9826 - val_loss: 0.4233 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.94595\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0567 - accuracy: 0.9811 - val_loss: 0.5245 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.94595\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0446 - accuracy: 0.9832 - val_loss: 0.9393 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.94595\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0402 - accuracy: 0.9879 - val_loss: 0.5602 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.94595\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0640 - accuracy: 0.9821 - val_loss: 1.5758 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.94595\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0619 - accuracy: 0.9826 - val_loss: 0.4222 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.94595\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0459 - accuracy: 0.9842 - val_loss: 0.4135 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.94595\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 0.5043 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.94595\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0376 - accuracy: 0.9874 - val_loss: 0.6063 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.94595\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0655 - accuracy: 0.9832 - val_loss: 0.5825 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.94595\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0488 - accuracy: 0.9832 - val_loss: 0.4133 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.94595\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0399 - accuracy: 0.9847 - val_loss: 0.5359 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.94595\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0683 - accuracy: 0.9789 - val_loss: 0.7414 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.94595\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0510 - accuracy: 0.9811 - val_loss: 0.5656 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.94595\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0338 - accuracy: 0.9895 - val_loss: 0.5710 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.94595\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0372 - accuracy: 0.9905 - val_loss: 1.1555 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.94595\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 0.0200 - accuracy: 0.9905 - val_loss: 0.6738 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.94595\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0476 - accuracy: 0.9858 - val_loss: 0.9014 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.94595\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0442 - accuracy: 0.9826 - val_loss: 0.7716 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.94595\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0707 - accuracy: 0.9774 - val_loss: 0.6542 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.94595\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0495 - accuracy: 0.9816 - val_loss: 0.4712 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.94595\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 0.0607 - accuracy: 0.9832 - val_loss: 0.4840 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.94595\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 0.0323 - accuracy: 0.9905 - val_loss: 0.5799 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.94595\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0591 - accuracy: 0.9826 - val_loss: 0.5852 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.94595\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.7388 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.94595\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.6143 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.94595\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0347 - accuracy: 0.9879 - val_loss: 0.8154 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.94595\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0484 - accuracy: 0.9853 - val_loss: 0.7307 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.94595\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0283 - accuracy: 0.9921 - val_loss: 0.5357 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.94595\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0320 - accuracy: 0.9905 - val_loss: 0.7692 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.94595\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0549 - accuracy: 0.9816 - val_loss: 0.5653 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.94595\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0520 - accuracy: 0.9847 - val_loss: 0.4832 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.94595\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0417 - accuracy: 0.9884 - val_loss: 0.8297 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.94595\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.4778 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.94595\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0295 - accuracy: 0.9889 - val_loss: 0.5484 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.94595\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0549 - accuracy: 0.9816 - val_loss: 0.6871 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.94595\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.3543 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.94595\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0410 - accuracy: 0.9858 - val_loss: 0.3381 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.94595\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0276 - accuracy: 0.9937 - val_loss: 0.4509 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.94595\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0863 - accuracy: 0.9789 - val_loss: 0.4439 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.94595\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 0.0322 - accuracy: 0.9905 - val_loss: 0.3341 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.94595\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0315 - accuracy: 0.9916 - val_loss: 0.4169 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.94595\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0318 - accuracy: 0.9911 - val_loss: 0.3890 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.94595\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0503 - accuracy: 0.9847 - val_loss: 0.7309 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.94595\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0468 - accuracy: 0.9868 - val_loss: 0.4491 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.94595\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 68s 288ms/step - loss: 0.0238 - accuracy: 0.9916 - val_loss: 0.5006 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.94595\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0634 - accuracy: 0.9821 - val_loss: 0.5337 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.94595\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0357 - accuracy: 0.9858 - val_loss: 0.3600 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.94595\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.3830 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.94595\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.6179 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.94595\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0311 - accuracy: 0.9884 - val_loss: 0.4941 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.94595\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0353 - accuracy: 0.9889 - val_loss: 0.4231 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.94595\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0411 - accuracy: 0.9900 - val_loss: 0.6036 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.94595\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 68s 287ms/step - loss: 0.0464 - accuracy: 0.9868 - val_loss: 0.4180 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.94595\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 0.5488 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.94595\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.5787 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.94595\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0565 - accuracy: 0.9863 - val_loss: 0.3159 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.94595\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0273 - accuracy: 0.9884 - val_loss: 0.4409 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.94595\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.5155 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.94595\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.4114 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.94595\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0371 - accuracy: 0.9905 - val_loss: 0.6757 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.94595\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0505 - accuracy: 0.9832 - val_loss: 0.8119 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.94595\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0313 - accuracy: 0.9895 - val_loss: 0.6473 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.94595\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0401 - accuracy: 0.9911 - val_loss: 0.6815 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.94595\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0292 - accuracy: 0.9874 - val_loss: 0.7481 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.94595\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.1074 - accuracy: 0.9732 - val_loss: 0.5506 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.94595\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.5957 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.94595\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0097 - accuracy: 0.9958 - val_loss: 0.4266 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.94595\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.6168 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.94595\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0296 - accuracy: 0.9916 - val_loss: 0.6664 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.94595\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0340 - accuracy: 0.9911 - val_loss: 0.3947 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.94595\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0516 - accuracy: 0.9842 - val_loss: 0.4535 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.94595\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.6494 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.94595\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.5431 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.94595\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0509 - accuracy: 0.9900 - val_loss: 0.6758 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.94595\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0174 - accuracy: 0.9926 - val_loss: 0.6246 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.94595\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0603 - accuracy: 0.9826 - val_loss: 0.7536 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.94595\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 0.5314 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.94595\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0257 - accuracy: 0.9937 - val_loss: 0.4235 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.94595\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.5837 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.94595\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0340 - accuracy: 0.9874 - val_loss: 0.8543 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.94595\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0397 - accuracy: 0.9863 - val_loss: 0.7157 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.94595\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0612 - accuracy: 0.9805 - val_loss: 0.6102 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.94595\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0499 - accuracy: 0.9847 - val_loss: 0.5315 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.94595\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.4018 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.94595\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0513 - accuracy: 0.9900 - val_loss: 0.3660 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.94595\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0109 - accuracy: 0.9947 - val_loss: 0.3627 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.94595\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0116 - accuracy: 0.9947 - val_loss: 0.4676 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.94595\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.5406 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.94595\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.5420 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.94595\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.7011 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.94595\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0619 - accuracy: 0.9826 - val_loss: 0.6270 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.94595\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0327 - accuracy: 0.9900 - val_loss: 0.4660 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.94595\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0541 - accuracy: 0.9879 - val_loss: 0.7548 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.94595\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0261 - accuracy: 0.9905 - val_loss: 0.5624 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.94595\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.5063 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.94595\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0568 - accuracy: 0.9842 - val_loss: 0.9396 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.94595\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 0.4628 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.94595\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0360 - accuracy: 0.9895 - val_loss: 0.6566 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.94595\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0433 - accuracy: 0.9884 - val_loss: 0.5480 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.94595\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.7003 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.94595\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.8053 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.94595\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0206 - accuracy: 0.9916 - val_loss: 0.4904 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.94595\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 0.7639 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.94595\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0233 - accuracy: 0.9900 - val_loss: 0.6857 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.94595\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0287 - accuracy: 0.9926 - val_loss: 0.6576 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.94595\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 0.6381 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.94595\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.5780 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.94595\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0175 - accuracy: 0.9932 - val_loss: 0.6606 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.94595\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 0.6239 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.94595\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0203 - accuracy: 0.9900 - val_loss: 0.5801 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.94595\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0384 - accuracy: 0.9895 - val_loss: 0.6826 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.94595\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 69s 288ms/step - loss: 0.0366 - accuracy: 0.9895 - val_loss: 0.7716 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.94595\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.6519 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.94595\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 1.0231 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.94595\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0350 - accuracy: 0.9937 - val_loss: 0.5204 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.94595\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0311 - accuracy: 0.9889 - val_loss: 0.5816 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.94595\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.8066 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.94595\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 69s 292ms/step - loss: 0.0335 - accuracy: 0.9900 - val_loss: 1.4427 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.94595\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0413 - accuracy: 0.9874 - val_loss: 0.8342 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.94595\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0305 - accuracy: 0.9879 - val_loss: 0.5062 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.94595\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0387 - accuracy: 0.9900 - val_loss: 1.2259 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.94595\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0409 - accuracy: 0.9905 - val_loss: 0.4601 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.94595\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.4846 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.94595\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.5287 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.94595\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.4053 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.94595\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.6548 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.94595\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0332 - accuracy: 0.9889 - val_loss: 0.5796 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.94595\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0354 - accuracy: 0.9900 - val_loss: 0.5674 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.94595\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0493 - accuracy: 0.9858 - val_loss: 0.6466 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.94595\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0283 - accuracy: 0.9953 - val_loss: 0.3738 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.94595\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0154 - accuracy: 0.9937 - val_loss: 0.4272 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.94595\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0314 - accuracy: 0.9932 - val_loss: 0.7764 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.94595\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0426 - accuracy: 0.9868 - val_loss: 0.4920 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.94595\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0306 - accuracy: 0.9911 - val_loss: 0.6698 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.94595\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0304 - accuracy: 0.9905 - val_loss: 0.5298 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.94595\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.5265 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.94595\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.6260 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.94595\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.4670 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.94595\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.6109 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.94595\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.3894 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.94595\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.6602 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.94595\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.5837 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.94595\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.7644 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.94595\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0241 - accuracy: 0.9937 - val_loss: 0.6315 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.94595\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.4914 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.94595\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0189 - accuracy: 0.9953 - val_loss: 0.7362 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.94595\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0353 - accuracy: 0.9879 - val_loss: 0.7490 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.94595\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0435 - accuracy: 0.9868 - val_loss: 0.4991 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.94595\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0703 - accuracy: 0.9795 - val_loss: 0.5164 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.94595\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 0.4743 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.94595\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0229 - accuracy: 0.9947 - val_loss: 0.5057 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.94595\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0273 - accuracy: 0.9905 - val_loss: 0.6658 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.94595\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0386 - accuracy: 0.9900 - val_loss: 0.6551 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.94595\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0171 - accuracy: 0.9911 - val_loss: 0.8427 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.94595\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.5853 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.94595\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0251 - accuracy: 0.9947 - val_loss: 0.7767 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.94595\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0338 - accuracy: 0.9879 - val_loss: 0.5676 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.94595\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0189 - accuracy: 0.9926 - val_loss: 0.6916 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.94595\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0147 - accuracy: 0.9942 - val_loss: 0.7703 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.94595\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0254 - accuracy: 0.9932 - val_loss: 0.6834 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.94595\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 1.0873 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.94595\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.7685 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.94595\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 69s 292ms/step - loss: 0.0208 - accuracy: 0.9968 - val_loss: 0.7373 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.94595\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0292 - accuracy: 0.9916 - val_loss: 0.8455 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.94595\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0264 - accuracy: 0.9937 - val_loss: 0.7025 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.94595\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0268 - accuracy: 0.9889 - val_loss: 0.7359 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.94595\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0222 - accuracy: 0.9900 - val_loss: 0.6730 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.94595\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.5441 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.94595\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0261 - accuracy: 0.9947 - val_loss: 0.5981 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.94595\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0374 - accuracy: 0.9905 - val_loss: 0.7752 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.94595\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 69s 289ms/step - loss: 0.0289 - accuracy: 0.9937 - val_loss: 0.6327 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.94595\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.6440 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.94595\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0186 - accuracy: 0.9926 - val_loss: 0.6629 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.94595\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.5504 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.94595\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.5363 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.94595\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0535 - accuracy: 0.9832 - val_loss: 0.5965 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.94595\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 69s 292ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.4980 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.94595\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0346 - accuracy: 0.9911 - val_loss: 0.5538 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.94595\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0240 - accuracy: 0.9942 - val_loss: 0.7262 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.94595\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0362 - accuracy: 0.9916 - val_loss: 0.7994 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.94595\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0194 - accuracy: 0.9926 - val_loss: 0.6699 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.94595\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 0.7374 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.94595\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 0.6578 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.94595\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.7100 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.94595\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.7078 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.94595\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 69s 290ms/step - loss: 0.0186 - accuracy: 0.9926 - val_loss: 0.8476 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.94595\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0624 - accuracy: 0.9853 - val_loss: 0.8870 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.94595\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 0.8556 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.94595\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.7284 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.94595\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.8528 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.94595\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.8359 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.94595\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 0.5253 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.94595\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0142 - accuracy: 0.9926 - val_loss: 0.6383 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.94595\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 0.8504 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.94595\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0295 - accuracy: 0.9911 - val_loss: 0.5490 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.94595\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0202 - accuracy: 0.9921 - val_loss: 0.8404 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.94595\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0428 - accuracy: 0.9884 - val_loss: 0.7948 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.94595\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 0.6487 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.94595\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.5792 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.94595\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.7410 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.94595\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.8293 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.94595\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 0.6273 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.94595\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.5898 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.94595\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0184 - accuracy: 0.9932 - val_loss: 0.6644 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.94595\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0198 - accuracy: 0.9911 - val_loss: 0.6689 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.94595\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.6988 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.94595\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0468 - accuracy: 0.9905 - val_loss: 0.4921 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.94595\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.6848 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.94595\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0548 - accuracy: 0.9847 - val_loss: 0.5952 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.94595\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0186 - accuracy: 0.9921 - val_loss: 0.3059 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00359: val_accuracy improved from 0.94595 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB6_4.h5\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 71s 296ms/step - loss: 0.0256 - accuracy: 0.9932 - val_loss: 0.4924 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95270\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.3958 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95270\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0237 - accuracy: 0.9932 - val_loss: 0.4486 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95270\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.7059 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95270\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0156 - accuracy: 0.9937 - val_loss: 0.4806 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95270\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.3603 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95270\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.5112 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95270\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.6236 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95270\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.7408 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95270\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.5347 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95270\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.5824 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95270\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0145 - accuracy: 0.9942 - val_loss: 0.7244 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95270\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.5489 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95270\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0335 - accuracy: 0.9889 - val_loss: 0.6509 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95270\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0299 - accuracy: 0.9932 - val_loss: 0.6122 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95270\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.6092 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95270\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.6600 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95270\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0424 - accuracy: 0.9889 - val_loss: 0.3810 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95270\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0094 - accuracy: 0.9958 - val_loss: 0.4797 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95270\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.5480 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95270\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 71s 297ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.5151 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95270\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 71s 297ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.7009 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95270\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0308 - accuracy: 0.9926 - val_loss: 0.4534 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95270\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 0.7601 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95270\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0088 - accuracy: 0.9953 - val_loss: 0.8329 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95270\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.8771 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95270\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 71s 298ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.5296 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95270\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0292 - accuracy: 0.9916 - val_loss: 0.4734 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95270\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0264 - accuracy: 0.9926 - val_loss: 0.4257 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95270\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.4290 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95270\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0291 - accuracy: 0.9942 - val_loss: 0.6337 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95270\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.7017 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95270\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.7550 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95270\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.7216 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95270\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0346 - accuracy: 0.9926 - val_loss: 0.5801 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95270\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 0.6971 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95270\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.6002 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95270\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.7253 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95270\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.4871 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95270\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0269 - accuracy: 0.9926 - val_loss: 0.4971 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95270\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.4647 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95270\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.6710 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95270\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.7429 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95270\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.6913 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95270\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 0.7419 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95270\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.5853 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95270\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.7647 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95270\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.4670 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95270\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.6537 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95270\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0330 - accuracy: 0.9921 - val_loss: 0.6329 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95270\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0254 - accuracy: 0.9911 - val_loss: 0.5786 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95270\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0106 - accuracy: 0.9947 - val_loss: 0.8816 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95270\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0287 - accuracy: 0.9926 - val_loss: 0.7875 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95270\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0271 - accuracy: 0.9916 - val_loss: 0.6608 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95270\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.6658 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95270\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.5380 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95270\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.7546 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95270\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0283 - accuracy: 0.9932 - val_loss: 0.7668 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95270\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0274 - accuracy: 0.9932 - val_loss: 0.5541 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95270\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.7058 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95270\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.7374 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95270\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0165 - accuracy: 0.9963 - val_loss: 0.9062 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95270\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0173 - accuracy: 0.9932 - val_loss: 0.6341 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95270\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0149 - accuracy: 0.9916 - val_loss: 0.7069 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95270\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0421 - accuracy: 0.9874 - val_loss: 0.7263 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95270\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.7531 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95270\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.8274 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95270\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.8124 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95270\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0298 - accuracy: 0.9911 - val_loss: 0.7461 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95270\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0311 - accuracy: 0.9916 - val_loss: 0.7711 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95270\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0197 - accuracy: 0.9916 - val_loss: 0.9067 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95270\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 69s 292ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.5458 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95270\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 69s 292ms/step - loss: 0.0120 - accuracy: 0.9953 - val_loss: 0.4147 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95270\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.6122 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95270\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0253 - accuracy: 0.9947 - val_loss: 0.5434 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95270\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.3751 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95270\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 69s 292ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.4941 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95270\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.6240 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95270\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 69s 292ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.4392 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95270\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 69s 292ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.8065 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95270\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 69s 292ms/step - loss: 0.0269 - accuracy: 0.9937 - val_loss: 0.9681 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95270\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0491 - accuracy: 0.9905 - val_loss: 0.5973 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95270\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0275 - accuracy: 0.9942 - val_loss: 0.6034 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95270\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 69s 291ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.6764 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95270\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.3873 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95270\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 69s 292ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.3937 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95270\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.4090 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95270\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.4719 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95270\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.6127 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95270\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 70s 292ms/step - loss: 0.0224 - accuracy: 0.9947 - val_loss: 0.4274 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95270\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.8452 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95270\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.6691 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95270\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0328 - accuracy: 0.9916 - val_loss: 0.7285 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95270\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0355 - accuracy: 0.9926 - val_loss: 0.5505 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95270\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0345 - accuracy: 0.9889 - val_loss: 0.8688 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95270\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 70s 293ms/step - loss: 0.0262 - accuracy: 0.9937 - val_loss: 0.6804 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95270\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.6342 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95270\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.6330 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95270\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0210 - accuracy: 0.9953 - val_loss: 0.8569 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95270\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.5815 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95270\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.5698 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95270\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.5545 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95270\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0232 - accuracy: 0.9942 - val_loss: 0.7717 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95270\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0258 - accuracy: 0.9958 - val_loss: 0.7126 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95270\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0239 - accuracy: 0.9916 - val_loss: 0.5873 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95270\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.7399 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95270\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0210 - accuracy: 0.9958 - val_loss: 0.5048 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95270\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.5502 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95270\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.4760 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95270\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.5163 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95270\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0126 - accuracy: 0.9942 - val_loss: 0.6759 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95270\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.7483 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95270\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.7541 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95270\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 70s 294ms/step - loss: 0.0205 - accuracy: 0.9926 - val_loss: 0.6705 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95270\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 0.4781 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95270\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.7013 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95270\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.8719 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95270\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.6421 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95270\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0086 - accuracy: 0.9958 - val_loss: 0.6729 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95270\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.5642 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95270\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0240 - accuracy: 0.9963 - val_loss: 0.6530 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95270\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.6454 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95270\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 71s 296ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.5800 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95270\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.7849 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95270\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0337 - accuracy: 0.9911 - val_loss: 0.5769 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95270\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 71s 296ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.7998 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95270\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.6882 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95270\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 71s 296ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.7808 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95270\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 70s 296ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.8030 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95270\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.6295 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95270\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0227 - accuracy: 0.9905 - val_loss: 0.4658 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95270\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 71s 296ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.6958 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95270\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0303 - accuracy: 0.9911 - val_loss: 0.6418 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95270\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.6276 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95270\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0186 - accuracy: 0.9968 - val_loss: 0.6220 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95270\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 71s 297ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.5135 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95270\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 71s 296ms/step - loss: 0.0331 - accuracy: 0.9937 - val_loss: 0.7449 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95270\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.5687 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95270\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5050 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95270\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.5963 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95270\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 70s 295ms/step - loss: 0.0275 - accuracy: 0.9937 - val_loss: 0.7559 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f941a2a3310>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "53902a15-1eae-4c52-d04d-96ec8ea02223"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dca7671-7b8c-46af-d7f9-e38b6e7d4b2a"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09f079c-7659-4285-b7ce-1ccfde4c6bcb"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "06d0e629-4b8b-4a2f-9146-6ae715949b78"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a31c3349-b424-4419-b519-90dff353745b\", \"EfficientNetB6_4.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}