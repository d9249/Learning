{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageSize_224_1_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3potMbBhb8baQ6YHd3sls",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/ImageSize_224_1_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "063f20ec-33f9-44ac-c86b-30fd51a9f7a6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep  9 09:06:08 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff5100b-604c-493c-eae8-6c0e56942fd2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296875db-276f-45d8-9476-47297b45dbfb"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e894ef-de28-42c3-a23c-4e9f45d729a8"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7bcc9b4-88da-4fca-e192-ec06cfc010bc"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 75s 866ms/step - loss: 1.9281 - accuracy: 0.3118 - val_loss: 7.7774 - val_accuracy: 0.1281\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.12808, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 39s 745ms/step - loss: 1.2372 - accuracy: 0.5773 - val_loss: 28.5099 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.12808\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.9654 - accuracy: 0.6742 - val_loss: 5.3893 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.12808\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.7931 - accuracy: 0.7253 - val_loss: 6.1125 - val_accuracy: 0.1084\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.12808\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.7151 - accuracy: 0.7643 - val_loss: 4.0234 - val_accuracy: 0.2167\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.12808 to 0.21675, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.6434 - accuracy: 0.7862 - val_loss: 2.7489 - val_accuracy: 0.3202\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.21675 to 0.32020, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.6474 - accuracy: 0.7832 - val_loss: 2.9742 - val_accuracy: 0.3325\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.32020 to 0.33251, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.5716 - accuracy: 0.8076 - val_loss: 2.0238 - val_accuracy: 0.4507\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.33251 to 0.45074, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.5000 - accuracy: 0.8216 - val_loss: 1.9101 - val_accuracy: 0.5394\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.45074 to 0.53941, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.4911 - accuracy: 0.8289 - val_loss: 3.2243 - val_accuracy: 0.4163\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.53941\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.4425 - accuracy: 0.8490 - val_loss: 1.2109 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.53941 to 0.72167, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.3778 - accuracy: 0.8812 - val_loss: 0.9914 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.72167\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.3500 - accuracy: 0.8703 - val_loss: 0.9817 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.72167 to 0.74384, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.3210 - accuracy: 0.8898 - val_loss: 1.0486 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.74384\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.3132 - accuracy: 0.8904 - val_loss: 0.6432 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.74384 to 0.79310, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.2750 - accuracy: 0.9062 - val_loss: 0.5420 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.79310 to 0.82020, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.2845 - accuracy: 0.8952 - val_loss: 1.1970 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.82020\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.2711 - accuracy: 0.9038 - val_loss: 3.0084 - val_accuracy: 0.4507\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.82020\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 39s 757ms/step - loss: 0.3139 - accuracy: 0.8922 - val_loss: 0.6005 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.82020\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.2283 - accuracy: 0.9257 - val_loss: 1.9156 - val_accuracy: 0.5788\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.82020\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.2789 - accuracy: 0.8989 - val_loss: 1.3675 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.82020\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.2715 - accuracy: 0.9068 - val_loss: 1.0379 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.82020\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.2427 - accuracy: 0.9147 - val_loss: 0.7682 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.82020\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.2087 - accuracy: 0.9245 - val_loss: 0.7039 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.82020\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.2310 - accuracy: 0.9208 - val_loss: 0.5581 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.82020 to 0.84729, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.1654 - accuracy: 0.9421 - val_loss: 0.6641 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.84729\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.1812 - accuracy: 0.9312 - val_loss: 0.6151 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.84729\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.1870 - accuracy: 0.9373 - val_loss: 0.6207 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.84729\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.1609 - accuracy: 0.9470 - val_loss: 0.4727 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.84729 to 0.85714, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.1207 - accuracy: 0.9592 - val_loss: 0.3205 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.85714 to 0.89163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.1603 - accuracy: 0.9519 - val_loss: 0.5361 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.89163\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.1788 - accuracy: 0.9428 - val_loss: 0.8461 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.89163\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.1601 - accuracy: 0.9452 - val_loss: 0.6228 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.89163\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.1269 - accuracy: 0.9616 - val_loss: 0.5017 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.89163\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.1124 - accuracy: 0.9610 - val_loss: 0.6854 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.89163\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.1460 - accuracy: 0.9476 - val_loss: 0.8724 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.89163\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.1269 - accuracy: 0.9549 - val_loss: 0.6226 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.89163\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.1109 - accuracy: 0.9629 - val_loss: 0.5565 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.89163\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0982 - accuracy: 0.9665 - val_loss: 0.6714 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.89163\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.1497 - accuracy: 0.9476 - val_loss: 0.9835 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.89163\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.1416 - accuracy: 0.9495 - val_loss: 0.9609 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.89163\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.1067 - accuracy: 0.9604 - val_loss: 0.4505 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89163\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0944 - accuracy: 0.9641 - val_loss: 0.4063 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.89163 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.1045 - accuracy: 0.9671 - val_loss: 0.4408 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.90148\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 39s 760ms/step - loss: 0.0972 - accuracy: 0.9659 - val_loss: 0.6239 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.90148\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.1088 - accuracy: 0.9635 - val_loss: 0.9005 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.90148\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.1091 - accuracy: 0.9665 - val_loss: 0.8672 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.90148\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.2260 - accuracy: 0.9190 - val_loss: 0.7141 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.90148\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.1212 - accuracy: 0.9555 - val_loss: 0.6478 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.90148\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0726 - accuracy: 0.9762 - val_loss: 0.4877 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.90148\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0592 - accuracy: 0.9866 - val_loss: 0.4425 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.90148\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0774 - accuracy: 0.9750 - val_loss: 0.5823 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.90148\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0704 - accuracy: 0.9756 - val_loss: 0.7480 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.90148\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0663 - accuracy: 0.9775 - val_loss: 0.4596 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.90148\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0801 - accuracy: 0.9708 - val_loss: 0.6846 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.90148\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0562 - accuracy: 0.9775 - val_loss: 0.5018 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.90148\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0975 - accuracy: 0.9665 - val_loss: 0.7531 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.90148\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0934 - accuracy: 0.9708 - val_loss: 0.6185 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.90148\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0777 - accuracy: 0.9720 - val_loss: 0.7773 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.90148\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.1263 - accuracy: 0.9604 - val_loss: 0.5241 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.90148\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0739 - accuracy: 0.9744 - val_loss: 0.5071 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.90148\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0792 - accuracy: 0.9702 - val_loss: 0.6162 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.90148\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.1033 - accuracy: 0.9653 - val_loss: 0.5724 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.90148\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0808 - accuracy: 0.9738 - val_loss: 0.6511 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.90148\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0703 - accuracy: 0.9756 - val_loss: 0.4405 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.90148\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0543 - accuracy: 0.9836 - val_loss: 0.4766 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.90148\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0344 - accuracy: 0.9872 - val_loss: 0.4983 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.90148\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 0.3808 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.90148\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0158 - accuracy: 0.9970 - val_loss: 0.7940 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.90148\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0445 - accuracy: 0.9854 - val_loss: 0.4957 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.90148\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.1671 - accuracy: 0.9488 - val_loss: 10.0796 - val_accuracy: 0.2759\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.90148\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.1440 - accuracy: 0.9513 - val_loss: 1.0793 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.90148\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.1212 - accuracy: 0.9629 - val_loss: 0.5776 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90148\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0613 - accuracy: 0.9787 - val_loss: 0.4286 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.90148\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 0.5247 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.90148\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0384 - accuracy: 0.9878 - val_loss: 0.5306 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.90148\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0425 - accuracy: 0.9866 - val_loss: 0.8403 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.90148\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.4650 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.90148\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.4633 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.90148\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 0.4148 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.90148\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0485 - accuracy: 0.9823 - val_loss: 0.5791 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.90148\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0679 - accuracy: 0.9823 - val_loss: 0.7246 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.90148\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0662 - accuracy: 0.9744 - val_loss: 0.6624 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.90148\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0683 - accuracy: 0.9708 - val_loss: 0.6353 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.90148\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0501 - accuracy: 0.9842 - val_loss: 0.4414 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.90148\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0455 - accuracy: 0.9829 - val_loss: 0.7819 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.90148\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0527 - accuracy: 0.9836 - val_loss: 0.6826 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.90148\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0522 - accuracy: 0.9829 - val_loss: 0.8438 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.90148\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0815 - accuracy: 0.9738 - val_loss: 1.0607 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.90148\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0422 - accuracy: 0.9884 - val_loss: 0.7239 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.90148\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0641 - accuracy: 0.9793 - val_loss: 0.7924 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.90148\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0599 - accuracy: 0.9817 - val_loss: 0.7065 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.90148\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0327 - accuracy: 0.9878 - val_loss: 0.5378 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.90148\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.4869 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.90148\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0351 - accuracy: 0.9909 - val_loss: 0.6179 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.90148\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 0.6259 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.90148\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.6337 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.90148\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0425 - accuracy: 0.9866 - val_loss: 0.5061 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.90148\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0664 - accuracy: 0.9817 - val_loss: 0.7763 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.90148\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.1239 - accuracy: 0.9610 - val_loss: 1.4210 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.90148\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.1096 - accuracy: 0.9659 - val_loss: 1.3078 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.90148\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0676 - accuracy: 0.9781 - val_loss: 0.6631 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.90148\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0366 - accuracy: 0.9860 - val_loss: 0.5584 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.90148\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0354 - accuracy: 0.9872 - val_loss: 0.4859 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.90148\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0405 - accuracy: 0.9848 - val_loss: 0.9321 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.90148\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0291 - accuracy: 0.9909 - val_loss: 0.5435 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.90148\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.5254 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.90148\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.4068 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00108: val_accuracy improved from 0.90148 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 0.3821 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91626\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0866 - accuracy: 0.9769 - val_loss: 1.2501 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91626\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0476 - accuracy: 0.9872 - val_loss: 0.5845 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91626\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 0.6607 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91626\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0581 - accuracy: 0.9805 - val_loss: 0.6009 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91626\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0520 - accuracy: 0.9817 - val_loss: 0.7743 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91626\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 0.7436 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91626\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.5809 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91626\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.6809 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91626\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.3874 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91626\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.4882 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91626\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.4602 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91626\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0401 - accuracy: 0.9903 - val_loss: 0.6247 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91626\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0827 - accuracy: 0.9714 - val_loss: 1.4031 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91626\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0665 - accuracy: 0.9781 - val_loss: 0.6629 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91626\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0407 - accuracy: 0.9836 - val_loss: 0.6001 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91626\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0335 - accuracy: 0.9896 - val_loss: 0.7751 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91626\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0273 - accuracy: 0.9878 - val_loss: 0.5623 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91626\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0411 - accuracy: 0.9878 - val_loss: 0.8351 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91626\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0623 - accuracy: 0.9793 - val_loss: 0.5668 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91626\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0724 - accuracy: 0.9775 - val_loss: 0.4336 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91626\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0373 - accuracy: 0.9848 - val_loss: 0.6126 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91626\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 39s 758ms/step - loss: 0.0196 - accuracy: 0.9951 - val_loss: 0.4443 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91626\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.4007 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91626\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.3706 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91626\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.3217 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00134: val_accuracy improved from 0.91626 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.4415 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.92611\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0262 - accuracy: 0.9903 - val_loss: 0.5908 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.92611\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0432 - accuracy: 0.9842 - val_loss: 0.6722 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.92611\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.6077 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.92611\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 39s 754ms/step - loss: 0.0165 - accuracy: 0.9927 - val_loss: 0.6535 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.92611\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.7545 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.92611\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0527 - accuracy: 0.9805 - val_loss: 1.6531 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.92611\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 39s 754ms/step - loss: 0.1333 - accuracy: 0.9635 - val_loss: 0.8632 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.92611\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0466 - accuracy: 0.9836 - val_loss: 0.7390 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.92611\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0357 - accuracy: 0.9896 - val_loss: 0.7714 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.92611\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.5402 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.92611\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 39s 754ms/step - loss: 0.0144 - accuracy: 0.9933 - val_loss: 0.5050 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.92611\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.8237 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.92611\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.8191 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.92611\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 39s 754ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.5242 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.92611\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 39s 755ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.4357 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.92611\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0530 - accuracy: 0.9866 - val_loss: 1.2755 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.92611\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 39s 754ms/step - loss: 0.0437 - accuracy: 0.9836 - val_loss: 0.5839 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.92611\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 39s 754ms/step - loss: 0.0570 - accuracy: 0.9823 - val_loss: 0.7088 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.92611\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0697 - accuracy: 0.9799 - val_loss: 0.7199 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92611\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0275 - accuracy: 0.9896 - val_loss: 0.8139 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92611\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0185 - accuracy: 0.9927 - val_loss: 0.6752 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92611\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0113 - accuracy: 0.9988 - val_loss: 0.7746 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92611\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 39s 754ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4147 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92611\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.5016 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92611\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4064 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92611\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.3773 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92611\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4140 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92611\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4761 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92611\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 39s 754ms/step - loss: 0.0161 - accuracy: 0.9970 - val_loss: 0.6700 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92611\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.7417 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92611\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 39s 754ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.5409 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92611\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0284 - accuracy: 0.9939 - val_loss: 0.8412 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92611\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 0.7663 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92611\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0368 - accuracy: 0.9878 - val_loss: 1.1228 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92611\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0384 - accuracy: 0.9884 - val_loss: 0.6418 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92611\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0373 - accuracy: 0.9872 - val_loss: 0.7119 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92611\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0329 - accuracy: 0.9909 - val_loss: 0.7742 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92611\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.5807 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92611\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 0.6139 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92611\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0706 - accuracy: 0.9756 - val_loss: 0.9494 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92611\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0471 - accuracy: 0.9842 - val_loss: 0.7296 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92611\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.4879 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92611\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4785 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92611\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.4248 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92611\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4395 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92611\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.4301 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92611\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4105 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92611\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92611\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3483 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92611\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92611\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0238 - accuracy: 0.9951 - val_loss: 0.4368 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92611\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0376 - accuracy: 0.9872 - val_loss: 0.9078 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92611\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.7115 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92611\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0153 - accuracy: 0.9927 - val_loss: 0.6755 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92611\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0263 - accuracy: 0.9896 - val_loss: 0.7886 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92611\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.5072 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92611\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0225 - accuracy: 0.9915 - val_loss: 0.6118 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92611\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.6594 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92611\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.6860 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92611\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0709 - accuracy: 0.9799 - val_loss: 2.2429 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92611\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.7399 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92611\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0274 - accuracy: 0.9878 - val_loss: 0.5820 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92611\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.5396 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92611\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4847 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92611\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5527 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92611\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.5773 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92611\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.5774 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92611\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.5230 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92611\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 0.7252 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92611\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0224 - accuracy: 0.9903 - val_loss: 0.8865 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92611\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0425 - accuracy: 0.9854 - val_loss: 0.7567 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92611\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.5892 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92611\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0247 - accuracy: 0.9939 - val_loss: 0.5616 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92611\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.4335 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00209: val_accuracy improved from 0.92611 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.6231 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92857\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.5150 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92857\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4203 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92857\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0470 - accuracy: 0.9890 - val_loss: 1.0231 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92857\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0782 - accuracy: 0.9769 - val_loss: 0.8728 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92857\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0509 - accuracy: 0.9799 - val_loss: 0.9551 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92857\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0344 - accuracy: 0.9903 - val_loss: 0.6192 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.92857\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.5138 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92857\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.4933 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92857\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.4241 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92857\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.5083 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92857\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4198 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.92857\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.3985 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.92857\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0027 - accuracy: 0.9982 - val_loss: 0.4328 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.92857\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.3736 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.92857\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0101 - accuracy: 0.9957 - val_loss: 0.5035 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.92857\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.5029 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.92857\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.5574 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92857\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0523 - accuracy: 0.9829 - val_loss: 1.0158 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92857\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0228 - accuracy: 0.9939 - val_loss: 0.8976 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92857\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.5763 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92857\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0076 - accuracy: 0.9957 - val_loss: 0.5896 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92857\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.6202 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92857\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.7187 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92857\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.6670 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92857\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0081 - accuracy: 0.9988 - val_loss: 0.5463 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92857\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92857\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5443 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92857\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 0.7266 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92857\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0162 - accuracy: 0.9921 - val_loss: 0.6302 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92857\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.5125 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92857\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.7602 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.92857\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0228 - accuracy: 0.9939 - val_loss: 0.5942 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.92857\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0151 - accuracy: 0.9933 - val_loss: 0.5700 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.92857\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0439 - accuracy: 0.9896 - val_loss: 0.8234 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.92857\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.5860 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.92857\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.7807 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.92857\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0622 - accuracy: 0.9762 - val_loss: 1.4651 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.92857\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0452 - accuracy: 0.9842 - val_loss: 0.6134 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.92857\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0402 - accuracy: 0.9860 - val_loss: 0.8672 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.92857\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.6124 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.92857\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0171 - accuracy: 0.9957 - val_loss: 0.4928 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.92857\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4594 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92857\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.92857\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4341 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.92857\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4664 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.92857\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0173 - accuracy: 0.9933 - val_loss: 0.6195 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.92857\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0198 - accuracy: 0.9927 - val_loss: 0.4884 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.92857\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.5994 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.92857\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 0.8856 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.92857\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0618 - accuracy: 0.9805 - val_loss: 1.1570 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.92857\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0323 - accuracy: 0.9872 - val_loss: 0.6291 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.92857\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.6039 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.92857\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.5005 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.92857\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.3648 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.92857\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3992 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.92857\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.92857\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.5283 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.92857\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4554 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.92857\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 9.5484e-04 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.92857\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4577 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.92857\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4195 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.92857\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4995 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.92857\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4481 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.92857\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 39s 756ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.92857\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.92857\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 4.4755e-04 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.92857\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 5.9677e-04 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.92857\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 3.0390e-04 - accuracy: 1.0000 - val_loss: 0.4063 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.92857\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 4.8615e-04 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00279: val_accuracy improved from 0.92857 to 0.94089, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 39s 754ms/step - loss: 5.6144e-04 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.94089\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 3.8217e-04 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.94089\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 1.8943e-04 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.94089\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 2.3502e-04 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.94089\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 3.9791e-04 - accuracy: 1.0000 - val_loss: 0.4259 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.94089\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 2.3439e-04 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.94089\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 3.8876e-04 - accuracy: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.94089\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 39s 754ms/step - loss: 2.1757e-04 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.94089\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 2.0406e-04 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.94089\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2846 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.94089\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0692 - accuracy: 0.9787 - val_loss: 1.5652 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.94089\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.1498 - accuracy: 0.9513 - val_loss: 2.2888 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.94089\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0611 - accuracy: 0.9750 - val_loss: 0.9839 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.94089\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0328 - accuracy: 0.9878 - val_loss: 0.8913 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.94089\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.6730 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.94089\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5725 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.94089\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3815 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.94089\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4473 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.94089\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4549 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.94089\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4126 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.94089\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.5466 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.94089\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4824 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.94089\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4765 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.94089\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4592 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.94089\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.5538 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.94089\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5336 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.94089\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5209 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.94089\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 39s 745ms/step - loss: 7.1081e-04 - accuracy: 1.0000 - val_loss: 0.5257 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.94089\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 6.5432e-04 - accuracy: 1.0000 - val_loss: 0.5422 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.94089\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 8.1115e-04 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.94089\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.94089\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.6937 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.94089\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 39s 745ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5704 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.94089\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5162 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.94089\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0046 - accuracy: 0.9976 - val_loss: 0.6744 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.94089\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 39s 745ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.6062 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.94089\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.5876 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.94089\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0478 - accuracy: 0.9860 - val_loss: 1.1051 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.94089\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0437 - accuracy: 0.9872 - val_loss: 1.0182 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.94089\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0686 - accuracy: 0.9787 - val_loss: 0.7641 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.94089\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0604 - accuracy: 0.9836 - val_loss: 1.0527 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.94089\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.5796 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.94089\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.4881 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.94089\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.4854 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.94089\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.5882 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.94089\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5105 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.94089\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.94089\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.4717 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.94089\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.6505 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.94089\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0079 - accuracy: 0.9963 - val_loss: 0.5345 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.94089\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.5994 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.94089\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.94089\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5714 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.94089\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5102 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.94089\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.5173 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.94089\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.94089\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5048 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.94089\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 6.5589e-04 - accuracy: 1.0000 - val_loss: 0.4784 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.94089\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5317 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.94089\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 2.4279e-04 - accuracy: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.94089\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 4.7168e-04 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.94089\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 3.6713e-04 - accuracy: 1.0000 - val_loss: 0.5288 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.94089\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 1.9880e-04 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.94089\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 9.5540e-04 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.94089\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 2.8327e-04 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.94089\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 39s 756ms/step - loss: 3.8695e-04 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.94089\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 1.7132e-04 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.94089\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0567 - accuracy: 0.9890 - val_loss: 2.1023 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.94089\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.1179 - accuracy: 0.9683 - val_loss: 1.3971 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.94089\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0598 - accuracy: 0.9787 - val_loss: 0.9850 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.94089\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.9365 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.94089\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.7565 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.94089\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.6270 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.94089\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.6433 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.94089\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 39s 759ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.94089\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5163 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.94089\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.5327 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.94089\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5423 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.94089\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.94089\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.5156 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.94089\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4747 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.94089\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.94089\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 6.0756e-04 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.94089\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4697 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.94089\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 5.6921e-04 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.94089\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5154 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.94089\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 7.8364e-04 - accuracy: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.94089\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 7.8740e-04 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.94089\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5937 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.94089\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 39s 757ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4836 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.94089\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 5.6672e-04 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.94089\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 5.8184e-04 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.94089\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 2.7704e-04 - accuracy: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.94089\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 1.9898e-04 - accuracy: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.94089\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 3.7030e-04 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.94089\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 4.9957e-04 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.94089\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 1.0461e-04 - accuracy: 1.0000 - val_loss: 0.4610 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.94089\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 2.8276e-04 - accuracy: 1.0000 - val_loss: 0.5156 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.94089\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 2.2086e-04 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.94089\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 6.7028e-04 - accuracy: 0.9994 - val_loss: 0.4434 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.94089\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.7216 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.94089\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 1.0729 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.94089\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0573 - accuracy: 0.9842 - val_loss: 1.1580 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.94089\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0573 - accuracy: 0.9829 - val_loss: 1.5366 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.94089\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0413 - accuracy: 0.9823 - val_loss: 0.6985 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.94089\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0147 - accuracy: 0.9939 - val_loss: 0.5618 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.94089\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0153 - accuracy: 0.9933 - val_loss: 0.6241 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94089\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0189 - accuracy: 0.9921 - val_loss: 0.4994 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94089\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.5436 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94089\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94089\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4839 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94089\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.5202 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94089\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4495 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94089\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 39s 758ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.5591 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94089\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4719 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94089\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0533 - accuracy: 0.9890 - val_loss: 0.5513 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94089\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 39s 759ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.5512 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94089\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.5039 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94089\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4071 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94089\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4230 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.94089\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 7.1295e-04 - accuracy: 1.0000 - val_loss: 0.3811 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94089\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.3906 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94089\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94089\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94089\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.3873 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94089\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 7.8169e-04 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94089\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 3.5226e-04 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94089\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4560 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94089\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0062 - accuracy: 0.9970 - val_loss: 0.5743 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94089\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4097 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94089\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5137 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94089\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.4640 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94089\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5162 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94089\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.6813 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94089\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 39s 759ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.8490 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94089\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 1.8946 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94089\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 1.2181 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94089\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0134 - accuracy: 0.9945 - val_loss: 0.7973 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94089\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.6678 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94089\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 9.8953e-04 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94089\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 7.4797e-04 - accuracy: 1.0000 - val_loss: 0.5124 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94089\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 1.0453 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94089\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 1.0167 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94089\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0511 - accuracy: 0.9866 - val_loss: 12.8953 - val_accuracy: 0.2340\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94089\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 0.7466 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94089\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.5956 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94089\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.6029 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94089\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.6066 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94089\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4360 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94089\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.3837 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94089\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94089\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94089\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5109 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94089\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.5602 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94089\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 5.2029e-04 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94089\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 7.1769e-04 - accuracy: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94089\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 3.0516e-04 - accuracy: 1.0000 - val_loss: 0.5377 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94089\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 8.6605e-04 - accuracy: 0.9994 - val_loss: 0.5780 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94089\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 9.1699e-04 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94089\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 5.8572e-04 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94089\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 3.3781e-04 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94089\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 2.0834e-04 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94089\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 1.8925e-04 - accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94089\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 1.3350e-04 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94089\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 3.3439e-04 - accuracy: 1.0000 - val_loss: 0.3930 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94089\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 9.0491e-05 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94089\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 3.2689e-04 - accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94089\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 5.8717e-04 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94089\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 7.6719e-04 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94089\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.6508 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94089\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 0.7940 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94089\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0205 - accuracy: 0.9927 - val_loss: 1.8882 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94089\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 39s 749ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 1.7912 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94089\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 39s 748ms/step - loss: 0.0161 - accuracy: 0.9970 - val_loss: 1.1264 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94089\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0461 - accuracy: 0.9860 - val_loss: 0.7360 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94089\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.4979 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94089\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.5171 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94089\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5275 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94089\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 39s 754ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94089\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94089\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 9.8999e-04 - accuracy: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94089\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94089\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 3.3507e-04 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94089\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 4.1466e-04 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94089\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 7.2678e-04 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94089\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 4.4121e-04 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94089\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 3.9164e-04 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94089\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 4.5343e-04 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94089\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 3.2556e-04 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94089\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 3.6969e-04 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94089\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 5.0690e-04 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94089\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.4562 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94089\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6109 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94089\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94089\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94089\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 9.0070e-04 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94089\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 4.2400e-04 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94089\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.5674 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94089\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 7.1388e-04 - accuracy: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94089\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0067 - accuracy: 0.9963 - val_loss: 1.0941 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94089\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0873 - accuracy: 0.9732 - val_loss: 2.1374 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94089\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0491 - accuracy: 0.9817 - val_loss: 1.0646 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94089\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 39s 746ms/step - loss: 0.0193 - accuracy: 0.9927 - val_loss: 0.7241 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94089\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.5484 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94089\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.6273 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94089\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.6099 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94089\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0096 - accuracy: 0.9957 - val_loss: 0.6367 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94089\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.6664 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94089\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.7884 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94089\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0177 - accuracy: 0.9970 - val_loss: 0.9314 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94089\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 39s 747ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.5841 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94089\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4978 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94089\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5111 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94089\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 39s 752ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.4946 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94089\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5466 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94089\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0059 - accuracy: 0.9970 - val_loss: 0.8562 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94089\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.6992 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94089\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 39s 753ms/step - loss: 0.0357 - accuracy: 0.9939 - val_loss: 1.1497 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94089\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 39s 750ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.6299 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94089\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.5995 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94089\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 39s 751ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.9246 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94089\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b616d93d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "99399c4c-e5b5-4716-d27d-133720b8a31f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_1_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c13c576d-8fc3-474e-cab5-c56914f4a3ed"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35ddd03-905b-4d89-9814-7b4493cacb2b"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b810c0f9-dfbb-4d16-b0f2-4d4c2c33c879"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "45fd527b-7122-4c42-d7c3-b0d2d5ce0924"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_224_1_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_224_1_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_aaeef6a5-11cc-4b7a-835f-79f20761a1d4\", \"ImageSize_224_1_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}