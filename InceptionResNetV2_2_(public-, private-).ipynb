{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionResNetV2_2_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/InceptionResNetV2_2_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0059ce2b-e2b2-4304-a872-340c9fa1915d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "InceptionResNetV2_model =  tf.keras.applications.InceptionResNetV2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "InceptionResNetV2_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0943f5a5-4756-4d0c-baec-db6c5c2e61a8"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_2.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eadd82df-4cff-44c7-a811-bd185d73d507"
      },
      "source": [
        "InceptionResNetV2_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 89s 229ms/step - loss: 1.7978 - accuracy: 0.4026 - val_loss: 5.1174 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_2.h5\n",
            "Epoch 2/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 1.1496 - accuracy: 0.6221 - val_loss: 6.5941 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10135\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.9369 - accuracy: 0.6853 - val_loss: 0.8605 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.10135 to 0.74324, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_2.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.7502 - accuracy: 0.7532 - val_loss: 0.7606 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.74324 to 0.79054, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_2.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.6523 - accuracy: 0.7905 - val_loss: 1.2269 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.79054\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.5637 - accuracy: 0.8179 - val_loss: 1.6600 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.79054\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.5619 - accuracy: 0.8132 - val_loss: 0.4761 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.79054 to 0.83784, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_2.h5\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.4875 - accuracy: 0.8442 - val_loss: 0.8443 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.83784\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.4544 - accuracy: 0.8489 - val_loss: 0.9257 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.83784\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.3839 - accuracy: 0.8747 - val_loss: 0.6514 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.83784\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.3530 - accuracy: 0.8837 - val_loss: 0.6286 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.83784\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.4114 - accuracy: 0.8642 - val_loss: 1.5858 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.83784\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.3387 - accuracy: 0.8911 - val_loss: 0.7874 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.83784\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.3107 - accuracy: 0.9032 - val_loss: 0.7448 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.83784\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.2986 - accuracy: 0.9016 - val_loss: 0.6238 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.83784\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.2871 - accuracy: 0.9021 - val_loss: 0.4373 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.83784 to 0.85135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_2.h5\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.2813 - accuracy: 0.9084 - val_loss: 0.4482 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.85135\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.2548 - accuracy: 0.9205 - val_loss: 0.8082 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.85135\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.2471 - accuracy: 0.9184 - val_loss: 0.4386 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.85135 to 0.88514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_2.h5\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.1993 - accuracy: 0.9358 - val_loss: 0.3231 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.88514 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_2.h5\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.2512 - accuracy: 0.9189 - val_loss: 0.8189 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.90541\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.2279 - accuracy: 0.9253 - val_loss: 0.4043 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.90541\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.2096 - accuracy: 0.9258 - val_loss: 0.3101 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.90541\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.2155 - accuracy: 0.9311 - val_loss: 0.7941 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.90541\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.1872 - accuracy: 0.9395 - val_loss: 0.4023 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.90541\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.1950 - accuracy: 0.9332 - val_loss: 0.5925 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.90541\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.1735 - accuracy: 0.9426 - val_loss: 0.4831 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.90541\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.1321 - accuracy: 0.9579 - val_loss: 0.3224 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.90541\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.1644 - accuracy: 0.9468 - val_loss: 0.7197 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.90541\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.1953 - accuracy: 0.9374 - val_loss: 0.4994 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.90541\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.1238 - accuracy: 0.9611 - val_loss: 0.4342 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.90541\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.1657 - accuracy: 0.9468 - val_loss: 0.7968 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.90541\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.1801 - accuracy: 0.9447 - val_loss: 0.6646 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.90541\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.0973 - accuracy: 0.9674 - val_loss: 0.4937 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.90541\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.1281 - accuracy: 0.9574 - val_loss: 0.4825 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.90541\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.1467 - accuracy: 0.9526 - val_loss: 0.4815 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.90541\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.1344 - accuracy: 0.9579 - val_loss: 0.5031 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.90541\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0791 - accuracy: 0.9726 - val_loss: 0.8311 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.90541\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.1666 - accuracy: 0.9505 - val_loss: 0.3633 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.90541\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.1227 - accuracy: 0.9611 - val_loss: 1.0655 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.90541\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0934 - accuracy: 0.9642 - val_loss: 0.4984 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.90541\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.1412 - accuracy: 0.9563 - val_loss: 0.5432 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.90541\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0875 - accuracy: 0.9663 - val_loss: 0.6633 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.90541\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.0847 - accuracy: 0.9700 - val_loss: 0.5214 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.90541\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.0842 - accuracy: 0.9779 - val_loss: 0.6646 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.90541\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0950 - accuracy: 0.9705 - val_loss: 0.4092 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.90541\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 51s 212ms/step - loss: 0.0852 - accuracy: 0.9721 - val_loss: 0.5165 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.90541\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0856 - accuracy: 0.9774 - val_loss: 0.3845 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.90541 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_2.h5\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0527 - accuracy: 0.9816 - val_loss: 0.5990 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91892\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.0922 - accuracy: 0.9695 - val_loss: 0.9518 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91892\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.1469 - accuracy: 0.9558 - val_loss: 0.5902 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91892\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0705 - accuracy: 0.9774 - val_loss: 0.4125 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91892\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0536 - accuracy: 0.9832 - val_loss: 0.4385 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91892\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0859 - accuracy: 0.9684 - val_loss: 0.4683 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91892\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0266 - accuracy: 0.9900 - val_loss: 0.4036 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91892\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0705 - accuracy: 0.9721 - val_loss: 0.5595 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91892\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.0854 - accuracy: 0.9747 - val_loss: 0.6984 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91892\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0873 - accuracy: 0.9711 - val_loss: 1.0879 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91892\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0625 - accuracy: 0.9832 - val_loss: 0.6067 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91892\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0614 - accuracy: 0.9763 - val_loss: 0.4417 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91892\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0871 - accuracy: 0.9732 - val_loss: 0.8326 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91892\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0811 - accuracy: 0.9742 - val_loss: 0.5453 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91892\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0818 - accuracy: 0.9758 - val_loss: 0.3377 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91892\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 0.5416 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91892\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.0446 - accuracy: 0.9884 - val_loss: 0.4451 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91892\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.6923 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91892\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0436 - accuracy: 0.9879 - val_loss: 0.4755 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91892\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0594 - accuracy: 0.9821 - val_loss: 0.4608 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91892\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.4413 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91892\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 0.8462 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91892\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.1043 - accuracy: 0.9695 - val_loss: 0.7490 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91892\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0607 - accuracy: 0.9800 - val_loss: 0.5621 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91892\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0470 - accuracy: 0.9826 - val_loss: 0.5102 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91892\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0723 - accuracy: 0.9758 - val_loss: 0.4893 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91892\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0399 - accuracy: 0.9863 - val_loss: 0.3775 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91892\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0551 - accuracy: 0.9816 - val_loss: 0.2961 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.91892 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_2.h5\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 53s 222ms/step - loss: 0.0473 - accuracy: 0.9874 - val_loss: 0.6684 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.92568\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0654 - accuracy: 0.9779 - val_loss: 0.4422 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.92568\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0440 - accuracy: 0.9879 - val_loss: 0.7067 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.92568\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0648 - accuracy: 0.9811 - val_loss: 0.5384 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.92568\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0366 - accuracy: 0.9847 - val_loss: 0.4777 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.92568\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0450 - accuracy: 0.9868 - val_loss: 0.3093 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.92568 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_2.h5\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0483 - accuracy: 0.9847 - val_loss: 0.6511 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.95270\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0754 - accuracy: 0.9747 - val_loss: 0.4768 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.95270\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.3570 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.95270\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.5201 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.95270\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0646 - accuracy: 0.9774 - val_loss: 0.3921 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.95270\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0251 - accuracy: 0.9905 - val_loss: 0.5295 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.95270\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.5669 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.95270\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0336 - accuracy: 0.9889 - val_loss: 0.4106 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.95270\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0415 - accuracy: 0.9879 - val_loss: 0.4529 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.95270\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0625 - accuracy: 0.9842 - val_loss: 0.6009 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.95270\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0382 - accuracy: 0.9900 - val_loss: 0.2941 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.95270\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0435 - accuracy: 0.9837 - val_loss: 0.8163 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.95270\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 0.4031 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.95270\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 0.5634 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.95270\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0687 - accuracy: 0.9789 - val_loss: 0.7469 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.95270\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0204 - accuracy: 0.9900 - val_loss: 0.6014 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.95270\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.3817 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.95270\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0231 - accuracy: 0.9905 - val_loss: 0.6399 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.95270\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.0770 - accuracy: 0.9795 - val_loss: 0.7513 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.95270\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.0559 - accuracy: 0.9832 - val_loss: 0.7132 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.95270\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0325 - accuracy: 0.9911 - val_loss: 0.3136 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.95270\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0400 - accuracy: 0.9895 - val_loss: 0.4237 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.95270\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0738 - accuracy: 0.9774 - val_loss: 0.5326 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.95270\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.4609 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.95270\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0389 - accuracy: 0.9884 - val_loss: 0.3698 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.95270\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.4691 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.95270\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.5448 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.95270\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0354 - accuracy: 0.9900 - val_loss: 0.4575 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.95270\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0424 - accuracy: 0.9853 - val_loss: 0.4903 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.95270\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0480 - accuracy: 0.9821 - val_loss: 0.3766 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.95270\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.4641 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.95270\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0113 - accuracy: 0.9984 - val_loss: 0.4971 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.95270\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.4954 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.95270\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0338 - accuracy: 0.9916 - val_loss: 0.6675 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.95270\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0437 - accuracy: 0.9874 - val_loss: 0.3706 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.95270\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0372 - accuracy: 0.9895 - val_loss: 0.5010 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.95270\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 0.5606 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.95270\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.3875 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.95270\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 51s 213ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.6571 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.95270\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0680 - accuracy: 0.9821 - val_loss: 1.0720 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.95270\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0327 - accuracy: 0.9895 - val_loss: 0.6181 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.95270\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.5046 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.95270\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.4441 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.95270\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 0.3650 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.95270\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0203 - accuracy: 0.9958 - val_loss: 0.7024 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.95270\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0518 - accuracy: 0.9826 - val_loss: 0.4358 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.95270\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0383 - accuracy: 0.9879 - val_loss: 0.4994 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.95270\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 53s 222ms/step - loss: 0.0491 - accuracy: 0.9868 - val_loss: 0.4954 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.95270\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.7409 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.95270\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.5581 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.95270\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 0.4119 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.95270\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.6408 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.95270\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 0.6148 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.95270\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.4898 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.95270\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.7019 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.95270\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0492 - accuracy: 0.9842 - val_loss: 0.4556 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.95270\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0355 - accuracy: 0.9895 - val_loss: 0.7385 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.95270\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.5850 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.95270\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0282 - accuracy: 0.9895 - val_loss: 0.4648 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.95270\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0150 - accuracy: 0.9932 - val_loss: 0.4499 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.95270\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.5549 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.95270\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0116 - accuracy: 0.9947 - val_loss: 0.4958 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.95270\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0309 - accuracy: 0.9947 - val_loss: 0.3940 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.95270\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.5523 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.95270\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0338 - accuracy: 0.9905 - val_loss: 0.7422 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.95270\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.4788 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.95270\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.6038 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.95270\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0409 - accuracy: 0.9868 - val_loss: 0.8111 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.95270\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0528 - accuracy: 0.9847 - val_loss: 0.3233 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.95270\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0319 - accuracy: 0.9911 - val_loss: 0.5908 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.95270\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5148 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.95270\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.3891 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.95270\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.4878 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.95270\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.4014 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.95270\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.3874 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.95270\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 1.0289 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.95270\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0691 - accuracy: 0.9821 - val_loss: 0.5642 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.95270\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.6179 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.95270\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.4926 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.95270\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0065 - accuracy: 0.9968 - val_loss: 0.3715 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.95270\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0321 - accuracy: 0.9911 - val_loss: 0.4831 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.95270\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.4188 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.95270\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.2961 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.95270\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0547 - accuracy: 0.9837 - val_loss: 0.6379 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.95270\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0374 - accuracy: 0.9895 - val_loss: 0.5150 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.95270\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 0.5139 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.95270\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.5794 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.95270\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0268 - accuracy: 0.9900 - val_loss: 0.5562 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.95270\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.7219 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.95270\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.4766 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.95270\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 0.0107 - accuracy: 0.9953 - val_loss: 0.5273 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.95270\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.6641 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.95270\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0293 - accuracy: 0.9926 - val_loss: 0.2539 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.95270\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0146 - accuracy: 0.9942 - val_loss: 0.4331 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.95270\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0203 - accuracy: 0.9921 - val_loss: 0.3995 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.95270\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.6183 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.95270\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 0.4044 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.95270\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.4055 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.95270\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.4117 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.95270\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0397 - accuracy: 0.9879 - val_loss: 0.4414 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.95270\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0144 - accuracy: 0.9937 - val_loss: 0.6277 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.95270\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.4860 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.95270\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.7333 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.95270\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0262 - accuracy: 0.9937 - val_loss: 0.5406 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.95270\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0395 - accuracy: 0.9889 - val_loss: 0.3531 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.95270\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0165 - accuracy: 0.9932 - val_loss: 0.5735 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.95270\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.5846 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.95270\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.5995 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.95270\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0453 - accuracy: 0.9874 - val_loss: 0.4385 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.95270\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0265 - accuracy: 0.9926 - val_loss: 0.5059 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.95270\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.3901 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.95270\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.2995 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.95270\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.3501 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.95270\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.1648 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00196: val_accuracy improved from 0.95270 to 0.97297, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_2.h5\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0265 - accuracy: 0.9942 - val_loss: 0.4634 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.97297\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 0.3848 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.97297\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0177 - accuracy: 0.9921 - val_loss: 0.3664 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.97297\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.4326 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.97297\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.4338 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.97297\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.5286 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.97297\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0122 - accuracy: 0.9984 - val_loss: 0.2381 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.97297\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.2329 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.97297\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.4086 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.97297\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3145 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.97297\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.6055 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.97297\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 0.0543 - accuracy: 0.9874 - val_loss: 0.5550 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.97297\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0162 - accuracy: 0.9932 - val_loss: 0.7181 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.97297\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.6764 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.97297\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.4486 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.97297\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.3524 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.97297\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.6127 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.97297\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0264 - accuracy: 0.9905 - val_loss: 0.6588 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.97297\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 53s 223ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.5377 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.97297\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.7691 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.97297\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0360 - accuracy: 0.9879 - val_loss: 0.6937 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.97297\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.5717 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.97297\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0075 - accuracy: 0.9953 - val_loss: 0.4727 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.97297\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.6855 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.97297\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.6930 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.97297\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 53s 223ms/step - loss: 9.1697e-04 - accuracy: 1.0000 - val_loss: 0.6751 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.97297\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.7642 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.97297\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0038 - accuracy: 0.9979 - val_loss: 0.5578 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.97297\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.6591 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.97297\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.5792 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.97297\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 4.1733e-04 - accuracy: 1.0000 - val_loss: 0.6008 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.97297\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0302 - accuracy: 0.9916 - val_loss: 0.7400 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.97297\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0333 - accuracy: 0.9905 - val_loss: 0.5518 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.97297\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0344 - accuracy: 0.9879 - val_loss: 0.5188 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.97297\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.4790 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.97297\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.9457 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.97297\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.6859 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.97297\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 0.5432 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.97297\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.4595 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.97297\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.3839 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.97297\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.4241 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.97297\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.4152 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.97297\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.5027 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.97297\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0083 - accuracy: 0.9953 - val_loss: 0.6788 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.97297\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0165 - accuracy: 0.9932 - val_loss: 0.5796 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.97297\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0213 - accuracy: 0.9958 - val_loss: 0.9217 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.97297\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.4522 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.97297\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.4169 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.97297\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.3532 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.97297\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.5746 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.97297\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0131 - accuracy: 0.9979 - val_loss: 0.6072 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.97297\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.7094 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.97297\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.5500 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.97297\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0250 - accuracy: 0.9942 - val_loss: 0.3757 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.97297\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0191 - accuracy: 0.9921 - val_loss: 0.5102 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.97297\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.4370 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.97297\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.4269 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.97297\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.4248 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.97297\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.3942 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.97297\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.3322 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.97297\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.3953 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.97297\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.5739 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.97297\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0197 - accuracy: 0.9958 - val_loss: 0.5471 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.97297\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0128 - accuracy: 0.9942 - val_loss: 0.9156 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.97297\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.4837 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.97297\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.4632 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.97297\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.3905 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.97297\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.5201 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.97297\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.7770 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.97297\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.6349 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.97297\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0142 - accuracy: 0.9932 - val_loss: 0.5117 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.97297\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.5190 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.97297\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.4958 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.97297\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.4303 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.97297\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0130 - accuracy: 0.9947 - val_loss: 0.6166 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.97297\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.4523 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.97297\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.5260 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.97297\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5547 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.97297\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 0.6873 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.97297\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.6997 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.97297\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.4608 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.97297\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.4220 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.97297\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0071 - accuracy: 0.9963 - val_loss: 0.4607 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.97297\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.4176 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.97297\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.8849 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.97297\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.6196 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.97297\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 8.3375e-04 - accuracy: 1.0000 - val_loss: 0.8135 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.97297\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7491 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.97297\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 1.6764e-04 - accuracy: 1.0000 - val_loss: 0.8647 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.97297\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 1.0506 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.97297\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0314 - accuracy: 0.9937 - val_loss: 0.8961 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.97297\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 54s 225ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.6038 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.97297\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.6931 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.97297\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0267 - accuracy: 0.9895 - val_loss: 1.6465 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.97297\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0417 - accuracy: 0.9900 - val_loss: 0.4068 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.97297\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.4959 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.97297\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.5134 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.97297\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.3794 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.97297\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.5514 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.97297\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 54s 226ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.4676 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.97297\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 6.4198e-04 - accuracy: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.97297\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 1.2131 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.97297\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0427 - accuracy: 0.9879 - val_loss: 0.8467 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.97297\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.5930 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.97297\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.5529 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.97297\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.5181 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.97297\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.5745 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.97297\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.4330 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.97297\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.4991 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.97297\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.4555 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.97297\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.6503 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.97297\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.6247 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.97297\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.5929 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.97297\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.5774 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.97297\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.5379 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.97297\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0037 - accuracy: 0.9979 - val_loss: 0.4103 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.97297\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 3.7205e-04 - accuracy: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.97297\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.5522 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.97297\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.9997 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.97297\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0259 - accuracy: 0.9937 - val_loss: 0.8481 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.97297\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 0.0259 - accuracy: 0.9932 - val_loss: 0.4158 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.97297\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.8045 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.97297\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 53s 222ms/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 0.4195 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.97297\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.3857 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.97297\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4052 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.97297\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 6.9301e-04 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.97297\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 7.4893e-04 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.97297\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 4.9284e-04 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.97297\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 1.4751e-04 - accuracy: 1.0000 - val_loss: 0.3126 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.97297\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 2.4097e-04 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.97297\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0494 - accuracy: 0.9847 - val_loss: 0.6955 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.97297\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.4784 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.97297\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.4052 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.97297\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.4039 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.97297\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0261 - accuracy: 0.9932 - val_loss: 0.3921 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.97297\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.5479 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.97297\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.2727 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.97297\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.3345 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.97297\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 53s 222ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.97297\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.3717 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.97297\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.97297\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 53s 223ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.8941 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.97297\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.4902 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.97297\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.97297\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 53s 223ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.4797 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.97297\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0457 - accuracy: 0.9900 - val_loss: 0.4527 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.97297\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0193 - accuracy: 0.9958 - val_loss: 0.3750 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.97297\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.3318 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.97297\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.4991 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.97297\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.3713 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.97297\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0026 - accuracy: 0.9984 - val_loss: 0.4480 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.97297\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3878 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.97297\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 4.3410e-04 - accuracy: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.97297\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3868 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.97297\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.4544 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.97297\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 0.0241 - accuracy: 0.9953 - val_loss: 0.7267 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.97297\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.8331 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.97297\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.6126 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.97297\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4162 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.97297\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.5951 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.97297\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.8025 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.97297\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0386 - accuracy: 0.9879 - val_loss: 0.7544 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.97297\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.7115 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.97297\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0187 - accuracy: 0.9958 - val_loss: 0.5783 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.97297\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.4541 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.97297\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 53s 223ms/step - loss: 0.0044 - accuracy: 0.9979 - val_loss: 0.3654 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.97297\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4317 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.97297\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5209 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.97297\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.97297\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 9.4813e-04 - accuracy: 0.9995 - val_loss: 0.5132 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.97297\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 5.5839e-04 - accuracy: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.97297\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 3.6267e-04 - accuracy: 1.0000 - val_loss: 0.5263 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.97297\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 3.6469e-04 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.97297\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.8799 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.97297\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0198 - accuracy: 0.9958 - val_loss: 0.5573 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.97297\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.6523 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.97297\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.4656 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.97297\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0202 - accuracy: 0.9953 - val_loss: 0.4188 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.97297\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 0.0228 - accuracy: 0.9947 - val_loss: 0.4642 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.97297\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5389 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.97297\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 7.4690e-04 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.97297\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 3.7691e-04 - accuracy: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.97297\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.6852 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.97297\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 4.7608e-04 - accuracy: 1.0000 - val_loss: 0.6132 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.97297\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 4.3285e-04 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.97297\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5162 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.97297\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0255 - accuracy: 0.9932 - val_loss: 0.8333 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.97297\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0168 - accuracy: 0.9926 - val_loss: 0.5668 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.97297\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 53s 222ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.4542 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.97297\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.4250 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.97297\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 5.3857e-04 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.97297\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 7.3733e-04 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.97297\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 53s 223ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.6577 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.97297\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.9349 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.97297\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0375 - accuracy: 0.9895 - val_loss: 0.6524 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.97297\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.7795 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.97297\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.6382 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.97297\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.6518 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.97297\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.5443 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.97297\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0070 - accuracy: 0.9963 - val_loss: 0.6317 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.97297\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.6527 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.97297\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.0744 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.97297\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0213 - accuracy: 0.9963 - val_loss: 0.5301 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.97297\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.97297\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.6414 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.97297\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.7921 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.97297\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.6963 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.97297\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.7905 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.97297\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.5204 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.97297\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 6.1612e-04 - accuracy: 1.0000 - val_loss: 0.6741 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.97297\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 1.3611 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.97297\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.5748 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.97297\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.5379 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.97297\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.5669 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.97297\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 51s 215ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.97297\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 51s 214ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.4784 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.97297\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.4597 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.97297\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 9.3929e-04 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.97297\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0024 - accuracy: 0.9984 - val_loss: 0.5936 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.97297\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 4.8334e-04 - accuracy: 1.0000 - val_loss: 0.5786 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.97297\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.5681 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.97297\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 53s 222ms/step - loss: 0.0262 - accuracy: 0.9942 - val_loss: 0.7249 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.97297\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5934 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.97297\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.7304 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.97297\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0160 - accuracy: 0.9942 - val_loss: 0.6688 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.97297\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.5251 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.97297\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.6108 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.97297\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0258 - accuracy: 0.9953 - val_loss: 0.7809 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.97297\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 53s 223ms/step - loss: 0.0270 - accuracy: 0.9937 - val_loss: 0.5549 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.97297\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 52s 221ms/step - loss: 0.0169 - accuracy: 0.9963 - val_loss: 0.3322 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.97297\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.3990 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.97297\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 53s 223ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.4107 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.97297\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 9.3921e-04 - accuracy: 0.9995 - val_loss: 0.4598 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.97297\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 7.0794e-04 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.97297\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 8.6363e-04 - accuracy: 0.9995 - val_loss: 0.4505 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.97297\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 51s 216ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.4853 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.97297\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.4367 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.97297\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6374 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.97297\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0105 - accuracy: 0.9953 - val_loss: 0.6154 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.97297\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.7336 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.97297\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.6523 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.97297\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.5413 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.97297\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0236 - accuracy: 0.9947 - val_loss: 0.6462 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.97297\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 53s 222ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.9360 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.97297\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.4066 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.97297\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 8.1426e-04 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.97297\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.4142 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.97297\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0150 - accuracy: 0.9974 - val_loss: 0.5963 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.97297\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.3861 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.97297\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.6473 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.97297\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.6120 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.97297\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 53s 222ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.5556 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.97297\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.5073 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.97297\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 53s 222ms/step - loss: 0.0272 - accuracy: 0.9932 - val_loss: 0.5209 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.97297\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0147 - accuracy: 0.9937 - val_loss: 0.5206 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.97297\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.6578 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.97297\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5654 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.97297\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4642 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.97297\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 2.2251e-04 - accuracy: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.97297\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 53s 222ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.4584 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.97297\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0058 - accuracy: 0.9968 - val_loss: 0.5074 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.97297\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 6.5350e-04 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.97297\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.5438 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.97297\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 3.0073e-04 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.97297\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 2.1401e-04 - accuracy: 1.0000 - val_loss: 0.5477 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.97297\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.5715 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.97297\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0213 - accuracy: 0.9958 - val_loss: 0.5826 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.97297\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.4621 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.97297\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.6035 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.97297\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 53s 223ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.6846 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.97297\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4369 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.97297\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 0.5949 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.97297\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 0.8040 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.97297\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.7086 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.97297\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.6530 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.97297\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.5807 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.97297\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 52s 216ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.6090 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.97297\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.3933 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.97297\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.2736 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.97297\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.3651 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.97297\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 5.5209e-04 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.97297\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4116 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.97297\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 52s 217ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.4525 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.97297\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.5818 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.97297\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.6127 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.97297\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.5279 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.97297\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.6283 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.97297\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.6623 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.97297\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.4595 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.97297\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 0.0034 - accuracy: 0.9974 - val_loss: 0.5704 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.97297\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4960 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.97297\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 53s 224ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.5474 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.97297\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 5.5411e-04 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.97297\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.5704 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.97297\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 53s 222ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.3661 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.97297\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 52s 218ms/step - loss: 7.1102e-04 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.97297\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 52s 220ms/step - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.4598 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.97297\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 54s 225ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.4032 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.97297\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 53s 221ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.5867 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.97297\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 53s 223ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.6213 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.97297\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 53s 222ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.3928 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.97297\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 53s 223ms/step - loss: 2.6414e-04 - accuracy: 1.0000 - val_loss: 0.5840 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.97297\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 53s 222ms/step - loss: 2.8345e-04 - accuracy: 1.0000 - val_loss: 0.5619 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.97297\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 52s 219ms/step - loss: 3.6310e-04 - accuracy: 1.0000 - val_loss: 0.5162 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.97297\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe932f476d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e0bd8ee9-c11e-423c-c095-2b5ed51468ed"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(InceptionResNetV2_model.history.history[\"accuracy\"], label='InceptionResNetV2_acc')\n",
        "plt.plot(InceptionResNetV2_model.history.history[\"val_accuracy\"], label='InceptionResNetV2_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "InceptionResNetV2_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_2.h5', compile=False)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e15f07-f289-4257-eccf-2c938d864ce3"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66325107-a8a4-4849-efb7-742dbb468e38"
      },
      "source": [
        "InceptionResNetV2_predict = InceptionResNetV2_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a88c6e7d-9559-42c1-cf51-72c5d207a451"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')\n",
        "submission.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2049</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2050</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2051</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2052</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2053</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  digit\n",
              "0  2049      0\n",
              "1  2050      0\n",
              "2  2051      0\n",
              "3  2052      0\n",
              "4  2053      0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"InceptionResNetV2_predict\"] = InceptionResNetV2_predict"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['InceptionResNetV2_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "40e83eb5-9556-4311-e52b-dab62b065a4c"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/InceptionResNetV2_2.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/InceptionResNetV2_2.csv')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e2149f4d-ab8f-4b5a-ab91-e1b402182575\", \"InceptionResNetV2_2.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}