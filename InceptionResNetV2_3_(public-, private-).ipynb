{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionResNetV2_3_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/InceptionResNetV2_3_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0yI4jO4W5lx",
        "outputId": "458f75ac-8e3c-49cf-9fe1-756a53938459"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep 17 15:24:53 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebdfba1-3c98-4cc7-b94d-036ec7e4d210"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "InceptionResNetV2_model =  tf.keras.applications.InceptionResNetV2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "InceptionResNetV2_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d308083-fe0e-455c-b58f-73a46adb2d91"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 4\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baebfff7-f720-439b-e703-00976d6fc4ef"
      },
      "source": [
        "InceptionResNetV2_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "475/475 [==============================] - 98s 140ms/step - loss: 2.0856 - accuracy: 0.2905 - val_loss: 2.7499 - val_accuracy: 0.2838\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.28378, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 2/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 1.4228 - accuracy: 0.5163 - val_loss: 2.7559 - val_accuracy: 0.2838\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.28378\n",
            "Epoch 3/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 1.1281 - accuracy: 0.6274 - val_loss: 1.6598 - val_accuracy: 0.4797\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.28378 to 0.47973, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 4/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.9494 - accuracy: 0.6947 - val_loss: 0.7903 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.47973 to 0.73649, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 5/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.8339 - accuracy: 0.7284 - val_loss: 0.8587 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.73649 to 0.74324, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 6/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.7100 - accuracy: 0.7663 - val_loss: 0.9615 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.74324\n",
            "Epoch 7/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.6291 - accuracy: 0.7858 - val_loss: 0.5258 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.74324 to 0.81081, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 8/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.6323 - accuracy: 0.7900 - val_loss: 0.4266 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.81081 to 0.85811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 9/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.5614 - accuracy: 0.8174 - val_loss: 0.5755 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.85811\n",
            "Epoch 10/500\n",
            "475/475 [==============================] - 65s 138ms/step - loss: 0.5404 - accuracy: 0.8232 - val_loss: 0.4604 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.85811\n",
            "Epoch 11/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.4647 - accuracy: 0.8500 - val_loss: 0.3988 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.85811 to 0.87838, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 12/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.4773 - accuracy: 0.8332 - val_loss: 0.5230 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.87838\n",
            "Epoch 13/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.4157 - accuracy: 0.8558 - val_loss: 0.5088 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.87838\n",
            "Epoch 14/500\n",
            "475/475 [==============================] - 66s 140ms/step - loss: 0.4122 - accuracy: 0.8711 - val_loss: 0.4561 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.87838\n",
            "Epoch 15/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.3499 - accuracy: 0.8853 - val_loss: 0.4036 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.87838 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 16/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.3599 - accuracy: 0.8842 - val_loss: 0.5004 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.89865\n",
            "Epoch 17/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.3475 - accuracy: 0.8889 - val_loss: 0.3528 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.89865\n",
            "Epoch 18/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.3974 - accuracy: 0.8658 - val_loss: 0.6391 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.89865\n",
            "Epoch 19/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.3096 - accuracy: 0.8995 - val_loss: 0.2501 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.89865 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 20/500\n",
            "475/475 [==============================] - 69s 144ms/step - loss: 0.2566 - accuracy: 0.9174 - val_loss: 0.4755 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91216\n",
            "Epoch 21/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.2937 - accuracy: 0.9053 - val_loss: 0.4853 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91216\n",
            "Epoch 22/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.2590 - accuracy: 0.9105 - val_loss: 0.5397 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91216\n",
            "Epoch 23/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.2592 - accuracy: 0.9195 - val_loss: 0.7239 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91216\n",
            "Epoch 24/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.1946 - accuracy: 0.9321 - val_loss: 0.4138 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91216\n",
            "Epoch 25/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.2095 - accuracy: 0.9289 - val_loss: 0.5146 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91216\n",
            "Epoch 26/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.2126 - accuracy: 0.9305 - val_loss: 0.3876 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91216\n",
            "Epoch 27/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.2008 - accuracy: 0.9363 - val_loss: 0.3490 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91216\n",
            "Epoch 28/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.1770 - accuracy: 0.9358 - val_loss: 0.3798 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91216\n",
            "Epoch 29/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.2268 - accuracy: 0.9284 - val_loss: 0.5288 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91216\n",
            "Epoch 30/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.1901 - accuracy: 0.9316 - val_loss: 0.3672 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91216\n",
            "Epoch 31/500\n",
            "475/475 [==============================] - 65s 136ms/step - loss: 0.2163 - accuracy: 0.9321 - val_loss: 0.8992 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91216\n",
            "Epoch 32/500\n",
            "475/475 [==============================] - 65s 136ms/step - loss: 0.1466 - accuracy: 0.9553 - val_loss: 0.3294 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91216\n",
            "Epoch 33/500\n",
            "475/475 [==============================] - 65s 136ms/step - loss: 0.1554 - accuracy: 0.9453 - val_loss: 0.4736 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91216\n",
            "Epoch 34/500\n",
            "475/475 [==============================] - 65s 136ms/step - loss: 0.1778 - accuracy: 0.9447 - val_loss: 0.3369 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91216\n",
            "Epoch 35/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.1211 - accuracy: 0.9553 - val_loss: 0.4629 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91216\n",
            "Epoch 36/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.1298 - accuracy: 0.9547 - val_loss: 0.3728 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91216\n",
            "Epoch 37/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.1204 - accuracy: 0.9616 - val_loss: 0.3433 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91216\n",
            "Epoch 38/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.1198 - accuracy: 0.9626 - val_loss: 0.3395 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91216\n",
            "Epoch 39/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.1737 - accuracy: 0.9437 - val_loss: 1.1289 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91216\n",
            "Epoch 40/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.2499 - accuracy: 0.9268 - val_loss: 0.6062 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91216\n",
            "Epoch 41/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.1863 - accuracy: 0.9363 - val_loss: 0.8532 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91216\n",
            "Epoch 42/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.1127 - accuracy: 0.9605 - val_loss: 0.4328 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91216\n",
            "Epoch 43/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.0802 - accuracy: 0.9716 - val_loss: 0.3866 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91216\n",
            "Epoch 44/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.1041 - accuracy: 0.9642 - val_loss: 0.4604 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.91216 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 45/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.1067 - accuracy: 0.9647 - val_loss: 0.3691 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91892\n",
            "Epoch 46/500\n",
            "475/475 [==============================] - 65s 136ms/step - loss: 0.1145 - accuracy: 0.9616 - val_loss: 0.4578 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91892\n",
            "Epoch 47/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.1138 - accuracy: 0.9642 - val_loss: 0.4071 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91892\n",
            "Epoch 48/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.1043 - accuracy: 0.9658 - val_loss: 0.2185 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.91892 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 49/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.1077 - accuracy: 0.9642 - val_loss: 0.3859 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.93243\n",
            "Epoch 50/500\n",
            "475/475 [==============================] - 65s 137ms/step - loss: 0.1138 - accuracy: 0.9653 - val_loss: 0.4651 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.93243\n",
            "Epoch 51/500\n",
            "475/475 [==============================] - 65s 138ms/step - loss: 0.0840 - accuracy: 0.9705 - val_loss: 0.6414 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.93243\n",
            "Epoch 52/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0921 - accuracy: 0.9705 - val_loss: 0.4555 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.93243\n",
            "Epoch 53/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0666 - accuracy: 0.9747 - val_loss: 0.4675 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.93243\n",
            "Epoch 54/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0865 - accuracy: 0.9705 - val_loss: 0.6134 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.93243\n",
            "Epoch 55/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.1142 - accuracy: 0.9584 - val_loss: 0.5169 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.93243\n",
            "Epoch 56/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0806 - accuracy: 0.9700 - val_loss: 0.4040 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.93243\n",
            "Epoch 57/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.0955 - accuracy: 0.9653 - val_loss: 1.1832 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.93243\n",
            "Epoch 58/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.1354 - accuracy: 0.9616 - val_loss: 0.3339 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.93243\n",
            "Epoch 59/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0554 - accuracy: 0.9837 - val_loss: 0.8918 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.93243\n",
            "Epoch 60/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0745 - accuracy: 0.9774 - val_loss: 0.4077 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.93243\n",
            "Epoch 61/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.1239 - accuracy: 0.9584 - val_loss: 0.6348 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.93243\n",
            "Epoch 62/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0801 - accuracy: 0.9721 - val_loss: 0.4195 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.93243\n",
            "Epoch 63/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0790 - accuracy: 0.9779 - val_loss: 0.5527 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.93243\n",
            "Epoch 64/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0907 - accuracy: 0.9742 - val_loss: 0.4594 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.93243\n",
            "Epoch 65/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0817 - accuracy: 0.9732 - val_loss: 0.4354 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.93243\n",
            "Epoch 66/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0808 - accuracy: 0.9753 - val_loss: 0.7715 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.93243\n",
            "Epoch 67/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0764 - accuracy: 0.9705 - val_loss: 0.4579 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.93243\n",
            "Epoch 68/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0681 - accuracy: 0.9784 - val_loss: 0.7741 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.93243\n",
            "Epoch 69/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0519 - accuracy: 0.9795 - val_loss: 0.5007 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.93243\n",
            "Epoch 70/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0612 - accuracy: 0.9784 - val_loss: 0.9152 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.93243\n",
            "Epoch 71/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.1143 - accuracy: 0.9658 - val_loss: 0.3103 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.93243\n",
            "Epoch 72/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0421 - accuracy: 0.9868 - val_loss: 0.7724 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.93243\n",
            "Epoch 73/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0571 - accuracy: 0.9805 - val_loss: 0.3367 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.93243\n",
            "Epoch 74/500\n",
            "475/475 [==============================] - 66s 140ms/step - loss: 0.0741 - accuracy: 0.9779 - val_loss: 0.6126 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.93243\n",
            "Epoch 75/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0607 - accuracy: 0.9795 - val_loss: 0.5251 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.93243\n",
            "Epoch 76/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0417 - accuracy: 0.9847 - val_loss: 0.4315 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.93243\n",
            "Epoch 77/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0582 - accuracy: 0.9842 - val_loss: 0.6546 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.93243\n",
            "Epoch 78/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0894 - accuracy: 0.9753 - val_loss: 0.3335 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.93243\n",
            "Epoch 79/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0621 - accuracy: 0.9779 - val_loss: 0.4345 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.93243\n",
            "Epoch 80/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0409 - accuracy: 0.9874 - val_loss: 0.4259 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.93243\n",
            "Epoch 81/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0746 - accuracy: 0.9763 - val_loss: 0.4076 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.93243\n",
            "Epoch 82/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0901 - accuracy: 0.9705 - val_loss: 0.6213 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.93243\n",
            "Epoch 83/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0610 - accuracy: 0.9774 - val_loss: 0.5230 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.93243\n",
            "Epoch 84/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0297 - accuracy: 0.9921 - val_loss: 0.5436 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.93243\n",
            "Epoch 85/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0397 - accuracy: 0.9863 - val_loss: 0.5192 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.93243\n",
            "Epoch 86/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0395 - accuracy: 0.9858 - val_loss: 0.7085 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.93243\n",
            "Epoch 87/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0426 - accuracy: 0.9884 - val_loss: 0.4704 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.93243\n",
            "Epoch 88/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0699 - accuracy: 0.9784 - val_loss: 0.9592 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.93243\n",
            "Epoch 89/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0388 - accuracy: 0.9879 - val_loss: 0.4066 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.93243\n",
            "Epoch 90/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0694 - accuracy: 0.9795 - val_loss: 0.5754 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.93243\n",
            "Epoch 91/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0718 - accuracy: 0.9811 - val_loss: 0.3135 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.93243\n",
            "Epoch 92/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0374 - accuracy: 0.9921 - val_loss: 0.4216 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.93243\n",
            "Epoch 93/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.3749 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.93243\n",
            "Epoch 94/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0667 - accuracy: 0.9795 - val_loss: 0.5966 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.93243\n",
            "Epoch 95/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0467 - accuracy: 0.9847 - val_loss: 0.6634 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.93243\n",
            "Epoch 96/500\n",
            "475/475 [==============================] - 65s 138ms/step - loss: 0.0601 - accuracy: 0.9821 - val_loss: 0.4365 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.93243\n",
            "Epoch 97/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0819 - accuracy: 0.9742 - val_loss: 0.3767 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.93243\n",
            "Epoch 98/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0590 - accuracy: 0.9847 - val_loss: 0.4884 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.93243\n",
            "Epoch 99/500\n",
            "475/475 [==============================] - 65s 138ms/step - loss: 0.0273 - accuracy: 0.9916 - val_loss: 0.4446 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.93243\n",
            "Epoch 100/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0254 - accuracy: 0.9900 - val_loss: 0.4318 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.93243\n",
            "Epoch 101/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.4666 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.93243\n",
            "Epoch 102/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0391 - accuracy: 0.9900 - val_loss: 0.5742 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.93243\n",
            "Epoch 103/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0283 - accuracy: 0.9916 - val_loss: 0.5023 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.93243\n",
            "Epoch 104/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0283 - accuracy: 0.9921 - val_loss: 0.3985 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00104: val_accuracy improved from 0.93243 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 105/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0623 - accuracy: 0.9826 - val_loss: 0.4582 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.93919\n",
            "Epoch 106/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0719 - accuracy: 0.9763 - val_loss: 0.4214 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.93919\n",
            "Epoch 107/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.8433 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.93919\n",
            "Epoch 108/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0444 - accuracy: 0.9858 - val_loss: 0.4416 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.93919\n",
            "Epoch 109/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0404 - accuracy: 0.9884 - val_loss: 0.3411 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.93919\n",
            "Epoch 110/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0403 - accuracy: 0.9868 - val_loss: 0.4466 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.93919\n",
            "Epoch 111/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0356 - accuracy: 0.9858 - val_loss: 0.6846 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.93919\n",
            "Epoch 112/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0553 - accuracy: 0.9853 - val_loss: 0.3332 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.93919\n",
            "Epoch 113/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0445 - accuracy: 0.9847 - val_loss: 0.4479 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.93919\n",
            "Epoch 114/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0395 - accuracy: 0.9889 - val_loss: 0.4545 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.93919\n",
            "Epoch 115/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.1341 - accuracy: 0.9621 - val_loss: 0.4000 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.93919\n",
            "Epoch 116/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0544 - accuracy: 0.9837 - val_loss: 0.4741 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.93919\n",
            "Epoch 117/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0331 - accuracy: 0.9868 - val_loss: 0.4438 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.93919\n",
            "Epoch 118/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.5927 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.93919\n",
            "Epoch 119/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0210 - accuracy: 0.9921 - val_loss: 0.3698 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.93919\n",
            "Epoch 120/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.3606 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.93919\n",
            "Epoch 121/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.6289 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.93919\n",
            "Epoch 122/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.3961 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.93919\n",
            "Epoch 123/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0327 - accuracy: 0.9905 - val_loss: 0.4425 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.93919\n",
            "Epoch 124/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0524 - accuracy: 0.9826 - val_loss: 0.8345 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.93919\n",
            "Epoch 125/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0334 - accuracy: 0.9874 - val_loss: 0.6148 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.93919\n",
            "Epoch 126/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.3732 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.93919\n",
            "Epoch 127/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0328 - accuracy: 0.9921 - val_loss: 0.5719 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.93919\n",
            "Epoch 128/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.4051 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.93919\n",
            "Epoch 129/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.4603 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.93919\n",
            "Epoch 130/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0301 - accuracy: 0.9916 - val_loss: 0.3314 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.93919\n",
            "Epoch 131/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0482 - accuracy: 0.9853 - val_loss: 0.5653 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.93919\n",
            "Epoch 132/500\n",
            "475/475 [==============================] - 66s 138ms/step - loss: 0.0499 - accuracy: 0.9858 - val_loss: 0.3343 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.93919\n",
            "Epoch 133/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 0.3300 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00133: val_accuracy improved from 0.93919 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 134/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0213 - accuracy: 0.9916 - val_loss: 0.4547 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.94595\n",
            "Epoch 135/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.1004 - accuracy: 0.9779 - val_loss: 0.5337 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.94595\n",
            "Epoch 136/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0346 - accuracy: 0.9911 - val_loss: 0.3591 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.94595\n",
            "Epoch 137/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0499 - accuracy: 0.9858 - val_loss: 1.4161 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.94595\n",
            "Epoch 138/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 0.5622 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.94595\n",
            "Epoch 139/500\n",
            "475/475 [==============================] - 66s 140ms/step - loss: 0.0304 - accuracy: 0.9895 - val_loss: 0.6200 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.94595\n",
            "Epoch 140/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0342 - accuracy: 0.9879 - val_loss: 0.8072 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.94595\n",
            "Epoch 141/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0416 - accuracy: 0.9900 - val_loss: 0.4737 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.94595\n",
            "Epoch 142/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 0.5351 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.94595\n",
            "Epoch 143/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.7135 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.94595\n",
            "Epoch 144/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0425 - accuracy: 0.9868 - val_loss: 0.9501 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.94595\n",
            "Epoch 145/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.5051 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.94595\n",
            "Epoch 146/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.5200 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.94595\n",
            "Epoch 147/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.0658 - accuracy: 0.9774 - val_loss: 0.7066 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.94595\n",
            "Epoch 148/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0667 - accuracy: 0.9800 - val_loss: 0.5044 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.94595\n",
            "Epoch 149/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0252 - accuracy: 0.9932 - val_loss: 0.3752 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.94595\n",
            "Epoch 150/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.3978 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.94595\n",
            "Epoch 151/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.0280 - accuracy: 0.9889 - val_loss: 0.8038 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.94595\n",
            "Epoch 152/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0454 - accuracy: 0.9889 - val_loss: 0.6222 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.94595\n",
            "Epoch 153/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0260 - accuracy: 0.9884 - val_loss: 0.4575 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.94595\n",
            "Epoch 154/500\n",
            "475/475 [==============================] - 66s 140ms/step - loss: 0.0253 - accuracy: 0.9911 - val_loss: 0.6100 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.94595\n",
            "Epoch 155/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0349 - accuracy: 0.9916 - val_loss: 0.6645 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.94595\n",
            "Epoch 156/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.4449 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.94595\n",
            "Epoch 157/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.0352 - accuracy: 0.9895 - val_loss: 0.6335 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.94595\n",
            "Epoch 158/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0456 - accuracy: 0.9868 - val_loss: 0.2316 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.94595\n",
            "Epoch 159/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.4273 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.94595\n",
            "Epoch 160/500\n",
            "475/475 [==============================] - 66s 140ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.4969 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.94595\n",
            "Epoch 161/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.5753 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.94595\n",
            "Epoch 162/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0355 - accuracy: 0.9879 - val_loss: 0.3541 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.94595\n",
            "Epoch 163/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0454 - accuracy: 0.9874 - val_loss: 0.2892 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.94595\n",
            "Epoch 164/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.4231 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.94595\n",
            "Epoch 165/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 1.6320 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.94595\n",
            "Epoch 166/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0741 - accuracy: 0.9795 - val_loss: 0.4466 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.94595\n",
            "Epoch 167/500\n",
            "475/475 [==============================] - 66s 140ms/step - loss: 0.0216 - accuracy: 0.9942 - val_loss: 0.2843 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.94595\n",
            "Epoch 168/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.7663 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.94595\n",
            "Epoch 169/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0395 - accuracy: 0.9879 - val_loss: 0.4745 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.94595\n",
            "Epoch 170/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0484 - accuracy: 0.9858 - val_loss: 0.4010 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.94595\n",
            "Epoch 171/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0215 - accuracy: 0.9953 - val_loss: 0.7710 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.94595\n",
            "Epoch 172/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.8274 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.94595\n",
            "Epoch 173/500\n",
            "475/475 [==============================] - 66s 139ms/step - loss: 0.0350 - accuracy: 0.9863 - val_loss: 0.4241 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.94595\n",
            "Epoch 174/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.0303 - accuracy: 0.9884 - val_loss: 0.7028 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.94595\n",
            "Epoch 175/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.5510 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.94595\n",
            "Epoch 176/500\n",
            "475/475 [==============================] - 66s 140ms/step - loss: 0.0135 - accuracy: 0.9942 - val_loss: 1.1146 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.94595\n",
            "Epoch 177/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.0375 - accuracy: 0.9911 - val_loss: 0.4912 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.94595\n",
            "Epoch 178/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.0366 - accuracy: 0.9889 - val_loss: 0.5633 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.94595\n",
            "Epoch 179/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.5432 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.94595\n",
            "Epoch 180/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0309 - accuracy: 0.9895 - val_loss: 0.4537 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.94595\n",
            "Epoch 181/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.7331 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.94595\n",
            "Epoch 182/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.6270 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.94595\n",
            "Epoch 183/500\n",
            "475/475 [==============================] - 66s 140ms/step - loss: 0.0305 - accuracy: 0.9895 - val_loss: 0.5543 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.94595\n",
            "Epoch 184/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.4993 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.94595\n",
            "Epoch 185/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0283 - accuracy: 0.9900 - val_loss: 0.8297 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.94595\n",
            "Epoch 186/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.6456 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.94595\n",
            "Epoch 187/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.4511 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.94595\n",
            "Epoch 188/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0239 - accuracy: 0.9911 - val_loss: 0.7659 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.94595\n",
            "Epoch 189/500\n",
            "475/475 [==============================] - 69s 145ms/step - loss: 0.0197 - accuracy: 0.9926 - val_loss: 1.0183 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.94595\n",
            "Epoch 190/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0552 - accuracy: 0.9847 - val_loss: 0.7084 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.94595\n",
            "Epoch 191/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.0162 - accuracy: 0.9968 - val_loss: 0.6522 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.94595\n",
            "Epoch 192/500\n",
            "475/475 [==============================] - 66s 140ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.8205 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.94595\n",
            "Epoch 193/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0333 - accuracy: 0.9926 - val_loss: 0.4276 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.94595\n",
            "Epoch 194/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.5197 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.94595\n",
            "Epoch 195/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0329 - accuracy: 0.9932 - val_loss: 0.7966 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.94595\n",
            "Epoch 196/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.4198 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.94595\n",
            "Epoch 197/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 1.6459 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.94595\n",
            "Epoch 198/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 0.8331 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.94595\n",
            "Epoch 199/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0332 - accuracy: 0.9895 - val_loss: 0.5846 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.94595\n",
            "Epoch 200/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.5887 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.94595\n",
            "Epoch 201/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0313 - accuracy: 0.9921 - val_loss: 0.5687 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.94595\n",
            "Epoch 202/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0214 - accuracy: 0.9916 - val_loss: 0.5850 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.94595\n",
            "Epoch 203/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0423 - accuracy: 0.9874 - val_loss: 0.3516 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.94595\n",
            "Epoch 204/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0294 - accuracy: 0.9932 - val_loss: 0.6210 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.94595\n",
            "Epoch 205/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.4087 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.94595\n",
            "Epoch 206/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0246 - accuracy: 0.9932 - val_loss: 0.5277 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.94595\n",
            "Epoch 207/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0324 - accuracy: 0.9905 - val_loss: 0.6048 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.94595\n",
            "Epoch 208/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0350 - accuracy: 0.9895 - val_loss: 0.3819 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.94595\n",
            "Epoch 209/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.4192 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.94595\n",
            "Epoch 210/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.3985 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.94595\n",
            "Epoch 211/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 1.7272 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.94595\n",
            "Epoch 212/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0299 - accuracy: 0.9921 - val_loss: 0.7363 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.94595\n",
            "Epoch 213/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0263 - accuracy: 0.9905 - val_loss: 0.8408 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.94595\n",
            "Epoch 214/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.4577 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.94595\n",
            "Epoch 215/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0373 - accuracy: 0.9879 - val_loss: 0.5269 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.94595\n",
            "Epoch 216/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 1.0508 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.94595\n",
            "Epoch 217/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.4565 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.94595\n",
            "Epoch 218/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.3934 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.94595\n",
            "Epoch 219/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.5689 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.94595\n",
            "Epoch 220/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.4626 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.94595\n",
            "Epoch 221/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 0.3745 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.94595\n",
            "Epoch 222/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.4677 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.94595\n",
            "Epoch 223/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0881 - accuracy: 0.9732 - val_loss: 0.3899 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.94595\n",
            "Epoch 224/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0227 - accuracy: 0.9942 - val_loss: 0.3568 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.94595\n",
            "Epoch 225/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.3749 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.94595\n",
            "Epoch 226/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.4734 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.94595\n",
            "Epoch 227/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0100 - accuracy: 0.9953 - val_loss: 0.5778 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.94595\n",
            "Epoch 228/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.5880 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.94595\n",
            "Epoch 229/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0398 - accuracy: 0.9900 - val_loss: 0.6154 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.94595\n",
            "Epoch 230/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 0.4449 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.94595\n",
            "Epoch 231/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.2669 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00231: val_accuracy improved from 0.94595 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5\n",
            "Epoch 232/500\n",
            "475/475 [==============================] - 70s 147ms/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 0.5921 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.95270\n",
            "Epoch 233/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0238 - accuracy: 0.9911 - val_loss: 0.9762 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.95270\n",
            "Epoch 234/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0442 - accuracy: 0.9884 - val_loss: 0.5841 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.95270\n",
            "Epoch 235/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0222 - accuracy: 0.9916 - val_loss: 0.4222 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.95270\n",
            "Epoch 236/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.6446 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.95270\n",
            "Epoch 237/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.5907 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.95270\n",
            "Epoch 238/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.7303 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.95270\n",
            "Epoch 239/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0145 - accuracy: 0.9968 - val_loss: 0.9843 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.95270\n",
            "Epoch 240/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0335 - accuracy: 0.9911 - val_loss: 0.5875 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.95270\n",
            "Epoch 241/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0125 - accuracy: 0.9947 - val_loss: 0.5657 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.95270\n",
            "Epoch 242/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.3693 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.95270\n",
            "Epoch 243/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0162 - accuracy: 0.9937 - val_loss: 0.7863 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.95270\n",
            "Epoch 244/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.6950 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.95270\n",
            "Epoch 245/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.3970 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.95270\n",
            "Epoch 246/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.2373 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.95270\n",
            "Epoch 247/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.3658 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.95270\n",
            "Epoch 248/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.3020 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.95270\n",
            "Epoch 249/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.5674 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.95270\n",
            "Epoch 250/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.5748 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.95270\n",
            "Epoch 251/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.4538 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.95270\n",
            "Epoch 252/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0516 - accuracy: 0.9874 - val_loss: 0.9035 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.95270\n",
            "Epoch 253/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0238 - accuracy: 0.9900 - val_loss: 0.5331 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.95270\n",
            "Epoch 254/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0160 - accuracy: 0.9942 - val_loss: 0.3052 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.95270\n",
            "Epoch 255/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 0.1880 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.95270\n",
            "Epoch 256/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.2361 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.95270\n",
            "Epoch 257/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0152 - accuracy: 0.9968 - val_loss: 0.6266 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.95270\n",
            "Epoch 258/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.4895 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.95270\n",
            "Epoch 259/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0367 - accuracy: 0.9916 - val_loss: 0.5146 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.95270\n",
            "Epoch 260/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0127 - accuracy: 0.9947 - val_loss: 0.5720 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.95270\n",
            "Epoch 261/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0110 - accuracy: 0.9953 - val_loss: 0.7922 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.95270\n",
            "Epoch 262/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 0.4035 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.95270\n",
            "Epoch 263/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0289 - accuracy: 0.9937 - val_loss: 0.8457 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.95270\n",
            "Epoch 264/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0292 - accuracy: 0.9932 - val_loss: 0.5401 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.95270\n",
            "Epoch 265/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.4350 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.95270\n",
            "Epoch 266/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4467 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.95270\n",
            "Epoch 267/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.5992 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.95270\n",
            "Epoch 268/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0600 - accuracy: 0.9816 - val_loss: 0.2656 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.95270\n",
            "Epoch 269/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.3839 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.95270\n",
            "Epoch 270/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0344 - accuracy: 0.9921 - val_loss: 0.6488 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.95270\n",
            "Epoch 271/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.3924 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.95270\n",
            "Epoch 272/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0333 - accuracy: 0.9911 - val_loss: 0.8099 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.95270\n",
            "Epoch 273/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0393 - accuracy: 0.9863 - val_loss: 1.0442 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.95270\n",
            "Epoch 274/500\n",
            "475/475 [==============================] - 69s 145ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.5732 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.95270\n",
            "Epoch 275/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.5303 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.95270\n",
            "Epoch 276/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.5261 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.95270\n",
            "Epoch 277/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 0.5136 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.95270\n",
            "Epoch 278/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.6119 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.95270\n",
            "Epoch 279/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0251 - accuracy: 0.9947 - val_loss: 0.4963 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.95270\n",
            "Epoch 280/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.4821 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.95270\n",
            "Epoch 281/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.5707 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.95270\n",
            "Epoch 282/500\n",
            "475/475 [==============================] - 69s 144ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 0.4655 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.95270\n",
            "Epoch 283/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.5527 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.95270\n",
            "Epoch 284/500\n",
            "475/475 [==============================] - 69s 144ms/step - loss: 0.0262 - accuracy: 0.9942 - val_loss: 0.4482 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.95270\n",
            "Epoch 285/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0320 - accuracy: 0.9905 - val_loss: 0.7684 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.95270\n",
            "Epoch 286/500\n",
            "475/475 [==============================] - 69s 144ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.5007 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.95270\n",
            "Epoch 287/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.4000 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.95270\n",
            "Epoch 288/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0275 - accuracy: 0.9937 - val_loss: 0.5599 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.95270\n",
            "Epoch 289/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.3681 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.95270\n",
            "Epoch 290/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.4126 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.95270\n",
            "Epoch 291/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.4452 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.95270\n",
            "Epoch 292/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.5844 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.95270\n",
            "Epoch 293/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.5660 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.95270\n",
            "Epoch 294/500\n",
            "475/475 [==============================] - 69s 144ms/step - loss: 0.0426 - accuracy: 0.9863 - val_loss: 0.4487 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.95270\n",
            "Epoch 295/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.3988 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.95270\n",
            "Epoch 296/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.4073 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.95270\n",
            "Epoch 297/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.5044 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.95270\n",
            "Epoch 298/500\n",
            "475/475 [==============================] - 69s 146ms/step - loss: 0.0220 - accuracy: 0.9953 - val_loss: 0.3647 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.95270\n",
            "Epoch 299/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 0.4114 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.95270\n",
            "Epoch 300/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.3791 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.95270\n",
            "Epoch 301/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0356 - accuracy: 0.9911 - val_loss: 0.6690 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.95270\n",
            "Epoch 302/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.4383 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.95270\n",
            "Epoch 303/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0201 - accuracy: 0.9926 - val_loss: 0.6112 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.95270\n",
            "Epoch 304/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.5372 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.95270\n",
            "Epoch 305/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0228 - accuracy: 0.9947 - val_loss: 0.5695 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.95270\n",
            "Epoch 306/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.6513 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.95270\n",
            "Epoch 307/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 1.2732 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.95270\n",
            "Epoch 308/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.7299 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.95270\n",
            "Epoch 309/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0284 - accuracy: 0.9942 - val_loss: 0.5641 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.95270\n",
            "Epoch 310/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.5214 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.95270\n",
            "Epoch 311/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6765 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.95270\n",
            "Epoch 312/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.5364 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.95270\n",
            "Epoch 313/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0209 - accuracy: 0.9947 - val_loss: 0.6289 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.95270\n",
            "Epoch 314/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0387 - accuracy: 0.9879 - val_loss: 0.5055 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.95270\n",
            "Epoch 315/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0247 - accuracy: 0.9932 - val_loss: 0.4494 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.95270\n",
            "Epoch 316/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.4508 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.95270\n",
            "Epoch 317/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.7553 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.95270\n",
            "Epoch 318/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.4411 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.95270\n",
            "Epoch 319/500\n",
            "475/475 [==============================] - 69s 145ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.5976 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.95270\n",
            "Epoch 320/500\n",
            "475/475 [==============================] - 69s 145ms/step - loss: 0.0084 - accuracy: 0.9984 - val_loss: 0.8178 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.95270\n",
            "Epoch 321/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.5322 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.95270\n",
            "Epoch 322/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.3378 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.95270\n",
            "Epoch 323/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.4072 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.95270\n",
            "Epoch 324/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0254 - accuracy: 0.9911 - val_loss: 0.6346 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.95270\n",
            "Epoch 325/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.6080 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.95270\n",
            "Epoch 326/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.6725 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.95270\n",
            "Epoch 327/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.6795 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.95270\n",
            "Epoch 328/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.5516 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.95270\n",
            "Epoch 329/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0357 - accuracy: 0.9905 - val_loss: 0.5109 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.95270\n",
            "Epoch 330/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.5906 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.95270\n",
            "Epoch 331/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0188 - accuracy: 0.9963 - val_loss: 0.4028 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.95270\n",
            "Epoch 332/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.3320 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.95270\n",
            "Epoch 333/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.3855 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.95270\n",
            "Epoch 334/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0225 - accuracy: 0.9916 - val_loss: 0.4329 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.95270\n",
            "Epoch 335/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.4404 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.95270\n",
            "Epoch 336/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.5457 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.95270\n",
            "Epoch 337/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.3517 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.95270\n",
            "Epoch 338/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.4436 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.95270\n",
            "Epoch 339/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3878 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.95270\n",
            "Epoch 340/500\n",
            "475/475 [==============================] - 69s 145ms/step - loss: 0.0303 - accuracy: 0.9921 - val_loss: 0.6716 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.95270\n",
            "Epoch 341/500\n",
            "475/475 [==============================] - 69s 144ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.6289 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95270\n",
            "Epoch 342/500\n",
            "475/475 [==============================] - 69s 144ms/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.6527 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95270\n",
            "Epoch 343/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.8558 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95270\n",
            "Epoch 344/500\n",
            "475/475 [==============================] - 69s 144ms/step - loss: 0.0227 - accuracy: 0.9911 - val_loss: 0.9055 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95270\n",
            "Epoch 345/500\n",
            "475/475 [==============================] - 69s 145ms/step - loss: 0.0290 - accuracy: 0.9937 - val_loss: 0.5553 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95270\n",
            "Epoch 346/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.4620 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95270\n",
            "Epoch 347/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0293 - accuracy: 0.9926 - val_loss: 0.9025 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95270\n",
            "Epoch 348/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 0.5661 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95270\n",
            "Epoch 349/500\n",
            "475/475 [==============================] - 69s 146ms/step - loss: 0.0263 - accuracy: 0.9937 - val_loss: 0.3920 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95270\n",
            "Epoch 350/500\n",
            "475/475 [==============================] - 69s 146ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.5667 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95270\n",
            "Epoch 351/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.4959 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95270\n",
            "Epoch 352/500\n",
            "475/475 [==============================] - 70s 146ms/step - loss: 0.0237 - accuracy: 0.9942 - val_loss: 0.5353 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95270\n",
            "Epoch 353/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.4100 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95270\n",
            "Epoch 354/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.4753 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95270\n",
            "Epoch 355/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.6038 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95270\n",
            "Epoch 356/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.3022 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95270\n",
            "Epoch 357/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.5564 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95270\n",
            "Epoch 358/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.6383 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95270\n",
            "Epoch 359/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0158 - accuracy: 0.9968 - val_loss: 0.8871 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95270\n",
            "Epoch 360/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0469 - accuracy: 0.9895 - val_loss: 0.4539 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95270\n",
            "Epoch 361/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0256 - accuracy: 0.9932 - val_loss: 0.5652 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95270\n",
            "Epoch 362/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.4714 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95270\n",
            "Epoch 363/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.5232 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95270\n",
            "Epoch 364/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.5027 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95270\n",
            "Epoch 365/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0068 - accuracy: 0.9968 - val_loss: 0.5612 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95270\n",
            "Epoch 366/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.5166 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95270\n",
            "Epoch 367/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.9987 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95270\n",
            "Epoch 368/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0312 - accuracy: 0.9916 - val_loss: 0.3370 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95270\n",
            "Epoch 369/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.3127 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95270\n",
            "Epoch 370/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0176 - accuracy: 0.9968 - val_loss: 0.4157 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95270\n",
            "Epoch 371/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.5049 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95270\n",
            "Epoch 372/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.4072 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95270\n",
            "Epoch 373/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 8.6077e-04 - accuracy: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95270\n",
            "Epoch 374/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.5673 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95270\n",
            "Epoch 375/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.6755 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95270\n",
            "Epoch 376/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0232 - accuracy: 0.9947 - val_loss: 0.7406 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95270\n",
            "Epoch 377/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0100 - accuracy: 0.9953 - val_loss: 0.5797 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95270\n",
            "Epoch 378/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0160 - accuracy: 0.9932 - val_loss: 0.6563 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95270\n",
            "Epoch 379/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.6990 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95270\n",
            "Epoch 380/500\n",
            "475/475 [==============================] - 67s 140ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.5860 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95270\n",
            "Epoch 381/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.7203 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95270\n",
            "Epoch 382/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.8077 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95270\n",
            "Epoch 383/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.7032 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95270\n",
            "Epoch 384/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0201 - accuracy: 0.9958 - val_loss: 0.7336 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95270\n",
            "Epoch 385/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4486 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95270\n",
            "Epoch 386/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0145 - accuracy: 0.9968 - val_loss: 0.9781 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95270\n",
            "Epoch 387/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0214 - accuracy: 0.9953 - val_loss: 0.5336 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95270\n",
            "Epoch 388/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0162 - accuracy: 0.9932 - val_loss: 0.6243 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95270\n",
            "Epoch 389/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.8379 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95270\n",
            "Epoch 390/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0226 - accuracy: 0.9947 - val_loss: 0.7846 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95270\n",
            "Epoch 391/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.5847 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95270\n",
            "Epoch 392/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.4464 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95270\n",
            "Epoch 393/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.3729 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95270\n",
            "Epoch 394/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.6236 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95270\n",
            "Epoch 395/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.7000 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95270\n",
            "Epoch 396/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0144 - accuracy: 0.9984 - val_loss: 0.5216 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95270\n",
            "Epoch 397/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.6524 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95270\n",
            "Epoch 398/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0107 - accuracy: 0.9958 - val_loss: 0.8110 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95270\n",
            "Epoch 399/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.7022 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95270\n",
            "Epoch 400/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.6414 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95270\n",
            "Epoch 401/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0178 - accuracy: 0.9926 - val_loss: 0.6298 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95270\n",
            "Epoch 402/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0270 - accuracy: 0.9942 - val_loss: 0.7173 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95270\n",
            "Epoch 403/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.6180 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95270\n",
            "Epoch 404/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.7443 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95270\n",
            "Epoch 405/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.4599 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95270\n",
            "Epoch 406/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.7308 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95270\n",
            "Epoch 407/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0096 - accuracy: 0.9984 - val_loss: 0.7454 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95270\n",
            "Epoch 408/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.4473 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95270\n",
            "Epoch 409/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.4452 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95270\n",
            "Epoch 410/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.6140 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95270\n",
            "Epoch 411/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0134 - accuracy: 0.9942 - val_loss: 0.6056 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95270\n",
            "Epoch 412/500\n",
            "475/475 [==============================] - 67s 141ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.7832 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95270\n",
            "Epoch 413/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0222 - accuracy: 0.9947 - val_loss: 0.6323 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95270\n",
            "Epoch 414/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.4964 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95270\n",
            "Epoch 415/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95270\n",
            "Epoch 416/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.5296 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95270\n",
            "Epoch 417/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.4896 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95270\n",
            "Epoch 418/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0105 - accuracy: 0.9984 - val_loss: 0.4330 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95270\n",
            "Epoch 419/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0270 - accuracy: 0.9932 - val_loss: 0.7756 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95270\n",
            "Epoch 420/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.6378 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95270\n",
            "Epoch 421/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.5435 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95270\n",
            "Epoch 422/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.7773 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95270\n",
            "Epoch 423/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.4962 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95270\n",
            "Epoch 424/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0193 - accuracy: 0.9958 - val_loss: 0.6739 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95270\n",
            "Epoch 425/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.6386 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95270\n",
            "Epoch 426/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0082 - accuracy: 0.9958 - val_loss: 0.7312 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95270\n",
            "Epoch 427/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.8276 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95270\n",
            "Epoch 428/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.7545 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95270\n",
            "Epoch 429/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.5708 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95270\n",
            "Epoch 430/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.5853 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95270\n",
            "Epoch 431/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.3673 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95270\n",
            "Epoch 432/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0163 - accuracy: 0.9937 - val_loss: 0.4771 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95270\n",
            "Epoch 433/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.7283 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95270\n",
            "Epoch 434/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.6321 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95270\n",
            "Epoch 435/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0199 - accuracy: 0.9926 - val_loss: 0.6788 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95270\n",
            "Epoch 436/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.5654 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95270\n",
            "Epoch 437/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 3.6338e-04 - accuracy: 1.0000 - val_loss: 0.6789 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95270\n",
            "Epoch 438/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 2.8018e-04 - accuracy: 1.0000 - val_loss: 0.6780 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95270\n",
            "Epoch 439/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 2.2497e-04 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95270\n",
            "Epoch 440/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 1.3604 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95270\n",
            "Epoch 441/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.6349 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95270\n",
            "Epoch 442/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.4377 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95270\n",
            "Epoch 443/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0197 - accuracy: 0.9958 - val_loss: 0.6725 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95270\n",
            "Epoch 444/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.6780 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95270\n",
            "Epoch 445/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.7745 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95270\n",
            "Epoch 446/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0159 - accuracy: 0.9937 - val_loss: 0.6909 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95270\n",
            "Epoch 447/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.5479 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95270\n",
            "Epoch 448/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.5850 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95270\n",
            "Epoch 449/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.5237 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95270\n",
            "Epoch 450/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.6751 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95270\n",
            "Epoch 451/500\n",
            "475/475 [==============================] - 69s 144ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.3849 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95270\n",
            "Epoch 452/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.2771 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95270\n",
            "Epoch 453/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.5755 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95270\n",
            "Epoch 454/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0194 - accuracy: 0.9926 - val_loss: 0.4783 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95270\n",
            "Epoch 455/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.6328 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95270\n",
            "Epoch 456/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.3290 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95270\n",
            "Epoch 457/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.5962 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95270\n",
            "Epoch 458/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.5188 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95270\n",
            "Epoch 459/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.5755 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95270\n",
            "Epoch 460/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0079 - accuracy: 0.9963 - val_loss: 0.6905 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95270\n",
            "Epoch 461/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.8818 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95270\n",
            "Epoch 462/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0208 - accuracy: 0.9958 - val_loss: 0.5752 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95270\n",
            "Epoch 463/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95270\n",
            "Epoch 464/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.7136 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95270\n",
            "Epoch 465/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.5051 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95270\n",
            "Epoch 466/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.7772 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95270\n",
            "Epoch 467/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0234 - accuracy: 0.9953 - val_loss: 0.7351 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95270\n",
            "Epoch 468/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.3546 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95270\n",
            "Epoch 469/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.5496 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95270\n",
            "Epoch 470/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.6822 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95270\n",
            "Epoch 471/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.6325 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95270\n",
            "Epoch 472/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.5548 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95270\n",
            "Epoch 473/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.6514 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95270\n",
            "Epoch 474/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0401 - accuracy: 0.9895 - val_loss: 0.3877 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95270\n",
            "Epoch 475/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.3762 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95270\n",
            "Epoch 476/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0126 - accuracy: 0.9947 - val_loss: 0.4659 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95270\n",
            "Epoch 477/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0129 - accuracy: 0.9947 - val_loss: 0.4686 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95270\n",
            "Epoch 478/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.4862 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95270\n",
            "Epoch 479/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.6805 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95270\n",
            "Epoch 480/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0222 - accuracy: 0.9953 - val_loss: 0.6913 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95270\n",
            "Epoch 481/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.6051 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95270\n",
            "Epoch 482/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.5856 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95270\n",
            "Epoch 483/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0238 - accuracy: 0.9942 - val_loss: 0.5955 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95270\n",
            "Epoch 484/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.5881 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95270\n",
            "Epoch 485/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.4701 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95270\n",
            "Epoch 486/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.5051 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95270\n",
            "Epoch 487/500\n",
            "475/475 [==============================] - 68s 144ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5578 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95270\n",
            "Epoch 488/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.5997 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95270\n",
            "Epoch 489/500\n",
            "475/475 [==============================] - 67s 142ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.8138 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95270\n",
            "Epoch 490/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 1.0171 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95270\n",
            "Epoch 491/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0215 - accuracy: 0.9953 - val_loss: 0.7434 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95270\n",
            "Epoch 492/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.3538 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95270\n",
            "Epoch 493/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.5397 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95270\n",
            "Epoch 494/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 9.2653e-04 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95270\n",
            "Epoch 495/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.6095 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95270\n",
            "Epoch 496/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 1.1989 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95270\n",
            "Epoch 497/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.6365 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95270\n",
            "Epoch 498/500\n",
            "475/475 [==============================] - 68s 142ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.7125 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95270\n",
            "Epoch 499/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.6705 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95270\n",
            "Epoch 500/500\n",
            "475/475 [==============================] - 68s 143ms/step - loss: 0.0246 - accuracy: 0.9942 - val_loss: 0.5478 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d11ece410>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "048eada7-1a43-49d8-8db8-7890aca6a2d1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(InceptionResNetV2_model.history.history[\"accuracy\"], label='InceptionResNetV2_acc')\n",
        "plt.plot(InceptionResNetV2_model.history.history[\"val_accuracy\"], label='InceptionResNetV2_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd5xU1fn/32dnK8sWellAQOlt6SWioCIolqBEJRqNJcQkaPKNsZDEHjV2ozGWX4waNQGDDSuKgoIVUHpnpSx1WdheZ+b8/jhzZ+7M3JmdhVlw4Hm/Xvvauf3c9rnPec5znqO01giCIAiJT9LRLoAgCIIQH0TQBUEQjhFE0AVBEI4RRNAFQRCOEUTQBUEQjhGSj9aBW7durbt27Xq0Di8IgpCQLFu2bL/Wuo3TsqMm6F27dmXp0qVH6/CCIAgJiVJqW6Rl4nIRBEE4RhBBFwRBOEYQQRcEQThGEEEXBEE4RhBBFwRBOEZoUNCVUv9SSu1TSq2OsFwppR5XSm1WSq1USg2JfzEFQRCEhojFQn8BmBRl+VlAD9/fdOCpwy+WIAiC0FgaFHSt9WfAgSirnA/8Wxu+AnKVUh3iVUBBiAWtNaGpoD3exqWGdnu8ABRX1FLn9kZcr7LWzdwVu1i69UDYMQG8Xs2ByrqYjrmrpNpxH3YOVtbxxneFeEPOx+3xBs3zenXQ9PIdJZRW1wOwdX8lr3y9LeiafLf9IBW1bmrqPRSV10Y8/o4DVf7ray/rl1uKmbdmj+M2Xq9mydYD/msKsLeshuo6D1prPF5NeU09+ysCx926v5JPNxYFbQPwzspdrN5Z6j+/HQeqACitrqfW7Qk6pzq3ly+27GfB+n088uEGnvl0C2U19Xi9mm+3H8Tr1eyvqKWgqIK9ZTVBx6n3ePl0YxHVdR7W7Cpl/tq9ANTUe1iwYR/FFbUcqKxjX3mN/5ger2ZXSTUb9pRTVF7L2yt2MXfFLipr3f79fraxiP9+s53KWjdfFRSzeV9FxGt9uMSjY1EesMM2Xeibtzt0RaXUdIwVT5cuXeJw6OODqjo3m/ZWMKhzboPr7i2rYe2uMorKaxnUOZcuLZvx+CebmD62Oy0yU6NuW1pVT2pyEmnJSSQlKcAIpVIqbN0H562nZ7ssPt1YxMXDOjOyeysASqrqWFFYypgTW7G/opb22elB2xcUVZCZlsycZYWc3qctdW4vy3eUcPnoruwqqWb9njJO693Ov77Xq3nmswIm9G1LWrKL5z/fyik9W9MqM41vth4gPSWJuct3sW53GRcP78yfJvdl0aYiZvznO0qr67lhQk9WFJYyqntLrhnbneU7Svi6oJjqeg+/GNudOreXpz/dwvYDVXy2sYizBnRgzrJCfj+hJ9ef3oN/Lipgx4Eqrj+9BzVuLy2bpfLUwi38fcFmAP52ST6TB3TAlaSo92ge/nADz3xWAMAbvx5DWY2bFs1S6NU+i9veXENVvYdlWw9QVe+hqs5DndvLiG4tuXFiL/JyM7jv/fWUVNXRISedrPQUfjqyC79++Vs27C2nus7LhUPzePzjTRRX1PFVQTHFlXWcN6gjt5/bj9veWs37q/dw9oAObD9QyeebixmQl8OPB+dx9ztrASivcfN1QTFdWjbjxS+3MbZHa1xJioUbivjw/07h+/2VFB6s5vnPvyfVlcQVY7py+9w1tM9Op7rew7mDOtC6eRqrd5Yxf50RvDZZaTx2cT6pyUn86Y1V9GyXxTsrzes/ZXAeo09sxQufb2Xt7jJSk5Ooc3v9/1NcitvO6cvbK3fzzffGbuzcMoPLR3Xl/MEd+WD1Hm57a03Y8zfmxFZ8WVCM1pCZ6qKyzkPnlhm4lGJrcVXQuve9v97/u1OLDAoPVvuns9KS+fHgPFpmpvK/pTvYVVpD7/ZZrN9TDkDXVs3C9mdxSs82rN1VFvRRstMxJ50z+7XnhS+2AjDz9VUAtM9OZ9HN40lxxb8JU8UywIVSqivwjta6v8Oyd4C/aq0X+6Y/Bm7WWkftBjps2DB9vPcU3V5cRUaqizZZaf55y7YdYNGm/cwYfxLJriRq6j386uVlLNhQxNOXDaFnuyw27i0nMy2ZsT2Ce//uKa1h1H0f+6dbZqZyy6Te3PTaSs4e0J67zu9Ps1QXzVKTKa6opVXzwHEPVNYx5O6PyMvNYF95DXec148PVu9hX1kt7/12LDX1HqrrPbRolsqtb63mP19vDzp27/ZZ3HBmL/6+YDMrdpRwRp92zF+3l0n92nP/1IGkupL4f4sKeOSjjY7XYnjXFizZehCAf181gr9/spkz+rYlIzWZW99cTW6zFPp3zGHx5v0oBZEe29+MP5GnFm7ByTh/YOpAbpqzMuo9sejWOpN6jzfo5bfTJistyKqd0Lcdvdpl+YU+GoO75JKXm+EXvcbQISed3aXGskxScNaADry7cjcjurbkm63BFemWman+mkJoeRuieVoyFTYrc3yvNizYUOSfbpedRs92WSzatD/mfY7q3pIUV1LUbWae1Zv3V+9h+Y4S/7xBnXNpluLiy4LimI8F8O2tE3h31W5ufTO8+S8rPZnyGnfQvB+d1IoT2zTn5a+24dX4n2EwH6ZN+8pZvbMs6jHvnTKAOreHJxduwevVFFfWkaTg0YvzWbihCI9XM3fFLv5x6RDOHnBojgyl1DKt9TDHZXEQ9GeAhVrr//qmNwDjtNZRn1YRdOh6y7sAfPC7sbRunkZ6iov+t88D4LVfjWboCS35zSvf8u6qwKVsn53OHl9V8cP/O4We7bLYU1rDhr2myveH/60A4Hdn9OCx+ZuCXmqAsT1ac3rvttzxtrHY2mWnkd85l2XbSoIsjXbZaewtM9P5nXPZsKec6npP0Px4k9sshZKq+qjrXDqyC19uKaZgf2XQ/N+MP5EnF2zxTy++eTx3zF3L/HV7g6ysTi0ymDaiCw/O2wBA/7xs/0s6a/oo/jZ/ExW1blbtLPXv69pTT+TpTwP77pCTzr1TBnDlC0vCynd+fkeuPfVE3ly+k2c+LeC03m2prvPwZUExJ7bJZFT3Vvzx7D54tWbAHR8CRgTa56Rx3X++o7LO4z/m6X3a8p+vt5PfOZfz8zuSf9dHAPzy1O786tQT2VtWS6/2Wcz4z7e8s3I3E/q2o6rOzeebi3nhyuFsKark7nfWMvSEFjx2cT5/eXctH6/bx3Wn9eDR+RtJUqCUYlCnHK46uRub9lZwSs827C6tZmBeLj9/4RsKiiq5/vQe/H5CTxZtKuJnz31DcpJixe1nkpmWzCtfb8OlFMt3lFBQVMlfpvSnstZN11aZZKYl8/aKXcxasp3z8/O4cEgn0pKT+Hj9Pn50UivqPZoPVu/m4Q83MrZHG7q3yeQ3408CYPXOUt5fvZv2ORlMGZxH87Rk3l+1m/8u2cE/Lh1CVZ2b5CRj4aa4FF9sKSYtOYlPNxax40A1riR45mfDqHV7uPXN1Uwd2pkOOen8/ZPN/HRkFwZ2yuHOt9fSt0M2j87fyJU/6sr0U04EjCvrYFU9bbLS0Fqzbnc5fTpkoZRix4Eqxj6wAIC//Lg/43u3ZU9pNS2apTJ/3V5+Mba7v0a6emcp5zyxmBFdW/LqtaMB46K58X8r+OnILgzr2jLqsx6Jphb0ycAM4GxgJPC41npEQ/s8HgS9otbNVS8s4bZz+tI2O419ZbV4vJrzn/yc9387lrP+tijitr88tTu/PvUkBt1lXvrJAzvw3baD7CoN9vtdMDiP17/bCcDEfu1YsvUgC28cR1ZaMqPu+5i9ZbV0apHBwco6v1g4kZacxNgerZm/bl/Y/Fq311+ttbhhQk8ejmBtW/x8TFfqPV5e+Xo7ORkpDOyUw+7SGnq0bc7Fwztzx9w1fqH95+XDOKNvOzbuLecfCzaTkerC49W8urSQO8/rR4oriVe+3sZjF+fTIjOV5z//3i/gK+84k+z0FH4/ezmvf7eTtllpfPOnM/h+fyVPLtjMTRN78e8vt/GPhZv591UjOblHazbsKae0up4R3Vrywuffs2pnGQ9fNMiUZVEBf3l3HQB5uRl8dtN4Nu0r58Q2zSmvcdPS57qyPsgvXjWCK/71DQBvzziZAZ1y8Ho1G/eV07t9NuU19bz01TZ+OqILuc0Cbi9r+61/nQxAUXkty7YdZFL/9o7X87J/fs3izftZ+uczaG2rXR2srOPzLfs5u38H9pXXMmfZDn41LiCMlquupt6D26vJSHHx0do9jOvVlrTkJEeXGsCHa/bwr8+/518/H06z1GS01izevJ922en0bJcV9d4nEpHcipHWvfblZZw9oAPn5+c1uP4n6/fSp0M2HXIyDreYfg5L0JVS/wXGAa2BvcDtQAqA1vppZa7E3zGRMFXAlQ25W+DYEPSaeg8j7/2YW8/py9ShncKWf11QzMXPfkXbrDTaZaezamcpqa4k6jxepg7txJxlhTEd59VfjmZEt5Zs2FPOxMc+88/v3T6LHQeqgoR2xviT+MPEXgD85OkvWLL1IPdOGcDkAR0oqa7zb19TbxqeurXO5LkrhuHV0DE3nScXbGZlYSmLNu0nJyOFZX8+gwOVdWSkunB7NF/5qr1n9mvPe6t2k5acxPSXlgHw8E8GMXvpDq45uRufbizij2f3ITMtGa9X+33ydr7dfpAL/vEFf7sk3/HlqHV7eGv5Ln6cn0dqcri/saCoglaZaeQ0SwHgpS+3cutba+iYk84XM08PW/9gZV2D7QgA5TX1zFuzlx/ndyQ5ip/TEuQ1d07kq4JiPttYxB3n9YtZHF752lTtfzbqhJjWL62uZ3dpNb3bZ8e0vnBsctgWelNwLAj6pr3lTHjUCOSim8ZzoLKOQZ1zWburjPveX8e24iq2H3BuUGmblca+8lre+PUYZr6+yt8I48T6uyeRnuLC69V0/+N7ALxyzUh+dFJr3B4vj3+ymcc/3gTA57ecRl6usQZW7CjhucXf88DUgaSnuABT5XMlKb8YfX/f2WECdMfcNbzwxVaGndCCOb8a0+B1CLU0G8PeshraZqXFLILRmL92L9f8eynts9P56o/hgh5vbpqzgjnLCim4r/HnLQiHSjRBP2rpcxOVL7bsR2v40Umt2WdrZDrv74s5WFXPJcM7M2vJjqBtUl1JDOqcg1fDsm2m4c/atnvr5tx+bj9unLOC8b3acvHwzhQerGZlYQn/WGhcCpYYJyUpBuTlsGpnKZ1bNAMg2ZXE0BNa+I/V1tbAOqhzLo9PGxxUFpfPUh7UOZfy6npHIe3TwVSnf/6jrjFdk8cuzifXZyU3lnbZ6Ye0nRMdcs2+vEfISHlg6iAemDroiBxLEGJBBD0Cry7ZQdvsNMb1auuf9+nGIr+vdP7vTwmyvg/6GvMsMR/SJZdvt5uW+lV3nkmqK4nFm/fz8lfb6NMhm8fmbyIrPZmcZimMPrEVi28+zb+v/nk5TOzXjn8s3MJFw4JdOS9cOZyP1u6lS6tm/nmtbG6EWEOh3vz1mIiRIhcO6cSYE1vTuWUz5xVC+PHghn2JR4KOPj9lLOGdgnAsIoLugNaam14z4W1b/zoZj1dTVF7L1baohjMe+SxsuxeuHM5XBQd4+tMtXH96D37+vFk/LdlY2GN7tGFsjzYUV9Ty2PxNXH9aj4hlUEqx8S9nkRzie27VPI1LRgTH8LeMwS/stP9IXo5kV1LMYv5DokVmKrOnj6JfXs7RLoogHBVE0G2UVJnGv90lgUiSyY8voqLWzTZfNMZrvxrDhU994bj9mBNbM65XW6477SQy0yJf2lbN01h710QyfK6USDg1BDpxKIJ+rGJ1cBKE4xERdB8frN7NtS9/yzUndwuqsq/ZZWKU+3TIZurQTkH+6lAsAbbEfN7vTsEhuAOAZqnxu/SWjz0rXW6nIBzPHNcK4PZ4qXV7cSUpHptvokRW7SwlO8M08K2/exKvfL2dk09qTa/2gbjbHm2bs2lfBU9fNhSAa19e5rh/+zZNzau/HE2nFvGLdRUEIfE4rgX9T2+sZvbSHUzo284fNri3rIb9FbXkZKSQnuLi6pO7hW338jUjWbe7zN9gOufa0UHd6I8GI7odWq+zYx6tYd3b0HMSJEdxTW35BDrkQzO5jscN9dWw+WPoc87RLkncOK4HuJi91ESkfLR2L64kxbQRndlVUsPespqg/CqhtMtOD4p+Gda1Jd1aZzZ5eYVDoGAhvPozWPCXyOvUVcFLU+A/Fx2xYgk/AN77A8y+FPasOtoliRvHtaB3yAnEQP/lx/3p2zGHOo+XdbvLad38GG5oXPkqFG042qU4MlT5Ejod3BZ5nRpfIqhj6MUOo64KFj8KHnfD6x4v7PYlaqt3TsCWiBzXgm6PRBl2Qgu/D3r7gaqgXBnHHK//Ap5sMN3O8UNNacPrJDoL74X5d8CaN452SX441Pv6kdRG7qWdaBzXgl5UXsuUwXnM//0p9GiXRafcQKNiNJfLUWPTfPjq6cPbhzu2gRcisnYuLHvx8PbxQ6O6xHn+9q/h47uObFniycd3w9bPze8KX+pbb/RsljHz7b9hxaz47OtoUecT9JoI9z8SpTvh7d9CXWXD6y68HwqPXIqT407Qn1v8PeMfWsjiTfspra6nW+tMTmprolHybFEiP0gL/ZUL4YObD28fdYc5WsqrP4O3rz+8fRxJYkkD4H+hQ2JM35gOix6GfevDNvnBs38TLHrI+IgB3L6+Fclxeq7nXgdv/BK8kTN4/uCp9wlypA96JL5+Cpa9YP6iobWpGf2z6fMKWRw3gr56Zym/eeVbHvlwA9/vr+Sy574GgnOf2GPDe9nTg877E3z64BEra5NSGz1Bfxj71sML50BVtFEIfwCU7YLnJ0N5yJBolpA5dYvd8gm8eG7g3NzV8JVtSNxsX0qD9W87H/O7V4ywHQ7r3ob/Tju8fdgpXGYaeFe/ZqZdvrYgj69mpqJ0Zvv4Llj41+B5790ES5+PvM2Orw+9rJFYNQfm2oyG164xNcN447fQG+lyc/k0Y94fYdd3kddzN824AdE4bgT95a+28e6q3VTWefzW9wmtmjHmxNaO6wd1IPry79GjJI40h5N8qrH+wuUvw9ZF8PVhunqamm/+H2xbDEueC55f75ztEoBXfw7ffwYltgbTD24J/E7yiV9phDTHb/3auB4Oh9mXwYb34tdY+fxZ5kNlCWBtBXi9gQ+buybytosehoX3Bc/75hl453fB82psRkFRE9ReXrsavn3RCGJNGaz6n6kZxhN3XcD91FiXi91o2Lo4yjGOfGPrcSPo1ig/T0wbzKzpI5kyOI+3rzs5KMkVBBI7xZI3u0H+fT68PPXQtv36WXiwh7N4e+qMNfXYQHjpAvNnsWoO3JsHb/8O/uGQ+jZWQS/fA/d0hC+eMNObPw5eXrQB7siBPeHDex0VUn33MfT8ogm6x2dBVewNnm+5ESp9ETINWVr2KInyPXBXa/ji73BPB3ON1r8XWD7nKvMXSvkuuLOlWf/9BtxqNaVmvbVvhZfbOqd9vnE46yvh4PeBtpNYIjoeHwzz7wx/9p4dZ477186BeWW7ou9r9etmm+oSeOpk8+GNleItsD/6ICpBfHQ7PHNKbOvaRby6BB7uDZ89FNu2ZTshbyikZEY///ooH88m4rgR9A17yjk/vyPnDurISW2zePTifLLTw1O+zp4+itV3TjQTjakyOa1bsBA2f3RoBX7/Rqjc52wd1lUaa6pkG2z52PxZLH7U+MmXPW9eaq8n+MGyC140S3/vmoCPEYxP1msbjX2T77wsP2JTPbyx7tdym5T7XjCrOm3993qMFWy3hC03ROhLaVnsVb6xLxsSwUrbGJnL/2Msvw//FPiYfPFE4COx+jXzVxfyodn+FWjfOl8/be6N/Zmyl/3gVvN/4f1mv5ZYW/MtOvhS+26cF91C93qhxJby+UABLH4kuL2lusTZvdCQoM+/3fxf8v9g7yoT+21H68j3uGh9oAaQ0UCHL63h88dg94ro61nYP+IHt0L5bvjk7sA8T725rvayWfPKdkF2R/PndP71Nb7zimJMNBHHvKC/+MVW3vxuJ7tLa2Ia6SU9xUXztGTTMv2Xtqb62hBbPzfrWhEF8cQpXjxaw2aHkPzca9+Ce9oFBNgu6NGq36EPam1pQCwB0poH1tv1ne8Y8yPv71DY9qXZbyzXtcwMw8f+zbDtC7i3g9nOeqncNfC3QfBwr8A22veBKgsZ/rZoo3khq6JY6PYPQ5Vt8GKnKvj2L4yv3t6AuDVk+MFdy4OnFz1sninLv/twL2M523FXm1rgX3yDhYc+K91OgbZ9YdO8gOXuJDKf3A2PhY0uGdxYuHdN+PLMtoHrHgmr/J/YXJb2Z2vBveYeW9fYfl33bzJ/EHjeImEvX0Puq71r4OmTA9Pffxq+zj9PN9f1nnaB6/DUj+Afo4z4Z0UQ9Poas82Ce6O/X03EsS3o7lqemfspv5ttXpbhXSMn1gpj+5fmf6irwQnrgXB6MKBhK8ZO6U7j97Rw8lFGC5cKFfvvXjL/N/iq/fZG0Wit+05l3vFN4LdllZbthC1m0Fz/+ddVmfM4XAp8+136L2MZ1ZbD94uMxVxfbWovVQeMcFsdh0oL4f2bzO9tNkGvq4KywoDVbad8F7Q6CS7y+cPLCk2V3OsThoo9wVY4BFur+zcGagiWAAH0PT/we9vnUGgbVDpUIHeGhLZ9+aT5b32Aq/ZD6XbzobE6QNXXBD4MHjfsDxH07DxzXsUFgW2KNph7a/eDhx7bYrftI7Pq1fDlXUYGPydaGzeJHXuDY8ch5r/dOl7ic8EUbzGWcqmtplBVHHCNlGw3H+pIYm13P1k1S6fyQLCbsPs42wJlntuijcGW/q5vjStt/wY4sMW8Q81ametbttPcc3edKf/GD8w2S58Lr3mU7Yot1PEwOKZzudS98Ru+SP8fvWpeQKWkM7BTIwY+sKIBYgrL8kVQRHJhPNIH7oihJd3rhUf7Qtt+gXnFm8P3Ha1VPlSkS7b79u17EewWek0JZHdw3o+T5bXTloSswjeY9IGCQHnSfDWg2Zeams3tJc7RJbFinfPqOdC6hzm3r5+C0/5sLLql/4K8YcYCtagtDYhX2a6AlRSt+ltVDG36QO9zzH0v2xUs4Lu+gwdPDNxDrWGWLTLl9V+Y7W7ZbkTXol1/Iyh7fQLyr4mBZaHW9M6QBG/VVuRNSO3gq6dg3kzfMptgHPzePCvN20FWeyNILU80Hxt7mVbONn/ZefD7tc5lsZh9WeB3aIhen/Mgp5MxeLxeSEoyjZev/wJ+9iacOD58f/2mGHG0P6NpWVB90Fzjt34NrXsGltk/qmAafC/4fzDQIUXDpg8Dv+sqIT3HNFi/fT1cNQ+6jAosT7ElsRt6pXGNAqDN+xfKS1PC56XnQI5P0P8+DHK7BN4167xCn7lH+kC7AfCrKA2ph0lMFrpSapJSaoNSarNS6haH5ScopT5WSq1USi1USoWPmHwUSPK5S7Kpon/HnOD84sVb4MD3zhvWlgesKY+tI05op5yS7eZlUNZ+o/ikY4lisF68fTbrzbKo7S+2U7mtD0+o2FsWQU2ZCbOzd3JY905k/6WThW4/bsWeQPksS9pKfmW5qWpKoOBTY1WvmhPsg9/2ZfQawtbFgWOA2f6Az9qy/LlVxcEWXbJtOLu2/cy9sc6/IX9mRq6JasnqYCJErI9Ciq3R3LrGu1dAZRHkXxpYpj3hDXjpuc7ummatzP4321xU3gjPx8HvgyNp1tnC9+yCXrQeqg5Cs9Zw2evwiwVw0hlm2omynfDtS+aDHNoo3BBdx8KFz5mPbH2V2VfBwsA7s3uF+eiFuuByfY2p9gZJ6/parir7NawuCW/ktp7LbV8EarJejzn/TF9+pbpKX/uV7/i7vvN1hJrta1OytYmc8CP41ZfQ59zGXYOM3OCPj13MrfMKuj++89q7ytS+DhQ07ngx0qCFrpRyAU8CE4BCYIlSaq7Weq1ttYeAf2utX1RKnQbcB8Q5zqjx1LsySAayVBW/GX9S8MInfNU/J8v59ekBF4W9ilRfGZyx77EB5v/4P5n/0RoZ68ohowGXj5OlZD3Q9nIccKhG1lUYqyE0BMt6Wde+af7sLPiLEaazHwjfX8We8Hn2RjfLQodA9dQqY3K6eZi3fRlsyTZvB93GGpF7fpJ5IWbY3BAWZbvhhZCBl4s3BY7pqQtcK3sIWZtegbJ0HmHON3Wor7wNiFa6r/aWnGaONedKM92ye8DCLtlmpte+ZSzyCXcba9cS44MhH9qM3IDv2k7vyUZgXr7QuSyu1IAh8ck9xqq1KLf5++0fqeIt5mOekQuZrc0fBP63PDH8uZk7w2ShdKJFt/DzsWjTy7wHbXqb6TVvwEe3Bpa7a2DN6+HRPDm+kbbsH3LLVbXx/eB1m7Uy5xNaw6spNbWn588yNapLXjFi6q6B7uPNfrZ/Gdw/YNmLULTO/HalBLsd03OgeRtoFXn0MEfScyPXbsEYG/YPx5PDA7/n/RFSM82zFGdisdBHAJu11gVa6zpgFnB+yDp9Aav1cIHD8iPLhg9g/2ZqMPHmr1zWi/G92zqvu87XaaRku0laBcFJmuw+6Uj+r9Wvm//a67wcgoV5wX2mjHa2fQHLXwnfrqbMVHftX/Ty3eHrffey+R9q9TqVKatj4HdJhKRV1aXmYbdIzQoWhPI9gY43FqU7zctjiWNo+N0+30tlNSLu32j8jytmmfjxg1uNWDqGVirjTgEjApZlXm3r8GQJTFKKEZ3qgwErrfpg8O62hYw6leErc6jotbSlT96zGpb80whYt7GQ2Sr4GtWEdNpKzw2u1SkX/HE3DIrQkWj8n+GUm4JrhaEdpUIjWSyq9puPub08YIQRIvcQtRqcm7cPnh96byFguCT5osNa+xqYQxt466uDP/gWloW++BHznLrrTCQXhN+fnM7mfGrLjXDfut/UNmpKArXQ9e+YBFvWxz3P9/EOtX6L1kGLrsaCX/ov+OofgWWWgWZv2I6FjNzIH4GTf2/OP1onvt5Nk7I3FkHPA+zD2Bf65tlZAVjB0FOALKVU2FhgSqnpSqmlSqmlRUVFh1Le2PjvxfD3oVQrUwVvlxyltXn2ZebBeu0a4xAbGHIAACAASURBVP87UABJtoqLXcQjCbr19Y/mcrFEasUs+PSv4Z01nj8rPK64WWvY8ZXJG2H3Z4a+5GC++p766P51lWQstXMeDcwLFQCLmpJg4c/IDa5CVuwzgmXvebj8ZeOztKz70pBqqNXAa/dP/32Y6UL+7u9NFMqrl4fXMrqMgS6jA9N7I8S+t/EJTHJa4HckFj8WPG1dh8kPB+ZltAx8nMB0bnn3BmO5dh9n5qXaoi9CP0TpOTDxnsB0qxNNvHznkSb3eig5eYEPi0WsQlNZbEQyPWR7y0J3pYZvA6bmmNIMfvyP4PnZtnv/o9+aiJnUkEiTzFaQ3cl0zrLjrnGOxLLcPyXb4etnAoaJ3XVlkdPJ53IpM/5oV4q5ntUlwc/HM2MDjcF5viggp49e237GrbJ1UUDw2w8ILB/68/BtopGea+5lpxFw8v8Fu+ZyuwA63A1j0f/CwH2JM/GKcvkDcKpS6jvgVGAnENaaqLV+Vms9TGs9rE2bNnE6dAi2RsxqTONHUm2p8f8uuDfYj2vx30sCIrl2bvDDb//K1lWY5WtCXBcWDVnou1cY4QJf3OtfnMtj0dxWq7C7QELD7Cz+cxFRPyp5Q+H6b41v1WLVHOPjXnBv4EH3esx521/qUKGorwy8aLGQ09lY5F8/C6/8JPq6dsGfeC9c9X5wxEik3omWxeSyuQMAxt4QvJ6n3tzLTrZqsHV+w68J7Cc7L9gvb8dqAE63hcLWlAIq0KaSkQsDpsI5vo+H9ZFJcsEvHSKisjuaaxpU1hj7Qqz4j4nOCf0gWNZ0tBwurXvCSafD+TZRt+59UgpMuAuuiJD+oPfk8PC8mjLnNpgkm9ysfSuwjv15tMjtYq5nbXngmmTkBlvoFh/dZmoY2b6mO6eMkm16Qd/zgudda2uczBsCl/w3fLtIWAbANR/BGXfADbZn0roHlqbMsDV4//gpmPqv2I/TSGIR9J2ArWsYnXzz/Gitd2mtL9BaDwb+5JvXyP60ccJ2swtKfeJWU2Is4k/vDw7FstjyccD1ULwpWNArbTWJukpjpf3vCudj2xsYQ/3pteWmURICYvDZgybUL5LvPdP20WvbLxD2tc8hJhgCjZG5Jzgvt87LZauBaA+8eI65Nv/+sZlnXUO7jzBUKMAn6DH0qG0/ELqfalxZ79/o7J+3U2mrrlsiOGCqefEtK1E5PLrt+kG/C2DaLNO4OeAncNlr4aJcXx0IPXM6PysKIrNVQAiTQpqbUn0Dmkx5NjCvfI+5Jtb9tD4S1r7tHxmAM/8Cp98GQ64wll77geGCHo0hV5gon/YDA/NCP7x5Q6HnWXDu3yLvx/Ll2qM/LJdLQ8m8+jp4V6v2B8R6TIRcN/vWBMJc2zpEljRrZeLsqw8Grkl6rnk2nRrTm7cJ3BMnWnSFE042YZyRsI9WNW5m+PLLXg/8Dn0f0mwfdkvsLUG3W+P2a9wExCLoS4AeSqluSqlU4BIgKFOOUqq1Uv43bCbQdJ+ghrBVxya4lgXmWRe8odZlrzdY8OzW4ns3Rd922+fwvytNREtouOMrU01ejLyhMPKXgfkvXxA5bMyy0PueD7/+AqYvCK4ahr68FieFZHezXCcNZZUr2WYiAaxraHe5WA9pti2AKa15ZAs9b1jg97T/mrDAWHNmVNg+opafNrO1EWdLfNr0DiRJsmjeFn7yvImPVgou/Kf5CIQK+pu/8ll+9pfQdi0tYUjLDjTK5YQEblkvZru+cO7j5nfZTiM+VvXbumbpEQR9zHWm9nDe48bSa9YyEA3VeRSO2MX7vMfhFx8Hf/hDXWgp6fDTWdC2j/P+wLh67OcEgWfP/sG27rX9nncZFXx8MCGEGz+AHhPNRysSVn4ge03Qwi6Ydgt957JAg7Udrze6oGe2Me/1NVE6v1kfry6jYcjlwcvG/iH4vQoVZnvjrXW/rXBa+3OW0rQjmzUo6FprNzADmAesA17VWq9RSt2llLLqMOOADUqpjUA74B7HnR0BassdsgJWl5gvNDQs6NoT/BDbIwn8vnKcw/32rjat+5VFwQ1bdrLzgh887TWNO05YYVh2S7KLLT+L36dpe5jO/RskhzxsJ4w2jW0/ftL5OHbemO5soVsPabt+MOwqY/XlXxrZQrdvm5YVsLSbt2u4DJaFPub6cCG1Xrqs9gHLZ8BFxqIK9fH6twkR9PXvGJ+z3RpuaxNb62VNyw64xELLbX8xrf2U7TK/r/rANHCm+I7beQQM/4WzayGUnhON2+dcm4+/+3gYMd3Mn+aQgzyos1QUl9tPHToHgc0at10ny5Vkv7+DL4MRvwx2YSW5YNJfTXx1KB0Ghs+b+rwv5LGnsb5Ts8yxLn3NXDN/meyGg+/6RstDNOWp4Ps/8trghkfrWYlkBIH5WI65DqY8Y2p4Y/8Av/zMXHurpnH1R5E/Uuc8aoyOMLeXTWab2EKPqWOR1vo94L2QebfZfs8B5sS3aI1k2xfw8lSKxz1I2Pe+psTcIAjuyQemKm2PAfZ6An5HOz0mBndgCe2GbeeR3pF9jmlZ4cJjzyHhSgv4TS3xsq9vt2asmsRPnof//dz8Hvpzk+7XTmpzOC1kXiRcqQFL3h7pYD2kzdsGN6pGstAzbf7/1OYBQe9zrokUiUbFPmPlnnl3+DJLYFKamQ9d2U7jCx85PfL+nNwGdeXBgp7bJfDbsrDTsgLPRrOQNn77i2lZYGW7zIehw8BgMUvNhMkxJn5KzzYNs/Z0xa17wNlR0jfbRSpa6GzPicZ1F+qys54pf8OeCpyTPUw3JcM5xHWALwHda1cbt6BSxpJ2csf098VOrH3TtKlYH/4eZ5jOSFZW0za2GO9U332KlFMn/7LwlBdn3W/+3+GrsVj3L1pHtyRXsFif7gvFtO+78wjz58QwX5hmtFTTqc0iL4sDx05P0UUPQ30l3o0OVaqqA4EbWrrDNIpZNGsVHKOsPcEuF4usEAut3KHRx05oFAXAWQ+a3nJWwq6UzOAEWGBeLiv+17Ly7VU2u6D7G7wy4CcvBqr0oQ+tk+V61bzgnosWWR0C/s8sWyib5eoJDbmzBPakCUa0N35geizaH9wkl2kUnfwI9DrL7KtgIXz4ZxyxImicsI6XnB64pw1ZPZGWp2XBtNnG/+q0flpWIMokVNDt52d9GEI/EoeD3VoOdSVc/VGwuE15xvSbcNcERCUSl80xeX3qKmD5f01HF6v2YYl3bpfANQh1a0XC+vinZpqGv00fmp6yAJe/Ff4MtvCFg9rFMskWMWVvB+roM57Oe8IYbm/92kxbHye7UXHhc4H17djv38/eCH6n4o3d7TXlmeBlKSLoseFz4ddXOOTqqNwfcLls/xLutjVSpGUFBD2jRSArXyihcboNERpXm54TsCKtF9SpYS+zTUDQLXdDqxMDy4MsdEvc0qCXvYNIqKA7PERdRoV/UHpOMoJsvTDWi96yu7ESJzp40qzGwryhMH6mcVEVbw5/cJWC4VcHzqFZ6yiCvse5ERZsFnp6oBrdkNUTqWEvLSvkujkst9w/oWFm9vOzJ46K5PZpLNEEPdRCzO4QuLYNkd0Rhvoa9Xev8Am6rzZl3csTxwfOr6NDeGWk/YI5/9zOweXpPi58fevZjuSGsou7Za237Gb+rOdzyM9M/np7g7VVWwjFLrInnhbpLOKDveyDLgleJoIeIz5xVE7Vnar9kX3advdKZltfOlKHqp3dQp822xdvHaX3odUA2G+K8Z/aRdlJ0NsPhD0rg4VsxHTzIbL35rNbm1ZNItRHHGahR2qICameW1ZT7gkmVC2rPVz1YQM92nzHsqyksOp7BKKJ8IEC6DXZeZl1nJRmgap4Q8eKGHoYwZq23CxpWYHG7TCXi4OFDvGz/Ox+13h9JEKZ/IgRHOv+th9g/Ozdxxtr/bLXg3OgRMNyaUZrmLQz7Coj6r3ODp5/7eeBffzqy2BxtLh+ualhWDlYQiOQnDicnELxpIkF/djJtugTx4xahw5LVcVRBN32MCSnGZeLlX/DXt20VwF7TYrcIcfC8kP3Pge6/ijYfeEPvVOBkC3LpWF/IZJcxkXh9DAmp0dukGwf0hgVSRBC/a1Wr8h2/aCfL4Sxy8hwl0TwTnzl8V0rq+rd0IPb0PJIHYOs4ySnm7DCWPbVaEH3BJZbFqoVMmoRUdDj5HKxE6tINpa05uHWas+JAdfLSafHfuzkVPOOxNLoDebD3Hty+LPdvr/tOezr/By07GY+PlYEVN6Q8HX85Ypw748IDu+t+NBjwJbWNdfrYKHXlIYPKGBhtwCSXD4LvcYk7bnkFdOd3Vsfbnk5+RYvfjnQo9NyuTg1Gtot9Ks+MB0x/Hm0Y7AkbthgxNw6VuhI7gOmGlF+5/+MiynWl9K6FvZ43FixPi5+Cz0DbiwIDNoQtr7tulz3rUkLMNvWYzA0xM9fRstCzwj0PGwqQXelwrCrzbMQGvZnryml2vbT0If+UGgqQY83V77XtL7pUHqeaaz4aCGZv18X2ZhrSqx3NJTQCLQ4k/iCXrQBnpvgt7TTqHdez6m7PJjtcroYX6lyGQGqrzGujowWgYRa1nBkFqFC3Wl4iGvCZ7k63VS7oKfnmL9Yqo0WlrXf/wIT++7Ukahtn0Djb6wul/a+Bqq+P469LDrkPFv3NL9bnBCwoBui1Ynh19Puogo+oPmXnG5EPynZOY7ZTiQfeqRMhJbLJcnlq0U5CIaT6wsi+/4Ph4ZG6/mhEBpieiRo59Apyc6hGCfxICukzW3ARSanfFLTOkUS3+VidfyJlH7UonyXcW/csoMgKzjJBdctM7ms7RZ6qAikh1ge9uXZeXDl+86WoJOFbq3n1CjaGIZdDTN3GvF0wromkQQ91OXSebi5Pj0mNL4sdgv9pgKTYrUx5HaBy2391SJFuVjWc0ozE19/89ZAx5hI2MV3pm1IP6ceihCoVYR+ZP9kazOJ5JONFud8qNjz2AiJyZSnTWK2JibxLfSGRgCxUpGWFhpLKz3bvOBWh6Gk5IDPULlMRx93bXjVyJViqvtjfx+YtkhOM9OOgu5goVsW13iH7sUA3U6NbTxTpaIPzeUX9Ejr2ATdcnGEfrhixf6BO1Q/st2aiuRrtMTW6rQTy7FCy9Z+gKlRRbKWhl9jsjSGJtBKicEfG08L/aQzzDMXy3GFHzZJrib3n8MxIehRxtcEU/Up2W5E3R/yZhd0Jx96tXM1/TZbSGSQUPustVgFPSU9+ghGV8yNvKwxWIIeycdsWegXvwJ9DjWdp+VyiTFJVzTs1ypircLXc7MxvsjQde1JmZzodVZsI0w5EU8L/bLX4rcv4bjgGBD0cAtdZ3VEWR1/mrcLpLH0x23bXnB7tVolgafaCGFDnVWcGkWdLKlYhe6k040PPjQz4OFgCXpDLf2xJNhqiEPZx4jpwRa2fR+Rcl5YLpeGkkbZacy6DXHGnc4DJls0hQ9dEGLkmBR01XEw9L3D5CVJSjGddSqLbDHMNoGzC3qSK2C5NyQCdqFWjbTQnWjWEq7/ruH1GoNlgTvF8poVzL/Dsa5DG0UbQ2h39qBEUBEeTW8E/3Y04hm6dvLvoi9viigXQYiRxG8UdXK5pGTYclDoQBSEk4VuH6BBuYKHUYuGk+DbhdMKZYuH9XuoXPIfX+ekbs7LD0eMQzlS+7BcLhE/Ug7E00JviKZoFBWEGDkGBL0yPFoktVnAJaK9gTSwVgxzaEiRRVIjBD0olMwh4sHqkOKJEEZ5JGjb21jBEUOl4uH/DulYdDgkxyLoPgtdNULQj2QvwSbOpicI0Tg2BD0ti4fTfsOaZiPNvJRmAXHQXtswXD7hmvK0c9VY2V0uDQj6aX+OPi7gT14wgxe06xfzqRw14tKgGedG0Uj4XS6NfHTPf9J0QmkqfvWFOcYPpYu5cFxyTAi6Tm3Ov+vGsTPHyrKmgi10S7wtwchsHWh8tL+ASUmx+9DTmgcGzXV6ia1j/JBf8Li6XOJgocdSDqvzSmNdG4Mva7gTyuHQrp85hiAcRRK/UbS+ktqkDEqr68lp0Rp2m3l+QdbaOfLAqcpunxdL1bkxDXM/SOIg6DqOYYux+MXPut9EBHUa1vC6gnCccUxY6AfrU0h1JTGgm89XXl9tE1sdsObsow85ibFdUI5kQ9rRJh5iHEsOmniQmmkyWAqCEEaim5hQV0m5N42Ouek0y/T1iKyrCjSUam8gH4s9xNHJGrRb6DGFulk9LW1i9tuVifcxOCyXS5QRcgRBOKLEZKErpSYppTYopTYrpW5xWN5FKbVAKfWdUmqlUupsp/00CXUVVOlUWmamBnJzdD814Lu2+9CDLHQHQU9qpKBbyZ1623J3tzghchTND5XDEfQ+55r/8UyC1Gl4/PYlCMcRDVroSikX8CQwASgEliil5mqt19pW+zNm8OinlFJ9MeOPdm2C8objrqPCk0nLzDQzqs4NG80ILHtXm+Xa5nKpc3K52Kzrxlroma3gxi2BGkCicjgul9NvN4M5x0vQb97a5ClGBeFYJRYLfQSwWWtdoLWuA2YBoaO/asDK6pQDNDDgZhzx1FHlUbTMtGLM2xnr3IqGGHZlBAvdyYduH507xt6Fma0b18nlh8jhWOhJrvDh2Q6HjBaSjEoQDpFYfOh5wA7bdCEwMmSdO4APlVLXAZmA40CBSqnpwHSALl26OK3SaLSnjgq3y1jodjJaBBIsle40/+2C3lCUy1Ed6eQIczR7swqCEDfiFeUyDXhBa90JOBt4SanwZN9a62e11sO01sPatIk2rFnsaHctNV4XrTKjiFLztma80In3BuZZVrVS4fMg8Ro2D4VzHze9aBO9hiEIAhCbhb4T6Gyb7uSbZ+dqYBKA1vpLpVQ60BrYF49CRkN76qkjhRbRBN2VAjduCp5nuVzsgzwEWejHgR936BWBEeAFQUh4YrHQlwA9lFLdlFKpwCVAaMLu7cDpAEqpPkA64DBac/zx1tdQTzIntW3kyOhOowUdbxa6IAjHFA0KutbaDcwA5gHrMNEsa5RSdymlzvOtdgPwC6XUCuC/wM+1Dh3frInw1NMquzn5nRvZFdxytdhdLpbIu9J+2F32BUEQHIipY5HW+j1MKKJ93m2232uBH8W3aDHg9ZKCmxbZjbTOIXw8TQhY6BJlIQhCApLQXf8rqqsBaJYRJ3+35UM/niJcBEE4ZkhoQd9zoAyAzGZxGnw1SQRdEITEJaEFfe9BI+hZmXESdLHQBUFIYBJa0PeXlgOQ1TzCgMKNxW+hS4SLIAiJR0ILekWl6fmZGTcfuu9yyDBigiAkIAkt6NU1plE0Ne1QXCRRolzEQhcEIQFJaEGv8UW5qMMRYOWQbVF86IIgJCCJLeg+Cz1uyaUkykUQhAQmoQW99nAEvdMI83/Y1YF5YqELgpDAJO4QdFoz+eBL5vehCHp2h0B6XQvxoQuCkMAkroW+ZyX5dd+a3/ESYIlyEQQhgUlcQV/3TuB3XEatRyx0QRASmsQV9JLtgd+ueFnolqCLhS4IQuKRsILu9XoCE3GPchELXRCExCNhBd3tsQt6nFwuEuUiCEICk7CCXu92ByacRh86FCQfuiAICUzCCrrb7aZQt+a7k5+B3M4NbxAL1odBLHRBEBKQhBX0ereHCp1BXfcJ8dup9BQVBCGBSVhB93g8eEkiOyNO/nMQH7ogCAlNTIKulJqklNqglNqslLrFYfmjSqnlvr+NSqmS+Bc1GLfHgxcVX0EXC10QhASmwa7/SikX8CQwASgEliil5voGhgZAa/1/tvWvAwY3QVmD8LjdeFFkpccxe4GSsEVBEBKXWCz0EcBmrXWB1roOmAWcH2X9acB/41G4aHg8HjSK5qlxFPSW3SCjpfkvCIKQYMQi6HnADtt0oW9eGEqpE4BuwCcRlk9XSi1VSi0tKipqbFmD8Hg9qCQXSUmq4ZVjpXUPuPl7yOkUv30KgiAcIeLdKHoJMEdr7XFaqLV+Vms9TGs9rE2bNod1II/HE3CRCIIgCDEJ+k7AHujdyTfPiUs4Au4WAK29qKSEDdIRBEGIO7Eo4hKgh1Kqm1IqFSPac0NXUkr1BloAX8a3iBHweuLXQ1QQBOEYoEFF1Fq7gRnAPGAd8KrWeo1S6i6l1Hm2VS8BZmmtHUZfbgK0VwRdEATBRkwhIlrr94D3QubdFjJ9R/yKFUOZvF5UUhxj0AVBEBKcxDVxxUIXBEEIImEVUWsvSqJcBEEQ/CTsINFKe0GiXARBEPwkriJK2KIgCEIQiauI2osSH7ogCIKfxFVE7UW5EtZjJAiCEHcSUtC11iix0AVBEIJISEWs92iS8JIkPnRBEAQ/CamINW4PSWiSkiRsURAEwSIhBb223otCS5SLIAiCjYRUxJp6j3G5uMRCFwRBsEhIQa91e3HhFZeLIAiCjQQVdA9JSnzogiAIdhJS0Gt8PnSJchEEQQiQkIpY5/aaKBfxoQuCIPhJSEF3e70k4UWJy0UQBMFPQvadd/s6Fkm2RUEQhAAJKej1HuNyQSx0QRAEPzGZuEqpSUqpDUqpzUqpWyKsc5FSaq1Sao1S6j/xLWYwbq/29RQVC10QBMGiQQtdmWGBngQmAIXAEqXUXK31Wts6PYCZwI+01geVUm2bqsBgWehetIxYJAiC4CcWE3cEsFlrXaC1rgNmAeeHrPML4Emt9UEArfW++BYzGJOcS6JcBEEQ7MQi6HnADtt0oW+enZ5AT6XU50qpr5RSk+JVQCfcPgtdXC6CIAgB4tUomgz0AMYBnYDPlFIDtNYl9pWUUtOB6QBdunQ55IPV+3zoXmkUFQRB8BOLibsT6Gyb7uSbZ6cQmKu1rtdafw9sxAh8EFrrZ7XWw7TWw9q0aXOoZfZZ6BqXWOiCIAh+YlHEJUAPpVQ3pVQqcAkwN2SdNzHWOUqp1hgXTEEcyxmE26NReFHiQxcEQfDToKBrrd3ADGAesA54VWu9Ril1l1LqPN9q84BipdRaYAFwo9a6uKkKXe812RZd4nIRBEHwE5MPXWv9HvBeyLzbbL818HvfX5Pj9mhcSnzogiAIdhLSCe12ewBkxCJBEAQbCamIbq8l6GKhC4IgWCSkoHt8FjoqIYsvCILQJCSkIno8bvNDBF0QBMFPQiqi2yMWuiAIQigJqYjichEEQQgnIRXRahQVQRcEQQiQkIrotVwuEuUiCILgJzEF3SuNooIgCKEkpCK6PV7zQwRdEATBT0Iqot/lotTRLYggCMIPiIQUdI80igqCIISRkIro9XcskkZRQRAEiwQVdPGhC4IghJKQiuiRnqKCIAhhJKQiesRCFwRBCCMhFVHi0AVBEMJJSEXUXukpKgiCEEpiCrq2XC4Shy4IgmARk6ArpSYppTYopTYrpW5xWP5zpVSRUmq57++a+Bc1QEDQE/J7JAiC0CQ0OEi0UsoFPAlMAAqBJUqpuVrrtSGrztZaz2iCMobj1b7CiaALgiBYxKKII4DNWusCrXUdMAs4v2mLFR2lJWxREAQhlFgUMQ/YYZsu9M0L5UKl1Eql1BylVGenHSmlpiulliqllhYVFR1CcQ0Bl4s0igqCIFjEy8R9G+iqtR4IfAS86LSS1vpZrfUwrfWwNm3aHPrRxIcuCIIQRiyKuBOwW9ydfPP8aK2Ltda1vsl/AkPjU7wIiKALgiCEEYsiLgF6KKW6KaVSgUuAufYVlFIdbJPnAeviV0QHRNAFQRDCaDDKRWvtVkrNAOYBLuBfWus1Sqm7gKVa67nA9Uqp8wA3cAD4eROWGbTkQxcEQQilQUEH0Fq/B7wXMu822++ZwMz4Fi0ySmtQiIUuCIJgIzEVUbr+C4IghJGQgq6wXC4i6IIgCBYJKehJVqOoWOiCIAh+ElLQlXQsEgRBCCMhBV2ScwmCIISTcIqotcaF5XJJuOILgiA0GQmniB6vTdDF5SIIguAn4QTdqyEJaRQVBEEIJQEFXSx0QRAEJxJS0MVCFwRBCCfhBD3Yh55wxRcEQWgyEk4RvRpcSix0QRCEUBJP0L0ahTWmqAi6IAiCReIJuhaXiyAIghMJp4ieoI5FYqELgiBYJJyga3scurhcBEEQ/CScoAdFuYiFLgiC4CfhBF186IIgCM4knCJ6vdL1XxAEwYmYBF0pNUkptUEptVkpdUuU9S5USmml1LD4FTEY6fovCILgTIOCrpRyAU8CZwF9gWlKqb4O62UBvwW+jnch7Xik678gCIIjsVjoI4DNWusCrXUdMAs432G9u4H7gZo4li8MrTVJ0rFIEAQhjFgEPQ/YYZsu9M3zo5QaAnTWWr8bbUdKqelKqaVKqaVFRUWNLiyAx4s0igqCIDhw2IqolEoCHgFuaGhdrfWzWuthWuthbdq0OaTjebUmScmIRYIgCKEkx7DOTqCzbbqTb55FFtAfWKiUAmgPzFVKnae1XhqvglpYcehe5Uq8EB3hmKK+vp7CwkJqaprUyygcp6Snp9OpUydSUlJi3iYWQV8C9FBKdcMI+SXAT62FWutSoLU1rZRaCPyhKcTcHM/nchF3i3CUKSwsJCsri65du+IzZgQhLmitKS4uprCwkG7dusW8XYOqqLV2AzOAecA64FWt9Rql1F1KqfMOucSHiBXloqVBVDjK1NTU0KpVKxFzIe4opWjVqlWja3+xWOhord8D3guZd1uEdcc1qgSNxIpDF0EXfgiImAtNxaE8Wwnnt/BauVzE5SIIghBEwqmi15dtUSx0QRCEYBJO0D1eX8cisdAFgebNmx+xY917771B02PGjDnkfY0bN45evXoxaNAghg8fzvLlyw9pP0opbrghEDH90EMPcccdd0TdZuHChXzxxRcAfPrpp4wePTpoudvtpl27duzatYsbb7yR3r17M3DgQKZMmUJJSckhlfNIEZMP/YeE9vvQRdCFHw53vr2GtbvK4rrPvh2zuf3cfnHd5+Fw77338sc//tE/bYniofLKK68wbNgwnn/+eW688UY+lNWckAAADw1JREFU+uijRu8jLS2N119/nZkzZ9K6deuGN8AIevPmzRkzZgxjx46lsLCQbdu2ccIJJwAwf/58+vXrR8eOHZkwYQL33XcfycnJ3Hzzzdx3333cf//9jS7nkSLhVNGfy0XyuAiCn4ULFzJu3DimTp1K7969ufTSS9HapMhYsmQJY8aMYdCgQYwYMYLy8nI8Hg833ngjw4cPZ+DAgTzzzDP+/ZxyyilMnjyZXr16ce211+L1ernllluorq4mPz+fSy+9FAjUDrTW3HjjjfTv358BAwYwe/bsBstkZ/To0ezcabq2VFZWctVVVzFixAgGDx7MW2+9BcCaNWsYMWIE+fn5DBw4kE2bNgGQnJzM9OnTefTRR8P2W1RUxIUXXsjw4cMZPnw4n3/+OVu3buXpp5/m0UcfJT8/n88//5yLLrqIWbNm+bebNWsW06ZNA+DMM88kOdnYvaNGjaKwsDDiPdi6dStjx45lyJAhDBkyJOiDd//99zNgwAAGDRrELbeY/IabN2/mjDPOYNCgQQwZMoQtW7ZEv8mxoLU+Kn9Dhw7Vh8LCDfv0q386R9c+0PuQtheEeLF27dqjXQSdmZmptdZ6wYIFOjs7W+/YsUN7PB49atQovWjRIl1bW6u7deumv/nmG6211qWlpbq+vl4/88wz+u6779Zaa11TU6OHDh2qCwoK9IIFC3RaWpresmWLdrvd+owzztD/+9//go4Veuw5c+boM844Q7vdbr1nzx7duXNnvWvXrohl0lrrU089VS9ZskRrrfWjjz6qZ86cqbXWeubMmfqll17SWmt98OBB3aNHD11RUaFnzJihX375Za211rW1tbqqqspfhtLSUn3CCSfokpIS/eCDD+rbb79da631tGnT/Mfbtm2b7t3baMbtt9+uH3zwQf95LFmyROfn5/uvRZs2bXRxcXHYtT7nnHP8ZXOisrJSV1dXa6213rhxo7Y07r333tOjR4/WlZWVWmvt3/eIESP066+/rrXWurq62r/cjtMzBizVEXQ14VwuXq/p+i8uF0EIZsSIEXTq1AmA/Px8tm7dSk5ODh06dGD48OEAZGdnA/Dhhx+ycuVK5syZA0BpaSmbNm0iNTWVESNG0L17dwCmTZvG4sWLmTp1asTjLl68mGnTpuFyuWjXrh2nnnoqS5YsITs727FMJ598MgCXXnopdXV1VFRU+H3oH374IXPnzuWhhx4CTKz/9u3bGT16NPfccw+FhYVccMEF9OjRw3/87OxsLr/8ch5//HEyMjL88+fPn8/atWv902VlZVRUVISVf9iwYVRUVLBhwwbWrVvHyJEjadmyZdA699xzD8nJyf7aiRP19fXMmDGD5cuX43K52Lhxo78cV155Jc2aNQOgZcuWlJeXs3PnTqZMmQKYXqHxIPEE3cqHLi4XQQgiLS3N/9vlcuF2uyOuq7XmiSeeYOLEiUHzFy5cGBb/fDix9tHK9MorrzB06FBuvPFGrrvuOl5//XW01rz22mv06tUraD99+vRh5MiRvPvuu5x99tk888wznHbaaf7lv/vd7xgyZAhXXnmlf57X6+Wrr76KSSynTZvGrFmzWLdund/dYvHCCy/wzjvv8PHHH0e9Fo8++ijt2rVjxYoVeL3euIl0Y0g4M9c/pqiELQpCg/Tq1Yvdu3ezZMkSAMrLy3G73UycOJGnnnqK+vp6ADZu3EhlZSUA33zzDd9//z1er5fZs2f7LeqUlBT/+nbGjh3L7Nmz8Xg8FBUV8dlnnzFixIiYyqeU4u677+arr75i/fr1TJw4kSeeeMLva//uu+8AKCgooHv37lx//fWcf/75rFy5Mmg/LVu25KKLLuK5557zzzvzzDN54okn/NNWLSArK4vy8vKg7adNm8bLL7/MJ598wvnnB7KDf/DBBzzwwAPMnTvXb2FHorS0lA4dOpCUlMRLL72Ex+MBYMKECTz//PNUVVUBcODAAbKysujUqRNvvvkmALW1tf7lh0PCCboVhy6CLggNk5qayuzZs7nuuusYNGgQEyZMoKamhmuuuYa+ffsyZMgQ+vfvzy9/+Uu/9Tx8+HBmzJhBnz596Natm98tMH36dAYOHBjmdpgyZQoDBw5k0KBBnHbaaTzwwAO0b98+5jJmZGRwww038OCDD3LrrbdSX1/PwIED6devH7feeisAr776Kv379yc/P5/Vq1dz+eWXh+3nhhtuYP/+/f7pxx9/nKVLlzJw4ED69u3L008/DcC5557LG2+8QX5+PosWLQJMDSAzM5PTTjuNzMxM/z5mzJhBeXk5EyZMID8/n2uvvTbiefz617/mxRdfZNCgQaxfv96/n0mTJnHeeecxbNgw8vPz/e6kl156iccff5yBAwcyZswY9uzZE/M1i4SyvoRHmmHDhumlSxufv+u9VbtRr/6M8W3KSL/+myYomSDExrp16+jTp8/RLkZcWbhwIQ899BDvvPPO0S6KgPMzppRaprV2HOYzAS1043JR0igqCIIQRMI1ipqeotL1XxCagnHjxjFu3LijXYwfNPPmzePmm28OmtetWzfeeOONo1SiAAkn6FY+dCVRLoIgHAUmTpwYFh30QyHh/BYS5SIIguBMwgm6V7r+C4IgOJKQgu5Ci6ALgiCEkICCDklKBrgQBEEIJSZVVEpNUkptUEptVkrd4rD8WqXUKqXUcqXUYqVU3/gX1WD50KVRVBAkH3oi50NfuHAh55xzTtz2BzFEuSilXMCTwASgEFiilJqrtV5rW+0/WuunfeufBzwCTIprSX1o8aELP0TevwX2rIrvPtsPgLP+Gt99HgaSD/3YyIc+AtistS7QWtcBs4Dz7Store2Z/TOBJut+asWhi8tFEAJIPvSjnw991KhRrFmzxj89btw4li5dyjfffMPo0aMZPHgwY8aMYcOGDQ3ez0MmUl5d6w+YCvzTNv0z4O8O6/0G2ALsAHpE2Nd0YCmwtEuXLhHzCkfjuUUFeuWtA3Xdixce0vaCEC8kH7rkQ7fzyCOP6Ntuu01rrfWuXbt0z549g6651lp/9NFH+oILLvDfs8mTJ0fcn9ZHMR+61vpJ4Eml1E+BPwNXOKzzLPAsmFwuh3IciXIRBGckH/rRzYd+0UUXceaZZ3LnnXfy6quv+q9ZaWkpV1xxBZs2bUIp5ZixMl7EIug7gc626U6+eZGYBTx1OIWKhuVykUZRQQhG8qEf3XzoeXl5tGrVipUrVzJ79mx/dsdbb72V8ePH88Ybb7B169YmTa0QiyN6CdBDKdVNKZUKXALMta+glOphm5wMbIpfEYNp1TyNZsmIoAtCDEg+9COXDx3g4osv5oEHHqC0tJSBAwcCxkLPy8sDzMehKWlQ0LXWbmAGMA9YB7yqtV6jlLrLF9ECMEMptUYptRz4PQ7ulngxVS2gi3cHLlfCpaERhCOO5EM/cvnQAaZOncqsWbO46KKL/PNuuukmZs6cyeDBg6PWmuJBwuVDZ/27sHI2DLkCTjo9/gUThBiRfOhCU9PYfOiJZ+b2nmz+BEEQhCAST9AFQWgyJB96w0g+dEE4RtFaH1YUiJB4HKl86IfiDpfuloJwiKSnp1NcXHxIL54gRENrTXFxcUwhl3bEQheEQ6RTp04UFhZSVFR0tIsiHIOkp6f7O2XFigi6IBwiKSkpdOvW7WgXQxD8iMtFEAThGEEEXRAE4RhBBF0QBOEY4aj1FFVKFQHbDnHz1sD+Btc6tpBzPj6Qcz4+OJxzPkFr3cZpwVET9MNBKbU0UtfXYxU55+MDOefjg6Y6Z3G5CIIgHCOIoAuCIBwjJKqgP3u0C3AUkHM+PpBzPj5oknNOSB+6IAiCEE6iWuiCIAhCCCLogiAIxwgJJ+hKqUlKqQ1Kqc1KqVuOdnnihVLqX0qpfUqp1bZ5LZVSHymlNvn+t/DNV0qpx33XYKVSasjRK/mho5TqrJRaoJRa6xvC8Le++cfseSul0pVS3yilVvjO+U7f/G5Kqa995zbbN34vSqk03/Rm3/KuR7P8h4pSyqWU+k4p9Y5v+pg+XwCl1Fal1Cql1HKl1FLfvCZ9thNK0JVSLuBJ4CygLzBNKdX36JYqbrwATAqZdwvwsda6B/CxbxrM+ffw/U0HnjpCZYw3buAGrXVfYBTwG9/9PJbPuxY4TWs9CMgHJimlRgH3A49qrU8CDgJX+9a/Gjjom/+ob71E5LeYMYktjvXztRivtc63xZw37bOttU6YP2A0MM82PROYebTLFcfz68r/b+/sWauIgjD8vBC/FYNRQzCCBAQrURA/MEUQtAhilUIRTCFYWwki+BNESwtLURAVQyqjsVaJRo3EaAIBDdELQmIrOhY7e1mCFiZulj3OA8udM+cU8y7nzj07Z/cujBXaE0CH2x3AhNvXgVO/G1fnA3gAHP1fdANrgRfAAbKnBlvc35znZC9nP+R2i49T1bH/pc5OT15HgEFAKest6J4GNi/wlTq3a7VCB7YBHwvtT+5LlXYzm3X7M9DudnLnwS+t9wJPSVy3lx9GgQYwBEwBc2aWvxK+qKup2fvngbbljXjJXAUuAD+93UbaenMMeChpRNI595U6t+P/0GuCmZmkJO8xlbQeuAucN7NvxVe6pajbzH4AeyS1AveBXRWHVBqSjgMNMxuR1FN1PMtMt5nNSNoKDEl6V+wsY27XbYU+A2wvtDvdlypfJHUA+GfD/cmcB0kryJL5TTO75+7kdQOY2RzwhKzk0CopX2AVdTU1e/9G4Osyh7oUDgMnJE0Dt8nKLtdIV28TM5vxzwbZD/d+Sp7bdUvoz4GdvkO+EjgJDFQcU5kMAP1u95PVmHP/Gd8ZPwjMFy7jaoOypfgNYNzMrhS6ktUtaYuvzJG0hmzPYJwssff5sIWa83PRBwybF1nrgJldNLNOM9tB9n0dNrPTJKo3R9I6SRtyGzgGjFH23K5642ARGw29wHuyuuOlquP5h7puAbPAd7L62Vmy2uFj4APwCNjkY0V2t88U8AbYV3X8i9TcTVZnfA2M+tGbsm5gN/DSNY8Bl93fBTwDJoE7wCr3r/b2pPd3Va1hCdp7gMH/Qa/re+XH2zxXlT2349H/IAiCRKhbySUIgiD4A5HQgyAIEiESehAEQSJEQg+CIEiESOhBEASJEAk9CIIgESKhB0EQJMIvZ9MQbVNcTwcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "InceptionResNetV2_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionResNetV2_3.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa49260f-77aa-48e0-dc64-5fe73cbc6d9a"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adcb18c6-dcfb-4778-d5dd-3251df8ebad3"
      },
      "source": [
        "InceptionResNetV2_predict = InceptionResNetV2_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2d29c058-59de-453e-85b0-b5c55e5b33f2"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')\n",
        "submission.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2049</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2050</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2051</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2052</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2053</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  digit\n",
              "0  2049      0\n",
              "1  2050      0\n",
              "2  2051      0\n",
              "3  2052      0\n",
              "4  2053      0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"InceptionResNetV2_predict\"] = InceptionResNetV2_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['InceptionResNetV2_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d98d255a-f824-4d8d-ec4e-f67467b11c7d"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/InceptionResNetV2_3.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/InceptionResNetV2_3.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9718dc9e-97fd-4791-bae9-d7c37c5108b5\", \"InceptionResNetV2_3.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}