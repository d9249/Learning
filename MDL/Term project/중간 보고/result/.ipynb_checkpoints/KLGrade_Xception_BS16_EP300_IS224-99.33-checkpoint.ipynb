{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18af0544",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/d9249/MDL/blob/main/KLGrade_DenseNet121-91.83.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b90db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10662605877982022121\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22727688192\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 18086061693943596665\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ts26D3gLnyLd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ts26D3gLnyLd",
    "outputId": "f4f6fa8d-223f-4028-b18f-b8da4113b6d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  3 16:30:06 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 461.72       Driver Version: 461.72       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3090   WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   44C    P2    37W / 350W |    599MiB / 24576MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3060      C   ...onda3\\envs\\MDL\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-picnic",
   "metadata": {
    "id": "decreased-picnic",
    "papermill": {
     "duration": 0.028073,
     "end_time": "2021-05-30T18:39:27.966668",
     "exception": false,
     "start_time": "2021-05-30T18:39:27.938595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Short description\n",
    "This notebook is a part of [Data Sprint #35: Osteoarthritis Knee X-ray](https://dphi.tech/challenges/data-sprint-35-osteoarthritis-knee-x-ray/81/leaderboard/datathon/) challenge hosted on [dphi.tech](https://dphi.tech/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-monaco",
   "metadata": {
    "id": "million-monaco",
    "papermill": {
     "duration": 0.026241,
     "end_time": "2021-05-30T18:39:28.019714",
     "exception": false,
     "start_time": "2021-05-30T18:39:27.993473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing dependencies\n",
    "\n",
    "## 종속성을 가져오는 중 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "floating-cincinnati",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:28.086573Z",
     "iopub.status.busy": "2021-05-30T18:39:28.085923Z",
     "iopub.status.idle": "2021-05-30T18:39:32.847126Z",
     "shell.execute_reply": "2021-05-30T18:39:32.846068Z",
     "shell.execute_reply.started": "2021-05-30T09:28:36.967323Z"
    },
    "id": "floating-cincinnati",
    "papermill": {
     "duration": 4.80129,
     "end_time": "2021-05-30T18:39:32.847355",
     "exception": false,
     "start_time": "2021-05-30T18:39:28.046065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-discipline",
   "metadata": {
    "id": "express-discipline",
    "papermill": {
     "duration": 0.026573,
     "end_time": "2021-05-30T18:39:32.900510",
     "exception": false,
     "start_time": "2021-05-30T18:39:32.873937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Basic Idea\n",
    "The Basic idea is to use external data present in kaggle here: [Kaggle: Knee Osteoarthritis Dataset with KL Grading - 2018](https://www.kaggle.com/tommyngx/kneeoa)\n",
    "\n",
    "As we have labels for train, validation and test, we will combine all splits into one and test it on dataset provided by the compitition team, this will make sure kaggle dataset and compitition dataset has same data distribution.\n",
    "\n",
    "If train(kaggle dataset) and test (compition dataset) data has same distribution then their metric score should be roughy be the same (accuracy score in our case).\n",
    "\n",
    "# 기본 아이디어\n",
    "기본 아이디어는 여기 카글에 있는 외부 데이터를 사용하는 것이다. [Kaggle: KL Grading이 있는 무릎 골관절염 데이터 세트 - 2018](https://www.kaggle.com/tommyngx/kneeoa)\n",
    "\n",
    "교육, 검증 및 테스트를 위한 레이블이 있으므로 모든 분할을 하나로 결합하고 구성 팀에서 제공하는 데이터 세트에서 테스트합니다. 이렇게 하면 Kaggle 데이터 세트와 구성 데이터 세트가 동일한 데이터 분포를 갖출 수 있습니다.\n",
    "\n",
    "열차(카글 데이터 세트)와 테스트(컴포지션 데이터 세트) 데이터의 분포가 동일하면 메트릭 점수가 대략 같아야 한다(우리의 경우 정확도 점수)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-prague",
   "metadata": {
    "id": "rotary-prague",
    "papermill": {
     "duration": 0.025647,
     "end_time": "2021-05-30T18:39:32.952047",
     "exception": false,
     "start_time": "2021-05-30T18:39:32.926400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read And Combining train dataset (kaggle dataset)\n",
    "\n",
    "# 열차 데이터 세트 읽기 및 결합 (Kaggle 데이터 세트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "emotional-valuable",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:33.012157Z",
     "iopub.status.busy": "2021-05-30T18:39:33.011596Z",
     "iopub.status.idle": "2021-05-30T18:39:35.556063Z",
     "shell.execute_reply": "2021-05-30T18:39:35.555555Z",
     "shell.execute_reply.started": "2021-05-30T09:28:38.947982Z"
    },
    "id": "emotional-valuable",
    "papermill": {
     "duration": 2.57776,
     "end_time": "2021-05-30T18:39:35.556225",
     "exception": false,
     "start_time": "2021-05-30T18:39:32.978465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of class\n",
    "n_class = 5\n",
    "\n",
    "# path to kaggle dataset\n",
    "root_path = \"C:\\\\Users\\\\ngkim\\\\Downloads\\\\ClsKLData\\\\kneeKL224\\\\\"\n",
    "\n",
    "# list of folders\n",
    "folder_list = os.listdir(root_path)\n",
    "image_path_list = []\n",
    "label_list = []\n",
    "\n",
    "# for each folder, get the image path and labels\n",
    "for folder in folder_list:\n",
    "    for label in range(n_class):\n",
    "        \n",
    "        # get all the images path inside the current folder\n",
    "        image_list = os.listdir(f\"{root_path}{folder}/{label}\")\n",
    "        # add to the image path list\n",
    "        image_path_list += [ f\"{root_path}{folder}/{label}/\"+ path for path in image_list]\n",
    "        \n",
    "        # add labels to the label list\n",
    "        label_list += [label] * len(image_list)\n",
    "\n",
    "# convert to dataframe\n",
    "df_train_kaggle = pd.DataFrame({\"filepath\" : image_path_list, \"label\": label_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "signal-responsibility",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:35.618734Z",
     "iopub.status.busy": "2021-05-30T18:39:35.617931Z",
     "iopub.status.idle": "2021-05-30T18:39:35.621117Z",
     "shell.execute_reply": "2021-05-30T18:39:35.621576Z",
     "shell.execute_reply.started": "2021-05-30T09:28:40.244589Z"
    },
    "id": "signal-responsibility",
    "outputId": "9be7a788-1c7a-498d-a3e9-7b2c5e8455ab",
    "papermill": {
     "duration": 0.03629,
     "end_time": "2021-05-30T18:39:35.621716",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.585426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9786, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_kaggle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-greene",
   "metadata": {
    "id": "hairy-greene",
    "papermill": {
     "duration": 0.030406,
     "end_time": "2021-05-30T18:39:35.680660",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.650254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Observation\n",
    "we have total of 9786 images in kaggle dataset. We will use data to train the deep learning model\n",
    "# Lets look at class distribution\n",
    "\n",
    "## 관찰\n",
    "우리는 카글 데이터 세트에 총 9786개의 이미지를 가지고 있다. 우리는 딥 러닝 모델을 훈련시키기 위해 데이터를 사용할 것이다.\n",
    "# 학급분포를 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "therapeutic-spending",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:35.750000Z",
     "iopub.status.busy": "2021-05-30T18:39:35.749277Z",
     "iopub.status.idle": "2021-05-30T18:39:35.918362Z",
     "shell.execute_reply": "2021-05-30T18:39:35.918766Z",
     "shell.execute_reply.started": "2021-05-30T09:28:41.597346Z"
    },
    "id": "therapeutic-spending",
    "outputId": "0e179822-cb9f-4a56-b0c3-1f99705e882b",
    "papermill": {
     "duration": 0.208649,
     "end_time": "2021-05-30T18:39:35.918905",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.710256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_kaggle.label.value_counts().plot.bar()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-calendar",
   "metadata": {
    "id": "cognitive-calendar",
    "papermill": {
     "duration": 0.027966,
     "end_time": "2021-05-30T18:39:35.973791",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.945825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Observation\n",
    "As our dataset is imbalanced, we will balance our class by weighting majority class less and minoiry class more\n",
    "\n",
    "## 관찰\n",
    "데이터 세트가 불균형적이므로 다수 클래스는 덜 가중치 부여하고 소수 클래스는 더 가중치를 부여하여 클래스 균형을 맞출 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-enzyme",
   "metadata": {
    "id": "dense-enzyme",
    "papermill": {
     "duration": 0.028255,
     "end_time": "2021-05-30T18:39:36.030250",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.001995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DataGenerator train and validation\n",
    "We will use kaggle dataset as train set and compitition dataset as validation set. If train and validation metric is similar, it shows their distribution is similar and hence we can use kaggle dataset as well.\n",
    "\n",
    "# 데이터 생성기 교육 및 검증\n",
    "우리는 캐글 데이터 세트를 열차 세트로, 컴포지션 데이터 세트를 검증 세트로 사용할 것이다. 열차와 검증 메트릭이 유사한 경우 분포가 유사함을 보여주므로 캐글 데이터 세트도 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "encouraging-novel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:36.090553Z",
     "iopub.status.busy": "2021-05-30T18:39:36.089729Z",
     "iopub.status.idle": "2021-05-30T18:39:36.092340Z",
     "shell.execute_reply": "2021-05-30T18:39:36.091828Z",
     "shell.execute_reply.started": "2021-05-30T09:28:44.189248Z"
    },
    "id": "encouraging-novel",
    "papermill": {
     "duration": 0.035021,
     "end_time": "2021-05-30T18:39:36.092447",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.057426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train data generator object\n",
    "train_aug = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    "  )\n",
    "\n",
    "# validation data generator object\n",
    "valid_aug = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "geological-philadelphia",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:36.172890Z",
     "iopub.status.busy": "2021-05-30T18:39:36.167698Z",
     "iopub.status.idle": "2021-05-30T18:39:39.954054Z",
     "shell.execute_reply": "2021-05-30T18:39:39.954888Z",
     "shell.execute_reply.started": "2021-05-30T09:28:47.478488Z"
    },
    "id": "geological-philadelphia",
    "outputId": "358f5e4e-a7b9-4d32-d0be-5a08a4e27ace",
    "papermill": {
     "duration": 3.835127,
     "end_time": "2021-05-30T18:39:39.955083",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.119956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9786 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# create train generator\n",
    "train_generator = train_aug.flow_from_dataframe(\n",
    "    dataframe = df_train_kaggle,\n",
    "    directory = None,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 16,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-chest",
   "metadata": {
    "id": "asian-chest",
    "papermill": {
     "duration": 0.027295,
     "end_time": "2021-05-30T18:39:40.011354",
     "exception": false,
     "start_time": "2021-05-30T18:39:39.984059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create validation dataframe using compitition dataset.\n",
    "We will download compition dataset from gdrive and use it as validation set to validated against kaggle dataset\n",
    "\n",
    "# composition dataset을 이용하여 검증 데이터 프레임을 생성합니다.\n",
    "gdrive에서 컴포지션 데이터 세트를 다운로드하여 Kaggle 데이터 세트에 대해 검증된 검증 세트로 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "threaded-characterization",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.229132Z",
     "iopub.status.busy": "2021-05-30T18:40:02.228400Z",
     "iopub.status.idle": "2021-05-30T18:40:02.250117Z",
     "shell.execute_reply": "2021-05-30T18:40:02.250642Z",
     "shell.execute_reply.started": "2021-05-30T08:33:23.833280Z"
    },
    "id": "threaded-characterization",
    "outputId": "283093ce-0819-4542-9ff8-555713912e62",
    "papermill": {
     "duration": 0.059732,
     "end_time": "2021-05-30T18:40:02.250775",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.191043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  label\n",
       "0  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      0\n",
       "1  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      1\n",
       "2  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      0\n",
       "3  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      1\n",
       "4  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read Train.csv file which contains image names and labels and preprocess them\n",
    "compi_root_path = \"C:\\\\Users\\\\ngkim\\\\Downloads\\\\KneeXray\\\\\"\n",
    "df_val_compi = pd.read_csv(compi_root_path + \"Train.csv\")\n",
    "\n",
    "# add absolute path to the image names\n",
    "df_val_compi[\"filename\"] = df_val_compi.filename.apply(lambda x: compi_root_path+\"train/\" + x)\n",
    "df_val_compi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suburban-shareware",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.339459Z",
     "iopub.status.busy": "2021-05-30T18:40:02.324109Z",
     "iopub.status.idle": "2021-05-30T18:40:02.442504Z",
     "shell.execute_reply": "2021-05-30T18:40:02.442056Z",
     "shell.execute_reply.started": "2021-05-30T08:33:23.865039Z"
    },
    "id": "suburban-shareware",
    "outputId": "8fb91f05-54a6-4bc7-d95f-68ea55748335",
    "papermill": {
     "duration": 0.158988,
     "end_time": "2021-05-30T18:40:02.442618",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.283630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class count of compitition dataset\n",
    "df_val_compi.label.value_counts().plot.bar()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "saving-homework",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.529039Z",
     "iopub.status.busy": "2021-05-30T18:40:02.528305Z",
     "iopub.status.idle": "2021-05-30T18:40:02.574290Z",
     "shell.execute_reply": "2021-05-30T18:40:02.574903Z",
     "shell.execute_reply.started": "2021-05-30T08:54:21.600981Z"
    },
    "id": "saving-homework",
    "outputId": "178977a9-4413-4d38-b7f0-de8a9904b0e0",
    "papermill": {
     "duration": 0.098388,
     "end_time": "2021-05-30T18:40:02.575081",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.476693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7828 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# create validation generator\n",
    "valid_generator = valid_aug.flow_from_dataframe( \n",
    "    dataframe = df_val_compi,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 16,\n",
    "    seed = 42,\n",
    "    shuffle= True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-belarus",
   "metadata": {
    "id": "marked-belarus",
    "papermill": {
     "duration": 0.033792,
     "end_time": "2021-05-30T18:40:02.643887",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.610095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Architecture\n",
    "Here we will be using Xception by google. (I encourage you to try different architectures)\n",
    "\n",
    "## 모델 아키텍처\n",
    "여기서는 구글의 Xception을 사용할 것입니다. (다양한 아키텍처를 사용해 보십시오)\n",
    "\n",
    "## CheXNet - DenseNet121 + Sigmoid\n",
    "https://github.com/arnoweng/CheXNet/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "buried-tablet",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.724467Z",
     "iopub.status.busy": "2021-05-30T18:40:02.723830Z",
     "iopub.status.idle": "2021-05-30T18:40:08.132744Z",
     "shell.execute_reply": "2021-05-30T18:40:08.131632Z",
     "shell.execute_reply.started": "2021-05-30T09:28:56.068101Z"
    },
    "id": "buried-tablet",
    "outputId": "2be7f5dd-25c9-49e7-fce8-f3e1fbe9c6a1",
    "papermill": {
     "duration": 5.455093,
     "end_time": "2021-05-30T18:40:08.132878",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.677785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "xception = Xception(weights = \"imagenet\",)\n",
    "x =  xception.layers[-3].output\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size= 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = n_class, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "GAP = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "pred = tf.keras.activations.softmax(GAP)\n",
    "\n",
    "xception_model = Model(inputs=xception.input,outputs = pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "DYVqXESmD_Fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYVqXESmD_Fd",
    "outputId": "88696012-6f00-42ba-d016-645743054fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 1024) 18875392    block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10, 10, 1024) 4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 10, 10, 1024) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 10, 10, 256)  2359552     activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 10, 10, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 10, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 10, 10, 64)   147520      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 10, 10, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 10, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 10, 10, 5)    2885        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 10, 10, 5)    20          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 10, 5)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 5)            0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.softmax (TFOpLambda)      (None, 5)            0           global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 42,252,225\n",
      "Trainable params: 42,194,999\n",
      "Non-trainable params: 57,226\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "norman-detector",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:08.391663Z",
     "iopub.status.busy": "2021-05-30T18:40:08.385701Z",
     "iopub.status.idle": "2021-05-30T18:40:08.398432Z",
     "shell.execute_reply": "2021-05-30T18:40:08.397997Z",
     "shell.execute_reply.started": "2021-05-30T09:28:58.465217Z"
    },
    "id": "norman-detector",
    "papermill": {
     "duration": 0.226948,
     "end_time": "2021-05-30T18:40:08.398547",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.171599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "xception_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001, decay = 0.0001),\n",
    "    metrics = [\"acc\"],\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy)\n",
    "\n",
    "# callbacks and checkpoints\n",
    "checkpoint_path = \"xception_best.ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "my_callbacks = [\n",
    "              ModelCheckpoint(\n",
    "                   checkpoint_path,\n",
    "                   monitor = 'val_acc',\n",
    "                   verbose = 1,\n",
    "                   save_weights_only = True,\n",
    "                   save_best_only = True,\n",
    "                   mode = \"max\"\n",
    "                  ),\n",
    "              EarlyStopping(\n",
    "                   monitor = 'val_loss',\n",
    "                   patience = 10,\n",
    "                   verbose = 0\n",
    "                  ),\n",
    "              ReduceLROnPlateau(\n",
    "                   monitor = 'val_loss',\n",
    "                   patience = 10,\n",
    "                   verbose = 1\n",
    "                  )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-administration",
   "metadata": {
    "id": "crucial-administration",
    "papermill": {
     "duration": 0.038495,
     "end_time": "2021-05-30T18:40:08.475329",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.436834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Weighting classes\n",
    "As we have unevenly class distibution, we will weight them based on the number of samples\n",
    "\n",
    "### 가중치 클래스\n",
    "우리는 등급 차이가 일정하지 않기 때문에 샘플 수에 따라 무게를 재도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regional-indie",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:08.558435Z",
     "iopub.status.busy": "2021-05-30T18:40:08.557616Z",
     "iopub.status.idle": "2021-05-30T18:40:09.060821Z",
     "shell.execute_reply": "2021-05-30T18:40:09.060357Z",
     "shell.execute_reply.started": "2021-05-30T09:30:11.007618Z"
    },
    "id": "regional-indie",
    "papermill": {
     "duration": 0.546357,
     "end_time": "2021-05-30T18:40:09.060960",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.514603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes = np.unique(df_train_kaggle.label.values),\n",
    "    y = df_train_kaggle.label.values\n",
    "  )\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-better",
   "metadata": {
    "id": "square-better",
    "papermill": {
     "duration": 0.037503,
     "end_time": "2021-05-30T18:40:09.136492",
     "exception": false,
     "start_time": "2021-05-30T18:40:09.098989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train\n",
    "Lets roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74860ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72c672ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2372203962267327224\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22727688192\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16673566931728661802\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hidden-stephen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:09.218272Z",
     "iopub.status.busy": "2021-05-30T18:40:09.217728Z",
     "iopub.status.idle": "2021-05-30T20:12:12.156502Z",
     "shell.execute_reply": "2021-05-30T20:12:12.154537Z",
     "shell.execute_reply.started": "2021-05-26T18:49:57.904339Z"
    },
    "id": "hidden-stephen",
    "outputId": "1432984b-6c8d-4523-de45-b163a07ed120",
    "papermill": {
     "duration": 5522.981999,
     "end_time": "2021-05-30T20:12:12.156678",
     "exception": false,
     "start_time": "2021-05-30T18:40:09.174679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "612/612 [==============================] - 93s 144ms/step - loss: 1.4003 - acc: 0.3257 - val_loss: 1.5241 - val_acc: 0.3604\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.36037, saving model to xception_best.ckpt\n",
      "Epoch 2/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 1.1781 - acc: 0.4745 - val_loss: 1.2709 - val_acc: 0.5446\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.36037 to 0.54458, saving model to xception_best.ckpt\n",
      "Epoch 3/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 1.0648 - acc: 0.5461 - val_loss: 1.2430 - val_acc: 0.5583\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.54458 to 0.55825, saving model to xception_best.ckpt\n",
      "Epoch 4/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.9764 - acc: 0.6022 - val_loss: 1.1287 - val_acc: 0.6385\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.55825 to 0.63848, saving model to xception_best.ckpt\n",
      "Epoch 5/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.8960 - acc: 0.6665 - val_loss: 1.0627 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.63848 to 0.66313, saving model to xception_best.ckpt\n",
      "Epoch 6/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.8118 - acc: 0.7267 - val_loss: 1.0225 - val_acc: 0.6785\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.66313 to 0.67846, saving model to xception_best.ckpt\n",
      "Epoch 7/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.7505 - acc: 0.7736 - val_loss: 0.9689 - val_acc: 0.7279\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.67846 to 0.72790, saving model to xception_best.ckpt\n",
      "Epoch 8/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.6969 - acc: 0.8133 - val_loss: 0.8869 - val_acc: 0.7929\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.72790 to 0.79292, saving model to xception_best.ckpt\n",
      "Epoch 9/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.6624 - acc: 0.8432 - val_loss: 0.8090 - val_acc: 0.8444\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.79292 to 0.84440, saving model to xception_best.ckpt\n",
      "Epoch 10/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.6314 - acc: 0.8663 - val_loss: 0.8214 - val_acc: 0.8453\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.84440 to 0.84530, saving model to xception_best.ckpt\n",
      "Epoch 11/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.5985 - acc: 0.8908 - val_loss: 0.7980 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.84530 to 0.85718, saving model to xception_best.ckpt\n",
      "Epoch 12/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.5836 - acc: 0.9016 - val_loss: 0.7800 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.85718 to 0.86893, saving model to xception_best.ckpt\n",
      "Epoch 13/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.5690 - acc: 0.9107 - val_loss: 0.7534 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.86893 to 0.88247, saving model to xception_best.ckpt\n",
      "Epoch 14/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.5565 - acc: 0.9213 - val_loss: 0.7434 - val_acc: 0.8794\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.88247\n",
      "Epoch 15/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.5344 - acc: 0.9357 - val_loss: 0.7127 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.88247 to 0.90738, saving model to xception_best.ckpt\n",
      "Epoch 16/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.5287 - acc: 0.9375 - val_loss: 0.7066 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.90738 to 0.91863, saving model to xception_best.ckpt\n",
      "Epoch 17/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.5309 - acc: 0.9390 - val_loss: 0.6945 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.91863\n",
      "Epoch 18/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.5124 - acc: 0.9474 - val_loss: 0.6899 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.91863 to 0.92092, saving model to xception_best.ckpt\n",
      "Epoch 19/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.5116 - acc: 0.9517 - val_loss: 0.6817 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.92092\n",
      "Epoch 20/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.5017 - acc: 0.9539 - val_loss: 0.6730 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.92092 to 0.92207, saving model to xception_best.ckpt\n",
      "Epoch 21/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4898 - acc: 0.9632 - val_loss: 0.6866 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.92207\n",
      "Epoch 22/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.4905 - acc: 0.9640 - val_loss: 0.6736 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.92207\n",
      "Epoch 23/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.4798 - acc: 0.9678 - val_loss: 0.6540 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.92207 to 0.93651, saving model to xception_best.ckpt\n",
      "Epoch 24/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4795 - acc: 0.9689 - val_loss: 0.6461 - val_acc: 0.9245\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.93651\n",
      "Epoch 25/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4831 - acc: 0.9676 - val_loss: 0.6424 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.93651\n",
      "Epoch 26/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4683 - acc: 0.9707 - val_loss: 0.6380 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.93651\n",
      "Epoch 27/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4652 - acc: 0.9744 - val_loss: 0.6179 - val_acc: 0.9438\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.93651 to 0.94379, saving model to xception_best.ckpt\n",
      "Epoch 28/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4681 - acc: 0.9744 - val_loss: 0.6087 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.94379 to 0.95312, saving model to xception_best.ckpt\n",
      "Epoch 29/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4664 - acc: 0.9744 - val_loss: 0.6198 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.95312\n",
      "Epoch 30/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.4633 - acc: 0.9769 - val_loss: 0.5914 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.95312\n",
      "Epoch 31/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4541 - acc: 0.9814 - val_loss: 0.6147 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.95312\n",
      "Epoch 32/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4535 - acc: 0.9801 - val_loss: 0.5907 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.95312 to 0.95899, saving model to xception_best.ckpt\n",
      "Epoch 33/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4529 - acc: 0.9795 - val_loss: 0.6141 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.95899\n",
      "Epoch 34/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4476 - acc: 0.9826 - val_loss: 0.5876 - val_acc: 0.9594\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.95899 to 0.95938, saving model to xception_best.ckpt\n",
      "Epoch 35/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4499 - acc: 0.9799 - val_loss: 0.5979 - val_acc: 0.9522\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.95938\n",
      "Epoch 36/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4455 - acc: 0.9800 - val_loss: 0.5896 - val_acc: 0.9545\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.95938\n",
      "Epoch 37/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.4437 - acc: 0.9835 - val_loss: 0.5748 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.95938 to 0.96270, saving model to xception_best.ckpt\n",
      "Epoch 38/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4393 - acc: 0.9829 - val_loss: 0.5670 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.96270 to 0.96653, saving model to xception_best.ckpt\n",
      "Epoch 39/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.4396 - acc: 0.9840 - val_loss: 0.5673 - val_acc: 0.9691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00039: val_acc improved from 0.96653 to 0.96909, saving model to xception_best.ckpt\n",
      "Epoch 40/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.4391 - acc: 0.9847 - val_loss: 0.5649 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.96909\n",
      "Epoch 41/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4355 - acc: 0.9849 - val_loss: 0.5657 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.96909\n",
      "Epoch 42/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4366 - acc: 0.9848 - val_loss: 0.5664 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.96909\n",
      "Epoch 43/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.4337 - acc: 0.9846 - val_loss: 0.5633 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.96909\n",
      "Epoch 44/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4342 - acc: 0.9852 - val_loss: 0.5695 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.96909\n",
      "Epoch 45/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4373 - acc: 0.9831 - val_loss: 0.5626 - val_acc: 0.9632\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.96909\n",
      "Epoch 46/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4312 - acc: 0.9851 - val_loss: 0.5595 - val_acc: 0.9632\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.96909\n",
      "Epoch 47/300\n",
      "612/612 [==============================] - 87s 143ms/step - loss: 0.4273 - acc: 0.9864 - val_loss: 0.5757 - val_acc: 0.9527\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.96909\n",
      "Epoch 48/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4264 - acc: 0.9870 - val_loss: 0.5458 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.96909\n",
      "Epoch 49/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4274 - acc: 0.9879 - val_loss: 0.5482 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.96909\n",
      "Epoch 50/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4200 - acc: 0.9874 - val_loss: 0.5419 - val_acc: 0.9677\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.96909\n",
      "Epoch 51/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4262 - acc: 0.9875 - val_loss: 0.5569 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.96909\n",
      "Epoch 52/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4151 - acc: 0.9912 - val_loss: 0.5364 - val_acc: 0.9711\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.96909 to 0.97113, saving model to xception_best.ckpt\n",
      "Epoch 53/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4201 - acc: 0.9908 - val_loss: 0.5340 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.97113\n",
      "Epoch 54/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4124 - acc: 0.9914 - val_loss: 0.5331 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.97113 to 0.97266, saving model to xception_best.ckpt\n",
      "Epoch 55/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4135 - acc: 0.9907 - val_loss: 0.5286 - val_acc: 0.9707\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.97266\n",
      "Epoch 56/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.4218 - acc: 0.9872 - val_loss: 0.5276 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.97266\n",
      "Epoch 57/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4098 - acc: 0.9923 - val_loss: 0.5347 - val_acc: 0.9654\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.97266\n",
      "Epoch 58/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.4186 - acc: 0.9909 - val_loss: 0.5228 - val_acc: 0.9695\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.97266\n",
      "Epoch 59/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4159 - acc: 0.9900 - val_loss: 0.5250 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.97266 to 0.97368, saving model to xception_best.ckpt\n",
      "Epoch 60/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.4096 - acc: 0.9912 - val_loss: 0.5195 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.97368\n",
      "Epoch 61/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.4082 - acc: 0.9902 - val_loss: 0.5267 - val_acc: 0.9682\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.97368\n",
      "Epoch 62/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4085 - acc: 0.9929 - val_loss: 0.5295 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.97368\n",
      "Epoch 63/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4047 - acc: 0.9910 - val_loss: 0.5242 - val_acc: 0.9636\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.97368\n",
      "Epoch 64/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4050 - acc: 0.9904 - val_loss: 0.5173 - val_acc: 0.9736\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.97368\n",
      "Epoch 65/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4088 - acc: 0.9915 - val_loss: 0.5110 - val_acc: 0.9715\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.97368\n",
      "Epoch 66/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4053 - acc: 0.9918 - val_loss: 0.5222 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.97368\n",
      "Epoch 67/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4058 - acc: 0.9928 - val_loss: 0.5195 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.97368\n",
      "Epoch 68/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4068 - acc: 0.9921 - val_loss: 0.5123 - val_acc: 0.9732\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.97368\n",
      "Epoch 69/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4030 - acc: 0.9927 - val_loss: 0.5031 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.97368 to 0.97649, saving model to xception_best.ckpt\n",
      "Epoch 70/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4029 - acc: 0.9927 - val_loss: 0.5187 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.97649\n",
      "Epoch 71/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.4002 - acc: 0.9935 - val_loss: 0.5036 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.97649\n",
      "Epoch 72/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3969 - acc: 0.9939 - val_loss: 0.5163 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.97649\n",
      "Epoch 73/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3973 - acc: 0.9935 - val_loss: 0.5008 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.97649\n",
      "Epoch 74/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.4028 - acc: 0.9919 - val_loss: 0.4981 - val_acc: 0.9752\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.97649\n",
      "Epoch 75/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3993 - acc: 0.9922 - val_loss: 0.4994 - val_acc: 0.9752\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.97649\n",
      "Epoch 76/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3992 - acc: 0.9944 - val_loss: 0.5042 - val_acc: 0.9734\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.97649\n",
      "Epoch 77/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3986 - acc: 0.9936 - val_loss: 0.4901 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.97649 to 0.97726, saving model to xception_best.ckpt\n",
      "Epoch 78/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3937 - acc: 0.9950 - val_loss: 0.4921 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.97726\n",
      "Epoch 79/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3895 - acc: 0.9948 - val_loss: 0.5005 - val_acc: 0.9774\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.97726 to 0.97739, saving model to xception_best.ckpt\n",
      "Epoch 80/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3896 - acc: 0.9948 - val_loss: 0.4992 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.97739\n",
      "Epoch 81/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3939 - acc: 0.9949 - val_loss: 0.4952 - val_acc: 0.9733\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.97739\n",
      "Epoch 82/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3911 - acc: 0.9937 - val_loss: 0.4987 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.97739\n",
      "Epoch 83/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3932 - acc: 0.9953 - val_loss: 0.4963 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.97739\n",
      "Epoch 84/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3954 - acc: 0.9927 - val_loss: 0.4981 - val_acc: 0.9695\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.97739\n",
      "Epoch 85/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3881 - acc: 0.9943 - val_loss: 0.4949 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.97739\n",
      "Epoch 86/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3895 - acc: 0.9928 - val_loss: 0.4877 - val_acc: 0.9762\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.97739\n",
      "Epoch 87/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3928 - acc: 0.9951 - val_loss: 0.4860 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.97739\n",
      "Epoch 88/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3920 - acc: 0.9939 - val_loss: 0.4831 - val_acc: 0.9734\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.97739\n",
      "Epoch 89/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3848 - acc: 0.9964 - val_loss: 0.4912 - val_acc: 0.9715\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.97739\n",
      "Epoch 90/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3964 - acc: 0.9919 - val_loss: 0.4957 - val_acc: 0.9673\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.97739\n",
      "Epoch 91/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3809 - acc: 0.9955 - val_loss: 0.4831 - val_acc: 0.9743\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.97739\n",
      "Epoch 92/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3877 - acc: 0.9940 - val_loss: 0.4830 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.97739\n",
      "Epoch 93/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3865 - acc: 0.9945 - val_loss: 0.4796 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.97739\n",
      "Epoch 94/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3844 - acc: 0.9962 - val_loss: 0.4878 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.97739\n",
      "Epoch 95/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3859 - acc: 0.9954 - val_loss: 0.4841 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.97739\n",
      "Epoch 96/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3855 - acc: 0.9951 - val_loss: 0.4768 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.97739\n",
      "Epoch 97/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3822 - acc: 0.9954 - val_loss: 0.4827 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.97739\n",
      "Epoch 98/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3811 - acc: 0.9942 - val_loss: 0.4794 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.97739 to 0.97867, saving model to xception_best.ckpt\n",
      "Epoch 99/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3822 - acc: 0.9960 - val_loss: 0.4774 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.97867\n",
      "Epoch 100/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3809 - acc: 0.9965 - val_loss: 0.4754 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.97867\n",
      "Epoch 101/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3790 - acc: 0.9964 - val_loss: 0.4791 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.97867\n",
      "Epoch 102/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3800 - acc: 0.9965 - val_loss: 0.4748 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.97867\n",
      "Epoch 103/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3786 - acc: 0.9964 - val_loss: 0.4685 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.97867 to 0.97931, saving model to xception_best.ckpt\n",
      "Epoch 104/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3797 - acc: 0.9962 - val_loss: 0.4655 - val_acc: 0.9785\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.97931\n",
      "Epoch 105/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3793 - acc: 0.9953 - val_loss: 0.4703 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.97931\n",
      "Epoch 106/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3756 - acc: 0.9961 - val_loss: 0.4774 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.97931\n",
      "Epoch 107/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3838 - acc: 0.9940 - val_loss: 0.4661 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.97931\n",
      "Epoch 108/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3752 - acc: 0.9950 - val_loss: 0.4674 - val_acc: 0.9764\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.97931\n",
      "Epoch 109/300\n",
      "612/612 [==============================] - 86s 140ms/step - loss: 0.3733 - acc: 0.9955 - val_loss: 0.4663 - val_acc: 0.9734\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.97931\n",
      "Epoch 110/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3795 - acc: 0.9950 - val_loss: 0.4680 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.97931\n",
      "Epoch 111/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3738 - acc: 0.9961 - val_loss: 0.4712 - val_acc: 0.9751\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.97931\n",
      "Epoch 112/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3742 - acc: 0.9962 - val_loss: 0.4701 - val_acc: 0.9746\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.97931\n",
      "Epoch 113/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3726 - acc: 0.9960 - val_loss: 0.4692 - val_acc: 0.9709\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.97931\n",
      "Epoch 114/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3699 - acc: 0.9969 - val_loss: 0.4589 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.97931\n",
      "Epoch 115/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3724 - acc: 0.9962 - val_loss: 0.4609 - val_acc: 0.9762\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.97931\n",
      "Epoch 116/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3742 - acc: 0.9947 - val_loss: 0.4568 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.97931\n",
      "Epoch 117/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3732 - acc: 0.9979 - val_loss: 0.4545 - val_acc: 0.9807\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.97931 to 0.98071, saving model to xception_best.ckpt\n",
      "Epoch 118/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3706 - acc: 0.9971 - val_loss: 0.4634 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.98071\n",
      "Epoch 119/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3710 - acc: 0.9974 - val_loss: 0.4603 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.98071\n",
      "Epoch 120/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3751 - acc: 0.9955 - val_loss: 0.4642 - val_acc: 0.9774\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.98071\n",
      "Epoch 121/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3683 - acc: 0.9963 - val_loss: 0.4599 - val_acc: 0.9803\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.98071\n",
      "Epoch 122/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3686 - acc: 0.9967 - val_loss: 0.4590 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.98071\n",
      "Epoch 123/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3701 - acc: 0.9959 - val_loss: 0.4502 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.98071 to 0.98275, saving model to xception_best.ckpt\n",
      "Epoch 124/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3703 - acc: 0.9968 - val_loss: 0.4587 - val_acc: 0.9775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00124: val_acc did not improve from 0.98275\n",
      "Epoch 125/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3679 - acc: 0.9969 - val_loss: 0.4565 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.98275\n",
      "Epoch 126/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3643 - acc: 0.9968 - val_loss: 0.4554 - val_acc: 0.9801\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.98275\n",
      "Epoch 127/300\n",
      "612/612 [==============================] - 87s 143ms/step - loss: 0.3650 - acc: 0.9967 - val_loss: 0.4567 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.98275\n",
      "Epoch 128/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3629 - acc: 0.9973 - val_loss: 0.4551 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.98275\n",
      "Epoch 129/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3675 - acc: 0.9955 - val_loss: 0.4549 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.98275\n",
      "Epoch 130/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3670 - acc: 0.9964 - val_loss: 0.4533 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.98275\n",
      "Epoch 131/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3639 - acc: 0.9971 - val_loss: 0.4536 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.98275\n",
      "Epoch 132/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3629 - acc: 0.9974 - val_loss: 0.4506 - val_acc: 0.9798\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.98275\n",
      "Epoch 133/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3654 - acc: 0.9970 - val_loss: 0.4486 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.98275\n",
      "Epoch 134/300\n",
      "612/612 [==============================] - 87s 143ms/step - loss: 0.3581 - acc: 0.9976 - val_loss: 0.4458 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.98275\n",
      "Epoch 135/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3648 - acc: 0.9962 - val_loss: 0.4433 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.98275\n",
      "Epoch 136/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3659 - acc: 0.9964 - val_loss: 0.4463 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.98275\n",
      "Epoch 137/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3648 - acc: 0.9976 - val_loss: 0.4471 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.98275\n",
      "Epoch 138/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3620 - acc: 0.9978 - val_loss: 0.4512 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.98275\n",
      "Epoch 139/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3633 - acc: 0.9973 - val_loss: 0.4434 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.98275\n",
      "Epoch 140/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3625 - acc: 0.9970 - val_loss: 0.4453 - val_acc: 0.9807\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.98275\n",
      "Epoch 141/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3558 - acc: 0.9980 - val_loss: 0.4465 - val_acc: 0.9785\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.98275\n",
      "Epoch 142/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3574 - acc: 0.9963 - val_loss: 0.4554 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.98275\n",
      "Epoch 143/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3614 - acc: 0.9958 - val_loss: 0.4563 - val_acc: 0.9729\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.98275\n",
      "Epoch 144/300\n",
      "612/612 [==============================] - 87s 143ms/step - loss: 0.3598 - acc: 0.9975 - val_loss: 0.4443 - val_acc: 0.9792\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.98275\n",
      "Epoch 145/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3603 - acc: 0.9972 - val_loss: 0.4358 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.98275\n",
      "Epoch 146/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3595 - acc: 0.9973 - val_loss: 0.4470 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.98275\n",
      "Epoch 147/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3588 - acc: 0.9970 - val_loss: 0.4367 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.98275\n",
      "Epoch 148/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3578 - acc: 0.9981 - val_loss: 0.4455 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.98275\n",
      "Epoch 149/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3593 - acc: 0.9964 - val_loss: 0.4440 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.98275\n",
      "Epoch 150/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3531 - acc: 0.9982 - val_loss: 0.4386 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.98275\n",
      "Epoch 151/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3612 - acc: 0.9959 - val_loss: 0.4369 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.98275\n",
      "Epoch 152/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3564 - acc: 0.9969 - val_loss: 0.4438 - val_acc: 0.9792\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.98275\n",
      "Epoch 153/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3574 - acc: 0.9958 - val_loss: 0.4425 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.98275\n",
      "Epoch 154/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3564 - acc: 0.9973 - val_loss: 0.4398 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.98275\n",
      "Epoch 155/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3570 - acc: 0.9983 - val_loss: 0.4336 - val_acc: 0.9803\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.98275\n",
      "Epoch 156/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3528 - acc: 0.9974 - val_loss: 0.4353 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.98275\n",
      "Epoch 157/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3552 - acc: 0.9974 - val_loss: 0.4402 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.98275\n",
      "Epoch 158/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3574 - acc: 0.9968 - val_loss: 0.4288 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.98275\n",
      "Epoch 159/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3586 - acc: 0.9979 - val_loss: 0.4297 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.98275\n",
      "Epoch 160/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3551 - acc: 0.9974 - val_loss: 0.4335 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.98275\n",
      "Epoch 161/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3558 - acc: 0.9976 - val_loss: 0.4297 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.98275\n",
      "Epoch 162/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3515 - acc: 0.9972 - val_loss: 0.4412 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.98275\n",
      "Epoch 163/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3537 - acc: 0.9979 - val_loss: 0.4343 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.98275\n",
      "Epoch 164/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3554 - acc: 0.9974 - val_loss: 0.4316 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.98275\n",
      "Epoch 165/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3559 - acc: 0.9980 - val_loss: 0.4257 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.98275\n",
      "Epoch 166/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3536 - acc: 0.9975 - val_loss: 0.4280 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00166: val_acc improved from 0.98275 to 0.98429, saving model to xception_best.ckpt\n",
      "Epoch 167/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3504 - acc: 0.9978 - val_loss: 0.4307 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.98429\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3500 - acc: 0.9981 - val_loss: 0.4272 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.98429\n",
      "Epoch 169/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3472 - acc: 0.9973 - val_loss: 0.4327 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.98429\n",
      "Epoch 170/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3536 - acc: 0.9974 - val_loss: 0.4346 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.98429\n",
      "Epoch 171/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3507 - acc: 0.9980 - val_loss: 0.4284 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.98429\n",
      "Epoch 172/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3482 - acc: 0.9978 - val_loss: 0.4313 - val_acc: 0.9801\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.98429\n",
      "Epoch 173/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3508 - acc: 0.9967 - val_loss: 0.4288 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.98429\n",
      "Epoch 174/300\n",
      "612/612 [==============================] - 87s 143ms/step - loss: 0.3474 - acc: 0.9981 - val_loss: 0.4244 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.98429\n",
      "Epoch 175/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3480 - acc: 0.9973 - val_loss: 0.4284 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.98429\n",
      "Epoch 176/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3498 - acc: 0.9980 - val_loss: 0.4325 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.98429\n",
      "Epoch 177/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3508 - acc: 0.9978 - val_loss: 0.4285 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.98429\n",
      "Epoch 178/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3555 - acc: 0.9964 - val_loss: 0.4229 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.98429\n",
      "Epoch 179/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3458 - acc: 0.9986 - val_loss: 0.4283 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.98429\n",
      "Epoch 180/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3513 - acc: 0.9970 - val_loss: 0.4230 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.98429\n",
      "Epoch 181/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3485 - acc: 0.9987 - val_loss: 0.4229 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.98429\n",
      "Epoch 182/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3469 - acc: 0.9980 - val_loss: 0.4268 - val_acc: 0.9806\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.98429\n",
      "Epoch 183/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3502 - acc: 0.9975 - val_loss: 0.4274 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.98429\n",
      "Epoch 184/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3452 - acc: 0.9964 - val_loss: 0.4301 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.98429\n",
      "Epoch 185/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3469 - acc: 0.9976 - val_loss: 0.4317 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.98429\n",
      "Epoch 186/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3433 - acc: 0.9980 - val_loss: 0.4203 - val_acc: 0.9851\n",
      "\n",
      "Epoch 00186: val_acc improved from 0.98429 to 0.98505, saving model to xception_best.ckpt\n",
      "Epoch 187/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3434 - acc: 0.9974 - val_loss: 0.4210 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.98505\n",
      "Epoch 188/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3467 - acc: 0.9976 - val_loss: 0.4202 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.98505\n",
      "Epoch 189/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3430 - acc: 0.9987 - val_loss: 0.4304 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.98505\n",
      "Epoch 190/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3463 - acc: 0.9980 - val_loss: 0.4218 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.98505\n",
      "Epoch 191/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3410 - acc: 0.9985 - val_loss: 0.4149 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.98505\n",
      "Epoch 192/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3488 - acc: 0.9972 - val_loss: 0.4208 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.98505\n",
      "Epoch 193/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3466 - acc: 0.9969 - val_loss: 0.4146 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.98505\n",
      "Epoch 194/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3426 - acc: 0.9978 - val_loss: 0.4213 - val_acc: 0.9801\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.98505\n",
      "Epoch 195/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3419 - acc: 0.9986 - val_loss: 0.4156 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.98505\n",
      "Epoch 196/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3442 - acc: 0.9971 - val_loss: 0.4149 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.98505\n",
      "Epoch 197/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3472 - acc: 0.9965 - val_loss: 0.4144 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.98505\n",
      "Epoch 198/300\n",
      "612/612 [==============================] - 87s 141ms/step - loss: 0.3462 - acc: 0.9984 - val_loss: 0.4201 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.98505\n",
      "Epoch 199/300\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.3435 - acc: 0.9978 - val_loss: 0.4148 - val_acc: 0.9848\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.98505\n",
      "Epoch 200/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3420 - acc: 0.9973 - val_loss: 0.4162 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.98505\n",
      "Epoch 201/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3415 - acc: 0.9985 - val_loss: 0.4146 - val_acc: 0.9819\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.98505\n",
      "Epoch 202/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3404 - acc: 0.9980 - val_loss: 0.4083 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.98505\n",
      "Epoch 203/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3432 - acc: 0.9982 - val_loss: 0.4178 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.98505\n",
      "Epoch 204/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3453 - acc: 0.9978 - val_loss: 0.4186 - val_acc: 0.9803\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.98505\n",
      "Epoch 205/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3399 - acc: 0.9980 - val_loss: 0.4211 - val_acc: 0.9807\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.98505\n",
      "Epoch 206/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3384 - acc: 0.9984 - val_loss: 0.4099 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.98505\n",
      "Epoch 207/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3378 - acc: 0.9976 - val_loss: 0.4147 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.98505\n",
      "Epoch 208/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3443 - acc: 0.9975 - val_loss: 0.4209 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.98505\n",
      "Epoch 209/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3391 - acc: 0.9984 - val_loss: 0.4091 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.98505\n",
      "Epoch 210/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3391 - acc: 0.9992 - val_loss: 0.4149 - val_acc: 0.9819\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.98505\n",
      "Epoch 211/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3392 - acc: 0.9974 - val_loss: 0.4156 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.98505\n",
      "Epoch 212/300\n",
      "612/612 [==============================] - 87s 142ms/step - loss: 0.3392 - acc: 0.9980 - val_loss: 0.4141 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.98505\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1e4681f7788>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "xception_model.fit(\n",
    "        train_generator,\n",
    "        epochs = 300,\n",
    "        validation_data = valid_generator,\n",
    "        callbacks = [my_callbacks],\n",
    "        class_weight = class_weights\n",
    "      )\n",
    "\n",
    "# load best saved weights\n",
    "xception_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-morris",
   "metadata": {
    "id": "pretty-morris",
    "papermill": {
     "duration": 3.201635,
     "end_time": "2021-05-30T20:12:18.344310",
     "exception": false,
     "start_time": "2021-05-30T20:12:15.142675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Observation\n",
    "As we can see train and validation accuracy is pretty close, which proves kaggle and competition data has come from the same distribution and we can freely use it to experiment with.\n",
    "\n",
    "## Retraining last trained model on competition data\n",
    "As we have used competition data as validation set previously, we will use it as train set now (and some part of it as validation set) hoping this additional training would give our model new information to perform better.\n",
    "\n",
    "## 관찰\n",
    "보시다시피 열차와 검증 정확도는 매우 가까우며, 이는 카글과 경쟁 데이터가 동일한 분포에서 나왔다는 것을 증명하며, 이를 실험하는 데 자유롭게 사용할 수 있습니다.\n",
    "\n",
    "## 경기 데이터에 대해 마지막으로 훈련된 모델 재교육\n",
    "이전에 경쟁 데이터를 검증 세트로 사용했으므로, 이제 열차 세트로 사용할 것이며(그리고 그 중 일부는 검증 세트로) 이 추가 교육을 통해 모델이 더 나은 성능을 발휘할 수 있는 새로운 정보를 얻을 수 있기를 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cloudy-idaho",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:24.238372Z",
     "iopub.status.busy": "2021-05-30T20:12:24.237660Z",
     "iopub.status.idle": "2021-05-30T20:12:24.305208Z",
     "shell.execute_reply": "2021-05-30T20:12:24.305579Z",
     "shell.execute_reply.started": "2021-05-30T09:30:16.948040Z"
    },
    "id": "cloudy-idaho",
    "papermill": {
     "duration": 3.027306,
     "end_time": "2021-05-30T20:12:24.305720",
     "exception": false,
     "start_time": "2021-05-30T20:12:21.278414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train and validation split on competition data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(\n",
    "    df_val_compi,\n",
    "    test_size = 0.1,\n",
    "    random_state = 42,\n",
    "    stratify = df_val_compi.label\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "nervous-crisis",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:30.429807Z",
     "iopub.status.busy": "2021-05-30T20:12:30.429001Z",
     "iopub.status.idle": "2021-05-30T20:12:30.472297Z",
     "shell.execute_reply": "2021-05-30T20:12:30.471634Z",
     "shell.execute_reply.started": "2021-05-30T09:30:18.098841Z"
    },
    "id": "nervous-crisis",
    "outputId": "bf1114cc-1f2d-4777-cef4-bd4eb24d75dd",
    "papermill": {
     "duration": 3.239148,
     "end_time": "2021-05-30T20:12:30.472465",
     "exception": false,
     "start_time": "2021-05-30T20:12:27.233317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7045 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_aug.flow_from_dataframe(\n",
    "    dataframe = X_train,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "instrumental-indie",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:36.309467Z",
     "iopub.status.busy": "2021-05-30T20:12:36.308631Z",
     "iopub.status.idle": "2021-05-30T20:12:36.318017Z",
     "shell.execute_reply": "2021-05-30T20:12:36.317530Z",
     "shell.execute_reply.started": "2021-05-30T09:30:23.206485Z"
    },
    "id": "instrumental-indie",
    "outputId": "dceb0588-b8e8-4658-a8e4-9c7f11fc65a0",
    "papermill": {
     "duration": 2.927421,
     "end_time": "2021-05-30T20:12:36.318129",
     "exception": false,
     "start_time": "2021-05-30T20:12:33.390708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 783 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = valid_aug.flow_from_dataframe( \n",
    "    dataframe = X_test,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dedicated-chapel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:42.897491Z",
     "iopub.status.busy": "2021-05-30T20:12:42.895853Z",
     "iopub.status.idle": "2021-05-30T20:12:42.898202Z",
     "shell.execute_reply": "2021-05-30T20:12:42.898602Z",
     "shell.execute_reply.started": "2021-05-30T09:30:26.966513Z"
    },
    "id": "dedicated-chapel",
    "papermill": {
     "duration": 3.108025,
     "end_time": "2021-05-30T20:12:42.898739",
     "exception": false,
     "start_time": "2021-05-30T20:12:39.790714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of steps to consider 1 as  epoch\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sized-norfolk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:48.820785Z",
     "iopub.status.busy": "2021-05-30T20:12:48.819337Z",
     "iopub.status.idle": "2021-05-30T20:25:26.371458Z",
     "shell.execute_reply": "2021-05-30T20:25:26.371941Z",
     "shell.execute_reply.started": "2021-05-30T09:30:36.962285Z"
    },
    "id": "sized-norfolk",
    "outputId": "fc9b987c-a11c-49f1-b98c-d4879cee12f6",
    "papermill": {
     "duration": 760.527609,
     "end_time": "2021-05-30T20:25:26.372105",
     "exception": false,
     "start_time": "2021-05-30T20:12:45.844496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "220/220 [==============================] - 52s 228ms/step - loss: 0.4377 - acc: 0.9835 - val_loss: 0.3719 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.98505 to 0.99740, saving model to xception_best.ckpt\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 50s 225ms/step - loss: 0.4317 - acc: 0.9847 - val_loss: 0.3680 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.99740 to 0.99870, saving model to xception_best.ckpt\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 50s 225ms/step - loss: 0.4168 - acc: 0.9903 - val_loss: 0.3697 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99870\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 49s 224ms/step - loss: 0.4153 - acc: 0.9934 - val_loss: 0.3665 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99870\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 50s 227ms/step - loss: 0.4139 - acc: 0.9930 - val_loss: 0.3646 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99870\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 48s 219ms/step - loss: 0.4147 - acc: 0.9943 - val_loss: 0.3657 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99870\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 49s 225ms/step - loss: 0.4113 - acc: 0.9962 - val_loss: 0.3680 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99870\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 49s 223ms/step - loss: 0.4118 - acc: 0.9960 - val_loss: 0.3699 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99870\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 49s 222ms/step - loss: 0.4141 - acc: 0.9952 - val_loss: 0.3656 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99870\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 49s 222ms/step - loss: 0.4082 - acc: 0.9959 - val_loss: 0.3719 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99870\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 49s 223ms/step - loss: 0.4086 - acc: 0.9954 - val_loss: 0.3672 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99870\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 49s 221ms/step - loss: 0.4084 - acc: 0.9969 - val_loss: 0.3671 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99870\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 49s 222ms/step - loss: 0.4088 - acc: 0.9963 - val_loss: 0.3682 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99870\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 49s 221ms/step - loss: 0.4107 - acc: 0.9962 - val_loss: 0.3668 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99870\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 49s 221ms/step - loss: 0.4077 - acc: 0.9983 - val_loss: 0.3690 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99870\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4682f1908>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kick off training\n",
    "xception_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "        epochs = 50,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = STEP_SIZE_VALID,callbacks = [my_callbacks]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "complete-spelling",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:33.497837Z",
     "iopub.status.busy": "2021-05-30T20:25:33.496999Z",
     "iopub.status.idle": "2021-05-30T20:25:34.695800Z",
     "shell.execute_reply": "2021-05-30T20:25:34.695365Z",
     "shell.execute_reply.started": "2021-05-24T16:41:06.725854Z"
    },
    "id": "complete-spelling",
    "outputId": "10521e37-45bc-43e8-eae3-62b233e07b14",
    "papermill": {
     "duration": 4.566888,
     "end_time": "2021-05-30T20:25:34.695951",
     "exception": false,
     "start_time": "2021-05-30T20:25:30.129063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1e45fae4c88>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best saved weights\n",
    "xception_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-cylinder",
   "metadata": {
    "id": "intended-cylinder",
    "papermill": {
     "duration": 3.633537,
     "end_time": "2021-05-30T20:25:41.743104",
     "exception": false,
     "start_time": "2021-05-30T20:25:38.109567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Confusion Matrix\n",
    "As our data set is imbalaned, lets see where is our model making mistakes. I encourage to you to take initative for bringing FPs and FNs down.\n",
    "\n",
    "# 혼란 매트릭스\n",
    "데이터 세트가 불균형 상태이므로 모델이 어디에서 실수를 하는지 살펴보자. FP와 FN을 끌어내리는데 솔선수범하길 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "equivalent-album",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:48.625234Z",
     "iopub.status.busy": "2021-05-30T20:25:48.624438Z",
     "iopub.status.idle": "2021-05-30T20:25:48.634216Z",
     "shell.execute_reply": "2021-05-30T20:25:48.633804Z",
     "shell.execute_reply.started": "2021-05-27T05:35:10.161826Z"
    },
    "id": "equivalent-album",
    "outputId": "2ed00c4a-4fd3-4d76-9ce5-6249f0da4489",
    "papermill": {
     "duration": 3.430239,
     "end_time": "2021-05-30T20:25:48.634343",
     "exception": false,
     "start_time": "2021-05-30T20:25:45.204104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 783 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "target_shape = 224\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# test generator\n",
    "compi_gen = valid_aug.flow_from_dataframe(\n",
    "    dataframe = X_test,\n",
    "    x_col = \"filename\",\n",
    "    class_mode = None,\n",
    "    target_size = (target_shape, target_shape),\n",
    "    shuffle = False,\n",
    "    batch_size = BATCH_SIZE\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "preceding-delight",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:56.117007Z",
     "iopub.status.busy": "2021-05-30T20:25:56.116264Z",
     "iopub.status.idle": "2021-05-30T20:26:05.659358Z",
     "shell.execute_reply": "2021-05-30T20:26:05.658569Z",
     "shell.execute_reply.started": "2021-05-27T05:35:17.324361Z"
    },
    "id": "preceding-delight",
    "outputId": "21817dd8-602c-4242-8998-5e3ae34e14e3",
    "papermill": {
     "duration": 12.914933,
     "end_time": "2021-05-30T20:26:05.659489",
     "exception": false,
     "start_time": "2021-05-30T20:25:52.744556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 5s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# prediction on train data\n",
    "predicition_compi = xception_model.predict(compi_gen, steps = compi_gen.n/ BATCH_SIZE, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "distinguished-midwest",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:12.667940Z",
     "iopub.status.busy": "2021-05-30T20:26:12.649791Z",
     "iopub.status.idle": "2021-05-30T20:26:13.051891Z",
     "shell.execute_reply": "2021-05-30T20:26:13.051413Z",
     "shell.execute_reply.started": "2021-05-27T05:43:44.837052Z"
    },
    "id": "distinguished-midwest",
    "outputId": "07a44daf-1bcd-454d-aa10-3c479b130443",
    "papermill": {
     "duration": 3.832152,
     "end_time": "2021-05-30T20:26:13.052010",
     "exception": false,
     "start_time": "2021-05-30T20:26:09.219858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1e469d40288>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "class_prediction_compi = np.argmax(predicition_compi, axis = 1)\n",
    "cm = confusion_matrix(X_test.label, class_prediction_compi, labels = [0, 1, 2, 3, 4])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix = cm,\n",
    "    display_labels = [0, 1, 2, 3, 4]\n",
    "  )\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-wilson",
   "metadata": {
    "id": "positive-wilson",
    "papermill": {
     "duration": 3.5306,
     "end_time": "2021-05-30T20:26:20.277590",
     "exception": false,
     "start_time": "2021-05-30T20:26:16.746990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Making prediction on test set (to make submission)\n",
    "Finally we save the predictions on disk in CSV format\n",
    "\n",
    "## 시험세트 예측하기 (제출하기)\n",
    "마지막으로 예측 내용을 CSV 형식으로 디스크에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "constitutional-catholic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:28.031789Z",
     "iopub.status.busy": "2021-05-30T20:26:28.031111Z",
     "iopub.status.idle": "2021-05-30T20:26:28.058944Z",
     "shell.execute_reply": "2021-05-30T20:26:28.058161Z",
     "shell.execute_reply.started": "2021-05-27T09:08:20.550041Z"
    },
    "id": "constitutional-catholic",
    "outputId": "91b6393c-4cdf-45ff-f39e-2eb2a0d17012",
    "papermill": {
     "duration": 4.034446,
     "end_time": "2021-05-30T20:26:28.059074",
     "exception": false,
     "start_time": "2021-05-30T20:26:24.024628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1958 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# read the csv file\n",
    "test = pd.read_csv(compi_root_path + \"Test.csv\")\n",
    "\n",
    "# create test generator\n",
    "test_generator = valid_aug.flow_from_dataframe(\n",
    "    dataframe = test,\n",
    "    directory = compi_root_path + \"test\",\n",
    "    x_col = \"filename\",\n",
    "    y_col = None,\n",
    "    batch_size = 1,\n",
    "    seed = 42,\n",
    "    shuffle = False,\n",
    "    class_mode = None,\n",
    "    target_size = (224,224)\n",
    "  )\n",
    "\n",
    "# number of steps to consider 1 epoch\n",
    "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "blocked-niagara",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:34.994605Z",
     "iopub.status.busy": "2021-05-30T20:26:34.994000Z",
     "iopub.status.idle": "2021-05-30T20:26:56.340759Z",
     "shell.execute_reply": "2021-05-30T20:26:56.341118Z",
     "shell.execute_reply.started": "2021-05-27T05:51:39.116529Z"
    },
    "id": "blocked-niagara",
    "outputId": "e8ed2e21-e61a-40ca-9976-0c87f7f7e9fa",
    "papermill": {
     "duration": 24.791614,
     "end_time": "2021-05-30T20:26:56.341303",
     "exception": false,
     "start_time": "2021-05-30T20:26:31.549689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958/1958 [==============================] - 12s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    766\n",
       "2    523\n",
       "1    353\n",
       "3    257\n",
       "4     59\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction and create dataframe out of it\n",
    "pred = xception_model.predict(test_generator,steps=STEP_SIZE_TEST,verbose=1)\n",
    "df_submit = pd.DataFrame({\"label\":np.argmax(pred, axis= 1)})\n",
    "df_submit[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-arthur",
   "metadata": {
    "id": "still-arthur",
    "papermill": {
     "duration": 3.549425,
     "end_time": "2021-05-30T20:27:04.148458",
     "exception": false,
     "start_time": "2021-05-30T20:27:00.599033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Clearing the working directory\n",
    "Because if don't, \"output\" tabl will show only images\n",
    "\n",
    "### 작업 디렉토리 지우기\n",
    "그렇지 않으면 \"출력\" 탭이 이미지만 표시되기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "decimal-hampshire",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:27:11.522864Z",
     "iopub.status.busy": "2021-05-30T20:27:11.522085Z",
     "iopub.status.idle": "2021-05-30T20:27:11.842332Z",
     "shell.execute_reply": "2021-05-30T20:27:11.842916Z",
     "shell.execute_reply.started": "2021-05-27T05:51:43.875589Z"
    },
    "id": "decimal-hampshire",
    "outputId": "bba496cf-d002-4106-cb8c-29be6b8078d2",
    "papermill": {
     "duration": 4.080149,
     "end_time": "2021-05-30T20:27:11.843118",
     "exception": false,
     "start_time": "2021-05-30T20:27:07.762969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: /kaggle/working - 지정된 경로를 찾을 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import shutil\n",
    "\n",
    "# Get directory name\n",
    "mydir = \"/kaggle/working\"\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(mydir)\n",
    "except OSError as e:\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-yacht",
   "metadata": {
    "id": "portable-yacht",
    "papermill": {
     "duration": 3.504245,
     "end_time": "2021-05-30T20:27:18.913681",
     "exception": false,
     "start_time": "2021-05-30T20:27:15.409436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Save best weights and output prediction file\n",
    "\n",
    "### 최적의 가중치 및 출력 예측 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "liquid-tsunami",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:27:26.290338Z",
     "iopub.status.busy": "2021-05-30T20:27:26.289493Z",
     "iopub.status.idle": "2021-05-30T20:27:26.809425Z",
     "shell.execute_reply": "2021-05-30T20:27:26.808879Z",
     "shell.execute_reply.started": "2021-05-27T05:51:46.57395Z"
    },
    "id": "liquid-tsunami",
    "papermill": {
     "duration": 4.073647,
     "end_time": "2021-05-30T20:27:26.809566",
     "exception": false,
     "start_time": "2021-05-30T20:27:22.735919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xception_model.save_weights(\"knee_xray_Xceptionnet_GPA.h5\")\n",
    "df_submit.to_csv(\"submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-baptist",
   "metadata": {
    "id": "sustainable-baptist",
    "papermill": {
     "duration": 3.563445,
     "end_time": "2021-05-30T20:27:34.549379",
     "exception": false,
     "start_time": "2021-05-30T20:27:30.985934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The submission results in 96.8% on public leaderboard.\n",
    "\n",
    "**Suggestion to improve the score**\n",
    "* Using right data augmentations\n",
    "* Using different model architecture\n",
    "* Ensembling and stacking\n",
    "* Using pretrained model trained on xray images\n",
    "\n",
    "제출 결과 공개 리더보드에서 96.8%의 결과가 나왔습니다.\n",
    "\n",
    "**점수 향상을 위한 제안*\n",
    "* 올바른 데이터 확대 사용\n",
    "* 다른 모델 아키텍처 사용\n",
    "* 조립 및 쌓기\n",
    "* X선 영상에 대해 사전 훈련된 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2538ff51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "KLGrade-DenseNet121-91.83.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6499.620651,
   "end_time": "2021-05-30T20:27:40.898205",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-30T18:39:21.277554",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
