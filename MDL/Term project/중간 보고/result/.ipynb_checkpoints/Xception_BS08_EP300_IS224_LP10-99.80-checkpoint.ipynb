{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18af0544",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/d9249/MDL/blob/main/KLGrade_DenseNet121-91.83.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33568de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\MDL\\model\n"
     ]
    }
   ],
   "source": [
    "cd D:\\MDL\\model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74860ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37b90db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13862928520253002627\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22727688192\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4339026329529511671\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ts26D3gLnyLd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ts26D3gLnyLd",
    "outputId": "f4f6fa8d-223f-4028-b18f-b8da4113b6d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  7 06:55:16 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 461.72       Driver Version: 461.72       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3090   WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   39C    P2    44W / 350W |    599MiB / 24576MiB |      8%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     12544      C   ...gkim\\anaconda3\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "floating-cincinnati",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:28.086573Z",
     "iopub.status.busy": "2021-05-30T18:39:28.085923Z",
     "iopub.status.idle": "2021-05-30T18:39:32.847126Z",
     "shell.execute_reply": "2021-05-30T18:39:32.846068Z",
     "shell.execute_reply.started": "2021-05-30T09:28:36.967323Z"
    },
    "id": "floating-cincinnati",
    "papermill": {
     "duration": 4.80129,
     "end_time": "2021-05-30T18:39:32.847355",
     "exception": false,
     "start_time": "2021-05-30T18:39:28.046065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73aea229",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = Xception\n",
    "name = 'Xception'\n",
    "batch_size = 8\n",
    "train_epoch = 300\n",
    "val_epoch = 50\n",
    "seed = 42\n",
    "image_size = 224\n",
    "LP = 10\n",
    "lr = 0.00001\n",
    "decay = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-prague",
   "metadata": {
    "id": "rotary-prague",
    "papermill": {
     "duration": 0.025647,
     "end_time": "2021-05-30T18:39:32.952047",
     "exception": false,
     "start_time": "2021-05-30T18:39:32.926400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 학습 데이터 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "emotional-valuable",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:33.012157Z",
     "iopub.status.busy": "2021-05-30T18:39:33.011596Z",
     "iopub.status.idle": "2021-05-30T18:39:35.556063Z",
     "shell.execute_reply": "2021-05-30T18:39:35.555555Z",
     "shell.execute_reply.started": "2021-05-30T09:28:38.947982Z"
    },
    "id": "emotional-valuable",
    "papermill": {
     "duration": 2.57776,
     "end_time": "2021-05-30T18:39:35.556225",
     "exception": false,
     "start_time": "2021-05-30T18:39:32.978465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of class\n",
    "n_class = 5\n",
    "\n",
    "# path to kaggle dataset\n",
    "root_path = \"C:\\\\Users\\\\ngkim\\\\Downloads\\\\ClsKLData\\\\kneeKL224\\\\\"\n",
    "\n",
    "# list of folders\n",
    "folder_list = os.listdir(root_path)\n",
    "image_path_list = []\n",
    "label_list = []\n",
    "\n",
    "# for each folder, get the image path and labels\n",
    "for folder in folder_list:\n",
    "    for label in range(n_class):\n",
    "        \n",
    "        # get all the images path inside the current folder\n",
    "        image_list = os.listdir(f\"{root_path}{folder}/{label}\")\n",
    "        # add to the image path list\n",
    "        image_path_list += [ f\"{root_path}{folder}/{label}/\"+ path for path in image_list]\n",
    "        \n",
    "        # add labels to the label list\n",
    "        label_list += [label] * len(image_list)\n",
    "\n",
    "# convert to dataframe\n",
    "df_train_kaggle = pd.DataFrame({\"filepath\" : image_path_list, \"label\": label_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "signal-responsibility",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:35.618734Z",
     "iopub.status.busy": "2021-05-30T18:39:35.617931Z",
     "iopub.status.idle": "2021-05-30T18:39:35.621117Z",
     "shell.execute_reply": "2021-05-30T18:39:35.621576Z",
     "shell.execute_reply.started": "2021-05-30T09:28:40.244589Z"
    },
    "id": "signal-responsibility",
    "outputId": "9be7a788-1c7a-498d-a3e9-7b2c5e8455ab",
    "papermill": {
     "duration": 0.03629,
     "end_time": "2021-05-30T18:39:35.621716",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.585426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9786, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_kaggle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-greene",
   "metadata": {
    "id": "hairy-greene",
    "papermill": {
     "duration": 0.030406,
     "end_time": "2021-05-30T18:39:35.680660",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.650254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 샘플 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "therapeutic-spending",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:35.750000Z",
     "iopub.status.busy": "2021-05-30T18:39:35.749277Z",
     "iopub.status.idle": "2021-05-30T18:39:35.918362Z",
     "shell.execute_reply": "2021-05-30T18:39:35.918766Z",
     "shell.execute_reply.started": "2021-05-30T09:28:41.597346Z"
    },
    "id": "therapeutic-spending",
    "outputId": "0e179822-cb9f-4a56-b0c3-1f99705e882b",
    "papermill": {
     "duration": 0.208649,
     "end_time": "2021-05-30T18:39:35.918905",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.710256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_kaggle.label.value_counts().plot.bar()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "encouraging-novel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:36.090553Z",
     "iopub.status.busy": "2021-05-30T18:39:36.089729Z",
     "iopub.status.idle": "2021-05-30T18:39:36.092340Z",
     "shell.execute_reply": "2021-05-30T18:39:36.091828Z",
     "shell.execute_reply.started": "2021-05-30T09:28:44.189248Z"
    },
    "id": "encouraging-novel",
    "papermill": {
     "duration": 0.035021,
     "end_time": "2021-05-30T18:39:36.092447",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.057426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train data generator object\n",
    "train_aug = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    "  )\n",
    "\n",
    "# validation data generator object\n",
    "valid_aug = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "geological-philadelphia",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:36.172890Z",
     "iopub.status.busy": "2021-05-30T18:39:36.167698Z",
     "iopub.status.idle": "2021-05-30T18:39:39.954054Z",
     "shell.execute_reply": "2021-05-30T18:39:39.954888Z",
     "shell.execute_reply.started": "2021-05-30T09:28:47.478488Z"
    },
    "id": "geological-philadelphia",
    "outputId": "358f5e4e-a7b9-4d32-d0be-5a08a4e27ace",
    "papermill": {
     "duration": 3.835127,
     "end_time": "2021-05-30T18:39:39.955083",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.119956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9786 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# create train generator\n",
    "train_generator = train_aug.flow_from_dataframe(\n",
    "    dataframe = df_train_kaggle,\n",
    "    directory = None,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = batch_size,\n",
    "    seed = seed,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (image_size,image_size)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-chest",
   "metadata": {
    "id": "asian-chest",
    "papermill": {
     "duration": 0.027295,
     "end_time": "2021-05-30T18:39:40.011354",
     "exception": false,
     "start_time": "2021-05-30T18:39:39.984059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 검증 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "threaded-characterization",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.229132Z",
     "iopub.status.busy": "2021-05-30T18:40:02.228400Z",
     "iopub.status.idle": "2021-05-30T18:40:02.250117Z",
     "shell.execute_reply": "2021-05-30T18:40:02.250642Z",
     "shell.execute_reply.started": "2021-05-30T08:33:23.833280Z"
    },
    "id": "threaded-characterization",
    "outputId": "283093ce-0819-4542-9ff8-555713912e62",
    "papermill": {
     "duration": 0.059732,
     "end_time": "2021-05-30T18:40:02.250775",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.191043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  label\n",
       "0  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      0\n",
       "1  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      1\n",
       "2  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      0\n",
       "3  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      1\n",
       "4  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read Train.csv file which contains image names and labels and preprocess them\n",
    "compi_root_path = \"C:\\\\Users\\\\ngkim\\\\Downloads\\\\KneeXray\\\\\"\n",
    "df_val_compi = pd.read_csv(compi_root_path + \"Train.csv\")\n",
    "\n",
    "# add absolute path to the image names\n",
    "df_val_compi[\"filename\"] = df_val_compi.filename.apply(lambda x: compi_root_path+\"train/\" + x)\n",
    "df_val_compi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "suburban-shareware",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.339459Z",
     "iopub.status.busy": "2021-05-30T18:40:02.324109Z",
     "iopub.status.idle": "2021-05-30T18:40:02.442504Z",
     "shell.execute_reply": "2021-05-30T18:40:02.442056Z",
     "shell.execute_reply.started": "2021-05-30T08:33:23.865039Z"
    },
    "id": "suburban-shareware",
    "outputId": "8fb91f05-54a6-4bc7-d95f-68ea55748335",
    "papermill": {
     "duration": 0.158988,
     "end_time": "2021-05-30T18:40:02.442618",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.283630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class count of compitition dataset\n",
    "df_val_compi.label.value_counts().plot.bar()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "saving-homework",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.529039Z",
     "iopub.status.busy": "2021-05-30T18:40:02.528305Z",
     "iopub.status.idle": "2021-05-30T18:40:02.574290Z",
     "shell.execute_reply": "2021-05-30T18:40:02.574903Z",
     "shell.execute_reply.started": "2021-05-30T08:54:21.600981Z"
    },
    "id": "saving-homework",
    "outputId": "178977a9-4413-4d38-b7f0-de8a9904b0e0",
    "papermill": {
     "duration": 0.098388,
     "end_time": "2021-05-30T18:40:02.575081",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.476693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7828 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# create validation generator\n",
    "valid_generator = valid_aug.flow_from_dataframe( \n",
    "    dataframe = df_val_compi,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = batch_size,\n",
    "    seed = seed,\n",
    "    shuffle= True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (image_size,image_size)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-belarus",
   "metadata": {
    "id": "marked-belarus",
    "papermill": {
     "duration": 0.033792,
     "end_time": "2021-05-30T18:40:02.643887",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.610095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "buried-tablet",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.724467Z",
     "iopub.status.busy": "2021-05-30T18:40:02.723830Z",
     "iopub.status.idle": "2021-05-30T18:40:08.132744Z",
     "shell.execute_reply": "2021-05-30T18:40:08.131632Z",
     "shell.execute_reply.started": "2021-05-30T09:28:56.068101Z"
    },
    "id": "buried-tablet",
    "outputId": "2be7f5dd-25c9-49e7-fce8-f3e1fbe9c6a1",
    "papermill": {
     "duration": 5.455093,
     "end_time": "2021-05-30T18:40:08.132878",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.677785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sel_model = model_name(weights = \"imagenet\",)\n",
    "x =  sel_model.layers[-10].output\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 1536, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 768, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 384, kernel_size= 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size= 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size= 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size= 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = n_class, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "GAP = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "pred = tf.keras.activations.softmax(GAP)\n",
    "\n",
    "pic_model = Model(inputs=sel_model.input,outputs = pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "DYVqXESmD_Fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYVqXESmD_Fd",
    "outputId": "88696012-6f00-42ba-d016-645743054fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 1536) 14157312    batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10, 10, 1536) 6144        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 10, 10, 1536) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 10, 10, 1024) 14156800    activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 10, 10, 1024) 4096        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 10, 1024) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 10, 10, 768)  7078656     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 10, 10, 768)  3072        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 10, 768)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 10, 10, 512)  3539456     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 10, 10, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 10, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 10, 10, 384)  1769856     activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 10, 10, 384)  1536        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 10, 384)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 10, 10, 256)  884992      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 10, 10, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 10, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 10, 10, 128)  295040      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 10, 10, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 10, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 10, 10, 64)   73792       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 10, 10, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 10, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 10, 10, 32)   18464       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 10, 10, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 10, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 10, 10, 16)   4624        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 10, 10, 16)   64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 10, 10, 16)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 10, 10, 5)    725         activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 10, 10, 5)    20          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 10, 10, 5)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 5)            0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.softmax (TFOpLambda)      (None, 5)            0           global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 56,808,561\n",
      "Trainable params: 56,755,255\n",
      "Non-trainable params: 53,306\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "norman-detector",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:08.391663Z",
     "iopub.status.busy": "2021-05-30T18:40:08.385701Z",
     "iopub.status.idle": "2021-05-30T18:40:08.398432Z",
     "shell.execute_reply": "2021-05-30T18:40:08.397997Z",
     "shell.execute_reply.started": "2021-05-30T09:28:58.465217Z"
    },
    "id": "norman-detector",
    "papermill": {
     "duration": 0.226948,
     "end_time": "2021-05-30T18:40:08.398547",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.171599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "pic_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr, decay = decay),\n",
    "    metrics = [\"acc\"],\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy)\n",
    "\n",
    "# callbacks and checkpoints\n",
    "checkpoint_name = name+\"_BS\"+str(batch_size)+\"_EP\"+str(train_epoch)+\"_IS\"+str(image_size)+\"_LP\"+str(LP)\n",
    "checkpoint_path = checkpoint_name+\".ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "my_callbacks = [\n",
    "              ModelCheckpoint(\n",
    "                   checkpoint_path,\n",
    "                   monitor = 'val_acc',\n",
    "                   verbose = 1,\n",
    "                   save_weights_only = True,\n",
    "                   save_best_only = True,\n",
    "                   mode = \"max\"\n",
    "                  ),\n",
    "              EarlyStopping(\n",
    "                   monitor = 'val_loss',\n",
    "                   patience = 10,\n",
    "                   verbose = 0\n",
    "                  ),\n",
    "              ReduceLROnPlateau(\n",
    "                   monitor = 'val_loss',\n",
    "                   patience = 10,\n",
    "                   verbose = 1\n",
    "                  )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-administration",
   "metadata": {
    "id": "crucial-administration",
    "papermill": {
     "duration": 0.038495,
     "end_time": "2021-05-30T18:40:08.475329",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.436834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weighting classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "regional-indie",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:08.558435Z",
     "iopub.status.busy": "2021-05-30T18:40:08.557616Z",
     "iopub.status.idle": "2021-05-30T18:40:09.060821Z",
     "shell.execute_reply": "2021-05-30T18:40:09.060357Z",
     "shell.execute_reply.started": "2021-05-30T09:30:11.007618Z"
    },
    "id": "regional-indie",
    "papermill": {
     "duration": 0.546357,
     "end_time": "2021-05-30T18:40:09.060960",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.514603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes = np.unique(df_train_kaggle.label.values),\n",
    "    y = df_train_kaggle.label.values\n",
    "  )\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-better",
   "metadata": {
    "id": "square-better",
    "papermill": {
     "duration": 0.037503,
     "end_time": "2021-05-30T18:40:09.136492",
     "exception": false,
     "start_time": "2021-05-30T18:40:09.098989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hidden-stephen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:09.218272Z",
     "iopub.status.busy": "2021-05-30T18:40:09.217728Z",
     "iopub.status.idle": "2021-05-30T20:12:12.156502Z",
     "shell.execute_reply": "2021-05-30T20:12:12.154537Z",
     "shell.execute_reply.started": "2021-05-26T18:49:57.904339Z"
    },
    "id": "hidden-stephen",
    "outputId": "1432984b-6c8d-4523-de45-b163a07ed120",
    "papermill": {
     "duration": 5522.981999,
     "end_time": "2021-05-30T20:12:12.156678",
     "exception": false,
     "start_time": "2021-05-30T18:40:09.174679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1224/1224 [==============================] - 129s 101ms/step - loss: 1.5043 - acc: 0.2399 - val_loss: 1.5766 - val_acc: 0.3625\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.36254, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 2/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 1.2641 - acc: 0.4348 - val_loss: 1.3681 - val_acc: 0.5147\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.36254 to 0.51469, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 3/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 1.1483 - acc: 0.5326 - val_loss: 1.2141 - val_acc: 0.6101\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.51469 to 0.61012, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 4/300\n",
      "1224/1224 [==============================] - 123s 100ms/step - loss: 1.0762 - acc: 0.5755 - val_loss: 1.2414 - val_acc: 0.5668\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.61012\n",
      "Epoch 5/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 1.0235 - acc: 0.6177 - val_loss: 1.0273 - val_acc: 0.7118\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.61012 to 0.71180, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 6/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.9623 - acc: 0.6646 - val_loss: 0.9300 - val_acc: 0.7687\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.71180 to 0.76865, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 7/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.9103 - acc: 0.7064 - val_loss: 0.9117 - val_acc: 0.7988\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.76865 to 0.79880, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 8/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.8434 - acc: 0.7644 - val_loss: 0.8484 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.79880 to 0.83367, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 9/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.7914 - acc: 0.8093 - val_loss: 0.7788 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.83367 to 0.86919, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 10/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.7477 - acc: 0.8431 - val_loss: 0.7497 - val_acc: 0.8797\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.86919 to 0.87966, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 11/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.7047 - acc: 0.8784 - val_loss: 0.6565 - val_acc: 0.9314\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.87966 to 0.93140, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 12/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.6842 - acc: 0.8937 - val_loss: 0.7195 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93140\n",
      "Epoch 13/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.6474 - acc: 0.9149 - val_loss: 0.6304 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.93140 to 0.96104, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 14/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.6395 - acc: 0.9189 - val_loss: 0.6245 - val_acc: 0.9596\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.96104\n",
      "Epoch 15/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.6210 - acc: 0.9325 - val_loss: 0.5778 - val_acc: 0.9746\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.96104 to 0.97458, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 16/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.6211 - acc: 0.9384 - val_loss: 0.6794 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.97458\n",
      "Epoch 17/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.6074 - acc: 0.9462 - val_loss: 0.6166 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.97458\n",
      "Epoch 18/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.5985 - acc: 0.9527 - val_loss: 0.5768 - val_acc: 0.9677\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.97458\n",
      "Epoch 19/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5949 - acc: 0.9496 - val_loss: 0.5964 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.97458\n",
      "Epoch 20/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5855 - acc: 0.9607 - val_loss: 0.6426 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.97458\n",
      "Epoch 21/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5805 - acc: 0.9608 - val_loss: 0.5453 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.97458 to 0.97611, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 22/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.5766 - acc: 0.9667 - val_loss: 0.5452 - val_acc: 0.9759\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.97611\n",
      "Epoch 23/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.5665 - acc: 0.9684 - val_loss: 0.5229 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.97611 to 0.98569, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 24/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.5685 - acc: 0.9711 - val_loss: 0.6418 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.98569\n",
      "Epoch 25/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.5557 - acc: 0.9748 - val_loss: 0.5359 - val_acc: 0.9851\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.98569\n",
      "Epoch 26/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.5660 - acc: 0.9732 - val_loss: 0.5160 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.98569 to 0.98723, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 27/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.5613 - acc: 0.9779 - val_loss: 0.5133 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.98723 to 0.99067, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 28/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5581 - acc: 0.9795 - val_loss: 0.5220 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.99067\n",
      "Epoch 29/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.5534 - acc: 0.9801 - val_loss: 0.5287 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.99067\n",
      "Epoch 30/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.5489 - acc: 0.9819 - val_loss: 0.4904 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.99067\n",
      "Epoch 31/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.5477 - acc: 0.9830 - val_loss: 0.4995 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.99067\n",
      "Epoch 32/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.5403 - acc: 0.9845 - val_loss: 0.5007 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.99067\n",
      "Epoch 33/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.5420 - acc: 0.9867 - val_loss: 0.5368 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.99067\n",
      "Epoch 34/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5383 - acc: 0.9850 - val_loss: 0.4936 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.99067\n",
      "Epoch 35/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5340 - acc: 0.9877 - val_loss: 0.4845 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.99067\n",
      "Epoch 36/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.5383 - acc: 0.9888 - val_loss: 0.4818 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.99067 to 0.99144, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 37/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.5357 - acc: 0.9867 - val_loss: 0.4751 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.99144\n",
      "Epoch 38/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.5414 - acc: 0.9877 - val_loss: 0.4796 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.99144\n",
      "Epoch 39/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5273 - acc: 0.9894 - val_loss: 0.5326 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.99144\n",
      "Epoch 40/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5223 - acc: 0.9929 - val_loss: 0.4824 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.99144\n",
      "Epoch 41/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5277 - acc: 0.9915 - val_loss: 0.4727 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.99144\n",
      "Epoch 42/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5250 - acc: 0.9908 - val_loss: 0.4653 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.99144\n",
      "Epoch 43/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5204 - acc: 0.9929 - val_loss: 0.4704 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.99144\n",
      "Epoch 44/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.5156 - acc: 0.9936 - val_loss: 0.4650 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.99144\n",
      "Epoch 45/300\n",
      "1224/1224 [==============================] - 123s 100ms/step - loss: 0.5170 - acc: 0.9929 - val_loss: 0.4781 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.99144\n",
      "Epoch 46/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5111 - acc: 0.9940 - val_loss: 0.4971 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.99144\n",
      "Epoch 47/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5145 - acc: 0.9936 - val_loss: 0.4737 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.99144\n",
      "Epoch 48/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5180 - acc: 0.9938 - val_loss: 0.4599 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.99144 to 0.99272, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 49/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5174 - acc: 0.9945 - val_loss: 0.4612 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.99272\n",
      "Epoch 50/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5027 - acc: 0.9955 - val_loss: 0.4535 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.99272\n",
      "Epoch 51/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.5139 - acc: 0.9947 - val_loss: 0.4632 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.99272\n",
      "Epoch 52/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.5093 - acc: 0.9963 - val_loss: 0.4469 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.99272 to 0.99387, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 53/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5063 - acc: 0.9968 - val_loss: 0.4772 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.99387\n",
      "Epoch 54/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.5097 - acc: 0.9942 - val_loss: 0.4643 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.99387\n",
      "Epoch 55/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.5005 - acc: 0.9951 - val_loss: 0.4599 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.99387\n",
      "Epoch 56/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5066 - acc: 0.9952 - val_loss: 0.4644 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.99387\n",
      "Epoch 57/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4964 - acc: 0.9963 - val_loss: 0.4408 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.99387 to 0.99540, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 58/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.5029 - acc: 0.9953 - val_loss: 0.4348 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.99540\n",
      "Epoch 59/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.4960 - acc: 0.9963 - val_loss: 0.4458 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.99540\n",
      "Epoch 60/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.5040 - acc: 0.9957 - val_loss: 0.4404 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.99540\n",
      "Epoch 61/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.4946 - acc: 0.9968 - val_loss: 0.4430 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.99540\n",
      "Epoch 62/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4967 - acc: 0.9959 - val_loss: 0.4396 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.99540\n",
      "Epoch 63/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.5056 - acc: 0.9956 - val_loss: 0.4376 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.99540\n",
      "Epoch 64/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.4948 - acc: 0.9978 - val_loss: 0.4249 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.99540\n",
      "Epoch 65/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4940 - acc: 0.9973 - val_loss: 0.4317 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.99540\n",
      "Epoch 66/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4943 - acc: 0.9962 - val_loss: 0.4345 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.99540\n",
      "Epoch 67/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4918 - acc: 0.9954 - val_loss: 0.4368 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.99540\n",
      "Epoch 68/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4811 - acc: 0.9973 - val_loss: 0.4347 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.99540\n",
      "Epoch 69/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4884 - acc: 0.9978 - val_loss: 0.4257 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.99540\n",
      "Epoch 70/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4879 - acc: 0.9972 - val_loss: 0.4322 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.99540\n",
      "Epoch 71/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4861 - acc: 0.9979 - val_loss: 0.4237 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.99540\n",
      "Epoch 72/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4877 - acc: 0.9981 - val_loss: 0.4285 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.99540\n",
      "Epoch 73/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4866 - acc: 0.9969 - val_loss: 0.4215 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.99540\n",
      "Epoch 74/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4751 - acc: 0.9986 - val_loss: 0.4272 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.99540\n",
      "Epoch 75/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4806 - acc: 0.9986 - val_loss: 0.4185 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.99540\n",
      "Epoch 76/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4869 - acc: 0.9975 - val_loss: 0.4212 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.99540\n",
      "Epoch 77/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4836 - acc: 0.9981 - val_loss: 0.4213 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.99540\n",
      "Epoch 78/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4792 - acc: 0.9980 - val_loss: 0.4229 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.99540\n",
      "Epoch 79/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4838 - acc: 0.9979 - val_loss: 0.4130 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.99540 to 0.99604, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 80/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4830 - acc: 0.9980 - val_loss: 0.4175 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.99604\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4776 - acc: 0.9985 - val_loss: 0.4346 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.99604\n",
      "Epoch 82/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4834 - acc: 0.9969 - val_loss: 0.4109 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.99604 to 0.99642, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 83/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4762 - acc: 0.9986 - val_loss: 0.4159 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.99642 to 0.99655, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 84/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4756 - acc: 0.9968 - val_loss: 0.4105 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.99655\n",
      "Epoch 85/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.4758 - acc: 0.9984 - val_loss: 0.4182 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.99655\n",
      "Epoch 86/300\n",
      "1224/1224 [==============================] - 123s 100ms/step - loss: 0.4788 - acc: 0.9971 - val_loss: 0.4198 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.99655\n",
      "Epoch 87/300\n",
      "1224/1224 [==============================] - 123s 100ms/step - loss: 0.4691 - acc: 0.9980 - val_loss: 0.4140 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.99655\n",
      "Epoch 88/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4729 - acc: 0.9985 - val_loss: 0.4113 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.99655\n",
      "Epoch 89/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4700 - acc: 0.9967 - val_loss: 0.4061 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.99655\n",
      "Epoch 90/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4700 - acc: 0.9986 - val_loss: 0.4079 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.99655\n",
      "Epoch 91/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4721 - acc: 0.9987 - val_loss: 0.4074 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.99655\n",
      "Epoch 92/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4703 - acc: 0.9984 - val_loss: 0.4171 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.99655\n",
      "Epoch 93/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4718 - acc: 0.9992 - val_loss: 0.4045 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.99655\n",
      "Epoch 94/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4717 - acc: 0.9984 - val_loss: 0.3994 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.99655\n",
      "Epoch 95/300\n",
      "1224/1224 [==============================] - 123s 100ms/step - loss: 0.4712 - acc: 0.9976 - val_loss: 0.3967 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.99655\n",
      "Epoch 96/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4712 - acc: 0.9983 - val_loss: 0.4070 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.99655\n",
      "Epoch 97/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4662 - acc: 0.9984 - val_loss: 0.4055 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.99655\n",
      "Epoch 98/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4662 - acc: 0.9969 - val_loss: 0.4050 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.99655\n",
      "Epoch 99/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4701 - acc: 0.9989 - val_loss: 0.4029 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.99655\n",
      "Epoch 100/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4680 - acc: 0.9991 - val_loss: 0.3916 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.99655\n",
      "Epoch 101/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4676 - acc: 0.9985 - val_loss: 0.3932 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.99655\n",
      "Epoch 102/300\n",
      "1224/1224 [==============================] - 123s 100ms/step - loss: 0.4625 - acc: 0.9982 - val_loss: 0.3941 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.99655\n",
      "Epoch 103/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.4680 - acc: 0.9979 - val_loss: 0.3997 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.99655\n",
      "Epoch 104/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4611 - acc: 0.9988 - val_loss: 0.4063 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.99655\n",
      "Epoch 105/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4650 - acc: 0.9990 - val_loss: 0.4008 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.99655\n",
      "Epoch 106/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4672 - acc: 0.9981 - val_loss: 0.3907 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.99655 to 0.99668, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 107/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4646 - acc: 0.9987 - val_loss: 0.3866 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.99668\n",
      "Epoch 108/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.4647 - acc: 0.9988 - val_loss: 0.3970 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.99668\n",
      "Epoch 109/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.4597 - acc: 0.9987 - val_loss: 0.4155 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.99668\n",
      "Epoch 110/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4582 - acc: 0.9996 - val_loss: 0.4121 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.99668\n",
      "Epoch 111/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4555 - acc: 0.9985 - val_loss: 0.3834 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.99668\n",
      "Epoch 112/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4600 - acc: 0.9990 - val_loss: 0.4000 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.99668\n",
      "Epoch 113/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4602 - acc: 0.9988 - val_loss: 0.3849 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.99668\n",
      "Epoch 114/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4576 - acc: 0.9987 - val_loss: 0.3965 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.99668\n",
      "Epoch 115/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4602 - acc: 0.9986 - val_loss: 0.3971 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.99668\n",
      "Epoch 116/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4584 - acc: 0.9988 - val_loss: 0.3982 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.99668\n",
      "Epoch 117/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4564 - acc: 0.9990 - val_loss: 0.3898 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.99668\n",
      "Epoch 118/300\n",
      "1224/1224 [==============================] - 122s 100ms/step - loss: 0.4544 - acc: 0.9994 - val_loss: 0.3839 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.99668\n",
      "Epoch 119/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4526 - acc: 0.9988 - val_loss: 0.3846 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.99668\n",
      "Epoch 120/300\n",
      "1224/1224 [==============================] - 121s 99ms/step - loss: 0.4567 - acc: 0.9990 - val_loss: 0.3872 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.99668\n",
      "Epoch 121/300\n",
      "1224/1224 [==============================] - 122s 99ms/step - loss: 0.4585 - acc: 0.9987 - val_loss: 0.3905 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.99668\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2da3ca425b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "pic_model.fit(\n",
    "        train_generator,\n",
    "        epochs = train_epoch,\n",
    "        validation_data = valid_generator,\n",
    "        callbacks = [my_callbacks],\n",
    "        class_weight = class_weights\n",
    "      )\n",
    "\n",
    "# load best saved weights\n",
    "pic_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-morris",
   "metadata": {
    "id": "pretty-morris",
    "papermill": {
     "duration": 3.201635,
     "end_time": "2021-05-30T20:12:18.344310",
     "exception": false,
     "start_time": "2021-05-30T20:12:15.142675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 훈련된 모델 재교육"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cloudy-idaho",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:24.238372Z",
     "iopub.status.busy": "2021-05-30T20:12:24.237660Z",
     "iopub.status.idle": "2021-05-30T20:12:24.305208Z",
     "shell.execute_reply": "2021-05-30T20:12:24.305579Z",
     "shell.execute_reply.started": "2021-05-30T09:30:16.948040Z"
    },
    "id": "cloudy-idaho",
    "papermill": {
     "duration": 3.027306,
     "end_time": "2021-05-30T20:12:24.305720",
     "exception": false,
     "start_time": "2021-05-30T20:12:21.278414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train and validation split on competition data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(\n",
    "    df_val_compi,\n",
    "    test_size = 0.1,\n",
    "    random_state = seed,\n",
    "    stratify = df_val_compi.label\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nervous-crisis",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:30.429807Z",
     "iopub.status.busy": "2021-05-30T20:12:30.429001Z",
     "iopub.status.idle": "2021-05-30T20:12:30.472297Z",
     "shell.execute_reply": "2021-05-30T20:12:30.471634Z",
     "shell.execute_reply.started": "2021-05-30T09:30:18.098841Z"
    },
    "id": "nervous-crisis",
    "outputId": "bf1114cc-1f2d-4777-cef4-bd4eb24d75dd",
    "papermill": {
     "duration": 3.239148,
     "end_time": "2021-05-30T20:12:30.472465",
     "exception": false,
     "start_time": "2021-05-30T20:12:27.233317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7045 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_aug.flow_from_dataframe(\n",
    "    dataframe = X_train,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = batch_size,\n",
    "    seed = seed,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (image_size,image_size)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "instrumental-indie",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:36.309467Z",
     "iopub.status.busy": "2021-05-30T20:12:36.308631Z",
     "iopub.status.idle": "2021-05-30T20:12:36.318017Z",
     "shell.execute_reply": "2021-05-30T20:12:36.317530Z",
     "shell.execute_reply.started": "2021-05-30T09:30:23.206485Z"
    },
    "id": "instrumental-indie",
    "outputId": "dceb0588-b8e8-4658-a8e4-9c7f11fc65a0",
    "papermill": {
     "duration": 2.927421,
     "end_time": "2021-05-30T20:12:36.318129",
     "exception": false,
     "start_time": "2021-05-30T20:12:33.390708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 783 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = valid_aug.flow_from_dataframe( \n",
    "    dataframe = X_test,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = batch_size,\n",
    "    seed = seed,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (image_size,image_size)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dedicated-chapel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:42.897491Z",
     "iopub.status.busy": "2021-05-30T20:12:42.895853Z",
     "iopub.status.idle": "2021-05-30T20:12:42.898202Z",
     "shell.execute_reply": "2021-05-30T20:12:42.898602Z",
     "shell.execute_reply.started": "2021-05-30T09:30:26.966513Z"
    },
    "id": "dedicated-chapel",
    "papermill": {
     "duration": 3.108025,
     "end_time": "2021-05-30T20:12:42.898739",
     "exception": false,
     "start_time": "2021-05-30T20:12:39.790714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of steps to consider 1 as  epoch\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sized-norfolk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:48.820785Z",
     "iopub.status.busy": "2021-05-30T20:12:48.819337Z",
     "iopub.status.idle": "2021-05-30T20:25:26.371458Z",
     "shell.execute_reply": "2021-05-30T20:25:26.371941Z",
     "shell.execute_reply.started": "2021-05-30T09:30:36.962285Z"
    },
    "id": "sized-norfolk",
    "outputId": "fc9b987c-a11c-49f1-b98c-d4879cee12f6",
    "papermill": {
     "duration": 760.527609,
     "end_time": "2021-05-30T20:25:26.372105",
     "exception": false,
     "start_time": "2021-05-30T20:12:45.844496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "880/880 [==============================] - 78s 87ms/step - loss: 0.5723 - acc: 0.9847 - val_loss: 0.3692 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.99668 to 0.99871, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 2/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5624 - acc: 0.9910 - val_loss: 0.3703 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.99871\n",
      "Epoch 3/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5663 - acc: 0.9915 - val_loss: 0.3682 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99871\n",
      "Epoch 4/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5587 - acc: 0.9925 - val_loss: 0.3662 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99871\n",
      "Epoch 5/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5648 - acc: 0.9929 - val_loss: 0.3711 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99871\n",
      "Epoch 6/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5517 - acc: 0.9953 - val_loss: 0.3785 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99871\n",
      "Epoch 7/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5485 - acc: 0.9957 - val_loss: 0.3759 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99871\n",
      "Epoch 8/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5536 - acc: 0.9970 - val_loss: 0.3752 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.99871 to 1.00000, saving model to Xception_BS8_EP300_IS224_LP10.ckpt\n",
      "Epoch 9/50\n",
      "880/880 [==============================] - 75s 86ms/step - loss: 0.5537 - acc: 0.9946 - val_loss: 0.3704 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 1.00000\n",
      "Epoch 10/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5525 - acc: 0.9960 - val_loss: 0.3755 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 1.00000\n",
      "Epoch 11/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5487 - acc: 0.9955 - val_loss: 0.3747 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 1.00000\n",
      "Epoch 12/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5484 - acc: 0.9979 - val_loss: 0.3724 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 1.00000\n",
      "Epoch 13/50\n",
      "880/880 [==============================] - 75s 86ms/step - loss: 0.5434 - acc: 0.9984 - val_loss: 0.3637 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 1.00000\n",
      "Epoch 14/50\n",
      "880/880 [==============================] - 75s 86ms/step - loss: 0.5491 - acc: 0.9972 - val_loss: 0.3699 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 1.00000\n",
      "Epoch 15/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5522 - acc: 0.9969 - val_loss: 0.3727 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 1.00000\n",
      "Epoch 16/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5439 - acc: 0.9969 - val_loss: 0.3670 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 1.00000\n",
      "Epoch 17/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5455 - acc: 0.9986 - val_loss: 0.3758 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 1.00000\n",
      "Epoch 18/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5452 - acc: 0.9973 - val_loss: 0.3691 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 1.00000\n",
      "Epoch 19/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5480 - acc: 0.9970 - val_loss: 0.3697 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 1.00000\n",
      "Epoch 20/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5435 - acc: 0.9964 - val_loss: 0.3753 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 1.00000\n",
      "Epoch 21/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5502 - acc: 0.9972 - val_loss: 0.3747 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 1.00000\n",
      "Epoch 22/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5463 - acc: 0.9974 - val_loss: 0.3664 - val_acc: 0.9987\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 1.00000\n",
      "Epoch 23/50\n",
      "880/880 [==============================] - 76s 86ms/step - loss: 0.5420 - acc: 0.9980 - val_loss: 0.3711 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2da3b8e7700>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kick off training\n",
    "pic_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "        epochs = val_epoch,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = STEP_SIZE_VALID,callbacks = [my_callbacks]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "complete-spelling",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:33.497837Z",
     "iopub.status.busy": "2021-05-30T20:25:33.496999Z",
     "iopub.status.idle": "2021-05-30T20:25:34.695800Z",
     "shell.execute_reply": "2021-05-30T20:25:34.695365Z",
     "shell.execute_reply.started": "2021-05-24T16:41:06.725854Z"
    },
    "id": "complete-spelling",
    "outputId": "10521e37-45bc-43e8-eae3-62b233e07b14",
    "papermill": {
     "duration": 4.566888,
     "end_time": "2021-05-30T20:25:34.695951",
     "exception": false,
     "start_time": "2021-05-30T20:25:30.129063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2d4c63f73a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best saved weights\n",
    "pic_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-cylinder",
   "metadata": {
    "id": "intended-cylinder",
    "papermill": {
     "duration": 3.633537,
     "end_time": "2021-05-30T20:25:41.743104",
     "exception": false,
     "start_time": "2021-05-30T20:25:38.109567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "equivalent-album",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:48.625234Z",
     "iopub.status.busy": "2021-05-30T20:25:48.624438Z",
     "iopub.status.idle": "2021-05-30T20:25:48.634216Z",
     "shell.execute_reply": "2021-05-30T20:25:48.633804Z",
     "shell.execute_reply.started": "2021-05-27T05:35:10.161826Z"
    },
    "id": "equivalent-album",
    "outputId": "2ed00c4a-4fd3-4d76-9ce5-6249f0da4489",
    "papermill": {
     "duration": 3.430239,
     "end_time": "2021-05-30T20:25:48.634343",
     "exception": false,
     "start_time": "2021-05-30T20:25:45.204104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 783 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "target_shape = 224\n",
    "BS = 1\n",
    "\n",
    "# test generator\n",
    "compi_gen = valid_aug.flow_from_dataframe(\n",
    "    dataframe = X_test,\n",
    "    x_col = \"filename\",\n",
    "    class_mode = None,\n",
    "    target_size = (target_shape, target_shape),\n",
    "    shuffle = False,\n",
    "    batch_size = BS\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "preceding-delight",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:56.117007Z",
     "iopub.status.busy": "2021-05-30T20:25:56.116264Z",
     "iopub.status.idle": "2021-05-30T20:26:05.659358Z",
     "shell.execute_reply": "2021-05-30T20:26:05.658569Z",
     "shell.execute_reply.started": "2021-05-27T05:35:17.324361Z"
    },
    "id": "preceding-delight",
    "outputId": "21817dd8-602c-4242-8998-5e3ae34e14e3",
    "papermill": {
     "duration": 12.914933,
     "end_time": "2021-05-30T20:26:05.659489",
     "exception": false,
     "start_time": "2021-05-30T20:25:52.744556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 6s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# prediction on train data\n",
    "predicition_compi = pic_model.predict(compi_gen, steps = compi_gen.n/ BS, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "distinguished-midwest",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:12.667940Z",
     "iopub.status.busy": "2021-05-30T20:26:12.649791Z",
     "iopub.status.idle": "2021-05-30T20:26:13.051891Z",
     "shell.execute_reply": "2021-05-30T20:26:13.051413Z",
     "shell.execute_reply.started": "2021-05-27T05:43:44.837052Z"
    },
    "id": "distinguished-midwest",
    "outputId": "07a44daf-1bcd-454d-aa10-3c479b130443",
    "papermill": {
     "duration": 3.832152,
     "end_time": "2021-05-30T20:26:13.052010",
     "exception": false,
     "start_time": "2021-05-30T20:26:09.219858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2da45c70220>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "class_prediction_compi = np.argmax(predicition_compi, axis = 1)\n",
    "cm = confusion_matrix(X_test.label, class_prediction_compi, labels = [0, 1, 2, 3, 4])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix = cm,\n",
    "    display_labels = [0, 1, 2, 3, 4]\n",
    "  )\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-wilson",
   "metadata": {
    "id": "positive-wilson",
    "papermill": {
     "duration": 3.5306,
     "end_time": "2021-05-30T20:26:20.277590",
     "exception": false,
     "start_time": "2021-05-30T20:26:16.746990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 시험세트 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "constitutional-catholic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:28.031789Z",
     "iopub.status.busy": "2021-05-30T20:26:28.031111Z",
     "iopub.status.idle": "2021-05-30T20:26:28.058944Z",
     "shell.execute_reply": "2021-05-30T20:26:28.058161Z",
     "shell.execute_reply.started": "2021-05-27T09:08:20.550041Z"
    },
    "id": "constitutional-catholic",
    "outputId": "91b6393c-4cdf-45ff-f39e-2eb2a0d17012",
    "papermill": {
     "duration": 4.034446,
     "end_time": "2021-05-30T20:26:28.059074",
     "exception": false,
     "start_time": "2021-05-30T20:26:24.024628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1958 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# read the csv file\n",
    "test = pd.read_csv(compi_root_path + \"Test.csv\")\n",
    "\n",
    "# create test generator\n",
    "test_generator = valid_aug.flow_from_dataframe(\n",
    "    dataframe = test,\n",
    "    directory = compi_root_path + \"test\",\n",
    "    x_col = \"filename\",\n",
    "    y_col = None,\n",
    "    batch_size = 1,\n",
    "    seed = seed,\n",
    "    shuffle = False,\n",
    "    class_mode = None,\n",
    "    target_size = (image_size, image_size)\n",
    "  )\n",
    "\n",
    "# number of steps to consider 1 epoch\n",
    "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "blocked-niagara",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:34.994605Z",
     "iopub.status.busy": "2021-05-30T20:26:34.994000Z",
     "iopub.status.idle": "2021-05-30T20:26:56.340759Z",
     "shell.execute_reply": "2021-05-30T20:26:56.341118Z",
     "shell.execute_reply.started": "2021-05-27T05:51:39.116529Z"
    },
    "id": "blocked-niagara",
    "outputId": "e8ed2e21-e61a-40ca-9976-0c87f7f7e9fa",
    "papermill": {
     "duration": 24.791614,
     "end_time": "2021-05-30T20:26:56.341303",
     "exception": false,
     "start_time": "2021-05-30T20:26:31.549689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958/1958 [==============================] - 14s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    769\n",
       "2    520\n",
       "1    353\n",
       "3    257\n",
       "4     59\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction and create dataframe out of it\n",
    "pred = pic_model.predict(test_generator,steps=STEP_SIZE_TEST,verbose=1)\n",
    "df_submit = pd.DataFrame({\"label\":np.argmax(pred, axis= 1)})\n",
    "df_submit[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-yacht",
   "metadata": {
    "id": "portable-yacht",
    "papermill": {
     "duration": 3.504245,
     "end_time": "2021-05-30T20:27:18.913681",
     "exception": false,
     "start_time": "2021-05-30T20:27:15.409436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 최적의 가중치 및 출력 예측 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "liquid-tsunami",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:27:26.290338Z",
     "iopub.status.busy": "2021-05-30T20:27:26.289493Z",
     "iopub.status.idle": "2021-05-30T20:27:26.809425Z",
     "shell.execute_reply": "2021-05-30T20:27:26.808879Z",
     "shell.execute_reply.started": "2021-05-27T05:51:46.57395Z"
    },
    "id": "liquid-tsunami",
    "papermill": {
     "duration": 4.073647,
     "end_time": "2021-05-30T20:27:26.809566",
     "exception": false,
     "start_time": "2021-05-30T20:27:22.735919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pic_model.save_weights(name+\"_BS\"+str(batch_size)+\"_EP\"+str(train_epoch)+\"_IS\"+str(image_size)+\"_LP\"+str(LP)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5096208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngkim\\Downloads\\MDL\\TermProject_중간보고\\result\n"
     ]
    }
   ],
   "source": [
    "cd C:\\\\Users\\\\ngkim\\\\Downloads\\\\MDL\\\\TermProject_중간보고\\\\result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4ee1c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv(name+\"_BS\"+str(batch_size)+\"_EP\"+str(train_epoch)+\"_IS\"+str(image_size)+\"_LP\"+str(LP)+\".csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-baptist",
   "metadata": {
    "id": "sustainable-baptist",
    "papermill": {
     "duration": 3.563445,
     "end_time": "2021-05-30T20:27:34.549379",
     "exception": false,
     "start_time": "2021-05-30T20:27:30.985934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Suggestion to improve the score**\n",
    "* Using right data augmentations\n",
    "* Using different model architecture\n",
    "* Ensembling and stacking\n",
    "* Using pretrained model trained on xray images\n",
    "\n",
    "**점수 향상을 위한 제안*\n",
    "* 올바른 데이터 확대 사용\n",
    "* 다른 모델 아키텍처 사용\n",
    "* 조립 및 쌓기\n",
    "* X선 영상에 대해 사전 훈련된 모델 사용\n",
    "\n",
    "## CheXNet - DenseNet121 + Sigmoid\n",
    "https://github.com/arnoweng/CheXNet/blob/master/model.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "KLGrade-DenseNet121-91.83.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6499.620651,
   "end_time": "2021-05-30T20:27:40.898205",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-30T18:39:21.277554",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
