{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optimizer_Nadam_5_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMDPrvCK3BK647Tj8SVaRJm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/Optimizer_Nadam_5_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e21c928-fac6-4e64-e529-bbbd1d8e141a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 15 17:43:47 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef0c992-e34d-41a9-eedc-0d5df41d81ae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18c6dbd-cbfe-4594-ff99-6975572b2046"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a1829e-0219-4d1e-f1a3-76937802c723"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 66s 323ms/step - loss: 1.7647 - accuracy: 0.3776 - val_loss: 2.7343 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 1.0109 - accuracy: 0.6626 - val_loss: 5.5294 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.09852 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.7536 - accuracy: 0.7491 - val_loss: 7.5640 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.10099\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.6087 - accuracy: 0.8015 - val_loss: 6.3354 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.10099 to 0.11330, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.5451 - accuracy: 0.8179 - val_loss: 2.9786 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.11330\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.4512 - accuracy: 0.8551 - val_loss: 3.8987 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.11330\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.4037 - accuracy: 0.8508 - val_loss: 9.4731 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.11330\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.3635 - accuracy: 0.8733 - val_loss: 10.8360 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.11330\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.3781 - accuracy: 0.8831 - val_loss: 5.4195 - val_accuracy: 0.2315\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.11330 to 0.23153, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.3170 - accuracy: 0.8861 - val_loss: 3.2368 - val_accuracy: 0.2833\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.23153 to 0.28325, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.2700 - accuracy: 0.9105 - val_loss: 1.4208 - val_accuracy: 0.5493\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.28325 to 0.54926, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.2760 - accuracy: 0.9105 - val_loss: 2.7785 - val_accuracy: 0.3695\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.54926\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.2632 - accuracy: 0.9013 - val_loss: 1.1196 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.54926 to 0.66256, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.1926 - accuracy: 0.9385 - val_loss: 3.6430 - val_accuracy: 0.3842\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.66256\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.2477 - accuracy: 0.9147 - val_loss: 1.2577 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.66256\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.1858 - accuracy: 0.9324 - val_loss: 1.5557 - val_accuracy: 0.5985\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.66256\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.1623 - accuracy: 0.9446 - val_loss: 0.8729 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.66256 to 0.72167, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.5781 - accuracy: 0.8295 - val_loss: 6.8143 - val_accuracy: 0.1650\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.72167\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.2116 - accuracy: 0.9208 - val_loss: 1.8627 - val_accuracy: 0.4729\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.72167\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.1781 - accuracy: 0.9434 - val_loss: 0.9011 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.72167 to 0.76601, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.1905 - accuracy: 0.9342 - val_loss: 0.7005 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.76601\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.1533 - accuracy: 0.9482 - val_loss: 2.6879 - val_accuracy: 0.4089\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.76601\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.1541 - accuracy: 0.9507 - val_loss: 0.9069 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.76601\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0982 - accuracy: 0.9653 - val_loss: 0.5979 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.76601 to 0.82266, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0818 - accuracy: 0.9750 - val_loss: 0.5365 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.82266 to 0.83498, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0720 - accuracy: 0.9769 - val_loss: 0.8848 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.83498\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0704 - accuracy: 0.9781 - val_loss: 0.4406 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.83498 to 0.88916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.1208 - accuracy: 0.9635 - val_loss: 1.2416 - val_accuracy: 0.5911\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.88916\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0821 - accuracy: 0.9738 - val_loss: 0.7950 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.88916\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0866 - accuracy: 0.9683 - val_loss: 0.5364 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.88916\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0717 - accuracy: 0.9787 - val_loss: 0.8136 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.88916\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.1037 - accuracy: 0.9689 - val_loss: 0.8540 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.88916\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0934 - accuracy: 0.9677 - val_loss: 0.6653 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.88916\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0720 - accuracy: 0.9799 - val_loss: 0.6222 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.88916\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.1416 - accuracy: 0.9598 - val_loss: 0.8026 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.88916\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.1008 - accuracy: 0.9689 - val_loss: 3.5820 - val_accuracy: 0.3227\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.88916\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0882 - accuracy: 0.9695 - val_loss: 0.7222 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.88916\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0661 - accuracy: 0.9811 - val_loss: 1.0432 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.88916\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0425 - accuracy: 0.9884 - val_loss: 0.4916 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.88916\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0747 - accuracy: 0.9756 - val_loss: 0.5437 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.88916\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.1229 - accuracy: 0.9562 - val_loss: 0.5170 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.88916\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0414 - accuracy: 0.9896 - val_loss: 0.6159 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.88916\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0298 - accuracy: 0.9927 - val_loss: 0.4711 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.88916\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0565 - accuracy: 0.9811 - val_loss: 0.9722 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.88916\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0426 - accuracy: 0.9878 - val_loss: 1.0909 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.88916\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0409 - accuracy: 0.9884 - val_loss: 0.6463 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.88916\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0851 - accuracy: 0.9756 - val_loss: 1.0894 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.88916\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0537 - accuracy: 0.9829 - val_loss: 0.9859 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.88916\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0476 - accuracy: 0.9811 - val_loss: 0.8162 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.88916\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0553 - accuracy: 0.9799 - val_loss: 0.3376 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.88916\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0526 - accuracy: 0.9842 - val_loss: 0.4603 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.88916\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0354 - accuracy: 0.9872 - val_loss: 0.4257 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.88916\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0418 - accuracy: 0.9854 - val_loss: 0.7873 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.88916\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 0.4769 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.88916\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.3723 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.88916 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.3376 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.90640\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0179 - accuracy: 0.9963 - val_loss: 0.3881 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.90640\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 1.0387 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.90640\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0575 - accuracy: 0.9842 - val_loss: 1.1122 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.90640\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0416 - accuracy: 0.9878 - val_loss: 0.9911 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.90640\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0571 - accuracy: 0.9781 - val_loss: 0.8421 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.90640\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0471 - accuracy: 0.9848 - val_loss: 1.3047 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.90640\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0773 - accuracy: 0.9732 - val_loss: 1.1459 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.90640\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0664 - accuracy: 0.9775 - val_loss: 0.7055 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.90640\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0533 - accuracy: 0.9836 - val_loss: 0.7501 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.90640\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0558 - accuracy: 0.9793 - val_loss: 0.7014 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.90640\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0492 - accuracy: 0.9872 - val_loss: 0.9046 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.90640\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0425 - accuracy: 0.9860 - val_loss: 0.7296 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.90640\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.5393 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.90640\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0368 - accuracy: 0.9890 - val_loss: 0.6245 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.90640\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0830 - accuracy: 0.9744 - val_loss: 1.1686 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.90640\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0654 - accuracy: 0.9750 - val_loss: 0.9075 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.90640\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0449 - accuracy: 0.9842 - val_loss: 1.4900 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90640\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0643 - accuracy: 0.9744 - val_loss: 0.5434 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.90640\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0553 - accuracy: 0.9805 - val_loss: 0.7761 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.90640\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 0.3739 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.90640 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.91379 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 1.5037 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.92611\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.1001 - accuracy: 0.9689 - val_loss: 2.3444 - val_accuracy: 0.5099\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.92611\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0630 - accuracy: 0.9775 - val_loss: 0.8249 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.92611\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0372 - accuracy: 0.9896 - val_loss: 1.0484 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.92611\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0231 - accuracy: 0.9909 - val_loss: 1.4567 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.92611\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.6848 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.92611\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 0.4263 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.92611\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5662 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.92611\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.5291 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.92611\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.3728 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.92611\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.4203 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.92611\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.3384 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.92611\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0181 - accuracy: 0.9957 - val_loss: 0.9434 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.92611\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0768 - accuracy: 0.9799 - val_loss: 0.9455 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.92611\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0813 - accuracy: 0.9708 - val_loss: 1.2350 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.92611\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0553 - accuracy: 0.9805 - val_loss: 1.0131 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.92611\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0252 - accuracy: 0.9927 - val_loss: 0.6922 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.92611\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 0.7576 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.92611\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0214 - accuracy: 0.9890 - val_loss: 1.6157 - val_accuracy: 0.6133\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.92611\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0537 - accuracy: 0.9823 - val_loss: 1.0345 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.92611\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0300 - accuracy: 0.9896 - val_loss: 0.5866 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.92611\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.4709 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.92611\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0637 - accuracy: 0.9775 - val_loss: 0.9775 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.92611\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0477 - accuracy: 0.9829 - val_loss: 0.8385 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.92611\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.5832 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.92611\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.6348 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.92611\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5251 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.92611\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.4348 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.92611\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0877 - accuracy: 0.9762 - val_loss: 0.7189 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.92611\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0462 - accuracy: 0.9860 - val_loss: 1.2148 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.92611\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0509 - accuracy: 0.9836 - val_loss: 0.5763 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.92611\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.3667 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.92611\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.3720 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.92611\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.5945 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.92611\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.3626 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.92611\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4397 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.92611\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.6798 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.92611\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4374 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.92611\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0418 - accuracy: 0.9896 - val_loss: 0.8184 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.92611\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0398 - accuracy: 0.9890 - val_loss: 0.7027 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.92611\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0305 - accuracy: 0.9890 - val_loss: 0.5959 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.92611\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0385 - accuracy: 0.9860 - val_loss: 0.9776 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.92611\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0566 - accuracy: 0.9811 - val_loss: 1.2450 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.92611\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0465 - accuracy: 0.9872 - val_loss: 1.1539 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.92611\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 1.4058 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.92611\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.8421 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.92611\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0522 - accuracy: 0.9866 - val_loss: 1.6243 - val_accuracy: 0.6133\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.92611\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0731 - accuracy: 0.9769 - val_loss: 0.9121 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.92611\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0887 - accuracy: 0.9720 - val_loss: 1.8707 - val_accuracy: 0.5369\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.92611\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0451 - accuracy: 0.9836 - val_loss: 1.2562 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.92611\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 1.2697 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.92611\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0293 - accuracy: 0.9896 - val_loss: 2.0307 - val_accuracy: 0.5567\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.92611\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 1.3240 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.92611\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6459 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.92611\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.92611\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4776 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.92611\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.5658 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.92611\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.4793 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.92611\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4385 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.92611\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5629 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.92611\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.3740 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.92611\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.92611\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.92611\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5944 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.92611\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0156 - accuracy: 0.9939 - val_loss: 0.5181 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.92611\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.6345 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.92611\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.7533 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.92611\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 0.7056 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.92611\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.7144 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.92611\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.6633 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.92611\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 1.4332 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.92611\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0355 - accuracy: 0.9866 - val_loss: 1.9650 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.92611\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0914 - accuracy: 0.9695 - val_loss: 3.2451 - val_accuracy: 0.6478\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.92611\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0608 - accuracy: 0.9823 - val_loss: 1.4096 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.92611\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.1097 - accuracy: 0.9720 - val_loss: 2.8780 - val_accuracy: 0.4064\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.92611\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0647 - accuracy: 0.9805 - val_loss: 1.8530 - val_accuracy: 0.5148\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.92611\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0317 - accuracy: 0.9872 - val_loss: 1.2956 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92611\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0280 - accuracy: 0.9927 - val_loss: 0.9826 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92611\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.8504 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92611\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.7869 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92611\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5718 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92611\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.5567 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92611\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 0.7589 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92611\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.8372 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92611\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0391 - accuracy: 0.9909 - val_loss: 1.0278 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92611\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0280 - accuracy: 0.9921 - val_loss: 0.5766 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92611\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.5567 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92611\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.5638 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92611\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 1.2353 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92611\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0411 - accuracy: 0.9836 - val_loss: 0.6587 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92611\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.5916 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92611\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.5520 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92611\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0396 - accuracy: 0.9878 - val_loss: 0.4829 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92611\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.4861 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92611\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.3556 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92611\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.4890 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92611\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.5381 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92611\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.4483 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92611\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 1.0463 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92611\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.5720 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92611\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.5856 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92611\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4182 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92611\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.4341 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92611\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.6739 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92611\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0413 - accuracy: 0.9848 - val_loss: 1.3016 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92611\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0378 - accuracy: 0.9890 - val_loss: 0.6076 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92611\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.4902 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92611\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4726 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92611\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4853 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92611\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92611\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92611\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3983 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92611\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92611\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.6862 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92611\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.1050 - accuracy: 0.9647 - val_loss: 1.3167 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92611\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 0.8655 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92611\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.5493 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92611\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0313 - accuracy: 0.9933 - val_loss: 0.8297 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92611\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0184 - accuracy: 0.9957 - val_loss: 0.5157 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92611\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.6111 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92611\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4800 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92611\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 7.8369e-04 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92611\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92611\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 3.6700 - val_accuracy: 0.5099\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92611\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0298 - accuracy: 0.9878 - val_loss: 1.3410 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92611\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0849 - accuracy: 0.9714 - val_loss: 1.4513 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92611\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0278 - accuracy: 0.9890 - val_loss: 0.6535 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92611\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0287 - accuracy: 0.9909 - val_loss: 0.7894 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92611\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0186 - accuracy: 0.9927 - val_loss: 0.7194 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92611\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.4515 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92611\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.5659 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92611\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4061 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92611\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 14s 260ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92611\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.4230 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92611\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4197 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92611\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00213: val_accuracy improved from 0.92611 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 7.3477e-04 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93350\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93350\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93350\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 4.1765e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93350\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 2.3580e-04 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93350\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 3.8294e-04 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93350\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.3746 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93350\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93350\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 4.0665e-04 - accuracy: 1.0000 - val_loss: 0.3288 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93350\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 3.1264e-04 - accuracy: 1.0000 - val_loss: 0.3387 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93350\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 13s 259ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93350\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.4629 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93350\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.1165 - accuracy: 0.9708 - val_loss: 1.5550 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93350\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0660 - accuracy: 0.9793 - val_loss: 1.2146 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93350\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0868 - accuracy: 0.9714 - val_loss: 2.7843 - val_accuracy: 0.5690\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93350\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.7297 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93350\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0461 - accuracy: 0.9860 - val_loss: 0.6975 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93350\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 0.7020 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93350\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0259 - accuracy: 0.9939 - val_loss: 2.9084 - val_accuracy: 0.4335\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93350\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 1.0205 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93350\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0135 - accuracy: 0.9939 - val_loss: 0.8556 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93350\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.6072 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93350\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.5418 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93350\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.3998 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93350\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93350\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3314 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93350\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.3428 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93350\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 8.2773e-04 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93350\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 5.4084e-04 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93350\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 6.1518e-04 - accuracy: 1.0000 - val_loss: 0.3771 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93350\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 3.1140e-04 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93350\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.4136 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93350\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.4383 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93350\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 7.3213e-04 - accuracy: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93350\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4702 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93350\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.5026 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93350\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.3865 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93350\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.3889 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93350\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.5756 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93350\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0479 - accuracy: 0.9872 - val_loss: 0.6755 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93350\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 0.8792 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93350\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 0.7692 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93350\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 1.2779 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93350\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0434 - accuracy: 0.9896 - val_loss: 0.8790 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93350\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.4970 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93350\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.4217 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93350\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0257 - accuracy: 0.9927 - val_loss: 0.5316 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93350\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0174 - accuracy: 0.9927 - val_loss: 1.3464 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93350\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.5159 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93350\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4596 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93350\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93350\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 9.3363e-04 - accuracy: 1.0000 - val_loss: 0.4081 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93350\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 7.5654e-04 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93350\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 6.5323e-04 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93350\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4539 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93350\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3975 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93350\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93350\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.5721 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93350\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4424 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93350\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.7951 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93350\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.4707 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93350\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0136 - accuracy: 0.9945 - val_loss: 0.7168 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93350\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.6999 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93350\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0403 - accuracy: 0.9909 - val_loss: 0.6845 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93350\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.7100 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93350\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.6648 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93350\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.4997 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93350\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0193 - accuracy: 0.9927 - val_loss: 1.1721 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93350\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0428 - accuracy: 0.9878 - val_loss: 0.7175 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93350\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 1.8089 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93350\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0745 - accuracy: 0.9769 - val_loss: 0.5967 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93350\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 13s 250ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.5516 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93350\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.6048 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93350\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5011 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93350\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4103 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93350\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3622 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93350\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.4792 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93350\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.3860 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93350\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 13s 250ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93350\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 13s 250ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5349 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93350\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 7.5072e-04 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93350\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.5188 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93350\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0329 - accuracy: 0.9903 - val_loss: 0.8236 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93350\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.5654 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93350\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.5184 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93350\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 0.5840 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93350\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0207 - accuracy: 0.9896 - val_loss: 0.9880 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93350\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 0.0131 - accuracy: 0.9945 - val_loss: 0.6463 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93350\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.7168 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93350\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.6734 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93350\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.4129 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93350\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 13s 250ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.6265 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93350\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5601 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93350\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.5600 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93350\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 13s 250ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.6434 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93350\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.4808 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93350\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.3493 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93350\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.8124 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93350\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 1.2209 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93350\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.7524 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93350\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 1.6471 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93350\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0091 - accuracy: 0.9957 - val_loss: 0.9988 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93350\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5907 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93350\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5351 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93350\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 9.2270e-04 - accuracy: 1.0000 - val_loss: 0.5668 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93350\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 7.0756e-04 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93350\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.7368 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93350\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.7521 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93350\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0228 - accuracy: 0.9896 - val_loss: 0.5758 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93350\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 14s 260ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.5292 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93350\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.5708 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93350\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4676 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93350\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93350\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5232 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93350\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0722 - accuracy: 0.9799 - val_loss: 1.3352 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93350\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0245 - accuracy: 0.9939 - val_loss: 1.1938 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93350\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0170 - accuracy: 0.9976 - val_loss: 1.0911 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93350\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0099 - accuracy: 0.9951 - val_loss: 0.6286 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93350\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4668 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93350\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 6.4270e-04 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93350\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 6.8715e-04 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93350\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4846 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93350\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4364 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93350\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 5.7924e-04 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93350\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5383 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93350\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5693 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93350\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 6.5107e-04 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93350\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4899 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93350\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0378 - accuracy: 0.9878 - val_loss: 0.6819 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93350\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0420 - accuracy: 0.9872 - val_loss: 1.3992 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93350\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 1.6822 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93350\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.6885 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93350\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0551 - accuracy: 0.9872 - val_loss: 0.9745 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93350\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.7425 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93350\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 1.0360 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93350\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6368 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93350\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4765 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93350\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 14s 261ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93350\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4337 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93350\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.6221 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93350\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 1.2538 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93350\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 1.0964 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93350\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5044 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93350\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93350\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93350\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93350\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5350 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93350\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0121 - accuracy: 0.9945 - val_loss: 1.0836 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93350\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.5760 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93350\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.6211 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93350\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.6232 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93350\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 1.0957 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93350\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.9642 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93350\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 0.6478 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93350\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.9034 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93350\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.8115 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93350\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.5092 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93350\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.6031 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93350\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5854 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93350\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5689 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93350\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5181 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93350\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.9144 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93350\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 13s 250ms/step - loss: 0.0194 - accuracy: 0.9927 - val_loss: 0.8340 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93350\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0136 - accuracy: 0.9945 - val_loss: 0.7527 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93350\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.7049 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93350\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.6684 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93350\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.5877 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93350\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.7252 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93350\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 13s 250ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 1.0795 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93350\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 13s 250ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.8433 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93350\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.7481 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93350\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 0.0254 - accuracy: 0.9933 - val_loss: 1.1851 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93350\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.7362 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93350\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5671 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93350\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93350\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 9.4792e-04 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93350\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0224 - accuracy: 0.9945 - val_loss: 0.8210 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93350\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0232 - accuracy: 0.9915 - val_loss: 1.2526 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93350\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.6796 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93350\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.7924 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93350\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4266 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93350\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 4.0148e-04 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93350\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 7.0528e-04 - accuracy: 0.9994 - val_loss: 0.4558 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93350\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 8.3815e-04 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93350\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 5.8665e-04 - accuracy: 1.0000 - val_loss: 0.4530 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93350\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 8.8908e-04 - accuracy: 1.0000 - val_loss: 0.5017 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93350\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 2.1423e-04 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93350\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 2.1760e-04 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93350\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4289 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93350\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 2.4700e-04 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93350\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 3.0221e-04 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93350\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 1.5325e-04 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93350\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 8.1693e-05 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93350\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 3.2137e-04 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93350\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 1.5601e-04 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93350\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 9.2451e-04 - accuracy: 0.9994 - val_loss: 0.4180 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93350\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 7.7212e-04 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.93350\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 1.2990e-04 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.93350\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 1.9112e-04 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.93350\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 8.9461e-05 - accuracy: 1.0000 - val_loss: 0.3977 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.93350\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 2.5496e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.93350\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 2.6807e-04 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.93350\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 9.8226e-05 - accuracy: 1.0000 - val_loss: 0.4164 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93350\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 2.2693e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93350\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 1.5977e-04 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93350\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 2.1884e-04 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93350\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 5.7095e-05 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.93350\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 14s 260ms/step - loss: 1.0709e-04 - accuracy: 1.0000 - val_loss: 0.3869 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00421: val_accuracy improved from 0.93350 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 8.9546e-05 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93596\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 5.7797e-05 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93596\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 1.1983e-04 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93596\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 1.0638e-04 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93596\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 3.7884e-05 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93596\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 6.3830e-05 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93596\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 4.1180e-05 - accuracy: 1.0000 - val_loss: 0.3705 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93596\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 3.9628e-05 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00429: val_accuracy improved from 0.93596 to 0.94335, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 4.1465e-05 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94335\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 3.5248e-05 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94335\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 4.1195e-05 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94335\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 14s 261ms/step - loss: 5.1395e-05 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.9483\n",
            "\n",
            "Epoch 00433: val_accuracy improved from 0.94335 to 0.94828, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 14s 261ms/step - loss: 4.8788e-05 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94828\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 1.5410e-04 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94828\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 2.9239e-05 - accuracy: 1.0000 - val_loss: 0.3866 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94828\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 4.1198e-05 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94828\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 14s 260ms/step - loss: 6.4062e-05 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94828\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 4.3636e-05 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94828\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 14s 261ms/step - loss: 5.2148e-05 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94828\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 7.2690e-05 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94828\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 3.0907e-05 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94828\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 2.5071e-05 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9483\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94828\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 4.9498e-05 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9458\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94828\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 14s 260ms/step - loss: 3.8101e-05 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94828\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 1.2088e-05 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94828\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 2.6081e-05 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94828\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 14s 261ms/step - loss: 4.1161e-05 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94828\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 14s 260ms/step - loss: 2.1063e-05 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94828\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 8.0827e-05 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94828\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 14s 262ms/step - loss: 3.7993e-05 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94828\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 2.2239e-05 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94828\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 2.1197e-05 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94828\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0722 - accuracy: 0.9836 - val_loss: 7.3581 - val_accuracy: 0.3867\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94828\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.1342 - accuracy: 0.9622 - val_loss: 4.4472 - val_accuracy: 0.5591\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94828\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0590 - accuracy: 0.9817 - val_loss: 0.6917 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94828\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 1.0257 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94828\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 0.0334 - accuracy: 0.9909 - val_loss: 0.9039 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94828\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 0.7807 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94828\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4351 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94828\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4693 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94828\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 13s 257ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94828\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.3986 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94828\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 8.3961e-04 - accuracy: 1.0000 - val_loss: 0.6254 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94828\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 14s 258ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.5091 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94828\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94828\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5195 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94828\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 4.6858e-04 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94828\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.4483 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94828\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.6671 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94828\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.6078 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94828\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.6889 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94828\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.5803 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94828\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.5666 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94828\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.6711 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94828\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.6694 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94828\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.8049 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94828\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4464 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94828\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0057 - accuracy: 0.9963 - val_loss: 0.5171 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94828\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0198 - accuracy: 0.9951 - val_loss: 0.8985 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94828\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 1.0677 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94828\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0097 - accuracy: 0.9957 - val_loss: 1.0201 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94828\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.6758 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94828\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.7123 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94828\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.7384 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94828\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0097 - accuracy: 0.9951 - val_loss: 1.2062 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94828\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 13s 256ms/step - loss: 0.0100 - accuracy: 0.9988 - val_loss: 1.0525 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94828\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 13s 258ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.6219 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94828\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.5413 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94828\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0183 - accuracy: 0.9957 - val_loss: 0.7116 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94828\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0338 - accuracy: 0.9921 - val_loss: 0.8485 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94828\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.6650 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94828\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.5841 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94828\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.8078 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94828\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.5442 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94828\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 9.1510e-04 - accuracy: 1.0000 - val_loss: 0.5281 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94828\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 7.5888e-04 - accuracy: 0.9994 - val_loss: 0.4595 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94828\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4410 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94828\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 5.5857e-04 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94828\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 3.9076e-04 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94828\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe6a9cdae50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "fa4beee9-f9b1-4c50-8919-4fae8ac5d686"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd5hbxdm375G0fdde97ZugI1xx9hgUw0GbHrooSShBEMCIW9CCUneL0ASaoAQSigpQCC00ELymhIbGwyhGQw2LtjGvXdvL5Lm+2M00jlH56jsale72rmvay+tjk4vv/PMb56ZEVJKDAaDwdDx8WV7BwwGg8GQGYygGwwGQ45gBN1gMBhyBCPoBoPBkCMYQTcYDIYcIZCtDffs2VMOGTIkW5s3GAyGDslnn322U0rZy+23rAn6kCFDWLBgQbY2bzAYDB0SIcQ6r9+M5WIwGAw5ghF0g8FgyBGMoBsMBkOOYATdYDAYcgQj6AaDwZAjJBV0IcRfhRDbhRBfefwuhBAPCCFWCSEWCSEmZH43DQaDwZCMVCL0J4EZCX4/CRgW+ZsJPNLy3TIYDAZDuiTNQ5dSvieEGJJgljOAv0nVD+9HQohyIUQ/KeWWDO1ju0NKSTAsyfOn7lhJKXlxwQZOGNmX7iX5ADQGw9Q0BPH5BHOXb+eQwd0Y2L3YtlwwFEYIgd8n2LKvDp8Q9OlSCEBdYwiAdbtr6FKYR/eSfArz/J77EAyFef7TDdQ1hjjj4P4s2rCPvICPRRv20rdrIWcePIBAgmOSUvLVpkqKC/zs36s04fFu2ltHnk/Qu0shwVAYv08ghKAhGGL20u1s2FNLbUOQ/ICP7x4+hC6FedF9fHvpNlZuq+aCQwfSO3KsAJ+t28OijXvpWVrAul01NAbD0d8K8vyEwpJgKEyXojzOnTiQrkV5cftV1xjin19sIhiWVNY3Ud8YIj/go0dpAfvqmjh6WC+6l+RTXOCP7pOVbZX1vPL5Juoag+T5ffQrL2JndQNDehRT1xTiuBF96FqUZztmgFBYsmxLJdsq69lT28SemkYkktKCPI4e3pM8vy96XRuCIeav2ElISob3KWPFtiomDelO95J8GoIhXvl8E1v21nFAnzJOH9efhmCI2oYQry7cxMGDyjl4UDd2VjfwyucbCYVhaM9iNu6po7YxRNeiPM4+pILSgkB0v/6zdBsb99RyUL8uHL5/D/61aAurtlXh8wmOP6gPowd05ePVuxjRr0v0nK7cVsVXm/fRv2sRYyvKKcpX992G3bVUdCsiFJZI4KXPNrJlbx3HHNiLsIS1O2vYVdMIQG1DMHrtgiFJKKyup9/nIy8gqI/c363N0cN7MXFIdwDCYckna3ezaONeBILaxhChcJghPUs4sG8Zw3qXUR8M0RQMs7WynrKCPAb1UM9sY1Bd88176ygtCFBenIcQgvqmEB+v2c3KbVXkB3zsrGpg2kF9GDewPOPHkomGRQOADZbvGyPT4gRdCDETFcUzaNCgDGw6O/xx3jf87q2vmTGqL3efO9b1wf/dW8s5bkRvDhmsbpQPV+/iZy8v5tWFm3h+5hS2V9Zz7mMfsm5XbXSZnqX5vPk/R9OztCA67caXF7G9soGbThrBWX/8L2EpeeqyQynM83PJE59QVR+MzvudyYP5zbdGA3Df21/z+PzV3HfeeE4e0w8pJc9/uoH/fU05Z7fNWha3zx9+s4srj9kfgAP7ltl+k1Jy67+W8uR/10an/ei4A6LCMHFIN0oKAizasI9/LdrMf7/ZhZSSKfv34PN1exnco5hHLz6Em19fwrsrdgAgBEgJYQkFAR+frNnNml01rN5RA8CmvbXcfc44AB579xvueGO5bZ8iWom1S3+9zhXbqqLLasF7f9VOHpizkpXbq+Pm19wZ2Ua+38e8G6bSv7yIJz9Yw6a9dfzi5IO45tnP+XTtnrjlNJP3685lRwzlx89/wZCeJTx12SS6Fedz2ZOfMn/lzvgFLLx45RTufnM5n6/fQ9ix7iE9iqmqD1LdEKTB8iLzCfjFK4upjNwHPUryGT+wnDnLt3tup7ohyMj+XSgtCPDcx+t5ZeEmz3nvn73Stg9njB/AO8u3s3RLJaHITp558AAuOXwIy7dW8rOXFzP1wF58vbWKLfvqo8s++u5qGkNh27qd18/re2siJcxbsYPXrzkSgF+9/hXPfLQ+5eX9PsGMUX3x+QQfrNqJT8DumkbCEvbvVUJ1Q5A9NU1xx967S2GrCLpIZYCLSIT+bynlaJff/g3cKaV8P/J9DvAzKWXCZqATJ06U7bWlaH1TiB89t5CJg7tFBU5T1xhi5M1vRm+6W04bySVHDLXNs35XLUf/bi4Aa+88BYDr//ElL322EYAF/3s81zz7OV9s2MthQ3tQWd/EaWP78+t/L+WOs8awcU8tG3bXccP0A5l277sUBHxccNggHn9vNQCXHjGELXvreXvpVs6fNJBB3Uu4683lBHyCD38+jZ6l+Rx511w27a1jxqi+PHjhwUy5Yw47qxuZNKQbA7sV88rCTVx2xFCOP6g3B/Yt47b/W2Z7sK84aii/OPmgaIT57Mfr+cWrizlrwgDmLNvOvrqmhOfwjPH92bK3nkWb9jJlvx58vn4v4bCkqiHIpUcM4X+mDadrcR7f+cvHLN60j721an3lxXncedZY5q/cwT8WbGTOdcfw4oINPPjOKk4Z24+rpx7Ah6t3cfaEAZQX59vOeUmBnx6lBZz9yH+RUvLXSybx94/X87cP17KtsgGAQd2L+eUpBzFmQFdKCwN0Kcxj7c4aNu+rY/9epfzzi000hSS/e+trAO44aww/f2UxAGWFAarqg9w440B+OPUAdtc0smVfHQPKi1i9s4a5y7fz4Dur8PsEBQEfwbDksKHdufLo/bn4Lx9zzbEHcOyIXvQqLaS0MICUkkN+O9t23gI+wUWHDWLqgb0J+AVb9tWzo6qBP8xeSfeSfLZW1nPttGH8cOr+TL//vWhAMHFwN/p2LeTfi2Jx1B++PZ5JQ7qzblctPUrz6VVawFmP/Jc1O2ts27z8yKFcefR+/POLzdw2axnnTxzIHWeNYWd1A6c8+D51jSEquhXxzY5qmkLqxj+wTxm3nzWGR+Z9w+xl2zzvg4sOG8SpY/tzwZ8+AuDpyw9lzICukWutrl9lfRP5fl+0dFnfFKIhGHYtYWWaW/+1hOc/2cCSW6fz78Vb+PHzC5k2og+3njGKpmCY1TurOXpYL57/dAN7ahp59N1vOGtCBYN7FFOU7+e9FTuYvWw73Uvy2VGl7rHifD+njOnHPyLP+5T9enDZkUMZV9EVCfQuK4g+V81BCPGZlHKi628ZEPTHgHlSyuci378GpiazXNqjoC/euI8f/P0zThnbj8feVeLZs7SAX502ktPH9efrrVVMv/89AJ694jBun7WMrzZVctyI3tx9zlh6lhZQVd/Ewb/+D8FI9PLxL6bRp0shh98xh82RiOWQwd34bN0ebjtzNBcdNhhQRb3Rt7zFeRMH2qJgTa+yAg7sU8bO6gaq6oNs2lvHWQcP4L7zxwPwxuIt/ODvnwMwY1Rf3lyyFYAuhQH+/L1JnPfYhwC8/IMpDOlRwjMfrefKY/aLPkSNwTDzvt7Otsp6Fq7fyysLN3Hq2H789lujKSkIcMzdcxnQrYgXZk5h4546/jhvFbOXbeOsCRVU1Tfx3CexQtpfvjeRaQf1iR6Xzyd46r9rufn1JQDMu34qQ3qWAHD/7BXRKPCSw4dw9bEH0KtMWSrH3jMvGqmePaGC288aTUHA21LS/OSFL/h07W7OPHgAD76zCoADepdy8ui+XDttWEJbCVRpZOjPZ9mmnTVhAIV5fory/PzkhOHRkolzuec+2cAf5qzg9jPHsHFPHTe/voSCgI+GYJhPfjHNZiEB3D5rGY+/t5rzJw7khQUbuPLo/fj5yQfFrTsUllQ3BFm/q5YxFUoQF2/cx2kPvc+g7sW8e8NU3lqylaueUffAN7efjN8XLxq/fHUxf/84FoFWdCti9k+Pid4HO6oa6FmaHxWcfbVNFOX7yQ/42LC7ll01jfiFYHDPYroU5lHXGOIv76/mvRU78fsEvzzlIF74dAOnj+/PruoGjh3Rm4KAn7+8v4blWyq5+5yxLRKzTPPcJ+v5+SuLufX0Udz8+hImDCrnme8fRnG+u3kRCkvX86pZv6uWvl0LyQ/4mL10G4s37eMnJwzP6D63tqCfAlwDnAwcBjwgpTw02Trbk6AHQ2ECfh/nP/YhH6/ZTX7AZ/NnAS48bBCvfr6JuqYQ4waW89oPD+etJdu46pnPovP85Pjh/H72CttyBw8qZ+H6vQAcN6I370SKwqeM7cfDF9oTgr718AfsqGpg0946xg0s58sNe22/P3rxBF7+fBP/Waoiot9+azQXTx4c/X3+yh089d910YjpFyeP4PZZy5k2ojdzlm/n3z86ktGR6CgR4bDk+pe+5JXPNzGyXxeOOKAHf5q/hr9eMpHjRvSJm//FBRu48aVFnDKmH/3LC7lh+gjyA3bR3LinliPvmsukId34x1WHR6fryB9gya3TKbEI5Zl//ICF61WE/9zMyUn3W3PHrGU88cFazptUwTMfreeUMf14+KL0kq/+PH81O6oa2K9XCQf0LuOQwd3SWh7UfXWpxWpZc8fJcWIWDksagmEK83ws31rFsN6lSV84VvbWNtIYCtO7rJBlWyo56Q/zgVjJ0MmyLZXc+cZyThrdl/9+s4vzJg7kyGE90z62XOGzdbs5+xEV7PQqK2D+jccmrIdqDyQS9KQeuhDiOWAq0FMIsRG4GcgDkFI+CsxCifkqoBa4NDO7nXnqGkP89YM15Pt9nH/oQH70rLJV7v3PCuZdP5VlWyoB4sQclPAAvDBzMqMGdEUIwfRRffjdOWO54aVFADYxX3LrdEbf8lZUzAFOG9cvKuiH798jbhsH9Svji4iI33HmGP48fzXdSvL5y/trGNa7lBNH9o1GV4O6F/OtgwfYlj9qWC8mDu7OUXfP5ehhPTnnkIHcPms5c5ZvZ/SALimJOYDPJ7j77LG88vkmlm6pZOmWSg7oXcrU4b1d5z9jfH+27avnkiOGUOZSnwBQ0a2Yf159RJw337ssVl9Q4oh6D+xTxsL1ezmgd+IKWCe9uxTSGArzzEfrGdW/Cw9deHBaywN8/6j90l7GScDv4+5zxjLljncAXCNTn09EKxQP6tcl7W1YbachPVSpJ9HL56B+XXjqMhVvffvQjluPlSmG9ozdW6eM6dfuxTwZqWS5XJDkdwlcnbE9akVmPr0gGi3pSkFdQffKwk3RiiWAUf278OKVU/jjvFU8PPcb7j13HIN6FDMpUhsO6gE9d+JAVu+s4ZF53wBw0ui+fP+o/SgpCDCgvIiNe+qi82sbAuCwobH1aI44oGfUuhjRt4z7zh9PfVOIBWt3c+20Yfh8gqOG9WT+yp08e8VhrsX+onw/8288ljy/IOD3MaJvGcu3VjFxcPz2EuGMEr81vj8+j6JmQcDPj6YNS7pOt0qgXhZBd6LFqltxel6qdZ0NwXBWi/j9uhbRu6ygTaLgonw/L101hWG9y5LPbADs99bwPh3/vGWt+9y2Zld1A++v2smA8iI27a2L+/2BOcrHPXlMX2Yt3kr3knxKCgJcO20YJ47sm7BG+mczRtC/vIiF6/Zwz7njosJ36+mjWLq5ki5FeRw8qNyWDXOAy0N39HDVxfFB/bpE11GY5+efkRp4gO8fuR9nHlyRUAh1xKf37dInP2XG6L6e86fCjNH9WrS8F727eB/HwYPUOU+1ZKGxPqSHurw425qPfzGtzV4qE4dk/3g7EtbrMqRncYI5OwadRtDnr9yJlHDjjAP58fNfAKqibP3u2qjFcvKYvhy+f09mLd5KUyTNqCDgTym96DuTB/Mdi58NKiK3RuUAP5y6f5ztoOlSmMfLPzicwT28byyfTyQUcyfHjujNV7dOd43mk/HyD6bwxYZ9nD9pYLOWTwVriqaT6aP6Mvunx6RtuRx5QE+euGQS+/UqieZ2Z5P2VAlo8EZbVh2ZTiPoX2zYG00nuvON5Vxx1H5cduRQW0bDfeeN57N1ewBs+d2Z5MYZIxL+3pzKt2Q0V4wPGdw9mkffWuT5fVw7bRhHHuBuSaQr5qAE9NgR7n6/weBE25h928HLv6V0GkFfurmSg/p1IeD38eHPp0WnCyH4zbdGU1XfRGGenwHlRYDKJTW0DT/NcFqXwZAOj39nIrtqGjzriDoSnULQK+ubWLqlkjMdWSEaq1UyuEcx/+/UkS32nA0GQxZoqIJAEfgd0lZfCYFCCOTHLVKU76civ+P755DD3edu3VfPul01SCm57d/LqG8KcdKY5CIthODyI4dGI3WDwdABCAXV3x0V8H8/jf/9iZPh7qFK8HOYnI3QJ98xB4A+XQrYVtnACSP7cPj+nbcBhcGQs3z+N3j9R3Dxy5HvT0Gf0TDmHCjurjps2aYar7H6XTjoVPvyUrZNxzFtQM4J+sNzV0X74QCifXiM6p9+ow2DwdDOCDbCkldh9Fngz4OdK5WYA8y9IzbfGzfAmnehqBvsXh2bvvsbeOZsED445V74+3kw5Aj1fw6Qc4JuFXMr+yXp7tXQgajbC0+dCif+Fvabmu29MbQ2wQZY8hr0HQPblsCrM2HrIph+G7z589h8mxxdiSz/d/y6/vOr2P/3j1GfdbtzRtBz1kO3ctFhgzh1TOs0jEmL7ctVhNGe2LNWCWRHYsuXsHUx/O2M5q+jZhcseAKe/bbyXg1tT/V22Lcx9j0cgp2rYt/n3wtv3ASfPK5E/PkLYc8a9dvCp+Gf18Cq/8DEy2DCd+3r9hdAcQ/ocUD8dkc4LJeeCbKs9q6HD/8Is25M79iyRM5F6MX5fmodHeNfesSQ7Kckbf0KHj0Cjv0lHNOObo4/jIO8EvjJV8pv7AjohxqgdjcE66G0jxKIsr7J/dBwSEX425eq79uXQL9xqW9/7wbIL4FZN6hSggxB14rUlq3bC9+8A5/+BY65oW1KGDtXqgyP8oGtvy036vaCLwAFllLy7Fvh/fvU/9+fA3lF8OHD8MXfocsAmHEnzPm1fT171sCKt9T/9fuUqAOMPlut//O/wUm/g6rNMOUadY0ChXBrpGFgv3EqGDjzMbgjkvHWa4R7x/ag7hMdxQOc8GvIa2GuekMVhIPKCmoFOoWg9+vaDjJWvlEdNFG11f33pnp1UzrTrdqCphp4aCLcuDr5vM2hsRb8+fZjkxL2roOy/q6pZDTVqYfRTZytnuiHD8H8+yCvWB3HxMvUS7PEowJ862JVTNdiDvCn4+BHn0FBF/VSa6yFQAH4XNoiVG6B+y2djn71kvr80efQY//4+Z3cZWlNvHxUckGXEubeDiNOhv7pdzLGtiXwSKR3y28/CzU74JBL0l9PS7hrMJT2hesjdmjd3piYA/x5mn3+yk3w4nfs0w77AXz8iLJV+o5R17HbULjsTfUSB7ju69j/Vg46DZb9C777T0CoF8tFL6t1rX1fCbeT+krY8Il92o5lzbsGVh47Wt2/t+xr2Xo8yDnLxdlXsRDtpJHQxk/VZ68D438LBeG2PvDCRW27T02WPm1qd7Xedh4YD385wT5t4dOqdPDqzPj5a3bCbX3hvw+4r2/XN+oFAapYjlRiDrDgryqq8kpPe/osWKu6mOW6iMCEg2pffj9aCeDt/ezerJVFz7tP19c3Ec5IsD6Fh3rJq/De3fYKPyd7N8BHj8av/6NHY2IOyrL414+hbk/y7Waaaksgs/Z9+2+n3AdHXQ/jL1Ivxh9/Cb1Hqd9KIi1+j7kRDox0CXzoTDXP1R/bBdxNzAHO/qtab1E3KIpE68OOh6k3RWZwnLdNn8GdA+HvZ9unb12c0qEmRAcjlZtbvi4XckbQl2zex3H3zGNbZQMBn4g2oS8I+NpHXxr7Nnj/tux19bnizbbZF1AP/4cPxb77U+8fJi3CIajeBps/hx2WvuI/e1J9bvo8fpkdEaFdPiv+t32bYNUcGH1ObNollvkmXw1NtbF1OBGWW760j3rQNU018PSZ6v9PHo9ftqFK2QJlLvUxqQh67W7796/fgJWz4+d7/iK4rb/6f+lr6jORXfLy5fDmz1SJRyOlmubG12/ET1v0onpRWtmxAr54znu7qeB8aVVujgUuvQ6C61fBpMth2v+Db/1RlXK6DYGZc+HSN5RoXzlflZzOegwun6388m5DVCkqFQL53qUn4Yt/EVrvnYIuMOAQ9f+edfb53r0bbukK4fjutl1ptIwUtWpOasukSc4I+kerd7M6MrTWj44bxhGRvkHy0xgsIGW+eA5u7RaJDlNEF+vcine6aDfo8PjfWouNC+Cd36r/+46BUIM9Ys8UNTti/1dGKsAaqlQU5AuoSifndvUybrbJyrcgWAdH/RS+92/4yRKVdjbkKDjuf5XlAt6CXtor9r8Q6kG/diFc+qbySKsjw6lZo719m+C+kfDePWrfTnsAhp0IB50OvUeqedbMV5FnZWSgrk2fq4fdmTJnpWGfigK/masicS0sy/8dK3Fsi1hDwQb34wFlEUFs2xD/8rBS6RhDdO378MoV8OL3YtPWfwwPT4LXrlL2wy3l8OUL3uv0Yq8jkNEe+PQ74OqP7NfDSqAABh+uhLzfWDWtoAwGTkp/HxIhBEiHIFdZzmOX/nDFO1DYFRqr7fN98Af1uS/FMUh3RgKafuNgYNIxgJpFzgj6FkuXuNUNTeT7VVSeaLioZrP5c3UTfPxY6hkS+mF13jxgKcolHz2KzV/E7IQtX8LmhbB7TeJl3LDehN0iY6JmoiheuxseOjR2TFbxaKhS50FHfQeeDEhVaWdFC3qpSwdb+zaqF0H3/WDoUbHKyEv+DUffoCI3fz7s9BD0YpeXRPf9YPAUOOwqJdRgv07v/U4dx5eR/S7qBhf9A85/Gn74IZx4m9rek6fE0uIW/EV9rn43tp5dlgwOK09/C/5xibqvrDTVx14Czpfe4peUffTu72KNZt78Gbz2Q/W/fpEcdT182xFlO7OaFv9DfW5bHLsH5t4W+/3OgYCEd+9y3/9E7HWI3TfvQNeBMPkH6a+rVRDEPXfWeq7iyEA0+WXQEBH0UBDWfagqb8Fe8tS8djXM+Y192pu/UPfu+X93t14zQO4I+r56BnYv4ifHD+fKY/YnLxKZ+1rDbtEPRPU2lSGRClogpCNClzImfuEkL4eGavjz8fDZUyqj47Gj4fGpyqPWUVqqWEW0e4YE/aXL4dnzlLjNv1dFydaosb4SVr6tGn0ADJ+uPrc5zmE0QncIen2lihzL+rlXWIKqeC0frNIx3dDn2Jm6BioqvOgfMPUX6to2RUat10Jcr0a0itv2kFh/9XwzRxXB9Uu30NKgbe0H7vukqdpmj+i3Lo7dN05Bf/lyta25v41N2/KlyhKB2Itg7Plw4En2Zesdgl6zM/b/9uXq02m/QPMyMzYvVJ95ka5pq7erF2h7sEEhEqE7BL1ys8p+mXGnyogBVZHaWAVfvwm/6QFPzIj54DuWx6/3i2dg/j2x73V7YP1/VdDRitlGOSPom/fVMah7MT8+fhg9Swuigh7nnwcbUquMchJsjBVjrQ+EfuiToYXcGaHX71VFb0gu6HvWQrhJ7b+OqjTp+O+1u+0VPDpC3706fdslHIbqHWqfvnop5iUveRUePtTu1zZU2cXjgBOUR7nRkU2gBd3aYVJDlWrht+595X0nIlAIoSb33xqrYejRcN7fvJfvNkR96peCvl+CkXPjc2QiFVj6t6/dBVsWWsQ/Mq+UsGp2bN3C5dH74H545IjYd+2fF3ZV9QIap43hxu7VahvdBivROv5WVelYPig+Qq/bo7KN9HJNdcoe0/uqCRTAqz9Q0ek/r1Ylw5pd3m0rpIQvn48tC8ra87tkNWUL4cMWoW/4VFleeUWqFKHFN79U3YPPnR+btzHy0t6TQgl561fqs8J1KNCMkROCLqVk8946+lvSE/UgxXGBwBMnwZ3NGEvxlStU5z7hsHogRCRKC6XYUEgLudNDt0awyewbLTDB+vgad2fU5UU4pI7D2opOR+gvXAyPHqVKAKny1s/hngO8Peuti2Li1VCpWuVpSnurG3z9x7FpNTtVpgrYI6c7KmLC75X6qfEHvAW9oVoVo70ifIA+kQyLbV/F9tuKU9D9jiHyVs2JRehN9er/WderTI8J34WfLoNRZ8Vvd9tSu3DrSus+o+0v2i1fuu93QVf1B+qlWNQtJqRH/o+qdOwyID6gqd0F/cere3r36th9pjNNNOs+gC+fVdHpwmdUyfB3+8HLl7nvT/U2Ze3589U9C+q6pFqZ2SY4PHT9EtV1I5qCUnXv5Ln0yqhLxwufgdXz3Os79PPad2yL9zgROSHoz3y8nm2VDbaRhfKjlotj5k2fNW8jOtLcuUKJp44SQwkqq6xoIbeK1Iq3YPn/qf+Le6YWoYO6YayRLqRuuWxfFj+t3JIbvWsl/Ota+OgR7wYXGinh40fV/695eKKN1dClQhW5G6piYjz5avW27Xmg3Wdd855l/R7ZA70PSrxfvoD3uWysVtFWInoOVyK0VQ3+HY22reu34ow4V82OCXqwTlU+f/pn9T2vRFW0ud03jR6plgVd7ELvlj7XdwxM+I4qwYG6H9yOs7A8PkKv3Q0lvVT0vnt1zALr4xD0Lh6Np5b9C1b+J366to/0C0lKde+2qwjdYbnoa3vib+3z5Zeqe8etAZkuuf3zatV62a1CevdqVdJyqxfKIDkh6C99tpGxFV256LBY5J0XUEouyJBXN2CC+px1vSqi6tp5r0jQiZuH/ux5MQ+0fKC7CD1zNvxhPPx+DLz9SzUtWB+fN/72L1XLxWRssETDE74HV8xVUdvAw+zzvXmTe65s7W6VvbH4JXjHUumjfebv/Qu6W1LE9m2CLv2Ul1y/T62z+34w43b1e6DALm7WrBi3SuLSPnD2nxIfoy/PW9Abqu0WiRuBfOWhrv1APewNlXYRd0b3VoEq6KrOsa6UbapTWSyavEgpsmuKPuq0X6llrBH61sXxohhqUiUFfT82VquWkk6Kyu2lOSlVqam4u3rRVG9TdnymZfsAACAASURBVF5Zv/h7wprb32eM/be/n6NKI589BZ/8Sd0jthdDRMxDje1M0B2WS6hRVYA6W00XRCpF3ey+pnp7VF5rCbZqdyvbqXqralzVynR4Qd9d08iijXuZNqKPzS/P84rQm0t55GWxdr4SHX1hE6WTWfHy0DVdK9xFaNVs5dFZs1KCDfabRuOWO+1kp6VGvucw9aIK5MPlb8OgKfZ53fZHvxAWPm2PpjWDDrenZIUalFAUlMUidO3XQkTQG1WWxy1d4Q1LtwgyrPxiq8Ww/3HJK+e8LBcpU4vQQVkjmxaoUlQ4CEWWB9wZoVu/Dzve/ltTrb2iUxfZp90M5z2dfD+Oui7SCtYh6PtNtc8XbIi8yJrUcTbVugu6M0JvqFTHV9wj9kJY/5GqsHYu32Cxag69ImbvaObfq0p3s65X31f+R50b3VdKsE5da7eWwVkjYrn8YRzMu8t7//IjlaLBBvUSGGyp6wjW24OfLYti/796pfpb/n+tHp1DDgj68q2VSAkTh9gfcs9K0ebiFAidgZFqhK79cbc89MKuKipw+811XQ2J84wTYS26O7NI3KI+JzoS776fu7D6A/HRZ1l/ZRvsWqXE2drIQ29zyavx65JSNbN/7OjYtFTE2Gq5VG9X9QI7V0UadsjkETrAyG+pT/0C0+lrev1WrOdt8OFw+kPw40WAUNGb1TPWEXpeIYw8Pfl+6GX0davdrV7ugw+370dh15iXHw6pY/WK0BsjDaT+cUnsPirqHnshhJrUebb2W9LLYnNNv0O98K54R1UuT4ukajpbgH7zTuTaR66ZjmTbVYQuVIC+Zy3Mu917/wpKVcl810oYflKssRFEBN2SnmstBWtxl+HklfkZoMML+sY9KnIZ2M1eWaErRX3NPcK5d9gbUoQd4ha1XFKI0Cu3xCrW3CpHS/uoYnwyD11Tvy++kUOqWCM9ZyQScHQ85HZsuqGLM2oEmDlPfe53jH16l35KRLd9pRrMTLnGss0EFWSupZkUcvW1MIHqBGvrIjXoge5KoCCFl0JxdxWJ6fS/hIJuqRT15ysvu9vgmBBbBSKvCFcKy+On6fNktVx0RW3fsbF98gVUTry2gsJBJeh5LoKut//WL9RLVKeqFnWLROjBiC2Sp4Zy01iv0/gLI/UfB8DIM2Le+vr/2rcVblLnWpdKmmoj1lA7qxS1WS5N8ZXcEHs51u1R/+scdFDXZp9F0K0Nk6ypwEbQk7NpTx1CQN+udjHSlaKeHnpjbbwg1e6G169VlXTv3mnvZ8SZgaKL4Klkudw3IibA2nqxCnJxj8QVeU72bUo+jxfWY+7uaA7tFHi3Y9N9cjTWxNtN+oXg9F4Ly+1Rcfmg+GXccKuU9bKsrGhhglgaZZ/RMYtov2OTr8PnV9dlV8QuKU5kuVg8dZ9FDLQQ2yJ0j7ErdaaR5ugb4YTfxJYJ1qkMK13H0GVATNCPul6dU73tcJN3hO5ziJVeX0GZOq5Qo1rel2d/+SQ6hq7uY/WqeYti1zhYH0lbdBHMbOGsFA01uL9wrNlo+cX2+yFYb++rxlp6tgZFZUbQE7JqezV/mLOSrkV50YhcE7NcPBa+vR/cM1yd/Dm/UQKw8GkVyd0/Jn5+Z4SuBSpVy0WjBakhBUH38uetEUC6NNXCgInwP4tjTao1+sHTkZnbselsmsYaJTJWH1U/9P481Zudxp9nFwRnROuKS5NsSM2WspZ2tP/u86tzfuDJ8eLpRUmvmMVkE/QEKY/WYwsUqYfdKhheEXr/CY5t94wVL/UywfpYzncgPybo+ne97ZAWdJeXh1NMX7lCfRaUqt90eqHfQ9B9gfgXfxdLnYgzgAoUxdbTpD30dhShO5v+h5rc78nDroz9n1+qLC5NsN4eKNV52KEmQk/MK5+rvkH21sYLT16k6X/ClqINlaqp9Px7YMNHiU94qDGWew4xQfcS3S9fsFeGaXRHPtYIPa8oIugOsXK23Bx7Puw/LT4v2kqyVMOmOvWgW6NkjY5MEh2b7mNER+jWlpDWyMb6kPvzYg+J8NkF0e3hPvsvkU6TXAT9yP+Jn+bEarnoymMZVt5xKh68pqRnLCXN+gCnKujacrG+qJ3Rbd9I8NB/vH26teQStSzqYqUmf37sJaN/1yWHcDBSKepyrM7Shc5Jzy9T500Lky9g3wd9bd1KGNa6FGeqozVC1/dte/LQ4ywXj0rRXgfCkZHBp/OKVOvgQVNUcNRUH3sRgneLa1MpmhoPXhDfR7FnwyInuv8Mr8jplq6qE55Q0P6ARCN0F1tCSmXXPHiIy286QrekgPnz3T10540xaHJii8K5Xjeaar2L/fpGTnRs+oFvrFY3coFF0L2icF9eTEicRX7nwz3kKDW4r46crC/R77yqKmOTYbVcNFJGUhbTEXRLx1FWP9opilbiLJd6e6qq8z777uvw/XfiK5Kt10gv88UzdlH0jNAbIx56ggjd2VJVR+j6+vrz3SN0t3Va7wFnG4G8otgy+uXRngTd2dtiokpbfe+EGpWdddmbUDEpUnKyBD91e+LvczARejL21DbRszSf08b1j/st5b5cdO96wUb7W9bKO79VEZ+1CKv9yUSi5xZh6ofbJuh57paLU9Dzih0Rrcux3b1ffLaBc9+8Xl76ZZHITrJZLvX2yNW6b9Yo1p8fe0icD4vXC0rnB1tLAKlG1/rlaC3xyEj/KmlF6FZBt+xnIkF3VoA21dq7V3UKYnF3qDgkNnBCxaT47enz+p9fwdv/G9uOU9C1iDRUAdLDQ4/suzNDKV8LeqQE5s9z2Eda0F3uHeu17jHM/pv1ntUNtDqi5QL2klJ0WqH6Hqy33xduPYUaQU/M3tpGuhW7n3zh+FQLJOjmMtTo3S+L8EdSuSwPSKBQXfhEgg7xrfKki+Xi8xB0ZwvFQKGjGOwSBYSbYh0iudFU5x2h+1OJ0K2WS7235WKNUPwBi6A7xNArJ1lbLtboz02g3NCWi/XchxrUXyopi27bs54zkchysRyfrhS1WS4eL9OicjWKzWFXqe/WDBM3gbEJemTf9P0QtVESCLqz4i+/RJ03fX/GZfIkiNCt9B2juhc+IJKPn1cU2y+detmeKkXjLJcEEbo+dmur7EBhpBK61h7cFHWzl4KE396WoZXo0IK+u8Zb0MORa2QL0N0qOzUhS4TuLI76XARdR53WKHbLInjlSntk7WzRqaNGa6Xo/seqB0iGYsW/3avtOeMQ8SMTZBv8OJLzmqiitqk2eYSebylaxi2vLReXCN1ms1gEwTr8nPNh8Uph04Je2AxB1w1krOdel4jSEXSvdMNEubA2y6U40mWwpaSQzDLrdSAg7JkjSQVdR+iRc6xfZG7nS1+jYL099U4IR2W1Q3T1fedW0WqloBQO+V6sw7e84th+RQW9nUXo1pJcopasurX4UEu7CH096/fZg4+8YrtNV9q7BTnUqdOhxxTdW9vE4B7uN1hpoTq00f0jglO9w3W+KFZBzyu2R9DCr97CTnvBn2/3zubdAV/Pslc4Om0cZ4R+9afQa3gsvzscgg8fhNm3qLEQrTgj9DMeVp0B7VwBa96NbTdRj4l6rE439EMc7RnPIeg6RxlUq8FQo/0mtr49nR66fkic3qJn8TuSTmZ9uabafauuYLZmG2hBT8dy8Tmi7VSwikHFJHU/2NaZ5KHuO0aN7WrNqokrxQgVZOjeEHVR3hmhu0XT+vwHG1TrZGuDGFv3BpbrZB0dKNl50C8RLfx5RTFLRke27cpy8TkEvcm71Nh3DNy4xn5t9Pmo3xsp5URK2vnF6k/3z9MGFaLQwQV9T20j4we6NMgABpQX8dJVUxg9ICLCzi5anQQblPj68+OL1D6fi+VSEG+56Bv1K0vKntPG0dGaFno9Mk60UUhTrLfDqm32ZZ0eevkgOOUeJdJ1e5Sg6pxlN3STcK9isxZPLUpOQdd2iy8QE41CR/NvjZeH7hQ0r4dbV1aFQ6pl3vTbvLcVt+2AOo/WfGBtX6VTKWoV50Cqgm55pA65BObcmvr2NM5+ROLqHQrUtR54qH1w6qiHHjlWN/GNRuh1sfE1nb9Z/79+pVrPu3dH1pkkQs8vs++LPz/2f3u1XKyWWLKWrM5ro4Ojur1KwP0Fan15JbEXZElvONgx6HUr0WEtFykle2ubKC/xvjkmDulOYV5EWLwGPNCEmiLNtAvj6xpFpJLNZrkUqDe5VfT0mIPW7l2d4qotFX0TRbM/Ip+39Y395mypmeeI0PUyeUWxNMFAoXeEHi2BJBEnHaE4+7nWEZa1csdqiVixWS4B74rEZJZLOJh4TEjXdUYsF6v1ZU3PS3k9KbTwdGKNbJPZKynvh+McWffLel70OdZjV7q9LKP9s4cTZxzp+Up7K5tK/5Ys0tTPSLS0JuP3q71ZLlZLLFif3v5FLZe9kRK0tqZKYi+wY3+u+r5pAzqsoO+qaaQxFKZ3WYoPjdOPdhKKROiBQuIU3eePpCpZoju3CF3nnetIFuIHonCOLaojWavgaQ/cKcwBh4fuJpJuTfI1erpnlBV52XhG6JFzaO3T2cuTtlWK5ntHPZ6VopHsg1BT4qwS121H6iOsL8SG5kToLbRcrPt9yKUw8934+VPBeY68Ily9v9rOc3uheNVzOL87r5ce5LyfI1/eiT6/urQnw7H1fv5U/D5kG6flUl+Z3v7lWTz0QIG9rkEHQNZsqVYmJUEXQswQQnwthFglhLjJ5fdBQoi5QoiFQohFQoiTM7+rdlZsU97U8D4pPqDJRhbSlkteYXylqM5ysaaS+fPVm1x76I217oNM6NHtNdFudMOxdYP9JtJC6txnZ6WoM2MEYmlUoSY1sPH8e2NdBWhBTiZOyQTd2pui18vB6cd6CbqOhvTnpO+rTy3o4aB7Tm8i9PzWymEt6Ol46DbLJcXAwXpNrOegfFB846Hm7Ad4R5BRy0ULuluEbhV0v+r+4YATIutNUCmqo+sBjhatGi1a0fMbCYqkjG+I1Z48dKfl0lSTXp68rvhsqlUBl142ryQWULShoCcNfYQQfuBh4ARgI/CpEOJ1KeVSy2z/C7wopXxECDESmAUMaYX9jbJiqxb0FIvQyYZWCzXFInTnYBE6r9lZnLb2P+2Vw+5EekXolpte76vTrnEKumuEHkmVq9mpKrzm/Fr93bLPEqGnKuiObBl9XvqMjk3zejhtHnogJnTOhqxaKHsOgx9YxtzUeejhYPoRut6W9ZpoQUqWpWFbj+XBTjVqswmmJTBI1Lo06X44LRevCD0yXVfEuUbojn7dr7UMTO1LEL2f/DvVZa9XhH75f1S3u/o4rRG6c3/bm+XibKGdTve+zkQJt2yg9iTowKHAKinlagAhxPPAGYBV0CWgzdSugMvICJll1Y5quhQG6F2W4s3hVVGoCTXEPHTnG1r4Yj3QafyBWF/e0Iyh6IJqvdprtD5Ael+dL6G8Yu8ivXWeptr4wait+5gsQhK+SEdNDg9fW0kFkb4s6vd5VxbaMl5SsFycvQ1aPXS3kkgi9HmxZiBFMyxStE6s63H+nwiv40z3pWRbZ5LWtc5tpBqhOyv/refZuc0u/RP7wN2H2vvIiQq7cMlpb0+Wi4h/VtKJ0K0Vy4HCWB2ZtSTYziyXAYB1VNqNkWlWbgEuFkJsREXnP3JbkRBiphBigRBiwY4dSdIIk7C7ppHeXQpT7+88meVijdAvftn+m85Dd3uwtEimGqFHh6IL2R8otwc+Lg+90LvxjiZQqPbFredGPS1RwxiNW6OpaOpfiWqiD6l145uK5eLMYNGC3iwP3ZKap9Evo1S9cEj+8nRdxkOsUjnnXjiF2fNc6gg9gYee6CVli9BbKLqHzoTxF6sugJ3bydQYBRlBxD8r6ZQgrIFIoCBWEa+z1yC9tg8tJFOVohcAT0opK4CTgaeFiB/WXEr5uJRyopRyYq9eLXtrVdUHKS1I40FPVim6fRmsnqtEs89IOOZnsd+ETwlwXFZAnkXQG2PzJsLaH3qyCNCt6wC/wwN1oiN0t8ZFzswaJ7oxSI8D7HaSRmfxlA+Ck+6GYdNT64pWd23g9RvEp9Dp3hbDLuc96fbcLJcU6w9s68mgoLfIcnGmLXpF6E4PPVmlaIKh9NItFTkp7ALfelhd12RjsGYTN8slnRKEM0LXbR/K+sL5f4dJV7TpCyyVq7YJsPYcVBGZZuVyYAaAlPJDIUQh0BPYnomddKOmIU1BTxZBL3lFfWqv1SoiWlidN7m/AII77esvKIsfVd2KTdCtEXqKD3wyX1d76G49JYY9mnVrRp2pbsRBU5Tv7ozQd69WzZeLuqm/i15McZ+tEbrDRBdCNU6yDiABljz0pvTFUB+fdf+bagGRnpgksiA8t90Ggp5yhJ4gbdH5v3V5aHmEbsUqaGPOSz7Id5viYrmkU2nrz1MVoE01ajn9fJf1U8d50KmZ29UUSCVC/xQYJoQYKoTIB74NvO6YZz0wDUAIcRBQCLTMU0lCdbqCnihCtxaxdkb6v/a7CbrjQbKOJKPFo8AjL9u5rlQsFyu63/GkHnqkhz+30YaiEbqHuAihhjYTEeFz5qHvXu3e22HFoTDuAu99T+ShA1z4gn0UI7AIejMqRV0tl0iDqnSipfZiuaQq6FEPPWKNuVkH1v2L6+IiQdpiphhyRPJ52hK3EnW6x67tQmuJqKxf8/epBSS9S6WUQSHENcBbgB/4q5RyiRDi18ACKeXrwHXAn4QQP0GFYJdImaxj7pZR0xCKNu9PiUQeekEZ1EYefj0QrpugO6OW/JJYRK/FQ/tlXh13hYOw7sNIhG7NgvA4lqJuypc77pfqeyAVQa+NF2O97UTbsmK1kzS7V8cPJA3w/f8kXpcvQMIi/ODD46fZKkXTtVxcBB3saacpracZgu71smxRhJ5mpWhjjfc5T5TJkihtMVO0J7sF3F/w5YPTW4fOaLFG9qm2as4wKd2lUspZqMpO67RfWf5fCrTpq7eqvilNyyVBlov1Quj+U6w3nn43OW9ym6BbLBdQF7TGpZCy/iN4YoYaZDaVLIrCcvjZ2tj3ZCKjK0UTRugpnDdrBg+oF+K+jan1R+5EpGl1gEpjDgftDVNSRYun02ZLJ8MFEotfurRkeafopGK5JOuvB+JfMpk8Xi8yaeVkBMu5Pf0hZTum0/gMYhZroEB13LXmvaxV/HbIlqJSSmoaQ6kJen2lEqNEeejWB+TcSGs26w0dzRl3bC8/4p1JabFctKC79zET9TdrdjgsF48ILlFx2+2m0ZWibiUSr+Nw3a4jQt+7DpDpNcG3rS+y36kW3IQvNupQcy0XZwkjnQpRSC9i3W9q4t9bYrk48ax4tVQGewm69Vymk7aYKVpa2ZpphKOUnK6YAwyNDIp+wAnwndfgf1ut6jAp7ezspkZ9U5hQWKZmudw5UGVteFku/oKY2PgLYsJqFU7rsF9W8opVFGntqdEaoTsRfssg0bXJGwmBS7PvJJGuthXcRi6KRugpvMcDRfaXoO7WoDkROqQvysIXs43Sblhk6SLWSmtaLhe+aO8S2Ukmu05NFqFDihF6guyT1oqk27PlkixDzYvT7oeT7ooNatESe62FdEhBr2pQkVtJqpbLrlXxWRSakl4x0bReUOuNbx049/pVMU9dNx6o3Q3v3aP+14LuzD2d+nNVFFsXaQ3pHMTXK3JNtUJMEx2/0SXTJh3LxWonQcsFPW3LxWd5kabb9N/SsMg6Nmm6lksi8XNibSVoIzKAQiYtDM/WuVZBT5LaCPEvGeegJK1Be7ZcmivoBWVtmmueiA5pudQ0qCi3LB0PvXaXvUN/TUnPWDaAV3/e1oFzS3tBWaS3Qd2z3Du/hW1fRaZFLqyzj5M+o+03TLDOXuR1awgELoKe5IFwDvdlRaZhuTgFvXq72pdU+yR34pW26ImICXpzOucCJejOMT7TwZYR0kJPtC0sF+v03Wvc5/ElyKyydQvQWSwX4f5/B6VDCnp1vRK/lCN0zbgLYNRZ9mm9R8bExhahWytFI0LojIx0hL3h49g0/aZ29hni87uPhKTxFPQUMxw01hFUnKQboVt7jQw1qRdfc2/6dB9k4Ys1bEq3CBsdLLnBfv7SFvQM2AP6mmcyQvfMcvGrkiDg+eK0NsWP6/ff0UNma9DeInSbh549qyRTdEhBr2mMCHp+mhcgrwhGnx37PvUXqtOhaPHUIlZuN54z6taWy66VsWla0J3iIVwE3fpAeQ0b58wlTtboIWq5uETo6VSK6gj9yVNh0YuqgrIl0VVzPHSdqdPc3ha3LrY/pOn2T54J8Yn21ZNBsUj0Yjr82uTL6+MyaYtkxHJpR3TII2gIKk+0IC/dyC3f/mAdNlPVamthtUXoLgLkHKPRrevYqKA75vX5XNLErNtI1UNPZrnoCN1N0JM0LLKiBX3tfHjlisRjLaZEmpG91UNP92XQz9Jfu/WlmWy0HSeZFLVMioXz3rKSSm+S0VKD4z6wZma1lv3Qri2XDimHNjrkETQ0qUizMC/N3Rc+RxErLzYd7BfXOnyZJi5Cd3mw9LRUInRrpdTwk2DCd2Pfu1Soz+ZaLq4RejqWS6m9dW2oGf2SW0lXIISIlVrSFda8Iph4ufrfanW1JMulubSG5ZJMtL/1CJz3dIJ98ig1dOnX/ErvVGl3losR9KxTryP0QJoRepygB2LTwX5xDzgeRp4BB1rG6nA+SG6CrgXV1UN37K/1eyAfTv2D/Tu49LSXzHJJUCmaTm+LzpdXSy2Xsv5w8MVwwXOpzS+slaLNsCus11Zf33Qtl4xE6BmyXH62LvaST1bSGH8hjDw9wS7p+91ln374MfxkSfP2MRXaU9e5gN1y6fgeejsr/6SGjtALAi2N0PVDL2K/a4rK4by/wf9dF5vmLOq6CXp0xBLHQ+caobsMRm2dH+IfgGTCkLBSNE0P3UpzLJfrVlgya3xwxsOpL2urFG2GCNgq/popqpnwvaP3VgvXVVRuH6+yRbj0wa8J5EPXihauPwHtzUPPsQi9Ywp61ENPcAG2L4/vkCtO0J3euYstYL3pnVF3cc/4+QMegu7zu+T9upz+/gfDmHPh80iROW6wjSTWhX7odyyL/805SlIirB30+yJd6aYrrGV9ks/jhfDF+mJpjl1hHQkqUUSaDld9ED/qe1ISiGe66BJLunUBTlqjojZVWqtLgWZjBD3rNKRiufzxsPhpQtgvmjMyd7ug1hvQ+SDlFcK0m+HTv0DlRjUtnQjdTWBmzlOfXzxrX1+qJLIV0k1b1PjzmzdyUIsQzW9YBO6WS0sf2L6jk8/juT8ZEAt9PtIZRs8NfU9lQ1zbm+XipgcdmA75SqpvSaVooqjE7YLqmz5Q6L7sUT+Fn3ylOuWBmMedXwylllFLhM8l7zfRvkSOLW1BT+CxpyXoFtHwBzKQ5ZImLclDh9gx+vwtj0itqa7pkqnSAcRKLImyXFJBVw5nIyJtz5WiOZCH3qEj9Hx/Cz1063TrpxUtDImKuULAdyNdxIeDcNT1qsOe65bDrZFUMJ/LthPdQG59yqRCxiJ0q+USaJ7l0hKEL9blQks8dL0u62c63Lw3/WWsuI0Z21z0C66lEbruAsFE6OSa5dIhj6AhGKIg4Et9PFGNW6YJpOahJ6uIEkL9+fNg2v9TQ3AJRw26U8ATRW16uy2J0Iscfm9aHrrleLWH3pYPox72D9S5TBd9jNY+cprzwOrr2lIyEf3phlb5zegR0Iq+R7IRkbY3QbdZLh1SDm10yCNoaAqnn+ECCSJ0lywXTdRySWNYKjeSNf2P26fIb16dLHlhjdCdHQZF0xZTOHc2Dz0vkrbYloJuEdFko0C5EY0+ZUzUs5KWlsEIXV+/llaK5mUxQm/PlosR9OzQEAxRmG4rUUjBcnGJxPzNjJTjtpEkD91Jsy0X64vH0fpUD+eWSsRpjQL9zcxyaQnW69Sc0V+0WNki9CxUeiUKFppLiy0X3RmdidBNHno7oKEpnDhl0Qvhc882SCTozbU+4tbjj19/cz30oUdD14Hx0yGxaMlQ6lGZNQrMluWiaWmErl9s2YjAWqUvlxZWikY99CwIWHvLJMmxCL1jCnownH4rUUgeobt56PqtXeQxAlE6245rSJSC5eImot/7V6obtX8NpyPoRZHlpdqHYH12LJe8kualS0Y9dGJRelayGDJoufgLIj1ItnBdLbUPc4kc89A7pKDXN4Va4KG7PdQJisV6YIfBR6a/PStuHnpKlktLHj43yyVFURNC2S6NVdnJctHXpLmD7UYtlzBZjdA1mSjO/+AD2PxFy9ejPXS3Qcw7HaY/9KzTEAw300MXiSN0twvac7j6HHlG+tuzbcPFQ08UtSWK0FOh96j4adpDTxVdMerPz57l0pwMF2g/laJePRs2h57DYOy5LV+PjtATjbObaQa36RjyqWN95E0eenbQaYtp05w89EnfVyOBl/ZKf3vJtp3QQ2+Bd3/TehXZPzzJPj0cTE/UooKejSyXyLlqjn8OHpWiWfTQ21NxXnvozjFXW5PvvNq2L5BUMZZL9mkIhilNd7Qi8G4pKuL+ieHztVzMIdKXSzpZLs1sKQreNkXaEXqkYtTnz16WSyYi9PZguXiNGZsNdEvRthRYzzFXs01uVYp2yCNQHrqLGEoJXzznPfq6W38q0LKWhKmSrD90t/kh/Tz0RITDaQp6JHUxK1kukQet2RG6pWFRtFI0C7d775Hqsz0N7NBtqPr0Gji9M+Fs/NfBaUd3Weo0hSR5bpbLhk/gtatgzXvuCzYnDz1TuDYsSnD6M5UuqZEyvUpRaB+WS7p9mGtsEbpjnW3J+c/A5s+bP7h2azDhe0rMR5ya7T1pB+RWhN4hBT0UlvjdtLexSn3u2+C+oJegJ8pyyRRu226NhkVehEPNrxSF7Fkuza2oai9ZLkXlsP9xbb/dRPh8iQfA6EzkmIfeIY8gLCU+X4Jo2isdqzl56JnCuH3zOwAAHQZJREFUzUNPKQ89Q4L+5k3pC7puwBJqQuWjt3Fvi9D8UoG1UjSrTf8N7Rph0hazTjgs8SU6+YkE3bVSNFseeiLLpQWVom58+ic16HM6gq5Hron2S96B+v6IXud2UilqaKfkVve5HfIOD0vwJxJ03W+0E888dG25tHzfPHEdUzTB6c+0hw6wdXF6FYNHXacq0PT5zEaE3twWlq4Reoe83Q2tibFcsk9IysS6tH2p+/Tm5KFnCrfuc5vb9L+51GxP03IphJJeLeuXvLlELZcWCrq1UjQHIjBDhsmxvlw65BFImcRy8cKr6X9beOjCFy/OqVSKZjp3N92IV/iyY7lkMkI3lovBEyPoWSfk6aEnEWTh86j4aIMsF58vPsJNqel/hm2O5gi6jtDb1HLRnVploFI0us4OebsbWhOb5dLxS3Ad8g4PS/AnynLxwi3TBNquebZTEFPqPjfDNke6toPwxTz0trRcoqMrNTdCt1aKRjCCbnBiLJfsEw7L5mUYZbNhEcRbFgkrRTPR26LbetON0EUsQs9kq9VkSDVubIs9dBOhG1IlB+6PDnkEYSkTZ7l40Zwh6FrK0GNi/8dF6K3Y26IX6Q5fJnzQlAXLRQt6Sy0XUylqSERnzEMXQswQQnwthFglhLjJY57zhBBLhRBLhBDPZnY37YSSNSzyIhuVohe+CNetUP9bxcmfn7jjqWEnwmE/aNlNdv4z8dOSDXbtxOaht2HnSi22XEyEbkgB6z2RAy/8pE+LEMIPPAycAGwEPhVCvC6lXGqZZxjwc+AIKeUeIUTv1tphUB66a6VoMvFL2h96KzzweYWx3u2s0fbMd6H7UO/lBk9Rfy2h3zg444/wzx9a9ifNCN3nJxrltmVfLjIi6M22XIyHbkiFzuehHwqsklKullI2As8DztEergAellLuAZBSbs/sbtpRLUWbsaBXS9Folktre+gWQewzMjZyTGviPN7mROiatuz+NGMRejg2LQeyGAwZphNWig4ArL1dbYxMszIcGC6E+EAI8ZEQYobbioQQM4UQC4QQC3bs2NG8PSbiobsperI+p7PZsAja1oPWOI+pOR66pk0j9Ax56DbLpeN7pIYMY1qKuhIAhgFTgQuAPwkh4kZVllI+LqWcKKWc2KtX8waNkFISliDcHk5rNOaGNQ/d2i1rW13ITAwUnC7OY8tviaC3YYQetVxMpaihNel8/aFvAgZavldEplnZCHwspWwC1gghVqAE/tOM7KUFHXC5ZrmkIugAJ91tzz5pq8gtGxG6U8TyWmC5tOX+h3WE3tzucy0DXGhyIAIzZJhOaLl8CgwTQgwVQuQD3wZed8zzGio6RwjRE2XBrM7gfkYJRR5QVw9d+65e6DfwYVdC7xGW6W10IdvSstDERejpCrrlRLdpHrr20DMYoefAA2vINJ1M0KWUQeAa4C1gGfCilHKJEOLXQgjdS/5bwC4hxFJgLnCDlHJXa+xwWAu6q4eepALM64K1WYSeDUF3Voq2xHJpywi9NdIWO36R2pBhbB56x69jSelpkVLOAmY5pv3K8r8Efhr5a1WiJfFklosvACFHxO4p6G3loWdB0HFUFLfIcumAHrrtJd/xIzBDhumMDYvaEzpC97vtubQIuJsQeF6wHPbQnTZUurZJtrJcohF6C4eg6zYkNs0IuiGOji/iVjrcHR7z0DNpueSwhx4O2r+naztkKw+9xR66D779LFz6hn2awWAlx17yHW6QaJnIcglbLRcj6EB8hJ7usdqaRrdlHnoGWqeOOMX+PcceXkMGyAGbxUqHu8MTZrk4PXQn2a4UzYaHLh2CXj7QfT4vdETvy2vbCLellaJuGEE35Dgd7g6PeegOEa7eAbNvjn139dCzHaFnw0OPWC7jL4LrV0L5oPSWjw4F18b7LltD0E2Wi8GBidCzSzisBD2upei//weqtsS+N8dySdZ1QEtpyyHcNFrQfQEobUafadGWtW0s6CZCN7QFOXZPdLijCWtr1Rmh61F1NG5C4Jkx0QmyXJorjNmO0DNZ72Ca/hviMBF6VvH00J1v2rQ89BzOQ88vVZ8lzes7JybobZjhApYGByZCN7QiOWa5dLgsF225xGW5OL+3y0rRLESIY8+HYB2Mv7h5y0cFvY1fRq3ioRtBNzjIsXui4wm6Zx66U9ATDAad6vRMk41owOeDiZc1f/msWS4mQje0BbkVoXe4O9zTQ+8IlktHRJ+brFWKZrBUY66zwUmOWS4d7g4PRbNcHD+0yHLR01s5y6Ujku1KUROhG1oVI+hZRXrloTtJR9Bz7KJmlKxViobs288EJsvF4CTHXvId7mg8+3LJSIRuhD0OX5YqRXsckPnt5tjDa8gAOWa5dLxKUa++XDLiobeB5XLZW1Dap/W3kymiHnobR+gXvgibP4eCssyt0wi6IQ49QHxulN46nqB79uXSAdIWAQZNbrttZYJspS2W9IBhJ2R2nTny0BoyiL6/c8SO63Ahi2dfLnGWi1vaosdFM5GbN9ny0FuDHCteGzKAviVyRAM63FGEPBsWpWK5eOWhd7jT0HZkK8ulNciRKMyQSXLLculwSqbz0OPHFE3FcsnyiEUdkWzlobcG5sVtcKI1IUde9h3uDvf00FPJcvHCFMW9yaUI3Qi6wYm+J3Lk3uhwR6H7cvEnbfqfjqC3Ufe5HZGcEvTciMIMmcRE6FlF56HH9YduIvTWQZ+bnBD0Dne7G1obYTz0rCK9+nJJpXMuL8yD7k228tBbA3OdDU5M2mJ2iWW5OH5IJcvFC/Oge5OtPPTWIEceWkMm0RF6bmhAhzuKaKVo0jz0dNpM6WWNhx6HLoqaPHRDLmIsl+yScn/o6USUOfJ2bhVyqVLUYHAStVxyQwM63FHovlzislw8LZgUojIj6N7kUh66wRCHsVyySizLxfGDl4eeyoXKkYvZKpgI3ZDLRBsWdbhurVzpcEqWcn/o2nJJSdCNt+qJEXRDTmM89KwS8uo+V3sxGv3GTSWzwQi6N7mUh24wODFpi9kl1tui4wfpFPTIBUrHcjEtRePJhTz0ocdkew8M7ZVob4u5EdR1OOMo7NVSVI9BqUnHQzedc3mTC3noF/0DGmuyvReG9kyOWC4dVtDjslzCXoKeiuXS4QoqbUcu9IceKOjYJQxD66FL5cZyyQ6eHnqc5aIF3aQttghTKWrIZaKDkRtBzwqxlqKOH+Isl3Q8dGO5eGLy0A25TDioPjtThC6EmCGE+FoIsUoIcVOC+c4WQkghxMTM7aKdsNeIRXGWS8TzTSnLpcO919oOff5MhG7IRWRuRehJPXQhhB94GDgB2Ah8KoR4XUq51DFfGfBj4OPW2FFN2Ku3RWeGirVS9PLZULU5wVpNXy6elPVT/nlJr2zvicGQebRV24ma/h8KrJJSrpZSNgLPA2e4zPcb4C6gPoP7F4dnS1FPy8UPAyfBSLddNiRl6NFw42oo6ZntPTEYMk/UQ+88gj4A2GD5vjEyLYoQYgIwUEr5f4lWJISYKYRYIIRYsGPHjrR3FiwtRVPOcknnQhkvPQ4hoKA023thMLQOOkLPEculxa8lIYQPuA+4Ltm8UsrHpZQTpZQTe/VqXhE+5OWhOyN00ZxOd4zlYjB0KnQg2IkqRTcBAy3fKyLTNGXAaGCeEGItMBl4vbUqRrWHHtcfujNtMTpWYG4UpQwGQytQUKY+ywdldz8yRCoNiz4FhgkhhqKE/NvAhfpHKeU+IGqwCiHmAddLKRdkdlcVYa8Ri5yWS46N5m0wGFqBIUfAOU/AgSdne08yQlK1k1IGgWuAt4BlwItSyiVCiF8LIU5v7R10EvbqbdEaod+yLz3LxeShGwydl9FnQV5htvciI6TU9F9KOQuY5Zj2K495p7Z8t7yZNLQ7N0w/kDxn71xelkuOVHYYDAZDMjpcXy4TBnVjwqBu8T/EWS65NRKJwWAwJCN31E6GYMAh8LO16ntz+jk23ecaDIYOTA4JehiKe0CRjt51hG78cYPB0DnIHUEPh+z2irFcDAZDJyN31E6G7RWg0bTFVCwXE8UbDIaOT24Juq0RkWkpajAYOhe5I+jGcjEYDJ2c3FE7GXLYK7rpv8lDNxgMnYPcEfRwyC7epqWowWDoZOSOoMuwsVwMBkOnJnfUzpnlkk6laF6x+izrl/HdMhgMhraiwzX99yQcsme5pNPbYt/RcObjcOCM1tk3g8FgaANyR9C9LJdUK0XHnZ/5fTIYDIY2JIcsF48sF+OhGwyGTkLuqF1LslwMBoMhB8gdtWtR03+DwWDo+OSYoLs1/Tc55gaDoXOQO4JuLBeDwdDJyR21i8tyacYAFwaDwdCByQ1BlxLCTeCzZmGaCN1gMHQuckPtgg0QDkJBaWyaMINEGwyGzkVuCHpDlfos6GKZaCJ0g8HQucgNtWvUgl4Wm2YqRQ0GQycjN9ROR+j5LpaLLzcO0WAwGJKRG2rX4BKhG8vFYDB0MnJD7dwEPZ3eFg0GgyEHyA21c6sUNVkuBoOhk5Fjgm7x0I3lYjAYOhm5oXaulosRdIPB0LnIDbVrqFLCrYeSA9P032AwdDpyY8SihirIL3P0rGgidEPu0NTUxMaNG6mvr8/2rhjaiMLCQioqKsjLy0t5mdwQ9FADBArs04zlYsghNm7cSFlZGUOGDEGYLqFzHiklu3btYuPGjQwdOjTl5XJD7UJB8Ofbp5m0RUMOUV9fT48ePYyYdxKEEPTo0SPtElluqF2oEfzOwoaJ0A25hRHzzkVzrnduqF24ySVC103/TaWowWDoHKQk6EKIGUKIr4UQq4QQN7n8/lMhxFIhxCIhxBwhxODM72oCQk3g86g4MBG6wWDoJCRVOyGEH3gYOAkYCVwghBjpmG0hMFFKORZ4Cbg70zuakFBTvOViPHSDIWP4/X7Gjx/PqFGjGDduHPfeey/hcLhNtv3kk0/i8/lYtGhRdNro0aNZu3ZtwuXuv/9+amtro99/+ctfMnDgQEpLS23z3XfffYwcOZKxY8cybdo01q1bF/1txowZlJeXc+qpp2bmYFqZVLJcDgVWSSlXAwghngfOAJbqGaSUcy3zfwRcnMmdTEqo0dtyMU3/DTnGrf9awtLNlRld58j+Xbj5tFGevxcVFfHFF18AsH37di688EIqKyu59dZbM7ofXlRUVHDbbbfxwgsvpLzM/fffz8UXX0xxsWqfctppp3HNNdcwbNgw23wHH3wwCxYsoLi4mEceeYQbb7wxup0bbriB2tpaHnvsscwdTCuSSvg6ANhg+b4xMs2Ly4E33H4QQswUQiwQQizYsWNH6nuZjHDQxXLRgm4qkgyGTNK7d28ef/xxHnroIaSUhEIhbrjhBiZNmsTYsWOj4jdv3jymTp3KOeecw4gRI7jooouQUgJw0003RaPi66+/HoAdO3Zw9tlnM2nSJCZNmsQHH3wQ3eapp57KkiVL+Prrr+P25+2332bKlClMmDCBc889l+rqah544AE2b97Msccey7HHHgvA5MmT6devX9zyxx57bFT0J0+ezMaNG6O/TZs2jbKysrhl3Pj1r3/NpEmTGD16NDNnzowe66pVqzj++OMZN24cEyZM4JtvvgHgrrvuYsyYMYwbN46bbopzspuHlDLhH3AO8GfL9+8AD3nMezEqQi9Itt5DDjlEZow/nyDlk6fZp+1ZL+XNXaR8797MbcdgyBJLly7N6vZLSkripnXt2lVu3bpVPvbYY/I3v/mNlFLK+vp6ecghh8jVq1fLuXPnyi5dusgNGzbIUCgkJ0+eLOfPny937twphw8fLsPhsJRSyj179kgppbzgggvk/PnzpZRSrlu3To4YMUJKKeUTTzwhr776avnUU0/J7373u1JKKUeNGiXXrFkjd+zYIY866ihZXV0tpZTyzjvvlLfeequUUsrBgwfLHTt2pHQsmquvvjp6LJq5c+fKU045Jek52rVrV/T/iy++WL7++utSSikPPfRQ+corr0gppayrq5M1NTVy1qxZcsqUKbKmpiZuWStu1x1YID10NRXLZRMw0PK9IjLNhhDieOCXwDFSyoYWvGPSJ9Tk6Asdk+ViMLQRb7/9NosWLeKll14CYN++faxcuZL8/HwOPfRQKioqABg/fjxr165l8uTJFBYWcvnll3PqqadG/enZs2ezdGnUyaWyspLq6uro9wsvvJDbbruNNWvWRKd99NFHLF26lCOOOAKAxsZGpkyZ0qzjeOaZZ1iwYAHvvvtus5afO3cud999N7W1tezevZtRo0YxdepUNm3axJlnngmo1p+gjvXSSy+Nlgy6d+/erG06SUXQPwWGCSGGooT828CF1hmEEAcDjwEzpJTbM7Jn6eCWtmjy0A2GVmP16tX4/X569+6NlJIHH3yQ6dOn2+aZN28eBQWxFtx+v59gMEggEOCTTz5hzpw5vPTSSzz00EO88847hMNhPvroo6joOQkEAlx33XXcdddd0WlSSk444QSee+65Fh3P7Nmzue2223j33Xdt+5wq9fX1/PCHP2TBggUMHDiQW265JSvdNCRVOyllELgGeAtYBrwopVwihPi1EOL0yGy/A0qBfwghvhBCvN5qe+xGqAl8ziwXUylqMLQGO3bs4KqrruKaa65BCMH06dN55JFHaGpqAmDFihXU1NR4Ll9dXc2+ffs4+eST+f3vf8+XX34JwIknnsiDDz4YnU9Xwlq55JJLmD17NroObvLkyXzwwQesWrUKgJqaGlasWAFAWVkZVVVVSY9n4cKFXHnllbz++uv07t07xbNgR4t3z549qa6ujpZWysrKqKio4LXXXgOgoaGB2tpaTjjhBJ544oloFs7u3bubtV0nKYWvUspZUsrhUsr9pZS3Rab9Skr5euT/46WUfaSU4yN/pydeY4YJuTUsMmmLBkOmqKuri6YtHn/88Zx44oncfPPNAHz/+99n5MiRTJgwgdGjR3PllVcSDAY911VVVcWpp57K2LFjOfLII7nvvvsAeOCBB1iwYAFjx45l5MiRPProo3HL5ufnc+2117J9uzICevXqxZNPPskFF1zA2LFjmTJlCsuXLwdg5syZzJgxI1opeuONN1JRUUFtbS0VFRXccsstgMpkqa6u5txzz2X8+PGcfnpMvo466ijOPfdc5syZQ0VFBW+99ZbrMZWXl3PFFVcwevRopk+fzqRJk6K/Pf300zzwwAOMHTuWww8/nK1btzJjxgxOP/10Jk6cyPjx47nnnntSvRQJETJSE9vWTJw4US5YsCAzK/v9GBhyBJxpuQGqtsG9w+Gk38FhMzOzHYMhSyxbtoyDDjoo27thaGPcrrsQ4jMp5US3+XMjfA27WC4FZVDcE7oNycouGQwGQ1uTI93nujQsyi+GG7/Jzv4YDIac5cwzz7Rl2oDKKXdWCmeDHBH0IPhT7wTeYDAYmsurr76a7V3wJDcsl1CjEXSDwdDpyQ1BDyfobdFgMBg6CR1f0KVUfbnENSwyGAyGzkXHF/SQaswQP2KRwWAwdC46vqCHtaCbCN1gaC1Mf+iZ7w996tSpZKwtToSOH9aGGtWn8dANnYU3boKtizO7zv/f3v2HVnWfcRx/f2xts2UhNabrdHHTbII/mD9G6FISsFOnSZH9FSF1sApCmNsfmYxJZSAMVGaRdBuOsTjH/GPrdKxi1cVWbYQhrKbaNDVGp0XnIpmZwVSQIUv27I/zze3FJJ0muTmec58XXM75fs8Bv8/15MnJc875ns99BWp/Mupmnw89PfOhP9oGwyPGfpeLc5PC50Mf7tixY6xduzbTPnXqVOasfuPGjVRUVLBw4cLMdAm5kp4zdE/oLl98wpn0ZCkvL2dwcJDe3l4OHTpEcXExbW1t3Lt3j6qqKlatWgVEE191dnYyc+ZMqqqqOH36NPPnz+fgwYNcvHgRSfT39wPQ2NjIpk2bqK6u5vr166xevZquri4ApkyZwubNm9mxYwf79u3LjOPWrVts27aNEydOUFhYyM6dO2lqamLr1q00NTXR2tpKaWnpA8e1d+9eamtrH/r7WLlyJQ0NDdy9e5fCwkL2799PfX09ANu3b6ekpITBwUFWrFhBR0cHixYteuh/40EkN6G/3gCX34KGU1HbSy7OxcLnQ4+m9q2pqeHw4cPU1dVx9OhRXnklerXygQMHaG5uZmBggJ6eHi5cuOAJfZiOUEv79+1o6RdFnZs0Ph/6cPX19ezevZuSkhIqKiooKiri6tWr7Nq1i7a2NqZNm8b69etzOk96Mmvo3Wc/Xm//fbT02xadmxQ+H/rIli1bxrlz59izZ0+m3HLnzh0KCwspLi7m5s2btLSM+LrlCZO8hN7+Gvx6+cftM83Rsmj4xQ7n3MTw+dA/eT50iP4CWbNmDS0tLZky0uLFi1m6dCnz5s1j3bp1mdJQriRvPvTrf4U//xBmPUv0mjmDyu/C9C9N9BCde2T4fOj56WHnQ09eneILlfCdv8Q9Cuece+QkL6E751yMfD5059y4mRkaevm5i81kzYc+lnJ48i6KOpeHCgoK6OvrG9MPuUseM6Ovr2/UWzhH42foziVAWVkZ3d3dmdv1XPoVFBRkHsp6UJ7QnUuAqVOnMmfOnLiH4R5xXnJxzrmU8ITunHMp4QndOedSIrYnRSX9C/j7/91xZKXArQkcThJ4zPnBY84P44n5i2b29EgbYkvo4yHp3dEefU0rjzk/eMz5IVcxe8nFOedSwhO6c86lRFITenPcA4iBx5wfPOb8kJOYE1lDd845N1xSz9Cdc87dxxO6c86lROISuqQaSZckXZH0ctzjmSiSfiOpV9L5rL4SScclXQ7LaaFfkn4evoMOSV+Nb+RjJ2mWpFZJFyR1SmoM/amNW1KBpDOS3g8x/zj0z5H0Tohtv6QnQv+ToX0lbJ8d5/jHStJjkt6TdCS0Ux0vgKRrkj6Q1C7p3dCX02M7UQld0mPAL4BaYAHwoqQF8Y5qwvwWqLmv72XgpJnNBU6GNkTxzw2fBuCXkzTGiTYA/MDMFgCVwPfC/2ea474HLDezxcASoEZSJbATeNXMvgzcBjaE/TcAt0P/q2G/JGoEurLaaY93yNfNbEnWPee5PbbNLDEf4Dngzaz2FmBL3OOawPhmA+ez2peAGWF9BnAprP8KeHGk/ZL8AQ4B38iXuIFPA+eArxE9Nfh46M8c58CbwHNh/fGwn+Ie+0PGWRaS13LgCNHLgFMbb1bc14DS+/pyemwn6gwd+Dzwj6x2d+hLq2fMrCes/xN4Jqyn7nsIf1ovBd4h5XGH8kM70AscBz4E+s1sIOySHVcm5rD9I2D65I543H4KbAb+G9rTSXe8Qwx4S9JZSQ2hL6fHts+HnhBmZpJSeY+ppM8AfwK+b2Z3sl+zlsa4zWwQWCLpKeAgMC/mIeWMpDVAr5mdlfR83OOZZNVmdkPSZ4Hjki5mb8zFsZ20M/QbwKysdlnoS6ubkmYAhGVv6E/N9yBpKlEy/52ZvR66Ux83gJn1A61EJYenJA2dYGXHlYk5bC8G+iZ5qONRBXxT0jXgD0Rll5+R3ngzzOxGWPYS/eJ+lhwf20lL6G3A3HCF/AmgHngj5jHl0hvAS2H9JaIa81D/t8OV8Urgo6w/4xJD0an4XqDLzJqyNqU2bklPhzNzJH2K6JpBF1Firwu73R/z0HdRB7xtociaBGa2xczKzGw20c/r22b2LVIa7xBJhZKKhtaBVcB5cn1sx33hYAwXGl4A/kZUd/xR3OOZwLheA3qA/xDVzzYQ1Q5PApeBE0BJ2FdEd/t8CHwAVMQ9/jHGXE1UZ+wA2sPnhTTHDSwC3gsxnwe2hv5y4AxwBfgj8GToLwjtK2F7edwxjCP254Ej+RBviO/98OkcylW5Prb90X/nnEuJpJVcnHPOjcITunPOpYQndOecSwlP6M45lxKe0J1zLiU8oTvnXEp4QnfOuZT4HxaKWGZUiycbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Nadam_5_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fecdc40-214a-49b5-864b-5fa05bf0148f"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f73400cf-2eaf-4f29-a54c-af724391ccbf"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6a060d6c-cb8b-4132-df78-25513d3b6dfb"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fd323baa-90c3-4a40-8d8b-c0272f5dbf8a"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Optimizer_Nadam_5_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Optimizer_Nadam_5_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_04d51006-c086-4763-babb-c80761b9c42c\", \"Optimizer_Nadam_5_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}