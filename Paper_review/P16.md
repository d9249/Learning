# Medical-Deep-Learning

Kyonggi Univ. 2021. 02. BE530_0058.

### P_16

Chest Radiograph Disentanglement for COVID-19 Outcome Prediction

### Date

2021.11.24

## Abstract.

Chest radiographs (CXRs) are often the primary front-line diagnostic imaging modality. 

Pulmonary diseases manifest as characteristic changes in lung tissue texture rather than anatomical structure. 

Hence, we expect that studying changes in only lung tissue texture without the influence of possible structure variations would be advantageous for downstream prognostic and predictive modeling tasks. 

In this paper, we propose a generative framework, Lung Swapping Auto Encoder (LSAE), that learns a factorized representation of a CXR to disentangle the tissue texture representation from the anatomic structure representation. 

Upon learning the disentanglement, we leverage LSAE in two applications. 

1. After adapting the texture encoder in LSAE to a thoracic disease classification task on the large-scale ChestX-ray14 database (N = 112,120), we achieve a competitive result (mAUC: 79.0%) with unsupervised pre-training. Moreover, when compared with Inception v3 on our multi-institutional COVID-19 dataset, COVOC (N = 340), for a COVID-19 outcome prediction task (estimating need for ventilation), the texture encoder achieves 13% less error with a 77% smaller model size, further demonstrating the efficacy of texture representation for lung diseases
2. We leverage the LSAE for data augmentation by generating hybrid lung images with textures and labels from the COVOC training data and lung structures from ChestX-ray14. 

This further improves ventilation outcome prediction on COVOC.

The code is available here: https://github.com/cvlab-stonybrook/LSAE.

**Keywords**: Chest radiographs, Disentanglement, Lung swapping, auto-encoder, Unsupervised learning

## 1. Introduction

![image-20211125153016860](P16_image\image-20211125153016860.png)

**Fig. 1.** **Lung Swapping Result.** Two examples of lung swapping between images in column I1 and images in column I2. 

The Lung Swapping Auto encoder (LSAE) is able to successfully transfer target lung textures without affecting the lung shape. 

The swapping results are shown in the second and the third columns.

------

Chest radiographs (CXRs) are the primary diagnostic tool for COVID-19 pneumonia because they are widely available, and have lower risk of cross infection compared to Computed Tomography (CT) scans. 

Despite these advantages, CXRs are less sensitive to subtle disease changes compared to CT scans [12].

In COVID-19 CXRs, we observe that lung tissue texture may change drastically during hospitalization due to varying infiltrate levels. 

However, chest anatomy remains mostly unchanged. 

Therefore, we hypothesize that disease information is more related to lung tissue texture rather than the anatomical structure of the lung. 

To be concise, we use the terms texture and structure in the rest of the article. 

Our hypothesis is also supported by recent findings that COVID-19 on CXR is observed as opacities within lung regions, and their extent and location is associated with disease severity and progression [22,25].

Previous medical image analysis in COVID-19 has mostly focused on diagnosis[7,13]. 

CT-based models are better at predicting COVID-19 outcomes, compared to CXR-based models [1,11,13]. 

This is largely due to the lack of COVID-19 CXR datasets with relevant endpoints and the limited information that CXRs contain relative to CT scans. 

Several data augmentation techniques have been proposed for CT scans in the COVID-19 setting [11], but CXR approaches have continued to rely on publicly sourced datasets [2,13]. 

These datasets tend to be homogeneous, and often lack disease outcome labels (hospitalization, mechanical ventilation requirement, etc.) [2,13]. 

Generative Adversarial Networks (GANs) [3] and Autoencoders [10] have been widely used for data augmentation, including in medical image applications [6,19,20]. 

However, standard GAN-based methods [8,26] are not suitable for CXR generation due to the lack of explicit structure supervision, which can lead to generating distorted shapes.

In this paper, we propose the Lung Swapping AutoEncoder (LSAE), which learns a factorized representation of a CXR to disentangle the texture factor from the structure factor. 

LSAE shares the same core idea as the recently-proposed Swapping AutoEncoder (SAE) [15], namely that a successful disentanglement model should be able to generate a realistic hybrid image that merges the structure of one image and the texture of another. 

To achieve this, images are encoded as a combination of two latent codes representing structure and texture respectively.

The SAE is trained to generate realistic images from the swapped codes of arbitrary image pairs. 

Moreover, the SAE is also forced to synthesize the target texture supervised by patches sampled from the target image. 

However, this vanilla SAE does not work well for CXR disentanglement. 

First, by sampling texture patches from the whole target image, irrelevant out-of-lung textures diminish the effect of the in-lung texture transfer. 

More importantly, because texture supervision is derived from image patches, irrelevant structure clues may leak into the hybrid image, resulting in undesired lung shape distortion and interference with successful disentanglement.

We address these problems by: 

1) Sampling patches from the lung area instead of the whole image for texture supervision (as the infiltrates of interest are located within lung zones), and 
2) Adding a patch contrastive loss to explicitly force outof-lung local patches in the hybrid image to mimic the corresponding patch in the structure image (to prevent structure information in texture patches from leaking into the hybrid image). 
   LSAE, trained on a large public CXR dataset, ChestXray14, can generate realistic and plausible hybrid CXRs with one patient’s lung structure and another patient’s disease texture (see Fig. 1). 
   We further provide quantitative results for disentanglement in the experiment section.

The trained disentanglement model is used in two applications: 

1) If textures represent disease infiltrates, the texture encoder in LSAE, Enct, should be discriminative in downstream CXR semantic tasks. To prove this, we finetune Enct in LSAE on both the large ChestX-ray14 database (N = 112,120) and our multi-institutional COVID-19 outcome prediction dataset, COVOC (N = 340). For thoracic disease classification on ChestX-ray14, Enct achieves competitive results without supervised pre-training. On COVOC, compared with a strong baseline Inception v3 [21], Enct reduces error by 13% with a much smaller model size. 
   Results show that Enct learns effective and transferable representations of lung diseases. 
2) To exploit the generative potential of LSAE, we generate hybrid images with textures and labels from COVOC training data and lung structures from ChestX-ray14. 
   Augmenting with these hybrid images further improves ventilation prediction on COVOC.

In summary: 

1) LSAE is the first approach to disentangle chest CXRs into structure and texture representations. 
   LSAE succeeds by explicit in-lung texture supervision and out-of-lung distortion suppression, 
2) We achieve superior performance for COVID-19 outcome prediction with an efficient model, and 
3) We propose a hybrid image augmentation technique, to further improve ventilation prediction.



## 2. Methodology

### 2.1 Swapping AutoEncoder(SAE)

The recent Swapping AutoEncoder (SAE) [15] consists of an encoder Enc, and a decoder Dec, where Enc is composed of a structure branch Encs and a texture branch Enct to encode the input into structure and texture codes zs and zt.

**Latent Code Swapping.**

![image-20211125161659658](P16_image\image-20211125161659658.png)

![image-20211125161832925](P16_image\image-20211125161832925.png)

### 2.2 Lung Swapping AutoEncoder (LSAE)

**In-lung Texture Supervision.**

![image-20211125164244183](P16_image\image-20211125164244183.png)

![image-20211125164219216](P16_image\image-20211125164219216.png)

**Fig. 2. Lung Swapping AutoEncoder**

**Out-of-Lung Structural Distortion Suppression.**

![image-20211125164308904](P16_image\image-20211125164308904.png)

![image-20211125164334559](P16_image\image-20211125164334559.png)

**Overall Objective.**



### 2.3 Hybrid Image Augmentation

## 3. Experimental Design and Results

### 3.1 Dataset Description

**ChestX-ray14**

**COVID-19 Outcome (COVOC)**

### 3.2 Implementaion

### 3.3 Hybrid CXR Generation

**Experimental Settings.**

**Evaluation Protocol.**

**Results**

### 3.4 Semantic Prediction in CXRs by Texture Encoder

![image-20211125164415646](P16_image\image-20211125164415646.png)

**Table 1. Left**

![image-20211125164438121](P16_image\image-20211125164438121.png)

**Table 2.**

**Disease Classification on ChestX-ray14.**

**Outcome Prediction on COVOC.**

### 3.5 Data Argmentation with Hybrid Images

As described in Sect. 2.3, we generate hybrid images to augment the training data in COVOC. 

To control the training budget, we set K = 2, i.e., the training data of COVOC is augmented 2 times. 

To avoid introducing irrelevant diseases, we only sample structure images from the healthy lungs in ChestX-ray14. 

With the same experimental setup with Table 2, the augmentation method can reduce error rate further from 16.50% to 15.67%, and improve mAUC from 90.41% to 92.04% on the ventilation prediction task. 

Moreover, we implement Mixup independently for training on COVOC which achieves 16.41% BER/90.82% mAUC.

Our method still shows superior performance.

## 4. Conclusion

We propose LSAE to disentangle texture from structure in CXR images, enabling analysis of disease-associated textural changes in COVID-19 and other pulmonary diseases. 

We also create a data augmentation technique which synthesizes images with structural and textural information from two CXRs. 

This technique can be used to augment data for machine learning applications. 

Our resulting predictive model for mechanical ventilation in COVID-19 patients outperforms conventional methods and may have clinical significance in enabling improved decision making. 

We will apply our texture disentanglement and data augmentation methods to study other pulmonary diseases in the future.
