# Medical-Deep-Learning

Kyonggi Univ. 2021. 02. BE530_0058.

### P_16

Chest Radiograph Disentanglement for COVID-19 Outcome Prediction

> COVID-19 결과 예측을 위한 흉부 방사선 사진 분리

### Date

2021.11.24

## Abstract.

Chest radiographs (CXRs) are often the primary front-line diagnostic imaging modality.

> 흉부 방사선 사진(CXR)은 종종 일차적인 진단 영상 기법입니다.

Pulmonary diseases manifest as characteristic changes in lung tissue texture rather than anatomical structure.

> 폐 질환은 해부학적 구조보다는 폐 조직 조직의 특징적인 변화로 나타납니다.

Hence, we expect that studying changes in only lung tissue texture without the influence of possible structure variations would be advantageous for downstream prognostic and predictive modeling tasks.

> 따라서 가능한 구조 변화의 영향 없이 폐 조직 질감의 변화만 연구하는 것이 다운스트림 예후 및 예측 모델링 작업에 유리할 것으로 기대합니다.

In this paper, we propose a generative framework, Lung Swapping Auto Encoder, that learns a factorized representation of a Chest radiograph to disentangle the tissue texture representation from the anatomic structure representation.

> 이 논문에서 우리는 해부학적 구조 표현에서 조직 질감 표현을 풀기 위해 흉부 방사선 사진의 인수분해 표현을 학습하는 생성 프레임워크인 Lung Swapping Auto Encoder를 제안합니다.

Upon learning the disentanglement, we leverage Lung Swapping Auto Encoder in two applications.

> 얽힘을 학습하면 두 가지 응용 프로그램에서 Lung Swapping Auto Encoder를 활용합니다.

1. After adapting the texture encoder in Lung Swapping Auto Encoder to a thoracic disease classification task on the large-scale ChestX-ray14 database (N = 112,120), we achieve a competitive result (mAUC: 79.0%) with unsupervised pre-training. Moreover, when compared with Inception v3 on our multi-institutional COVID-19 dataset, COVOC (N = 340), for a COVID-19 outcome prediction task (estimating need for ventilation), the texture encoder achieves 13% less error with a 77% smaller model size, further demonstrating the efficacy of texture representation for lung diseases

   > Lung Swapping Auto Encoder의 텍스처 인코더를 대규모 ChestX-ray14 데이터베이스(N = 112,120)의 흉부 질환 분류 작업에 적용한 후 감독되지 않은 사전 훈련으로 경쟁력 있는 결과(mAUC: 79.0%)를 달성했습니다. 또한, COVID-19 결과 예측 작업(환기 필요성 추정)에 대해 다중 기관 COVID-19 데이터세트인 COVOC(N = 340)의 Inception v3와 비교할 때 텍스처 인코더는 77%로 13% 더 적은 오류를 달성합니다. 더 작은 모델 크기, 폐 질환에 대한 질감 표현의 효능 추가 입증
2. We leverage the Lung Swapping Auto Encoder for data augmentation by generating hybrid lung images with textures and labels from the COVOC training data and lung structures from ChestX-ray14.

   > 우리는 COVOC 훈련 데이터와 ChestX-ray14의 폐 구조에서 텍스처와 레이블이 있는 하이브리드 폐 이미지를 생성하여 데이터 증대를 위해 Lung Swapping Auto Encoder를 활용합니다.

This further improves ventilation outcome prediction on COVOC.

> 이는 COVOC에 대한 환기 결과 예측을 더욱 향상시킵니다.

The code is available here: https://github.com/cvlab-stonybrook/LSAE.

**Keywords**: Chest radiographs, Disentanglement, Lung swapping, auto-encoder, Unsupervised learning

> **키워드**: 흉부 방사선 사진, 분리, 폐 교환, 자동 인코더, 비지도 학습

## 1. Introduction

![image-20211125153016860](P16_image/image-20211125153016860.png)

**Fig. 1.** **Lung Swapping Result.** Two examples of lung swapping between images in column I1 and images in column I2.

> Fig 1. 폐 교체 결과.
> I1열의 이미지와 I2열의 이미지 간의 폐 교환의 두 가지 예.

The Lung Swapping Auto encoder is able to successfully transfer target lung textures without affecting the lung shape.

> Lung Swapping Auto 인코더는 폐 모양에 영향을 주지 않고 대상 폐 텍스처를 성공적으로 전송할 수 있습니다.

The swapping results are shown in the second and the third columns.

> 스와핑 결과는 두 번째 및 세 번째 열에 표시됩니다.

------

Chest radiographs are the primary diagnostic tool for COVID-19 pneumonia because they are widely available, and have lower risk of cross infection compared to Computed Tomography (CT) scans.

> 흉부 방사선 사진은 널리 사용 가능하고 컴퓨터 단층 촬영(CT) 스캔에 비해 교차 감염 위험이 낮기 때문에 COVID-19 폐렴의 주요 진단 도구입니다.

Despite these advantages, Chest radiographs are less sensitive to subtle disease changes compared to CT scans [12].

> 이러한 장점에도 불구하고 흉부 방사선 사진은 CT 스캔에 비해 미묘한 질병 변화에 덜 민감합니다[12].

In COVID-19 Chest radiographs, we observe that lung tissue texture may change drastically during hospitalization due to varying infiltrate levels.

> COVID-19 흉부 방사선 사진에서 우리는 다양한 침윤 수준으로 인해 입원 중에 폐 조직 질감이 급격히 변할 수 있음을 관찰했습니다.

However, chest anatomy remains mostly unchanged. 

Therefore, we hypothesize that disease information is more related to lung tissue texture rather than the anatomical structure of the lung. 

To be concise, we use the terms texture and structure in the rest of the article. 

Our hypothesis is also supported by recent findings that COVID-19 on Chest radiograph is observed as opacities within lung regions, and their extent and location is associated with disease severity and progression [22,25].

Previous medical image analysis in COVID-19 has mostly focused on diagnosis[7,13]. 

CT-based models are better at predicting COVID-19 outcomes, compared to Chest radiograph-based models [1,11,13]. 

This is largely due to the lack of COVID-19 Chest radiograph datasets with relevant endpoints and the limited information that Chest radiographs contain relative to CT scans. 

Several data augmentation techniques have been proposed for CT scans in the COVID-19 setting [11], but Chest radiograph approaches have continued to rely on publicly sourced datasets [2,13]. 

These datasets tend to be homogeneous, and often lack disease outcome labels (hospitalization, mechanical ventilation requirement, etc.) [2,13]. 

Generative Adversarial Networks (GANs) [3] and Auto encoders [10] have been widely used for data augmentation, including in medical image applications [6,19,20]. 

However, standard GAN-based methods [8,26] are not suitable for Chest radiograph generation due to the lack of explicit structure supervision, which can lead to generating distorted shapes.

In this paper, we propose the Lung Swapping Auto Encoder, which learns a factorized representation of a Chest radiograph to disentangle the texture factor from the structure factor. 

Lung Swapping Auto Encoder shares the same core idea as the recently-proposed Swapping Auto Encoder (SAE) [15], namely that a successful disentanglement model should be able to generate a realistic hybrid image that merges the structure of one image and the texture of another. 

To achieve this, images are encoded as a combination of two latent codes representing structure and texture respectively.

The Swapping Auto Encoder is trained to generate realistic images from the swapped codes of arbitrary image pairs. 

Moreover, the Swapping Auto Encoder is also forced to synthesize the target texture supervised by patches sampled from the target image. 

However, this vanilla Swapping Auto Encoder does not work well for Chest radiograph disentanglement. 

First, by sampling texture patches from the whole target image, irrelevant out-of-lung textures diminish the effect of the in-lung texture transfer. 

More importantly, because texture supervision is derived from image patches, irrelevant structure clues may leak into the hybrid image, resulting in undesired lung shape distortion and interference with successful disentanglement.

We address these problems by: 

1) Sampling patches from the lung area instead of the whole image for texture supervision (as the infiltrates of interest are located within lung zones), and 
2) Adding a patch contrastive loss to explicitly force outof-lung local patches in the hybrid image to mimic the corresponding patch in the structure image (to prevent structure information in texture patches from leaking into the hybrid image). 
   Lung Swapping Auto Encoder, trained on a large public Chest radiograph dataset, ChestXray14, can generate realistic and plausible hybrid Chest radiographs with one patient’s lung structure and another patient’s disease texture (see Fig. 1). 
   We further provide quantitative results for disentanglement in the experiment section.

The trained disentanglement model is used in two applications: 

1) If textures represent disease infiltrates, the texture encoder in Lung Swapping Auto Encoder, Enct, should be discriminative in downstream Chest radiograph semantic tasks. To prove this, we finetune Enct in Lung Swapping Auto Encoder on both the large ChestX-ray14 database (N = 112,120) and our multi-institutional COVID-19 outcome prediction dataset, COVOC (N = 340). For thoracic disease classification on ChestX-ray14, Enct achieves competitive results without supervised pre-training. On COVOC, compared with a strong baseline Inception v3 [21], Enct reduces error by 13% with a much smaller model size. 
   Results show that Enct learns effective and transferable representations of lung diseases. 
2) To exploit the generative potential of Lung Swapping Auto Encoder, we generate hybrid images with textures and labels from COVOC training data and lung structures from ChestX-ray14. 
   Augmenting with these hybrid images further improves ventilation prediction on COVOC.

In summary: 

1) Lung Swapping Auto Encoder is the first approach to disentangle chest radiographs into structure and texture representations. 
   Lung Swapping Auto Encoder succeeds by explicit in-lung texture supervision and out-of-lung distortion suppression, 
2) We achieve superior performance for COVID-19 outcome prediction with an efficient model, and 
3) We propose a hybrid image augmentation technique, to further improve ventilation prediction.



## 2. Methodology

### 2.1 Swapping Auto Encoder

The recent Swapping Auto Encoder[15] consists of an encoder Enc, and a decoder Dec, where Enc is composed of a structure branch Encs and a texture branch Enct to encode the input into structure and texture codes zs and zt.

**Latent Code Swapping.**

![image-20211125161659658](P16_image/image-20211125161659658.png)

![image-20211125161832925](P16_image/image-20211125161832925.png)

### 2.2 Lung Swapping Auto Encoder

**In-lung Texture Supervision.**

![image-20211125164244183](P16_image/image-20211125164244183.png)

![image-20211125164219216](P16_image/image-20211125164219216.png)

**Fig. 2. Lung Swapping AutoEncoder**

**Out-of-Lung Structural Distortion Suppression.**

![image-20211125164308904](P16_image/image-20211125164308904.png)

where α is the temperature, and {p}N = {p+}∪{p−}N−1. 

To prevent lNCE from affecting the in-lung texture transfer, we only apply it outside the lung region.

Thus, the structural distortion suppression loss is expressed as

![image-20211125164334559](P16_image/image-20211125164334559.png)

**Overall Objective.**

Combining the above, we term the final loss as L = Lrecon+ λ1LG + λ2LinTex + λ3Lsup, where λ1, λ2 and λ3 are tunnable hyper-parameters.

### 2.3 Hybrid Image Augmentation

If the texture in I2 can be transferred to Ihybrid, we assume the label (e.g., ventilation) of I2 is also attached to Ihybrid. 

Based on this hypothesis, we design a new data augmentation method: Given an image Idst in the target domain, e.g., COVOC, we sample K images {Isrc} from a source domain, e.g., ChestX-ray14.

Then, we use Lung Swapping Auto Encoder to take Idst as the texture template and images from {Isrc} as structure templates to generate K hybrid images {Ihybrid}. 

We label {Ihybrid} with the label of Idst. 

Following this protocol, we can enlarge the training set in target domain K times. 

Experimental results show the augmentation method can improve performance further on the COVID-19 ventilation prediction task.

## 3. Experimental Design and Results

### 3.1 Dataset Description

**ChestX-ray14**  is a large-scale Chest radiograph database consisting of 112,120 frontalview Chest radiographs from 32,717 patients. 

We report all the results based on the official split which consists of training (∼70%), validation (∼10%), and testing (∼20%) sets. 

Images from the same patient will only appear in one of the sets.

------

**COVID-19 Outcome (COVOC)** is a COVID-19 Chest radiograph dataset curated from two institutions. 

It consists of 340 Chest radiographs from 327 COVID-19 patients acquired upon disease presentation [9]. 

Each Chest radiograph in COVOC is labeled based upon whether the patient required mechanical ventilation (henceforth ventilation) or not. 

We separate COVOC randomly into 3 splits. 

Each split has 250 samples for training, 30 for validation, and 60 for testing.

### 3.2 Implementaion

For Lung Swapping Auto Encoder, both decoder and discriminator architectures follow StyleGAN2.

Encoders are built with residual blocks [5]. 

The texture encoder outputs a flattened vector while the structure encoder’s output preserves spatial dimension.

The input image size is of 256 × 256. 

Patch sizes sampled for texture supervision vary from 16 × 16 to 64 × 64. 

We set λ1 = 0.5, λ2 = 1, and λ3 = 1. 

The temperature α is set to 0.07. 

Lung Swapping Auto Encoder is optimized by Adam with learning rate 1e-3. Our code is based on PyTorch 1.7. 

We preprocess all Chest radiographs with histogram equalization.

### 3.3 Hybrid Chest radiograph Generation

We start with a larger dataset, i.e., ChestX-ray14, to pre-train Lung Swapping Auto Encoder by learning to generate hybrid Chest radiographs from swapped latent code.

------

**Experimental Settings.**

We train Lung Swapping Auto Encoder on the training set of ChestX-ray14 with a batch of 16 images for 150K iterations. 

To evaluate performance, we define a lung swapping task by creating two sets of 9,000 images, {I+} and {I−}, from the test set of ChestX-ray14. 

{I+} are sampled from the images diagnosed with at least one of the diseases: infiltration, pneumonia, and fibrosis, which are tightly related with COVID-19 [18]. In contrast, {I−} are sampled from healthy lungs.

We generate hybrid image sets by mixing texture and structure from {I+} and {I−} in both directions. 

We measure the distance of hybrid image set between both the target texture image set and the structure image set.

------

**Evaluation Protocol.**

First, we propose a new metric, Masked SIFID, to measure the disease level distance between Ihybrid and I2. 

Masked SIFID is based on the SIFID [17] which calculates the FID distance between two images in the Inception v3 feature space. 

To customize it to disease level distance, we only consider features within the lung region. 

Additionally, we use the ChestX-ray14 pre-trained Inception v3 (mAUC: 79.56%) to infer features. 

Second, to quantify structural distortion, we use lung segmentation metrics as surrogates. 

Given a lung segmentation model Seg, we can compute segmentation metrics by treating Seg(G(I1, I2)) as the query and Seg(I1) as the ground truth. 

Third, we solicit feedback from 5 radiologists through a 4-question survey. 

Please refer to the supplementary material for details. 

In the first two questions regarding image quality, radiologists misconstrue 56% of the generated images as real, and 74% of the hybrid image patches as real. 

The third question is to verify the correlation between Masked SIFID and disease level distance. 

When picking which of two query images is closer to the reference, 78.67% of the radiologists’ answers match with Masked SIFID. 

The fourth question is to ascertain whether our method can transfer disease correctly. 

When the radiologists were shown the original and the hybrid image with the same texture, 60% of the images passed the test.

------

**Results**

To get reference values, we first report initial results by directly comparing {I−} with {I+}. 

In Table 1 (left), Lung Swapping Auto Encoder achieves lower Masked SIFID when compared with Swapping Auto Encoder, which demonstrates that our design of in-lung texture supervision works as expected. 

Lung Swapping Auto Encoder also outperforms Swapping Auto Encoder by a large margin in the segmentation metrics, and achieves over 90% in all segmentation metrics, which proves out-of-lung patch contrastive loss can effectively suppress structural distortion. 

Please refer to the supplementary material for details

### 3.4 Semantic Prediction in Chest radiographs by Texture Encoder

Based on hypothesis that pulmonary diseases are tightly related to Chest radiograph texture, the texture encoder in a well-trained Lung Swapping Auto Encoder should be discriminative on Chest radiograph semantic tasks. 

To verify this hypothesis, we evaluate texture encoder, Enct, on both lung disease classification and COVID-19 outcome prediction tasks.

![image-20211125164415646](P16_image/image-20211125164415646.png)

**Table 1. Left** On the hybrid image generation task, Lung Swapping Auto Encoder surpasses Swapping Auto Encoder in both texture synthesis and structure maintenance. 

We report the average of two directions’ texture transfer. 

**Right**. For the 14 pulmonary diseases classification task on ChestXray14, the texture encoder in Lung Swapping Auto Encoder achieves competitive results with a smaller model size. 

∗Note that the data split in [16] is not released. 

We reimplemented CheXNet on the official split. 

The Inception v3 model is also self-implemented.

------

![image-20211125164438121](P16_image/image-20211125164438121.png)

**Table 2.** COVOC Outcome Prediction. We evaluate models with Balanced Error Rate (BER) and average AUC (mAUC). 

The texture encoder surpasses Inception v3 by a large margin. 

It also outperforms the texture encoder in a baseline model Swapping Auto Encoder, which demonstrates that better disentanglement does lead to better discrimination. 

We report mean and std of 5 random runs.

------

**Disease Classification on ChestX-ray14.**

We finetune Enct on the training set of ChestX-ray14 with 14 disease labels, and report mean AUC in Table 1(right). 

We achieve competitive results, despite having a smaller model size.

**Outcome Prediction on COVOC.**

Considering the possible domain discrepancy between ChestX-ray14 and COVOC, we first adapt Lung Swapping Auto Encoder to the new domain by training to generate hybrid images on COVOC for 10K iterations.

Then, we evaluate the texture encoder Enct on the outcome prediction task by further finetuning. 

As COVOC is imbalanced, we report the ventilation prediction Balanced Error Rate (BER) together with mAUC in Table 2. 

Compared with Inception v3, Enct reduces BER by 13.5%, and improves mAUC by 4.1%.

When comparing with the texture encoder in baseline model Swapping Auto Encoder, Lung Swapping Auto Encoder also performs better. 

It demonstrates that better disentanglement leads to better discrimination. 

We also report the prediction of mortality in Table 2 in SM.

### 3.5 Data Argmentation with Hybrid Images

As described in Sect. 2.3, we generate hybrid images to augment the training data in COVOC. 

To control the training budget, we set K = 2, i.e., the training data of COVOC is augmented 2 times. 

To avoid introducing irrelevant diseases, we only sample structure images from the healthy lungs in ChestX-ray14. 

With the same experimental setup with Table 2, the augmentation method can reduce error rate further from 16.50% to 15.67%, and improve mAUC from 90.41% to 92.04% on the ventilation prediction task. 

Moreover, we implement Mixup independently for training on COVOC which achieves 16.41% BER/90.82% mAUC.

Our method still shows superior performance.

## 4. Conclusion

We propose Lung Swapping Auto Encoder to disentangle texture from structure in Chest radiograph images, enabling analysis of disease-associated textural changes in COVID-19 and other pulmonary diseases. 

We also create a data augmentation technique which synthesizes images with structural and textural information from two Chest radiographs. 

This technique can be used to augment data for machine learning applications. 

Our resulting predictive model for mechanical ventilation in COVID-19 patients outperforms conventional methods and may have clinical significance in enabling improved decision making. 

We will apply our texture disentanglement and data augmentation methods to study other pulmonary diseases in the future.
