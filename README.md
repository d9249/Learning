# DIYA_2021_CV

### 2012

[**imageNet Classification with Deep Convolutional Neural Network**](https://www.notion.so/imageNet-Classification-with-Deep-Convolutional-Neural-Network-74b0fc38e9af4073b421d284b1f25f60)

### 2013

[**Network In Network**](https://www.notion.so/Network-In-Network-1204aa586bdc4e1eb091ccfa2516a959)

### 2014

[**Visualizing and Understanding Convolutional Networks**](https://www.notion.so/Visualizing-and-Understanding-Convolutional-Networks-00b895b0ca9c49e08cea3689980fbf48)

[**OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks**](https://www.notion.so/OverFeat-Integrated-Recognition-Localization-and-Detection-using-Convolutional-Networks-566b4eac9804469c9e36c5395a7383a2)

### 2015

[**Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition**](https://www.notion.so/Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition-4a8895352109462f92ebc1e86f6dba5d)

[**Very Deep Convolutional Networks for Large-Scale Image Recognition**](https://www.notion.so/Very-Deep-Convolutional-Networks-for-Large-Scale-Image-Recognition-1433b0fdc3ef40b9b2b33a2ee6bea891)

[**Going Deeper with Convolutions**](https://www.notion.so/Going-Deeper-with-Convolutions-d6e3064831d340b9a62a6d51c19f2cec)

[**Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification**](https://www.notion.so/Delving-Deep-into-Rectifiers-Surpassing-Human-Level-Performance-on-ImageNet-Classification-5dc0462fb81747db949bc724a5b8afd0)

[**Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift**](https://www.notion.so/Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift-df6613cbe9404f919af107c7d20a9f08)

[**Spatial Transformer Networks**](https://www.notion.so/Spatial-Transformer-Networks-839b6a12e69f4cc0ae5c9829c6f03d47)

### 2016

[**Rethinking the Inception Architecture for Computer Vision**](https://www.notion.so/Rethinking-the-Inception-Architecture-for-Computer-Vision-d7b2da742e55418e8856a6c29fc29deb)

[**Deep Residual Learning for Image Recognition**](https://www.notion.so/Deep-Residual-Learning-for-Image-Recognition-5ad0b39db4444e739d6f707707067093)

[**Learning Deep Features for Discriminative Localization**](https://www.notion.so/Learning-Deep-Features-for-Discriminative-Localization-a5acb9db59f043caabf498b4dc94c691)

[**SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size**](https://www.notion.so/SqueezeNet-AlexNet-level-accuracy-with-50x-fewer-parameters-and-0-5MB-model-size-2aa832275f6b44feac64bd11d3171fd1)

[**Identity Mappings in Deep Residual Networks**](https://www.notion.so/Identity-Mappings-in-Deep-Residual-Networks-599310352e994685968cc585f0cabd93)

[**Wide Residual Networks**](https://www.notion.so/Wide-Residual-Networks-c2dcbd8dcc2a432cb2613d5cc265428b)

### 2017

[**Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning**](https://www.notion.so/Inception-v4-Inception-ResNet-and-the-Impact-of-Residual-Connections-on-Learning-622c720280cf472592a981f392bd9c03)

[**Densely Connected Convolutional Networks**](https://www.notion.so/Densely-Connected-Convolutional-Networks-05e53d2598694bb99fff6d7e5cb4c9da)

[**Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization**](https://www.notion.so/Grad-CAM-Visual-Explanations-from-Deep-Networks-via-Gradient-based-Localization-433a6764a8814dc9a49a26bac7c755cc)

[**Deep Pyramidal Residual Networks**](https://www.notion.so/Deep-Pyramidal-Residual-Networks-a6001a1851d84292a528f6f18cb95001)

[**Xception: Deep Learning with Depthwise Separable Convolutions**](https://www.notion.so/Xception-Deep-Learning-with-Depthwise-Separable-Convolutions-5818af0061c044f3b88bd4f71d9e765c)

[**Aggregated Residual Transformations for Deep Neural Networks**](https://www.notion.so/Aggregated-Residual-Transformations-for-Deep-Neural-Networks-dbf9287a5edb440cb4b89944a9f54a66)

[**PolyNet: A Pursuit of Structural Diversity in Very Deep Networks**](https://www.notion.so/PolyNet-A-Pursuit-of-Structural-Diversity-in-Very-Deep-Networks-03dbcccd1ab74e51b0dfda93a0a3114a)

[**MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications**](https://www.notion.so/MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications-3622fa839f474e88ad20a1fd27800e32)

[**Dynamic Routing Between Capsules**](https://www.notion.so/Dynamic-Routing-Between-Capsules-02be72ea401c47f390c3eac814fc83a8)

### 2018

[**ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices**](https://www.notion.so/ShuffleNet-An-Extremely-Efficient-Convolutional-Neural-Network-for-Mobile-Devices-64406878d4a04caa8e6eeda56b83c69f)

[**Squeeze-and-Excitation Networks**](https://www.notion.so/Squeeze-and-Excitation-Networks-9a916233a6a945e68396ecdffca6a858)

[**Non-local Neural Networks**](https://www.notion.so/Non-local-Neural-Networks-99fa2a9d393646af90246a37c0d03f05)

[**MobileNetV2: Inverted Residuals and Linear Bottlenecks**](https://www.notion.so/MobileNetV2-Inverted-Residuals-and-Linear-Bottlenecks-9720a7607f024cb69eabb0ef54907164)

[**Exploring the Limits of Weakly Supervised Pretraining**](https://www.notion.so/Exploring-the-Limits-of-Weakly-Supervised-Pretraining-8aa9db8d23024a8c861930b783b27625)

[**How Does Batch Normalization Help Optimization?**](https://www.notion.so/How-Does-Batch-Normalization-Help-Optimization-e5ff18c092d94021832b192f350ab69a)

[**Understanding Batch Normalization**](https://www.notion.so/Understanding-Batch-Normalization-38516d2f1a024d4699f8a878b6e3a0a8)

[**ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design**](https://www.notion.so/ShuffleNet-V2-Practical-Guidelines-for-Efficient-CNN-Architecture-Design-4bb42454f3314d57ac227b72e631b3bd)

### ðŸ“†  Year

---

[2012](https://www.notion.so/2012-790d4938e5804bf99600049a2dc7ee09)

---

[2014](https://www.notion.so/2014-1cde4be137ea4691b457c4be7b062408)

[2014](https://www.notion.so/2014-a84ac5cd1ef84416a671aeeae0937e86)

[2014](https://www.notion.so/2014-8cdc6cf10eea4b6188a15e6058dc8306)

---

[2015](https://www.notion.so/2015-06b57e48475141249219d40a1af3bf02)

[2015](https://www.notion.so/2015-c43b85c58ece46ed87f1efaa91f64ac4)

[2015](https://www.notion.so/2015-ca508053630340a088e929631ad4a862)

[2015](https://www.notion.so/2015-4c5fe4b71b2341ce865d84ebcc0af645)

[2015](https://www.notion.so/2015-630f55ad1eb74e43a031dd1c197eb6ae)

[2015](https://www.notion.so/2015-09c27c48ecee4efd8fac6a1c97e52a18)

---

[2016](https://www.notion.so/2016-1883509d07214dada397ede030862f41)

[2016](https://www.notion.so/2016-5d538570c3e941f7aea5d035a9b9628e)

[2016](https://www.notion.so/2016-ef4bd9f4585e40e2a6af8723f36a3e7f)

[2016](https://www.notion.so/2016-f94cb60593b540c2ab145e0ff8c0796a)

[2016](https://www.notion.so/2016-a05b05722bd04620ba7daa96f6dc8f15)

[2016](https://www.notion.so/2016-bc139e632ed143ab904951b456dd9b32)

---

[2017](https://www.notion.so/2017-cd8caa859c2447baa573ae62de4374d1)

[2017](https://www.notion.so/2017-38f22c65e8dd4df0b0f5cda0c4478358)

[2017](https://www.notion.so/2017-bd9506a551de4b85b1d86afd602b22ca)

[2017](https://www.notion.so/2017-e8dc3620293f427eadc91d1265f9ab36)

[2017](https://www.notion.so/2017-07ba0c43b8e04dc692b6d8465baf1279)

[2017](https://www.notion.so/2017-73e7195893524fe8a70923a9684b43ce)

[2017](https://www.notion.so/2017-49b36784d54540f0ab9c0c7cabdb4cf5)

[2017](https://www.notion.so/2017-3a3510b39b8748cab257580ac9b669a4)

[2017](https://www.notion.so/2017-9f7f7fc7c2bd4e588c05921d9f24b5d7)

---

[2018](https://www.notion.so/2018-0c6dcfa4460e43d1ac2c320d40310059)

[2018](https://www.notion.so/2018-da4fb24e87c64038944e8cffdf5a8880)

[2018](https://www.notion.so/2018-329a7ee43e264e4083a8746d66a3e3e0)

[2018](https://www.notion.so/2018-b0a7dea9bd1e4fdd9fac5d08fc612c1a)

[2018](https://www.notion.so/2018-ed78c4d3d4de4c36967f6fcc4bbe11a5)

[2018](https://www.notion.so/2018-83efcc57413548c49397878a76d9d25b)

[2018](https://www.notion.so/2018-f1d95dec3a8444e1bdbb9331c09515d4)

[2018](https://www.notion.so/2018-e05ef750525e4b4c9b05f5547f2f5f89)

---

[2019](https://www.notion.so/2019-a851f3728b7d4f3eb2ed850dd654ed18)

[2019](https://www.notion.so/2019-c97317cf946a4ca59776d9e3bb494cb2)

[2019](https://www.notion.so/2019-3d6b7aa636ac475aa93a10d5b10a069c)

[2019](https://www.notion.so/2019-044db423c5854c9b8b11be9c8e7ceae7)

[2019](https://www.notion.so/2019-96f6c037a3794629a526344523ba416a)

[2019](https://www.notion.so/2019-ec10e4e6153f418fb070d72ca0403df2)

---

[2020](https://www.notion.so/2020-98ca5f38cc2248beb2e8617069707196)

[2020](https://www.notion.so/2020-41153233ee9c476e8ae341d8427f9957)

[2020](https://www.notion.so/2020-c42fa1d5b34a410397a2df5ae889adf9)

[2020](https://www.notion.so/2020-67b5f96835b048718c979725a17028f8)

---

[2021](https://www.notion.so/2021-e44f8cfddb64492183fabc649c781710)

[2021](https://www.notion.so/2021-9773e89394244c499afa6ed869d47c0c)

---

### ðŸ“®  Conference

---

[NIPS, Spotlight](https://www.notion.so/NIPS-Spotlight-2dbf6d4e61924d1b94fac34fcc997fe9)

---

[ICLR](https://www.notion.so/ICLR-f45d7cde5b15473fb3d803fb2b71c872)

[ECCV](https://www.notion.so/ECCV-d3e0763c3f354a7d9fcc3426f61cfedb)

[ICLR](https://www.notion.so/ICLR-a9cd101395584c629eb311b2f1a7209c)

---

[TPAMI](https://www.notion.so/TPAMI-1029765cdbcd46128eb86b0481ede25d)

[ICLR, Oral](https://www.notion.so/ICLR-Oral-368e5410362b410687fc6aca6342b57d)

[CVPR, Oral](https://www.notion.so/CVPR-Oral-bd5506bba0744716a0e41506a207a8d6)

[ICCV](https://www.notion.so/ICCV-18f874b5effa4d768512f27face62f6f)

[ICML](https://www.notion.so/ICML-a78fa7f7bdd94267848d5634de1e37f5)

[NIPS](https://www.notion.so/NIPS-ec86d5f5b3a147a2bc1bd162eb3f1008)

---

[CVPR](https://www.notion.so/CVPR-0ca314a157794aee97929184cd95e4ba)

[CVPR, Oral, Best Paper Award](https://www.notion.so/CVPR-Oral-Best-Paper-Award-fe8be881989643e88fd50eb1c3c99535)

[CVPR](https://www.notion.so/CVPR-8fffbac74d7a48cab0d73a362f6c4a4f)

[Arxiv](https://www.notion.so/Arxiv-f0c9bc6fa40a48869a1616cda28f83e0)

[ECCV, Spotlight](https://www.notion.so/ECCV-Spotlight-9b38fc564b8d483bb578c02e41f40a12)

[BMVC](https://www.notion.so/BMVC-66228c54381847e49679a395aab3824c)

---

[AAAI](https://www.notion.so/AAAI-9285d0b2e82e4e87b75adc26210f1408)

[CVPR, Oral, Best Paper Award](https://www.notion.so/CVPR-Oral-Best-Paper-Award-9f784cf82d2b443e94d6c02af4de5077)

[ICCV](https://www.notion.so/ICCV-06249934bff74d15b7286051c071e5d7)

[CVPR](https://www.notion.so/CVPR-983cca2608f34044a5ef992d17478465)

[CVPR](https://www.notion.so/CVPR-c2a2a9d6d2fa47a590898f2df15f5799)

[CVPR](https://www.notion.so/CVPR-9fa705e0a0ed4e21bad913852dc07554)

[CVPR](https://www.notion.so/CVPR-c98e312e2f224f889adc6ad0325a734c)

[CoRR](https://www.notion.so/CoRR-0acada831ca34dd1a83198c6982349cc)

[NIPS](https://www.notion.so/NIPS-f7bf126c619044f3ab9fb1dce56888e3)

---

[CVPR](https://www.notion.so/CVPR-36d25dbe145045c9af3a2787dc106dd4)

[CVPR, Oral](https://www.notion.so/CVPR-Oral-7214ddd82dfc43898ce5f434d6979e8f)

[CVPR](https://www.notion.so/CVPR-3b194d5502574b869ceb0b78b9b76117)

[CVPR](https://www.notion.so/CVPR-253475ac9ad5480bab0ad7b7c028097c)

[ECCV](https://www.notion.so/ECCV-d9278ac02a344427ade0279c7faffea2)

[NIPS, Oral](https://www.notion.so/NIPS-Oral-27f83afd531646908606b0b85bbe5667)

[NIPS](https://www.notion.so/NIPS-51249d006c4344f09c645e246903faa3)

[ECCV](https://www.notion.so/ECCV-577c5e22227b46839d78edbb43c4c60b)

---

[CVPR](https://www.notion.so/CVPR-78a77d002e2d49fe9c4e9ee6f317d0a2)

[ICCV, Oral](https://www.notion.so/ICCV-Oral-421cd5ac8b4e4cbb86bd7b39d3e76936)

[ICML, Oral](https://www.notion.so/ICML-Oral-9fd584e1ef5f480a91838c04980fced8)

[NIPS, Spotlight](https://www.notion.so/NIPS-Spotlight-98203d9aa6304e9998aa376095a4f691)

[NIPS](https://www.notion.so/NIPS-b8639a254dec42fab7b115aebf2f8f03)

[NIPS](https://www.notion.so/NIPS-b96fb3149afa441abc28ec7b63321479)

---

[CVPR](https://www.notion.so/CVPR-225325d9e5dc4a19b16de6714a902aad)

[CVPR](https://www.notion.so/CVPR-aae0dba9126b4056b5a5eefc58a0f64b)

[ECCV, Spotlight](https://www.notion.so/ECCV-Spotlight-fd770bddf82c4f3b8707a702c76bcc7b)

[Arxiv](https://www.notion.so/Arxiv-9cac93a8f37f41949262c8cab16ff155)

---

[ICLR, Spotlight](https://www.notion.so/ICLR-Spotlight-f1584c4d172b46f19172064cdb069c1c)

[ICLR, Oral](https://www.notion.so/ICLR-Oral-f42e65e8e2624efdab6c82a1944e8deb)

---

### ðŸ“•  Paper

---

[**imageNet Classification with Deep Convolutional Neural Network**](https://www.notion.so/imageNet-Classification-with-Deep-Convolutional-Neural-Network-74b0fc38e9af4073b421d284b1f25f60)

---

[**Network In Network**](https://www.notion.so/Network-In-Network-1204aa586bdc4e1eb091ccfa2516a959)

[**Visualizing and Understanding Convolutional Networks**](https://www.notion.so/Visualizing-and-Understanding-Convolutional-Networks-00b895b0ca9c49e08cea3689980fbf48)

[**OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks**](https://www.notion.so/OverFeat-Integrated-Recognition-Localization-and-Detection-using-Convolutional-Networks-566b4eac9804469c9e36c5395a7383a2)

---

[**Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition**](https://www.notion.so/Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition-4a8895352109462f92ebc1e86f6dba5d)

[**Very Deep Convolutional Networks for Large-Scale Image Recognition**](https://www.notion.so/Very-Deep-Convolutional-Networks-for-Large-Scale-Image-Recognition-1433b0fdc3ef40b9b2b33a2ee6bea891)

[**Going Deeper with Convolutions**](https://www.notion.so/Going-Deeper-with-Convolutions-d6e3064831d340b9a62a6d51c19f2cec)

[**Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification**](https://www.notion.so/Delving-Deep-into-Rectifiers-Surpassing-Human-Level-Performance-on-ImageNet-Classification-5dc0462fb81747db949bc724a5b8afd0)

[**Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift**](https://www.notion.so/Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift-df6613cbe9404f919af107c7d20a9f08)

[**Spatial Transformer Networks**](https://www.notion.so/Spatial-Transformer-Networks-839b6a12e69f4cc0ae5c9829c6f03d47)

---

[**Rethinking the Inception Architecture for Computer Vision**](https://www.notion.so/Rethinking-the-Inception-Architecture-for-Computer-Vision-d7b2da742e55418e8856a6c29fc29deb)

[**Deep Residual Learning for Image Recognition**](https://www.notion.so/Deep-Residual-Learning-for-Image-Recognition-5ad0b39db4444e739d6f707707067093)

[**Learning Deep Features for Discriminative Localization**](https://www.notion.so/Learning-Deep-Features-for-Discriminative-Localization-a5acb9db59f043caabf498b4dc94c691)

[**SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size**](https://www.notion.so/SqueezeNet-AlexNet-level-accuracy-with-50x-fewer-parameters-and-0-5MB-model-size-2aa832275f6b44feac64bd11d3171fd1)

[**Identity Mappings in Deep Residual Networks**](https://www.notion.so/Identity-Mappings-in-Deep-Residual-Networks-599310352e994685968cc585f0cabd93)

[**Wide Residual Networks**](https://www.notion.so/Wide-Residual-Networks-c2dcbd8dcc2a432cb2613d5cc265428b)

---

[**Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning**](https://www.notion.so/Inception-v4-Inception-ResNet-and-the-Impact-of-Residual-Connections-on-Learning-622c720280cf472592a981f392bd9c03)

[**Densely Connected Convolutional Networks**](https://www.notion.so/Densely-Connected-Convolutional-Networks-05e53d2598694bb99fff6d7e5cb4c9da)

[**Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization**](https://www.notion.so/Grad-CAM-Visual-Explanations-from-Deep-Networks-via-Gradient-based-Localization-433a6764a8814dc9a49a26bac7c755cc)

[**Deep Pyramidal Residual Networks**](https://www.notion.so/Deep-Pyramidal-Residual-Networks-a6001a1851d84292a528f6f18cb95001)

[**Xception: Deep Learning with Depthwise Separable Convolutions**](https://www.notion.so/Xception-Deep-Learning-with-Depthwise-Separable-Convolutions-5818af0061c044f3b88bd4f71d9e765c)

[**Aggregated Residual Transformations for Deep Neural Networks**](https://www.notion.so/Aggregated-Residual-Transformations-for-Deep-Neural-Networks-dbf9287a5edb440cb4b89944a9f54a66)

[**PolyNet: A Pursuit of Structural Diversity in Very Deep Networks**](https://www.notion.so/PolyNet-A-Pursuit-of-Structural-Diversity-in-Very-Deep-Networks-03dbcccd1ab74e51b0dfda93a0a3114a)

[**MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications**](https://www.notion.so/MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications-3622fa839f474e88ad20a1fd27800e32)

[**Dynamic Routing Between Capsules**](https://www.notion.so/Dynamic-Routing-Between-Capsules-02be72ea401c47f390c3eac814fc83a8)

---

[**ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices**](https://www.notion.so/ShuffleNet-An-Extremely-Efficient-Convolutional-Neural-Network-for-Mobile-Devices-64406878d4a04caa8e6eeda56b83c69f)

[**Squeeze-and-Excitation Networks**](https://www.notion.so/Squeeze-and-Excitation-Networks-9a916233a6a945e68396ecdffca6a858)

[**Non-local Neural Networks**](https://www.notion.so/Non-local-Neural-Networks-99fa2a9d393646af90246a37c0d03f05)

[**MobileNetV2: Inverted Residuals and Linear Bottlenecks**](https://www.notion.so/MobileNetV2-Inverted-Residuals-and-Linear-Bottlenecks-9720a7607f024cb69eabb0ef54907164)

[**Exploring the Limits of Weakly Supervised Pretraining**](https://www.notion.so/Exploring-the-Limits-of-Weakly-Supervised-Pretraining-8aa9db8d23024a8c861930b783b27625)

[**How Does Batch Normalization Help Optimization?**](https://www.notion.so/How-Does-Batch-Normalization-Help-Optimization-e5ff18c092d94021832b192f350ab69a)

[**Understanding Batch Normalization**](https://www.notion.so/Understanding-Batch-Normalization-38516d2f1a024d4699f8a878b6e3a0a8)

[**ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design**](https://www.notion.so/ShuffleNet-V2-Practical-Guidelines-for-Efficient-CNN-Architecture-Design-4bb42454f3314d57ac227b72e631b3bd)

---

[Bag of Tricks for Image Classification with Convolutional Neural Networks](https://www.notion.so/Bag-of-Tricks-for-Image-Classification-with-Convolutional-Neural-Networks-e81ae42863d5452a9e8d739c6d7f953b)

[Searching for MobileNetV3](https://www.notion.so/Searching-for-MobileNetV3-03b1798e240d44a98da0050305c34387)

[EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://www.notion.so/EfficientNet-Rethinking-Model-Scaling-for-Convolutional-Neural-Networks-dbad07b6dcc84f3480be869a7b186927)

[When Does Label Smoothing Help?](https://www.notion.so/When-Does-Label-Smoothing-Help-499c58240fc94fa3813804dcfed3e81a)

[Stand-Alone Self-Attention in Vision Models](https://www.notion.so/Stand-Alone-Self-Attention-in-Vision-Models-7943de8101644322b3a449bc7b8646ef)

[Fixing the train-test resolution discrepancy](https://www.notion.so/Fixing-the-train-test-resolution-discrepancy-c5361686c90544d7b30fdb79b62ebbcd)

---

[Self-training with Noisy Student improves ImageNet classification](https://www.notion.so/Self-training-with-Noisy-Student-improves-ImageNet-classification-8ae35f49144f46469c8ef67118d1db91)

[Adversarial Examples Improve Image Recognition](https://www.notion.so/Adversarial-Examples-Improve-Image-Recognition-bf802d61fead4686a36d562a680f9655)

[Big Transfer (BiT): General Visual Representation Learning](https://www.notion.so/Big-Transfer-BiT-General-Visual-Representation-Learning-d81a0b0bade141aa9ae6f06458a0d050)

[Fixing the train-test resolution discrepancy: FixEfficientNet](https://www.notion.so/Fixing-the-train-test-resolution-discrepancy-FixEfficientNet-1b752988a8254996a2bd4bc7fd3284fc)

---

[Sharpness-Aware Minimization for Efficiently Improving Generalization](https://www.notion.so/Sharpness-Aware-Minimization-for-Efficiently-Improving-Generalization-564eeafb95274c3ca309ee9e10b2d1a6)

[An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://www.notion.so/An-Image-is-Worth-16x16-Words-Transformers-for-Image-Recognition-at-Scale-3f65fe916c0b4d52a86adde2a94b48b4)

---

[Training data-efficient image transformers & distillation through attention](https://www.notion.so/Training-data-efficient-image-transformers-distillation-through-attention-f3311d82d37548d7a651a1ad991ea3d9)

[High-Performance Large-Scale Image Recognition Without Normalization](https://www.notion.so/High-Performance-Large-Scale-Image-Recognition-Without-Normalization-da5ec8784e804ca88da63c077b221193)

### ðŸ“†  Completion date

---

[2021. 04. 11](https://www.notion.so/2021-04-11-78f08c463f714ce8a41f1f3e252d6c92)

---

[Incomplete](https://www.notion.so/Incomplete-60dfc2f1a9364610a2d1f8906e2699b5)

[2021. 04. 11](https://www.notion.so/2021-04-11-d1aecbc338704340a216b80234412e35)

[Incomplete](https://www.notion.so/Incomplete-e06e892363f1456db9be7ddeb7b414be)

---

[Incomplete](https://www.notion.so/Incomplete-c25ef3d1ab7540e1aa1ed37a911f742b)

[Incomplete](https://www.notion.so/Incomplete-910980f6a6764e07a24bd3881d721f74)

[Incomplete](https://www.notion.so/Incomplete-775ee725389242c798e12901e5cd503c)

[Incomplete](https://www.notion.so/Incomplete-7a02fccd6f07464eadcab962cd4b585e)

[Incomplete](https://www.notion.so/Incomplete-634ac481151d436aa458126df1b8e1c0)

[Incomplete](https://www.notion.so/Incomplete-1da07a9fdccd4097a323ead3bd56c77b)

---

[Incomplete](https://www.notion.so/Incomplete-f1b93bef1c7341139c1de6a86ebf9822)

[Incomplete](https://www.notion.so/Incomplete-edd213d3a1734d628f69f7cb2c8dfdde)

[Incomplete](https://www.notion.so/Incomplete-39c3ee4a07294d34ab2f307330f05c48)

[Incomplete](https://www.notion.so/Incomplete-b2dd33d7418f4cbbb3b82a7e433cf6cb)

[Incomplete](https://www.notion.so/Incomplete-c119939944ce4c26920218cb81729780)

[Incomplete](https://www.notion.so/Incomplete-563039adc39a4d2bb33384d9e83a3303)

---

[Incomplete](https://www.notion.so/Incomplete-46d82faad4d640339b11cd3a72ae7d5f)

[Incomplete](https://www.notion.so/Incomplete-37a36f05be4844619b0d639a3bbf8989)

[Incomplete](https://www.notion.so/Incomplete-fb79137ddf4e42998153621f91b95a80)

[Incomplete](https://www.notion.so/Incomplete-9eefbfb65e1e4db697a83a188896016b)

[Incomplete](https://www.notion.so/Incomplete-65277cb034c5415ea35e6ca9a286e46c)

[Incomplete](https://www.notion.so/Incomplete-2fa47fcd153c42f49d499d251a8946a1)

[Incomplete](https://www.notion.so/Incomplete-8bbf774a73b442b691549d31de633293)

[Incomplete](https://www.notion.so/Incomplete-8584c362ef0541ee9e70d460e43ac6d6)

[Incomplete](https://www.notion.so/Incomplete-bfa402132d58457c9196f7c1a39b39f3)

---

[Incomplete](https://www.notion.so/Incomplete-4d60bf454ca54aebb70f49fada17278d)

[Incomplete](https://www.notion.so/Incomplete-c6ee9c8490314e889c84861bcee5cdda)

[Incomplete](https://www.notion.so/Incomplete-44f38bd96c6f4cb080c76aa5414a970d)

[Incomplete](https://www.notion.so/Incomplete-a1718fac3bc043f08b35b62705384e58)

[Incomplete](https://www.notion.so/Incomplete-6c5db3a336de45d8a406d82b8c30737c)

[Incomplete](https://www.notion.so/Incomplete-b9242a7a1a7b4eed9ed53f62adf63ec5)

[Incomplete](https://www.notion.so/Incomplete-7eb117c2a70f4e77a820844f5eaffe05)

[Incomplete](https://www.notion.so/Incomplete-4982bc14667145e59be2100977c81c51)

---

[Incomplete](https://www.notion.so/Incomplete-856e1a0652f84b028a528b1e92ae620f)

[Incomplete](https://www.notion.so/Incomplete-df111fbac30346e9bf32ce5c62600f48)

[Incomplete](https://www.notion.so/Incomplete-839e5c80d3ef4a5ba1a4f5b8b8cc9c87)

[Incomplete](https://www.notion.so/Incomplete-a2e8cd85df374befa987071147c0a07a)

[Incomplete](https://www.notion.so/Incomplete-6f427210fc6043259d10b228fb5732de)

[Incomplete](https://www.notion.so/Incomplete-615a9687a4694ca68172a39494cd784f)

---

[Incomplete](https://www.notion.so/Incomplete-27cf5fb83dab49a6b07eaead8d093408)

[Incomplete](https://www.notion.so/Incomplete-090b5c6e74f84237ba7922e49fe26221)

[Incomplete](https://www.notion.so/Incomplete-b612f9f673eb4d479962a2427afeab96)

[Incomplete](https://www.notion.so/Incomplete-01f9320d12fd424d8b129a55c0520971)

---

[Incomplete](https://www.notion.so/Incomplete-2e3d106ff1734ef48cd0a8f80752bd5a)

[Incomplete](https://www.notion.so/Incomplete-e3234694620f45a2888edc51d6abd70a)

---

[Incomplete](https://www.notion.so/Incomplete-9c9b94da67ab416c9f913f56df19a1ec)

[Incomplete](https://www.notion.so/Incomplete-7e9d6cfd2ca54e478ee8ec9765487d90)
