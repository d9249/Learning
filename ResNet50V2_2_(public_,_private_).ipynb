{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet50V2_2_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/ResNet50V2_2_(public_%2C_private_).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9379b1d4-3866-4a9e-b1bc-daab1ee4bace"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 26 09:44:35 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "866c4276-8b48-497a-8f88-ced0774ca606"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "model_save = 'ResNet50V2_2'\n",
        "Target_model = 'ResNet50V2_model'\n",
        "Target_predict = 'ResNet50V2_predict'\n",
        "Target_acc = 'ResNet50V2_acc'\n",
        "Target_val = 'ResNet50V2_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.ResNet50V2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1970d3-1fd8-4bad-af1c-a7f3e4f70c8d"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b79aa1ce-33fa-4f4c-edc6-63fa30079183"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 48s 103ms/step - loss: 1.9301 - accuracy: 0.3342 - val_loss: 11.1104 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 23s 97ms/step - loss: 1.2911 - accuracy: 0.5679 - val_loss: 3.3597 - val_accuracy: 0.3311\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.10135 to 0.33108, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 24s 99ms/step - loss: 1.0654 - accuracy: 0.6558 - val_loss: 1.5596 - val_accuracy: 0.5608\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.33108 to 0.56081, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 1.0144 - accuracy: 0.6611 - val_loss: 1.6196 - val_accuracy: 0.6081\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.56081 to 0.60811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.8106 - accuracy: 0.7395 - val_loss: 1.1260 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.60811 to 0.69595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.7764 - accuracy: 0.7437 - val_loss: 0.8720 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.69595 to 0.74324, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.7166 - accuracy: 0.7600 - val_loss: 0.8422 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.74324 to 0.76351, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.6495 - accuracy: 0.7916 - val_loss: 0.5185 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.76351 to 0.83108, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.5846 - accuracy: 0.8100 - val_loss: 0.7567 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.83108\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.5975 - accuracy: 0.8037 - val_loss: 1.0541 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.83108\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.5568 - accuracy: 0.8116 - val_loss: 0.6730 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.83108\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.5501 - accuracy: 0.8189 - val_loss: 0.8620 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.83108\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.5116 - accuracy: 0.8389 - val_loss: 0.5160 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.83108\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.4242 - accuracy: 0.8626 - val_loss: 0.5189 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.83108\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.4601 - accuracy: 0.8516 - val_loss: 2.3344 - val_accuracy: 0.4797\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.83108\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.4306 - accuracy: 0.8495 - val_loss: 0.6795 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.83108\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.4519 - accuracy: 0.8574 - val_loss: 0.7821 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.83108\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.3863 - accuracy: 0.8579 - val_loss: 0.4087 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.83108 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.3962 - accuracy: 0.8684 - val_loss: 0.5522 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.89189\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.3513 - accuracy: 0.8784 - val_loss: 0.7237 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.89189\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.3630 - accuracy: 0.8816 - val_loss: 0.4006 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.89189\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 24s 99ms/step - loss: 0.3258 - accuracy: 0.8884 - val_loss: 0.6755 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.89189\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.3101 - accuracy: 0.8942 - val_loss: 0.7926 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.89189\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.2934 - accuracy: 0.9089 - val_loss: 0.4051 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.89189\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.2918 - accuracy: 0.8984 - val_loss: 0.5637 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.89189\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.2920 - accuracy: 0.9032 - val_loss: 0.7113 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.89189\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.2526 - accuracy: 0.9163 - val_loss: 0.6962 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.89189\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.2568 - accuracy: 0.9126 - val_loss: 0.4909 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.89189\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.2263 - accuracy: 0.9184 - val_loss: 0.3657 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.89189\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.2308 - accuracy: 0.9253 - val_loss: 0.3333 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.89189\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.2076 - accuracy: 0.9321 - val_loss: 0.5972 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.89189\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.2041 - accuracy: 0.9321 - val_loss: 0.6666 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.89189\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1890 - accuracy: 0.9316 - val_loss: 0.8440 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.89189\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.2026 - accuracy: 0.9279 - val_loss: 0.7782 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.89189\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.2079 - accuracy: 0.9289 - val_loss: 0.6608 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.89189\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.2427 - accuracy: 0.9237 - val_loss: 19.8377 - val_accuracy: 0.0946\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.89189\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1932 - accuracy: 0.9311 - val_loss: 0.8177 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.89189\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.2395 - accuracy: 0.9258 - val_loss: 0.6103 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.89189\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1642 - accuracy: 0.9453 - val_loss: 0.6871 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.89189\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1772 - accuracy: 0.9389 - val_loss: 0.3482 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.89189 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1293 - accuracy: 0.9495 - val_loss: 0.3849 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.90541\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1621 - accuracy: 0.9432 - val_loss: 0.4186 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.90541\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1583 - accuracy: 0.9400 - val_loss: 0.4866 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.90541\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 24s 99ms/step - loss: 0.1490 - accuracy: 0.9511 - val_loss: 0.4443 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.90541\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1242 - accuracy: 0.9542 - val_loss: 0.6496 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.90541\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1511 - accuracy: 0.9495 - val_loss: 2.2215 - val_accuracy: 0.6486\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.90541\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1414 - accuracy: 0.9500 - val_loss: 0.4507 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.90541\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1536 - accuracy: 0.9479 - val_loss: 0.6637 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.90541\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1277 - accuracy: 0.9547 - val_loss: 0.4496 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.90541\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1434 - accuracy: 0.9511 - val_loss: 0.5851 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.90541\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1486 - accuracy: 0.9542 - val_loss: 0.3790 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.90541\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1063 - accuracy: 0.9621 - val_loss: 0.4167 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.90541\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1065 - accuracy: 0.9632 - val_loss: 0.3272 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0883 - accuracy: 0.9658 - val_loss: 0.3787 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91216\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0702 - accuracy: 0.9716 - val_loss: 0.5228 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91216\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 24s 99ms/step - loss: 0.1149 - accuracy: 0.9621 - val_loss: 0.5794 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91216\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1228 - accuracy: 0.9600 - val_loss: 0.5848 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91216\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1423 - accuracy: 0.9547 - val_loss: 0.6122 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91216\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1092 - accuracy: 0.9584 - val_loss: 0.5377 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91216\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1200 - accuracy: 0.9600 - val_loss: 0.4522 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91216\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0931 - accuracy: 0.9679 - val_loss: 0.4968 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91216\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0978 - accuracy: 0.9684 - val_loss: 0.4901 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91216\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0610 - accuracy: 0.9789 - val_loss: 0.5304 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91216\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1009 - accuracy: 0.9663 - val_loss: 0.4937 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91216\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1026 - accuracy: 0.9637 - val_loss: 0.6393 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91216\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1021 - accuracy: 0.9642 - val_loss: 0.4661 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91216\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0805 - accuracy: 0.9721 - val_loss: 0.4753 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91216\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0647 - accuracy: 0.9758 - val_loss: 0.5314 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91216\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0870 - accuracy: 0.9711 - val_loss: 2.2211 - val_accuracy: 0.6014\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91216\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0907 - accuracy: 0.9689 - val_loss: 0.4594 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91216\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0745 - accuracy: 0.9742 - val_loss: 0.3008 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91216\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0431 - accuracy: 0.9863 - val_loss: 0.6749 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91216\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0563 - accuracy: 0.9805 - val_loss: 6.2431 - val_accuracy: 0.4459\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91216\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.1210 - accuracy: 0.9574 - val_loss: 0.6492 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91216\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0724 - accuracy: 0.9763 - val_loss: 0.3474 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91216\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0885 - accuracy: 0.9658 - val_loss: 0.3880 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91216\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0630 - accuracy: 0.9800 - val_loss: 0.4791 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91216\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 0.5108 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91216\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0510 - accuracy: 0.9821 - val_loss: 0.5323 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91216\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0700 - accuracy: 0.9747 - val_loss: 0.4582 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91216\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0414 - accuracy: 0.9879 - val_loss: 0.4716 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91216\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0541 - accuracy: 0.9800 - val_loss: 0.4987 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91216\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0986 - accuracy: 0.9679 - val_loss: 0.5440 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91216\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0647 - accuracy: 0.9789 - val_loss: 0.5110 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91216\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0741 - accuracy: 0.9774 - val_loss: 0.3536 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00085: val_accuracy improved from 0.91216 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0360 - accuracy: 0.9879 - val_loss: 0.5408 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91892\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0444 - accuracy: 0.9847 - val_loss: 0.4347 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91892\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0526 - accuracy: 0.9805 - val_loss: 0.5059 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91892\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0563 - accuracy: 0.9811 - val_loss: 0.7926 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91892\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0835 - accuracy: 0.9732 - val_loss: 0.4141 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91892\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0761 - accuracy: 0.9747 - val_loss: 0.5021 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91892\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.8571 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91892\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0414 - accuracy: 0.9842 - val_loss: 0.8317 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91892\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0352 - accuracy: 0.9868 - val_loss: 0.3017 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91892\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0462 - accuracy: 0.9821 - val_loss: 0.5034 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91892\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0554 - accuracy: 0.9816 - val_loss: 0.4587 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91892\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0544 - accuracy: 0.9821 - val_loss: 0.3465 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91892\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0301 - accuracy: 0.9916 - val_loss: 0.6108 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91892\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0539 - accuracy: 0.9826 - val_loss: 1.1385 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91892\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0816 - accuracy: 0.9747 - val_loss: 0.6895 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91892\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0525 - accuracy: 0.9821 - val_loss: 0.4628 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91892\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0352 - accuracy: 0.9911 - val_loss: 0.4810 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.91892\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.6246 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.91892\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0473 - accuracy: 0.9868 - val_loss: 0.6102 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.91892\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0911 - accuracy: 0.9705 - val_loss: 0.5977 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91892\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0762 - accuracy: 0.9774 - val_loss: 0.6750 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91892\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0294 - accuracy: 0.9900 - val_loss: 0.3853 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91892\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0440 - accuracy: 0.9868 - val_loss: 0.5057 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91892\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.4432 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91892\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0529 - accuracy: 0.9821 - val_loss: 0.5591 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91892\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.5843 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91892\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0292 - accuracy: 0.9895 - val_loss: 0.4103 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91892\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0467 - accuracy: 0.9826 - val_loss: 0.7994 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91892\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0349 - accuracy: 0.9879 - val_loss: 0.6147 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91892\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.5643 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91892\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.7079 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91892\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0360 - accuracy: 0.9889 - val_loss: 0.5482 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91892\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0846 - accuracy: 0.9732 - val_loss: 0.7369 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91892\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0445 - accuracy: 0.9842 - val_loss: 0.7371 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91892\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0263 - accuracy: 0.9926 - val_loss: 8.4635 - val_accuracy: 0.3851\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91892\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0765 - accuracy: 0.9789 - val_loss: 0.4941 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91892\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.7590 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91892\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.4909 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91892\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0313 - accuracy: 0.9916 - val_loss: 0.4951 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91892\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0391 - accuracy: 0.9868 - val_loss: 0.5604 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91892\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.5954 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91892\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.5221 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91892\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.5659 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91892\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.4258 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91892\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0819 - accuracy: 0.9742 - val_loss: 0.4346 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91892\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0482 - accuracy: 0.9842 - val_loss: 0.2600 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91892\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0411 - accuracy: 0.9863 - val_loss: 0.8209 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91892\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0576 - accuracy: 0.9811 - val_loss: 0.6156 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91892\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0384 - accuracy: 0.9847 - val_loss: 0.6594 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91892\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.6234 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91892\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.6494 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91892\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0193 - accuracy: 0.9926 - val_loss: 0.4753 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91892\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0418 - accuracy: 0.9842 - val_loss: 0.5818 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91892\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 0.5728 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91892\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0199 - accuracy: 0.9958 - val_loss: 0.5606 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91892\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.5347 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.91892\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0271 - accuracy: 0.9900 - val_loss: 0.5442 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.91892\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0307 - accuracy: 0.9895 - val_loss: 0.4474 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.91892\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0205 - accuracy: 0.9916 - val_loss: 0.6408 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.91892\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0300 - accuracy: 0.9889 - val_loss: 0.5706 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.91892\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0438 - accuracy: 0.9879 - val_loss: 0.5684 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.91892\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0337 - accuracy: 0.9911 - val_loss: 0.5816 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.91892\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 0.4399 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.91892\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0370 - accuracy: 0.9911 - val_loss: 0.5614 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.91892\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0379 - accuracy: 0.9879 - val_loss: 0.4572 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.91892\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0299 - accuracy: 0.9916 - val_loss: 0.3749 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.91892\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 0.4014 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.91892\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.4871 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.91892\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0243 - accuracy: 0.9942 - val_loss: 0.4994 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.91892\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0436 - accuracy: 0.9853 - val_loss: 0.5052 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.91892\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0171 - accuracy: 0.9958 - val_loss: 0.6232 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.91892\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.5495 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.91892\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.6102 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.91892\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.3562 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00159: val_accuracy improved from 0.91892 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.5793 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92568\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.5420 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92568\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0434 - accuracy: 0.9832 - val_loss: 0.6577 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92568\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.5699 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92568\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0279 - accuracy: 0.9889 - val_loss: 0.6540 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92568\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0205 - accuracy: 0.9926 - val_loss: 0.4955 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92568\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.4606 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92568\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.6536 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92568\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.6178 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92568\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.3912 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92568\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.5650 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92568\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.3610 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92568\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.5341 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92568\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0140 - accuracy: 0.9974 - val_loss: 0.4279 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92568\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 0.8011 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92568\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0422 - accuracy: 0.9884 - val_loss: 0.5408 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92568\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.4193 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92568\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0170 - accuracy: 0.9926 - val_loss: 0.4010 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92568\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0233 - accuracy: 0.9932 - val_loss: 0.5138 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92568\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 24s 100ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 0.5648 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92568\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0295 - accuracy: 0.9916 - val_loss: 0.5357 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92568\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0302 - accuracy: 0.9900 - val_loss: 0.5781 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92568\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.4984 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92568\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.7393 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92568\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.5124 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92568\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0280 - accuracy: 0.9889 - val_loss: 0.6401 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92568\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 0.5878 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92568\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0148 - accuracy: 0.9932 - val_loss: 0.5775 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92568\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 0.4970 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92568\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.4020 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92568\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0326 - accuracy: 0.9874 - val_loss: 0.5397 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92568\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0292 - accuracy: 0.9916 - val_loss: 0.4560 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92568\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.5376 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92568\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.3329 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92568\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.5068 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92568\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.3872 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92568\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.4552 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92568\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0299 - accuracy: 0.9921 - val_loss: 0.6459 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92568\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0359 - accuracy: 0.9889 - val_loss: 0.5646 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92568\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0204 - accuracy: 0.9916 - val_loss: 0.5325 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92568\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.5447 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92568\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.5473 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92568\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.5525 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92568\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.5597 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92568\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0079 - accuracy: 0.9968 - val_loss: 0.6835 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92568\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.5724 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92568\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0590 - accuracy: 0.9868 - val_loss: 1.1910 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92568\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0271 - accuracy: 0.9932 - val_loss: 0.3345 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92568\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.3441 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00208: val_accuracy improved from 0.92568 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.3086 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93243\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.4492 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93243\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0396 - accuracy: 0.9905 - val_loss: 0.6970 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93243\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.4296 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93243\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.4033 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93243\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.4404 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93243\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.4235 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00215: val_accuracy improved from 0.93243 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.4938 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93919\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.7318 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93919\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.3973 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93919\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.4387 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93919\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.6128 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93919\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0272 - accuracy: 0.9889 - val_loss: 0.5260 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93919\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.4891 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93919\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.4677 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93919\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.6490 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93919\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0259 - accuracy: 0.9926 - val_loss: 0.6245 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93919\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.3653 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93919\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0498 - accuracy: 0.9863 - val_loss: 0.5912 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93919\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.5622 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93919\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.4679 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93919\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 0.5255 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93919\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.4754 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93919\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.4199 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93919\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.4697 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93919\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0345 - accuracy: 0.9900 - val_loss: 0.9001 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93919\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.4005 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93919\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.5543 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93919\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 0.4418 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93919\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.3723 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93919\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.4452 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93919\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0111 - accuracy: 0.9953 - val_loss: 0.4673 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93919\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.5384 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93919\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0285 - accuracy: 0.9926 - val_loss: 0.6769 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93919\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.3637 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93919\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.4916 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93919\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.5016 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93919\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.3183 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93919\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0091 - accuracy: 0.9958 - val_loss: 0.4200 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93919\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0167 - accuracy: 0.9937 - val_loss: 0.4463 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93919\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.4994 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93919\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.6858 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93919\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.5759 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93919\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0138 - accuracy: 0.9947 - val_loss: 0.4351 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93919\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.5413 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93919\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.4219 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93919\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.4853 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93919\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0171 - accuracy: 0.9937 - val_loss: 0.4757 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93919\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0506 - accuracy: 0.9868 - val_loss: 0.9491 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93919\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 0.5262 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93919\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.5697 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93919\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 0.4629 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93919\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.4773 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93919\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.3050 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93919\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.4863 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93919\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0193 - accuracy: 0.9932 - val_loss: 0.6326 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93919\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.6720 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93919\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.7756 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93919\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 0.7280 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93919\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.8010 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93919\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0223 - accuracy: 0.9953 - val_loss: 0.6682 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93919\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0249 - accuracy: 0.9937 - val_loss: 0.5623 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93919\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0128 - accuracy: 0.9947 - val_loss: 0.5184 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93919\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0190 - accuracy: 0.9926 - val_loss: 0.6205 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93919\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.5606 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93919\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93919\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93919\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.3793 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93919\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.5228 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93919\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.4310 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93919\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4015 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93919\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.4157 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93919\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0193 - accuracy: 0.9926 - val_loss: 0.3911 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93919\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0294 - accuracy: 0.9911 - val_loss: 0.7795 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93919\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.7014 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93919\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.5476 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93919\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.4604 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93919\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.5400 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93919\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.4881 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93919\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5507 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93919\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.5620 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93919\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.7941 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93919\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0245 - accuracy: 0.9942 - val_loss: 0.7057 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93919\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.6701 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93919\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.5193 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93919\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.4810 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93919\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4703 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93919\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.4528 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93919\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.6058 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93919\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.4614 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93919\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.5525 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93919\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.6134 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93919\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.5268 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93919\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.4082 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93919\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.4698 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93919\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.3877 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93919\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.5242 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93919\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.4384 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93919\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.4599 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93919\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.3672 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93919\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.3808 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93919\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.4008 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93919\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.4017 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93919\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0393 - accuracy: 0.9900 - val_loss: 0.5489 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93919\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.4266 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93919\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.5249 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93919\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.5344 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93919\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.5074 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93919\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.6765 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93919\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 0.6337 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93919\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.6267 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93919\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 0.6843 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93919\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.5529 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93919\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.4778 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93919\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.5023 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93919\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0275 - accuracy: 0.9895 - val_loss: 1.1928 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93919\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.3839 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93919\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.4753 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93919\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0104 - accuracy: 0.9953 - val_loss: 0.5536 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93919\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0174 - accuracy: 0.9932 - val_loss: 0.4817 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93919\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0089 - accuracy: 0.9984 - val_loss: 0.5174 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93919\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0097 - accuracy: 0.9953 - val_loss: 0.6795 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93919\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0084 - accuracy: 0.9984 - val_loss: 0.6390 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93919\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.6327 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93919\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.7153 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93919\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0090 - accuracy: 0.9958 - val_loss: 0.5802 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93919\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.0154 - accuracy: 0.9968 - val_loss: 0.7050 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93919\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.7006 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93919\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.6858 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93919\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.4014 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93919\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0257 - accuracy: 0.9911 - val_loss: 0.6835 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93919\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0175 - accuracy: 0.9953 - val_loss: 0.5154 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93919\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0130 - accuracy: 0.9947 - val_loss: 0.4146 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93919\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.9332 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93919\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.6134 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93919\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.4005 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93919\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 9.6973e-04 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93919\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.4635 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93919\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3625 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00347: val_accuracy improved from 0.93919 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0048 - accuracy: 0.9968 - val_loss: 0.4673 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.94595\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.5512 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.94595\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.4598 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.94595\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.5660 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.94595\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.3987 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.94595\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.6115 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.94595\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 9.2316e-04 - accuracy: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.94595\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 8.5330e-04 - accuracy: 1.0000 - val_loss: 0.3809 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.94595\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.5153 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.94595\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5330 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.94595\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 4.4414e-04 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.94595\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0429 - accuracy: 0.9911 - val_loss: 0.7657 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.94595\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0371 - accuracy: 0.9879 - val_loss: 0.9145 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.94595\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0190 - accuracy: 0.9958 - val_loss: 0.4785 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.94595\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.4417 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.94595\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.5550 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.94595\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.4265 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.94595\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.8785 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.94595\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0093 - accuracy: 0.9947 - val_loss: 0.3813 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.94595\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.4037 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.94595\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.94595\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.4354 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.94595\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.6033 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.94595\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 0.6124 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.94595\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.0095 - accuracy: 0.9958 - val_loss: 0.5791 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.94595\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.5431 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.94595\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.8219 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.94595\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 1.1549 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.94595\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0199 - accuracy: 0.9911 - val_loss: 0.5675 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.94595\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5111 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.94595\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 0.4804 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.94595\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 0.5609 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.94595\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.9210 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.94595\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0245 - accuracy: 0.9947 - val_loss: 0.7364 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.94595\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0091 - accuracy: 0.9958 - val_loss: 0.6825 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.94595\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.4608 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.94595\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 6.2807e-04 - accuracy: 1.0000 - val_loss: 0.3643 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.94595\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 4.0080e-04 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.94595\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0027 - accuracy: 0.9979 - val_loss: 0.5446 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94595\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.5313 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94595\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.6174 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94595\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.5799 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94595\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.8957 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94595\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0284 - accuracy: 0.9937 - val_loss: 0.6758 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94595\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.4763 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94595\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.7049 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94595\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0260 - accuracy: 0.9937 - val_loss: 0.5207 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94595\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0070 - accuracy: 0.9963 - val_loss: 0.6866 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94595\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.5166 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94595\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.4804 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94595\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.3181 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94595\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.4669 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.94595\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.5813 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94595\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 7.6457e-04 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94595\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 4.2955e-04 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94595\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 1.3653e-04 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94595\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 1.9824e-04 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94595\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 2.3194e-04 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94595\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.7808 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94595\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0383 - accuracy: 0.9879 - val_loss: 0.6108 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94595\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.3913 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94595\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.4376 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94595\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.6014 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94595\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.4515 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94595\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 7.0372e-04 - accuracy: 1.0000 - val_loss: 0.5427 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94595\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.3545 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94595\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.4993 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94595\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.4417 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94595\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0036 - accuracy: 0.9979 - val_loss: 0.3540 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94595\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94595\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 7.4016e-04 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94595\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4304 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94595\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 6.2305e-04 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94595\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 2.5336e-04 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94595\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.5053 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94595\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0496 - accuracy: 0.9905 - val_loss: 0.6983 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94595\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0284 - accuracy: 0.9942 - val_loss: 0.3441 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94595\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0128 - accuracy: 0.9947 - val_loss: 0.4921 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94595\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0049 - accuracy: 0.9974 - val_loss: 0.3819 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94595\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.5579 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94595\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.5333 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94595\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.5381 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94595\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.5143 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94595\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.5244 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94595\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.6043 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94595\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.6902 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94595\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0263 - accuracy: 0.9889 - val_loss: 0.5312 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94595\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.4854 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94595\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0076 - accuracy: 0.9963 - val_loss: 0.3100 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94595\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94595\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.5607 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94595\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.5264 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94595\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 6.2823e-04 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94595\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4531 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94595\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.3921 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94595\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.3682 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94595\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.5738 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94595\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.7595 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94595\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.3424 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94595\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0179 - accuracy: 0.9932 - val_loss: 0.8153 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94595\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.5291 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94595\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.3895 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94595\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.4909 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94595\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.4906 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94595\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.5211 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94595\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94595\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 8.4066e-04 - accuracy: 1.0000 - val_loss: 0.3737 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00454: val_accuracy improved from 0.94595 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet50V2_2.h5\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.4786 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95270\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0103 - accuracy: 0.9947 - val_loss: 0.6171 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95270\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.4985 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95270\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0100 - accuracy: 0.9953 - val_loss: 0.5467 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95270\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.6589 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95270\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.5864 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95270\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.5279 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95270\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.4240 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95270\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.4501 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95270\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.7857 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95270\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.6414 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95270\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0051 - accuracy: 0.9974 - val_loss: 0.3697 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95270\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 0.5441 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95270\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.5422 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95270\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.4884 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95270\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.4438 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95270\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.4284 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95270\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95270\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.5175 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95270\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.5231 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95270\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.3975 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95270\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5781 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95270\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.5842 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95270\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 8.9808e-04 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95270\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 8.6894e-04 - accuracy: 1.0000 - val_loss: 0.5224 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95270\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 6.6025e-04 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95270\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 8.6194e-04 - accuracy: 0.9995 - val_loss: 0.5670 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95270\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0295 - accuracy: 0.9916 - val_loss: 0.6839 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95270\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 0.5472 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95270\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.5645 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95270\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.5984 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95270\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0161 - accuracy: 0.9937 - val_loss: 0.5335 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95270\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.4368 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95270\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.4897 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95270\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.4411 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95270\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.4220 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95270\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.3725 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95270\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 3.6928e-04 - accuracy: 1.0000 - val_loss: 0.4827 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95270\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.6899 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95270\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.5901 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95270\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.6817 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95270\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.6045 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95270\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.6713 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95270\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.4492 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95270\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.4033 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95270\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 4.6932e-04 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6068586150>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d666be05-63e6-4a9c-82d0-0e16441bdf13"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef5bad1-f5c0-44d1-b3b8-36aaf058869d"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZ06MWjdN2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5581ce50-8951-4c20-cb91-c6a09f699794"
      },
      "source": [
        "!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: dacon-submit-api\n",
            "Successfully installed dacon-submit-api-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKDp3mdOZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f3ee89-d96d-46dc-93d7-eeb4981255c6"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    # \n",
        "    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n",
        "    # d9249@kyonggi.ac.kr\n",
        "    # 'c2ecc8b05a9867f71ebb86f632ae73326696cb7f6e21be07ab43a7b400ef1f11',\n",
        "    # dodo9249@gmail.com\n",
        "    'abc9927563b1882b2480ac943a313a002631fb00c5a0daea43b12720ed34114e',\n",
        "    # d9249.acc001@gmail.com\n",
        "    # 'b27d6929e0eedade68e6a882d4006ec463f061c75a81aa27561c2c606dde8ad7',\n",
        "    #  ID\n",
        "    '235626',\n",
        "    # d9249@kyonggi.ac.kr \n",
        "    # 'iDeal9',\n",
        "    # dodo9249@gmail.com \n",
        "    'iDeal96',\n",
        "    # d9249.acc001@gmail.com\n",
        "    # 'iDeal01',\n",
        "    # memo\n",
        "    'd9249_kyonggi_ac_kr' )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'isSubmitted': True, 'detail': 'Success'}\n"
          ]
        }
      ]
    }
  ]
}