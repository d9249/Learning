{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18af0544",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/d9249/MDL/blob/main/KLGrade_DenseNet121-91.83.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b90db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18405285743504429305\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22727688192\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10198676264927950832\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ts26D3gLnyLd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ts26D3gLnyLd",
    "outputId": "f4f6fa8d-223f-4028-b18f-b8da4113b6d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov  6 05:25:13 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 461.72       Driver Version: 461.72       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3090   WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   35C    P2    41W / 350W |    599MiB / 24576MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      4856      C   ...gkim\\anaconda3\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-picnic",
   "metadata": {
    "id": "decreased-picnic",
    "papermill": {
     "duration": 0.028073,
     "end_time": "2021-05-30T18:39:27.966668",
     "exception": false,
     "start_time": "2021-05-30T18:39:27.938595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Short description\n",
    "This notebook is a part of [Data Sprint #35: Osteoarthritis Knee X-ray](https://dphi.tech/challenges/data-sprint-35-osteoarthritis-knee-x-ray/81/leaderboard/datathon/) challenge hosted on [dphi.tech](https://dphi.tech/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-monaco",
   "metadata": {
    "id": "million-monaco",
    "papermill": {
     "duration": 0.026241,
     "end_time": "2021-05-30T18:39:28.019714",
     "exception": false,
     "start_time": "2021-05-30T18:39:27.993473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing dependencies\n",
    "\n",
    "## 종속성을 가져오는 중 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "floating-cincinnati",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:28.086573Z",
     "iopub.status.busy": "2021-05-30T18:39:28.085923Z",
     "iopub.status.idle": "2021-05-30T18:39:32.847126Z",
     "shell.execute_reply": "2021-05-30T18:39:32.846068Z",
     "shell.execute_reply.started": "2021-05-30T09:28:36.967323Z"
    },
    "id": "floating-cincinnati",
    "papermill": {
     "duration": 4.80129,
     "end_time": "2021-05-30T18:39:32.847355",
     "exception": false,
     "start_time": "2021-05-30T18:39:28.046065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-discipline",
   "metadata": {
    "id": "express-discipline",
    "papermill": {
     "duration": 0.026573,
     "end_time": "2021-05-30T18:39:32.900510",
     "exception": false,
     "start_time": "2021-05-30T18:39:32.873937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Basic Idea\n",
    "The Basic idea is to use external data present in kaggle here: [Kaggle: Knee Osteoarthritis Dataset with KL Grading - 2018](https://www.kaggle.com/tommyngx/kneeoa)\n",
    "\n",
    "As we have labels for train, validation and test, we will combine all splits into one and test it on dataset provided by the compitition team, this will make sure kaggle dataset and compitition dataset has same data distribution.\n",
    "\n",
    "If train(kaggle dataset) and test (compition dataset) data has same distribution then their metric score should be roughy be the same (accuracy score in our case).\n",
    "\n",
    "# 기본 아이디어\n",
    "기본 아이디어는 여기 카글에 있는 외부 데이터를 사용하는 것이다. [Kaggle: KL Grading이 있는 무릎 골관절염 데이터 세트 - 2018](https://www.kaggle.com/tommyngx/kneeoa)\n",
    "\n",
    "교육, 검증 및 테스트를 위한 레이블이 있으므로 모든 분할을 하나로 결합하고 구성 팀에서 제공하는 데이터 세트에서 테스트합니다. 이렇게 하면 Kaggle 데이터 세트와 구성 데이터 세트가 동일한 데이터 분포를 갖출 수 있습니다.\n",
    "\n",
    "열차(카글 데이터 세트)와 테스트(컴포지션 데이터 세트) 데이터의 분포가 동일하면 메트릭 점수가 대략 같아야 한다(우리의 경우 정확도 점수)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-prague",
   "metadata": {
    "id": "rotary-prague",
    "papermill": {
     "duration": 0.025647,
     "end_time": "2021-05-30T18:39:32.952047",
     "exception": false,
     "start_time": "2021-05-30T18:39:32.926400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read And Combining train dataset (kaggle dataset)\n",
    "\n",
    "# 열차 데이터 세트 읽기 및 결합 (Kaggle 데이터 세트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "emotional-valuable",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:33.012157Z",
     "iopub.status.busy": "2021-05-30T18:39:33.011596Z",
     "iopub.status.idle": "2021-05-30T18:39:35.556063Z",
     "shell.execute_reply": "2021-05-30T18:39:35.555555Z",
     "shell.execute_reply.started": "2021-05-30T09:28:38.947982Z"
    },
    "id": "emotional-valuable",
    "papermill": {
     "duration": 2.57776,
     "end_time": "2021-05-30T18:39:35.556225",
     "exception": false,
     "start_time": "2021-05-30T18:39:32.978465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of class\n",
    "n_class = 5\n",
    "\n",
    "# path to kaggle dataset\n",
    "root_path = \"C:\\\\Users\\\\ngkim\\\\Downloads\\\\ClsKLData\\\\kneeKL224\\\\\"\n",
    "\n",
    "# list of folders\n",
    "folder_list = os.listdir(root_path)\n",
    "image_path_list = []\n",
    "label_list = []\n",
    "\n",
    "# for each folder, get the image path and labels\n",
    "for folder in folder_list:\n",
    "    for label in range(n_class):\n",
    "        \n",
    "        # get all the images path inside the current folder\n",
    "        image_list = os.listdir(f\"{root_path}{folder}/{label}\")\n",
    "        # add to the image path list\n",
    "        image_path_list += [ f\"{root_path}{folder}/{label}/\"+ path for path in image_list]\n",
    "        \n",
    "        # add labels to the label list\n",
    "        label_list += [label] * len(image_list)\n",
    "\n",
    "# convert to dataframe\n",
    "df_train_kaggle = pd.DataFrame({\"filepath\" : image_path_list, \"label\": label_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "signal-responsibility",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:35.618734Z",
     "iopub.status.busy": "2021-05-30T18:39:35.617931Z",
     "iopub.status.idle": "2021-05-30T18:39:35.621117Z",
     "shell.execute_reply": "2021-05-30T18:39:35.621576Z",
     "shell.execute_reply.started": "2021-05-30T09:28:40.244589Z"
    },
    "id": "signal-responsibility",
    "outputId": "9be7a788-1c7a-498d-a3e9-7b2c5e8455ab",
    "papermill": {
     "duration": 0.03629,
     "end_time": "2021-05-30T18:39:35.621716",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.585426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9786, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_kaggle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-greene",
   "metadata": {
    "id": "hairy-greene",
    "papermill": {
     "duration": 0.030406,
     "end_time": "2021-05-30T18:39:35.680660",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.650254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Observation\n",
    "we have total of 9786 images in kaggle dataset. We will use data to train the deep learning model\n",
    "# Lets look at class distribution\n",
    "\n",
    "## 관찰\n",
    "우리는 카글 데이터 세트에 총 9786개의 이미지를 가지고 있다. 우리는 딥 러닝 모델을 훈련시키기 위해 데이터를 사용할 것이다.\n",
    "# 학급분포를 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "therapeutic-spending",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:35.750000Z",
     "iopub.status.busy": "2021-05-30T18:39:35.749277Z",
     "iopub.status.idle": "2021-05-30T18:39:35.918362Z",
     "shell.execute_reply": "2021-05-30T18:39:35.918766Z",
     "shell.execute_reply.started": "2021-05-30T09:28:41.597346Z"
    },
    "id": "therapeutic-spending",
    "outputId": "0e179822-cb9f-4a56-b0c3-1f99705e882b",
    "papermill": {
     "duration": 0.208649,
     "end_time": "2021-05-30T18:39:35.918905",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.710256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_kaggle.label.value_counts().plot.bar()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-calendar",
   "metadata": {
    "id": "cognitive-calendar",
    "papermill": {
     "duration": 0.027966,
     "end_time": "2021-05-30T18:39:35.973791",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.945825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Observation\n",
    "As our dataset is imbalanced, we will balance our class by weighting majority class less and minoiry class more\n",
    "\n",
    "## 관찰\n",
    "데이터 세트가 불균형적이므로 다수 클래스는 덜 가중치 부여하고 소수 클래스는 더 가중치를 부여하여 클래스 균형을 맞출 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-enzyme",
   "metadata": {
    "id": "dense-enzyme",
    "papermill": {
     "duration": 0.028255,
     "end_time": "2021-05-30T18:39:36.030250",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.001995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DataGenerator train and validation\n",
    "We will use kaggle dataset as train set and compitition dataset as validation set. If train and validation metric is similar, it shows their distribution is similar and hence we can use kaggle dataset as well.\n",
    "\n",
    "# 데이터 생성기 교육 및 검증\n",
    "우리는 캐글 데이터 세트를 열차 세트로, 컴포지션 데이터 세트를 검증 세트로 사용할 것이다. 열차와 검증 메트릭이 유사한 경우 분포가 유사함을 보여주므로 캐글 데이터 세트도 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "encouraging-novel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:36.090553Z",
     "iopub.status.busy": "2021-05-30T18:39:36.089729Z",
     "iopub.status.idle": "2021-05-30T18:39:36.092340Z",
     "shell.execute_reply": "2021-05-30T18:39:36.091828Z",
     "shell.execute_reply.started": "2021-05-30T09:28:44.189248Z"
    },
    "id": "encouraging-novel",
    "papermill": {
     "duration": 0.035021,
     "end_time": "2021-05-30T18:39:36.092447",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.057426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train data generator object\n",
    "train_aug = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    "  )\n",
    "\n",
    "# validation data generator object\n",
    "valid_aug = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "geological-philadelphia",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:36.172890Z",
     "iopub.status.busy": "2021-05-30T18:39:36.167698Z",
     "iopub.status.idle": "2021-05-30T18:39:39.954054Z",
     "shell.execute_reply": "2021-05-30T18:39:39.954888Z",
     "shell.execute_reply.started": "2021-05-30T09:28:47.478488Z"
    },
    "id": "geological-philadelphia",
    "outputId": "358f5e4e-a7b9-4d32-d0be-5a08a4e27ace",
    "papermill": {
     "duration": 3.835127,
     "end_time": "2021-05-30T18:39:39.955083",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.119956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9786 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# create train generator\n",
    "train_generator = train_aug.flow_from_dataframe(\n",
    "    dataframe = df_train_kaggle,\n",
    "    directory = None,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 16,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-chest",
   "metadata": {
    "id": "asian-chest",
    "papermill": {
     "duration": 0.027295,
     "end_time": "2021-05-30T18:39:40.011354",
     "exception": false,
     "start_time": "2021-05-30T18:39:39.984059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create validation dataframe using compitition dataset.\n",
    "We will download compition dataset from gdrive and use it as validation set to validated against kaggle dataset\n",
    "\n",
    "# composition dataset을 이용하여 검증 데이터 프레임을 생성합니다.\n",
    "gdrive에서 컴포지션 데이터 세트를 다운로드하여 Kaggle 데이터 세트에 대해 검증된 검증 세트로 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "threaded-characterization",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.229132Z",
     "iopub.status.busy": "2021-05-30T18:40:02.228400Z",
     "iopub.status.idle": "2021-05-30T18:40:02.250117Z",
     "shell.execute_reply": "2021-05-30T18:40:02.250642Z",
     "shell.execute_reply.started": "2021-05-30T08:33:23.833280Z"
    },
    "id": "threaded-characterization",
    "outputId": "283093ce-0819-4542-9ff8-555713912e62",
    "papermill": {
     "duration": 0.059732,
     "end_time": "2021-05-30T18:40:02.250775",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.191043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  label\n",
       "0  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      0\n",
       "1  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      1\n",
       "2  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      0\n",
       "3  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      1\n",
       "4  C:\\Users\\ngkim\\Downloads\\KneeXray\\train/Image_...      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read Train.csv file which contains image names and labels and preprocess them\n",
    "compi_root_path = \"C:\\\\Users\\\\ngkim\\\\Downloads\\\\KneeXray\\\\\"\n",
    "df_val_compi = pd.read_csv(compi_root_path + \"Train.csv\")\n",
    "\n",
    "# add absolute path to the image names\n",
    "df_val_compi[\"filename\"] = df_val_compi.filename.apply(lambda x: compi_root_path+\"train/\" + x)\n",
    "df_val_compi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suburban-shareware",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.339459Z",
     "iopub.status.busy": "2021-05-30T18:40:02.324109Z",
     "iopub.status.idle": "2021-05-30T18:40:02.442504Z",
     "shell.execute_reply": "2021-05-30T18:40:02.442056Z",
     "shell.execute_reply.started": "2021-05-30T08:33:23.865039Z"
    },
    "id": "suburban-shareware",
    "outputId": "8fb91f05-54a6-4bc7-d95f-68ea55748335",
    "papermill": {
     "duration": 0.158988,
     "end_time": "2021-05-30T18:40:02.442618",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.283630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class count of compitition dataset\n",
    "df_val_compi.label.value_counts().plot.bar()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "saving-homework",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.529039Z",
     "iopub.status.busy": "2021-05-30T18:40:02.528305Z",
     "iopub.status.idle": "2021-05-30T18:40:02.574290Z",
     "shell.execute_reply": "2021-05-30T18:40:02.574903Z",
     "shell.execute_reply.started": "2021-05-30T08:54:21.600981Z"
    },
    "id": "saving-homework",
    "outputId": "178977a9-4413-4d38-b7f0-de8a9904b0e0",
    "papermill": {
     "duration": 0.098388,
     "end_time": "2021-05-30T18:40:02.575081",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.476693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7828 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# create validation generator\n",
    "valid_generator = valid_aug.flow_from_dataframe( \n",
    "    dataframe = df_val_compi,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 16,\n",
    "    seed = 42,\n",
    "    shuffle= True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-belarus",
   "metadata": {
    "id": "marked-belarus",
    "papermill": {
     "duration": 0.033792,
     "end_time": "2021-05-30T18:40:02.643887",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.610095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Architecture\n",
    "Here we will be using Xception by google. (I encourage you to try different architectures)\n",
    "\n",
    "## 모델 아키텍처\n",
    "여기서는 구글의 Xception을 사용할 것입니다. (다양한 아키텍처를 사용해 보십시오)\n",
    "\n",
    "## CheXNet - DenseNet121 + Sigmoid\n",
    "https://github.com/arnoweng/CheXNet/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "buried-tablet",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.724467Z",
     "iopub.status.busy": "2021-05-30T18:40:02.723830Z",
     "iopub.status.idle": "2021-05-30T18:40:08.132744Z",
     "shell.execute_reply": "2021-05-30T18:40:08.131632Z",
     "shell.execute_reply.started": "2021-05-30T09:28:56.068101Z"
    },
    "id": "buried-tablet",
    "outputId": "2be7f5dd-25c9-49e7-fce8-f3e1fbe9c6a1",
    "papermill": {
     "duration": 5.455093,
     "end_time": "2021-05-30T18:40:08.132878",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.677785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "xception = Xception(weights = \"imagenet\",)\n",
    "x =  xception.layers[-5].output\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size= 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = n_class, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "GAP = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "pred = tf.keras.activations.softmax(GAP)\n",
    "\n",
    "xception_model = Model(inputs=xception.input,outputs = pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "DYVqXESmD_Fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYVqXESmD_Fd",
    "outputId": "88696012-6f00-42ba-d016-645743054fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 1024) 18875392    block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10, 10, 1024) 4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 10, 10, 1024) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 10, 10, 512)  4719104     activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 10, 10, 512)  2048        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 10, 512)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 10, 10, 256)  1179904     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 10, 10, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 10, 10, 128)  295040      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 10, 10, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 10, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 10, 10, 64)   73792       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 10, 10, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 10, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 10, 10, 5)    2885        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 10, 10, 5)    20          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 10, 5)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 5)            0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.softmax (TFOpLambda)      (None, 5)            0           global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 46,007,361\n",
      "Trainable params: 45,952,951\n",
      "Non-trainable params: 54,410\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "norman-detector",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:08.391663Z",
     "iopub.status.busy": "2021-05-30T18:40:08.385701Z",
     "iopub.status.idle": "2021-05-30T18:40:08.398432Z",
     "shell.execute_reply": "2021-05-30T18:40:08.397997Z",
     "shell.execute_reply.started": "2021-05-30T09:28:58.465217Z"
    },
    "id": "norman-detector",
    "papermill": {
     "duration": 0.226948,
     "end_time": "2021-05-30T18:40:08.398547",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.171599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "xception_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001, decay = 0.0001),\n",
    "    metrics = [\"acc\"],\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy)\n",
    "\n",
    "# callbacks and checkpoints\n",
    "checkpoint_path = \"xception_best.ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "my_callbacks = [\n",
    "              ModelCheckpoint(\n",
    "                   checkpoint_path,\n",
    "                   monitor = 'val_acc',\n",
    "                   verbose = 1,\n",
    "                   save_weights_only = True,\n",
    "                   save_best_only = True,\n",
    "                   mode = \"max\"\n",
    "                  ),\n",
    "              EarlyStopping(\n",
    "                   monitor = 'val_loss',\n",
    "                   patience = 10,\n",
    "                   verbose = 0\n",
    "                  ),\n",
    "              ReduceLROnPlateau(\n",
    "                   monitor = 'val_loss',\n",
    "                   patience = 10,\n",
    "                   verbose = 1\n",
    "                  )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-administration",
   "metadata": {
    "id": "crucial-administration",
    "papermill": {
     "duration": 0.038495,
     "end_time": "2021-05-30T18:40:08.475329",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.436834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Weighting classes\n",
    "As we have unevenly class distibution, we will weight them based on the number of samples\n",
    "\n",
    "### 가중치 클래스\n",
    "우리는 등급 차이가 일정하지 않기 때문에 샘플 수에 따라 무게를 재도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regional-indie",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:08.558435Z",
     "iopub.status.busy": "2021-05-30T18:40:08.557616Z",
     "iopub.status.idle": "2021-05-30T18:40:09.060821Z",
     "shell.execute_reply": "2021-05-30T18:40:09.060357Z",
     "shell.execute_reply.started": "2021-05-30T09:30:11.007618Z"
    },
    "id": "regional-indie",
    "papermill": {
     "duration": 0.546357,
     "end_time": "2021-05-30T18:40:09.060960",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.514603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes = np.unique(df_train_kaggle.label.values),\n",
    "    y = df_train_kaggle.label.values\n",
    "  )\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-better",
   "metadata": {
    "id": "square-better",
    "papermill": {
     "duration": 0.037503,
     "end_time": "2021-05-30T18:40:09.136492",
     "exception": false,
     "start_time": "2021-05-30T18:40:09.098989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train\n",
    "Lets roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74860ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72c672ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11182929336557808816\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22727688192\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9467392316341342428\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hidden-stephen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:09.218272Z",
     "iopub.status.busy": "2021-05-30T18:40:09.217728Z",
     "iopub.status.idle": "2021-05-30T20:12:12.156502Z",
     "shell.execute_reply": "2021-05-30T20:12:12.154537Z",
     "shell.execute_reply.started": "2021-05-26T18:49:57.904339Z"
    },
    "id": "hidden-stephen",
    "outputId": "1432984b-6c8d-4523-de45-b163a07ed120",
    "papermill": {
     "duration": 5522.981999,
     "end_time": "2021-05-30T20:12:12.156678",
     "exception": false,
     "start_time": "2021-05-30T18:40:09.174679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "612/612 [==============================] - 96s 149ms/step - loss: 1.4086 - acc: 0.3357 - val_loss: 1.8691 - val_acc: 0.2469\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.24693, saving model to xception_best.ckpt\n",
      "Epoch 2/300\n",
      "612/612 [==============================] - 88s 145ms/step - loss: 1.1808 - acc: 0.4879 - val_loss: 1.3592 - val_acc: 0.5303\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.24693 to 0.53028, saving model to xception_best.ckpt\n",
      "Epoch 3/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 1.0607 - acc: 0.5535 - val_loss: 1.1469 - val_acc: 0.6170\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.53028 to 0.61702, saving model to xception_best.ckpt\n",
      "Epoch 4/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.9723 - acc: 0.6065 - val_loss: 1.1103 - val_acc: 0.6521\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.61702 to 0.65215, saving model to xception_best.ckpt\n",
      "Epoch 5/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.8918 - acc: 0.6648 - val_loss: 1.0467 - val_acc: 0.6796\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.65215 to 0.67961, saving model to xception_best.ckpt\n",
      "Epoch 6/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.8171 - acc: 0.7182 - val_loss: 0.9598 - val_acc: 0.7290\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.67961 to 0.72905, saving model to xception_best.ckpt\n",
      "Epoch 7/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.7547 - acc: 0.7658 - val_loss: 0.8910 - val_acc: 0.7777\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.72905 to 0.77772, saving model to xception_best.ckpt\n",
      "Epoch 8/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.7040 - acc: 0.8054 - val_loss: 0.8923 - val_acc: 0.7735\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.77772\n",
      "Epoch 9/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.6679 - acc: 0.8363 - val_loss: 0.8827 - val_acc: 0.7936\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.77772 to 0.79356, saving model to xception_best.ckpt\n",
      "Epoch 10/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.6307 - acc: 0.8651 - val_loss: 0.7929 - val_acc: 0.8461\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.79356 to 0.84607, saving model to xception_best.ckpt\n",
      "Epoch 11/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.5974 - acc: 0.8894 - val_loss: 0.8329 - val_acc: 0.8213\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.84607\n",
      "Epoch 12/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.5831 - acc: 0.9012 - val_loss: 0.7640 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.84607 to 0.87672, saving model to xception_best.ckpt\n",
      "Epoch 13/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.5651 - acc: 0.9123 - val_loss: 0.7177 - val_acc: 0.8967\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.87672 to 0.89665, saving model to xception_best.ckpt\n",
      "Epoch 14/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.5539 - acc: 0.9213 - val_loss: 0.7209 - val_acc: 0.8938\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.89665\n",
      "Epoch 15/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.5342 - acc: 0.9331 - val_loss: 0.6971 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.89665 to 0.90598, saving model to xception_best.ckpt\n",
      "Epoch 16/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.5269 - acc: 0.9368 - val_loss: 0.7261 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.90598\n",
      "Epoch 17/300\n",
      "612/612 [==============================] - 89s 146ms/step - loss: 0.5309 - acc: 0.9425 - val_loss: 0.6668 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.90598 to 0.92271, saving model to xception_best.ckpt\n",
      "Epoch 18/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.5133 - acc: 0.9457 - val_loss: 0.6830 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92271\n",
      "Epoch 19/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.5111 - acc: 0.9579 - val_loss: 0.7200 - val_acc: 0.9089\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.92271\n",
      "Epoch 20/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.5008 - acc: 0.9590 - val_loss: 0.6573 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.92271 to 0.92527, saving model to xception_best.ckpt\n",
      "Epoch 21/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4907 - acc: 0.9623 - val_loss: 0.6864 - val_acc: 0.9073\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.92527\n",
      "Epoch 22/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4905 - acc: 0.9649 - val_loss: 0.6525 - val_acc: 0.9319\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.92527 to 0.93191, saving model to xception_best.ckpt\n",
      "Epoch 23/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4817 - acc: 0.9700 - val_loss: 0.6448 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.93191 to 0.93332, saving model to xception_best.ckpt\n",
      "Epoch 24/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4806 - acc: 0.9704 - val_loss: 0.6474 - val_acc: 0.9272\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.93332\n",
      "Epoch 25/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4862 - acc: 0.9682 - val_loss: 0.6334 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.93332 to 0.93868, saving model to xception_best.ckpt\n",
      "Epoch 26/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.4718 - acc: 0.9692 - val_loss: 0.6026 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.93868 to 0.94762, saving model to xception_best.ckpt\n",
      "Epoch 27/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4676 - acc: 0.9769 - val_loss: 0.6262 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.94762\n",
      "Epoch 28/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4705 - acc: 0.9735 - val_loss: 0.6220 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.94762\n",
      "Epoch 29/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.4677 - acc: 0.9762 - val_loss: 0.6404 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.94762\n",
      "Epoch 30/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.4656 - acc: 0.9781 - val_loss: 0.6075 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.94762\n",
      "Epoch 31/300\n",
      "612/612 [==============================] - 87s 143ms/step - loss: 0.4559 - acc: 0.9811 - val_loss: 0.6010 - val_acc: 0.9502\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.94762 to 0.95018, saving model to xception_best.ckpt\n",
      "Epoch 32/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4557 - acc: 0.9810 - val_loss: 0.5950 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.95018\n",
      "Epoch 33/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.4555 - acc: 0.9820 - val_loss: 0.5965 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.95018\n",
      "Epoch 34/300\n",
      "612/612 [==============================] - 87s 143ms/step - loss: 0.4479 - acc: 0.9861 - val_loss: 0.6087 - val_acc: 0.9414\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.95018\n",
      "Epoch 35/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.4527 - acc: 0.9826 - val_loss: 0.6267 - val_acc: 0.9351\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.95018\n",
      "Epoch 36/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.4464 - acc: 0.9825 - val_loss: 0.6001 - val_acc: 0.9443\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.95018\n",
      "Epoch 37/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.4462 - acc: 0.9845 - val_loss: 0.5910 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.95018 to 0.95184, saving model to xception_best.ckpt\n",
      "Epoch 38/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4426 - acc: 0.9856 - val_loss: 0.5811 - val_acc: 0.9555\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.95184 to 0.95554, saving model to xception_best.ckpt\n",
      "Epoch 39/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4418 - acc: 0.9862 - val_loss: 0.5911 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.95554\n",
      "Epoch 40/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4418 - acc: 0.9858 - val_loss: 0.5738 - val_acc: 0.9569\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.95554 to 0.95695, saving model to xception_best.ckpt\n",
      "Epoch 41/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4368 - acc: 0.9878 - val_loss: 0.5585 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.95695 to 0.96410, saving model to xception_best.ckpt\n",
      "Epoch 42/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4376 - acc: 0.9875 - val_loss: 0.5723 - val_acc: 0.9569\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.96410\n",
      "Epoch 43/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4367 - acc: 0.9872 - val_loss: 0.5774 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.96410\n",
      "Epoch 44/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4367 - acc: 0.9876 - val_loss: 0.5627 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.96410\n",
      "Epoch 45/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4401 - acc: 0.9856 - val_loss: 0.5724 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.96410\n",
      "Epoch 46/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4320 - acc: 0.9897 - val_loss: 0.5591 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.96410\n",
      "Epoch 47/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.4295 - acc: 0.9888 - val_loss: 0.5588 - val_acc: 0.9563\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.96410\n",
      "Epoch 48/300\n",
      "612/612 [==============================] - 87s 143ms/step - loss: 0.4275 - acc: 0.9910 - val_loss: 0.5512 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.96410\n",
      "Epoch 49/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4289 - acc: 0.9908 - val_loss: 0.5372 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.96410 to 0.96998, saving model to xception_best.ckpt\n",
      "Epoch 50/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4216 - acc: 0.9914 - val_loss: 0.5444 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.96998\n",
      "Epoch 51/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4288 - acc: 0.9904 - val_loss: 0.5445 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.96998\n",
      "Epoch 52/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.4171 - acc: 0.9922 - val_loss: 0.5391 - val_acc: 0.9638\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.96998\n",
      "Epoch 53/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4233 - acc: 0.9921 - val_loss: 0.5392 - val_acc: 0.9647\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.96998\n",
      "Epoch 54/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4173 - acc: 0.9916 - val_loss: 0.5398 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.96998\n",
      "Epoch 55/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4157 - acc: 0.9929 - val_loss: 0.5316 - val_acc: 0.9702\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.96998 to 0.97024, saving model to xception_best.ckpt\n",
      "Epoch 56/300\n",
      "612/612 [==============================] - 88s 145ms/step - loss: 0.4239 - acc: 0.9916 - val_loss: 0.5435 - val_acc: 0.9587\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.97024\n",
      "Epoch 57/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4122 - acc: 0.9937 - val_loss: 0.5312 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.97024\n",
      "Epoch 58/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4213 - acc: 0.9919 - val_loss: 0.5340 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.97024\n",
      "Epoch 59/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4186 - acc: 0.9929 - val_loss: 0.5362 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.97024\n",
      "Epoch 60/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4121 - acc: 0.9940 - val_loss: 0.5304 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.97024\n",
      "Epoch 61/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4102 - acc: 0.9928 - val_loss: 0.5331 - val_acc: 0.9660\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.97024\n",
      "Epoch 62/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.4112 - acc: 0.9939 - val_loss: 0.5225 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.97024 to 0.97062, saving model to xception_best.ckpt\n",
      "Epoch 63/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.4071 - acc: 0.9932 - val_loss: 0.5148 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.97062\n",
      "Epoch 64/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4079 - acc: 0.9920 - val_loss: 0.5183 - val_acc: 0.9673\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.97062\n",
      "Epoch 65/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4116 - acc: 0.9924 - val_loss: 0.5145 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.97062\n",
      "Epoch 66/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.4080 - acc: 0.9948 - val_loss: 0.5203 - val_acc: 0.9632\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.97062\n",
      "Epoch 67/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4083 - acc: 0.9949 - val_loss: 0.5254 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.97062\n",
      "Epoch 68/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4093 - acc: 0.9934 - val_loss: 0.5160 - val_acc: 0.9715\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.97062 to 0.97151, saving model to xception_best.ckpt\n",
      "Epoch 69/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.4063 - acc: 0.9942 - val_loss: 0.5148 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.97151 to 0.97241, saving model to xception_best.ckpt\n",
      "Epoch 70/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4060 - acc: 0.9948 - val_loss: 0.5235 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.97241\n",
      "Epoch 71/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4037 - acc: 0.9952 - val_loss: 0.5182 - val_acc: 0.9723\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.97241\n",
      "Epoch 72/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4005 - acc: 0.9950 - val_loss: 0.5088 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.97241\n",
      "Epoch 73/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3997 - acc: 0.9956 - val_loss: 0.5128 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.97241\n",
      "Epoch 74/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.4050 - acc: 0.9929 - val_loss: 0.5137 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.97241\n",
      "Epoch 75/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4025 - acc: 0.9935 - val_loss: 0.5125 - val_acc: 0.9697\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.97241\n",
      "Epoch 76/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4011 - acc: 0.9955 - val_loss: 0.5064 - val_acc: 0.9687\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.97241\n",
      "Epoch 77/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.4017 - acc: 0.9940 - val_loss: 0.5039 - val_acc: 0.9715\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.97241\n",
      "Epoch 78/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3964 - acc: 0.9970 - val_loss: 0.5009 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.97241 to 0.97368, saving model to xception_best.ckpt\n",
      "Epoch 79/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.3918 - acc: 0.9963 - val_loss: 0.5001 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.97368 to 0.97483, saving model to xception_best.ckpt\n",
      "Epoch 80/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3924 - acc: 0.9964 - val_loss: 0.5053 - val_acc: 0.9678\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.97483\n",
      "Epoch 81/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3961 - acc: 0.9959 - val_loss: 0.4937 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.97483\n",
      "Epoch 82/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 89s 145ms/step - loss: 0.3928 - acc: 0.9954 - val_loss: 0.4888 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.97483\n",
      "Epoch 83/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3962 - acc: 0.9953 - val_loss: 0.5056 - val_acc: 0.9696\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.97483\n",
      "Epoch 84/300\n",
      "612/612 [==============================] - 88s 145ms/step - loss: 0.3977 - acc: 0.9950 - val_loss: 0.4923 - val_acc: 0.9722\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.97483\n",
      "Epoch 85/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3904 - acc: 0.9966 - val_loss: 0.4921 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.97483\n",
      "Epoch 86/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3916 - acc: 0.9950 - val_loss: 0.4743 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.97483 to 0.97701, saving model to xception_best.ckpt\n",
      "Epoch 87/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3942 - acc: 0.9954 - val_loss: 0.4826 - val_acc: 0.9739\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.97701\n",
      "Epoch 88/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3920 - acc: 0.9961 - val_loss: 0.4816 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.97701\n",
      "Epoch 89/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3862 - acc: 0.9960 - val_loss: 0.4810 - val_acc: 0.9728\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.97701\n",
      "Epoch 90/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3965 - acc: 0.9946 - val_loss: 0.4875 - val_acc: 0.9709\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.97701\n",
      "Epoch 91/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3806 - acc: 0.9967 - val_loss: 0.4789 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.97701\n",
      "Epoch 92/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.3877 - acc: 0.9954 - val_loss: 0.4852 - val_acc: 0.9704\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.97701\n",
      "Epoch 93/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.3859 - acc: 0.9963 - val_loss: 0.4761 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.97701\n",
      "Epoch 94/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3843 - acc: 0.9965 - val_loss: 0.4839 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.97701\n",
      "Epoch 95/300\n",
      "612/612 [==============================] - 88s 145ms/step - loss: 0.3857 - acc: 0.9967 - val_loss: 0.4724 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.97701\n",
      "Epoch 96/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3842 - acc: 0.9973 - val_loss: 0.4811 - val_acc: 0.9732\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.97701\n",
      "Epoch 97/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3815 - acc: 0.9974 - val_loss: 0.4741 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.97701\n",
      "Epoch 98/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3805 - acc: 0.9961 - val_loss: 0.4646 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.97701\n",
      "Epoch 99/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3818 - acc: 0.9968 - val_loss: 0.4629 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.97701 to 0.97828, saving model to xception_best.ckpt\n",
      "Epoch 100/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3806 - acc: 0.9958 - val_loss: 0.4762 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.97828\n",
      "Epoch 101/300\n",
      "612/612 [==============================] - 87s 143ms/step - loss: 0.3789 - acc: 0.9975 - val_loss: 0.4688 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.97828\n",
      "Epoch 102/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3794 - acc: 0.9981 - val_loss: 0.4726 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.97828\n",
      "Epoch 103/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3778 - acc: 0.9968 - val_loss: 0.4636 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.97828\n",
      "Epoch 104/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3786 - acc: 0.9974 - val_loss: 0.4541 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.97828 to 0.97867, saving model to xception_best.ckpt\n",
      "Epoch 105/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3790 - acc: 0.9962 - val_loss: 0.4676 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.97867\n",
      "Epoch 106/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3745 - acc: 0.9971 - val_loss: 0.4582 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.97867\n",
      "Epoch 107/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3838 - acc: 0.9954 - val_loss: 0.4661 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.97867\n",
      "Epoch 108/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3743 - acc: 0.9967 - val_loss: 0.4585 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.97867\n",
      "Epoch 109/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3731 - acc: 0.9968 - val_loss: 0.4480 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.97867 to 0.97931, saving model to xception_best.ckpt\n",
      "Epoch 110/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3789 - acc: 0.9965 - val_loss: 0.4552 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.97931\n",
      "Epoch 111/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3734 - acc: 0.9965 - val_loss: 0.4526 - val_acc: 0.9779\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.97931\n",
      "Epoch 112/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3727 - acc: 0.9976 - val_loss: 0.4482 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.97931\n",
      "Epoch 113/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3719 - acc: 0.9975 - val_loss: 0.4481 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.97931\n",
      "Epoch 114/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3693 - acc: 0.9974 - val_loss: 0.4574 - val_acc: 0.9762\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.97931\n",
      "Epoch 115/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3714 - acc: 0.9980 - val_loss: 0.4442 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00115: val_acc improved from 0.97931 to 0.98045, saving model to xception_best.ckpt\n",
      "Epoch 116/300\n",
      "612/612 [==============================] - 87s 143ms/step - loss: 0.3726 - acc: 0.9972 - val_loss: 0.4548 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.98045\n",
      "Epoch 117/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3723 - acc: 0.9983 - val_loss: 0.4514 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.98045\n",
      "Epoch 118/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3697 - acc: 0.9974 - val_loss: 0.4555 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.98045\n",
      "Epoch 119/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3700 - acc: 0.9974 - val_loss: 0.4500 - val_acc: 0.9759\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.98045\n",
      "Epoch 120/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3748 - acc: 0.9968 - val_loss: 0.4562 - val_acc: 0.9746\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.98045\n",
      "Epoch 121/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3672 - acc: 0.9978 - val_loss: 0.4500 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.98045\n",
      "Epoch 122/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3672 - acc: 0.9974 - val_loss: 0.4499 - val_acc: 0.9764\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.98045\n",
      "Epoch 123/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3684 - acc: 0.9972 - val_loss: 0.4512 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.98045\n",
      "Epoch 124/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3691 - acc: 0.9982 - val_loss: 0.4434 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00124: val_acc improved from 0.98045 to 0.98135, saving model to xception_best.ckpt\n",
      "Epoch 125/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3672 - acc: 0.9978 - val_loss: 0.4430 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.98135\n",
      "Epoch 126/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3636 - acc: 0.9976 - val_loss: 0.4523 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.98135\n",
      "Epoch 127/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3641 - acc: 0.9978 - val_loss: 0.4417 - val_acc: 0.9801\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.98135\n",
      "Epoch 128/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3618 - acc: 0.9981 - val_loss: 0.4411 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.98135\n",
      "Epoch 129/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3661 - acc: 0.9971 - val_loss: 0.4457 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.98135\n",
      "Epoch 130/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3658 - acc: 0.9976 - val_loss: 0.4441 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.98135\n",
      "Epoch 131/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3630 - acc: 0.9979 - val_loss: 0.4413 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.98135\n",
      "Epoch 132/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3617 - acc: 0.9985 - val_loss: 0.4425 - val_acc: 0.9779\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.98135\n",
      "Epoch 133/300\n",
      "612/612 [==============================] - 87s 143ms/step - loss: 0.3638 - acc: 0.9978 - val_loss: 0.4381 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.98135\n",
      "Epoch 134/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3570 - acc: 0.9984 - val_loss: 0.4383 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.98135\n",
      "Epoch 135/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3633 - acc: 0.9978 - val_loss: 0.4414 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.98135\n",
      "Epoch 136/300\n",
      "612/612 [==============================] - 88s 145ms/step - loss: 0.3648 - acc: 0.9966 - val_loss: 0.4398 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.98135\n",
      "Epoch 137/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3636 - acc: 0.9984 - val_loss: 0.4393 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.98135\n",
      "Epoch 138/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3613 - acc: 0.9983 - val_loss: 0.4563 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.98135\n",
      "Epoch 139/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3627 - acc: 0.9980 - val_loss: 0.4395 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.98135\n",
      "Epoch 140/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3622 - acc: 0.9976 - val_loss: 0.4362 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.98135\n",
      "Epoch 141/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3551 - acc: 0.9980 - val_loss: 0.4442 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.98135\n",
      "Epoch 142/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3563 - acc: 0.9981 - val_loss: 0.4406 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.98135\n",
      "Epoch 143/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3607 - acc: 0.9973 - val_loss: 0.4465 - val_acc: 0.9741\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.98135\n",
      "Epoch 144/300\n",
      "612/612 [==============================] - 87s 143ms/step - loss: 0.3588 - acc: 0.9978 - val_loss: 0.4367 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.98135\n",
      "Epoch 145/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3597 - acc: 0.9972 - val_loss: 0.4368 - val_acc: 0.9774\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.98135\n",
      "Epoch 146/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3590 - acc: 0.9978 - val_loss: 0.4340 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.98135\n",
      "Epoch 147/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3577 - acc: 0.9979 - val_loss: 0.4334 - val_acc: 0.9779\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.98135\n",
      "Epoch 148/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3570 - acc: 0.9989 - val_loss: 0.4266 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.98135\n",
      "Epoch 149/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3585 - acc: 0.9974 - val_loss: 0.4363 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.98135\n",
      "Epoch 150/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3527 - acc: 0.9983 - val_loss: 0.4280 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.98135\n",
      "Epoch 151/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3592 - acc: 0.9976 - val_loss: 0.4175 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00151: val_acc improved from 0.98135 to 0.98288, saving model to xception_best.ckpt\n",
      "Epoch 152/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3548 - acc: 0.9989 - val_loss: 0.4264 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.98288\n",
      "Epoch 153/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3563 - acc: 0.9969 - val_loss: 0.4336 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.98288\n",
      "Epoch 154/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3550 - acc: 0.9993 - val_loss: 0.4340 - val_acc: 0.9771\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.98288\n",
      "Epoch 155/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3560 - acc: 0.9990 - val_loss: 0.4308 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.98288\n",
      "Epoch 156/300\n",
      "612/612 [==============================] - 89s 145ms/step - loss: 0.3514 - acc: 0.9982 - val_loss: 0.4224 - val_acc: 0.9798\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.98288\n",
      "Epoch 157/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3542 - acc: 0.9984 - val_loss: 0.4314 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.98288\n",
      "Epoch 158/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3562 - acc: 0.9975 - val_loss: 0.4227 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.98288\n",
      "Epoch 159/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3581 - acc: 0.9982 - val_loss: 0.4268 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.98288\n",
      "Epoch 160/300\n",
      "612/612 [==============================] - 88s 143ms/step - loss: 0.3542 - acc: 0.9986 - val_loss: 0.4267 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.98288\n",
      "Epoch 161/300\n",
      "612/612 [==============================] - 88s 144ms/step - loss: 0.3539 - acc: 0.9989 - val_loss: 0.4331 - val_acc: 0.9759\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.98288\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2033d1871f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "xception_model.fit(\n",
    "        train_generator,\n",
    "        epochs = 300,\n",
    "        validation_data = valid_generator,\n",
    "        callbacks = [my_callbacks],\n",
    "        class_weight = class_weights\n",
    "      )\n",
    "\n",
    "# load best saved weights\n",
    "xception_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-morris",
   "metadata": {
    "id": "pretty-morris",
    "papermill": {
     "duration": 3.201635,
     "end_time": "2021-05-30T20:12:18.344310",
     "exception": false,
     "start_time": "2021-05-30T20:12:15.142675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Observation\n",
    "As we can see train and validation accuracy is pretty close, which proves kaggle and competition data has come from the same distribution and we can freely use it to experiment with.\n",
    "\n",
    "## Retraining last trained model on competition data\n",
    "As we have used competition data as validation set previously, we will use it as train set now (and some part of it as validation set) hoping this additional training would give our model new information to perform better.\n",
    "\n",
    "## 관찰\n",
    "보시다시피 열차와 검증 정확도는 매우 가까우며, 이는 카글과 경쟁 데이터가 동일한 분포에서 나왔다는 것을 증명하며, 이를 실험하는 데 자유롭게 사용할 수 있습니다.\n",
    "\n",
    "## 경기 데이터에 대해 마지막으로 훈련된 모델 재교육\n",
    "이전에 경쟁 데이터를 검증 세트로 사용했으므로, 이제 열차 세트로 사용할 것이며(그리고 그 중 일부는 검증 세트로) 이 추가 교육을 통해 모델이 더 나은 성능을 발휘할 수 있는 새로운 정보를 얻을 수 있기를 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cloudy-idaho",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:24.238372Z",
     "iopub.status.busy": "2021-05-30T20:12:24.237660Z",
     "iopub.status.idle": "2021-05-30T20:12:24.305208Z",
     "shell.execute_reply": "2021-05-30T20:12:24.305579Z",
     "shell.execute_reply.started": "2021-05-30T09:30:16.948040Z"
    },
    "id": "cloudy-idaho",
    "papermill": {
     "duration": 3.027306,
     "end_time": "2021-05-30T20:12:24.305720",
     "exception": false,
     "start_time": "2021-05-30T20:12:21.278414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train and validation split on competition data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(\n",
    "    df_val_compi,\n",
    "    test_size = 0.1,\n",
    "    random_state = 42,\n",
    "    stratify = df_val_compi.label\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "nervous-crisis",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:30.429807Z",
     "iopub.status.busy": "2021-05-30T20:12:30.429001Z",
     "iopub.status.idle": "2021-05-30T20:12:30.472297Z",
     "shell.execute_reply": "2021-05-30T20:12:30.471634Z",
     "shell.execute_reply.started": "2021-05-30T09:30:18.098841Z"
    },
    "id": "nervous-crisis",
    "outputId": "bf1114cc-1f2d-4777-cef4-bd4eb24d75dd",
    "papermill": {
     "duration": 3.239148,
     "end_time": "2021-05-30T20:12:30.472465",
     "exception": false,
     "start_time": "2021-05-30T20:12:27.233317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7045 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_aug.flow_from_dataframe(\n",
    "    dataframe = X_train,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "instrumental-indie",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:36.309467Z",
     "iopub.status.busy": "2021-05-30T20:12:36.308631Z",
     "iopub.status.idle": "2021-05-30T20:12:36.318017Z",
     "shell.execute_reply": "2021-05-30T20:12:36.317530Z",
     "shell.execute_reply.started": "2021-05-30T09:30:23.206485Z"
    },
    "id": "instrumental-indie",
    "outputId": "dceb0588-b8e8-4658-a8e4-9c7f11fc65a0",
    "papermill": {
     "duration": 2.927421,
     "end_time": "2021-05-30T20:12:36.318129",
     "exception": false,
     "start_time": "2021-05-30T20:12:33.390708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 783 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = valid_aug.flow_from_dataframe( \n",
    "    dataframe = X_test,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dedicated-chapel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:42.897491Z",
     "iopub.status.busy": "2021-05-30T20:12:42.895853Z",
     "iopub.status.idle": "2021-05-30T20:12:42.898202Z",
     "shell.execute_reply": "2021-05-30T20:12:42.898602Z",
     "shell.execute_reply.started": "2021-05-30T09:30:26.966513Z"
    },
    "id": "dedicated-chapel",
    "papermill": {
     "duration": 3.108025,
     "end_time": "2021-05-30T20:12:42.898739",
     "exception": false,
     "start_time": "2021-05-30T20:12:39.790714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of steps to consider 1 as  epoch\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sized-norfolk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:48.820785Z",
     "iopub.status.busy": "2021-05-30T20:12:48.819337Z",
     "iopub.status.idle": "2021-05-30T20:25:26.371458Z",
     "shell.execute_reply": "2021-05-30T20:25:26.371941Z",
     "shell.execute_reply.started": "2021-05-30T09:30:36.962285Z"
    },
    "id": "sized-norfolk",
    "outputId": "fc9b987c-a11c-49f1-b98c-d4879cee12f6",
    "papermill": {
     "duration": 760.527609,
     "end_time": "2021-05-30T20:25:26.372105",
     "exception": false,
     "start_time": "2021-05-30T20:12:45.844496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "220/220 [==============================] - 52s 227ms/step - loss: 0.4492 - acc: 0.9815 - val_loss: 0.3873 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.98288 to 0.99349, saving model to xception_best.ckpt\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 49s 222ms/step - loss: 0.4434 - acc: 0.9855 - val_loss: 0.3840 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.99349\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 50s 228ms/step - loss: 0.4277 - acc: 0.9899 - val_loss: 0.3847 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.99349 to 0.99479, saving model to xception_best.ckpt\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 50s 227ms/step - loss: 0.4254 - acc: 0.9929 - val_loss: 0.3822 - val_acc: 0.9974\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.99479 to 0.99740, saving model to xception_best.ckpt\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 50s 225ms/step - loss: 0.4227 - acc: 0.9934 - val_loss: 0.3823 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99740\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 49s 224ms/step - loss: 0.4245 - acc: 0.9940 - val_loss: 0.3853 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99740\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 49s 223ms/step - loss: 0.4234 - acc: 0.9957 - val_loss: 0.3866 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99740\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 49s 222ms/step - loss: 0.4223 - acc: 0.9963 - val_loss: 0.3859 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99740\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 50s 227ms/step - loss: 0.4229 - acc: 0.9956 - val_loss: 0.3847 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99740\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 49s 222ms/step - loss: 0.4170 - acc: 0.9970 - val_loss: 0.3903 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99740\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 49s 222ms/step - loss: 0.4195 - acc: 0.9960 - val_loss: 0.3880 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99740\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 50s 225ms/step - loss: 0.4181 - acc: 0.9973 - val_loss: 0.3841 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99740\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 50s 226ms/step - loss: 0.4190 - acc: 0.9960 - val_loss: 0.3841 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99740\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 50s 227ms/step - loss: 0.4197 - acc: 0.9969 - val_loss: 0.3855 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99740\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2033ff62550>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kick off training\n",
    "xception_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "        epochs = 50,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = STEP_SIZE_VALID,callbacks = [my_callbacks]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "complete-spelling",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:33.497837Z",
     "iopub.status.busy": "2021-05-30T20:25:33.496999Z",
     "iopub.status.idle": "2021-05-30T20:25:34.695800Z",
     "shell.execute_reply": "2021-05-30T20:25:34.695365Z",
     "shell.execute_reply.started": "2021-05-24T16:41:06.725854Z"
    },
    "id": "complete-spelling",
    "outputId": "10521e37-45bc-43e8-eae3-62b233e07b14",
    "papermill": {
     "duration": 4.566888,
     "end_time": "2021-05-30T20:25:34.695951",
     "exception": false,
     "start_time": "2021-05-30T20:25:30.129063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x203478248b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best saved weights\n",
    "xception_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-cylinder",
   "metadata": {
    "id": "intended-cylinder",
    "papermill": {
     "duration": 3.633537,
     "end_time": "2021-05-30T20:25:41.743104",
     "exception": false,
     "start_time": "2021-05-30T20:25:38.109567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Confusion Matrix\n",
    "As our data set is imbalaned, lets see where is our model making mistakes. I encourage to you to take initative for bringing FPs and FNs down.\n",
    "\n",
    "# 혼란 매트릭스\n",
    "데이터 세트가 불균형 상태이므로 모델이 어디에서 실수를 하는지 살펴보자. FP와 FN을 끌어내리는데 솔선수범하길 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "equivalent-album",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:48.625234Z",
     "iopub.status.busy": "2021-05-30T20:25:48.624438Z",
     "iopub.status.idle": "2021-05-30T20:25:48.634216Z",
     "shell.execute_reply": "2021-05-30T20:25:48.633804Z",
     "shell.execute_reply.started": "2021-05-27T05:35:10.161826Z"
    },
    "id": "equivalent-album",
    "outputId": "2ed00c4a-4fd3-4d76-9ce5-6249f0da4489",
    "papermill": {
     "duration": 3.430239,
     "end_time": "2021-05-30T20:25:48.634343",
     "exception": false,
     "start_time": "2021-05-30T20:25:45.204104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 783 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "target_shape = 224\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# test generator\n",
    "compi_gen = valid_aug.flow_from_dataframe(\n",
    "    dataframe = X_test,\n",
    "    x_col = \"filename\",\n",
    "    class_mode = None,\n",
    "    target_size = (target_shape, target_shape),\n",
    "    shuffle = False,\n",
    "    batch_size = BATCH_SIZE\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "preceding-delight",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:56.117007Z",
     "iopub.status.busy": "2021-05-30T20:25:56.116264Z",
     "iopub.status.idle": "2021-05-30T20:26:05.659358Z",
     "shell.execute_reply": "2021-05-30T20:26:05.658569Z",
     "shell.execute_reply.started": "2021-05-27T05:35:17.324361Z"
    },
    "id": "preceding-delight",
    "outputId": "21817dd8-602c-4242-8998-5e3ae34e14e3",
    "papermill": {
     "duration": 12.914933,
     "end_time": "2021-05-30T20:26:05.659489",
     "exception": false,
     "start_time": "2021-05-30T20:25:52.744556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 6s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# prediction on train data\n",
    "predicition_compi = xception_model.predict(compi_gen, steps = compi_gen.n/ BATCH_SIZE, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "distinguished-midwest",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:12.667940Z",
     "iopub.status.busy": "2021-05-30T20:26:12.649791Z",
     "iopub.status.idle": "2021-05-30T20:26:13.051891Z",
     "shell.execute_reply": "2021-05-30T20:26:13.051413Z",
     "shell.execute_reply.started": "2021-05-27T05:43:44.837052Z"
    },
    "id": "distinguished-midwest",
    "outputId": "07a44daf-1bcd-454d-aa10-3c479b130443",
    "papermill": {
     "duration": 3.832152,
     "end_time": "2021-05-30T20:26:13.052010",
     "exception": false,
     "start_time": "2021-05-30T20:26:09.219858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2034d0b51f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "class_prediction_compi = np.argmax(predicition_compi, axis = 1)\n",
    "cm = confusion_matrix(X_test.label, class_prediction_compi, labels = [0, 1, 2, 3, 4])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix = cm,\n",
    "    display_labels = [0, 1, 2, 3, 4]\n",
    "  )\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-wilson",
   "metadata": {
    "id": "positive-wilson",
    "papermill": {
     "duration": 3.5306,
     "end_time": "2021-05-30T20:26:20.277590",
     "exception": false,
     "start_time": "2021-05-30T20:26:16.746990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Making prediction on test set (to make submission)\n",
    "Finally we save the predictions on disk in CSV format\n",
    "\n",
    "## 시험세트 예측하기 (제출하기)\n",
    "마지막으로 예측 내용을 CSV 형식으로 디스크에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "constitutional-catholic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:28.031789Z",
     "iopub.status.busy": "2021-05-30T20:26:28.031111Z",
     "iopub.status.idle": "2021-05-30T20:26:28.058944Z",
     "shell.execute_reply": "2021-05-30T20:26:28.058161Z",
     "shell.execute_reply.started": "2021-05-27T09:08:20.550041Z"
    },
    "id": "constitutional-catholic",
    "outputId": "91b6393c-4cdf-45ff-f39e-2eb2a0d17012",
    "papermill": {
     "duration": 4.034446,
     "end_time": "2021-05-30T20:26:28.059074",
     "exception": false,
     "start_time": "2021-05-30T20:26:24.024628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1958 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# read the csv file\n",
    "test = pd.read_csv(compi_root_path + \"Test.csv\")\n",
    "\n",
    "# create test generator\n",
    "test_generator = valid_aug.flow_from_dataframe(\n",
    "    dataframe = test,\n",
    "    directory = compi_root_path + \"test\",\n",
    "    x_col = \"filename\",\n",
    "    y_col = None,\n",
    "    batch_size = 1,\n",
    "    seed = 42,\n",
    "    shuffle = False,\n",
    "    class_mode = None,\n",
    "    target_size = (224,224)\n",
    "  )\n",
    "\n",
    "# number of steps to consider 1 epoch\n",
    "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "blocked-niagara",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:34.994605Z",
     "iopub.status.busy": "2021-05-30T20:26:34.994000Z",
     "iopub.status.idle": "2021-05-30T20:26:56.340759Z",
     "shell.execute_reply": "2021-05-30T20:26:56.341118Z",
     "shell.execute_reply.started": "2021-05-27T05:51:39.116529Z"
    },
    "id": "blocked-niagara",
    "outputId": "e8ed2e21-e61a-40ca-9976-0c87f7f7e9fa",
    "papermill": {
     "duration": 24.791614,
     "end_time": "2021-05-30T20:26:56.341303",
     "exception": false,
     "start_time": "2021-05-30T20:26:31.549689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958/1958 [==============================] - 14s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    768\n",
       "2    520\n",
       "1    353\n",
       "3    258\n",
       "4     59\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction and create dataframe out of it\n",
    "pred = xception_model.predict(test_generator,steps=STEP_SIZE_TEST,verbose=1)\n",
    "df_submit = pd.DataFrame({\"label\":np.argmax(pred, axis= 1)})\n",
    "df_submit[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-arthur",
   "metadata": {
    "id": "still-arthur",
    "papermill": {
     "duration": 3.549425,
     "end_time": "2021-05-30T20:27:04.148458",
     "exception": false,
     "start_time": "2021-05-30T20:27:00.599033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Clearing the working directory\n",
    "Because if don't, \"output\" tabl will show only images\n",
    "\n",
    "### 작업 디렉토리 지우기\n",
    "그렇지 않으면 \"출력\" 탭이 이미지만 표시되기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "decimal-hampshire",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:27:11.522864Z",
     "iopub.status.busy": "2021-05-30T20:27:11.522085Z",
     "iopub.status.idle": "2021-05-30T20:27:11.842332Z",
     "shell.execute_reply": "2021-05-30T20:27:11.842916Z",
     "shell.execute_reply.started": "2021-05-27T05:51:43.875589Z"
    },
    "id": "decimal-hampshire",
    "outputId": "bba496cf-d002-4106-cb8c-29be6b8078d2",
    "papermill": {
     "duration": 4.080149,
     "end_time": "2021-05-30T20:27:11.843118",
     "exception": false,
     "start_time": "2021-05-30T20:27:07.762969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: /kaggle/working - 지정된 경로를 찾을 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import shutil\n",
    "\n",
    "# Get directory name\n",
    "mydir = \"/kaggle/working\"\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(mydir)\n",
    "except OSError as e:\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-yacht",
   "metadata": {
    "id": "portable-yacht",
    "papermill": {
     "duration": 3.504245,
     "end_time": "2021-05-30T20:27:18.913681",
     "exception": false,
     "start_time": "2021-05-30T20:27:15.409436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Save best weights and output prediction file\n",
    "\n",
    "### 최적의 가중치 및 출력 예측 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "liquid-tsunami",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:27:26.290338Z",
     "iopub.status.busy": "2021-05-30T20:27:26.289493Z",
     "iopub.status.idle": "2021-05-30T20:27:26.809425Z",
     "shell.execute_reply": "2021-05-30T20:27:26.808879Z",
     "shell.execute_reply.started": "2021-05-27T05:51:46.57395Z"
    },
    "id": "liquid-tsunami",
    "papermill": {
     "duration": 4.073647,
     "end_time": "2021-05-30T20:27:26.809566",
     "exception": false,
     "start_time": "2021-05-30T20:27:22.735919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xception_model.save_weights(\"knee_xray_Xceptionnet_GPA.h5\")\n",
    "df_submit.to_csv(\"submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-baptist",
   "metadata": {
    "id": "sustainable-baptist",
    "papermill": {
     "duration": 3.563445,
     "end_time": "2021-05-30T20:27:34.549379",
     "exception": false,
     "start_time": "2021-05-30T20:27:30.985934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The submission results in 96.8% on public leaderboard.\n",
    "\n",
    "**Suggestion to improve the score**\n",
    "* Using right data augmentations\n",
    "* Using different model architecture\n",
    "* Ensembling and stacking\n",
    "* Using pretrained model trained on xray images\n",
    "\n",
    "제출 결과 공개 리더보드에서 96.8%의 결과가 나왔습니다.\n",
    "\n",
    "**점수 향상을 위한 제안*\n",
    "* 올바른 데이터 확대 사용\n",
    "* 다른 모델 아키텍처 사용\n",
    "* 조립 및 쌓기\n",
    "* X선 영상에 대해 사전 훈련된 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2538ff51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a2b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "KLGrade-DenseNet121-91.83.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6499.620651,
   "end_time": "2021-05-30T20:27:40.898205",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-30T18:39:21.277554",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
