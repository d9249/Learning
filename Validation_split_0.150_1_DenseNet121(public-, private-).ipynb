{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Validation_split_0.150_1_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOow8NbQlFYEdMjvUbbnh6J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/Validation_split_0.150_1_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3330c9dd-fb0b-4bc6-d70c-283e705cda89"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Aug 23 02:19:19 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f8114f-6efe-4bdf-8d51-75fa93675b4e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09797785-4006-419e-a7a0-5a5ddc2ca8d8"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff8d9c83-02cf-41f0-e293-506669c280da"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.1,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1847 images belonging to 10 classes.\n",
            "Found 201 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ffcb8a-ec27-464a-9c13-6407569a7aff"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "58/58 [==============================] - 39s 252ms/step - loss: 1.7864 - accuracy: 0.3660 - val_loss: 4.9462 - val_accuracy: 0.0796\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.07960, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 2/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 1.0661 - accuracy: 0.6475 - val_loss: 7.2900 - val_accuracy: 0.0348\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.07960\n",
            "Epoch 3/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.8965 - accuracy: 0.7055 - val_loss: 11.0413 - val_accuracy: 0.0995\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.07960 to 0.09950, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 4/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.7309 - accuracy: 0.7547 - val_loss: 6.1947 - val_accuracy: 0.1443\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.09950 to 0.14428, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 5/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.6919 - accuracy: 0.7558 - val_loss: 5.5029 - val_accuracy: 0.2139\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.14428 to 0.21393, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 6/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.6229 - accuracy: 0.7894 - val_loss: 4.9182 - val_accuracy: 0.2736\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.21393 to 0.27363, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 7/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.5161 - accuracy: 0.8370 - val_loss: 7.0761 - val_accuracy: 0.2139\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.27363\n",
            "Epoch 8/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.5185 - accuracy: 0.8240 - val_loss: 3.3261 - val_accuracy: 0.4030\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.27363 to 0.40299, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 9/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.4623 - accuracy: 0.8517 - val_loss: 0.8011 - val_accuracy: 0.7811\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.40299 to 0.78109, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 10/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.4065 - accuracy: 0.8592 - val_loss: 1.7880 - val_accuracy: 0.6368\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.78109\n",
            "Epoch 11/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.4222 - accuracy: 0.8603 - val_loss: 1.3017 - val_accuracy: 0.6617\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.78109\n",
            "Epoch 12/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.3618 - accuracy: 0.8744 - val_loss: 1.2666 - val_accuracy: 0.6915\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.78109\n",
            "Epoch 13/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.3289 - accuracy: 0.8868 - val_loss: 1.7944 - val_accuracy: 0.6418\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.78109\n",
            "Epoch 14/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.3050 - accuracy: 0.8944 - val_loss: 1.9868 - val_accuracy: 0.5721\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.78109\n",
            "Epoch 15/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.3458 - accuracy: 0.8863 - val_loss: 1.1157 - val_accuracy: 0.7164\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.78109\n",
            "Epoch 16/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.2460 - accuracy: 0.9139 - val_loss: 1.1363 - val_accuracy: 0.7214\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.78109\n",
            "Epoch 17/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.2849 - accuracy: 0.9042 - val_loss: 0.4694 - val_accuracy: 0.8507\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.78109 to 0.85075, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 18/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.2542 - accuracy: 0.9134 - val_loss: 0.6851 - val_accuracy: 0.8109\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.85075\n",
            "Epoch 19/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.2466 - accuracy: 0.9063 - val_loss: 0.9036 - val_accuracy: 0.7413\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.85075\n",
            "Epoch 20/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.2717 - accuracy: 0.9080 - val_loss: 0.6063 - val_accuracy: 0.8159\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.85075\n",
            "Epoch 21/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.2223 - accuracy: 0.9285 - val_loss: 0.6319 - val_accuracy: 0.7910\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.85075\n",
            "Epoch 22/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.2058 - accuracy: 0.9302 - val_loss: 0.8054 - val_accuracy: 0.7960\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.85075\n",
            "Epoch 23/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.2190 - accuracy: 0.9264 - val_loss: 0.5251 - val_accuracy: 0.8408\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.85075\n",
            "Epoch 24/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.1665 - accuracy: 0.9453 - val_loss: 0.6915 - val_accuracy: 0.8109\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.85075\n",
            "Epoch 25/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.1791 - accuracy: 0.9361 - val_loss: 0.5896 - val_accuracy: 0.8109\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.85075\n",
            "Epoch 26/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.1618 - accuracy: 0.9421 - val_loss: 0.6612 - val_accuracy: 0.8408\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.85075\n",
            "Epoch 27/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.1881 - accuracy: 0.9367 - val_loss: 0.6794 - val_accuracy: 0.8159\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.85075\n",
            "Epoch 28/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.2046 - accuracy: 0.9253 - val_loss: 0.5328 - val_accuracy: 0.8408\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.85075\n",
            "Epoch 29/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.1508 - accuracy: 0.9475 - val_loss: 0.8074 - val_accuracy: 0.7711\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.85075\n",
            "Epoch 30/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.1723 - accuracy: 0.9356 - val_loss: 0.4936 - val_accuracy: 0.8507\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.85075\n",
            "Epoch 31/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.1476 - accuracy: 0.9496 - val_loss: 0.4437 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.85075 to 0.86070, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 32/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.1366 - accuracy: 0.9540 - val_loss: 0.5721 - val_accuracy: 0.8209\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.86070\n",
            "Epoch 33/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.1611 - accuracy: 0.9480 - val_loss: 0.5690 - val_accuracy: 0.8159\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.86070\n",
            "Epoch 34/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.1346 - accuracy: 0.9545 - val_loss: 0.6710 - val_accuracy: 0.8507\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.86070\n",
            "Epoch 35/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.1156 - accuracy: 0.9567 - val_loss: 0.9416 - val_accuracy: 0.7711\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.86070\n",
            "Epoch 36/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.1226 - accuracy: 0.9529 - val_loss: 0.6879 - val_accuracy: 0.8010\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.86070\n",
            "Epoch 37/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.1253 - accuracy: 0.9583 - val_loss: 0.4399 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.86070 to 0.87562, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 38/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0778 - accuracy: 0.9762 - val_loss: 0.4598 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.87562 to 0.88060, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 39/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.1134 - accuracy: 0.9610 - val_loss: 0.5172 - val_accuracy: 0.8358\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.88060\n",
            "Epoch 40/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.1486 - accuracy: 0.9491 - val_loss: 0.8267 - val_accuracy: 0.8010\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.88060\n",
            "Epoch 41/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.1098 - accuracy: 0.9605 - val_loss: 0.6808 - val_accuracy: 0.8259\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.88060\n",
            "Epoch 42/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0790 - accuracy: 0.9718 - val_loss: 0.3573 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.88060 to 0.89055, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 43/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0901 - accuracy: 0.9708 - val_loss: 0.4759 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89055\n",
            "Epoch 44/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0605 - accuracy: 0.9773 - val_loss: 0.4461 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89055\n",
            "Epoch 45/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0732 - accuracy: 0.9735 - val_loss: 0.5720 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89055\n",
            "Epoch 46/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0799 - accuracy: 0.9664 - val_loss: 0.5494 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89055\n",
            "Epoch 47/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.1159 - accuracy: 0.9610 - val_loss: 0.9097 - val_accuracy: 0.8308\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89055\n",
            "Epoch 48/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0917 - accuracy: 0.9653 - val_loss: 0.8199 - val_accuracy: 0.8109\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89055\n",
            "Epoch 49/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.1168 - accuracy: 0.9605 - val_loss: 0.9264 - val_accuracy: 0.8010\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89055\n",
            "Epoch 50/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.1435 - accuracy: 0.9518 - val_loss: 0.6867 - val_accuracy: 0.8557\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89055\n",
            "Epoch 51/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.1011 - accuracy: 0.9681 - val_loss: 0.4458 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.89055 to 0.90050, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 52/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0813 - accuracy: 0.9681 - val_loss: 0.4619 - val_accuracy: 0.8507\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.90050\n",
            "Epoch 53/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0725 - accuracy: 0.9762 - val_loss: 0.4397 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.90050\n",
            "Epoch 54/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.0699 - accuracy: 0.9713 - val_loss: 0.7170 - val_accuracy: 0.8259\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.90050\n",
            "Epoch 55/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0749 - accuracy: 0.9751 - val_loss: 0.4908 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.90050\n",
            "Epoch 56/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0812 - accuracy: 0.9686 - val_loss: 0.6706 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.90050\n",
            "Epoch 57/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0849 - accuracy: 0.9708 - val_loss: 0.5232 - val_accuracy: 0.8557\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.90050\n",
            "Epoch 58/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0547 - accuracy: 0.9789 - val_loss: 0.4072 - val_accuracy: 0.8557\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.90050\n",
            "Epoch 59/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0330 - accuracy: 0.9886 - val_loss: 0.4142 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.90050\n",
            "Epoch 60/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.0404 - accuracy: 0.9854 - val_loss: 0.3347 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.90050\n",
            "Epoch 61/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0345 - accuracy: 0.9870 - val_loss: 0.4033 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.90050 to 0.91542, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 62/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0996 - accuracy: 0.9686 - val_loss: 0.5581 - val_accuracy: 0.8458\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91542\n",
            "Epoch 63/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.1243 - accuracy: 0.9578 - val_loss: 0.9001 - val_accuracy: 0.8060\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91542\n",
            "Epoch 64/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.0816 - accuracy: 0.9708 - val_loss: 0.7272 - val_accuracy: 0.8408\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91542\n",
            "Epoch 65/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0766 - accuracy: 0.9724 - val_loss: 0.8118 - val_accuracy: 0.7960\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91542\n",
            "Epoch 66/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0907 - accuracy: 0.9729 - val_loss: 0.4466 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91542\n",
            "Epoch 67/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0667 - accuracy: 0.9778 - val_loss: 0.5571 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91542\n",
            "Epoch 68/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0530 - accuracy: 0.9805 - val_loss: 0.3641 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91542\n",
            "Epoch 69/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0332 - accuracy: 0.9881 - val_loss: 0.4444 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91542\n",
            "Epoch 70/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0511 - accuracy: 0.9827 - val_loss: 0.4309 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91542\n",
            "Epoch 71/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0663 - accuracy: 0.9778 - val_loss: 0.6893 - val_accuracy: 0.8408\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91542\n",
            "Epoch 72/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0494 - accuracy: 0.9827 - val_loss: 0.5113 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91542\n",
            "Epoch 73/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0623 - accuracy: 0.9767 - val_loss: 0.6767 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91542\n",
            "Epoch 74/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0314 - accuracy: 0.9892 - val_loss: 0.4368 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91542\n",
            "Epoch 75/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0320 - accuracy: 0.9892 - val_loss: 0.4405 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91542\n",
            "Epoch 76/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.6667 - val_accuracy: 0.8308\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91542\n",
            "Epoch 77/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0390 - accuracy: 0.9870 - val_loss: 0.4997 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91542\n",
            "Epoch 78/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0725 - accuracy: 0.9762 - val_loss: 0.7362 - val_accuracy: 0.8408\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91542\n",
            "Epoch 79/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.1104 - accuracy: 0.9648 - val_loss: 0.7138 - val_accuracy: 0.8557\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91542\n",
            "Epoch 80/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0710 - accuracy: 0.9767 - val_loss: 0.5396 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91542\n",
            "Epoch 81/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0290 - accuracy: 0.9886 - val_loss: 0.4842 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91542\n",
            "Epoch 82/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0579 - accuracy: 0.9778 - val_loss: 0.5365 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91542\n",
            "Epoch 83/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.1026 - accuracy: 0.9670 - val_loss: 0.8908 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91542\n",
            "Epoch 84/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0612 - accuracy: 0.9783 - val_loss: 0.6410 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91542\n",
            "Epoch 85/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0307 - accuracy: 0.9875 - val_loss: 0.5235 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91542\n",
            "Epoch 86/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0218 - accuracy: 0.9951 - val_loss: 0.5041 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91542\n",
            "Epoch 87/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.3390 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.91542 to 0.92040, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 88/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 0.4902 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.92040\n",
            "Epoch 89/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.4839 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.92040\n",
            "Epoch 90/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.5144 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.92040\n",
            "Epoch 91/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.6664 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.92040\n",
            "Epoch 92/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 0.5204 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.92040\n",
            "Epoch 93/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.3529 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.92040\n",
            "Epoch 94/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0293 - accuracy: 0.9897 - val_loss: 0.6252 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.92040\n",
            "Epoch 95/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.4889 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.92040\n",
            "Epoch 96/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.0406 - accuracy: 0.9854 - val_loss: 0.5513 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.92040\n",
            "Epoch 97/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.0966 - accuracy: 0.9686 - val_loss: 1.5896 - val_accuracy: 0.7065\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.92040\n",
            "Epoch 98/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0625 - accuracy: 0.9816 - val_loss: 0.4173 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.92040\n",
            "Epoch 99/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0692 - accuracy: 0.9740 - val_loss: 0.5457 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.92040\n",
            "Epoch 100/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0546 - accuracy: 0.9811 - val_loss: 0.4157 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.92040\n",
            "Epoch 101/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.0662 - accuracy: 0.9783 - val_loss: 0.5041 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.92040\n",
            "Epoch 102/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.0776 - accuracy: 0.9751 - val_loss: 0.7477 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.92040\n",
            "Epoch 103/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0523 - accuracy: 0.9843 - val_loss: 0.6135 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.92040\n",
            "Epoch 104/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.0391 - accuracy: 0.9848 - val_loss: 0.6899 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.92040\n",
            "Epoch 105/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.2301 - val_accuracy: 0.9403\n",
            "\n",
            "Epoch 00105: val_accuracy improved from 0.92040 to 0.94030, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 106/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.2190 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.94030\n",
            "Epoch 107/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.7026 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.94030\n",
            "Epoch 108/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0347 - accuracy: 0.9875 - val_loss: 0.5426 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.94030\n",
            "Epoch 109/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0250 - accuracy: 0.9940 - val_loss: 0.4270 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.94030\n",
            "Epoch 110/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0332 - accuracy: 0.9886 - val_loss: 0.5871 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.94030\n",
            "Epoch 111/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0531 - accuracy: 0.9821 - val_loss: 0.7853 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.94030\n",
            "Epoch 112/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0308 - accuracy: 0.9913 - val_loss: 0.5074 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.94030\n",
            "Epoch 113/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0288 - accuracy: 0.9903 - val_loss: 0.5403 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.94030\n",
            "Epoch 114/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0424 - accuracy: 0.9875 - val_loss: 0.4633 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.94030\n",
            "Epoch 115/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0536 - accuracy: 0.9821 - val_loss: 0.6293 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.94030\n",
            "Epoch 116/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0433 - accuracy: 0.9881 - val_loss: 0.7884 - val_accuracy: 0.8458\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.94030\n",
            "Epoch 117/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0343 - accuracy: 0.9903 - val_loss: 0.5747 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.94030\n",
            "Epoch 118/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0488 - accuracy: 0.9875 - val_loss: 1.3952 - val_accuracy: 0.6816\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.94030\n",
            "Epoch 119/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0311 - accuracy: 0.9897 - val_loss: 0.6200 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.94030\n",
            "Epoch 120/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.6525 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.94030\n",
            "Epoch 121/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0288 - accuracy: 0.9886 - val_loss: 0.8061 - val_accuracy: 0.8557\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.94030\n",
            "Epoch 122/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0770 - accuracy: 0.9767 - val_loss: 0.6014 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.94030\n",
            "Epoch 123/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0418 - accuracy: 0.9881 - val_loss: 0.8079 - val_accuracy: 0.8507\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.94030\n",
            "Epoch 124/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0447 - accuracy: 0.9854 - val_loss: 0.5611 - val_accuracy: 0.8507\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.94030\n",
            "Epoch 125/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0312 - accuracy: 0.9892 - val_loss: 0.3552 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.94030\n",
            "Epoch 126/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.3482 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.94030\n",
            "Epoch 127/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0087 - accuracy: 0.9984 - val_loss: 0.3464 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.94030\n",
            "Epoch 128/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0069 - accuracy: 0.9973 - val_loss: 0.3268 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.94030\n",
            "Epoch 129/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.3767 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.94030\n",
            "Epoch 130/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.3562 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.94030\n",
            "Epoch 131/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.3552 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.94030\n",
            "Epoch 132/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.5018 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.94030\n",
            "Epoch 133/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 0.4935 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.94030\n",
            "Epoch 134/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0169 - accuracy: 0.9935 - val_loss: 0.5038 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.94030\n",
            "Epoch 135/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0471 - accuracy: 0.9838 - val_loss: 0.7414 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.94030\n",
            "Epoch 136/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0837 - accuracy: 0.9746 - val_loss: 1.8745 - val_accuracy: 0.7761\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.94030\n",
            "Epoch 137/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0940 - accuracy: 0.9697 - val_loss: 0.6592 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.94030\n",
            "Epoch 138/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0177 - accuracy: 0.9924 - val_loss: 0.5039 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.94030\n",
            "Epoch 139/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0358 - accuracy: 0.9870 - val_loss: 0.4638 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.94030\n",
            "Epoch 140/500\n",
            "58/58 [==============================] - 12s 209ms/step - loss: 0.0202 - accuracy: 0.9951 - val_loss: 0.4465 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.94030\n",
            "Epoch 141/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0284 - accuracy: 0.9886 - val_loss: 0.6039 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.94030\n",
            "Epoch 142/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 0.5402 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.94030\n",
            "Epoch 143/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.4023 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.94030\n",
            "Epoch 144/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.4233 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.94030\n",
            "Epoch 145/500\n",
            "58/58 [==============================] - 12s 199ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.7145 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.94030\n",
            "Epoch 146/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.94030\n",
            "Epoch 147/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.94030\n",
            "Epoch 148/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0097 - accuracy: 0.9957 - val_loss: 0.5694 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.94030\n",
            "Epoch 149/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.5889 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.94030\n",
            "Epoch 150/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0059 - accuracy: 0.9973 - val_loss: 0.4904 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.94030\n",
            "Epoch 151/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.4138 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.94030\n",
            "Epoch 152/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.94030\n",
            "Epoch 153/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0067 - accuracy: 0.9973 - val_loss: 0.4782 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.94030\n",
            "Epoch 154/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0193 - accuracy: 0.9919 - val_loss: 0.8799 - val_accuracy: 0.8507\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.94030\n",
            "Epoch 155/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0435 - accuracy: 0.9865 - val_loss: 1.0525 - val_accuracy: 0.7960\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.94030\n",
            "Epoch 156/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0478 - accuracy: 0.9811 - val_loss: 0.4357 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.94030\n",
            "Epoch 157/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0479 - accuracy: 0.9859 - val_loss: 0.9892 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.94030\n",
            "Epoch 158/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0346 - accuracy: 0.9875 - val_loss: 0.6245 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.94030\n",
            "Epoch 159/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0321 - accuracy: 0.9892 - val_loss: 0.4849 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.94030\n",
            "Epoch 160/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.8811 - val_accuracy: 0.8458\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.94030\n",
            "Epoch 161/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0300 - accuracy: 0.9897 - val_loss: 0.9122 - val_accuracy: 0.8109\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.94030\n",
            "Epoch 162/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.3720 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.94030\n",
            "Epoch 163/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.5013 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.94030\n",
            "Epoch 164/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0192 - accuracy: 0.9930 - val_loss: 0.4293 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.94030\n",
            "Epoch 165/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0219 - accuracy: 0.9930 - val_loss: 0.5022 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.94030\n",
            "Epoch 166/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.4494 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.94030\n",
            "Epoch 167/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.4480 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.94030\n",
            "Epoch 168/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.4789 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.94030\n",
            "Epoch 169/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.5071 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.94030\n",
            "Epoch 170/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0068 - accuracy: 0.9968 - val_loss: 0.5427 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.94030\n",
            "Epoch 171/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.8822 - val_accuracy: 0.8209\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.94030\n",
            "Epoch 172/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0184 - accuracy: 0.9957 - val_loss: 0.4926 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.94030\n",
            "Epoch 173/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.6646 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.94030\n",
            "Epoch 174/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0305 - accuracy: 0.9875 - val_loss: 1.0196 - val_accuracy: 0.7960\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.94030\n",
            "Epoch 175/500\n",
            "58/58 [==============================] - 12s 200ms/step - loss: 0.0584 - accuracy: 0.9783 - val_loss: 0.6893 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.94030\n",
            "Epoch 176/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0676 - accuracy: 0.9778 - val_loss: 0.5277 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.94030\n",
            "Epoch 177/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0407 - accuracy: 0.9892 - val_loss: 0.4828 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.94030\n",
            "Epoch 178/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0426 - accuracy: 0.9859 - val_loss: 0.6551 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.94030\n",
            "Epoch 179/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0353 - accuracy: 0.9913 - val_loss: 0.4064 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.94030\n",
            "Epoch 180/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.4501 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.94030\n",
            "Epoch 181/500\n",
            "58/58 [==============================] - 12s 208ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.94030\n",
            "Epoch 182/500\n",
            "58/58 [==============================] - 12s 207ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.4177 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.94030\n",
            "Epoch 183/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9403\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.94030\n",
            "Epoch 184/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0090 - accuracy: 0.9962 - val_loss: 0.5082 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.94030\n",
            "Epoch 185/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.3962 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.94030\n",
            "Epoch 186/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.94030\n",
            "Epoch 187/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.4401 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.94030\n",
            "Epoch 188/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0214 - accuracy: 0.9946 - val_loss: 0.7674 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.94030\n",
            "Epoch 189/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.6306 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.94030\n",
            "Epoch 190/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0140 - accuracy: 0.9924 - val_loss: 0.5201 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.94030\n",
            "Epoch 191/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.5151 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.94030\n",
            "Epoch 192/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0298 - accuracy: 0.9924 - val_loss: 0.7158 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.94030\n",
            "Epoch 193/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.8042 - val_accuracy: 0.8507\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.94030\n",
            "Epoch 194/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0213 - accuracy: 0.9919 - val_loss: 1.1158 - val_accuracy: 0.7910\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.94030\n",
            "Epoch 195/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0386 - accuracy: 0.9870 - val_loss: 0.6725 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.94030\n",
            "Epoch 196/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0456 - accuracy: 0.9865 - val_loss: 0.7007 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.94030\n",
            "Epoch 197/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0262 - accuracy: 0.9886 - val_loss: 0.4760 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.94030\n",
            "Epoch 198/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.8081 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.94030\n",
            "Epoch 199/500\n",
            "58/58 [==============================] - 12s 208ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 0.5843 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.94030\n",
            "Epoch 200/500\n",
            "58/58 [==============================] - 12s 209ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.3170 - val_accuracy: 0.9403\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.94030\n",
            "Epoch 201/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.3046 - val_accuracy: 0.9403\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.94030\n",
            "Epoch 202/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.4507 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.94030\n",
            "Epoch 203/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5894 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.94030\n",
            "Epoch 204/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.8332 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.94030\n",
            "Epoch 205/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0574 - accuracy: 0.9827 - val_loss: 0.7301 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.94030\n",
            "Epoch 206/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0365 - accuracy: 0.9881 - val_loss: 0.6039 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.94030\n",
            "Epoch 207/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0183 - accuracy: 0.9930 - val_loss: 0.5767 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.94030\n",
            "Epoch 208/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0198 - accuracy: 0.9924 - val_loss: 0.5631 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.94030\n",
            "Epoch 209/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.8300 - val_accuracy: 0.8358\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.94030\n",
            "Epoch 210/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 0.3612 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.94030\n",
            "Epoch 211/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.4794 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.94030\n",
            "Epoch 212/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.4352 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.94030\n",
            "Epoch 213/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.3536 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.94030\n",
            "Epoch 214/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.3871 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.94030\n",
            "Epoch 215/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.3818 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.94030\n",
            "Epoch 216/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.3581 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.94030\n",
            "Epoch 217/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.3667 - val_accuracy: 0.9403\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.94030\n",
            "Epoch 218/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0105 - accuracy: 0.9984 - val_loss: 0.3965 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.94030\n",
            "Epoch 219/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.3255 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.94030\n",
            "Epoch 220/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.3925 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.94030\n",
            "Epoch 221/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.3978 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.94030\n",
            "Epoch 222/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.5526 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.94030\n",
            "Epoch 223/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.5596 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.94030\n",
            "Epoch 224/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0328 - accuracy: 0.9908 - val_loss: 0.6759 - val_accuracy: 0.8557\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.94030\n",
            "Epoch 225/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.5075 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.94030\n",
            "Epoch 226/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0446 - accuracy: 0.9875 - val_loss: 0.6498 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.94030\n",
            "Epoch 227/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.5412 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.94030\n",
            "Epoch 228/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.7485 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.94030\n",
            "Epoch 229/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0475 - accuracy: 0.9859 - val_loss: 0.4803 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.94030\n",
            "Epoch 230/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0468 - accuracy: 0.9854 - val_loss: 1.0285 - val_accuracy: 0.8358\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.94030\n",
            "Epoch 231/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0285 - accuracy: 0.9919 - val_loss: 0.5598 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.94030\n",
            "Epoch 232/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.4594 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.94030\n",
            "Epoch 233/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.4490 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.94030\n",
            "Epoch 234/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0065 - accuracy: 0.9962 - val_loss: 0.3587 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.94030\n",
            "Epoch 235/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.3503 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.94030\n",
            "Epoch 236/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.2944 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.94030\n",
            "Epoch 237/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.3428 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.94030\n",
            "Epoch 238/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.5271 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.94030\n",
            "Epoch 239/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.4243 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.94030\n",
            "Epoch 240/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.3648 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.94030\n",
            "Epoch 241/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.4894 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.94030\n",
            "Epoch 242/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0099 - accuracy: 0.9962 - val_loss: 0.5974 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.94030\n",
            "Epoch 243/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0182 - accuracy: 0.9962 - val_loss: 0.5080 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.94030\n",
            "Epoch 244/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.4706 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.94030\n",
            "Epoch 245/500\n",
            "58/58 [==============================] - 12s 210ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.6151 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.94030\n",
            "Epoch 246/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.5493 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.94030\n",
            "Epoch 247/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.4552 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.94030\n",
            "Epoch 248/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.4379 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.94030\n",
            "Epoch 249/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 0.3986 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.94030\n",
            "Epoch 250/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.5386 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.94030\n",
            "Epoch 251/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.5027 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.94030\n",
            "Epoch 252/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0086 - accuracy: 0.9962 - val_loss: 0.5263 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.94030\n",
            "Epoch 253/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.6160 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.94030\n",
            "Epoch 254/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0273 - accuracy: 0.9919 - val_loss: 0.6967 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.94030\n",
            "Epoch 255/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0428 - accuracy: 0.9875 - val_loss: 0.8818 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.94030\n",
            "Epoch 256/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0353 - accuracy: 0.9865 - val_loss: 0.7045 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.94030\n",
            "Epoch 257/500\n",
            "58/58 [==============================] - 12s 211ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.7423 - val_accuracy: 0.8458\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.94030\n",
            "Epoch 258/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0115 - accuracy: 0.9951 - val_loss: 0.6587 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.94030\n",
            "Epoch 259/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0095 - accuracy: 0.9962 - val_loss: 0.3266 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.94030\n",
            "Epoch 260/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.3636 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.94030\n",
            "Epoch 261/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0202 - accuracy: 0.9946 - val_loss: 0.5395 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.94030\n",
            "Epoch 262/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.7232 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.94030\n",
            "Epoch 263/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.6036 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.94030\n",
            "Epoch 264/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0106 - accuracy: 0.9978 - val_loss: 0.6045 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.94030\n",
            "Epoch 265/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0061 - accuracy: 0.9973 - val_loss: 0.5488 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.94030\n",
            "Epoch 266/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.4861 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.94030\n",
            "Epoch 267/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0174 - accuracy: 0.9935 - val_loss: 0.5523 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.94030\n",
            "Epoch 268/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.5474 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.94030\n",
            "Epoch 269/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5639 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.94030\n",
            "Epoch 270/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.4192 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.94030\n",
            "Epoch 271/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.5598 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.94030\n",
            "Epoch 272/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.6845 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.94030\n",
            "Epoch 273/500\n",
            "58/58 [==============================] - 12s 207ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.6001 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.94030\n",
            "Epoch 274/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.4427 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.94030\n",
            "Epoch 275/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.5367 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.94030\n",
            "Epoch 276/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.6327 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.94030\n",
            "Epoch 277/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0234 - accuracy: 0.9908 - val_loss: 2.1403 - val_accuracy: 0.6020\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.94030\n",
            "Epoch 278/500\n",
            "58/58 [==============================] - 12s 201ms/step - loss: 0.0325 - accuracy: 0.9892 - val_loss: 0.7277 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.94030\n",
            "Epoch 279/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0325 - accuracy: 0.9903 - val_loss: 0.4468 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.94030\n",
            "Epoch 280/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.3947 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.94030\n",
            "Epoch 281/500\n",
            "58/58 [==============================] - 12s 210ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.5056 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.94030\n",
            "Epoch 282/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.94030\n",
            "Epoch 283/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0069 - accuracy: 0.9968 - val_loss: 0.5636 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.94030\n",
            "Epoch 284/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0172 - accuracy: 0.9924 - val_loss: 0.7069 - val_accuracy: 0.8557\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.94030\n",
            "Epoch 285/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.7106 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.94030\n",
            "Epoch 286/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.5612 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.94030\n",
            "Epoch 287/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.6294 - val_accuracy: 0.8557\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.94030\n",
            "Epoch 288/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.5273 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.94030\n",
            "Epoch 289/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 1.2577 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.94030\n",
            "Epoch 290/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0164 - accuracy: 0.9940 - val_loss: 0.4815 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.94030\n",
            "Epoch 291/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.4744 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.94030\n",
            "Epoch 292/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.7400 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.94030\n",
            "Epoch 293/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.6978 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.94030\n",
            "Epoch 294/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.5833 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.94030\n",
            "Epoch 295/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0159 - accuracy: 0.9924 - val_loss: 0.7275 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.94030\n",
            "Epoch 296/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0182 - accuracy: 0.9930 - val_loss: 0.7147 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.94030\n",
            "Epoch 297/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 0.5496 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.94030\n",
            "Epoch 298/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0228 - accuracy: 0.9946 - val_loss: 0.3738 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.94030\n",
            "Epoch 299/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.5073 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.94030\n",
            "Epoch 300/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.3596 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.94030\n",
            "Epoch 301/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.3727 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.94030\n",
            "Epoch 302/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.94030\n",
            "Epoch 303/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.4000 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.94030\n",
            "Epoch 304/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.4344 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.94030\n",
            "Epoch 305/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 7.4481e-04 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.94030\n",
            "Epoch 306/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 3.2597e-04 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.94030\n",
            "Epoch 307/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.4534 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.94030\n",
            "Epoch 308/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.3435 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.94030\n",
            "Epoch 309/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4825 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.94030\n",
            "Epoch 310/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.4329 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.94030\n",
            "Epoch 311/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.3268 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.94030\n",
            "Epoch 312/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.2629 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.94030\n",
            "Epoch 313/500\n",
            "58/58 [==============================] - 12s 213ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.94030\n",
            "Epoch 314/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.3450 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.94030\n",
            "Epoch 315/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.4871 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.94030\n",
            "Epoch 316/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.5635 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.94030\n",
            "Epoch 317/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.3131 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.94030\n",
            "Epoch 318/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.4590 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.94030\n",
            "Epoch 319/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.5983 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.94030\n",
            "Epoch 320/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0437 - accuracy: 0.9886 - val_loss: 0.8308 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.94030\n",
            "Epoch 321/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 0.7079 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.94030\n",
            "Epoch 322/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0196 - accuracy: 0.9919 - val_loss: 0.6829 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.94030\n",
            "Epoch 323/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.7716 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.94030\n",
            "Epoch 324/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.6043 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.94030\n",
            "Epoch 325/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.6792 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.94030\n",
            "Epoch 326/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.5036 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.94030\n",
            "Epoch 327/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.3955 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.94030\n",
            "Epoch 328/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4753 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.94030\n",
            "Epoch 329/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 6.8953e-04 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.94030\n",
            "Epoch 330/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0109 - accuracy: 0.9978 - val_loss: 0.6374 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.94030\n",
            "Epoch 331/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6368 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.94030\n",
            "Epoch 332/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.8838 - val_accuracy: 0.8358\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.94030\n",
            "Epoch 333/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.5689 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.94030\n",
            "Epoch 334/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.5801 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.94030\n",
            "Epoch 335/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.3794 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.94030\n",
            "Epoch 336/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.5803 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.94030\n",
            "Epoch 337/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.4333 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.94030\n",
            "Epoch 338/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.4070 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.94030\n",
            "Epoch 339/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0374 - accuracy: 0.9897 - val_loss: 1.3367 - val_accuracy: 0.7811\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.94030\n",
            "Epoch 340/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0279 - accuracy: 0.9919 - val_loss: 1.0497 - val_accuracy: 0.8060\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.94030\n",
            "Epoch 341/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.3840 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.94030\n",
            "Epoch 342/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.4960 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.94030\n",
            "Epoch 343/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0065 - accuracy: 0.9968 - val_loss: 0.5657 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.94030\n",
            "Epoch 344/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.3726 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.94030\n",
            "Epoch 345/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0054 - accuracy: 0.9978 - val_loss: 0.2724 - val_accuracy: 0.9403\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.94030\n",
            "Epoch 346/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.4068 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.94030\n",
            "Epoch 347/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.4573 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.94030\n",
            "Epoch 348/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0054 - accuracy: 0.9973 - val_loss: 0.4232 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.94030\n",
            "Epoch 349/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.7638 - val_accuracy: 0.8607\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.94030\n",
            "Epoch 350/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0202 - accuracy: 0.9924 - val_loss: 0.4260 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.94030\n",
            "Epoch 351/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.7429 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.94030\n",
            "Epoch 352/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.94030\n",
            "Epoch 353/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.4709 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.94030\n",
            "Epoch 354/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.94030\n",
            "Epoch 355/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 8.1296e-04 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9453\n",
            "\n",
            "Epoch 00355: val_accuracy improved from 0.94030 to 0.94527, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5\n",
            "Epoch 356/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 4.0935e-04 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.94527\n",
            "Epoch 357/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.3823 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.94527\n",
            "Epoch 358/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.6968 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.94527\n",
            "Epoch 359/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 1.0428 - val_accuracy: 0.7811\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.94527\n",
            "Epoch 360/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.5036 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.94527\n",
            "Epoch 361/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.4150 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.94527\n",
            "Epoch 362/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.6007 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.94527\n",
            "Epoch 363/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0076 - accuracy: 0.9951 - val_loss: 0.9847 - val_accuracy: 0.8458\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.94527\n",
            "Epoch 364/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0202 - accuracy: 0.9946 - val_loss: 0.6044 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.94527\n",
            "Epoch 365/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0309 - accuracy: 0.9897 - val_loss: 0.5449 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.94527\n",
            "Epoch 366/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0326 - accuracy: 0.9881 - val_loss: 0.6228 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.94527\n",
            "Epoch 367/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0104 - accuracy: 0.9951 - val_loss: 0.5715 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.94527\n",
            "Epoch 368/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.8554 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.94527\n",
            "Epoch 369/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.5418 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.94527\n",
            "Epoch 370/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.6269 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.94527\n",
            "Epoch 371/500\n",
            "58/58 [==============================] - 12s 202ms/step - loss: 0.0086 - accuracy: 0.9962 - val_loss: 0.5444 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.94527\n",
            "Epoch 372/500\n",
            "58/58 [==============================] - 12s 213ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.4681 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.94527\n",
            "Epoch 373/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.4940 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.94527\n",
            "Epoch 374/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 8.6571e-04 - accuracy: 1.0000 - val_loss: 0.5231 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.94527\n",
            "Epoch 375/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4521 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.94527\n",
            "Epoch 376/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4729 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.94527\n",
            "Epoch 377/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 4.6013e-04 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.94527\n",
            "Epoch 378/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4601 - val_accuracy: 0.9453\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.94527\n",
            "Epoch 379/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.6253 - val_accuracy: 0.8557\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.94527\n",
            "Epoch 380/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0309 - accuracy: 0.9897 - val_loss: 0.9771 - val_accuracy: 0.8408\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.94527\n",
            "Epoch 381/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.4582 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.94527\n",
            "Epoch 382/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0235 - accuracy: 0.9913 - val_loss: 0.6382 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.94527\n",
            "Epoch 383/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.6454 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.94527\n",
            "Epoch 384/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0064 - accuracy: 0.9973 - val_loss: 0.4279 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.94527\n",
            "Epoch 385/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0127 - accuracy: 0.9978 - val_loss: 0.4392 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.94527\n",
            "Epoch 386/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.4155 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94527\n",
            "Epoch 387/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.4992 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94527\n",
            "Epoch 388/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 0.9403\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94527\n",
            "Epoch 389/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.3469 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94527\n",
            "Epoch 390/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.4781 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94527\n",
            "Epoch 391/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4013 - val_accuracy: 0.9403\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94527\n",
            "Epoch 392/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.5343 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94527\n",
            "Epoch 393/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 6.1506e-04 - accuracy: 1.0000 - val_loss: 0.5201 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94527\n",
            "Epoch 394/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.5834 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94527\n",
            "Epoch 395/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.9675 - val_accuracy: 0.8358\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94527\n",
            "Epoch 396/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0159 - accuracy: 0.9973 - val_loss: 0.3516 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94527\n",
            "Epoch 397/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94527\n",
            "Epoch 398/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.3893 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94527\n",
            "Epoch 399/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 9.7933e-04 - accuracy: 0.9995 - val_loss: 0.3626 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.94527\n",
            "Epoch 400/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 7.8106e-04 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94527\n",
            "Epoch 401/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.3449 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94527\n",
            "Epoch 402/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0051 - accuracy: 0.9978 - val_loss: 0.4082 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94527\n",
            "Epoch 403/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.3960 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94527\n",
            "Epoch 404/500\n",
            "58/58 [==============================] - 12s 211ms/step - loss: 0.0257 - accuracy: 0.9946 - val_loss: 0.7849 - val_accuracy: 0.8557\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94527\n",
            "Epoch 405/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0232 - accuracy: 0.9930 - val_loss: 1.1163 - val_accuracy: 0.8259\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94527\n",
            "Epoch 406/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.4001 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94527\n",
            "Epoch 407/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0177 - accuracy: 0.9968 - val_loss: 0.6330 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94527\n",
            "Epoch 408/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0314 - accuracy: 0.9940 - val_loss: 1.2310 - val_accuracy: 0.8209\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94527\n",
            "Epoch 409/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.6185 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94527\n",
            "Epoch 410/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.7507 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94527\n",
            "Epoch 411/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.5435 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94527\n",
            "Epoch 412/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0168 - accuracy: 0.9968 - val_loss: 0.4948 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94527\n",
            "Epoch 413/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.4945 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94527\n",
            "Epoch 414/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0221 - accuracy: 0.9940 - val_loss: 0.9132 - val_accuracy: 0.8557\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94527\n",
            "Epoch 415/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.7199 - val_accuracy: 0.8259\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94527\n",
            "Epoch 416/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.8071 - val_accuracy: 0.8308\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94527\n",
            "Epoch 417/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0042 - accuracy: 0.9978 - val_loss: 0.5179 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94527\n",
            "Epoch 418/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94527\n",
            "Epoch 419/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 6.5448e-04 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94527\n",
            "Epoch 420/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 2.2128e-04 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94527\n",
            "Epoch 421/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 2.2260e-04 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94527\n",
            "Epoch 422/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 1.7487e-04 - accuracy: 1.0000 - val_loss: 0.3874 - val_accuracy: 0.9403\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94527\n",
            "Epoch 423/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 1.8259e-04 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94527\n",
            "Epoch 424/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 3.3076e-04 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94527\n",
            "Epoch 425/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 4.9753e-04 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9403\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94527\n",
            "Epoch 426/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 2.6735e-04 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94527\n",
            "Epoch 427/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 3.2328e-04 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9453\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94527\n",
            "Epoch 428/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 1.1731e-04 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94527\n",
            "Epoch 429/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.4985 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94527\n",
            "Epoch 430/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.5127 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94527\n",
            "Epoch 431/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.7041 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94527\n",
            "Epoch 432/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0121 - accuracy: 0.9984 - val_loss: 0.3977 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94527\n",
            "Epoch 433/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 0.5341 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94527\n",
            "Epoch 434/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.6163 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94527\n",
            "Epoch 435/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.3858 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94527\n",
            "Epoch 436/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0117 - accuracy: 0.9984 - val_loss: 0.3852 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94527\n",
            "Epoch 437/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.8059 - val_accuracy: 0.8458\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94527\n",
            "Epoch 438/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 1.2349 - val_accuracy: 0.7015\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94527\n",
            "Epoch 439/500\n",
            "58/58 [==============================] - 12s 207ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.7150 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94527\n",
            "Epoch 440/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.5190 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94527\n",
            "Epoch 441/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.4468 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94527\n",
            "Epoch 442/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0104 - accuracy: 0.9989 - val_loss: 0.4966 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94527\n",
            "Epoch 443/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.7739 - val_accuracy: 0.8408\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94527\n",
            "Epoch 444/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 0.5499 - val_accuracy: 0.8856\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94527\n",
            "Epoch 445/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.3939 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94527\n",
            "Epoch 446/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.5726 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94527\n",
            "Epoch 447/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4529 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94527\n",
            "Epoch 448/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3587 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94527\n",
            "Epoch 449/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.4777 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94527\n",
            "Epoch 450/500\n",
            "58/58 [==============================] - 12s 203ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.4204 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94527\n",
            "Epoch 451/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 2.1983e-04 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94527\n",
            "Epoch 452/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 2.3922e-04 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94527\n",
            "Epoch 453/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0114 - accuracy: 0.9978 - val_loss: 0.4127 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94527\n",
            "Epoch 454/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.4379 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94527\n",
            "Epoch 455/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.6367 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94527\n",
            "Epoch 456/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.6895 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94527\n",
            "Epoch 457/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.4937 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94527\n",
            "Epoch 458/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3142 - val_accuracy: 0.9403\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94527\n",
            "Epoch 459/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 4.9419e-04 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94527\n",
            "Epoch 460/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 0.0017 - accuracy: 0.9989 - val_loss: 0.4292 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94527\n",
            "Epoch 461/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 7.1975e-04 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94527\n",
            "Epoch 462/500\n",
            "58/58 [==============================] - 12s 204ms/step - loss: 5.4390e-04 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94527\n",
            "Epoch 463/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 2.8859e-04 - accuracy: 1.0000 - val_loss: 0.4777 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94527\n",
            "Epoch 464/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 1.8384e-04 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94527\n",
            "Epoch 465/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 2.9762e-04 - accuracy: 1.0000 - val_loss: 0.3707 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94527\n",
            "Epoch 466/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 4.9425e-04 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94527\n",
            "Epoch 467/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 1.1043e-04 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94527\n",
            "Epoch 468/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 1.5932e-04 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94527\n",
            "Epoch 469/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 5.2879e-05 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94527\n",
            "Epoch 470/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 2.3306e-04 - accuracy: 1.0000 - val_loss: 0.4586 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94527\n",
            "Epoch 471/500\n",
            "58/58 [==============================] - 12s 214ms/step - loss: 2.9990e-04 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94527\n",
            "Epoch 472/500\n",
            "58/58 [==============================] - 12s 207ms/step - loss: 9.4425e-05 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.9104\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94527\n",
            "Epoch 473/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 1.0703e-04 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94527\n",
            "Epoch 474/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 6.0656e-05 - accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94527\n",
            "Epoch 475/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 8.3978e-05 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94527\n",
            "Epoch 476/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 1.3644e-04 - accuracy: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94527\n",
            "Epoch 477/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 1.1824e-04 - accuracy: 1.0000 - val_loss: 0.3294 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94527\n",
            "Epoch 478/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 3.4453e-05 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94527\n",
            "Epoch 479/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 7.6989e-05 - accuracy: 1.0000 - val_loss: 0.3736 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94527\n",
            "Epoch 480/500\n",
            "58/58 [==============================] - 12s 207ms/step - loss: 2.7855e-05 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94527\n",
            "Epoch 481/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 7.9163e-05 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94527\n",
            "Epoch 482/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 1.4363e-04 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9403\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94527\n",
            "Epoch 483/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 2.8692e-04 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94527\n",
            "Epoch 484/500\n",
            "58/58 [==============================] - 12s 207ms/step - loss: 7.3696e-05 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94527\n",
            "Epoch 485/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 8.0315e-05 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94527\n",
            "Epoch 486/500\n",
            "58/58 [==============================] - 12s 207ms/step - loss: 7.0070e-04 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94527\n",
            "Epoch 487/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 4.3524e-04 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94527\n",
            "Epoch 488/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 9.8757e-05 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94527\n",
            "Epoch 489/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 8.7816e-05 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94527\n",
            "Epoch 490/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 1.4236e-04 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94527\n",
            "Epoch 491/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 5.3580e-05 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94527\n",
            "Epoch 492/500\n",
            "58/58 [==============================] - 12s 207ms/step - loss: 3.0402e-05 - accuracy: 1.0000 - val_loss: 0.4522 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94527\n",
            "Epoch 493/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 5.8102e-05 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94527\n",
            "Epoch 494/500\n",
            "58/58 [==============================] - 12s 206ms/step - loss: 8.9459e-05 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94527\n",
            "Epoch 495/500\n",
            "58/58 [==============================] - 12s 207ms/step - loss: 1.5368e-04 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94527\n",
            "Epoch 496/500\n",
            "58/58 [==============================] - 12s 207ms/step - loss: 8.2880e-05 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94527\n",
            "Epoch 497/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 7.0556e-05 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9254\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94527\n",
            "Epoch 498/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 1.2606e-04 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94527\n",
            "Epoch 499/500\n",
            "58/58 [==============================] - 12s 207ms/step - loss: 3.8678e-05 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94527\n",
            "Epoch 500/500\n",
            "58/58 [==============================] - 12s 205ms/step - loss: 2.0051e-05 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9403\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1f327bccd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "42d97ef2-3c14-40e1-ff47-3aa2b4efe148"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0150_1_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24daafd2-96d6-47c1-df37-74c0348b3912"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1f8495-d6cc-49b9-bb7e-1d73b84731a7"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c522e641-f500-4084-93e8-f9813c9f6ddf"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "67a266f0-1d55-4121-bee1-13a341dc3ce9"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Validation_split_0.150_1_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Validation_split_0.150_1_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2ee61547-7c7c-4713-86e5-fe843bf7d93c\", \"Validation_split_0.150_1_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}