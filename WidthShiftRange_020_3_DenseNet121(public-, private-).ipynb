{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WidthShiftRange_020_3_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO6SoFIJoe16wDvSfDI9Vx0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/WidthShiftRange_020_3_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e27398a-174a-4ada-8bcf-f37a8f4e260e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug 31 16:00:56 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca872d3-be48-410b-eb4c-63902ff788ed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1e1532-3f04-4f4a-f0fa-06ba697222bc"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e58d14-df63-48f7-811e-1954c9344887"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.2,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2545ef13-9ada-4291-a1e6-27fbc4e723c6"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 38s 260ms/step - loss: 1.8061 - accuracy: 0.3721 - val_loss: 51.9232 - val_accuracy: 0.1034\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10345, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 1.2417 - accuracy: 0.5853 - val_loss: 42.7835 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.10345 to 0.11330, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.9592 - accuracy: 0.6760 - val_loss: 15.2052 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.11330\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.8662 - accuracy: 0.7028 - val_loss: 13.0692 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.11330\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.7516 - accuracy: 0.7540 - val_loss: 11.4897 - val_accuracy: 0.1330\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.11330 to 0.13300, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.6719 - accuracy: 0.7765 - val_loss: 23.5995 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.13300\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.5844 - accuracy: 0.8009 - val_loss: 6.4920 - val_accuracy: 0.2635\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.13300 to 0.26355, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.4833 - accuracy: 0.8410 - val_loss: 4.9852 - val_accuracy: 0.2783\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.26355 to 0.27833, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.4740 - accuracy: 0.8404 - val_loss: 5.5020 - val_accuracy: 0.3768\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.27833 to 0.37685, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.4507 - accuracy: 0.8465 - val_loss: 2.1314 - val_accuracy: 0.5296\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.37685 to 0.52956, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.4846 - accuracy: 0.8356 - val_loss: 1.5838 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.52956 to 0.61823, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.4130 - accuracy: 0.8618 - val_loss: 0.8512 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.61823 to 0.76847, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.4071 - accuracy: 0.8557 - val_loss: 0.9807 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.76847\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3339 - accuracy: 0.8892 - val_loss: 1.0642 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.76847\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.3162 - accuracy: 0.8855 - val_loss: 0.6975 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.76847 to 0.77586, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.2666 - accuracy: 0.9080 - val_loss: 0.7267 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.77586\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.3095 - accuracy: 0.8971 - val_loss: 1.2050 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.77586\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.3024 - accuracy: 0.8977 - val_loss: 1.2089 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.77586\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2851 - accuracy: 0.9032 - val_loss: 1.6850 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.77586\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.2462 - accuracy: 0.9208 - val_loss: 0.8013 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.77586\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2518 - accuracy: 0.9202 - val_loss: 0.5056 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.77586 to 0.86700, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.2169 - accuracy: 0.9257 - val_loss: 0.6746 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.86700\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.2012 - accuracy: 0.9385 - val_loss: 2.5871 - val_accuracy: 0.4975\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.86700\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2104 - accuracy: 0.9287 - val_loss: 0.6241 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.86700\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.2184 - accuracy: 0.9233 - val_loss: 1.0422 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.86700\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.2070 - accuracy: 0.9287 - val_loss: 0.6030 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.86700\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1591 - accuracy: 0.9495 - val_loss: 0.6858 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.86700\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1771 - accuracy: 0.9415 - val_loss: 0.6938 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.86700\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1909 - accuracy: 0.9415 - val_loss: 1.8170 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.86700\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1898 - accuracy: 0.9336 - val_loss: 1.3518 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.86700\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1924 - accuracy: 0.9373 - val_loss: 0.6247 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.86700\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1934 - accuracy: 0.9342 - val_loss: 1.1423 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.86700\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1349 - accuracy: 0.9580 - val_loss: 0.4542 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.86700 to 0.87931, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1393 - accuracy: 0.9549 - val_loss: 1.5034 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.87931\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.2433 - accuracy: 0.9166 - val_loss: 5.0733 - val_accuracy: 0.3892\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.87931\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1718 - accuracy: 0.9452 - val_loss: 0.6902 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.87931\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1443 - accuracy: 0.9531 - val_loss: 0.5169 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.87931\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1516 - accuracy: 0.9531 - val_loss: 0.8979 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.87931\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1388 - accuracy: 0.9513 - val_loss: 0.5193 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.87931\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1012 - accuracy: 0.9671 - val_loss: 0.7394 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.87931\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0851 - accuracy: 0.9726 - val_loss: 0.5292 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.87931\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0698 - accuracy: 0.9793 - val_loss: 0.4613 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.87931 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0971 - accuracy: 0.9659 - val_loss: 0.8147 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.88424\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1374 - accuracy: 0.9531 - val_loss: 0.7305 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.88424\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1168 - accuracy: 0.9592 - val_loss: 0.7198 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.88424\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1108 - accuracy: 0.9598 - val_loss: 0.5927 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.88424\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0900 - accuracy: 0.9714 - val_loss: 0.4376 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.88424\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1043 - accuracy: 0.9683 - val_loss: 1.0352 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.88424\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1113 - accuracy: 0.9555 - val_loss: 0.5407 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.88424\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0900 - accuracy: 0.9695 - val_loss: 0.4479 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.88424\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0828 - accuracy: 0.9695 - val_loss: 0.4755 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.88424\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0524 - accuracy: 0.9829 - val_loss: 0.3620 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.88424\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0491 - accuracy: 0.9854 - val_loss: 0.6107 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.88424\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0584 - accuracy: 0.9781 - val_loss: 0.4593 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.88424\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0607 - accuracy: 0.9787 - val_loss: 1.0112 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.88424\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0929 - accuracy: 0.9659 - val_loss: 1.1681 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.88424\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0962 - accuracy: 0.9635 - val_loss: 0.5864 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.88424\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0732 - accuracy: 0.9726 - val_loss: 0.8970 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.88424\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1238 - accuracy: 0.9549 - val_loss: 1.1907 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.88424\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0907 - accuracy: 0.9708 - val_loss: 0.5586 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.88424\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0466 - accuracy: 0.9860 - val_loss: 0.4758 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.88424 to 0.88916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0617 - accuracy: 0.9836 - val_loss: 0.5266 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.88916\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0719 - accuracy: 0.9762 - val_loss: 0.8162 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.88916\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1333 - accuracy: 0.9598 - val_loss: 0.4207 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.88916\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0972 - accuracy: 0.9665 - val_loss: 0.6826 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.88916\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0991 - accuracy: 0.9677 - val_loss: 0.6319 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.88916\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0499 - accuracy: 0.9836 - val_loss: 0.4513 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.88916\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0291 - accuracy: 0.9903 - val_loss: 0.6840 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.88916\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0293 - accuracy: 0.9878 - val_loss: 0.3761 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.88916 to 0.89901, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.3738 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.89901\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.3716 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.89901 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0410 - accuracy: 0.9866 - val_loss: 0.5488 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.90148\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1213 - accuracy: 0.9580 - val_loss: 0.4499 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90148\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0796 - accuracy: 0.9726 - val_loss: 0.4058 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00074: val_accuracy improved from 0.90148 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0548 - accuracy: 0.9793 - val_loss: 0.6148 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.90640\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0779 - accuracy: 0.9732 - val_loss: 0.4509 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.90640\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0616 - accuracy: 0.9829 - val_loss: 1.1325 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.90640\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1090 - accuracy: 0.9659 - val_loss: 0.7326 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.90640\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0742 - accuracy: 0.9775 - val_loss: 0.5249 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.90640\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0414 - accuracy: 0.9890 - val_loss: 0.6648 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.90640\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0262 - accuracy: 0.9933 - val_loss: 0.5276 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.90640\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0355 - accuracy: 0.9890 - val_loss: 0.6001 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.90640\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0348 - accuracy: 0.9896 - val_loss: 0.4339 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.90640\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.4022 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.90640\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.6702 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.90640\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0784 - accuracy: 0.9750 - val_loss: 0.4906 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.90640\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0588 - accuracy: 0.9817 - val_loss: 0.8146 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.90640\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0970 - accuracy: 0.9647 - val_loss: 1.0599 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.90640\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0785 - accuracy: 0.9738 - val_loss: 0.6873 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.90640\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0600 - accuracy: 0.9799 - val_loss: 0.7113 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.90640\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0700 - accuracy: 0.9762 - val_loss: 1.2937 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.90640\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0582 - accuracy: 0.9793 - val_loss: 0.5919 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.90640\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0510 - accuracy: 0.9848 - val_loss: 0.6043 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.90640\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0646 - accuracy: 0.9787 - val_loss: 0.9372 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.90640\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0821 - accuracy: 0.9750 - val_loss: 0.6721 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.90640\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0897 - accuracy: 0.9732 - val_loss: 0.7867 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.90640\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0788 - accuracy: 0.9726 - val_loss: 0.9773 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.90640\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0418 - accuracy: 0.9854 - val_loss: 0.4505 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.90640\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0296 - accuracy: 0.9884 - val_loss: 0.5796 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.90640\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0317 - accuracy: 0.9909 - val_loss: 0.4745 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.90640\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.4713 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.90640\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0238 - accuracy: 0.9909 - val_loss: 0.4511 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.90640\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0407 - accuracy: 0.9872 - val_loss: 0.5133 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.90640\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.4836 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.90640\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 0.4906 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.90640\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0181 - accuracy: 0.9921 - val_loss: 0.5340 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.90640\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.4504 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.90640\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.4975 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.90640\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.6384 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.90640\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.5438 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.90640\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.4148 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.90640\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.7170 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.90640\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0343 - accuracy: 0.9903 - val_loss: 0.4231 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.90640\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0295 - accuracy: 0.9927 - val_loss: 0.5730 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.90640\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0294 - accuracy: 0.9890 - val_loss: 0.7013 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.90640\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0884 - accuracy: 0.9714 - val_loss: 0.6353 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.90640\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0965 - accuracy: 0.9653 - val_loss: 1.1673 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.90640\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1002 - accuracy: 0.9671 - val_loss: 1.0430 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.90640\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0712 - accuracy: 0.9756 - val_loss: 0.6239 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.90640\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0441 - accuracy: 0.9848 - val_loss: 0.5067 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.90640\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.5790 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.90640\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0328 - accuracy: 0.9884 - val_loss: 0.6954 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.90640\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.5082 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.90640\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.6511 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.90640\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.4847 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.90640\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.4841 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.90640\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.3896 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00127: val_accuracy improved from 0.90640 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.4240 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.92365\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.5025 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.92365\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0195 - accuracy: 0.9957 - val_loss: 0.6023 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.92365\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0932 - accuracy: 0.9702 - val_loss: 1.3202 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.92365\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0843 - accuracy: 0.9756 - val_loss: 0.6682 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.92365\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0479 - accuracy: 0.9811 - val_loss: 0.5328 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.92365\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.7889 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.92365\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.6220 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.92365\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.4490 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.92365\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.5557 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.92365\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0298 - accuracy: 0.9915 - val_loss: 0.6871 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.92365\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 0.6798 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.92365\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.6711 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.92365\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0525 - accuracy: 0.9823 - val_loss: 0.6374 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.92365\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0457 - accuracy: 0.9848 - val_loss: 0.7146 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.92365\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0373 - accuracy: 0.9896 - val_loss: 0.5749 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.92365\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.5075 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.92365\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0842 - accuracy: 0.9726 - val_loss: 0.8011 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.92365\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0366 - accuracy: 0.9921 - val_loss: 0.6042 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.92365\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.5931 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.92365\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0201 - accuracy: 0.9951 - val_loss: 0.3743 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.92365\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.3939 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.92365\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.4310 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.92365\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.6542 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.92365\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.4035 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.92365\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.5423 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.92365\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.4793 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92365\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.8357 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92365\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 0.9042 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92365\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 0.6233 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92365\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0235 - accuracy: 0.9945 - val_loss: 0.4973 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92365\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0265 - accuracy: 0.9903 - val_loss: 0.5682 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92365\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0387 - accuracy: 0.9866 - val_loss: 0.8052 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92365\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0304 - accuracy: 0.9866 - val_loss: 1.5961 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92365\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1603 - accuracy: 0.9592 - val_loss: 1.4852 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92365\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0675 - accuracy: 0.9781 - val_loss: 0.7753 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92365\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0530 - accuracy: 0.9872 - val_loss: 0.7285 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92365\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.6257 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92365\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.5069 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92365\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.4161 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92365\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0110 - accuracy: 0.9951 - val_loss: 0.4099 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92365\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.3899 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92365\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5163 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92365\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.5111 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92365\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.5481 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92365\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.6191 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92365\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 0.4299 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92365\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92365\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.5201 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92365\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.4643 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92365\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.5458 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92365\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.6112 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92365\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0177 - accuracy: 0.9933 - val_loss: 0.5079 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92365\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.5292 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92365\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.6687 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92365\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.4318 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92365\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3861 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92365\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.3939 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00185: val_accuracy improved from 0.92365 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0186 - accuracy: 0.9921 - val_loss: 0.8307 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92857\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0378 - accuracy: 0.9872 - val_loss: 1.0527 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92857\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0735 - accuracy: 0.9787 - val_loss: 1.9677 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92857\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0622 - accuracy: 0.9799 - val_loss: 1.1311 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92857\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.5000 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92857\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0510 - accuracy: 0.9872 - val_loss: 0.9351 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92857\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0347 - accuracy: 0.9866 - val_loss: 0.5529 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92857\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.7010 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92857\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0344 - accuracy: 0.9921 - val_loss: 0.5710 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92857\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0489 - accuracy: 0.9823 - val_loss: 0.7153 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92857\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0326 - accuracy: 0.9884 - val_loss: 0.7303 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92857\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0347 - accuracy: 0.9854 - val_loss: 0.5524 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92857\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0383 - accuracy: 0.9890 - val_loss: 0.5046 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92857\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.4326 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92857\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.4217 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92857\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.4614 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92857\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.3678 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92857\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92857\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92857\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.3574 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92857\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.4961 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92857\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.6554 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92857\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0336 - accuracy: 0.9878 - val_loss: 0.9800 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92857\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0205 - accuracy: 0.9915 - val_loss: 0.7139 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92857\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0284 - accuracy: 0.9933 - val_loss: 0.6994 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92857\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.5682 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92857\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.7848 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92857\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0666 - accuracy: 0.9829 - val_loss: 0.6890 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92857\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 0.7768 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92857\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.8126 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92857\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0213 - accuracy: 0.9915 - val_loss: 0.4834 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.92857\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.4622 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92857\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 12s 229ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.5553 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92857\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.6384 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92857\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.5838 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92857\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.4145 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.92857\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.7104 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.92857\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 0.6105 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.92857\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.5894 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.92857\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.92857\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.4809 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.92857\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.4655 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92857\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0510 - accuracy: 0.9854 - val_loss: 0.8191 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92857\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0446 - accuracy: 0.9836 - val_loss: 0.7675 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92857\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.4409 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92857\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.3972 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92857\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0834 - accuracy: 0.9726 - val_loss: 0.7072 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92857\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0455 - accuracy: 0.9884 - val_loss: 0.8459 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92857\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0472 - accuracy: 0.9842 - val_loss: 0.9818 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92857\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.5297 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92857\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.6057 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92857\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4445 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92857\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4616 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92857\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4315 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92857\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92857\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3875 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.92857\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.3452 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.92857\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.4530 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.92857\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.5066 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.92857\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.5573 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.92857\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.5520 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.92857\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5442 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.92857\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0061 - accuracy: 0.9970 - val_loss: 0.5308 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.92857\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.4177 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.92857\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.5460 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.92857\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.5712 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.92857\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.4527 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92857\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0270 - accuracy: 0.9909 - val_loss: 0.6306 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.92857\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0432 - accuracy: 0.9872 - val_loss: 1.5259 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.92857\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0921 - accuracy: 0.9689 - val_loss: 1.0346 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.92857\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 0.7035 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.92857\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0227 - accuracy: 0.9909 - val_loss: 0.5698 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.92857\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.5829 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.92857\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4327 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.92857\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.92857\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4391 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.92857\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.5541 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.92857\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0256 - accuracy: 0.9945 - val_loss: 1.2138 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.92857\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0945 - accuracy: 0.9793 - val_loss: 16.8713 - val_accuracy: 0.3227\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.92857\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0868 - accuracy: 0.9714 - val_loss: 0.7570 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.92857\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0295 - accuracy: 0.9915 - val_loss: 0.6564 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.92857\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0112 - accuracy: 0.9939 - val_loss: 0.4888 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.92857\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0135 - accuracy: 0.9939 - val_loss: 0.4301 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.92857\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4748 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.92857\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.3838 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.92857\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.3908 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.92857\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.92857\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4571 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.92857\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.3771 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.92857\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4341 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.92857\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4675 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.92857\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.4369 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.92857\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.3821 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.92857\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.92857\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.4330 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.92857\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.6525 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.92857\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0153 - accuracy: 0.9933 - val_loss: 0.4812 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.92857\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.4992 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.92857\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.5885 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.92857\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0195 - accuracy: 0.9921 - val_loss: 0.5207 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.92857\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.5658 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.92857\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 0.8067 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.92857\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.5181 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.92857\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.6271 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.92857\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3879 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.92857\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.3936 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.92857\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.4916 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.92857\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4490 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.92857\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3874 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.92857\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 5.6982e-04 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00295: val_accuracy improved from 0.92857 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5810 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93350\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0105 - accuracy: 0.9957 - val_loss: 0.5967 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93350\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.8461 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93350\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0813 - accuracy: 0.9750 - val_loss: 1.0991 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93350\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0545 - accuracy: 0.9836 - val_loss: 0.6496 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93350\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0177 - accuracy: 0.9933 - val_loss: 0.5232 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93350\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.4355 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93350\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4815 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93350\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4896 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93350\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93350\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93350\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.3447 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93350\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5351 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93350\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.6340 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93350\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.5741 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93350\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.4717 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93350\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93350\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.6466 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93350\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0191 - accuracy: 0.9957 - val_loss: 0.5590 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93350\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0462 - accuracy: 0.9860 - val_loss: 0.7064 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93350\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.5582 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93350\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0173 - accuracy: 0.9970 - val_loss: 0.5390 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93350\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.4505 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93350\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4154 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93350\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4418 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93350\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4408 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93350\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.5199 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93350\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4724 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93350\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.5196 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93350\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93350\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 9.0183e-04 - accuracy: 1.0000 - val_loss: 0.4809 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93350\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 5.8812e-04 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93350\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4914 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93350\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0282 - accuracy: 0.9951 - val_loss: 1.5071 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93350\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 0.7643 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93350\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.8276 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93350\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0540 - accuracy: 0.9836 - val_loss: 0.6226 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93350\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0352 - accuracy: 0.9854 - val_loss: 0.5275 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93350\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0274 - accuracy: 0.9903 - val_loss: 0.8469 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93350\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.5031 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93350\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.5869 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93350\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.6770 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93350\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.5257 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93350\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.4293 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93350\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4604 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93350\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93350\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0040 - accuracy: 0.9976 - val_loss: 0.4065 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93350\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4270 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93350\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 9.4717e-04 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93350\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 5.6214e-04 - accuracy: 1.0000 - val_loss: 0.4161 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93350\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 6.5045e-04 - accuracy: 1.0000 - val_loss: 0.3989 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00346: val_accuracy improved from 0.93350 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 4.3788e-04 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93596\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 6.4603e-04 - accuracy: 1.0000 - val_loss: 0.3994 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00348: val_accuracy improved from 0.93596 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 2.3265e-04 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93842\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4725 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93842\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.3779 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93842\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.3519 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93842\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4263 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93842\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 3.5290e-04 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93842\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4017 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93842\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 8.6752e-04 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93842\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.2956e-04 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93842\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4389 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93842\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0153 - accuracy: 0.9933 - val_loss: 0.5292 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93842\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0310 - accuracy: 0.9933 - val_loss: 0.5942 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93842\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.6362 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93842\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.5753 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93842\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0214 - accuracy: 0.9909 - val_loss: 1.1150 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93842\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0246 - accuracy: 0.9890 - val_loss: 0.6687 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93842\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 0.9941 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93842\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0385 - accuracy: 0.9854 - val_loss: 1.1342 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93842\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0729 - accuracy: 0.9842 - val_loss: 0.6074 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93842\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0283 - accuracy: 0.9927 - val_loss: 0.6023 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93842\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.4013 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93842\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0077 - accuracy: 0.9963 - val_loss: 0.4630 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93842\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4114 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93842\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4237 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93842\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.4952 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93842\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.5344 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93842\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0200 - accuracy: 0.9951 - val_loss: 0.7790 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93842\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4903 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93842\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4509 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93842\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93842\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4269 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93842\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93842\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 3.6472e-04 - accuracy: 1.0000 - val_loss: 0.4455 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93842\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.9803e-04 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93842\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.7489e-04 - accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93842\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 5.7600e-04 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93842\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 4.0012e-04 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93842\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.7082e-04 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93842\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 4.1028e-04 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93842\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.7735e-04 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93842\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 4.5740e-04 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93842\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 1.8836e-04 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93842\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.4824e-04 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93842\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 7.3095e-04 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93842\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 2.1951e-04 - accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93842\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.8902e-04 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93842\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.0067e-04 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93842\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 1.6625e-04 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93842\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 1.7062e-04 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93842\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0381 - accuracy: 0.9957 - val_loss: 0.8579 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93842\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0874 - accuracy: 0.9744 - val_loss: 0.9332 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93842\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0456 - accuracy: 0.9872 - val_loss: 0.8041 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93842\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0179 - accuracy: 0.9933 - val_loss: 0.4229 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93842\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.6006 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93842\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.4950 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93842\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4319 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93842\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.4525 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93842\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4661 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93842\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3889 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93842\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 9.2236e-04 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93842\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.6525e-04 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93842\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 3.6779e-04 - accuracy: 1.0000 - val_loss: 0.3379 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00410: val_accuracy improved from 0.93842 to 0.94089, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 3.4551e-04 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94089\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 4.8990e-04 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94089\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 7.5305e-04 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94089\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 3.7189e-04 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94089\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 1.9086e-04 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94089\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 4.4199e-04 - accuracy: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94089\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.2392e-04 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94089\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.1501e-04 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94089\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 6.5078e-04 - accuracy: 0.9994 - val_loss: 0.4487 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94089\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4405 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94089\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 5.6445e-04 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94089\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 0.5118 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94089\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 5.7620e-04 - accuracy: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94089\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94089\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 6.3595e-04 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94089\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.4541 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94089\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.6907 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94089\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.5640 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94089\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94089\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.5253 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94089\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.8641 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94089\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0974 - accuracy: 0.9750 - val_loss: 1.3084 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94089\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0542 - accuracy: 0.9854 - val_loss: 0.7964 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94089\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0422 - accuracy: 0.9860 - val_loss: 0.6196 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94089\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 0.7008 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94089\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.5492 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94089\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.5587 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94089\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5198 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94089\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.5183 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94089\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4505 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94089\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94089\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.4030 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94089\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4336 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94089\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94089\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 7.9034e-04 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94089\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 6.3733e-04 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94089\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.6032e-04 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94089\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 3.1521e-04 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94089\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5217 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94089\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4395 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94089\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4743 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94089\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4823 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94089\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.4242 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94089\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.4144 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94089\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4292 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94089\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0075 - accuracy: 0.9970 - val_loss: 0.5170 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94089\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.4767 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94089\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.5284 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94089\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.5202 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94089\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.6946 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94089\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.5794 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94089\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.5454 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94089\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5296 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94089\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94089\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94089\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 3.8337e-04 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94089\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 8.7278e-04 - accuracy: 1.0000 - val_loss: 0.4675 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94089\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 4.6612e-04 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94089\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.4196e-04 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94089\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4709 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94089\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.7325 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94089\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.7125 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94089\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0327 - accuracy: 0.9909 - val_loss: 0.9501 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94089\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.6012 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94089\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0156 - accuracy: 0.9933 - val_loss: 0.6788 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94089\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.6154 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94089\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.8807 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94089\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0204 - accuracy: 0.9915 - val_loss: 0.5623 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94089\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.8577 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94089\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.6457 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94089\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4508 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94089\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94089\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94089\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.8084e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94089\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 6.1533e-04 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94089\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 7.5376e-04 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94089\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 5.0099e-04 - accuracy: 1.0000 - val_loss: 0.4500 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94089\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5049 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94089\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 4.0226e-04 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94089\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 6.6518e-04 - accuracy: 1.0000 - val_loss: 0.4565 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94089\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 1.2650e-04 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94089\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 6.3805e-04 - accuracy: 1.0000 - val_loss: 0.5424 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94089\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94089\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4470 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94089\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.6881 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94089\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.5841 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94089\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.7479 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94089\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0530 - accuracy: 0.9860 - val_loss: 0.8668 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94089\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.7897 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94089\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.4831 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94089\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd4f00449d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8db252ca-f512-45a5-d3d8-95ebe88f96ce"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_3_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf392195-38df-474f-bb16-ef21f11e4be8"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a51f26-c614-414b-b4af-68f4c315f670"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "13fb3fcf-c6ab-45e9-8df4-00899901a791"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e4db1f33-fae9-45d3-9b3a-9eb608f28980"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_020_3_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_020_3_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_526906d4-b7a0-42cb-8e9c-a5437620eab0\", \"WidthShiftRange_020_3_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}