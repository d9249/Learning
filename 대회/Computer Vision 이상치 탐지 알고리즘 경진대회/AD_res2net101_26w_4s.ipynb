{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breathing-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.19.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (4.4.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.58.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from gdown) (4.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from gdown) (3.4.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.6/dist-packages (from gdown) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (1.26.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (2020.12.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.6/dist-packages (0.5.4)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm) (0.8.2+cu110)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from timm) (1.7.1+cu110)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.8)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (8.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install gdown\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "republican-treatment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access denied with the following error:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id=1AWOO1awvSGHHKbydWJTmeZ0g5f5rV85I \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "google_path = 'https://drive.google.com/uc?id='\n",
    "file_id = '1AWOO1awvSGHHKbydWJTmeZ0g5f5rV85I'\n",
    "output_name = 'open.zip'\n",
    "gdown.download(google_path+file_id,output_name,quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "foster-scholarship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  open.zip\n",
      "replace open/sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip open.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "complete-retention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  test.zip\n",
      "replace test/20000.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n",
      "Archive:  train.zip\n",
      "replace train/10000.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip test.zip\n",
    "!unzip train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-optics",
   "metadata": {},
   "source": [
    "### 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "direct-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dried-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_png = sorted(glob('/home/open/train/*.png'))\n",
    "test_png = sorted(glob('/home/open/test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "republican-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"/home/open/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "objective-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "tamil-regression",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4277/4277 [02:31<00:00, 28.21it/s]\n",
      "100%|██████████| 2154/2154 [01:15<00:00, 28.63it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "waiting-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode=='train':\n",
    "            augmentation = random.randint(0,2)\n",
    "            if augmentation==1:\n",
    "                img = img[::-1].copy()\n",
    "            elif augmentation==2:\n",
    "                img = img[:,::-1].copy()\n",
    "        img = transforms.ToTensor()(img)\n",
    "        if self.mode=='test':\n",
    "            pass\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = timm.create_model('res2net101_26w_4s', pretrained=True, num_classes=88)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "packed-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 150\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-strength",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-commercial",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net101_26w_4s-02a759a1.pth\" to /root/.cache/torch/hub/checkpoints/res2net101_26w_4s-02a759a1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/150    time : 139s/20720s\n",
      "TRAIN    loss : 2.06364    f1 : 0.09100\n",
      "epoch : 2/150    time : 140s/20764s\n",
      "TRAIN    loss : 1.03610    f1 : 0.14737\n",
      "epoch : 3/150    time : 141s/20775s\n",
      "TRAIN    loss : 0.88601    f1 : 0.15170\n",
      "epoch : 4/150    time : 142s/20702s\n",
      "TRAIN    loss : 0.81507    f1 : 0.15692\n",
      "epoch : 5/150    time : 141s/20431s\n",
      "TRAIN    loss : 0.79141    f1 : 0.16130\n",
      "epoch : 6/150    time : 142s/20514s\n",
      "TRAIN    loss : 0.77151    f1 : 0.16496\n",
      "epoch : 7/150    time : 140s/20026s\n",
      "TRAIN    loss : 0.73975    f1 : 0.16158\n",
      "epoch : 8/150    time : 140s/19844s\n",
      "TRAIN    loss : 0.74000    f1 : 0.17928\n",
      "epoch : 9/150    time : 140s/19805s\n",
      "TRAIN    loss : 0.73287    f1 : 0.17237\n",
      "epoch : 10/150    time : 140s/19644s\n",
      "TRAIN    loss : 0.73038    f1 : 0.17901\n",
      "epoch : 11/150    time : 137s/19075s\n",
      "TRAIN    loss : 0.69862    f1 : 0.18369\n",
      "epoch : 12/150    time : 139s/19244s\n",
      "TRAIN    loss : 0.69040    f1 : 0.18137\n",
      "epoch : 13/150    time : 139s/19029s\n",
      "TRAIN    loss : 0.68934    f1 : 0.18613\n",
      "epoch : 14/150    time : 140s/18997s\n",
      "TRAIN    loss : 0.67122    f1 : 0.19525\n",
      "epoch : 15/150    time : 139s/18732s\n",
      "TRAIN    loss : 0.66081    f1 : 0.20454\n",
      "epoch : 16/150    time : 140s/18783s\n",
      "TRAIN    loss : 0.63886    f1 : 0.22239\n",
      "epoch : 17/150    time : 139s/18508s\n",
      "TRAIN    loss : 0.63940    f1 : 0.22140\n",
      "epoch : 18/150    time : 140s/18451s\n",
      "TRAIN    loss : 0.60895    f1 : 0.23219\n",
      "epoch : 19/150    time : 140s/18382s\n",
      "TRAIN    loss : 0.60738    f1 : 0.23936\n",
      "epoch : 20/150    time : 139s/18027s\n",
      "TRAIN    loss : 0.58677    f1 : 0.25704\n",
      "epoch : 21/150    time : 139s/17908s\n",
      "TRAIN    loss : 0.58280    f1 : 0.26372\n",
      "epoch : 22/150    time : 140s/17968s\n",
      "TRAIN    loss : 0.58231    f1 : 0.26049\n",
      "epoch : 23/150    time : 142s/18031s\n",
      "TRAIN    loss : 0.55240    f1 : 0.29000\n",
      "epoch : 24/150    time : 138s/17445s\n",
      "TRAIN    loss : 0.54868    f1 : 0.28617\n",
      "epoch : 25/150    time : 141s/17608s\n",
      "TRAIN    loss : 0.52499    f1 : 0.31395\n",
      "epoch : 26/150    time : 140s/17352s\n",
      "TRAIN    loss : 0.51573    f1 : 0.32572\n",
      "epoch : 27/150    time : 141s/17378s\n",
      "TRAIN    loss : 0.50703    f1 : 0.32654\n",
      "epoch : 28/150    time : 139s/16925s\n",
      "TRAIN    loss : 0.50812    f1 : 0.33038\n",
      "epoch : 29/150    time : 141s/17095s\n",
      "TRAIN    loss : 0.49393    f1 : 0.34925\n",
      "epoch : 30/150    time : 140s/16820s\n",
      "TRAIN    loss : 0.48206    f1 : 0.35499\n",
      "epoch : 31/150    time : 138s/16479s\n",
      "TRAIN    loss : 0.48590    f1 : 0.36676\n",
      "epoch : 32/150    time : 143s/16885s\n",
      "TRAIN    loss : 0.47554    f1 : 0.36394\n",
      "epoch : 33/150    time : 140s/16341s\n",
      "TRAIN    loss : 0.46597    f1 : 0.37507\n"
     ]
    }
   ],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "\n",
    "\n",
    "best=0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-saying",
   "metadata": {},
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "f_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-muscle",
   "metadata": {},
   "source": [
    "### 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"/home/open/sample_submission.csv\")\n",
    "submission[\"label\"] = f_result\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"baseline.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-powell",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
