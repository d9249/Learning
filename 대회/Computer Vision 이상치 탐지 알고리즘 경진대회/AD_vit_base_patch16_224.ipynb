{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breathing-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.19.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (4.4.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.58.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from gdown) (4.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from gdown) (3.4.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.6/dist-packages (from gdown) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (1.26.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (2020.12.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.6/dist-packages (0.5.4)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm) (0.8.2+cu110)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from timm) (1.7.1+cu110)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.8)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (8.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install gdown\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "republican-treatment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access denied with the following error:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id=1AWOO1awvSGHHKbydWJTmeZ0g5f5rV85I \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "google_path = 'https://drive.google.com/uc?id='\n",
    "file_id = '1AWOO1awvSGHHKbydWJTmeZ0g5f5rV85I'\n",
    "output_name = 'open.zip'\n",
    "gdown.download(google_path+file_id,output_name,quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "foster-scholarship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  open.zip\n",
      "replace open/sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip open.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "geological-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/open\n"
     ]
    }
   ],
   "source": [
    "cd open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "complete-retention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  test.zip\n",
      "replace test/20000.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n",
      "Archive:  train.zip\n",
      "replace train/10000.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip test.zip\n",
    "!unzip train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-optics",
   "metadata": {},
   "source": [
    "### 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "protecting-limitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "direct-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dried-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_png = sorted(glob('open/train/*.png'))\n",
    "test_png = sorted(glob('open/test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "republican-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"open/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "objective-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tamil-regression",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4277/4277 [02:31<00:00, 28.22it/s]\n",
      "100%|██████████| 2154/2154 [01:16<00:00, 28.31it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "waiting-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode=='train':\n",
    "            augmentation = random.randint(0,2)\n",
    "            if augmentation==1:\n",
    "                img = img[::-1].copy()\n",
    "            elif augmentation==2:\n",
    "                img = img[:,::-1].copy()\n",
    "        img = transforms.ToTensor()(img)\n",
    "        if self.mode=='test':\n",
    "            pass\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = timm.create_model('efficientnet_b1', pretrained=True, num_classes=88)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "packed-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 150\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-strength",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-commercial",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b1-533bc792.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b1-533bc792.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/150    time : 88s/13040s\n",
      "TRAIN    loss : 1.11478    f1 : 0.17999\n",
      "epoch : 2/150    time : 88s/12979s\n",
      "TRAIN    loss : 0.62227    f1 : 0.31980\n",
      "epoch : 3/150    time : 88s/12900s\n",
      "TRAIN    loss : 0.51545    f1 : 0.40152\n",
      "epoch : 4/150    time : 88s/12814s\n",
      "TRAIN    loss : 0.42573    f1 : 0.48138\n",
      "epoch : 5/150    time : 88s/12790s\n",
      "TRAIN    loss : 0.37334    f1 : 0.53786\n",
      "epoch : 6/150    time : 87s/12599s\n",
      "TRAIN    loss : 0.33615    f1 : 0.59699\n",
      "epoch : 7/150    time : 88s/12565s\n",
      "TRAIN    loss : 0.31997    f1 : 0.58258\n",
      "epoch : 8/150    time : 89s/12688s\n",
      "TRAIN    loss : 0.28047    f1 : 0.63491\n",
      "epoch : 9/150    time : 88s/12457s\n",
      "TRAIN    loss : 0.25685    f1 : 0.65594\n",
      "epoch : 10/150    time : 87s/12136s\n",
      "TRAIN    loss : 0.21968    f1 : 0.73339\n",
      "epoch : 11/150    time : 88s/12287s\n",
      "TRAIN    loss : 0.22244    f1 : 0.73097\n",
      "epoch : 12/150    time : 87s/12060s\n",
      "TRAIN    loss : 0.18821    f1 : 0.76888\n",
      "epoch : 13/150    time : 87s/11972s\n",
      "TRAIN    loss : 0.17503    f1 : 0.76471\n",
      "epoch : 14/150    time : 88s/11949s\n",
      "TRAIN    loss : 0.17984    f1 : 0.78108\n",
      "epoch : 15/150    time : 88s/11939s\n",
      "TRAIN    loss : 0.16186    f1 : 0.80261\n",
      "epoch : 16/150    time : 88s/11735s\n",
      "TRAIN    loss : 0.13838    f1 : 0.82958\n",
      "epoch : 17/150    time : 89s/11848s\n",
      "TRAIN    loss : 0.15374    f1 : 0.82565\n",
      "epoch : 18/150    time : 87s/11427s\n",
      "TRAIN    loss : 0.14370    f1 : 0.80440\n",
      "epoch : 19/150    time : 87s/11440s\n",
      "TRAIN    loss : 0.11844    f1 : 0.86079\n",
      "epoch : 20/150    time : 87s/11297s\n",
      "TRAIN    loss : 0.12772    f1 : 0.84195\n",
      "epoch : 21/150    time : 89s/11515s\n",
      "TRAIN    loss : 0.12866    f1 : 0.84992\n",
      "epoch : 22/150    time : 87s/11153s\n",
      "TRAIN    loss : 0.12879    f1 : 0.85044\n",
      "epoch : 23/150    time : 89s/11314s\n",
      "TRAIN    loss : 0.08475    f1 : 0.89794\n",
      "epoch : 24/150    time : 89s/11171s\n",
      "TRAIN    loss : 0.09396    f1 : 0.88968\n",
      "epoch : 25/150    time : 87s/10933s\n",
      "TRAIN    loss : 0.09631    f1 : 0.88162\n",
      "epoch : 26/150    time : 89s/11051s\n",
      "TRAIN    loss : 0.09759    f1 : 0.87824\n",
      "epoch : 27/150    time : 89s/10899s\n",
      "TRAIN    loss : 0.10027    f1 : 0.88129\n",
      "epoch : 28/150    time : 88s/10680s\n",
      "TRAIN    loss : 0.10645    f1 : 0.87525\n",
      "epoch : 29/150    time : 87s/10559s\n",
      "TRAIN    loss : 0.06725    f1 : 0.91518\n",
      "epoch : 30/150    time : 87s/10447s\n",
      "TRAIN    loss : 0.09107    f1 : 0.88960\n",
      "epoch : 31/150    time : 87s/10298s\n",
      "TRAIN    loss : 0.07702    f1 : 0.90523\n",
      "epoch : 32/150    time : 87s/10290s\n",
      "TRAIN    loss : 0.08833    f1 : 0.90306\n",
      "epoch : 33/150    time : 87s/10127s\n",
      "TRAIN    loss : 0.07510    f1 : 0.91845\n",
      "epoch : 34/150    time : 89s/10289s\n",
      "TRAIN    loss : 0.06902    f1 : 0.92681\n",
      "epoch : 35/150    time : 88s/10085s\n",
      "TRAIN    loss : 0.06840    f1 : 0.92041\n",
      "epoch : 36/150    time : 89s/10169s\n",
      "TRAIN    loss : 0.06915    f1 : 0.92941\n",
      "epoch : 37/150    time : 88s/9928s\n",
      "TRAIN    loss : 0.06177    f1 : 0.94118\n",
      "epoch : 38/150    time : 88s/9825s\n",
      "TRAIN    loss : 0.10254    f1 : 0.88140\n",
      "epoch : 39/150    time : 87s/9674s\n",
      "TRAIN    loss : 0.04450    f1 : 0.94299\n",
      "epoch : 40/150    time : 87s/9595s\n",
      "TRAIN    loss : 0.05072    f1 : 0.93297\n",
      "epoch : 41/150    time : 88s/9622s\n",
      "TRAIN    loss : 0.06031    f1 : 0.93746\n",
      "epoch : 42/150    time : 88s/9492s\n",
      "TRAIN    loss : 0.07173    f1 : 0.91880\n",
      "epoch : 43/150    time : 88s/9382s\n",
      "TRAIN    loss : 0.04001    f1 : 0.95064\n",
      "epoch : 44/150    time : 88s/9365s\n",
      "TRAIN    loss : 0.06810    f1 : 0.92340\n",
      "epoch : 45/150    time : 88s/9288s\n",
      "TRAIN    loss : 0.09184    f1 : 0.90942\n",
      "epoch : 46/150    time : 89s/9228s\n",
      "TRAIN    loss : 0.06596    f1 : 0.92030\n",
      "epoch : 47/150    time : 88s/9062s\n",
      "TRAIN    loss : 0.02708    f1 : 0.96890\n",
      "epoch : 48/150    time : 88s/9022s\n",
      "TRAIN    loss : 0.03956    f1 : 0.95992\n",
      "epoch : 49/150    time : 88s/8878s\n",
      "TRAIN    loss : 0.09156    f1 : 0.90445\n",
      "epoch : 50/150    time : 88s/8760s\n",
      "TRAIN    loss : 0.05514    f1 : 0.94190\n",
      "epoch : 51/150    time : 87s/8624s\n",
      "TRAIN    loss : 0.04855    f1 : 0.95976\n",
      "epoch : 52/150    time : 87s/8561s\n",
      "TRAIN    loss : 0.05093    f1 : 0.93338\n",
      "epoch : 53/150    time : 89s/8628s\n",
      "TRAIN    loss : 0.04778    f1 : 0.94420\n",
      "epoch : 54/150    time : 89s/8511s\n",
      "TRAIN    loss : 0.05572    f1 : 0.93795\n",
      "epoch : 55/150    time : 87s/8247s\n",
      "TRAIN    loss : 0.04892    f1 : 0.94940\n",
      "epoch : 56/150    time : 88s/8309s\n",
      "TRAIN    loss : 0.02854    f1 : 0.98243\n",
      "epoch : 57/150    time : 87s/8053s\n",
      "TRAIN    loss : 0.02239    f1 : 0.97746\n",
      "epoch : 58/150    time : 87s/7995s\n",
      "TRAIN    loss : 0.05724    f1 : 0.94400\n",
      "epoch : 59/150    time : 86s/7812s\n",
      "TRAIN    loss : 0.04018    f1 : 0.95777\n",
      "epoch : 60/150    time : 87s/7866s\n",
      "TRAIN    loss : 0.05758    f1 : 0.93699\n",
      "epoch : 61/150    time : 86s/7614s\n",
      "TRAIN    loss : 0.06215    f1 : 0.93920\n",
      "epoch : 62/150    time : 87s/7669s\n",
      "TRAIN    loss : 0.05627    f1 : 0.94397\n",
      "epoch : 63/150    time : 89s/7707s\n",
      "TRAIN    loss : 0.03565    f1 : 0.95517\n",
      "epoch : 64/150    time : 88s/7591s\n",
      "TRAIN    loss : 0.02812    f1 : 0.97689\n",
      "epoch : 65/150    time : 87s/7365s\n",
      "TRAIN    loss : 0.02848    f1 : 0.97351\n",
      "epoch : 66/150    time : 87s/7318s\n",
      "TRAIN    loss : 0.02679    f1 : 0.97302\n",
      "epoch : 67/150    time : 89s/7351s\n",
      "TRAIN    loss : 0.02899    f1 : 0.97091\n",
      "epoch : 68/150    time : 87s/7170s\n",
      "TRAIN    loss : 0.05920    f1 : 0.94487\n",
      "epoch : 69/150    time : 88s/7097s\n",
      "TRAIN    loss : 0.06315    f1 : 0.93334\n",
      "epoch : 70/150    time : 87s/6946s\n",
      "TRAIN    loss : 0.02662    f1 : 0.97371\n",
      "epoch : 71/150    time : 89s/7025s\n",
      "TRAIN    loss : 0.02470    f1 : 0.97451\n",
      "epoch : 72/150    time : 86s/6725s\n",
      "TRAIN    loss : 0.03649    f1 : 0.95889\n",
      "epoch : 73/150    time : 88s/6742s\n",
      "TRAIN    loss : 0.03915    f1 : 0.96609\n",
      "epoch : 74/150    time : 86s/6538s\n",
      "TRAIN    loss : 0.03969    f1 : 0.95592\n",
      "epoch : 75/150    time : 88s/6629s\n",
      "TRAIN    loss : 0.02960    f1 : 0.96066\n",
      "epoch : 76/150    time : 87s/6451s\n",
      "TRAIN    loss : 0.04502    f1 : 0.95377\n",
      "epoch : 77/150    time : 88s/6445s\n",
      "TRAIN    loss : 0.02406    f1 : 0.97322\n",
      "epoch : 78/150    time : 86s/6219s\n",
      "TRAIN    loss : 0.03866    f1 : 0.95640\n",
      "epoch : 79/150    time : 88s/6234s\n",
      "TRAIN    loss : 0.03596    f1 : 0.96226\n",
      "epoch : 80/150    time : 89s/6265s\n",
      "TRAIN    loss : 0.04819    f1 : 0.95354\n",
      "epoch : 81/150    time : 88s/6052s\n",
      "TRAIN    loss : 0.02357    f1 : 0.97418\n",
      "epoch : 82/150    time : 87s/5895s\n",
      "TRAIN    loss : 0.03272    f1 : 0.96645\n"
     ]
    }
   ],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "\n",
    "\n",
    "best=0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-saying",
   "metadata": {},
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "f_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-muscle",
   "metadata": {},
   "source": [
    "### 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"open/sample_submission.csv\")\n",
    "submission[\"label\"] = f_result\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"baseline.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-joseph",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-influence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
