{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ts26D3gLnyLd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ts26D3gLnyLd",
    "outputId": "f4f6fa8d-223f-4028-b18f-b8da4113b6d3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr  5 06:37:38 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\r\n",
      "| N/A   30C    P0    39W / 300W |      0MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "floating-cincinnati",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:28.086573Z",
     "iopub.status.busy": "2021-05-30T18:39:28.085923Z",
     "iopub.status.idle": "2021-05-30T18:39:32.847126Z",
     "shell.execute_reply": "2021-05-30T18:39:32.846068Z",
     "shell.execute_reply.started": "2021-05-30T09:28:36.967323Z"
    },
    "id": "floating-cincinnati",
    "papermill": {
     "duration": 4.80129,
     "end_time": "2021-05-30T18:39:32.847355",
     "exception": false,
     "start_time": "2021-05-30T18:39:28.046065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "FJJHQpPrpYcy",
   "metadata": {
    "id": "FJJHQpPrpYcy"
   },
   "outputs": [],
   "source": [
    "!unzip -q -o '/home/ClsKLData.zip' -d '/home/grade/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assumed-litigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "emotional-valuable",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:33.012157Z",
     "iopub.status.busy": "2021-05-30T18:39:33.011596Z",
     "iopub.status.idle": "2021-05-30T18:39:35.556063Z",
     "shell.execute_reply": "2021-05-30T18:39:35.555555Z",
     "shell.execute_reply.started": "2021-05-30T09:28:38.947982Z"
    },
    "id": "emotional-valuable",
    "papermill": {
     "duration": 2.57776,
     "end_time": "2021-05-30T18:39:35.556225",
     "exception": false,
     "start_time": "2021-05-30T18:39:32.978465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of class\n",
    "n_class = 5\n",
    "\n",
    "# path to kaggle dataset\n",
    "root_path = \"/home/grade/kneeKL224/\"\n",
    "\n",
    "# list of folders\n",
    "folder_list = os.listdir(root_path)\n",
    "image_path_list = []\n",
    "label_list = []\n",
    "\n",
    "# for each folder, get the image path and labels\n",
    "for folder in folder_list:\n",
    "    for label in range(n_class):\n",
    "        \n",
    "        # get all the images path inside the current folder\n",
    "        image_list = os.listdir(f\"{root_path}{folder}/{label}\")\n",
    "        # add to the image path list\n",
    "        image_path_list += [ f\"{root_path}{folder}/{label}/\"+ path for path in image_list]\n",
    "        \n",
    "        # add labels to the label list\n",
    "        label_list += [label] * len(image_list)\n",
    "\n",
    "# convert to dataframe\n",
    "df_train_kaggle = pd.DataFrame({\"filepath\" : image_path_list, \"label\": label_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "signal-responsibility",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:35.618734Z",
     "iopub.status.busy": "2021-05-30T18:39:35.617931Z",
     "iopub.status.idle": "2021-05-30T18:39:35.621117Z",
     "shell.execute_reply": "2021-05-30T18:39:35.621576Z",
     "shell.execute_reply.started": "2021-05-30T09:28:40.244589Z"
    },
    "id": "signal-responsibility",
    "outputId": "9be7a788-1c7a-498d-a3e9-7b2c5e8455ab",
    "papermill": {
     "duration": 0.03629,
     "end_time": "2021-05-30T18:39:35.621716",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.585426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9786, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_kaggle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-greene",
   "metadata": {
    "id": "hairy-greene",
    "papermill": {
     "duration": 0.030406,
     "end_time": "2021-05-30T18:39:35.680660",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.650254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Observation\n",
    "we have total of 9786 images in kaggle dataset. We will use data to train the deep learning model\n",
    "# Lets look at class distribution\n",
    "\n",
    "## 관찰\n",
    "우리는 카글 데이터 세트에 총 9786개의 이미지를 가지고 있다. 우리는 딥 러닝 모델을 훈련시키기 위해 데이터를 사용할 것이다.\n",
    "# 학급분포를 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "therapeutic-spending",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:35.750000Z",
     "iopub.status.busy": "2021-05-30T18:39:35.749277Z",
     "iopub.status.idle": "2021-05-30T18:39:35.918362Z",
     "shell.execute_reply": "2021-05-30T18:39:35.918766Z",
     "shell.execute_reply.started": "2021-05-30T09:28:41.597346Z"
    },
    "id": "therapeutic-spending",
    "outputId": "0e179822-cb9f-4a56-b0c3-1f99705e882b",
    "papermill": {
     "duration": 0.208649,
     "end_time": "2021-05-30T18:39:35.918905",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.710256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAECCAYAAAALqiumAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAARl0lEQVR4nO3df6zdd13H8eeLrnTKD2m3S8jUUpVtfzBA8EZkxkFxI7ISy68AMhCM22XMDN2Q0EV+2jEmCUIiMuyiMLZK1BA6sIDbwiw6yKRjCGEglDgQFXLpZY5uWNfy9o/7LT29u5/2nrbfc852n4/kZOf7/n7OOe/zTXZf/Xx/nVQVkiQt5iHjbkCSNLkMCUlSkyEhSWoyJCRJTYaEJKnJkJAkNZ3Q55snOQH4IPCDqnpVkrOBS4B7gG9X1aXduKHqLSeffHKtW7eur68jSQ9Kt9122/eqamqxdb2GBPAG4APAi5IEuAw4t6r2Jrk8yTnATcPUq+rG1oetW7eOnTt39vyVJOnBJck3W+t6292U5KXATuBrXek04I6q2tstbwPWH0VdkjQivYREkicDj6mqvx8onwTMDSzPdbVh6ws/aybJziQ7Z2dnj9M3kCRBf7ubXgI8Ksn7gEcATwG+BKweGLMG2N09hqkfoqq2AFsApqenvceIJB1HvYREVb3+wPMk65g/NvEe4MYkq7pdSBuBHcAu4Iwh6pKkEen7wDXAfmBfVe1PshnYmmQPMAvcUFU1TH0E/UqSOnkw3QV2enq6PLtJkoaT5Laqml5snRfTSZKaDAlJUpMhIUlqGsWB6weUdZu2j7sFAO68csO4W5AkZxKSpDZDQpLUZEhIkpoMCUlSkyEhSWoyJCRJTYaEJKnJkJAkNRkSkqQmQ0KS1GRISJKaDAlJUpMhIUlqMiQkSU2GhCSpqbffk0jyXmAl8DDga1X1liQ3AbsGhm2qqruSPAm4AtgD3AvMVNV9rXpfPUuSDtVbSFTVRQeeJ7kmyeld/cJFhl8BvLyq5pKcD7wSuPowdUnSCPS+uynJamAK+C6wJ8nmJNcmuaBbfyKwr6rmupdsA9a36n33K0k6qM/dTY8D3gqcCVxSVXcBz+3WBbgqyTeArwJ3Dbx0DljTPRarL/ycGWAGYO3atcf3S0jSMtfbTKKqdlXVecCpwHlJHjOwroCPAU8EdgOrB166hvlAaNUXfs6Wqpququmpqanj/0UkaRnrfXdTVe0DVgAPXbDqLOBzVbUXWNntlgLYCOxo1fvuV5J0UC+7m5I8BbiU+bOSHgl8uKq+leSdwMOBE4Fbq+qW7iWvB65OcjewD7j4CHVJ0gj0EhJV9XngZYvUX9sY/0XghUutS5JGw4vpJElNhoQkqcmQkCQ1GRKSpCZDQpLUZEhIkpoMCUlSkyEhSWoyJCRJTYaEJKnJkJAkNRkSkqQmQ0KS1GRISJKaDAlJUpMhIUlqMiQkSU2GhCSpyZCQJDX18hvXAEneC6wEHgZ8rarekuRs4BLgHuDbVXVpN3aouiRpNHqbSVTVRVV1QVW9FPi5JKcDlwHPr6oXAfcmOSdJhqn31a8k6f56392UZDUwBTwKuKOq9nartgHrgdOGrEuSRqS3kEjyuCRbgc8DW4AVwNzAkDngpO4xTH3h58wk2Zlk5+zs7PH9EpK0zPW5u2lXVZ0HnAqcx/zxidUDQ9YAu7vHMPWFn7Olqqaranpqaur4fglJWuZ6391UVfuYn0XcCZyRZFW3aiOwA9g1ZF2SNCK9nN2U5CnApcAe4JHAh6vqm0k2A1uT7AFmgRuqqoap99GvJGlxvYREVX0eeNki9ZuBm4+1LkkaDS+mkyQ1GRKSpCZDQpLUZEhIkpoMCUlSkyEhSWoyJCRJTYaEJKnJkJAkNRkSkqQmQ0KS1GRISJKaDAlJUpMhIUlqMiQkSU2GhCSpyZCQJDX18st0enBYt2n7uFsA4M4rN4y7BWnZciYhSWrqbSaR5CrgR8AaYHtVXZfkJmDXwLBNVXVXkicBVwB7gHuBmaq6r1Xvq2dJ0qF6C4mqejVAkgCfBq7r6hcuMvwK4OVVNZfkfOCVwNWHqUuSRmAUu5tWAXPd8z1JNie5NskFAElOBPZV1YEx24D1rfrCN08yk2Rnkp2zs7N9fg9JWnZGceD6cuAdAFX1XPjx7OKqJN8AvgrcNTB+jvldVGsa9UNU1RZgC8D09HQd7+YlaTnrdSaR5BLg9qq6ZbBeVQV8DHgisBtYPbB6DfOB0KpLkkakt5BIchFwT1VtbQw5C/hcVe0FViY5EAgbgR2tel/9SpLur5fdTUnOBDYBH0/yvq78xq72cOBE4NaBGcbrgauT3A3sAy4+Ql2SNAK9hERVfQZYu8iq1zbGfxF44VLrkqTR8GI6SVKTISFJajIkJElNhoQkqcmQkCQ1GRKSpCZDQpLUZEhIkpoMCUlS05JCIskZC5b9PUlJWgYOGxJJHp3kFOA1SU7pHo8Ffnc07UmSxulI9266HFgJ/HL3PMzfaO8jPfclSZoAhw2JqpoBSPKKqrpmNC1JkibFku4CW1XXJHkY8FNdaX9Vfbe/tiRJk2BJIZHkzcBTge9wcJfTBT32JUmaAEv9PYlTqurcXjuRJE2cpV4n8aNeu5AkTaSlziTWJHk/8PVueX9V/UlPPUmSJsRSQ+K9C5b3H+9GJEmTZ6lnN+0Y9o2TXMX8bqo1wPaqui7J2cAlwD3At6vq0m7sUHVJ0mgs9bYc25PckORTSf47yfVHek1Vvbqqfg94KfCqJAEuA55fVS8C7k1yzrD1o/yekqSjsKSQqKoNVfWsqnomcCrwX0N8xipgDjgNuKOq9nb1bcD6o6gfIslMkp1Jds7Ozg7RliTpSIa+C2xV7WH+Oomluhx4B3AS82FxwFxXG7a+sJ8tVTVdVdNTU1NDtCVJOpKlXkz3YmBFt3gK8NNLfN0lwO1VdUuS04HVA6vXALu7xzB1SdKILHUmsXLgsQs470gvSHIRcE9Vbe1Ku4AzkqzqljcCO46iLkkakaWe3XRdklOBJwBfqqofHm58kjOBTcDHk7yvK78R2AxsTbIHmAVuqKpKsuT6UXxHSdJRWurupt8BngHcArwpyc1V9YHW+Kr6DLB2kVU3d4+F44eqS5JGY6m7m9ZX1Su6g8SvAJ7ZZ1OSpMmw1JC45wjLkqQHoaWGxAndBW4nJHkW87cLlyQ9yC01JD7K/IVsHwHOArb31pEkaWIs9QZ/T6+qPzywkORdwMf6aUmSNCmWOpN4+ILlRx3nPiRJE2ipM4kvJ3kr8E/As4Cv9NeSJGlSLPViuj9L8nRgGvhkVX2q37akybJu02Qchrvzyg3jbkHLzFJnEgd+U8LbYkjSMjL0XWAlScuHISFJajIkJElNhoQkqcmQkCQ1GRKSpCZDQpLUZEhIkpoMCUlS05KvuB5WkhXAHwO/VFW/0dVuAnYNDNtUVXcleRJwBbAHuBeYqar7WvW+epYkHaq3kACew/zvUDx1sFhVFy4y9grg5VU1l+R84JXA1YepS5JGoLfdTVV1fVXduqC8J8nmJNcmuQAgyYnAvqqa68ZsA9a36n31K0m6vz5nEvdTVc8FSBLgqiTfAL4K3DUwbA5Y0z0Wqx8iyQwwA7B27doeupak5WssB66rqpj/ZbsnAruB1QOr1zAfCK36wvfaUlXTVTU9NTXVX9OStAyN8+yms4DPVdVeYGWSA4GwEdjRqo+hT0latkaxu+nHZyMleSfzP4V6InBrVd3SrXo9cHWSu4F9wMVHqEuSRqD3kKiqZw88f21jzBeBFy61LkkaDS+mkyQ1GRKSpCZDQpLUZEhIkpoMCUlSkyEhSWoyJCRJTSO9d5OkB751m7aPuwUA7rxyw7hbWBacSUiSmgwJSVKTISFJajIkJElNhoQkqcmQkCQ1GRKSpCZDQpLUZEhIkpoMCUlSkyEhSWrqLSSSrEjytiSfHKidnWR7kr9N8qdHW5ckjUafM4nnAB+lu4lgkgCXAc+vqhcB9yY5Z9h6j/1KkhboLSSq6vqqunWgdBpwR1Xt7Za3AeuPoi5JGpFRHpM4CZgbWJ7rasPWD5FkJsnOJDtnZ2ePe9OStJyNMiR2A6sHltd0tWHrh6iqLVU1XVXTU1NTx71pSVrORhkSu4AzkqzqljcCO46iLkkakVH8Mt19AFW1P8lmYGuSPcAscENV1TD1EfQrSer0HhJV9eyB5zcDNy8yZqi6JGk0vJhOktRkSEiSmgwJSVKTISFJajIkJElNhoQkqcmQkCQ1GRKSpCZDQpLUZEhIkpoMCUlSkyEhSWoyJCRJTYaEJKnJkJAkNRkSkqQmQ0KS1GRISJKaDAlJUlPvv3E9KMntwK3d4j7g4qqqJGcDlwD3AN+uqku78YvWJUmjMdKQAHZX1YWDhSQBLgPOraq9SS5Pcg5w02L1qrpxxD1L0rI16t1NK5K8PcnWJM/taqcBd1TV3m55G7D+MHVJ0oiMdCZRVesBkqwE/i7Jl4GTgLmBYXNdrVU/RJIZYAZg7dq1/TQuScvUWA5cV9V9wI3A44HdwOqB1Wu6Wqu+8L22VNV0VU1PTU3117QkLUPjPLvpacAXgF3AGUlWdfWNwI7D1CVJIzLqs5uuAX4IPBzYVlV3dvXNwNYke4BZ4IburKf71UfZryQtd6M+JvGKRv1m4Oal1iVJo+HFdJKkJkNCktRkSEiSmgwJSVKTISFJajIkJElNo77BnyQ9aKzbtH3cLQBw55UbentvZxKSpCZDQpLUZEhIkpoMCUlSkyEhSWoyJCRJTYaEJKnJkJAkNRkSkqQmQ0KS1GRISJKaDAlJUtPE3+AvyXnAi4H9wGer6h1jbkmSlo2JnkkkeQTwcmBjVT0PeEKSU8fcliQtGxMdEsCZwI1VVd3y9cD6MfYjSctKDv79nTxJXgqsqqr3d8vPBJ5aVW8fGDMDzHSLpwP/NvJG7+9k4HvjbmJCuC0Oclsc5LY4aBK2xWOramqxFZN+TGI38PiB5TVd7ceqaguwZZRNHUmSnVU1Pe4+JoHb4iC3xUFui4MmfVtM+u6mW4Gzk6Rb/k3g02PsR5KWlYmeSVTVXUmuBT6UZB/whar66rj7kqTlYqJDAqCqPgR8aNx9DGmidn+NmdviILfFQW6LgyZ6W0z0gWtJ0nhN+jEJSdIYGRKSpKaJPybxQJDkF5i/yO8k5k/R/XRVfW28XUnSsXMmcYySvA54E/B94F+6//5RkkvH2tgESXLSuHvQeCU5Nckju+ePTvIz4+5pEiS5cNw9HIkziWP3K1X1ggW1Dyf54Fi6GaPuZoyvYn429Y6q+my3ajNw0dga01gleRPw88DJSbYALwMekuTD3dmLy0aSq4AVBxaBM5M8BdhXVRP5/4ghcexa23DlSLuYDOdW1VlJTgQ2J1nX/RHIkV6oB7XTq+q8JKuBncCpVfWjJNfxwDu9/Vg9Eng/8PVu+W3dY//YOjoCQ+LY/U2SjwM3AnPM3zrk14Frx9rVeMwBVNX/Aq9L8gdJzgeW5XnWST7BwX81/rgM/F9VbRhDS+OyB6Cqvp/ks1X1o65+9xh7GpffBt4APLSqPp7k7qr65ribOhxD4hhV1V8n+Sjzd6w9Cfgy8FdV9T/j7WwsDvmDWFXvTnIRcO6Y+hm324Drq+pz425kzPYNPH/zwPNHjLqRcauq/cBbk/xWkkt4AMyyvZhOvUvytIHjE8tGkocAG6rqY+PuZRIleXJV3T7uPsYlyS8CL6mqTePu5XAMCUlSk6fASpKaDAlJUpMhIR2jJD+b5C8a634tyWVDvNcnjl9n0rEzJKRjt4L7n+q6lHWLWY7X12iCeQqsdJwkeQ7wDOZPa/xBVb2lWzWd5J3MX0j1w6p6TZKVwLuYv4hqNfD2qvrK6LuWDs+ZhHT8fBM4kfmLB1/QXWEMcEJVvbaqLmD+dhRPBc4H/rmqfh+4mPlbl0gTx5mEdHw8hPlfGHteVX0nyTrgYd26LwyMux1YBzwBWNGdKw/wg5F0KQ3JkJCOjwL+owuIn2D+CvwDfnXg+ZOAvwROAf69qraNrkVpeIaEdOz2M3/riW8leQ/wk8A/Mh8c+4H/TPJuYBXwnar61yRfB/48yYZuzEeq6h+A+8bQv9TkFdeSpCYPXEuSmgwJSVKTISFJajIkJElNhoQkqcmQkCQ1GRKSpKb/B5WVH/ij8wR1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_kaggle.label.value_counts().plot.bar()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-calendar",
   "metadata": {
    "id": "cognitive-calendar",
    "papermill": {
     "duration": 0.027966,
     "end_time": "2021-05-30T18:39:35.973791",
     "exception": false,
     "start_time": "2021-05-30T18:39:35.945825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Observation\n",
    "As our dataset is imbalanced, we will balance our class by weighting majority class less and minoiry class more\n",
    "\n",
    "## 관찰\n",
    "데이터 세트가 불균형적이므로 다수 클래스는 덜 가중치 부여하고 소수 클래스는 더 가중치를 부여하여 클래스 균형을 맞출 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-enzyme",
   "metadata": {
    "id": "dense-enzyme",
    "papermill": {
     "duration": 0.028255,
     "end_time": "2021-05-30T18:39:36.030250",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.001995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DataGenerator train and validation\n",
    "We will use kaggle dataset as train set and compitition dataset as validation set. If train and validation metric is similar, it shows their distribution is similar and hence we can use kaggle dataset as well.\n",
    "\n",
    "# 데이터 생성기 교육 및 검증\n",
    "우리는 캐글 데이터 세트를 열차 세트로, 컴포지션 데이터 세트를 검증 세트로 사용할 것이다. 열차와 검증 메트릭이 유사한 경우 분포가 유사함을 보여주므로 캐글 데이터 세트도 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "encouraging-novel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:36.090553Z",
     "iopub.status.busy": "2021-05-30T18:39:36.089729Z",
     "iopub.status.idle": "2021-05-30T18:39:36.092340Z",
     "shell.execute_reply": "2021-05-30T18:39:36.091828Z",
     "shell.execute_reply.started": "2021-05-30T09:28:44.189248Z"
    },
    "id": "encouraging-novel",
    "papermill": {
     "duration": 0.035021,
     "end_time": "2021-05-30T18:39:36.092447",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.057426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train data generator object\n",
    "train_aug = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    "  )\n",
    "\n",
    "# validation data generator object\n",
    "valid_aug = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "geological-philadelphia",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:36.172890Z",
     "iopub.status.busy": "2021-05-30T18:39:36.167698Z",
     "iopub.status.idle": "2021-05-30T18:39:39.954054Z",
     "shell.execute_reply": "2021-05-30T18:39:39.954888Z",
     "shell.execute_reply.started": "2021-05-30T09:28:47.478488Z"
    },
    "id": "geological-philadelphia",
    "outputId": "358f5e4e-a7b9-4d32-d0be-5a08a4e27ace",
    "papermill": {
     "duration": 3.835127,
     "end_time": "2021-05-30T18:39:39.955083",
     "exception": false,
     "start_time": "2021-05-30T18:39:36.119956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9786 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# create train generator\n",
    "train_generator = train_aug.flow_from_dataframe(\n",
    "    dataframe=df_train_kaggle,\n",
    "    directory=None,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    batch_size=8,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-chest",
   "metadata": {
    "id": "asian-chest",
    "papermill": {
     "duration": 0.027295,
     "end_time": "2021-05-30T18:39:40.011354",
     "exception": false,
     "start_time": "2021-05-30T18:39:39.984059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create validation dataframe using compitition dataset.\n",
    "We will download compition dataset from gdrive and use it as validation set to validated against kaggle dataset\n",
    "\n",
    "# composition dataset을 이용하여 검증 데이터 프레임을 생성합니다.\n",
    "gdrive에서 컴포지션 데이터 세트를 다운로드하여 Kaggle 데이터 세트에 대해 검증된 검증 세트로 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "opening-there",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:39:40.083024Z",
     "iopub.status.busy": "2021-05-30T18:39:40.070866Z",
     "iopub.status.idle": "2021-05-30T18:39:59.971445Z",
     "shell.execute_reply": "2021-05-30T18:39:59.970929Z",
     "shell.execute_reply.started": "2021-05-30T08:33:03.440635Z"
    },
    "id": "opening-there",
    "outputId": "72cebcb2-17b3-4ee2-a2c0-94a96edcb0c6",
    "papermill": {
     "duration": 19.932071,
     "end_time": "2021-05-30T18:39:59.971577",
     "exception": false,
     "start_time": "2021-05-30T18:39:40.039506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (4.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from gdown) (4.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from gdown) (3.4.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.58.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.6/dist-packages (from gdown) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (1.26.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2.6)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1NdDqPK4NLn2aV8ZdF5ilux1sfG6IyebC\n",
      "To: /home/KneeXray.zip\n",
      "100%|████████████████████████████████████████| 120M/120M [00:08<00:00, 14.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "# download data from shared google drive link\n",
    "!pip install gdown\n",
    "!gdown --id \"1NdDqPK4NLn2aV8ZdF5ilux1sfG6IyebC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "controlled-macedonia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:00.065743Z",
     "iopub.status.busy": "2021-05-30T18:40:00.063845Z",
     "iopub.status.idle": "2021-05-30T18:40:02.157906Z",
     "shell.execute_reply": "2021-05-30T18:40:02.157449Z",
     "shell.execute_reply.started": "2021-05-30T08:33:21.245827Z"
    },
    "id": "controlled-macedonia",
    "papermill": {
     "duration": 2.152312,
     "end_time": "2021-05-30T18:40:02.158032",
     "exception": false,
     "start_time": "2021-05-30T18:40:00.005720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unzip the data\n",
    "!unzip -q -o /home/KneeXray.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "threaded-characterization",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.229132Z",
     "iopub.status.busy": "2021-05-30T18:40:02.228400Z",
     "iopub.status.idle": "2021-05-30T18:40:02.250117Z",
     "shell.execute_reply": "2021-05-30T18:40:02.250642Z",
     "shell.execute_reply.started": "2021-05-30T08:33:23.833280Z"
    },
    "id": "threaded-characterization",
    "outputId": "283093ce-0819-4542-9ff8-555713912e62",
    "papermill": {
     "duration": 0.059732,
     "end_time": "2021-05-30T18:40:02.250775",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.191043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/KneeXray/train/Image_1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/KneeXray/train/Image_2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/KneeXray/train/Image_3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/KneeXray/train/Image_4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/KneeXray/train/Image_5.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  label\n",
       "0  /home/KneeXray/train/Image_1.jpg      0\n",
       "1  /home/KneeXray/train/Image_2.jpg      1\n",
       "2  /home/KneeXray/train/Image_3.jpg      0\n",
       "3  /home/KneeXray/train/Image_4.jpg      1\n",
       "4  /home/KneeXray/train/Image_5.jpg      2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read Train.csv file which contains image names and labels and preprocess them\n",
    "compi_root_path= \"/home/KneeXray/\"\n",
    "df_val_compi = pd.read_csv(compi_root_path + \"Train.csv\")\n",
    "\n",
    "# add absolute path to the image names\n",
    "df_val_compi[\"filename\"] = df_val_compi.filename.apply(lambda x: compi_root_path+\"train/\" + x)\n",
    "df_val_compi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "suburban-shareware",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.339459Z",
     "iopub.status.busy": "2021-05-30T18:40:02.324109Z",
     "iopub.status.idle": "2021-05-30T18:40:02.442504Z",
     "shell.execute_reply": "2021-05-30T18:40:02.442056Z",
     "shell.execute_reply.started": "2021-05-30T08:33:23.865039Z"
    },
    "id": "suburban-shareware",
    "outputId": "8fb91f05-54a6-4bc7-d95f-68ea55748335",
    "papermill": {
     "duration": 0.158988,
     "end_time": "2021-05-30T18:40:02.442618",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.283630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class count of compitition dataset\n",
    "df_val_compi.label.value_counts().plot.bar()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "saving-homework",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.529039Z",
     "iopub.status.busy": "2021-05-30T18:40:02.528305Z",
     "iopub.status.idle": "2021-05-30T18:40:02.574290Z",
     "shell.execute_reply": "2021-05-30T18:40:02.574903Z",
     "shell.execute_reply.started": "2021-05-30T08:54:21.600981Z"
    },
    "id": "saving-homework",
    "outputId": "178977a9-4413-4d38-b7f0-de8a9904b0e0",
    "papermill": {
     "duration": 0.098388,
     "end_time": "2021-05-30T18:40:02.575081",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.476693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7828 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# create validation generator\n",
    "valid_generator = valid_aug.flow_from_dataframe( \n",
    "    dataframe= df_val_compi,\n",
    "    x_col= \"filename\",\n",
    "    y_col= \"label\",\n",
    "    batch_size= 8,\n",
    "    seed= 42,\n",
    "    shuffle= True,\n",
    "    class_mode= \"raw\",\n",
    "    target_size= (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-belarus",
   "metadata": {
    "id": "marked-belarus",
    "papermill": {
     "duration": 0.033792,
     "end_time": "2021-05-30T18:40:02.643887",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.610095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Architecture\n",
    "Here we will be using Xception by google. (I encourage you to try different architectures)\n",
    "\n",
    "## 모델 아키텍처\n",
    "여기서는 구글의 Xception을 사용할 것입니다. (다양한 아키텍처를 사용해 보십시오)\n",
    "\n",
    "## CheXNet - DenseNet121 + Sigmoid\n",
    "https://github.com/arnoweng/CheXNet/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "buried-tablet",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:02.724467Z",
     "iopub.status.busy": "2021-05-30T18:40:02.723830Z",
     "iopub.status.idle": "2021-05-30T18:40:08.132744Z",
     "shell.execute_reply": "2021-05-30T18:40:08.131632Z",
     "shell.execute_reply.started": "2021-05-30T09:28:56.068101Z"
    },
    "id": "buried-tablet",
    "outputId": "2be7f5dd-25c9-49e7-fce8-f3e1fbe9c6a1",
    "papermill": {
     "duration": 5.455093,
     "end_time": "2021-05-30T18:40:08.132878",
     "exception": false,
     "start_time": "2021-05-30T18:40:02.677785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "xception = DenseNet121(weights = \"imagenet\",)\n",
    "x =  xception.layers[-3].output\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 1536, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 768, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 384, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size= 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = n_class, kernel_size = 3, padding = \"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "GAP = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "pred = tf.keras.activations.softmax(GAP)\n",
    "\n",
    "xception_model = Model(inputs=xception.input,outputs = pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "DYVqXESmD_Fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYVqXESmD_Fd",
    "outputId": "88696012-6f00-42ba-d016-645743054fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 7, 7, 1536)   14157312    relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 7, 7, 1536)   6144        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 7, 7, 1536)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 7, 7, 1024)   14156800    activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 7, 7, 1024)   4096        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 7, 7, 1024)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 7, 7, 768)    7078656     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 7, 7, 768)    3072        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 7, 7, 768)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 7, 7, 512)    3539456     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 7, 7, 512)    2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 7, 7, 512)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 7, 7, 384)    1769856     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 7, 7, 384)    1536        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 7, 7, 384)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 7, 7, 256)    884992      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 7, 7, 256)    1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 7, 7, 256)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 7, 7, 128)    295040      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 7, 7, 128)    512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 7, 7, 128)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 7, 7, 64)     73792       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 7, 7, 64)     256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 7, 7, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 7, 7, 32)     18464       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 7, 7, 32)     128         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 7, 7, 32)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 7, 7, 16)     4624        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 7, 7, 16)     64          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 7, 7, 16)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 7, 7, 5)      725         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 7, 7, 5)      20          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 7, 7, 5)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 5)            0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.softmax_1 (TFOp (None, 5)            0           global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 49,036,121\n",
      "Trainable params: 48,943,023\n",
      "Non-trainable params: 93,098\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "norman-detector",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:08.391663Z",
     "iopub.status.busy": "2021-05-30T18:40:08.385701Z",
     "iopub.status.idle": "2021-05-30T18:40:08.398432Z",
     "shell.execute_reply": "2021-05-30T18:40:08.397997Z",
     "shell.execute_reply.started": "2021-05-30T09:28:58.465217Z"
    },
    "id": "norman-detector",
    "papermill": {
     "duration": 0.226948,
     "end_time": "2021-05-30T18:40:08.398547",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.171599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "xception_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001, decay = 0.0001),\n",
    "                 metrics = [\"acc\"],\n",
    "                 loss = tf.keras.losses.sparse_categorical_crossentropy)\n",
    "\n",
    "# callbacks and checkpoints\n",
    "checkpoint_path = \"xception_best.ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "my_callbacks = [\n",
    "              ModelCheckpoint(\n",
    "                   checkpoint_path,\n",
    "                   monitor = 'val_acc',\n",
    "                   verbose = 1,\n",
    "                   save_weights_only = True,\n",
    "                   save_best_only = True,\n",
    "                   mode = \"max\"\n",
    "                  ),\n",
    "              EarlyStopping(\n",
    "                   monitor = 'val_loss',\n",
    "                   patience = 5,\n",
    "                   verbose = 0\n",
    "                  ),\n",
    "              ReduceLROnPlateau(\n",
    "                   monitor = 'val_loss',\n",
    "                   patience = 5,\n",
    "                   verbose = 1\n",
    "                  )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-administration",
   "metadata": {
    "id": "crucial-administration",
    "papermill": {
     "duration": 0.038495,
     "end_time": "2021-05-30T18:40:08.475329",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.436834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Weighting classes\n",
    "As we have unevenly class distibution, we will weight them based on the number of samples\n",
    "\n",
    "### 가중치 클래스\n",
    "우리는 등급 차이가 일정하지 않기 때문에 샘플 수에 따라 무게를 재도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "regional-indie",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:08.558435Z",
     "iopub.status.busy": "2021-05-30T18:40:08.557616Z",
     "iopub.status.idle": "2021-05-30T18:40:09.060821Z",
     "shell.execute_reply": "2021-05-30T18:40:09.060357Z",
     "shell.execute_reply.started": "2021-05-30T09:30:11.007618Z"
    },
    "id": "regional-indie",
    "papermill": {
     "duration": 0.546357,
     "end_time": "2021-05-30T18:40:09.060960",
     "exception": false,
     "start_time": "2021-05-30T18:40:08.514603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes = np.unique(df_train_kaggle.label.values),\n",
    "    y = df_train_kaggle.label.values\n",
    "  )\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-better",
   "metadata": {
    "id": "square-better",
    "papermill": {
     "duration": 0.037503,
     "end_time": "2021-05-30T18:40:09.136492",
     "exception": false,
     "start_time": "2021-05-30T18:40:09.098989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train\n",
    "Lets roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hidden-stephen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T18:40:09.218272Z",
     "iopub.status.busy": "2021-05-30T18:40:09.217728Z",
     "iopub.status.idle": "2021-05-30T20:12:12.156502Z",
     "shell.execute_reply": "2021-05-30T20:12:12.154537Z",
     "shell.execute_reply.started": "2021-05-26T18:49:57.904339Z"
    },
    "id": "hidden-stephen",
    "outputId": "3f60471b-8d09-471d-fb05-9b069c83bc2c",
    "papermill": {
     "duration": 5522.981999,
     "end_time": "2021-05-30T20:12:12.156678",
     "exception": false,
     "start_time": "2021-05-30T18:40:09.174679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "306/306 [==============================] - 104s 254ms/step - loss: 1.4449 - acc: 0.2933 - val_loss: 1.5197 - val_acc: 0.3022\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.30225, saving model to xception_best.ckpt\n",
      "Epoch 2/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 1.2059 - acc: 0.4694 - val_loss: 1.4840 - val_acc: 0.3645\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.30225 to 0.36446, saving model to xception_best.ckpt\n",
      "Epoch 3/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 1.0602 - acc: 0.5740 - val_loss: 1.2899 - val_acc: 0.5305\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.36446 to 0.53053, saving model to xception_best.ckpt\n",
      "Epoch 4/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.9490 - acc: 0.6501 - val_loss: 1.2033 - val_acc: 0.5911\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.53053 to 0.59108, saving model to xception_best.ckpt\n",
      "Epoch 5/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.8694 - acc: 0.7054 - val_loss: 1.1448 - val_acc: 0.6519\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.59108 to 0.65189, saving model to xception_best.ckpt\n",
      "Epoch 6/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.7896 - acc: 0.7709 - val_loss: 1.1247 - val_acc: 0.6514\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.65189\n",
      "Epoch 7/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.7261 - acc: 0.8209 - val_loss: 1.0533 - val_acc: 0.7195\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.65189 to 0.71947, saving model to xception_best.ckpt\n",
      "Epoch 8/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.6667 - acc: 0.8626 - val_loss: 1.0780 - val_acc: 0.7020\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.71947\n",
      "Epoch 9/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.6262 - acc: 0.8947 - val_loss: 0.9829 - val_acc: 0.7870\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.71947 to 0.78705, saving model to xception_best.ckpt\n",
      "Epoch 10/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.5987 - acc: 0.9161 - val_loss: 0.9926 - val_acc: 0.7846\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.78705\n",
      "Epoch 11/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.5648 - acc: 0.9390 - val_loss: 0.9646 - val_acc: 0.8002\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.78705 to 0.80020, saving model to xception_best.ckpt\n",
      "Epoch 12/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.5495 - acc: 0.9488 - val_loss: 0.9858 - val_acc: 0.8103\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.80020 to 0.81030, saving model to xception_best.ckpt\n",
      "Epoch 13/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.5288 - acc: 0.9593 - val_loss: 0.9359 - val_acc: 0.8241\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.81030 to 0.82409, saving model to xception_best.ckpt\n",
      "Epoch 14/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.5152 - acc: 0.9707 - val_loss: 0.9952 - val_acc: 0.7821\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.82409\n",
      "Epoch 15/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.5079 - acc: 0.9732 - val_loss: 0.9048 - val_acc: 0.8468\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.82409 to 0.84683, saving model to xception_best.ckpt\n",
      "Epoch 16/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4945 - acc: 0.9800 - val_loss: 0.8947 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.84683 to 0.85871, saving model to xception_best.ckpt\n",
      "Epoch 17/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4900 - acc: 0.9804 - val_loss: 0.9005 - val_acc: 0.8514\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.85871\n",
      "Epoch 18/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4801 - acc: 0.9845 - val_loss: 0.8730 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.85871 to 0.88056, saving model to xception_best.ckpt\n",
      "Epoch 19/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4700 - acc: 0.9874 - val_loss: 0.8882 - val_acc: 0.8576\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.88056\n",
      "Epoch 20/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4643 - acc: 0.9928 - val_loss: 0.9035 - val_acc: 0.8466\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.88056\n",
      "Epoch 21/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4581 - acc: 0.9901 - val_loss: 0.8542 - val_acc: 0.8758\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.88056\n",
      "Epoch 22/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4550 - acc: 0.9936 - val_loss: 0.8650 - val_acc: 0.8762\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.88056\n",
      "Epoch 23/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4464 - acc: 0.9946 - val_loss: 0.8382 - val_acc: 0.8965\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.88056 to 0.89653, saving model to xception_best.ckpt\n",
      "Epoch 24/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4507 - acc: 0.9943 - val_loss: 0.8497 - val_acc: 0.8770\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.89653\n",
      "Epoch 25/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4409 - acc: 0.9957 - val_loss: 0.8414 - val_acc: 0.8859\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.89653\n",
      "Epoch 26/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4399 - acc: 0.9938 - val_loss: 0.8121 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.89653 to 0.90304, saving model to xception_best.ckpt\n",
      "Epoch 27/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4321 - acc: 0.9960 - val_loss: 0.8340 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.90304\n",
      "Epoch 28/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4325 - acc: 0.9968 - val_loss: 0.8091 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.90304 to 0.90560, saving model to xception_best.ckpt\n",
      "Epoch 29/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4330 - acc: 0.9963 - val_loss: 0.8357 - val_acc: 0.8775\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.90560\n",
      "Epoch 30/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4276 - acc: 0.9968 - val_loss: 0.8283 - val_acc: 0.8777\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.90560\n",
      "Epoch 31/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4232 - acc: 0.9965 - val_loss: 0.8421 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.90560\n",
      "Epoch 32/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4281 - acc: 0.9970 - val_loss: 0.8541 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.90560\n",
      "Epoch 33/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4222 - acc: 0.9967 - val_loss: 0.7821 - val_acc: 0.9082\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.90560 to 0.90815, saving model to xception_best.ckpt\n",
      "Epoch 34/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4182 - acc: 0.9981 - val_loss: 0.7833 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.90815 to 0.91224, saving model to xception_best.ckpt\n",
      "Epoch 35/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4144 - acc: 0.9981 - val_loss: 0.7904 - val_acc: 0.8995\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.91224\n",
      "Epoch 36/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4112 - acc: 0.9961 - val_loss: 0.8823 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.91224\n",
      "Epoch 37/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4096 - acc: 0.9966 - val_loss: 0.7689 - val_acc: 0.9142\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.91224 to 0.91415, saving model to xception_best.ckpt\n",
      "Epoch 38/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4067 - acc: 0.9985 - val_loss: 0.7723 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.91415\n",
      "Epoch 39/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4110 - acc: 0.9967 - val_loss: 0.7851 - val_acc: 0.8967\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.91415\n",
      "Epoch 40/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4102 - acc: 0.9968 - val_loss: 0.7694 - val_acc: 0.9016\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.91415\n",
      "Epoch 41/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4078 - acc: 0.9963 - val_loss: 0.7505 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.91415 to 0.91454, saving model to xception_best.ckpt\n",
      "Epoch 42/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.3999 - acc: 0.9985 - val_loss: 0.7662 - val_acc: 0.9021\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.91454\n",
      "Epoch 43/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4020 - acc: 0.9989 - val_loss: 0.8098 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.91454\n",
      "Epoch 44/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4021 - acc: 0.9973 - val_loss: 0.7376 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.91454 to 0.91926, saving model to xception_best.ckpt\n",
      "Epoch 45/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.3981 - acc: 0.9978 - val_loss: 0.7661 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.91926\n",
      "Epoch 46/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.3956 - acc: 0.9983 - val_loss: 0.7427 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.91926\n",
      "Epoch 47/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.4022 - acc: 0.9985 - val_loss: 0.7385 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.91926\n",
      "Epoch 48/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.3997 - acc: 0.9963 - val_loss: 0.7615 - val_acc: 0.8983\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.91926\n",
      "Epoch 49/100\n",
      "306/306 [==============================] - 74s 243ms/step - loss: 0.3921 - acc: 0.9991 - val_loss: 0.7636 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.91926\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f26437fa550>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "xception_model.fit(\n",
    "        train_generator,\n",
    "        epochs = 100,\n",
    "        validation_data = valid_generator,\n",
    "        callbacks = [my_callbacks],\n",
    "        class_weight = class_weights\n",
    "      )\n",
    "\n",
    "# load best saved weights\n",
    "xception_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-morris",
   "metadata": {
    "id": "pretty-morris",
    "papermill": {
     "duration": 3.201635,
     "end_time": "2021-05-30T20:12:18.344310",
     "exception": false,
     "start_time": "2021-05-30T20:12:15.142675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Observation\n",
    "As we can see train and validation accuracy is pretty close, which proves kaggle and competition data has come from the same distribution and we can freely use it to experiment with.\n",
    "\n",
    "## Retraining last trained model on competition data\n",
    "As we have used competition data as validation set previously, we will use it as train set now (and some part of it as validation set) hoping this additional training would give our model new information to perform better.\n",
    "\n",
    "## 관찰\n",
    "보시다시피 열차와 검증 정확도는 매우 가까우며, 이는 카글과 경쟁 데이터가 동일한 분포에서 나왔다는 것을 증명하며, 이를 실험하는 데 자유롭게 사용할 수 있습니다.\n",
    "\n",
    "## 경기 데이터에 대해 마지막으로 훈련된 모델 재교육\n",
    "이전에 경쟁 데이터를 검증 세트로 사용했으므로, 이제 열차 세트로 사용할 것이며(그리고 그 중 일부는 검증 세트로) 이 추가 교육을 통해 모델이 더 나은 성능을 발휘할 수 있는 새로운 정보를 얻을 수 있기를 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cloudy-idaho",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:24.238372Z",
     "iopub.status.busy": "2021-05-30T20:12:24.237660Z",
     "iopub.status.idle": "2021-05-30T20:12:24.305208Z",
     "shell.execute_reply": "2021-05-30T20:12:24.305579Z",
     "shell.execute_reply.started": "2021-05-30T09:30:16.948040Z"
    },
    "id": "cloudy-idaho",
    "papermill": {
     "duration": 3.027306,
     "end_time": "2021-05-30T20:12:24.305720",
     "exception": false,
     "start_time": "2021-05-30T20:12:21.278414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train and validation split on competition data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(\n",
    "    df_val_compi,\n",
    "    test_size = 0.1,\n",
    "    random_state = 42,\n",
    "    stratify = df_val_compi.label\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "nervous-crisis",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:30.429807Z",
     "iopub.status.busy": "2021-05-30T20:12:30.429001Z",
     "iopub.status.idle": "2021-05-30T20:12:30.472297Z",
     "shell.execute_reply": "2021-05-30T20:12:30.471634Z",
     "shell.execute_reply.started": "2021-05-30T09:30:18.098841Z"
    },
    "id": "nervous-crisis",
    "outputId": "fa3e5791-4503-4ee4-8fd0-ab9c8b3c0525",
    "papermill": {
     "duration": 3.239148,
     "end_time": "2021-05-30T20:12:30.472465",
     "exception": false,
     "start_time": "2021-05-30T20:12:27.233317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7045 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_aug.flow_from_dataframe(\n",
    "    dataframe = X_train,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "instrumental-indie",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:36.309467Z",
     "iopub.status.busy": "2021-05-30T20:12:36.308631Z",
     "iopub.status.idle": "2021-05-30T20:12:36.318017Z",
     "shell.execute_reply": "2021-05-30T20:12:36.317530Z",
     "shell.execute_reply.started": "2021-05-30T09:30:23.206485Z"
    },
    "id": "instrumental-indie",
    "outputId": "9165daf2-7a24-446a-b73a-cf8700918d0b",
    "papermill": {
     "duration": 2.927421,
     "end_time": "2021-05-30T20:12:36.318129",
     "exception": false,
     "start_time": "2021-05-30T20:12:33.390708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 783 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = valid_aug.flow_from_dataframe( \n",
    "    dataframe = X_test,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"raw\",\n",
    "    target_size = (224,224)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dedicated-chapel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:42.897491Z",
     "iopub.status.busy": "2021-05-30T20:12:42.895853Z",
     "iopub.status.idle": "2021-05-30T20:12:42.898202Z",
     "shell.execute_reply": "2021-05-30T20:12:42.898602Z",
     "shell.execute_reply.started": "2021-05-30T09:30:26.966513Z"
    },
    "id": "dedicated-chapel",
    "papermill": {
     "duration": 3.108025,
     "end_time": "2021-05-30T20:12:42.898739",
     "exception": false,
     "start_time": "2021-05-30T20:12:39.790714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of steps to consider 1 as  epoch\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sized-norfolk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:12:48.820785Z",
     "iopub.status.busy": "2021-05-30T20:12:48.819337Z",
     "iopub.status.idle": "2021-05-30T20:25:26.371458Z",
     "shell.execute_reply": "2021-05-30T20:25:26.371941Z",
     "shell.execute_reply.started": "2021-05-30T09:30:36.962285Z"
    },
    "id": "sized-norfolk",
    "outputId": "31c1072e-449f-4c31-9ab7-e08107cb0976",
    "papermill": {
     "duration": 760.527609,
     "end_time": "2021-05-30T20:25:26.372105",
     "exception": false,
     "start_time": "2021-05-30T20:12:45.844496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "220/220 [==============================] - 51s 208ms/step - loss: 0.7202 - acc: 0.8797 - val_loss: 0.8871 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.91926\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 45s 204ms/step - loss: 0.6268 - acc: 0.9413 - val_loss: 0.6876 - val_acc: 0.9076\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91926\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 45s 204ms/step - loss: 0.5774 - acc: 0.9766 - val_loss: 0.6366 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91926 to 0.93880, saving model to xception_best.ckpt\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 45s 204ms/step - loss: 0.5648 - acc: 0.9836 - val_loss: 0.6404 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.93880\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 45s 203ms/step - loss: 0.5526 - acc: 0.9894 - val_loss: 0.6487 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.93880\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 45s 203ms/step - loss: 0.5501 - acc: 0.9913 - val_loss: 0.6674 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93880\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 45s 203ms/step - loss: 0.5504 - acc: 0.9904 - val_loss: 0.6665 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.93880\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 45s 204ms/step - loss: 0.5452 - acc: 0.9923 - val_loss: 0.6459 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93880\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f25d563c290>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kick off training\n",
    "xception_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "        epochs = 50,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = STEP_SIZE_VALID,callbacks = [my_callbacks]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "complete-spelling",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:33.497837Z",
     "iopub.status.busy": "2021-05-30T20:25:33.496999Z",
     "iopub.status.idle": "2021-05-30T20:25:34.695800Z",
     "shell.execute_reply": "2021-05-30T20:25:34.695365Z",
     "shell.execute_reply.started": "2021-05-24T16:41:06.725854Z"
    },
    "id": "complete-spelling",
    "outputId": "a0128618-5cf0-4a00-a3ac-0dc7de725bf0",
    "papermill": {
     "duration": 4.566888,
     "end_time": "2021-05-30T20:25:34.695951",
     "exception": false,
     "start_time": "2021-05-30T20:25:30.129063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f25d57a6d50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best saved weights\n",
    "xception_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-cylinder",
   "metadata": {
    "id": "intended-cylinder",
    "papermill": {
     "duration": 3.633537,
     "end_time": "2021-05-30T20:25:41.743104",
     "exception": false,
     "start_time": "2021-05-30T20:25:38.109567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Confusion Matrix\n",
    "As our data set is imbalaned, lets see where is our model making mistakes. I encourage to you to take initative for bringing FPs and FNs down.\n",
    "\n",
    "# 혼란 매트릭스\n",
    "데이터 세트가 불균형 상태이므로 모델이 어디에서 실수를 하는지 살펴보자. FP와 FN을 끌어내리는데 솔선수범하길 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "equivalent-album",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:48.625234Z",
     "iopub.status.busy": "2021-05-30T20:25:48.624438Z",
     "iopub.status.idle": "2021-05-30T20:25:48.634216Z",
     "shell.execute_reply": "2021-05-30T20:25:48.633804Z",
     "shell.execute_reply.started": "2021-05-27T05:35:10.161826Z"
    },
    "id": "equivalent-album",
    "outputId": "2da8e6ed-d6f9-4eda-d770-c354555a3fd7",
    "papermill": {
     "duration": 3.430239,
     "end_time": "2021-05-30T20:25:48.634343",
     "exception": false,
     "start_time": "2021-05-30T20:25:45.204104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 783 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "target_shape = 224\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# test generator\n",
    "compi_gen = valid_aug.flow_from_dataframe(\n",
    "    dataframe = X_test,\n",
    "    x_col = \"filename\",\n",
    "    class_mode = None,\n",
    "    target_size = (target_shape, target_shape),\n",
    "    shuffle = False,\n",
    "    batch_size = BATCH_SIZE\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "preceding-delight",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:25:56.117007Z",
     "iopub.status.busy": "2021-05-30T20:25:56.116264Z",
     "iopub.status.idle": "2021-05-30T20:26:05.659358Z",
     "shell.execute_reply": "2021-05-30T20:26:05.658569Z",
     "shell.execute_reply.started": "2021-05-27T05:35:17.324361Z"
    },
    "id": "preceding-delight",
    "outputId": "8cb3ac1b-b2bc-4672-9bae-bf65a97f41d4",
    "papermill": {
     "duration": 12.914933,
     "end_time": "2021-05-30T20:26:05.659489",
     "exception": false,
     "start_time": "2021-05-30T20:25:52.744556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 14s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# prediction on train data\n",
    "predicition_compi = xception_model.predict(compi_gen, steps = compi_gen.n/ BATCH_SIZE, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "distinguished-midwest",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:12.667940Z",
     "iopub.status.busy": "2021-05-30T20:26:12.649791Z",
     "iopub.status.idle": "2021-05-30T20:26:13.051891Z",
     "shell.execute_reply": "2021-05-30T20:26:13.051413Z",
     "shell.execute_reply.started": "2021-05-27T05:43:44.837052Z"
    },
    "id": "distinguished-midwest",
    "outputId": "cd5327cd-6290-4225-9360-aa951675b70b",
    "papermill": {
     "duration": 3.832152,
     "end_time": "2021-05-30T20:26:13.052010",
     "exception": false,
     "start_time": "2021-05-30T20:26:09.219858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f25d44b6850>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "class_prediction_compi = np.argmax(predicition_compi, axis = 1)\n",
    "cm = confusion_matrix(X_test.label, class_prediction_compi, labels = [0, 1, 2, 3, 4])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix = cm,\n",
    "    display_labels = [0, 1, 2, 3, 4]\n",
    "  )\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-wilson",
   "metadata": {
    "id": "positive-wilson",
    "papermill": {
     "duration": 3.5306,
     "end_time": "2021-05-30T20:26:20.277590",
     "exception": false,
     "start_time": "2021-05-30T20:26:16.746990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Making prediction on test set (to make submission)\n",
    "Finally we save the predictions on disk in CSV format\n",
    "\n",
    "## 시험세트 예측하기 (제출하기)\n",
    "마지막으로 예측 내용을 CSV 형식으로 디스크에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "constitutional-catholic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:28.031789Z",
     "iopub.status.busy": "2021-05-30T20:26:28.031111Z",
     "iopub.status.idle": "2021-05-30T20:26:28.058944Z",
     "shell.execute_reply": "2021-05-30T20:26:28.058161Z",
     "shell.execute_reply.started": "2021-05-27T09:08:20.550041Z"
    },
    "id": "constitutional-catholic",
    "outputId": "127f7450-99d8-4880-c5a2-e07c01344142",
    "papermill": {
     "duration": 4.034446,
     "end_time": "2021-05-30T20:26:28.059074",
     "exception": false,
     "start_time": "2021-05-30T20:26:24.024628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1958 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# read the csv file\n",
    "test = pd.read_csv(compi_root_path + \"Test.csv\")\n",
    "\n",
    "# create test generator\n",
    "test_generator = valid_aug.flow_from_dataframe(\n",
    "    dataframe = test,\n",
    "    directory = compi_root_path + \"test\",\n",
    "    x_col = \"filename\",\n",
    "    y_col = None,\n",
    "    batch_size = 1,\n",
    "    seed = 42,\n",
    "    shuffle = False,\n",
    "    class_mode = None,\n",
    "    target_size = (224,224)\n",
    "  )\n",
    "\n",
    "# number of steps to consider 1 epoch\n",
    "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "blocked-niagara",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:26:34.994605Z",
     "iopub.status.busy": "2021-05-30T20:26:34.994000Z",
     "iopub.status.idle": "2021-05-30T20:26:56.340759Z",
     "shell.execute_reply": "2021-05-30T20:26:56.341118Z",
     "shell.execute_reply.started": "2021-05-27T05:51:39.116529Z"
    },
    "id": "blocked-niagara",
    "outputId": "92a7f207-7ced-4ade-d9f0-d3f37e0f782f",
    "papermill": {
     "duration": 24.791614,
     "end_time": "2021-05-30T20:26:56.341303",
     "exception": false,
     "start_time": "2021-05-30T20:26:31.549689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958/1958 [==============================] - 31s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    767\n",
       "2    513\n",
       "1    361\n",
       "3    258\n",
       "4     59\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction and create dataframe out of it\n",
    "pred = xception_model.predict(test_generator,steps=STEP_SIZE_TEST,verbose=1)\n",
    "df_submit = pd.DataFrame({\"label\":np.argmax(pred, axis= 1)})\n",
    "df_submit[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-arthur",
   "metadata": {
    "id": "still-arthur",
    "papermill": {
     "duration": 3.549425,
     "end_time": "2021-05-30T20:27:04.148458",
     "exception": false,
     "start_time": "2021-05-30T20:27:00.599033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Clearing the working directory\n",
    "Because if don't, \"output\" tabl will show only images\n",
    "\n",
    "### 작업 디렉토리 지우기\n",
    "그렇지 않으면 \"출력\" 탭이 이미지만 표시되기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "decimal-hampshire",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-30T20:27:11.522864Z",
     "iopub.status.busy": "2021-05-30T20:27:11.522085Z",
     "iopub.status.idle": "2021-05-30T20:27:11.842332Z",
     "shell.execute_reply": "2021-05-30T20:27:11.842916Z",
     "shell.execute_reply.started": "2021-05-27T05:51:43.875589Z"
    },
    "id": "decimal-hampshire",
    "outputId": "4c58489b-a23b-4dfb-845f-60432705e0d7",
    "papermill": {
     "duration": 4.080149,
     "end_time": "2021-05-30T20:27:11.843118",
     "exception": false,
     "start_time": "2021-05-30T20:27:07.762969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: /kaggle/working - No such file or directory.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import shutil\n",
    "\n",
    "# Get directory name\n",
    "mydir = \"/kaggle/working\"\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(mydir)\n",
    "except OSError as e:\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-yacht",
   "metadata": {
    "id": "portable-yacht",
    "papermill": {
     "duration": 3.504245,
     "end_time": "2021-05-30T20:27:18.913681",
     "exception": false,
     "start_time": "2021-05-30T20:27:15.409436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Save best weights and output prediction file\n",
    "\n",
    "### 최적의 가중치 및 출력 예측 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "liquid-tsunami",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T20:27:26.290338Z",
     "iopub.status.busy": "2021-05-30T20:27:26.289493Z",
     "iopub.status.idle": "2021-05-30T20:27:26.809425Z",
     "shell.execute_reply": "2021-05-30T20:27:26.808879Z",
     "shell.execute_reply.started": "2021-05-27T05:51:46.57395Z"
    },
    "id": "liquid-tsunami",
    "papermill": {
     "duration": 4.073647,
     "end_time": "2021-05-30T20:27:26.809566",
     "exception": false,
     "start_time": "2021-05-30T20:27:22.735919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xception_model.save_weights(\"knee_xray_Xceptionnet_GPA.h5\")\n",
    "df_submit.to_csv(\"submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-baptist",
   "metadata": {
    "id": "sustainable-baptist",
    "papermill": {
     "duration": 3.563445,
     "end_time": "2021-05-30T20:27:34.549379",
     "exception": false,
     "start_time": "2021-05-30T20:27:30.985934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The submission results in 96.8% on public leaderboard.\n",
    "\n",
    "**Suggestion to improve the score**\n",
    "* Using right data augmentations\n",
    "* Using different model architecture\n",
    "* Ensembling and stacking\n",
    "* Using pretrained model trained on xray images\n",
    "\n",
    "제출 결과 공개 리더보드에서 96.8%의 결과가 나왔습니다.\n",
    "\n",
    "**점수 향상을 위한 제안*\n",
    "* 올바른 데이터 확대 사용\n",
    "* 다른 모델 아키텍처 사용\n",
    "* 조립 및 쌓기\n",
    "* X선 영상에 대해 사전 훈련된 모델 사용"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "KLGrade-DenseNet121-93.41.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6499.620651,
   "end_time": "2021-05-30T20:27:40.898205",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-30T18:39:21.277554",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
