{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "_-WG94kK7V9p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-WG94kK7V9p",
    "outputId": "b7c710cf-9278-4504-ba52-00c87f007523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google import colab\n",
    "colab.drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LDacldMA7ptp",
   "metadata": {
    "id": "LDacldMA7ptp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /usr/local/lib/python3.6/dist-packages (0.5.4)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from timm) (1.7.1+cu110)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm) (0.8.2+cu110)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (1.19.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (8.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "LlcNsGEk7L5r",
   "metadata": {
    "id": "LlcNsGEk7L5r"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lXH5F_hA7uMl",
   "metadata": {
    "id": "lXH5F_hA7uMl"
   },
   "outputs": [],
   "source": [
    "path = '/home/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "FWntO1VD7L5u",
   "metadata": {
    "id": "FWntO1VD7L5u"
   },
   "outputs": [],
   "source": [
    "train_png = sorted(glob(path + 'open/train/*.png'))\n",
    "test_png = sorted(glob(path + 'open/test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atSgPJRn-OCW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atSgPJRn-OCW",
    "outputId": "87b6f90b-5c1c-4a0e-de54-994458543687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4277, 2154)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_png), len(test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "xv0_rDVq7L5v",
   "metadata": {
    "id": "xv0_rDVq7L5v"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(path +\"open/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "iMhC0nPw7L5w",
   "metadata": {
    "id": "iMhC0nPw7L5w"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "zsmJA3E97L5x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsmJA3E97L5x",
    "outputId": "e0dc61fe-5617-42e8-c8b0-0e95b9f60656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4277/4277 [02:52<00:00, 24.73it/s]\n",
      "100%|██████████| 2154/2154 [01:24<00:00, 25.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "KA73Lku9A2N9",
   "metadata": {
    "id": "KA73Lku9A2N9"
   },
   "outputs": [],
   "source": [
    "np.save(path + 'train_imgs_384', np.array(train_imgs))\n",
    "np.save(path + 'test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "L6qBdX7nCp8L",
   "metadata": {
    "id": "L6qBdX7nCp8L"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.load(path + 'train_imgs_384.npy')\n",
    "test_imgs = np.load(path + 'test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sscGLiJKPy6H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sscGLiJKPy6H",
    "outputId": "976516c0-507d-458f-f0c4-6695751605d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평균 0.4330380901867049 0.4034575319032911 0.39415050509784405\n",
      "train 표준편차 0.1815717110252788 0.17403455556798705 0.16323395055036488\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"train 평균\",meanR, meanG, meanB)\n",
    "print(\"train 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "JwVIQCrUSCFE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwVIQCrUSCFE",
    "outputId": "293981ef-7f6a-4602-d208-5fd8473d5261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 평균 0.41825619520929724 0.3931011906330291 0.386631764639131\n",
      "test 표준편차 0.19505524270747931 0.19005280951759498 0.18053225852732663\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"test 평균\",meanR, meanG, meanB)\n",
    "print(\"test 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "VFXzojoo7L5y",
   "metadata": {
    "id": "VFXzojoo7L5y"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "                                     std = [0.181572, 0.174035, 0.163234]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
    "                                     std = [0.195055, 0.190053, 0.185323])\n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=88, drop_path_rate = 0.2)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=88, drop_path_rate = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38qk8sGbYiO_",
   "metadata": {
    "id": "38qk8sGbYiO_"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "EnOG2n30-Dz5",
   "metadata": {
    "id": "EnOG2n30-Dz5"
   },
   "outputs": [],
   "source": [
    "def main(seed = 2022):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "main(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lkNCkyG9RPzX",
   "metadata": {
    "id": "lkNCkyG9RPzX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b3_ra2-cf984f9c.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_ra2-cf984f9c.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 47s/3256s\n",
      "TRAIN    loss : 1.18003    f1 : 0.17458\n",
      "Val    loss : 0.67017    f1 : 0.24356\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 42s/2850s\n",
      "TRAIN    loss : 0.54855    f1 : 0.34165\n",
      "Val    loss : 0.49407    f1 : 0.39124\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 42s/2783s\n",
      "TRAIN    loss : 0.38202    f1 : 0.50511\n",
      "Val    loss : 0.37423    f1 : 0.53545\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 45s/2968s\n",
      "TRAIN    loss : 0.28057    f1 : 0.59147\n",
      "Val    loss : 0.31233    f1 : 0.62464\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 43s/2774s\n",
      "TRAIN    loss : 0.20686    f1 : 0.72829\n",
      "Val    loss : 0.25508    f1 : 0.64506\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 40s/2589s\n",
      "TRAIN    loss : 0.16698    f1 : 0.78842\n",
      "Val    loss : 0.22048    f1 : 0.70016\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/70    time : 41s/2579s\n",
      "TRAIN    loss : 0.12414    f1 : 0.84999\n",
      "Val    loss : 0.22242    f1 : 0.70668\n",
      "epoch : 8/70    time : 42s/2621s\n",
      "TRAIN    loss : 0.10218    f1 : 0.88049\n",
      "Val    loss : 0.19587    f1 : 0.70598\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/70    time : 42s/2577s\n",
      "TRAIN    loss : 0.07783    f1 : 0.90625\n",
      "Val    loss : 0.19051    f1 : 0.70891\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/70    time : 41s/2487s\n",
      "TRAIN    loss : 0.06805    f1 : 0.92342\n",
      "Val    loss : 0.18424    f1 : 0.73903\n",
      "epoch : 11/70    time : 41s/2408s\n",
      "TRAIN    loss : 0.05300    f1 : 0.93790\n",
      "Val    loss : 0.15945    f1 : 0.72817\n",
      "epoch : 12/70    time : 41s/2353s\n",
      "TRAIN    loss : 0.05011    f1 : 0.94202\n",
      "Val    loss : 0.19448    f1 : 0.69176\n",
      "epoch : 13/70    time : 43s/2469s\n",
      "TRAIN    loss : 0.05893    f1 : 0.93192\n",
      "Val    loss : 0.21919    f1 : 0.70833\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/70    time : 41s/2320s\n",
      "TRAIN    loss : 0.04502    f1 : 0.96074\n",
      "Val    loss : 0.17799    f1 : 0.75687\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/70    time : 41s/2238s\n",
      "TRAIN    loss : 0.03324    f1 : 0.96899\n",
      "Val    loss : 0.16331    f1 : 0.78513\n",
      "epoch : 16/70    time : 41s/2229s\n",
      "TRAIN    loss : 0.04199    f1 : 0.94242\n",
      "Val    loss : 0.21988    f1 : 0.75924\n",
      "epoch : 17/70    time : 43s/2255s\n",
      "TRAIN    loss : 0.04584    f1 : 0.95109\n",
      "Val    loss : 0.15808    f1 : 0.77030\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/70    time : 41s/2140s\n",
      "TRAIN    loss : 0.03690    f1 : 0.95554\n",
      "Val    loss : 0.17556    f1 : 0.80028\n",
      "epoch : 19/70    time : 41s/2100s\n",
      "TRAIN    loss : 0.02597    f1 : 0.97730\n",
      "Val    loss : 0.17265    f1 : 0.76434\n",
      "epoch : 20/70    time : 40s/2009s\n",
      "TRAIN    loss : 0.03536    f1 : 0.96568\n",
      "Val    loss : 0.18165    f1 : 0.76654\n",
      "epoch : 21/70    time : 42s/2074s\n",
      "TRAIN    loss : 0.02676    f1 : 0.98287\n",
      "Val    loss : 0.15520    f1 : 0.77553\n",
      "-----------------SAVE:22 epoch----------------\n",
      "epoch : 22/70    time : 41s/1977s\n",
      "TRAIN    loss : 0.01806    f1 : 0.97656\n",
      "Val    loss : 0.18534    f1 : 0.80584\n",
      "epoch : 23/70    time : 41s/1921s\n",
      "TRAIN    loss : 0.03681    f1 : 0.95579\n",
      "Val    loss : 0.22742    f1 : 0.75685\n",
      "epoch : 24/70    time : 41s/1869s\n",
      "TRAIN    loss : 0.01937    f1 : 0.97005\n",
      "Val    loss : 0.17557    f1 : 0.77942\n",
      "epoch : 25/70    time : 41s/1864s\n",
      "TRAIN    loss : 0.02876    f1 : 0.97505\n",
      "Val    loss : 0.18425    f1 : 0.79292\n",
      "epoch : 26/70    time : 44s/1917s\n",
      "TRAIN    loss : 0.02206    f1 : 0.97681\n",
      "Val    loss : 0.24605    f1 : 0.75615\n",
      "epoch : 27/70    time : 41s/1782s\n",
      "TRAIN    loss : 0.01834    f1 : 0.98671\n",
      "Val    loss : 0.18386    f1 : 0.78162\n",
      "-----------------SAVE:28 epoch----------------\n",
      "epoch : 28/70    time : 42s/1768s\n",
      "TRAIN    loss : 0.02281    f1 : 0.97414\n",
      "Val    loss : 0.17884    f1 : 0.80806\n",
      "epoch : 29/70    time : 42s/1736s\n",
      "TRAIN    loss : 0.02133    f1 : 0.98116\n",
      "Val    loss : 0.18895    f1 : 0.77812\n",
      "epoch : 30/70    time : 42s/1686s\n",
      "TRAIN    loss : 0.01215    f1 : 0.99067\n",
      "Val    loss : 0.17789    f1 : 0.79326\n",
      "epoch : 31/70    time : 41s/1588s\n",
      "TRAIN    loss : 0.01710    f1 : 0.98548\n",
      "Val    loss : 0.17291    f1 : 0.77624\n",
      "epoch : 32/70    time : 41s/1547s\n",
      "TRAIN    loss : 0.03126    f1 : 0.96630\n",
      "Val    loss : 0.27056    f1 : 0.76809\n",
      "epoch : 33/70    time : 40s/1485s\n",
      "TRAIN    loss : 0.03734    f1 : 0.97389\n",
      "Val    loss : 0.19554    f1 : 0.79160\n",
      "epoch : 34/70    time : 45s/1613s\n",
      "TRAIN    loss : 0.01391    f1 : 0.98468\n",
      "Val    loss : 0.22174    f1 : 0.78728\n",
      "epoch : 35/70    time : 41s/1439s\n",
      "TRAIN    loss : 0.01203    f1 : 0.97816\n",
      "Val    loss : 0.22173    f1 : 0.76828\n",
      "-----------------SAVE:36 epoch----------------\n",
      "epoch : 36/70    time : 41s/1386s\n",
      "TRAIN    loss : 0.02065    f1 : 0.97842\n",
      "Val    loss : 0.20856    f1 : 0.80814\n",
      "epoch : 37/70    time : 41s/1355s\n",
      "TRAIN    loss : 0.01313    f1 : 0.98193\n",
      "Val    loss : 0.21665    f1 : 0.78461\n",
      "epoch : 38/70    time : 41s/1301s\n",
      "TRAIN    loss : 0.02489    f1 : 0.97620\n",
      "Val    loss : 0.25874    f1 : 0.76971\n",
      "epoch : 39/70    time : 44s/1357s\n",
      "TRAIN    loss : 0.01735    f1 : 0.98272\n",
      "Val    loss : 0.23351    f1 : 0.79155\n",
      "epoch : 40/70    time : 41s/1219s\n",
      "TRAIN    loss : 0.01926    f1 : 0.97914\n",
      "Val    loss : 0.22930    f1 : 0.77321\n",
      "epoch : 41/70    time : 41s/1198s\n",
      "TRAIN    loss : 0.01315    f1 : 0.98901\n",
      "Val    loss : 0.18984    f1 : 0.80658\n",
      "epoch : 42/70    time : 41s/1140s\n",
      "TRAIN    loss : 0.00848    f1 : 0.98795\n",
      "Val    loss : 0.20015    f1 : 0.80682\n",
      "-----------------SAVE:43 epoch----------------\n",
      "epoch : 43/70    time : 43s/1172s\n",
      "TRAIN    loss : 0.00998    f1 : 0.99116\n",
      "Val    loss : 0.17892    f1 : 0.82647\n",
      "epoch : 44/70    time : 42s/1083s\n",
      "TRAIN    loss : 0.01289    f1 : 0.98872\n",
      "Val    loss : 0.20123    f1 : 0.81469\n",
      "-----------------SAVE:45 epoch----------------\n",
      "epoch : 45/70    time : 42s/1039s\n",
      "TRAIN    loss : 0.01053    f1 : 0.99337\n",
      "Val    loss : 0.16983    f1 : 0.83162\n",
      "epoch : 46/70    time : 41s/974s\n",
      "TRAIN    loss : 0.00748    f1 : 0.99599\n",
      "Val    loss : 0.21950    f1 : 0.80544\n",
      "epoch : 47/70    time : 43s/985s\n",
      "TRAIN    loss : 0.02120    f1 : 0.98763\n",
      "Val    loss : 0.20881    f1 : 0.75355\n",
      "epoch : 48/70    time : 41s/903s\n",
      "TRAIN    loss : 0.01689    f1 : 0.98196\n",
      "Val    loss : 0.19870    f1 : 0.79047\n",
      "epoch : 49/70    time : 40s/843s\n",
      "TRAIN    loss : 0.02499    f1 : 0.98504\n",
      "Val    loss : 0.21654    f1 : 0.79317\n",
      "epoch : 50/70    time : 41s/811s\n",
      "TRAIN    loss : 0.02805    f1 : 0.96888\n",
      "Val    loss : 0.21753    f1 : 0.75270\n",
      "epoch : 51/70    time : 41s/787s\n",
      "TRAIN    loss : 0.02525    f1 : 0.97891\n",
      "Val    loss : 0.22698    f1 : 0.76668\n",
      "epoch : 52/70    time : 42s/764s\n",
      "TRAIN    loss : 0.02651    f1 : 0.97825\n",
      "Val    loss : 0.19274    f1 : 0.78697\n",
      "epoch : 53/70    time : 40s/684s\n",
      "TRAIN    loss : 0.01286    f1 : 0.99083\n",
      "Val    loss : 0.17129    f1 : 0.82629\n",
      "epoch : 54/70    time : 42s/667s\n",
      "TRAIN    loss : 0.00854    f1 : 0.99512\n",
      "Val    loss : 0.17598    f1 : 0.80744\n",
      "epoch : 55/70    time : 40s/606s\n",
      "TRAIN    loss : 0.00283    f1 : 0.99930\n",
      "Val    loss : 0.16817    f1 : 0.80492\n",
      "epoch : 56/70    time : 42s/592s\n",
      "TRAIN    loss : 0.00301    f1 : 0.99756\n",
      "Val    loss : 0.14960    f1 : 0.82970\n",
      "epoch : 57/70    time : 41s/531s\n",
      "TRAIN    loss : 0.00706    f1 : 0.99007\n",
      "Val    loss : 0.16245    f1 : 0.79909\n",
      "epoch : 58/70    time : 41s/490s\n",
      "TRAIN    loss : 0.00809    f1 : 0.99192\n",
      "Val    loss : 0.21756    f1 : 0.80255\n",
      "epoch : 59/70    time : 41s/449s\n",
      "TRAIN    loss : 0.02681    f1 : 0.97977\n",
      "Val    loss : 0.17892    f1 : 0.78631\n",
      "epoch : 60/70    time : 43s/428s\n",
      "TRAIN    loss : 0.03426    f1 : 0.96520\n",
      "Val    loss : 0.23707    f1 : 0.74987\n",
      "epoch : 61/70    time : 40s/362s\n",
      "TRAIN    loss : 0.01977    f1 : 0.97012\n",
      "Val    loss : 0.17756    f1 : 0.78507\n",
      "epoch : 62/70    time : 41s/329s\n",
      "TRAIN    loss : 0.01167    f1 : 0.99019\n",
      "Val    loss : 0.23006    f1 : 0.76199\n",
      "epoch : 63/70    time : 40s/281s\n",
      "TRAIN    loss : 0.01390    f1 : 0.99055\n",
      "Val    loss : 0.19928    f1 : 0.76000\n",
      "epoch : 64/70    time : 41s/245s\n",
      "TRAIN    loss : 0.01243    f1 : 0.98882\n",
      "Val    loss : 0.24622    f1 : 0.75079\n",
      "epoch : 65/70    time : 42s/212s\n",
      "TRAIN    loss : 0.01328    f1 : 0.99130\n",
      "Val    loss : 0.24160    f1 : 0.73469\n",
      "----------fold_1 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 40s/2745s\n",
      "TRAIN    loss : 1.16517    f1 : 0.17298\n",
      "Val    loss : 0.62326    f1 : 0.29102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 41s/2756s\n",
      "TRAIN    loss : 0.52734    f1 : 0.34787\n",
      "Val    loss : 0.42744    f1 : 0.41935\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 40s/2699s\n",
      "TRAIN    loss : 0.37642    f1 : 0.52579\n",
      "Val    loss : 0.36167    f1 : 0.53129\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 42s/2791s\n",
      "TRAIN    loss : 0.27608    f1 : 0.63821\n",
      "Val    loss : 0.24869    f1 : 0.64042\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 41s/2686s\n",
      "TRAIN    loss : 0.20599    f1 : 0.70789\n",
      "Val    loss : 0.19019    f1 : 0.66433\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 41s/2596s\n",
      "TRAIN    loss : 0.15448    f1 : 0.80644\n",
      "Val    loss : 0.19303    f1 : 0.72520\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/70    time : 41s/2584s\n",
      "TRAIN    loss : 0.11675    f1 : 0.85582\n",
      "Val    loss : 0.18720    f1 : 0.77551\n",
      "epoch : 8/70    time : 41s/2559s\n",
      "TRAIN    loss : 0.09406    f1 : 0.88897\n",
      "Val    loss : 0.16742    f1 : 0.76549\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/70    time : 40s/2465s\n",
      "TRAIN    loss : 0.08983    f1 : 0.89226\n",
      "Val    loss : 0.15221    f1 : 0.78699\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/70    time : 41s/2472s\n",
      "TRAIN    loss : 0.06821    f1 : 0.92231\n",
      "Val    loss : 0.15136    f1 : 0.79753\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/70    time : 40s/2386s\n",
      "TRAIN    loss : 0.04796    f1 : 0.95089\n",
      "Val    loss : 0.18834    f1 : 0.79784\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/70    time : 42s/2464s\n",
      "TRAIN    loss : 0.04659    f1 : 0.93476\n",
      "Val    loss : 0.16523    f1 : 0.80559\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/70    time : 42s/2402s\n",
      "TRAIN    loss : 0.03715    f1 : 0.95434\n",
      "Val    loss : 0.18083    f1 : 0.82156\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/70    time : 40s/2226s\n",
      "TRAIN    loss : 0.04134    f1 : 0.95652\n",
      "Val    loss : 0.17209    f1 : 0.82317\n",
      "epoch : 15/70    time : 41s/2266s\n",
      "TRAIN    loss : 0.03802    f1 : 0.96237\n",
      "Val    loss : 0.17985    f1 : 0.79789\n",
      "epoch : 16/70    time : 39s/2129s\n",
      "TRAIN    loss : 0.02704    f1 : 0.97337\n",
      "Val    loss : 0.23635    f1 : 0.80608\n",
      "epoch : 17/70    time : 41s/2195s\n",
      "TRAIN    loss : 0.02414    f1 : 0.97493\n",
      "Val    loss : 0.20476    f1 : 0.78137\n",
      "epoch : 18/70    time : 40s/2080s\n",
      "TRAIN    loss : 0.02170    f1 : 0.97185\n",
      "Val    loss : 0.22584    f1 : 0.77536\n",
      "epoch : 19/70    time : 40s/2027s\n",
      "TRAIN    loss : 0.01897    f1 : 0.98084\n",
      "Val    loss : 0.18450    f1 : 0.80727\n",
      "epoch : 20/70    time : 40s/2004s\n",
      "TRAIN    loss : 0.02221    f1 : 0.97173\n",
      "Val    loss : 0.33720    f1 : 0.74338\n",
      "epoch : 21/70    time : 41s/1991s\n",
      "TRAIN    loss : 0.04020    f1 : 0.95137\n",
      "Val    loss : 0.18268    f1 : 0.78823\n",
      "epoch : 22/70    time : 41s/1979s\n",
      "TRAIN    loss : 0.04140    f1 : 0.96100\n",
      "Val    loss : 0.19526    f1 : 0.79506\n",
      "epoch : 23/70    time : 39s/1851s\n",
      "TRAIN    loss : 0.03060    f1 : 0.97007\n",
      "Val    loss : 0.19011    f1 : 0.79830\n",
      "epoch : 24/70    time : 40s/1835s\n",
      "TRAIN    loss : 0.02972    f1 : 0.97791\n",
      "Val    loss : 0.24011    f1 : 0.74628\n",
      "epoch : 25/70    time : 40s/1778s\n",
      "TRAIN    loss : 0.02228    f1 : 0.97766\n",
      "Val    loss : 0.19515    f1 : 0.79214\n",
      "epoch : 26/70    time : 41s/1793s\n",
      "TRAIN    loss : 0.02577    f1 : 0.96424\n",
      "Val    loss : 0.18849    f1 : 0.79010\n",
      "epoch : 27/70    time : 40s/1724s\n",
      "TRAIN    loss : 0.02985    f1 : 0.96849\n",
      "Val    loss : 0.15852    f1 : 0.81357\n",
      "epoch : 28/70    time : 40s/1675s\n",
      "TRAIN    loss : 0.01672    f1 : 0.98142\n",
      "Val    loss : 0.17860    f1 : 0.80706\n",
      "-----------------SAVE:29 epoch----------------\n",
      "epoch : 29/70    time : 40s/1649s\n",
      "TRAIN    loss : 0.02087    f1 : 0.97097\n",
      "Val    loss : 0.19008    f1 : 0.83509\n",
      "epoch : 30/70    time : 40s/1604s\n",
      "TRAIN    loss : 0.02601    f1 : 0.97228\n",
      "Val    loss : 0.19670    f1 : 0.80397\n",
      "epoch : 31/70    time : 41s/1602s\n",
      "TRAIN    loss : 0.02145    f1 : 0.98426\n",
      "Val    loss : 0.19590    f1 : 0.82107\n",
      "epoch : 32/70    time : 39s/1494s\n",
      "TRAIN    loss : 0.01063    f1 : 0.99494\n",
      "Val    loss : 0.16834    f1 : 0.83324\n",
      "-----------------SAVE:33 epoch----------------\n",
      "epoch : 33/70    time : 40s/1494s\n",
      "TRAIN    loss : 0.00685    f1 : 0.99165\n",
      "Val    loss : 0.15855    f1 : 0.84249\n",
      "epoch : 34/70    time : 39s/1414s\n",
      "TRAIN    loss : 0.02127    f1 : 0.97980\n",
      "Val    loss : 0.15792    f1 : 0.79134\n",
      "epoch : 35/70    time : 42s/1460s\n",
      "TRAIN    loss : 0.01569    f1 : 0.98389\n",
      "Val    loss : 0.17673    f1 : 0.82826\n",
      "epoch : 36/70    time : 39s/1341s\n",
      "TRAIN    loss : 0.01763    f1 : 0.98772\n",
      "Val    loss : 0.17510    f1 : 0.80926\n",
      "epoch : 37/70    time : 40s/1318s\n",
      "TRAIN    loss : 0.01640    f1 : 0.97931\n",
      "Val    loss : 0.23429    f1 : 0.80186\n",
      "epoch : 38/70    time : 41s/1300s\n",
      "TRAIN    loss : 0.01336    f1 : 0.97985\n",
      "Val    loss : 0.24594    f1 : 0.79064\n",
      "epoch : 39/70    time : 40s/1231s\n",
      "TRAIN    loss : 0.01107    f1 : 0.98917\n",
      "Val    loss : 0.23904    f1 : 0.80853\n",
      "epoch : 40/70    time : 41s/1240s\n",
      "TRAIN    loss : 0.01689    f1 : 0.98151\n",
      "Val    loss : 0.23009    f1 : 0.80609\n",
      "epoch : 41/70    time : 40s/1152s\n",
      "TRAIN    loss : 0.02188    f1 : 0.97986\n",
      "Val    loss : 0.19382    f1 : 0.81184\n",
      "epoch : 42/70    time : 40s/1111s\n",
      "TRAIN    loss : 0.00924    f1 : 0.99373\n",
      "Val    loss : 0.19137    f1 : 0.81460\n",
      "epoch : 43/70    time : 39s/1060s\n",
      "TRAIN    loss : 0.01036    f1 : 0.99285\n",
      "Val    loss : 0.26532    f1 : 0.77249\n",
      "epoch : 44/70    time : 42s/1103s\n",
      "TRAIN    loss : 0.01626    f1 : 0.98919\n",
      "Val    loss : 0.18548    f1 : 0.77156\n",
      "epoch : 45/70    time : 40s/1010s\n",
      "TRAIN    loss : 0.02098    f1 : 0.98213\n",
      "Val    loss : 0.16241    f1 : 0.78385\n",
      "epoch : 46/70    time : 39s/932s\n",
      "TRAIN    loss : 0.01946    f1 : 0.98138\n",
      "Val    loss : 0.20967    f1 : 0.81039\n",
      "epoch : 47/70    time : 39s/903s\n",
      "TRAIN    loss : 0.02596    f1 : 0.98215\n",
      "Val    loss : 0.22796    f1 : 0.82176\n",
      "epoch : 48/70    time : 41s/891s\n",
      "TRAIN    loss : 0.01491    f1 : 0.98132\n",
      "Val    loss : 0.19784    f1 : 0.81359\n",
      "epoch : 49/70    time : 42s/877s\n",
      "TRAIN    loss : 0.02402    f1 : 0.98204\n",
      "Val    loss : 0.22759    f1 : 0.80532\n",
      "epoch : 50/70    time : 39s/780s\n",
      "TRAIN    loss : 0.01308    f1 : 0.98302\n",
      "Val    loss : 0.19571    f1 : 0.78072\n",
      "-----------------SAVE:51 epoch----------------\n",
      "epoch : 51/70    time : 41s/784s\n",
      "TRAIN    loss : 0.01843    f1 : 0.97643\n",
      "Val    loss : 0.19071    f1 : 0.84341\n",
      "epoch : 52/70    time : 39s/707s\n",
      "TRAIN    loss : 0.01271    f1 : 0.98641\n",
      "Val    loss : 0.17714    f1 : 0.82143\n",
      "epoch : 53/70    time : 42s/707s\n",
      "TRAIN    loss : 0.01006    f1 : 0.99119\n",
      "Val    loss : 0.17179    f1 : 0.82073\n",
      "epoch : 54/70    time : 40s/634s\n",
      "TRAIN    loss : 0.00671    f1 : 0.99424\n",
      "Val    loss : 0.22236    f1 : 0.79780\n",
      "epoch : 55/70    time : 39s/592s\n",
      "TRAIN    loss : 0.00719    f1 : 0.99318\n",
      "Val    loss : 0.19906    f1 : 0.81625\n",
      "epoch : 56/70    time : 40s/559s\n",
      "TRAIN    loss : 0.00748    f1 : 0.99318\n",
      "Val    loss : 0.21876    f1 : 0.80011\n",
      "epoch : 57/70    time : 43s/555s\n",
      "TRAIN    loss : 0.00530    f1 : 0.99047\n",
      "Val    loss : 0.22834    f1 : 0.81256\n",
      "epoch : 58/70    time : 39s/471s\n",
      "TRAIN    loss : 0.01883    f1 : 0.98535\n",
      "Val    loss : 0.24783    f1 : 0.80727\n",
      "epoch : 59/70    time : 40s/435s\n",
      "TRAIN    loss : 0.03566    f1 : 0.97317\n",
      "Val    loss : 0.18419    f1 : 0.82266\n",
      "-----------------SAVE:60 epoch----------------\n",
      "epoch : 60/70    time : 40s/404s\n",
      "TRAIN    loss : 0.01596    f1 : 0.98096\n",
      "Val    loss : 0.17147    f1 : 0.84619\n",
      "epoch : 61/70    time : 41s/371s\n",
      "TRAIN    loss : 0.01569    f1 : 0.98357\n",
      "Val    loss : 0.15297    f1 : 0.82113\n",
      "epoch : 62/70    time : 42s/336s\n",
      "TRAIN    loss : 0.00914    f1 : 0.98436\n",
      "Val    loss : 0.17288    f1 : 0.83260\n",
      "epoch : 63/70    time : 40s/281s\n",
      "TRAIN    loss : 0.01464    f1 : 0.97735\n",
      "Val    loss : 0.22952    f1 : 0.79840\n",
      "epoch : 64/70    time : 40s/241s\n",
      "TRAIN    loss : 0.02496    f1 : 0.97952\n",
      "Val    loss : 0.23456    f1 : 0.79385\n",
      "epoch : 65/70    time : 40s/198s\n",
      "TRAIN    loss : 0.01091    f1 : 0.99101\n",
      "Val    loss : 0.24840    f1 : 0.80224\n",
      "epoch : 66/70    time : 41s/165s\n",
      "TRAIN    loss : 0.02038    f1 : 0.98657\n",
      "Val    loss : 0.22043    f1 : 0.80313\n",
      "epoch : 67/70    time : 39s/118s\n",
      "TRAIN    loss : 0.02086    f1 : 0.98110\n",
      "Val    loss : 0.18638    f1 : 0.79402\n",
      "epoch : 68/70    time : 40s/79s\n",
      "TRAIN    loss : 0.01402    f1 : 0.98910\n",
      "Val    loss : 0.18747    f1 : 0.79155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 69/70    time : 39s/39s\n",
      "TRAIN    loss : 0.00720    f1 : 0.99337\n",
      "Val    loss : 0.21583    f1 : 0.78208\n",
      "epoch : 70/70    time : 40s/0s\n",
      "TRAIN    loss : 0.00690    f1 : 0.99157\n",
      "Val    loss : 0.20141    f1 : 0.81555\n",
      "----------fold_2 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 45s/3086s\n",
      "TRAIN    loss : 1.21485    f1 : 0.17259\n",
      "Val    loss : 0.62505    f1 : 0.24639\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 40s/2731s\n",
      "TRAIN    loss : 0.54730    f1 : 0.33472\n",
      "Val    loss : 0.42973    f1 : 0.37020\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 40s/2680s\n",
      "TRAIN    loss : 0.36599    f1 : 0.52247\n",
      "Val    loss : 0.27733    f1 : 0.55605\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 40s/2662s\n",
      "TRAIN    loss : 0.26594    f1 : 0.65265\n",
      "Val    loss : 0.23799    f1 : 0.59698\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 42s/2736s\n",
      "TRAIN    loss : 0.19550    f1 : 0.73906\n",
      "Val    loss : 0.24024    f1 : 0.60460\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 40s/2561s\n",
      "TRAIN    loss : 0.16033    f1 : 0.81934\n",
      "Val    loss : 0.20118    f1 : 0.71065\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/70    time : 41s/2562s\n",
      "TRAIN    loss : 0.12401    f1 : 0.83651\n",
      "Val    loss : 0.19267    f1 : 0.72965\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/70    time : 41s/2514s\n",
      "TRAIN    loss : 0.10251    f1 : 0.87757\n",
      "Val    loss : 0.16140    f1 : 0.76174\n",
      "epoch : 9/70    time : 40s/2427s\n",
      "TRAIN    loss : 0.06724    f1 : 0.92663\n",
      "Val    loss : 0.16453    f1 : 0.75277\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/70    time : 42s/2544s\n",
      "TRAIN    loss : 0.05415    f1 : 0.93897\n",
      "Val    loss : 0.18001    f1 : 0.77807\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/70    time : 40s/2378s\n",
      "TRAIN    loss : 0.05963    f1 : 0.93215\n",
      "Val    loss : 0.13558    f1 : 0.78846\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/70    time : 40s/2341s\n",
      "TRAIN    loss : 0.04403    f1 : 0.94707\n",
      "Val    loss : 0.13593    f1 : 0.82018\n",
      "epoch : 13/70    time : 40s/2287s\n",
      "TRAIN    loss : 0.03498    f1 : 0.96101\n",
      "Val    loss : 0.14395    f1 : 0.78180\n",
      "epoch : 14/70    time : 41s/2314s\n",
      "TRAIN    loss : 0.03162    f1 : 0.96007\n",
      "Val    loss : 0.14861    f1 : 0.79425\n",
      "epoch : 15/70    time : 39s/2155s\n",
      "TRAIN    loss : 0.03800    f1 : 0.95764\n",
      "Val    loss : 0.17604    f1 : 0.77062\n",
      "epoch : 16/70    time : 41s/2198s\n",
      "TRAIN    loss : 0.04305    f1 : 0.96109\n",
      "Val    loss : 0.15417    f1 : 0.81332\n",
      "epoch : 17/70    time : 40s/2100s\n",
      "TRAIN    loss : 0.03216    f1 : 0.96155\n",
      "Val    loss : 0.15953    f1 : 0.78997\n",
      "epoch : 18/70    time : 41s/2156s\n",
      "TRAIN    loss : 0.02368    f1 : 0.98151\n",
      "Val    loss : 0.16079    f1 : 0.76632\n",
      "epoch : 19/70    time : 40s/2037s\n",
      "TRAIN    loss : 0.02462    f1 : 0.96743\n",
      "Val    loss : 0.16629    f1 : 0.79217\n",
      "epoch : 20/70    time : 40s/2017s\n",
      "TRAIN    loss : 0.02909    f1 : 0.96585\n",
      "Val    loss : 0.13518    f1 : 0.78508\n",
      "epoch : 21/70    time : 40s/1976s\n",
      "TRAIN    loss : 0.02008    f1 : 0.98290\n",
      "Val    loss : 0.12598    f1 : 0.79494\n",
      "epoch : 22/70    time : 40s/1920s\n",
      "TRAIN    loss : 0.02880    f1 : 0.97824\n",
      "Val    loss : 0.15560    f1 : 0.76779\n",
      "epoch : 23/70    time : 41s/1922s\n",
      "TRAIN    loss : 0.03146    f1 : 0.96222\n",
      "Val    loss : 0.15185    f1 : 0.77041\n",
      "-----------------SAVE:24 epoch----------------\n",
      "epoch : 24/70    time : 40s/1835s\n",
      "TRAIN    loss : 0.03070    f1 : 0.97280\n",
      "Val    loss : 0.14922    f1 : 0.83102\n",
      "epoch : 25/70    time : 41s/1831s\n",
      "TRAIN    loss : 0.01192    f1 : 0.99436\n",
      "Val    loss : 0.13601    f1 : 0.82226\n",
      "epoch : 26/70    time : 39s/1723s\n",
      "TRAIN    loss : 0.00788    f1 : 0.98933\n",
      "Val    loss : 0.15816    f1 : 0.80587\n",
      "epoch : 27/70    time : 41s/1777s\n",
      "TRAIN    loss : 0.01626    f1 : 0.98077\n",
      "Val    loss : 0.15789    f1 : 0.80421\n",
      "epoch : 28/70    time : 40s/1672s\n",
      "TRAIN    loss : 0.02855    f1 : 0.97176\n",
      "Val    loss : 0.16103    f1 : 0.81947\n",
      "-----------------SAVE:29 epoch----------------\n",
      "epoch : 29/70    time : 40s/1640s\n",
      "TRAIN    loss : 0.03900    f1 : 0.96775\n",
      "Val    loss : 0.13893    f1 : 0.83577\n",
      "epoch : 30/70    time : 39s/1574s\n",
      "TRAIN    loss : 0.02123    f1 : 0.98400\n",
      "Val    loss : 0.15393    f1 : 0.81770\n",
      "epoch : 31/70    time : 40s/1577s\n",
      "TRAIN    loss : 0.01926    f1 : 0.98598\n",
      "Val    loss : 0.15089    f1 : 0.80678\n",
      "epoch : 32/70    time : 41s/1572s\n",
      "TRAIN    loss : 0.01583    f1 : 0.98891\n",
      "Val    loss : 0.16650    f1 : 0.79839\n",
      "epoch : 33/70    time : 39s/1455s\n",
      "TRAIN    loss : 0.02995    f1 : 0.97606\n",
      "Val    loss : 0.19704    f1 : 0.76196\n",
      "epoch : 34/70    time : 39s/1415s\n",
      "TRAIN    loss : 0.01804    f1 : 0.98486\n",
      "Val    loss : 0.17073    f1 : 0.81274\n",
      "epoch : 35/70    time : 40s/1404s\n",
      "TRAIN    loss : 0.02118    f1 : 0.97182\n",
      "Val    loss : 0.16834    f1 : 0.79500\n",
      "epoch : 36/70    time : 41s/1383s\n",
      "TRAIN    loss : 0.01589    f1 : 0.98385\n",
      "Val    loss : 0.14622    f1 : 0.78600\n",
      "epoch : 37/70    time : 40s/1316s\n",
      "TRAIN    loss : 0.02288    f1 : 0.97520\n",
      "Val    loss : 0.15512    f1 : 0.81626\n",
      "epoch : 38/70    time : 39s/1255s\n",
      "TRAIN    loss : 0.02425    f1 : 0.98733\n",
      "Val    loss : 0.16173    f1 : 0.80777\n",
      "-----------------SAVE:39 epoch----------------\n",
      "epoch : 39/70    time : 40s/1230s\n",
      "TRAIN    loss : 0.01053    f1 : 0.99340\n",
      "Val    loss : 0.13124    f1 : 0.83793\n",
      "epoch : 40/70    time : 40s/1190s\n",
      "TRAIN    loss : 0.00827    f1 : 0.99008\n",
      "Val    loss : 0.12821    f1 : 0.82394\n",
      "epoch : 41/70    time : 42s/1207s\n",
      "TRAIN    loss : 0.00656    f1 : 0.99424\n",
      "Val    loss : 0.14208    f1 : 0.81211\n",
      "epoch : 42/70    time : 40s/1111s\n",
      "TRAIN    loss : 0.00784    f1 : 0.98981\n",
      "Val    loss : 0.16301    f1 : 0.83269\n",
      "epoch : 43/70    time : 41s/1094s\n",
      "TRAIN    loss : 0.01141    f1 : 0.98857\n",
      "Val    loss : 0.15432    f1 : 0.83766\n",
      "epoch : 44/70    time : 39s/1026s\n",
      "TRAIN    loss : 0.01224    f1 : 0.99417\n",
      "Val    loss : 0.23296    f1 : 0.80624\n",
      "epoch : 45/70    time : 41s/1034s\n",
      "TRAIN    loss : 0.01320    f1 : 0.99118\n",
      "Val    loss : 0.19327    f1 : 0.79278\n",
      "epoch : 46/70    time : 40s/958s\n",
      "TRAIN    loss : 0.01710    f1 : 0.98031\n",
      "Val    loss : 0.17000    f1 : 0.80064\n",
      "epoch : 47/70    time : 40s/913s\n",
      "TRAIN    loss : 0.03077    f1 : 0.97395\n",
      "Val    loss : 0.20367    f1 : 0.78203\n",
      "epoch : 48/70    time : 39s/868s\n",
      "TRAIN    loss : 0.01611    f1 : 0.98596\n",
      "Val    loss : 0.17311    f1 : 0.79191\n",
      "epoch : 49/70    time : 40s/840s\n",
      "TRAIN    loss : 0.02319    f1 : 0.98039\n",
      "Val    loss : 0.16974    f1 : 0.80923\n",
      "epoch : 50/70    time : 41s/823s\n",
      "TRAIN    loss : 0.01690    f1 : 0.98383\n",
      "Val    loss : 0.17734    f1 : 0.81725\n",
      "epoch : 51/70    time : 39s/740s\n",
      "TRAIN    loss : 0.01050    f1 : 0.99109\n",
      "Val    loss : 0.16630    f1 : 0.80669\n",
      "epoch : 52/70    time : 40s/720s\n",
      "TRAIN    loss : 0.01188    f1 : 0.98974\n",
      "Val    loss : 0.17261    f1 : 0.81082\n",
      "epoch : 53/70    time : 39s/671s\n",
      "TRAIN    loss : 0.02382    f1 : 0.98202\n",
      "Val    loss : 0.17980    f1 : 0.81415\n",
      "epoch : 54/70    time : 41s/661s\n",
      "TRAIN    loss : 0.01541    f1 : 0.98502\n",
      "Val    loss : 0.13264    f1 : 0.81197\n",
      "epoch : 55/70    time : 39s/591s\n",
      "TRAIN    loss : 0.00672    f1 : 0.99434\n",
      "Val    loss : 0.16322    f1 : 0.78211\n",
      "epoch : 56/70    time : 39s/546s\n",
      "TRAIN    loss : 0.02541    f1 : 0.97481\n",
      "Val    loss : 0.14376    f1 : 0.80297\n",
      "epoch : 57/70    time : 39s/510s\n",
      "TRAIN    loss : 0.01786    f1 : 0.98633\n",
      "Val    loss : 0.16772    f1 : 0.80474\n",
      "epoch : 58/70    time : 41s/487s\n",
      "TRAIN    loss : 0.01651    f1 : 0.97728\n",
      "Val    loss : 0.19515    f1 : 0.82027\n",
      "epoch : 59/70    time : 42s/460s\n",
      "TRAIN    loss : 0.01336    f1 : 0.98080\n",
      "Val    loss : 0.19905    f1 : 0.79626\n",
      "----------fold_3 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 41s/2810s\n",
      "TRAIN    loss : 1.18347    f1 : 0.16286\n",
      "Val    loss : 0.58653    f1 : 0.26749\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 41s/2767s\n",
      "TRAIN    loss : 0.55165    f1 : 0.33880\n",
      "Val    loss : 0.43361    f1 : 0.45464\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 41s/2750s\n",
      "TRAIN    loss : 0.38020    f1 : 0.53649\n",
      "Val    loss : 0.32934    f1 : 0.53164\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 42s/2774s\n",
      "TRAIN    loss : 0.26788    f1 : 0.64054\n",
      "Val    loss : 0.25083    f1 : 0.56882\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 41s/2663s\n",
      "TRAIN    loss : 0.20391    f1 : 0.74366\n",
      "Val    loss : 0.19009    f1 : 0.69354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 40s/2587s\n",
      "TRAIN    loss : 0.13485    f1 : 0.82656\n",
      "Val    loss : 0.18239    f1 : 0.73501\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/70    time : 40s/2528s\n",
      "TRAIN    loss : 0.11254    f1 : 0.86498\n",
      "Val    loss : 0.15266    f1 : 0.75473\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/70    time : 41s/2539s\n",
      "TRAIN    loss : 0.09184    f1 : 0.88427\n",
      "Val    loss : 0.18032    f1 : 0.76833\n",
      "epoch : 9/70    time : 42s/2545s\n",
      "TRAIN    loss : 0.07311    f1 : 0.90049\n",
      "Val    loss : 0.18976    f1 : 0.74187\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/70    time : 40s/2410s\n",
      "TRAIN    loss : 0.06178    f1 : 0.92467\n",
      "Val    loss : 0.16073    f1 : 0.77272\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/70    time : 41s/2413s\n",
      "TRAIN    loss : 0.06141    f1 : 0.93477\n",
      "Val    loss : 0.14852    f1 : 0.78937\n",
      "epoch : 12/70    time : 40s/2325s\n",
      "TRAIN    loss : 0.04679    f1 : 0.95763\n",
      "Val    loss : 0.16440    f1 : 0.77004\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/70    time : 42s/2411s\n",
      "TRAIN    loss : 0.03766    f1 : 0.95008\n",
      "Val    loss : 0.13802    f1 : 0.82558\n",
      "epoch : 14/70    time : 40s/2263s\n",
      "TRAIN    loss : 0.05179    f1 : 0.95177\n",
      "Val    loss : 0.14894    f1 : 0.81535\n",
      "epoch : 15/70    time : 40s/2189s\n",
      "TRAIN    loss : 0.02686    f1 : 0.97568\n",
      "Val    loss : 0.21982    f1 : 0.76896\n",
      "epoch : 16/70    time : 40s/2184s\n",
      "TRAIN    loss : 0.03792    f1 : 0.95582\n",
      "Val    loss : 0.16275    f1 : 0.78635\n",
      "-----------------SAVE:17 epoch----------------\n",
      "epoch : 17/70    time : 44s/2309s\n",
      "TRAIN    loss : 0.02720    f1 : 0.97258\n",
      "Val    loss : 0.13660    f1 : 0.85460\n",
      "epoch : 18/70    time : 40s/2082s\n",
      "TRAIN    loss : 0.03045    f1 : 0.96529\n",
      "Val    loss : 0.13245    f1 : 0.84777\n",
      "epoch : 19/70    time : 40s/2030s\n",
      "TRAIN    loss : 0.05247    f1 : 0.94303\n",
      "Val    loss : 0.12941    f1 : 0.82651\n",
      "epoch : 20/70    time : 41s/2053s\n",
      "TRAIN    loss : 0.02808    f1 : 0.97836\n",
      "Val    loss : 0.13035    f1 : 0.83903\n",
      "epoch : 21/70    time : 40s/1973s\n",
      "TRAIN    loss : 0.01582    f1 : 0.98013\n",
      "Val    loss : 0.13260    f1 : 0.83293\n",
      "epoch : 22/70    time : 41s/1978s\n",
      "TRAIN    loss : 0.03295    f1 : 0.96366\n",
      "Val    loss : 0.13273    f1 : 0.82908\n",
      "epoch : 23/70    time : 40s/1892s\n",
      "TRAIN    loss : 0.03275    f1 : 0.96791\n",
      "Val    loss : 0.15217    f1 : 0.83440\n",
      "epoch : 24/70    time : 40s/1833s\n",
      "TRAIN    loss : 0.01925    f1 : 0.98454\n",
      "Val    loss : 0.14373    f1 : 0.84731\n",
      "epoch : 25/70    time : 40s/1783s\n",
      "TRAIN    loss : 0.01491    f1 : 0.98937\n",
      "Val    loss : 0.15116    f1 : 0.82590\n",
      "epoch : 26/70    time : 43s/1878s\n",
      "TRAIN    loss : 0.01235    f1 : 0.99126\n",
      "Val    loss : 0.16643    f1 : 0.80494\n",
      "-----------------SAVE:27 epoch----------------\n",
      "epoch : 27/70    time : 41s/1771s\n",
      "TRAIN    loss : 0.02244    f1 : 0.97500\n",
      "Val    loss : 0.12451    f1 : 0.86298\n",
      "epoch : 28/70    time : 40s/1665s\n",
      "TRAIN    loss : 0.01090    f1 : 0.98719\n",
      "Val    loss : 0.14937    f1 : 0.83959\n",
      "epoch : 29/70    time : 40s/1653s\n",
      "TRAIN    loss : 0.01758    f1 : 0.98252\n",
      "Val    loss : 0.12484    f1 : 0.82804\n",
      "epoch : 30/70    time : 40s/1595s\n",
      "TRAIN    loss : 0.02566    f1 : 0.97057\n",
      "Val    loss : 0.20449    f1 : 0.83040\n",
      "epoch : 31/70    time : 42s/1648s\n",
      "TRAIN    loss : 0.04088    f1 : 0.96007\n",
      "Val    loss : 0.12722    f1 : 0.80796\n",
      "epoch : 32/70    time : 41s/1564s\n",
      "TRAIN    loss : 0.02047    f1 : 0.98123\n",
      "Val    loss : 0.17044    f1 : 0.79555\n",
      "epoch : 33/70    time : 40s/1468s\n",
      "TRAIN    loss : 0.01520    f1 : 0.98820\n",
      "Val    loss : 0.17205    f1 : 0.84518\n",
      "-----------------SAVE:34 epoch----------------\n",
      "epoch : 34/70    time : 40s/1432s\n",
      "TRAIN    loss : 0.02869    f1 : 0.97502\n",
      "Val    loss : 0.13843    f1 : 0.87120\n",
      "-----------------SAVE:35 epoch----------------\n",
      "epoch : 35/70    time : 42s/1474s\n",
      "TRAIN    loss : 0.01394    f1 : 0.98276\n",
      "Val    loss : 0.10072    f1 : 0.89914\n",
      "epoch : 36/70    time : 41s/1388s\n",
      "TRAIN    loss : 0.01973    f1 : 0.98136\n",
      "Val    loss : 0.12270    f1 : 0.87499\n",
      "epoch : 37/70    time : 41s/1349s\n",
      "TRAIN    loss : 0.01907    f1 : 0.98441\n",
      "Val    loss : 0.13522    f1 : 0.84694\n",
      "epoch : 38/70    time : 39s/1263s\n",
      "TRAIN    loss : 0.02368    f1 : 0.97097\n",
      "Val    loss : 0.12888    f1 : 0.88542\n",
      "epoch : 39/70    time : 42s/1313s\n",
      "TRAIN    loss : 0.02671    f1 : 0.97629\n",
      "Val    loss : 0.19306    f1 : 0.83571\n",
      "epoch : 40/70    time : 40s/1210s\n",
      "TRAIN    loss : 0.01351    f1 : 0.98550\n",
      "Val    loss : 0.15111    f1 : 0.82061\n",
      "epoch : 41/70    time : 39s/1138s\n",
      "TRAIN    loss : 0.01295    f1 : 0.98047\n",
      "Val    loss : 0.16984    f1 : 0.81129\n",
      "epoch : 42/70    time : 40s/1119s\n",
      "TRAIN    loss : 0.01859    f1 : 0.98050\n",
      "Val    loss : 0.14450    f1 : 0.84501\n",
      "epoch : 43/70    time : 40s/1083s\n",
      "TRAIN    loss : 0.00529    f1 : 0.99321\n",
      "Val    loss : 0.13895    f1 : 0.85621\n",
      "epoch : 44/70    time : 42s/1091s\n",
      "TRAIN    loss : 0.01658    f1 : 0.98580\n",
      "Val    loss : 0.17323    f1 : 0.83036\n",
      "epoch : 45/70    time : 40s/1002s\n",
      "TRAIN    loss : 0.01937    f1 : 0.98062\n",
      "Val    loss : 0.16566    f1 : 0.80747\n",
      "epoch : 46/70    time : 41s/994s\n",
      "TRAIN    loss : 0.01839    f1 : 0.97799\n",
      "Val    loss : 0.20257    f1 : 0.79788\n",
      "epoch : 47/70    time : 40s/931s\n",
      "TRAIN    loss : 0.00834    f1 : 0.98869\n",
      "Val    loss : 0.16917    f1 : 0.79890\n",
      "epoch : 48/70    time : 42s/914s\n",
      "TRAIN    loss : 0.01027    f1 : 0.98258\n",
      "Val    loss : 0.15699    f1 : 0.86907\n",
      "epoch : 49/70    time : 40s/840s\n",
      "TRAIN    loss : 0.01525    f1 : 0.98657\n",
      "Val    loss : 0.14886    f1 : 0.85206\n",
      "epoch : 50/70    time : 40s/790s\n",
      "TRAIN    loss : 0.01040    f1 : 0.99170\n",
      "Val    loss : 0.15086    f1 : 0.84939\n",
      "epoch : 51/70    time : 40s/755s\n",
      "TRAIN    loss : 0.02163    f1 : 0.98099\n",
      "Val    loss : 0.14662    f1 : 0.85696\n",
      "epoch : 52/70    time : 41s/743s\n",
      "TRAIN    loss : 0.01107    f1 : 0.99047\n",
      "Val    loss : 0.19439    f1 : 0.84878\n",
      "epoch : 53/70    time : 41s/702s\n",
      "TRAIN    loss : 0.00771    f1 : 0.99223\n",
      "Val    loss : 0.16435    f1 : 0.83379\n",
      "epoch : 54/70    time : 41s/653s\n",
      "TRAIN    loss : 0.02014    f1 : 0.97149\n",
      "Val    loss : 0.14333    f1 : 0.83707\n",
      "epoch : 55/70    time : 40s/605s\n",
      "TRAIN    loss : 0.01801    f1 : 0.98294\n",
      "Val    loss : 0.13570    f1 : 0.86581\n",
      "----------fold_4 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 40s/2737s\n",
      "TRAIN    loss : 1.16917    f1 : 0.17057\n",
      "Val    loss : 0.63652    f1 : 0.28093\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 43s/2925s\n",
      "TRAIN    loss : 0.53992    f1 : 0.35533\n",
      "Val    loss : 0.41626    f1 : 0.42221\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 41s/2734s\n",
      "TRAIN    loss : 0.39329    f1 : 0.51836\n",
      "Val    loss : 0.29099    f1 : 0.54545\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 41s/2700s\n",
      "TRAIN    loss : 0.28470    f1 : 0.63273\n",
      "Val    loss : 0.26253    f1 : 0.58766\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 41s/2673s\n",
      "TRAIN    loss : 0.21522    f1 : 0.70987\n",
      "Val    loss : 0.23305    f1 : 0.69354\n",
      "epoch : 6/70    time : 43s/2733s\n",
      "TRAIN    loss : 0.17023    f1 : 0.77531\n",
      "Val    loss : 0.22489    f1 : 0.68513\n",
      "epoch : 7/70    time : 40s/2521s\n",
      "TRAIN    loss : 0.13201    f1 : 0.82641\n",
      "Val    loss : 0.21875    f1 : 0.69181\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/70    time : 41s/2533s\n",
      "TRAIN    loss : 0.10435    f1 : 0.87331\n",
      "Val    loss : 0.16128    f1 : 0.78489\n",
      "epoch : 9/70    time : 42s/2537s\n",
      "TRAIN    loss : 0.08232    f1 : 0.90690\n",
      "Val    loss : 0.18435    f1 : 0.75828\n",
      "epoch : 10/70    time : 40s/2427s\n",
      "TRAIN    loss : 0.07967    f1 : 0.90116\n",
      "Val    loss : 0.18406    f1 : 0.78435\n",
      "epoch : 11/70    time : 42s/2495s\n",
      "TRAIN    loss : 0.06618    f1 : 0.92033\n",
      "Val    loss : 0.22320    f1 : 0.71861\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/70    time : 41s/2381s\n",
      "TRAIN    loss : 0.06053    f1 : 0.93320\n",
      "Val    loss : 0.19826    f1 : 0.79243\n",
      "epoch : 13/70    time : 41s/2325s\n",
      "TRAIN    loss : 0.04951    f1 : 0.94027\n",
      "Val    loss : 0.16408    f1 : 0.75690\n",
      "epoch : 14/70    time : 40s/2262s\n",
      "TRAIN    loss : 0.04087    f1 : 0.96256\n",
      "Val    loss : 0.15329    f1 : 0.78568\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/70    time : 43s/2382s\n",
      "TRAIN    loss : 0.04510    f1 : 0.94159\n",
      "Val    loss : 0.15858    f1 : 0.79323\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/70    time : 42s/2273s\n",
      "TRAIN    loss : 0.03608    f1 : 0.96385\n",
      "Val    loss : 0.17085    f1 : 0.79865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 17/70    time : 40s/2122s\n",
      "TRAIN    loss : 0.02000    f1 : 0.98277\n",
      "Val    loss : 0.15462    f1 : 0.79483\n",
      "epoch : 18/70    time : 40s/2101s\n",
      "TRAIN    loss : 0.02685    f1 : 0.96939\n",
      "Val    loss : 0.19076    f1 : 0.78083\n",
      "epoch : 19/70    time : 41s/2089s\n",
      "TRAIN    loss : 0.02669    f1 : 0.97793\n",
      "Val    loss : 0.17328    f1 : 0.77480\n",
      "-----------------SAVE:20 epoch----------------\n",
      "epoch : 20/70    time : 42s/2088s\n",
      "TRAIN    loss : 0.03179    f1 : 0.96624\n",
      "Val    loss : 0.18530    f1 : 0.80036\n",
      "epoch : 21/70    time : 40s/1980s\n",
      "TRAIN    loss : 0.02341    f1 : 0.97496\n",
      "Val    loss : 0.19689    f1 : 0.78856\n",
      "epoch : 22/70    time : 40s/1944s\n",
      "TRAIN    loss : 0.02628    f1 : 0.97106\n",
      "Val    loss : 0.17547    f1 : 0.76873\n",
      "epoch : 23/70    time : 41s/1915s\n",
      "TRAIN    loss : 0.03657    f1 : 0.95278\n",
      "Val    loss : 0.19700    f1 : 0.77782\n",
      "epoch : 24/70    time : 42s/1930s\n",
      "TRAIN    loss : 0.02569    f1 : 0.97535\n",
      "Val    loss : 0.17588    f1 : 0.78824\n",
      "-----------------SAVE:25 epoch----------------\n",
      "epoch : 25/70    time : 42s/1886s\n",
      "TRAIN    loss : 0.02104    f1 : 0.98554\n",
      "Val    loss : 0.14656    f1 : 0.83457\n",
      "epoch : 26/70    time : 40s/1767s\n",
      "TRAIN    loss : 0.01794    f1 : 0.97975\n",
      "Val    loss : 0.19196    f1 : 0.80121\n",
      "epoch : 27/70    time : 40s/1736s\n",
      "TRAIN    loss : 0.02918    f1 : 0.97113\n",
      "Val    loss : 0.19939    f1 : 0.82212\n",
      "epoch : 28/70    time : 43s/1787s\n",
      "TRAIN    loss : 0.03491    f1 : 0.97888\n",
      "Val    loss : 0.16419    f1 : 0.83189\n",
      "epoch : 29/70    time : 40s/1642s\n",
      "TRAIN    loss : 0.02526    f1 : 0.97611\n",
      "Val    loss : 0.22307    f1 : 0.79107\n",
      "epoch : 30/70    time : 40s/1590s\n",
      "TRAIN    loss : 0.02426    f1 : 0.96687\n",
      "Val    loss : 0.27723    f1 : 0.81344\n",
      "epoch : 31/70    time : 40s/1562s\n",
      "TRAIN    loss : 0.01408    f1 : 0.98688\n",
      "Val    loss : 0.21532    f1 : 0.80359\n",
      "epoch : 32/70    time : 41s/1546s\n",
      "TRAIN    loss : 0.01310    f1 : 0.98377\n",
      "Val    loss : 0.21009    f1 : 0.80830\n",
      "epoch : 33/70    time : 42s/1562s\n",
      "TRAIN    loss : 0.02635    f1 : 0.97387\n",
      "Val    loss : 0.20115    f1 : 0.76188\n",
      "epoch : 34/70    time : 40s/1455s\n",
      "TRAIN    loss : 0.02574    f1 : 0.96761\n",
      "Val    loss : 0.21216    f1 : 0.75421\n",
      "-----------------SAVE:35 epoch----------------\n",
      "epoch : 35/70    time : 42s/1456s\n",
      "TRAIN    loss : 0.01791    f1 : 0.98010\n",
      "Val    loss : 0.15827    f1 : 0.83652\n",
      "epoch : 36/70    time : 41s/1387s\n",
      "TRAIN    loss : 0.01697    f1 : 0.98319\n",
      "Val    loss : 0.17224    f1 : 0.80006\n",
      "epoch : 37/70    time : 43s/1406s\n",
      "TRAIN    loss : 0.02985    f1 : 0.96565\n",
      "Val    loss : 0.17748    f1 : 0.78164\n",
      "epoch : 38/70    time : 41s/1318s\n",
      "TRAIN    loss : 0.01810    f1 : 0.98182\n",
      "Val    loss : 0.12894    f1 : 0.83333\n",
      "epoch : 39/70    time : 41s/1285s\n",
      "TRAIN    loss : 0.01373    f1 : 0.98001\n",
      "Val    loss : 0.14410    f1 : 0.79974\n",
      "epoch : 40/70    time : 41s/1216s\n",
      "TRAIN    loss : 0.01167    f1 : 0.99176\n",
      "Val    loss : 0.17287    f1 : 0.80957\n",
      "-----------------SAVE:41 epoch----------------\n",
      "epoch : 41/70    time : 44s/1273s\n",
      "TRAIN    loss : 0.00462    f1 : 0.99525\n",
      "Val    loss : 0.15449    f1 : 0.83679\n",
      "-----------------SAVE:42 epoch----------------\n",
      "epoch : 42/70    time : 42s/1172s\n",
      "TRAIN    loss : 0.00980    f1 : 0.99232\n",
      "Val    loss : 0.16573    f1 : 0.84481\n",
      "epoch : 43/70    time : 41s/1104s\n",
      "TRAIN    loss : 0.01297    f1 : 0.98908\n",
      "Val    loss : 0.17797    f1 : 0.82986\n",
      "epoch : 44/70    time : 41s/1063s\n",
      "TRAIN    loss : 0.03511    f1 : 0.96132\n",
      "Val    loss : 0.20816    f1 : 0.80677\n",
      "-----------------SAVE:45 epoch----------------\n",
      "epoch : 45/70    time : 41s/1023s\n",
      "TRAIN    loss : 0.01801    f1 : 0.98648\n",
      "Val    loss : 0.16196    f1 : 0.85175\n",
      "-----------------SAVE:46 epoch----------------\n",
      "epoch : 46/70    time : 44s/1047s\n",
      "TRAIN    loss : 0.02193    f1 : 0.97683\n",
      "Val    loss : 0.19034    f1 : 0.85231\n",
      "epoch : 47/70    time : 41s/938s\n",
      "TRAIN    loss : 0.01770    f1 : 0.98950\n",
      "Val    loss : 0.26603    f1 : 0.83251\n",
      "epoch : 48/70    time : 41s/905s\n",
      "TRAIN    loss : 0.01686    f1 : 0.98492\n",
      "Val    loss : 0.20537    f1 : 0.80604\n",
      "epoch : 49/70    time : 40s/850s\n",
      "TRAIN    loss : 0.01840    f1 : 0.98212\n",
      "Val    loss : 0.17376    f1 : 0.83414\n",
      "epoch : 50/70    time : 42s/835s\n",
      "TRAIN    loss : 0.02294    f1 : 0.98237\n",
      "Val    loss : 0.15433    f1 : 0.84936\n",
      "-----------------SAVE:51 epoch----------------\n",
      "epoch : 51/70    time : 42s/789s\n",
      "TRAIN    loss : 0.01146    f1 : 0.98902\n",
      "Val    loss : 0.25412    f1 : 0.85505\n",
      "-----------------SAVE:52 epoch----------------\n",
      "epoch : 52/70    time : 42s/760s\n",
      "TRAIN    loss : 0.01161    f1 : 0.98846\n",
      "Val    loss : 0.17051    f1 : 0.85855\n",
      "-----------------SAVE:53 epoch----------------\n",
      "epoch : 53/70    time : 41s/701s\n",
      "TRAIN    loss : 0.01598    f1 : 0.98442\n",
      "Val    loss : 0.17215    f1 : 0.86818\n",
      "epoch : 54/70    time : 42s/674s\n",
      "TRAIN    loss : 0.01155    f1 : 0.98851\n",
      "Val    loss : 0.18347    f1 : 0.86132\n",
      "epoch : 55/70    time : 40s/604s\n",
      "TRAIN    loss : 0.02910    f1 : 0.98156\n",
      "Val    loss : 0.22838    f1 : 0.84202\n",
      "epoch : 56/70    time : 40s/565s\n",
      "TRAIN    loss : 0.00436    f1 : 0.99670\n",
      "Val    loss : 0.24750    f1 : 0.81512\n",
      "epoch : 57/70    time : 41s/529s\n",
      "TRAIN    loss : 0.00423    f1 : 0.99792\n",
      "Val    loss : 0.23954    f1 : 0.83572\n",
      "epoch : 58/70    time : 42s/500s\n",
      "TRAIN    loss : 0.00624    f1 : 0.99588\n",
      "Val    loss : 0.22387    f1 : 0.83514\n",
      "epoch : 59/70    time : 42s/462s\n",
      "TRAIN    loss : 0.01208    f1 : 0.98898\n",
      "Val    loss : 0.20004    f1 : 0.82142\n",
      "epoch : 60/70    time : 40s/405s\n",
      "TRAIN    loss : 0.01385    f1 : 0.98482\n",
      "Val    loss : 0.18627    f1 : 0.82510\n",
      "epoch : 61/70    time : 41s/368s\n",
      "TRAIN    loss : 0.01056    f1 : 0.98924\n",
      "Val    loss : 0.21066    f1 : 0.83873\n",
      "epoch : 62/70    time : 41s/329s\n",
      "TRAIN    loss : 0.01038    f1 : 0.99153\n",
      "Val    loss : 0.22827    f1 : 0.81406\n",
      "epoch : 63/70    time : 42s/291s\n",
      "TRAIN    loss : 0.01808    f1 : 0.98424\n",
      "Val    loss : 0.33372    f1 : 0.76798\n",
      "epoch : 64/70    time : 41s/244s\n",
      "TRAIN    loss : 0.02507    f1 : 0.98136\n",
      "Val    loss : 0.16472    f1 : 0.82552\n",
      "epoch : 65/70    time : 40s/200s\n",
      "TRAIN    loss : 0.01143    f1 : 0.98741\n",
      "Val    loss : 0.19845    f1 : 0.80515\n",
      "epoch : 66/70    time : 41s/166s\n",
      "TRAIN    loss : 0.02068    f1 : 0.97803\n",
      "Val    loss : 0.19710    f1 : 0.84133\n",
      "epoch : 67/70    time : 40s/120s\n",
      "TRAIN    loss : 0.00822    f1 : 0.99233\n",
      "Val    loss : 0.21407    f1 : 0.83613\n",
      "epoch : 68/70    time : 43s/85s\n",
      "TRAIN    loss : 0.02730    f1 : 0.97619\n",
      "Val    loss : 0.17416    f1 : 0.81568\n",
      "epoch : 69/70    time : 41s/41s\n",
      "TRAIN    loss : 0.00690    f1 : 0.99372\n",
      "Val    loss : 0.19067    f1 : 0.83468\n",
      "epoch : 70/70    time : 40s/0s\n",
      "TRAIN    loss : 0.01252    f1 : 0.99249\n",
      "Val    loss : 0.17465    f1 : 0.85914\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022,shuffle=True)\n",
    "batch_size = 32\n",
    "epochs = 70\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "  print(\"----------fold_{} start!----------\".format(idx))\n",
    "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "  # Train\n",
    "  train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Val\n",
    "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  best=0\n",
    "\n",
    "  model = Network().to(device)\n",
    "\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay = 2e-2)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "  best_f1 = 0\n",
    "  early_stopping = 0\n",
    "  for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss = 0 \n",
    "      val_pred = []\n",
    "      val_y = []\n",
    "      \n",
    "\n",
    "      for batch in (val_loader):\n",
    "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_val = model(x_val)\n",
    "        loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "        val_loss += loss_val.item()/len(val_loader)\n",
    "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "        val_y += y_val.detach().cpu().numpy().tolist()\n",
    "      val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "      if val_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_loss = val_loss\n",
    "        best_f1 = val_f1\n",
    "        early_stopping = 0\n",
    "\n",
    "        torch.save({'epoch':epoch,\n",
    "                    'state_dict':state_dict,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "             }, path +'best_model_{}.pth'.format(idx))\n",
    "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "      else:\n",
    "          early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "      if early_stopping == 20:\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "Jl2OKpQiO5S1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl2OKpQiO5S1",
    "outputId": "e48def07-ef6d-4325-f297-c705088b3eb8"
   },
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 32\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load((path+'best_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "seat84vNOOtT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seat84vNOOtT",
    "outputId": "71c853b2-29c3-430e-e4d0-cb1a66e11196"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "GjsHs-T3SPJq",
   "metadata": {
    "id": "GjsHs-T3SPJq"
   },
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1])+ np.array(pred_ensemble[3]) + np.array(pred_ensemble[4]) )/4\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "UIglTwAV7L54",
   "metadata": {
    "id": "UIglTwAV7L54"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "292QDIS5DOKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "292QDIS5DOKf",
    "outputId": "0e47d38f-d36a-40cd-a925-90e6bce52652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1naZSLGZ7L55",
   "metadata": {
    "id": "1naZSLGZ7L55"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"b3_norm_epoch70_4_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p87_msjB7L51",
   "metadata": {
    "id": "p87_msjB7L51"
   },
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MW9Fx7QADii5",
   "metadata": {
    "id": "MW9Fx7QADii5"
   },
   "source": [
    "사전 학습 모델의 성능 파악을 할 때 Fold 학습은 실행 시간이 오래걸려서 fold를 나누지 않은 데이터에 대해서 학습을 진행하고 성능을 비교하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "syUpL8e_7L50",
   "metadata": {
    "id": "syUpL8e_7L50"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cJc8Yj7zrh4g",
   "metadata": {
    "id": "cJc8Yj7zrh4g"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tpCGp41k7L51",
   "metadata": {
    "id": "tpCGp41k7L51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/30    time : 52s/1495s\n",
      "TRAIN    loss : 1.62875    f1 : 0.15265\n",
      "epoch : 2/30    time : 47s/1312s\n",
      "TRAIN    loss : 0.78266    f1 : 0.19686\n",
      "epoch : 3/30    time : 48s/1294s\n",
      "TRAIN    loss : 0.59936    f1 : 0.29615\n",
      "epoch : 4/30    time : 46s/1209s\n",
      "TRAIN    loss : 0.47578    f1 : 0.39296\n",
      "epoch : 5/30    time : 49s/1224s\n",
      "TRAIN    loss : 0.40606    f1 : 0.48568\n",
      "epoch : 6/30    time : 49s/1164s\n",
      "TRAIN    loss : 0.34266    f1 : 0.55320\n",
      "epoch : 7/30    time : 48s/1104s\n",
      "TRAIN    loss : 0.28676    f1 : 0.60903\n",
      "epoch : 8/30    time : 48s/1049s\n",
      "TRAIN    loss : 0.24467    f1 : 0.69303\n",
      "epoch : 9/30    time : 49s/1037s\n",
      "TRAIN    loss : 0.20959    f1 : 0.71534\n",
      "epoch : 10/30    time : 46s/922s\n",
      "TRAIN    loss : 0.18401    f1 : 0.77599\n",
      "epoch : 11/30    time : 47s/893s\n",
      "TRAIN    loss : 0.15921    f1 : 0.81108\n",
      "epoch : 12/30    time : 49s/877s\n",
      "TRAIN    loss : 0.13784    f1 : 0.83371\n",
      "epoch : 13/30    time : 49s/826s\n",
      "TRAIN    loss : 0.12121    f1 : 0.84938\n",
      "epoch : 14/30    time : 46s/741s\n",
      "TRAIN    loss : 0.09335    f1 : 0.90110\n",
      "epoch : 15/30    time : 47s/707s\n",
      "TRAIN    loss : 0.08708    f1 : 0.90457\n",
      "epoch : 16/30    time : 49s/687s\n",
      "TRAIN    loss : 0.07931    f1 : 0.91797\n",
      "epoch : 17/30    time : 46s/598s\n",
      "TRAIN    loss : 0.07098    f1 : 0.92517\n",
      "epoch : 18/30    time : 47s/562s\n",
      "TRAIN    loss : 0.06265    f1 : 0.93078\n",
      "epoch : 19/30    time : 46s/511s\n",
      "TRAIN    loss : 0.05610    f1 : 0.93764\n",
      "epoch : 20/30    time : 49s/487s\n",
      "TRAIN    loss : 0.04765    f1 : 0.95464\n",
      "epoch : 21/30    time : 49s/438s\n",
      "TRAIN    loss : 0.04165    f1 : 0.95884\n",
      "epoch : 22/30    time : 47s/375s\n",
      "TRAIN    loss : 0.04206    f1 : 0.95879\n",
      "epoch : 23/30    time : 48s/334s\n",
      "TRAIN    loss : 0.04165    f1 : 0.95816\n",
      "epoch : 24/30    time : 48s/289s\n",
      "TRAIN    loss : 0.03794    f1 : 0.96630\n",
      "epoch : 25/30    time : 47s/233s\n",
      "TRAIN    loss : 0.03458    f1 : 0.96676\n",
      "epoch : 26/30    time : 48s/190s\n",
      "TRAIN    loss : 0.03391    f1 : 0.95902\n",
      "epoch : 27/30    time : 49s/147s\n",
      "TRAIN    loss : 0.03721    f1 : 0.96333\n",
      "epoch : 28/30    time : 47s/95s\n",
      "TRAIN    loss : 0.03108    f1 : 0.96724\n",
      "epoch : 29/30    time : 47s/47s\n",
      "TRAIN    loss : 0.03028    f1 : 0.97580\n",
      "epoch : 30/30    time : 48s/0s\n",
      "TRAIN    loss : 0.02582    f1 : 0.97447\n"
     ]
    }
   ],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "best=0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YssPW4xq7L53",
   "metadata": {
    "id": "YssPW4xq7L53"
   },
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1w_VB_PY7L53",
   "metadata": {
    "id": "1w_VB_PY7L53"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "f_pred = []\n",
    "pred_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "            pred_prob.extend(pred.detach().cpu().numpy())\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aZMML2u3DTHx",
   "metadata": {
    "id": "aZMML2u3DTHx"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I4io2mJC7L54",
   "metadata": {
    "id": "I4io2mJC7L54"
   },
   "source": [
    "### 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "XCV3FEKe7L55",
   "metadata": {
    "id": "XCV3FEKe7L55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "jsl6tXbz7L56",
   "metadata": {
    "id": "jsl6tXbz7L56"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \" b3_norm.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-instruction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[BASELINE]_EfficientNet_b3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
