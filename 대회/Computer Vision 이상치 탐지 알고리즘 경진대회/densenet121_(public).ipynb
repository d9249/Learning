{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "LlcNsGEk7L5r",
   "metadata": {
    "id": "LlcNsGEk7L5r"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "popular-bathroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3',\n",
      " 'bat_resnext26ts',\n",
      " 'beit_base_patch16_224',\n",
      " 'beit_base_patch16_224_in22k',\n",
      " 'beit_base_patch16_384',\n",
      " 'beit_large_patch16_224',\n",
      " 'beit_large_patch16_224_in22k',\n",
      " 'beit_large_patch16_384',\n",
      " 'beit_large_patch16_512',\n",
      " 'botnet26t_256',\n",
      " 'cait_m36_384',\n",
      " 'cait_m48_448',\n",
      " 'cait_s24_224',\n",
      " 'cait_s24_384',\n",
      " 'cait_s36_384',\n",
      " 'cait_xs24_384',\n",
      " 'cait_xxs24_224',\n",
      " 'cait_xxs24_384',\n",
      " 'cait_xxs36_224',\n",
      " 'cait_xxs36_384',\n",
      " 'coat_lite_mini',\n",
      " 'coat_lite_small',\n",
      " 'coat_lite_tiny',\n",
      " 'coat_mini',\n",
      " 'coat_tiny',\n",
      " 'convit_base',\n",
      " 'convit_small',\n",
      " 'convit_tiny',\n",
      " 'convmixer_768_32',\n",
      " 'convmixer_1024_20_ks9_p14',\n",
      " 'convmixer_1536_20',\n",
      " 'convnext_base',\n",
      " 'convnext_base_384_in22ft1k',\n",
      " 'convnext_base_in22ft1k',\n",
      " 'convnext_base_in22k',\n",
      " 'convnext_large',\n",
      " 'convnext_large_384_in22ft1k',\n",
      " 'convnext_large_in22ft1k',\n",
      " 'convnext_large_in22k',\n",
      " 'convnext_small',\n",
      " 'convnext_tiny',\n",
      " 'convnext_xlarge_384_in22ft1k',\n",
      " 'convnext_xlarge_in22ft1k',\n",
      " 'convnext_xlarge_in22k',\n",
      " 'crossvit_9_240',\n",
      " 'crossvit_9_dagger_240',\n",
      " 'crossvit_15_240',\n",
      " 'crossvit_15_dagger_240',\n",
      " 'crossvit_15_dagger_408',\n",
      " 'crossvit_18_240',\n",
      " 'crossvit_18_dagger_240',\n",
      " 'crossvit_18_dagger_408',\n",
      " 'crossvit_base_240',\n",
      " 'crossvit_small_240',\n",
      " 'crossvit_tiny_240',\n",
      " 'cspdarknet53',\n",
      " 'cspresnet50',\n",
      " 'cspresnext50',\n",
      " 'deit_base_distilled_patch16_224',\n",
      " 'deit_base_distilled_patch16_384',\n",
      " 'deit_base_patch16_224',\n",
      " 'deit_base_patch16_384',\n",
      " 'deit_small_distilled_patch16_224',\n",
      " 'deit_small_patch16_224',\n",
      " 'deit_tiny_distilled_patch16_224',\n",
      " 'deit_tiny_patch16_224',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dm_nfnet_f0',\n",
      " 'dm_nfnet_f1',\n",
      " 'dm_nfnet_f2',\n",
      " 'dm_nfnet_f3',\n",
      " 'dm_nfnet_f4',\n",
      " 'dm_nfnet_f5',\n",
      " 'dm_nfnet_f6',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'eca_botnext26ts_256',\n",
      " 'eca_halonext26ts',\n",
      " 'eca_nfnet_l0',\n",
      " 'eca_nfnet_l1',\n",
      " 'eca_nfnet_l2',\n",
      " 'eca_resnet33ts',\n",
      " 'eca_resnext26ts',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b4',\n",
      " 'efficientnet_el',\n",
      " 'efficientnet_el_pruned',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_es_pruned',\n",
      " 'efficientnet_lite0',\n",
      " 'efficientnetv2_rw_m',\n",
      " 'efficientnetv2_rw_s',\n",
      " 'efficientnetv2_rw_t',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'fbnetc_100',\n",
      " 'fbnetv3_b',\n",
      " 'fbnetv3_d',\n",
      " 'fbnetv3_g',\n",
      " 'gc_efficientnetv2_rw_t',\n",
      " 'gcresnet33ts',\n",
      " 'gcresnet50t',\n",
      " 'gcresnext26ts',\n",
      " 'gcresnext50ts',\n",
      " 'gernet_l',\n",
      " 'gernet_m',\n",
      " 'gernet_s',\n",
      " 'ghostnet_100',\n",
      " 'gluon_inception_v3',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_senet154',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'gluon_xception65',\n",
      " 'gmixer_24_224',\n",
      " 'gmlp_s16_224',\n",
      " 'halo2botnet50ts_256',\n",
      " 'halonet26t',\n",
      " 'halonet50ts',\n",
      " 'haloregnetz_b',\n",
      " 'hardcorenas_a',\n",
      " 'hardcorenas_b',\n",
      " 'hardcorenas_c',\n",
      " 'hardcorenas_d',\n",
      " 'hardcorenas_e',\n",
      " 'hardcorenas_f',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w64',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'jx_nest_base',\n",
      " 'jx_nest_small',\n",
      " 'jx_nest_tiny',\n",
      " 'lambda_resnet26rpt_256',\n",
      " 'lambda_resnet26t',\n",
      " 'lambda_resnet50ts',\n",
      " 'lamhalobotnet50ts_256',\n",
      " 'lcnet_050',\n",
      " 'lcnet_075',\n",
      " 'lcnet_100',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'levit_128',\n",
      " 'levit_128s',\n",
      " 'levit_192',\n",
      " 'levit_256',\n",
      " 'levit_384',\n",
      " 'mixer_b16_224',\n",
      " 'mixer_b16_224_in21k',\n",
      " 'mixer_b16_224_miil',\n",
      " 'mixer_b16_224_miil_in21k',\n",
      " 'mixer_l16_224',\n",
      " 'mixer_l16_224_in21k',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mnasnet_100',\n",
      " 'mnasnet_small',\n",
      " 'mobilenetv2_050',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_large_100_miil',\n",
      " 'mobilenetv3_large_100_miil_in21k',\n",
      " 'mobilenetv3_rw',\n",
      " 'nasnetalarge',\n",
      " 'nf_regnet_b1',\n",
      " 'nf_resnet50',\n",
      " 'nfnet_l0',\n",
      " 'pit_b_224',\n",
      " 'pit_b_distilled_224',\n",
      " 'pit_s_224',\n",
      " 'pit_s_distilled_224',\n",
      " 'pit_ti_224',\n",
      " 'pit_ti_distilled_224',\n",
      " 'pit_xs_224',\n",
      " 'pit_xs_distilled_224',\n",
      " 'pnasnet5large',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'regnetz_b16',\n",
      " 'regnetz_c16',\n",
      " 'regnetz_d8',\n",
      " 'regnetz_d32',\n",
      " 'regnetz_e8',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2next50',\n",
      " 'resmlp_12_224',\n",
      " 'resmlp_12_224_dino',\n",
      " 'resmlp_12_distilled_224',\n",
      " 'resmlp_24_224',\n",
      " 'resmlp_24_224_dino',\n",
      " 'resmlp_24_distilled_224',\n",
      " 'resmlp_36_224',\n",
      " 'resmlp_36_distilled_224',\n",
      " 'resmlp_big_24_224',\n",
      " 'resmlp_big_24_224_in22ft1k',\n",
      " 'resmlp_big_24_distilled_224',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet26t',\n",
      " 'resnet32ts',\n",
      " 'resnet33ts',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50_gn',\n",
      " 'resnet50d',\n",
      " 'resnet51q',\n",
      " 'resnet61q',\n",
      " 'resnet101',\n",
      " 'resnet101d',\n",
      " 'resnet152',\n",
      " 'resnet152d',\n",
      " 'resnet200d',\n",
      " 'resnetblur50',\n",
      " 'resnetrs50',\n",
      " 'resnetrs101',\n",
      " 'resnetrs152',\n",
      " 'resnetrs200',\n",
      " 'resnetrs270',\n",
      " 'resnetrs350',\n",
      " 'resnetrs420',\n",
      " 'resnetv2_50',\n",
      " 'resnetv2_50x1_bit_distilled',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bit_teacher',\n",
      " 'resnetv2_152x2_bit_teacher_384',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext26ts',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'sebotnet33ts_256',\n",
      " 'sehalonet33ts',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'semnasnet_075',\n",
      " 'semnasnet_100',\n",
      " 'seresnet33ts',\n",
      " 'seresnet50',\n",
      " 'seresnet152d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext26ts',\n",
      " 'seresnext50_32x4d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swin_base_patch4_window7_224',\n",
      " 'swin_base_patch4_window7_224_in22k',\n",
      " 'swin_base_patch4_window12_384',\n",
      " 'swin_base_patch4_window12_384_in22k',\n",
      " 'swin_large_patch4_window7_224',\n",
      " 'swin_large_patch4_window7_224_in22k',\n",
      " 'swin_large_patch4_window12_384',\n",
      " 'swin_large_patch4_window12_384_in22k',\n",
      " 'swin_small_patch4_window7_224',\n",
      " 'swin_tiny_patch4_window7_224',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b0_ap',\n",
      " 'tf_efficientnet_b0_ns',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b1_ap',\n",
      " 'tf_efficientnet_b1_ns',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b2_ap',\n",
      " 'tf_efficientnet_b2_ns',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b3_ap',\n",
      " 'tf_efficientnet_b3_ns',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b4_ap',\n",
      " 'tf_efficientnet_b4_ns',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b5_ap',\n",
      " 'tf_efficientnet_b5_ns',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b6_ap',\n",
      " 'tf_efficientnet_b6_ns',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b7_ap',\n",
      " 'tf_efficientnet_b7_ns',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_b8_ap',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2_ns',\n",
      " 'tf_efficientnet_l2_ns_475',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_efficientnetv2_b0',\n",
      " 'tf_efficientnetv2_b1',\n",
      " 'tf_efficientnetv2_b2',\n",
      " 'tf_efficientnetv2_b3',\n",
      " 'tf_efficientnetv2_l',\n",
      " 'tf_efficientnetv2_l_in21ft1k',\n",
      " 'tf_efficientnetv2_l_in21k',\n",
      " 'tf_efficientnetv2_m',\n",
      " 'tf_efficientnetv2_m_in21ft1k',\n",
      " 'tf_efficientnetv2_m_in21k',\n",
      " 'tf_efficientnetv2_s',\n",
      " 'tf_efficientnetv2_s_in21ft1k',\n",
      " 'tf_efficientnetv2_s_in21k',\n",
      " 'tf_efficientnetv2_xl_in21ft1k',\n",
      " 'tf_efficientnetv2_xl_in21k',\n",
      " 'tf_inception_v3',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tinynet_a',\n",
      " 'tinynet_b',\n",
      " 'tinynet_c',\n",
      " 'tinynet_d',\n",
      " 'tinynet_e',\n",
      " 'tnt_s_patch16_224',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_m_miil_in21k',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_densenet121',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'twins_pcpvt_base',\n",
      " 'twins_pcpvt_large',\n",
      " 'twins_pcpvt_small',\n",
      " 'twins_svt_base',\n",
      " 'twins_svt_large',\n",
      " 'twins_svt_small',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'visformer_small',\n",
      " 'vit_base_patch8_224',\n",
      " 'vit_base_patch8_224_in21k',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_224_in21k',\n",
      " 'vit_base_patch16_224_miil',\n",
      " 'vit_base_patch16_224_miil_in21k',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch16_sam_224',\n",
      " 'vit_base_patch32_224',\n",
      " 'vit_base_patch32_224_in21k',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_patch32_sam_224',\n",
      " 'vit_base_r50_s16_224_in21k',\n",
      " 'vit_base_r50_s16_384',\n",
      " 'vit_huge_patch14_224_in21k',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_224_in21k',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch32_224_in21k',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_large_r50_s32_224',\n",
      " 'vit_large_r50_s32_224_in21k',\n",
      " 'vit_large_r50_s32_384',\n",
      " 'vit_small_patch16_224',\n",
      " 'vit_small_patch16_224_in21k',\n",
      " 'vit_small_patch16_384',\n",
      " 'vit_small_patch32_224',\n",
      " 'vit_small_patch32_224_in21k',\n",
      " 'vit_small_patch32_384',\n",
      " 'vit_small_r26_s32_224',\n",
      " 'vit_small_r26_s32_224_in21k',\n",
      " 'vit_small_r26_s32_384',\n",
      " 'vit_tiny_patch16_224',\n",
      " 'vit_tiny_patch16_224_in21k',\n",
      " 'vit_tiny_patch16_384',\n",
      " 'vit_tiny_r_s16_p8_224',\n",
      " 'vit_tiny_r_s16_p8_224_in21k',\n",
      " 'vit_tiny_r_s16_p8_384',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception',\n",
      " 'xception41',\n",
      " 'xception65',\n",
      " 'xception71',\n",
      " 'xcit_large_24_p8_224',\n",
      " 'xcit_large_24_p8_224_dist',\n",
      " 'xcit_large_24_p8_384_dist',\n",
      " 'xcit_large_24_p16_224',\n",
      " 'xcit_large_24_p16_224_dist',\n",
      " 'xcit_large_24_p16_384_dist',\n",
      " 'xcit_medium_24_p8_224',\n",
      " 'xcit_medium_24_p8_224_dist',\n",
      " 'xcit_medium_24_p8_384_dist',\n",
      " 'xcit_medium_24_p16_224',\n",
      " 'xcit_medium_24_p16_224_dist',\n",
      " 'xcit_medium_24_p16_384_dist',\n",
      " 'xcit_nano_12_p8_224',\n",
      " 'xcit_nano_12_p8_224_dist',\n",
      " 'xcit_nano_12_p8_384_dist',\n",
      " 'xcit_nano_12_p16_224',\n",
      " 'xcit_nano_12_p16_224_dist',\n",
      " 'xcit_nano_12_p16_384_dist',\n",
      " 'xcit_small_12_p8_224',\n",
      " 'xcit_small_12_p8_224_dist',\n",
      " 'xcit_small_12_p8_384_dist',\n",
      " 'xcit_small_12_p16_224',\n",
      " 'xcit_small_12_p16_224_dist',\n",
      " 'xcit_small_12_p16_384_dist',\n",
      " 'xcit_small_24_p8_224',\n",
      " 'xcit_small_24_p8_224_dist',\n",
      " 'xcit_small_24_p8_384_dist',\n",
      " 'xcit_small_24_p16_224',\n",
      " 'xcit_small_24_p16_224_dist',\n",
      " 'xcit_small_24_p16_384_dist',\n",
      " 'xcit_tiny_12_p8_224',\n",
      " 'xcit_tiny_12_p8_224_dist',\n",
      " 'xcit_tiny_12_p8_384_dist',\n",
      " 'xcit_tiny_12_p16_224',\n",
      " 'xcit_tiny_12_p16_224_dist',\n",
      " 'xcit_tiny_12_p16_384_dist',\n",
      " 'xcit_tiny_24_p8_224',\n",
      " 'xcit_tiny_24_p8_224_dist',\n",
      " 'xcit_tiny_24_p8_384_dist',\n",
      " 'xcit_tiny_24_p16_224',\n",
      " 'xcit_tiny_24_p16_224_dist',\n",
      " 'xcit_tiny_24_p16_384_dist']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lXH5F_hA7uMl",
   "metadata": {
    "id": "lXH5F_hA7uMl"
   },
   "outputs": [],
   "source": [
    "path = '/home/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "FWntO1VD7L5u",
   "metadata": {
    "id": "FWntO1VD7L5u"
   },
   "outputs": [],
   "source": [
    "train_png = sorted(glob(path + 'open/train/*.png'))\n",
    "test_png = sorted(glob(path + 'open/test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "atSgPJRn-OCW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atSgPJRn-OCW",
    "outputId": "87b6f90b-5c1c-4a0e-de54-994458543687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4277, 2154)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_png), len(test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "xv0_rDVq7L5v",
   "metadata": {
    "id": "xv0_rDVq7L5v"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(path +\"open/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "iMhC0nPw7L5w",
   "metadata": {
    "id": "iMhC0nPw7L5w"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "zsmJA3E97L5x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsmJA3E97L5x",
    "outputId": "e0dc61fe-5617-42e8-c8b0-0e95b9f60656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4277/4277 [02:51<00:00, 24.99it/s]\n",
      "100%|██████████| 2154/2154 [01:25<00:00, 25.14it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "KA73Lku9A2N9",
   "metadata": {
    "id": "KA73Lku9A2N9"
   },
   "outputs": [],
   "source": [
    "np.save(path + 'train_imgs_384', np.array(train_imgs))\n",
    "np.save(path + 'test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "L6qBdX7nCp8L",
   "metadata": {
    "id": "L6qBdX7nCp8L"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.load(path + 'train_imgs_384.npy')\n",
    "test_imgs = np.load(path + 'test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sscGLiJKPy6H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sscGLiJKPy6H",
    "outputId": "976516c0-507d-458f-f0c4-6695751605d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평균 0.4330380901867049 0.4034575319032911 0.39415050509784405\n",
      "train 표준편차 0.1815717110252788 0.17403455556798705 0.16323395055036488\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"train 평균\",meanR, meanG, meanB)\n",
    "print(\"train 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "JwVIQCrUSCFE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwVIQCrUSCFE",
    "outputId": "293981ef-7f6a-4602-d208-5fd8473d5261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 평균 0.41825619520929724 0.3931011906330291 0.386631764639131\n",
      "test 표준편차 0.19505524270747931 0.19005280951759498 0.18053225852732663\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"test 평균\",meanR, meanG, meanB)\n",
    "print(\"test 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "VFXzojoo7L5y",
   "metadata": {
    "id": "VFXzojoo7L5y"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "                                     std = [0.181572, 0.174035, 0.163234]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
    "                                     std = [0.195055, 0.190053, 0.185323])\n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('densenet121', pretrained=True, num_classes=88)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('densenet121', pretrained=True, num_classes=88)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38qk8sGbYiO_",
   "metadata": {
    "id": "38qk8sGbYiO_"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "EnOG2n30-Dz5",
   "metadata": {
    "id": "EnOG2n30-Dz5"
   },
   "outputs": [],
   "source": [
    "def main(seed = 2022):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "main(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "lkNCkyG9RPzX",
   "metadata": {
    "id": "lkNCkyG9RPzX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 55s/5402s\n",
      "TRAIN    loss : 1.39541    f1 : 0.15106\n",
      "Val    loss : 0.79334    f1 : 0.15600\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 54s/5340s\n",
      "TRAIN    loss : 0.75454    f1 : 0.17218\n",
      "Val    loss : 0.60800    f1 : 0.21792\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 54s/5281s\n",
      "TRAIN    loss : 0.56252    f1 : 0.24395\n",
      "Val    loss : 0.45816    f1 : 0.29586\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 56s/5389s\n",
      "TRAIN    loss : 0.44076    f1 : 0.37636\n",
      "Val    loss : 0.39546    f1 : 0.37855\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 54s/5172s\n",
      "TRAIN    loss : 0.36290    f1 : 0.49377\n",
      "Val    loss : 0.32091    f1 : 0.42818\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 54s/5112s\n",
      "TRAIN    loss : 0.28459    f1 : 0.60304\n",
      "Val    loss : 0.24839    f1 : 0.58239\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 56s/5178s\n",
      "TRAIN    loss : 0.23807    f1 : 0.67986\n",
      "Val    loss : 0.21670    f1 : 0.59766\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 54s/4934s\n",
      "TRAIN    loss : 0.19462    f1 : 0.71985\n",
      "Val    loss : 0.17704    f1 : 0.68200\n",
      "epoch : 9/100    time : 54s/4932s\n",
      "TRAIN    loss : 0.15848    f1 : 0.81665\n",
      "Val    loss : 0.18504    f1 : 0.68177\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/100    time : 56s/5057s\n",
      "TRAIN    loss : 0.13955    f1 : 0.81983\n",
      "Val    loss : 0.18719    f1 : 0.69786\n",
      "epoch : 11/100    time : 54s/4778s\n",
      "TRAIN    loss : 0.11744    f1 : 0.86422\n",
      "Val    loss : 0.22226    f1 : 0.68456\n",
      "epoch : 12/100    time : 55s/4821s\n",
      "TRAIN    loss : 0.10736    f1 : 0.86519\n",
      "Val    loss : 0.24443    f1 : 0.67268\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/100    time : 55s/4747s\n",
      "TRAIN    loss : 0.09240    f1 : 0.89265\n",
      "Val    loss : 0.22225    f1 : 0.70735\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/100    time : 56s/4816s\n",
      "TRAIN    loss : 0.07887    f1 : 0.92460\n",
      "Val    loss : 0.16278    f1 : 0.76066\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/100    time : 55s/4650s\n",
      "TRAIN    loss : 0.06924    f1 : 0.93454\n",
      "Val    loss : 0.14682    f1 : 0.78979\n",
      "epoch : 16/100    time : 54s/4503s\n",
      "TRAIN    loss : 0.06542    f1 : 0.92591\n",
      "Val    loss : 0.19602    f1 : 0.75301\n",
      "epoch : 17/100    time : 56s/4618s\n",
      "TRAIN    loss : 0.05884    f1 : 0.94186\n",
      "Val    loss : 0.17710    f1 : 0.72937\n",
      "epoch : 18/100    time : 53s/4383s\n",
      "TRAIN    loss : 0.05491    f1 : 0.94046\n",
      "Val    loss : 0.21466    f1 : 0.70587\n",
      "epoch : 19/100    time : 54s/4362s\n",
      "TRAIN    loss : 0.05824    f1 : 0.95023\n",
      "Val    loss : 0.18010    f1 : 0.75623\n",
      "epoch : 20/100    time : 56s/4519s\n",
      "TRAIN    loss : 0.06590    f1 : 0.93208\n",
      "Val    loss : 0.16104    f1 : 0.71611\n",
      "epoch : 21/100    time : 54s/4288s\n",
      "TRAIN    loss : 0.04973    f1 : 0.94660\n",
      "Val    loss : 0.17164    f1 : 0.77016\n",
      "epoch : 22/100    time : 54s/4210s\n",
      "TRAIN    loss : 0.03508    f1 : 0.97039\n",
      "Val    loss : 0.19570    f1 : 0.74932\n",
      "epoch : 23/100    time : 54s/4149s\n",
      "TRAIN    loss : 0.05514    f1 : 0.94537\n",
      "Val    loss : 0.20916    f1 : 0.76643\n",
      "epoch : 24/100    time : 56s/4231s\n",
      "TRAIN    loss : 0.04687    f1 : 0.96274\n",
      "Val    loss : 0.17578    f1 : 0.76369\n",
      "-----------------SAVE:25 epoch----------------\n",
      "epoch : 25/100    time : 54s/4068s\n",
      "TRAIN    loss : 0.04003    f1 : 0.97017\n",
      "Val    loss : 0.30311    f1 : 0.79604\n",
      "epoch : 26/100    time : 54s/4014s\n",
      "TRAIN    loss : 0.03067    f1 : 0.96809\n",
      "Val    loss : 0.14960    f1 : 0.78502\n",
      "epoch : 27/100    time : 55s/4049s\n",
      "TRAIN    loss : 0.02994    f1 : 0.97116\n",
      "Val    loss : 0.18860    f1 : 0.76156\n",
      "epoch : 28/100    time : 53s/3792s\n",
      "TRAIN    loss : 0.03365    f1 : 0.96704\n",
      "Val    loss : 0.20871    f1 : 0.72498\n",
      "epoch : 29/100    time : 54s/3820s\n",
      "TRAIN    loss : 0.03426    f1 : 0.96581\n",
      "Val    loss : 0.16633    f1 : 0.78714\n",
      "epoch : 30/100    time : 56s/3920s\n",
      "TRAIN    loss : 0.02376    f1 : 0.98098\n",
      "Val    loss : 0.14575    f1 : 0.78646\n",
      "epoch : 31/100    time : 54s/3743s\n",
      "TRAIN    loss : 0.02794    f1 : 0.97248\n",
      "Val    loss : 0.21406    f1 : 0.69698\n",
      "epoch : 32/100    time : 54s/3647s\n",
      "TRAIN    loss : 0.02417    f1 : 0.98325\n",
      "Val    loss : 0.18844    f1 : 0.74873\n",
      "epoch : 33/100    time : 55s/3716s\n",
      "TRAIN    loss : 0.02788    f1 : 0.96840\n",
      "Val    loss : 0.27949    f1 : 0.78814\n",
      "-----------------SAVE:34 epoch----------------\n",
      "epoch : 34/100    time : 54s/3558s\n",
      "TRAIN    loss : 0.02938    f1 : 0.97451\n",
      "Val    loss : 0.17361    f1 : 0.80380\n",
      "epoch : 35/100    time : 54s/3530s\n",
      "TRAIN    loss : 0.03339    f1 : 0.95758\n",
      "Val    loss : 0.18835    f1 : 0.77287\n",
      "epoch : 36/100    time : 54s/3435s\n",
      "TRAIN    loss : 0.02492    f1 : 0.98410\n",
      "Val    loss : 0.18400    f1 : 0.75802\n",
      "epoch : 37/100    time : 56s/3525s\n",
      "TRAIN    loss : 0.03007    f1 : 0.97634\n",
      "Val    loss : 0.16127    f1 : 0.78362\n",
      "-----------------SAVE:38 epoch----------------\n",
      "epoch : 38/100    time : 54s/3344s\n",
      "TRAIN    loss : 0.02441    f1 : 0.97617\n",
      "Val    loss : 0.16426    f1 : 0.80811\n",
      "epoch : 39/100    time : 55s/3330s\n",
      "TRAIN    loss : 0.02326    f1 : 0.97335\n",
      "Val    loss : 0.14543    f1 : 0.77448\n",
      "epoch : 40/100    time : 56s/3340s\n",
      "TRAIN    loss : 0.04340    f1 : 0.94664\n",
      "Val    loss : 0.16630    f1 : 0.73863\n",
      "epoch : 41/100    time : 54s/3170s\n",
      "TRAIN    loss : 0.05492    f1 : 0.94298\n",
      "Val    loss : 0.14952    f1 : 0.79464\n",
      "epoch : 42/100    time : 54s/3158s\n",
      "TRAIN    loss : 0.02415    f1 : 0.97634\n",
      "Val    loss : 0.15757    f1 : 0.78748\n",
      "epoch : 43/100    time : 55s/3134s\n",
      "TRAIN    loss : 0.01725    f1 : 0.98137\n",
      "Val    loss : 0.15535    f1 : 0.77680\n",
      "epoch : 44/100    time : 55s/3081s\n",
      "TRAIN    loss : 0.01101    f1 : 0.99249\n",
      "Val    loss : 0.14608    f1 : 0.78239\n",
      "epoch : 45/100    time : 53s/2889s\n",
      "TRAIN    loss : 0.01738    f1 : 0.98420\n",
      "Val    loss : 0.16825    f1 : 0.78033\n",
      "epoch : 46/100    time : 54s/2913s\n",
      "TRAIN    loss : 0.03481    f1 : 0.96919\n",
      "Val    loss : 0.15627    f1 : 0.80769\n",
      "epoch : 47/100    time : 56s/2944s\n",
      "TRAIN    loss : 0.01702    f1 : 0.98327\n",
      "Val    loss : 0.17101    f1 : 0.76771\n",
      "epoch : 48/100    time : 53s/2780s\n",
      "TRAIN    loss : 0.01820    f1 : 0.98095\n",
      "Val    loss : 0.21681    f1 : 0.77450\n",
      "epoch : 49/100    time : 53s/2726s\n",
      "TRAIN    loss : 0.02049    f1 : 0.97727\n",
      "Val    loss : 0.18893    f1 : 0.78804\n",
      "epoch : 50/100    time : 55s/2736s\n",
      "TRAIN    loss : 0.01175    f1 : 0.99400\n",
      "Val    loss : 0.18570    f1 : 0.79217\n",
      "-----------------SAVE:51 epoch----------------\n",
      "epoch : 51/100    time : 55s/2687s\n",
      "TRAIN    loss : 0.00767    f1 : 0.99504\n",
      "Val    loss : 0.17619    f1 : 0.82447\n",
      "epoch : 52/100    time : 54s/2586s\n",
      "TRAIN    loss : 0.00699    f1 : 0.99517\n",
      "Val    loss : 0.23237    f1 : 0.77257\n",
      "epoch : 53/100    time : 56s/2639s\n",
      "TRAIN    loss : 0.03437    f1 : 0.97013\n",
      "Val    loss : 0.23119    f1 : 0.73286\n",
      "epoch : 54/100    time : 53s/2440s\n",
      "TRAIN    loss : 0.03105    f1 : 0.96809\n",
      "Val    loss : 0.29577    f1 : 0.70294\n",
      "epoch : 55/100    time : 54s/2429s\n",
      "TRAIN    loss : 0.03450    f1 : 0.96332\n",
      "Val    loss : 0.20448    f1 : 0.74513\n",
      "epoch : 56/100    time : 54s/2357s\n",
      "TRAIN    loss : 0.03241    f1 : 0.97419\n",
      "Val    loss : 0.19134    f1 : 0.79358\n",
      "epoch : 57/100    time : 59s/2520s\n",
      "TRAIN    loss : 0.02341    f1 : 0.98109\n",
      "Val    loss : 0.19131    f1 : 0.78827\n",
      "epoch : 58/100    time : 53s/2243s\n",
      "TRAIN    loss : 0.01027    f1 : 0.99307\n",
      "Val    loss : 0.19517    f1 : 0.75717\n",
      "epoch : 59/100    time : 55s/2244s\n",
      "TRAIN    loss : 0.00892    f1 : 0.99172\n",
      "Val    loss : 0.19578    f1 : 0.76483\n",
      "-----------------SAVE:60 epoch----------------\n",
      "epoch : 60/100    time : 56s/2231s\n",
      "TRAIN    loss : 0.00347    f1 : 0.99652\n",
      "Val    loss : 0.17072    f1 : 0.82471\n",
      "epoch : 61/100    time : 54s/2102s\n",
      "TRAIN    loss : 0.02325    f1 : 0.98173\n",
      "Val    loss : 0.22681    f1 : 0.81228\n",
      "epoch : 62/100    time : 54s/2050s\n",
      "TRAIN    loss : 0.01323    f1 : 0.98716\n",
      "Val    loss : 0.19745    f1 : 0.78889\n",
      "epoch : 63/100    time : 54s/2014s\n",
      "TRAIN    loss : 0.01258    f1 : 0.99170\n",
      "Val    loss : 0.24002    f1 : 0.75400\n",
      "epoch : 64/100    time : 53s/1920s\n",
      "TRAIN    loss : 0.02355    f1 : 0.97934\n",
      "Val    loss : 0.17622    f1 : 0.81729\n",
      "epoch : 65/100    time : 54s/1890s\n",
      "TRAIN    loss : 0.01782    f1 : 0.98498\n",
      "Val    loss : 0.21814    f1 : 0.77892\n",
      "epoch : 66/100    time : 56s/1905s\n",
      "TRAIN    loss : 0.01388    f1 : 0.98657\n",
      "Val    loss : 0.20073    f1 : 0.78202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 67/100    time : 54s/1773s\n",
      "TRAIN    loss : 0.01530    f1 : 0.97891\n",
      "Val    loss : 0.26976    f1 : 0.73426\n",
      "epoch : 68/100    time : 55s/1751s\n",
      "TRAIN    loss : 0.01211    f1 : 0.98675\n",
      "Val    loss : 0.20046    f1 : 0.79940\n",
      "epoch : 69/100    time : 53s/1644s\n",
      "TRAIN    loss : 0.00713    f1 : 0.99479\n",
      "Val    loss : 0.20705    f1 : 0.77863\n",
      "epoch : 70/100    time : 56s/1677s\n",
      "TRAIN    loss : 0.01943    f1 : 0.98352\n",
      "Val    loss : 0.22508    f1 : 0.77000\n",
      "epoch : 71/100    time : 54s/1576s\n",
      "TRAIN    loss : 0.02980    f1 : 0.98021\n",
      "Val    loss : 0.23807    f1 : 0.75186\n",
      "epoch : 72/100    time : 53s/1496s\n",
      "TRAIN    loss : 0.01711    f1 : 0.99013\n",
      "Val    loss : 0.25268    f1 : 0.75083\n",
      "epoch : 73/100    time : 56s/1515s\n",
      "TRAIN    loss : 0.03646    f1 : 0.96078\n",
      "Val    loss : 0.20223    f1 : 0.72375\n",
      "epoch : 74/100    time : 54s/1403s\n",
      "TRAIN    loss : 0.03837    f1 : 0.95584\n",
      "Val    loss : 0.16735    f1 : 0.79409\n",
      "epoch : 75/100    time : 54s/1340s\n",
      "TRAIN    loss : 0.01311    f1 : 0.99382\n",
      "Val    loss : 0.16362    f1 : 0.80372\n",
      "epoch : 76/100    time : 56s/1342s\n",
      "TRAIN    loss : 0.00610    f1 : 0.99381\n",
      "Val    loss : 0.15648    f1 : 0.81640\n",
      "epoch : 77/100    time : 54s/1240s\n",
      "TRAIN    loss : 0.00221    f1 : 1.00000\n",
      "Val    loss : 0.17124    f1 : 0.82237\n",
      "-----------------SAVE:78 epoch----------------\n",
      "epoch : 78/100    time : 54s/1187s\n",
      "TRAIN    loss : 0.00538    f1 : 0.99578\n",
      "Val    loss : 0.18640    f1 : 0.82800\n",
      "epoch : 79/100    time : 54s/1142s\n",
      "TRAIN    loss : 0.00661    f1 : 0.99146\n",
      "Val    loss : 0.19449    f1 : 0.78272\n",
      "epoch : 80/100    time : 55s/1105s\n",
      "TRAIN    loss : 0.00809    f1 : 0.99321\n",
      "Val    loss : 0.18317    f1 : 0.77236\n",
      "epoch : 81/100    time : 54s/1021s\n",
      "TRAIN    loss : 0.01812    f1 : 0.98162\n",
      "Val    loss : 0.21730    f1 : 0.76295\n",
      "epoch : 82/100    time : 54s/974s\n",
      "TRAIN    loss : 0.01693    f1 : 0.99211\n",
      "Val    loss : 0.28673    f1 : 0.73411\n",
      "epoch : 83/100    time : 55s/929s\n",
      "TRAIN    loss : 0.01998    f1 : 0.98192\n",
      "Val    loss : 0.20893    f1 : 0.76213\n",
      "epoch : 84/100    time : 54s/857s\n",
      "TRAIN    loss : 0.02281    f1 : 0.97553\n",
      "Val    loss : 0.19805    f1 : 0.74640\n",
      "epoch : 85/100    time : 54s/804s\n",
      "TRAIN    loss : 0.01145    f1 : 0.98815\n",
      "Val    loss : 0.16168    f1 : 0.78295\n",
      "epoch : 86/100    time : 55s/775s\n",
      "TRAIN    loss : 0.01553    f1 : 0.98323\n",
      "Val    loss : 0.22684    f1 : 0.78608\n",
      "epoch : 87/100    time : 54s/708s\n",
      "TRAIN    loss : 0.01324    f1 : 0.98700\n",
      "Val    loss : 0.21080    f1 : 0.77943\n",
      "epoch : 88/100    time : 54s/643s\n",
      "TRAIN    loss : 0.01388    f1 : 0.98656\n",
      "Val    loss : 0.22134    f1 : 0.79059\n",
      "epoch : 89/100    time : 54s/590s\n",
      "TRAIN    loss : 0.02336    f1 : 0.97573\n",
      "Val    loss : 0.19708    f1 : 0.75649\n",
      "epoch : 90/100    time : 56s/556s\n",
      "TRAIN    loss : 0.01709    f1 : 0.98632\n",
      "Val    loss : 0.19442    f1 : 0.78362\n",
      "epoch : 91/100    time : 53s/480s\n",
      "TRAIN    loss : 0.00431    f1 : 0.99754\n",
      "Val    loss : 0.20205    f1 : 0.78214\n",
      "epoch : 92/100    time : 55s/436s\n",
      "TRAIN    loss : 0.01325    f1 : 0.98505\n",
      "Val    loss : 0.25933    f1 : 0.74330\n",
      "epoch : 93/100    time : 55s/388s\n",
      "TRAIN    loss : 0.00958    f1 : 0.99259\n",
      "Val    loss : 0.19874    f1 : 0.78977\n",
      "epoch : 94/100    time : 53s/320s\n",
      "TRAIN    loss : 0.00802    f1 : 0.99052\n",
      "Val    loss : 0.22896    f1 : 0.72344\n",
      "epoch : 95/100    time : 54s/271s\n",
      "TRAIN    loss : 0.02257    f1 : 0.97697\n",
      "Val    loss : 0.24071    f1 : 0.72532\n",
      "epoch : 96/100    time : 56s/225s\n",
      "TRAIN    loss : 0.00640    f1 : 0.99786\n",
      "Val    loss : 0.24646    f1 : 0.80775\n",
      "epoch : 97/100    time : 54s/161s\n",
      "TRAIN    loss : 0.00484    f1 : 0.99636\n",
      "Val    loss : 0.24600    f1 : 0.76188\n",
      "epoch : 98/100    time : 54s/107s\n",
      "TRAIN    loss : 0.02480    f1 : 0.98107\n",
      "Val    loss : 0.17842    f1 : 0.78208\n",
      "----------fold_1 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 57s/5673s\n",
      "TRAIN    loss : 1.37268    f1 : 0.14858\n",
      "Val    loss : 0.76259    f1 : 0.15627\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 53s/5200s\n",
      "TRAIN    loss : 0.71162    f1 : 0.18754\n",
      "Val    loss : 0.60151    f1 : 0.22629\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 54s/5196s\n",
      "TRAIN    loss : 0.54261    f1 : 0.27273\n",
      "Val    loss : 0.48976    f1 : 0.31651\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 53s/5115s\n",
      "TRAIN    loss : 0.42564    f1 : 0.37381\n",
      "Val    loss : 0.37020    f1 : 0.39247\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 55s/5183s\n",
      "TRAIN    loss : 0.35723    f1 : 0.50103\n",
      "Val    loss : 0.33515    f1 : 0.50643\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 53s/5021s\n",
      "TRAIN    loss : 0.28996    f1 : 0.58534\n",
      "Val    loss : 0.39169    f1 : 0.54023\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 53s/4931s\n",
      "TRAIN    loss : 0.23354    f1 : 0.65458\n",
      "Val    loss : 0.25118    f1 : 0.54465\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 55s/5059s\n",
      "TRAIN    loss : 0.19332    f1 : 0.73026\n",
      "Val    loss : 0.20517    f1 : 0.69374\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 54s/4883s\n",
      "TRAIN    loss : 0.16240    f1 : 0.80750\n",
      "Val    loss : 0.21088    f1 : 0.74650\n",
      "epoch : 10/100    time : 52s/4710s\n",
      "TRAIN    loss : 0.15224    f1 : 0.80693\n",
      "Val    loss : 0.17903    f1 : 0.73152\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 53s/4750s\n",
      "TRAIN    loss : 0.11578    f1 : 0.84881\n",
      "Val    loss : 0.16098    f1 : 0.76046\n",
      "epoch : 12/100    time : 55s/4827s\n",
      "TRAIN    loss : 0.10320    f1 : 0.88697\n",
      "Val    loss : 0.15806    f1 : 0.74002\n",
      "epoch : 13/100    time : 54s/4666s\n",
      "TRAIN    loss : 0.10018    f1 : 0.89269\n",
      "Val    loss : 0.25933    f1 : 0.74110\n",
      "epoch : 14/100    time : 53s/4526s\n",
      "TRAIN    loss : 0.08451    f1 : 0.90747\n",
      "Val    loss : 0.21417    f1 : 0.69661\n",
      "epoch : 15/100    time : 54s/4568s\n",
      "TRAIN    loss : 0.08011    f1 : 0.90773\n",
      "Val    loss : 0.25270    f1 : 0.72289\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/100    time : 54s/4522s\n",
      "TRAIN    loss : 0.06516    f1 : 0.92189\n",
      "Val    loss : 0.16689    f1 : 0.76226\n",
      "epoch : 17/100    time : 52s/4351s\n",
      "TRAIN    loss : 0.06068    f1 : 0.94993\n",
      "Val    loss : 0.19166    f1 : 0.75907\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/100    time : 57s/4683s\n",
      "TRAIN    loss : 0.05642    f1 : 0.93784\n",
      "Val    loss : 0.17358    f1 : 0.77129\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/100    time : 53s/4280s\n",
      "TRAIN    loss : 0.04698    f1 : 0.96058\n",
      "Val    loss : 0.17113    f1 : 0.79400\n",
      "epoch : 20/100    time : 53s/4214s\n",
      "TRAIN    loss : 0.04445    f1 : 0.95492\n",
      "Val    loss : 0.19154    f1 : 0.76289\n",
      "epoch : 21/100    time : 52s/4142s\n",
      "TRAIN    loss : 0.04929    f1 : 0.95171\n",
      "Val    loss : 0.25063    f1 : 0.72249\n",
      "epoch : 22/100    time : 54s/4199s\n",
      "TRAIN    loss : 0.04822    f1 : 0.94858\n",
      "Val    loss : 0.16319    f1 : 0.78034\n",
      "epoch : 23/100    time : 52s/4001s\n",
      "TRAIN    loss : 0.03046    f1 : 0.96984\n",
      "Val    loss : 0.17595    f1 : 0.72758\n",
      "epoch : 24/100    time : 52s/3945s\n",
      "TRAIN    loss : 0.04343    f1 : 0.96357\n",
      "Val    loss : 0.25380    f1 : 0.75020\n",
      "epoch : 25/100    time : 54s/4079s\n",
      "TRAIN    loss : 0.04454    f1 : 0.96174\n",
      "Val    loss : 0.33874    f1 : 0.76727\n",
      "epoch : 26/100    time : 53s/3901s\n",
      "TRAIN    loss : 0.04714    f1 : 0.95311\n",
      "Val    loss : 0.16264    f1 : 0.75418\n",
      "-----------------SAVE:27 epoch----------------\n",
      "epoch : 27/100    time : 54s/3948s\n",
      "TRAIN    loss : 0.01704    f1 : 0.98395\n",
      "Val    loss : 0.15255    f1 : 0.81341\n",
      "epoch : 28/100    time : 55s/3955s\n",
      "TRAIN    loss : 0.03387    f1 : 0.96772\n",
      "Val    loss : 0.15469    f1 : 0.80986\n",
      "epoch : 29/100    time : 52s/3719s\n",
      "TRAIN    loss : 0.04671    f1 : 0.95899\n",
      "Val    loss : 0.19786    f1 : 0.80595\n",
      "epoch : 30/100    time : 52s/3667s\n",
      "TRAIN    loss : 0.02781    f1 : 0.97419\n",
      "Val    loss : 0.17454    f1 : 0.75566\n",
      "epoch : 31/100    time : 53s/3647s\n",
      "TRAIN    loss : 0.02714    f1 : 0.97363\n",
      "Val    loss : 0.18970    f1 : 0.76648\n",
      "epoch : 32/100    time : 54s/3682s\n",
      "TRAIN    loss : 0.03641    f1 : 0.97154\n",
      "Val    loss : 0.22527    f1 : 0.77800\n",
      "epoch : 33/100    time : 52s/3506s\n",
      "TRAIN    loss : 0.03472    f1 : 0.96604\n",
      "Val    loss : 0.20942    f1 : 0.76610\n",
      "epoch : 34/100    time : 53s/3481s\n",
      "TRAIN    loss : 0.02438    f1 : 0.97814\n",
      "Val    loss : 0.22143    f1 : 0.79837\n",
      "epoch : 35/100    time : 54s/3512s\n",
      "TRAIN    loss : 0.01918    f1 : 0.98105\n",
      "Val    loss : 0.22882    f1 : 0.74328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 36/100    time : 53s/3422s\n",
      "TRAIN    loss : 0.01708    f1 : 0.98892\n",
      "Val    loss : 0.18421    f1 : 0.81015\n",
      "epoch : 37/100    time : 54s/3411s\n",
      "TRAIN    loss : 0.01789    f1 : 0.97784\n",
      "Val    loss : 0.17034    f1 : 0.78908\n",
      "epoch : 38/100    time : 57s/3527s\n",
      "TRAIN    loss : 0.02513    f1 : 0.97257\n",
      "Val    loss : 0.18125    f1 : 0.79018\n",
      "epoch : 39/100    time : 52s/3196s\n",
      "TRAIN    loss : 0.03360    f1 : 0.97592\n",
      "Val    loss : 0.27344    f1 : 0.72489\n",
      "-----------------SAVE:40 epoch----------------\n",
      "epoch : 40/100    time : 53s/3184s\n",
      "TRAIN    loss : 0.02829    f1 : 0.97625\n",
      "Val    loss : 0.19035    f1 : 0.81585\n",
      "-----------------SAVE:41 epoch----------------\n",
      "epoch : 41/100    time : 53s/3107s\n",
      "TRAIN    loss : 0.01630    f1 : 0.98812\n",
      "Val    loss : 0.22086    f1 : 0.81938\n",
      "-----------------SAVE:42 epoch----------------\n",
      "epoch : 42/100    time : 55s/3193s\n",
      "TRAIN    loss : 0.03724    f1 : 0.95699\n",
      "Val    loss : 0.16691    f1 : 0.83111\n",
      "epoch : 43/100    time : 53s/3014s\n",
      "TRAIN    loss : 0.01345    f1 : 0.99140\n",
      "Val    loss : 0.19423    f1 : 0.82831\n",
      "epoch : 44/100    time : 53s/2979s\n",
      "TRAIN    loss : 0.02517    f1 : 0.97817\n",
      "Val    loss : 0.15184    f1 : 0.80017\n",
      "epoch : 45/100    time : 55s/2998s\n",
      "TRAIN    loss : 0.02650    f1 : 0.97279\n",
      "Val    loss : 0.19790    f1 : 0.75166\n",
      "epoch : 46/100    time : 53s/2857s\n",
      "TRAIN    loss : 0.03470    f1 : 0.97198\n",
      "Val    loss : 0.21284    f1 : 0.81008\n",
      "epoch : 47/100    time : 53s/2823s\n",
      "TRAIN    loss : 0.01834    f1 : 0.97925\n",
      "Val    loss : 0.21720    f1 : 0.77384\n",
      "epoch : 48/100    time : 53s/2750s\n",
      "TRAIN    loss : 0.01708    f1 : 0.98614\n",
      "Val    loss : 0.18469    f1 : 0.81478\n",
      "-----------------SAVE:49 epoch----------------\n",
      "epoch : 49/100    time : 55s/2797s\n",
      "TRAIN    loss : 0.00567    f1 : 0.99733\n",
      "Val    loss : 0.18912    f1 : 0.84117\n",
      "epoch : 50/100    time : 53s/2645s\n",
      "TRAIN    loss : 0.01490    f1 : 0.98484\n",
      "Val    loss : 0.39171    f1 : 0.75716\n",
      "epoch : 51/100    time : 53s/2595s\n",
      "TRAIN    loss : 0.02220    f1 : 0.98060\n",
      "Val    loss : 0.28828    f1 : 0.72576\n",
      "epoch : 52/100    time : 54s/2598s\n",
      "TRAIN    loss : 0.02655    f1 : 0.98299\n",
      "Val    loss : 0.23104    f1 : 0.77339\n",
      "epoch : 53/100    time : 52s/2467s\n",
      "TRAIN    loss : 0.03751    f1 : 0.96905\n",
      "Val    loss : 0.20261    f1 : 0.77895\n",
      "epoch : 54/100    time : 53s/2425s\n",
      "TRAIN    loss : 0.01059    f1 : 0.99360\n",
      "Val    loss : 0.16548    f1 : 0.81619\n",
      "epoch : 55/100    time : 55s/2453s\n",
      "TRAIN    loss : 0.01544    f1 : 0.97798\n",
      "Val    loss : 0.16242    f1 : 0.80047\n",
      "epoch : 56/100    time : 53s/2329s\n",
      "TRAIN    loss : 0.01340    f1 : 0.98240\n",
      "Val    loss : 0.15620    f1 : 0.81729\n",
      "epoch : 57/100    time : 53s/2271s\n",
      "TRAIN    loss : 0.01643    f1 : 0.98117\n",
      "Val    loss : 0.19157    f1 : 0.79828\n",
      "epoch : 58/100    time : 52s/2203s\n",
      "TRAIN    loss : 0.00838    f1 : 0.99049\n",
      "Val    loss : 0.16896    f1 : 0.80028\n",
      "epoch : 59/100    time : 54s/2226s\n",
      "TRAIN    loss : 0.00698    f1 : 0.99290\n",
      "Val    loss : 0.15364    f1 : 0.81795\n",
      "epoch : 60/100    time : 53s/2103s\n",
      "TRAIN    loss : 0.00202    f1 : 1.00000\n",
      "Val    loss : 0.18316    f1 : 0.78961\n",
      "epoch : 61/100    time : 53s/2074s\n",
      "TRAIN    loss : 0.01349    f1 : 0.99059\n",
      "Val    loss : 0.18755    f1 : 0.77239\n",
      "epoch : 62/100    time : 54s/2052s\n",
      "TRAIN    loss : 0.02008    f1 : 0.96940\n",
      "Val    loss : 0.38644    f1 : 0.71996\n",
      "epoch : 63/100    time : 53s/1962s\n",
      "TRAIN    loss : 0.02002    f1 : 0.98369\n",
      "Val    loss : 0.22580    f1 : 0.74554\n",
      "epoch : 64/100    time : 53s/1910s\n",
      "TRAIN    loss : 0.02959    f1 : 0.96631\n",
      "Val    loss : 0.28922    f1 : 0.75380\n",
      "epoch : 65/100    time : 56s/1949s\n",
      "TRAIN    loss : 0.01935    f1 : 0.98343\n",
      "Val    loss : 0.24636    f1 : 0.77598\n",
      "epoch : 66/100    time : 53s/1790s\n",
      "TRAIN    loss : 0.02488    f1 : 0.97927\n",
      "Val    loss : 0.25907    f1 : 0.77551\n",
      "epoch : 67/100    time : 53s/1759s\n",
      "TRAIN    loss : 0.03178    f1 : 0.97069\n",
      "Val    loss : 0.25956    f1 : 0.76420\n",
      "epoch : 68/100    time : 53s/1707s\n",
      "TRAIN    loss : 0.02491    f1 : 0.98145\n",
      "Val    loss : 0.22283    f1 : 0.79126\n",
      "epoch : 69/100    time : 54s/1670s\n",
      "TRAIN    loss : 0.02043    f1 : 0.98563\n",
      "Val    loss : 0.23743    f1 : 0.79141\n",
      "----------fold_2 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 55s/5474s\n",
      "TRAIN    loss : 1.42384    f1 : 0.14878\n",
      "Val    loss : 0.83950    f1 : 0.15618\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 54s/5289s\n",
      "TRAIN    loss : 0.73889    f1 : 0.18655\n",
      "Val    loss : 0.61012    f1 : 0.21362\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 56s/5389s\n",
      "TRAIN    loss : 0.58855    f1 : 0.23439\n",
      "Val    loss : 0.47242    f1 : 0.28789\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 54s/5203s\n",
      "TRAIN    loss : 0.45885    f1 : 0.35249\n",
      "Val    loss : 0.40968    f1 : 0.35306\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 55s/5204s\n",
      "TRAIN    loss : 0.37704    f1 : 0.47756\n",
      "Val    loss : 0.33116    f1 : 0.50187\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 57s/5340s\n",
      "TRAIN    loss : 0.31187    f1 : 0.57355\n",
      "Val    loss : 0.27321    f1 : 0.58251\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 54s/5051s\n",
      "TRAIN    loss : 0.24765    f1 : 0.66130\n",
      "Val    loss : 0.22910    f1 : 0.60765\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 54s/4995s\n",
      "TRAIN    loss : 0.20359    f1 : 0.71117\n",
      "Val    loss : 0.24114    f1 : 0.61022\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 55s/4963s\n",
      "TRAIN    loss : 0.18624    f1 : 0.73960\n",
      "Val    loss : 0.19512    f1 : 0.70007\n",
      "epoch : 10/100    time : 56s/5019s\n",
      "TRAIN    loss : 0.15461    f1 : 0.81530\n",
      "Val    loss : 0.23244    f1 : 0.68874\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 55s/4903s\n",
      "TRAIN    loss : 0.12315    f1 : 0.86703\n",
      "Val    loss : 0.16284    f1 : 0.71281\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 54s/4780s\n",
      "TRAIN    loss : 0.10644    f1 : 0.85773\n",
      "Val    loss : 0.18937    f1 : 0.79369\n",
      "epoch : 13/100    time : 56s/4849s\n",
      "TRAIN    loss : 0.09060    f1 : 0.89400\n",
      "Val    loss : 0.17651    f1 : 0.73518\n",
      "epoch : 14/100    time : 54s/4667s\n",
      "TRAIN    loss : 0.08287    f1 : 0.89476\n",
      "Val    loss : 0.16690    f1 : 0.76486\n",
      "epoch : 15/100    time : 54s/4549s\n",
      "TRAIN    loss : 0.07978    f1 : 0.90324\n",
      "Val    loss : 0.15858    f1 : 0.75539\n",
      "epoch : 16/100    time : 56s/4703s\n",
      "TRAIN    loss : 0.06497    f1 : 0.93263\n",
      "Val    loss : 0.14714    f1 : 0.76584\n",
      "epoch : 17/100    time : 53s/4439s\n",
      "TRAIN    loss : 0.04695    f1 : 0.95515\n",
      "Val    loss : 0.15687    f1 : 0.77887\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/100    time : 54s/4421s\n",
      "TRAIN    loss : 0.05289    f1 : 0.94444\n",
      "Val    loss : 0.18424    f1 : 0.80484\n",
      "epoch : 19/100    time : 56s/4547s\n",
      "TRAIN    loss : 0.04863    f1 : 0.95200\n",
      "Val    loss : 0.14922    f1 : 0.79452\n",
      "epoch : 20/100    time : 54s/4288s\n",
      "TRAIN    loss : 0.03456    f1 : 0.96086\n",
      "Val    loss : 0.14219    f1 : 0.80414\n",
      "epoch : 21/100    time : 53s/4176s\n",
      "TRAIN    loss : 0.03550    f1 : 0.97312\n",
      "Val    loss : 0.26331    f1 : 0.74830\n",
      "epoch : 22/100    time : 57s/4416s\n",
      "TRAIN    loss : 0.05414    f1 : 0.93247\n",
      "Val    loss : 0.15714    f1 : 0.76377\n",
      "epoch : 23/100    time : 55s/4212s\n",
      "TRAIN    loss : 0.03804    f1 : 0.97264\n",
      "Val    loss : 0.16046    f1 : 0.77936\n",
      "epoch : 24/100    time : 53s/4063s\n",
      "TRAIN    loss : 0.04217    f1 : 0.95536\n",
      "Val    loss : 0.15500    f1 : 0.77359\n",
      "epoch : 25/100    time : 54s/4087s\n",
      "TRAIN    loss : 0.04126    f1 : 0.95667\n",
      "Val    loss : 0.18381    f1 : 0.76714\n",
      "-----------------SAVE:26 epoch----------------\n",
      "epoch : 26/100    time : 56s/4149s\n",
      "TRAIN    loss : 0.02708    f1 : 0.98115\n",
      "Val    loss : 0.13566    f1 : 0.80534\n",
      "-----------------SAVE:27 epoch----------------\n",
      "epoch : 27/100    time : 55s/4015s\n",
      "TRAIN    loss : 0.04513    f1 : 0.96455\n",
      "Val    loss : 0.12666    f1 : 0.81852\n",
      "epoch : 28/100    time : 53s/3832s\n",
      "TRAIN    loss : 0.02066    f1 : 0.98398\n",
      "Val    loss : 0.16972    f1 : 0.80637\n",
      "epoch : 29/100    time : 56s/3988s\n",
      "TRAIN    loss : 0.02781    f1 : 0.97875\n",
      "Val    loss : 0.15782    f1 : 0.81559\n",
      "-----------------SAVE:30 epoch----------------\n",
      "epoch : 30/100    time : 54s/3788s\n",
      "TRAIN    loss : 0.03210    f1 : 0.98035\n",
      "Val    loss : 0.14117    f1 : 0.83600\n",
      "epoch : 31/100    time : 54s/3730s\n",
      "TRAIN    loss : 0.03392    f1 : 0.96563\n",
      "Val    loss : 0.17922    f1 : 0.78695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 32/100    time : 54s/3654s\n",
      "TRAIN    loss : 0.05065    f1 : 0.95382\n",
      "Val    loss : 0.23538    f1 : 0.74777\n",
      "epoch : 33/100    time : 56s/3731s\n",
      "TRAIN    loss : 0.03524    f1 : 0.95800\n",
      "Val    loss : 0.16378    f1 : 0.81472\n",
      "epoch : 34/100    time : 53s/3475s\n",
      "TRAIN    loss : 0.03060    f1 : 0.96301\n",
      "Val    loss : 0.42426    f1 : 0.72920\n",
      "epoch : 35/100    time : 54s/3508s\n",
      "TRAIN    loss : 0.03032    f1 : 0.97879\n",
      "Val    loss : 0.18545    f1 : 0.78227\n",
      "epoch : 36/100    time : 56s/3557s\n",
      "TRAIN    loss : 0.03316    f1 : 0.97386\n",
      "Val    loss : 0.17114    f1 : 0.78257\n",
      "epoch : 37/100    time : 54s/3396s\n",
      "TRAIN    loss : 0.01375    f1 : 0.99157\n",
      "Val    loss : 0.14901    f1 : 0.83542\n",
      "epoch : 38/100    time : 54s/3366s\n",
      "TRAIN    loss : 0.00764    f1 : 0.99407\n",
      "Val    loss : 0.14495    f1 : 0.80874\n",
      "epoch : 39/100    time : 55s/3373s\n",
      "TRAIN    loss : 0.00960    f1 : 0.99058\n",
      "Val    loss : 0.16501    f1 : 0.81905\n",
      "epoch : 40/100    time : 55s/3287s\n",
      "TRAIN    loss : 0.01359    f1 : 0.98940\n",
      "Val    loss : 0.14813    f1 : 0.79789\n",
      "epoch : 41/100    time : 54s/3204s\n",
      "TRAIN    loss : 0.04192    f1 : 0.96282\n",
      "Val    loss : 0.17840    f1 : 0.78030\n",
      "epoch : 42/100    time : 53s/3096s\n",
      "TRAIN    loss : 0.03949    f1 : 0.95699\n",
      "Val    loss : 0.18183    f1 : 0.77846\n",
      "epoch : 43/100    time : 55s/3145s\n",
      "TRAIN    loss : 0.03390    f1 : 0.95439\n",
      "Val    loss : 0.16408    f1 : 0.77504\n",
      "epoch : 44/100    time : 54s/3036s\n",
      "TRAIN    loss : 0.01766    f1 : 0.98828\n",
      "Val    loss : 0.16515    f1 : 0.79152\n",
      "epoch : 45/100    time : 54s/2967s\n",
      "TRAIN    loss : 0.03830    f1 : 0.97127\n",
      "Val    loss : 0.24851    f1 : 0.74926\n",
      "epoch : 46/100    time : 56s/2997s\n",
      "TRAIN    loss : 0.02809    f1 : 0.97900\n",
      "Val    loss : 0.16610    f1 : 0.80028\n",
      "epoch : 47/100    time : 54s/2885s\n",
      "TRAIN    loss : 0.01659    f1 : 0.98698\n",
      "Val    loss : 0.18474    f1 : 0.82219\n",
      "epoch : 48/100    time : 54s/2808s\n",
      "TRAIN    loss : 0.01453    f1 : 0.98748\n",
      "Val    loss : 0.15948    f1 : 0.82789\n",
      "epoch : 49/100    time : 56s/2838s\n",
      "TRAIN    loss : 0.01042    f1 : 0.99058\n",
      "Val    loss : 1.09711    f1 : 0.79255\n",
      "epoch : 50/100    time : 54s/2713s\n",
      "TRAIN    loss : 0.00918    f1 : 0.99249\n",
      "Val    loss : 0.25875    f1 : 0.83069\n",
      "----------fold_3 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 55s/5434s\n",
      "TRAIN    loss : 1.39974    f1 : 0.14957\n",
      "Val    loss : 0.78981    f1 : 0.16782\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 56s/5496s\n",
      "TRAIN    loss : 0.74024    f1 : 0.17299\n",
      "Val    loss : 0.56690    f1 : 0.20442\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 55s/5311s\n",
      "TRAIN    loss : 0.57450    f1 : 0.25608\n",
      "Val    loss : 0.47838    f1 : 0.29887\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 55s/5306s\n",
      "TRAIN    loss : 0.46485    f1 : 0.37043\n",
      "Val    loss : 0.39273    f1 : 0.39570\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 56s/5326s\n",
      "TRAIN    loss : 0.38395    f1 : 0.46548\n",
      "Val    loss : 0.33535    f1 : 0.49828\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 56s/5286s\n",
      "TRAIN    loss : 0.31591    f1 : 0.56466\n",
      "Val    loss : 0.31046    f1 : 0.51987\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 55s/5098s\n",
      "TRAIN    loss : 0.26310    f1 : 0.63016\n",
      "Val    loss : 0.26993    f1 : 0.63082\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 54s/4987s\n",
      "TRAIN    loss : 0.21481    f1 : 0.70629\n",
      "Val    loss : 0.21368    f1 : 0.71452\n",
      "epoch : 9/100    time : 57s/5142s\n",
      "TRAIN    loss : 0.18229    f1 : 0.76919\n",
      "Val    loss : 0.20909    f1 : 0.70143\n",
      "epoch : 10/100    time : 54s/4897s\n",
      "TRAIN    loss : 0.15054    f1 : 0.81683\n",
      "Val    loss : 0.22915    f1 : 0.67491\n",
      "epoch : 11/100    time : 55s/4875s\n",
      "TRAIN    loss : 0.13935    f1 : 0.82969\n",
      "Val    loss : 0.19889    f1 : 0.69954\n",
      "epoch : 12/100    time : 56s/4958s\n",
      "TRAIN    loss : 0.09911    f1 : 0.88955\n",
      "Val    loss : 0.21353    f1 : 0.69558\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/100    time : 54s/4725s\n",
      "TRAIN    loss : 0.10470    f1 : 0.86424\n",
      "Val    loss : 0.19686    f1 : 0.72216\n",
      "epoch : 14/100    time : 55s/4748s\n",
      "TRAIN    loss : 0.08211    f1 : 0.91666\n",
      "Val    loss : 0.18852    f1 : 0.72128\n",
      "epoch : 15/100    time : 55s/4705s\n",
      "TRAIN    loss : 0.07191    f1 : 0.90478\n",
      "Val    loss : 0.22201    f1 : 0.71932\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/100    time : 54s/4575s\n",
      "TRAIN    loss : 0.06684    f1 : 0.92715\n",
      "Val    loss : 0.18127    f1 : 0.77528\n",
      "epoch : 17/100    time : 54s/4486s\n",
      "TRAIN    loss : 0.06608    f1 : 0.93317\n",
      "Val    loss : 0.20061    f1 : 0.71233\n",
      "epoch : 18/100    time : 54s/4461s\n",
      "TRAIN    loss : 0.07032    f1 : 0.92912\n",
      "Val    loss : 0.19000    f1 : 0.75913\n",
      "epoch : 19/100    time : 56s/4516s\n",
      "TRAIN    loss : 0.05619    f1 : 0.95509\n",
      "Val    loss : 0.17245    f1 : 0.76338\n",
      "epoch : 20/100    time : 54s/4347s\n",
      "TRAIN    loss : 0.04563    f1 : 0.95392\n",
      "Val    loss : 0.18630    f1 : 0.75929\n",
      "epoch : 21/100    time : 54s/4303s\n",
      "TRAIN    loss : 0.03751    f1 : 0.95616\n",
      "Val    loss : 0.20571    f1 : 0.71355\n",
      "-----------------SAVE:22 epoch----------------\n",
      "epoch : 22/100    time : 56s/4391s\n",
      "TRAIN    loss : 0.03630    f1 : 0.96801\n",
      "Val    loss : 0.19073    f1 : 0.79096\n",
      "epoch : 23/100    time : 55s/4209s\n",
      "TRAIN    loss : 0.04486    f1 : 0.96338\n",
      "Val    loss : 0.26993    f1 : 0.72324\n",
      "-----------------SAVE:24 epoch----------------\n",
      "epoch : 24/100    time : 54s/4124s\n",
      "TRAIN    loss : 0.04202    f1 : 0.95072\n",
      "Val    loss : 0.17293    f1 : 0.80657\n",
      "epoch : 25/100    time : 57s/4265s\n",
      "TRAIN    loss : 0.04531    f1 : 0.96297\n",
      "Val    loss : 0.21084    f1 : 0.75799\n",
      "epoch : 26/100    time : 54s/3999s\n",
      "TRAIN    loss : 0.03663    f1 : 0.96422\n",
      "Val    loss : 0.19657    f1 : 0.73673\n",
      "epoch : 27/100    time : 54s/3922s\n",
      "TRAIN    loss : 0.03771    f1 : 0.97084\n",
      "Val    loss : 0.20732    f1 : 0.78768\n",
      "epoch : 28/100    time : 55s/3961s\n",
      "TRAIN    loss : 0.02665    f1 : 0.97364\n",
      "Val    loss : 0.21011    f1 : 0.76744\n",
      "epoch : 29/100    time : 56s/3974s\n",
      "TRAIN    loss : 0.03261    f1 : 0.97185\n",
      "Val    loss : 0.23534    f1 : 0.77617\n",
      "epoch : 30/100    time : 55s/3838s\n",
      "TRAIN    loss : 0.04296    f1 : 0.96297\n",
      "Val    loss : 0.24672    f1 : 0.75178\n",
      "epoch : 31/100    time : 55s/3782s\n",
      "TRAIN    loss : 0.04212    f1 : 0.96441\n",
      "Val    loss : 0.19595    f1 : 0.73279\n",
      "-----------------SAVE:32 epoch----------------\n",
      "epoch : 32/100    time : 55s/3774s\n",
      "TRAIN    loss : 0.01937    f1 : 0.98942\n",
      "Val    loss : 0.17170    f1 : 0.81585\n",
      "epoch : 33/100    time : 54s/3618s\n",
      "TRAIN    loss : 0.03274    f1 : 0.96977\n",
      "Val    loss : 0.20813    f1 : 0.79713\n",
      "epoch : 34/100    time : 54s/3556s\n",
      "TRAIN    loss : 0.03139    f1 : 0.95852\n",
      "Val    loss : 0.19896    f1 : 0.76672\n",
      "epoch : 35/100    time : 56s/3656s\n",
      "TRAIN    loss : 0.02762    f1 : 0.96877\n",
      "Val    loss : 0.20502    f1 : 0.77899\n",
      "epoch : 36/100    time : 54s/3454s\n",
      "TRAIN    loss : 0.02831    f1 : 0.97384\n",
      "Val    loss : 0.25789    f1 : 0.73237\n",
      "epoch : 37/100    time : 54s/3427s\n",
      "TRAIN    loss : 0.02273    f1 : 0.97417\n",
      "Val    loss : 0.21191    f1 : 0.79852\n",
      "epoch : 38/100    time : 57s/3543s\n",
      "TRAIN    loss : 0.00991    f1 : 0.99203\n",
      "Val    loss : 0.20491    f1 : 0.81119\n",
      "epoch : 39/100    time : 54s/3276s\n",
      "TRAIN    loss : 0.01722    f1 : 0.99115\n",
      "Val    loss : 0.20892    f1 : 0.78251\n",
      "epoch : 40/100    time : 56s/3334s\n",
      "TRAIN    loss : 0.04073    f1 : 0.96012\n",
      "Val    loss : 0.26906    f1 : 0.76925\n",
      "epoch : 41/100    time : 54s/3172s\n",
      "TRAIN    loss : 0.02884    f1 : 0.96371\n",
      "Val    loss : 0.27548    f1 : 0.73799\n",
      "epoch : 42/100    time : 56s/3237s\n",
      "TRAIN    loss : 0.01869    f1 : 0.97611\n",
      "Val    loss : 0.21294    f1 : 0.80149\n",
      "-----------------SAVE:43 epoch----------------\n",
      "epoch : 43/100    time : 54s/3092s\n",
      "TRAIN    loss : 0.00877    f1 : 0.99644\n",
      "Val    loss : 0.18072    f1 : 0.82500\n",
      "epoch : 44/100    time : 55s/3068s\n",
      "TRAIN    loss : 0.01405    f1 : 0.99090\n",
      "Val    loss : 0.25246    f1 : 0.77952\n",
      "epoch : 45/100    time : 55s/3009s\n",
      "TRAIN    loss : 0.02321    f1 : 0.98034\n",
      "Val    loss : 0.23270    f1 : 0.79032\n",
      "epoch : 46/100    time : 54s/2920s\n",
      "TRAIN    loss : 0.04715    f1 : 0.96333\n",
      "Val    loss : 0.21711    f1 : 0.75388\n",
      "epoch : 47/100    time : 55s/2917s\n",
      "TRAIN    loss : 0.03184    f1 : 0.96738\n",
      "Val    loss : 0.22239    f1 : 0.77726\n",
      "epoch : 48/100    time : 55s/2868s\n",
      "TRAIN    loss : 0.01451    f1 : 0.98652\n",
      "Val    loss : 0.20891    f1 : 0.77955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 49/100    time : 56s/2848s\n",
      "TRAIN    loss : 0.02349    f1 : 0.98831\n",
      "Val    loss : 0.26322    f1 : 0.79326\n",
      "epoch : 50/100    time : 53s/2661s\n",
      "TRAIN    loss : 0.01066    f1 : 0.98845\n",
      "Val    loss : 0.20192    f1 : 0.81267\n",
      "epoch : 51/100    time : 58s/2839s\n",
      "TRAIN    loss : 0.02519    f1 : 0.97834\n",
      "Val    loss : 0.24916    f1 : 0.75607\n",
      "epoch : 52/100    time : 54s/2592s\n",
      "TRAIN    loss : 0.03072    f1 : 0.96966\n",
      "Val    loss : 0.18119    f1 : 0.78709\n",
      "epoch : 53/100    time : 54s/2550s\n",
      "TRAIN    loss : 0.01845    f1 : 0.97295\n",
      "Val    loss : 0.20235    f1 : 0.75240\n",
      "epoch : 54/100    time : 53s/2454s\n",
      "TRAIN    loss : 0.02194    f1 : 0.98191\n",
      "Val    loss : 0.18281    f1 : 0.80024\n",
      "-----------------SAVE:55 epoch----------------\n",
      "epoch : 55/100    time : 57s/2565s\n",
      "TRAIN    loss : 0.00925    f1 : 0.99361\n",
      "Val    loss : 0.20515    f1 : 0.82699\n",
      "epoch : 56/100    time : 54s/2373s\n",
      "TRAIN    loss : 0.02150    f1 : 0.97570\n",
      "Val    loss : 0.18432    f1 : 0.77332\n",
      "epoch : 57/100    time : 55s/2349s\n",
      "TRAIN    loss : 0.02055    f1 : 0.97834\n",
      "Val    loss : 0.19744    f1 : 0.78419\n",
      "epoch : 58/100    time : 56s/2339s\n",
      "TRAIN    loss : 0.01359    f1 : 0.98750\n",
      "Val    loss : 0.18058    f1 : 0.81199\n",
      "epoch : 59/100    time : 55s/2248s\n",
      "TRAIN    loss : 0.02105    f1 : 0.98425\n",
      "Val    loss : 0.22878    f1 : 0.78588\n",
      "epoch : 60/100    time : 54s/2174s\n",
      "TRAIN    loss : 0.01986    f1 : 0.98355\n",
      "Val    loss : 0.18854    f1 : 0.80095\n",
      "-----------------SAVE:61 epoch----------------\n",
      "epoch : 61/100    time : 56s/2195s\n",
      "TRAIN    loss : 0.01487    f1 : 0.98033\n",
      "Val    loss : 0.19291    f1 : 0.83645\n",
      "epoch : 62/100    time : 55s/2081s\n",
      "TRAIN    loss : 0.01126    f1 : 0.98218\n",
      "Val    loss : 0.23981    f1 : 0.79942\n",
      "epoch : 63/100    time : 54s/1985s\n",
      "TRAIN    loss : 0.01692    f1 : 0.98239\n",
      "Val    loss : 0.22205    f1 : 0.79388\n",
      "epoch : 64/100    time : 55s/1966s\n",
      "TRAIN    loss : 0.01393    f1 : 0.99203\n",
      "Val    loss : 0.22772    f1 : 0.79535\n",
      "epoch : 65/100    time : 56s/1952s\n",
      "TRAIN    loss : 0.00913    f1 : 0.99376\n",
      "Val    loss : 0.21387    f1 : 0.81729\n",
      "epoch : 66/100    time : 55s/1856s\n",
      "TRAIN    loss : 0.00313    f1 : 0.99877\n",
      "Val    loss : 0.20699    f1 : 0.82235\n",
      "epoch : 67/100    time : 53s/1763s\n",
      "TRAIN    loss : 0.02305    f1 : 0.97496\n",
      "Val    loss : 0.30089    f1 : 0.71907\n",
      "epoch : 68/100    time : 56s/1805s\n",
      "TRAIN    loss : 0.01845    f1 : 0.98120\n",
      "Val    loss : 0.23395    f1 : 0.75488\n",
      "epoch : 69/100    time : 54s/1668s\n",
      "TRAIN    loss : 0.03077    f1 : 0.96074\n",
      "Val    loss : 0.24747    f1 : 0.78605\n",
      "epoch : 70/100    time : 54s/1622s\n",
      "TRAIN    loss : 0.03720    f1 : 0.96798\n",
      "Val    loss : 0.23588    f1 : 0.74551\n",
      "epoch : 71/100    time : 56s/1613s\n",
      "TRAIN    loss : 0.01663    f1 : 0.98955\n",
      "Val    loss : 0.25946    f1 : 0.73229\n",
      "epoch : 72/100    time : 54s/1515s\n",
      "TRAIN    loss : 0.01986    f1 : 0.98062\n",
      "Val    loss : 0.22183    f1 : 0.77066\n",
      "epoch : 73/100    time : 55s/1475s\n",
      "TRAIN    loss : 0.01522    f1 : 0.98589\n",
      "Val    loss : 0.20778    f1 : 0.79774\n",
      "epoch : 74/100    time : 56s/1466s\n",
      "TRAIN    loss : 0.00256    f1 : 0.99938\n",
      "Val    loss : 0.18763    f1 : 0.81747\n",
      "-----------------SAVE:75 epoch----------------\n",
      "epoch : 75/100    time : 55s/1364s\n",
      "TRAIN    loss : 0.00252    f1 : 0.99937\n",
      "Val    loss : 0.17710    f1 : 0.84629\n",
      "epoch : 76/100    time : 54s/1296s\n",
      "TRAIN    loss : 0.00788    f1 : 0.99459\n",
      "Val    loss : 0.20743    f1 : 0.79621\n",
      "epoch : 77/100    time : 56s/1295s\n",
      "TRAIN    loss : 0.00608    f1 : 0.99764\n",
      "Val    loss : 0.20145    f1 : 0.78159\n",
      "epoch : 78/100    time : 56s/1225s\n",
      "TRAIN    loss : 0.01888    f1 : 0.98675\n",
      "Val    loss : 0.19353    f1 : 0.79777\n",
      "epoch : 79/100    time : 55s/1155s\n",
      "TRAIN    loss : 0.02675    f1 : 0.97719\n",
      "Val    loss : 0.23031    f1 : 0.75885\n",
      "epoch : 80/100    time : 54s/1086s\n",
      "TRAIN    loss : 0.02605    f1 : 0.98367\n",
      "Val    loss : 0.19812    f1 : 0.79442\n",
      "epoch : 81/100    time : 56s/1065s\n",
      "TRAIN    loss : 0.00997    f1 : 0.98612\n",
      "Val    loss : 0.21148    f1 : 0.76732\n",
      "epoch : 82/100    time : 55s/991s\n",
      "TRAIN    loss : 0.01132    f1 : 0.99292\n",
      "Val    loss : 0.22021    f1 : 0.78159\n",
      "epoch : 83/100    time : 54s/923s\n",
      "TRAIN    loss : 0.02268    f1 : 0.97908\n",
      "Val    loss : 0.24086    f1 : 0.78122\n",
      "epoch : 84/100    time : 56s/898s\n",
      "TRAIN    loss : 0.02171    f1 : 0.98712\n",
      "Val    loss : 0.14595    f1 : 0.81869\n",
      "-----------------SAVE:85 epoch----------------\n",
      "epoch : 85/100    time : 54s/816s\n",
      "TRAIN    loss : 0.01257    f1 : 0.98943\n",
      "Val    loss : 0.18620    f1 : 0.84764\n",
      "epoch : 86/100    time : 55s/765s\n",
      "TRAIN    loss : 0.01020    f1 : 0.99292\n",
      "Val    loss : 0.18940    f1 : 0.80438\n",
      "epoch : 87/100    time : 54s/698s\n",
      "TRAIN    loss : 0.01000    f1 : 0.98816\n",
      "Val    loss : 0.19917    f1 : 0.80723\n",
      "epoch : 88/100    time : 56s/676s\n",
      "TRAIN    loss : 0.00957    f1 : 0.99280\n",
      "Val    loss : 0.20849    f1 : 0.79466\n",
      "epoch : 89/100    time : 54s/597s\n",
      "TRAIN    loss : 0.01403    f1 : 0.98963\n",
      "Val    loss : 0.15281    f1 : 0.80785\n",
      "epoch : 90/100    time : 55s/548s\n",
      "TRAIN    loss : 0.00997    f1 : 0.99116\n",
      "Val    loss : 0.20292    f1 : 0.78340\n",
      "epoch : 91/100    time : 56s/502s\n",
      "TRAIN    loss : 0.00296    f1 : 0.99745\n",
      "Val    loss : 0.17724    f1 : 0.82712\n",
      "epoch : 92/100    time : 54s/434s\n",
      "TRAIN    loss : 0.01066    f1 : 0.98967\n",
      "Val    loss : 0.27977    f1 : 0.75912\n",
      "epoch : 93/100    time : 54s/376s\n",
      "TRAIN    loss : 0.01004    f1 : 0.99576\n",
      "Val    loss : 0.30606    f1 : 0.76527\n",
      "epoch : 94/100    time : 56s/336s\n",
      "TRAIN    loss : 0.00992    f1 : 0.99500\n",
      "Val    loss : 0.23801    f1 : 0.78700\n",
      "epoch : 95/100    time : 55s/275s\n",
      "TRAIN    loss : 0.02742    f1 : 0.97459\n",
      "Val    loss : 0.31600    f1 : 0.72767\n",
      "epoch : 96/100    time : 53s/214s\n",
      "TRAIN    loss : 0.01816    f1 : 0.97587\n",
      "Val    loss : 0.22593    f1 : 0.75986\n",
      "epoch : 97/100    time : 57s/170s\n",
      "TRAIN    loss : 0.03992    f1 : 0.94880\n",
      "Val    loss : 0.19870    f1 : 0.78371\n",
      "epoch : 98/100    time : 55s/110s\n",
      "TRAIN    loss : 0.02241    f1 : 0.97922\n",
      "Val    loss : 0.21329    f1 : 0.78066\n",
      "epoch : 99/100    time : 54s/54s\n",
      "TRAIN    loss : 0.01036    f1 : 0.98749\n",
      "Val    loss : 0.25834    f1 : 0.77756\n",
      "epoch : 100/100    time : 54s/0s\n",
      "TRAIN    loss : 0.01352    f1 : 0.98706\n",
      "Val    loss : 0.19970    f1 : 0.80992\n",
      "----------fold_4 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 56s/5554s\n",
      "TRAIN    loss : 1.40744    f1 : 0.14926\n",
      "Val    loss : 0.80906    f1 : 0.15780\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 54s/5323s\n",
      "TRAIN    loss : 0.73293    f1 : 0.17197\n",
      "Val    loss : 0.59135    f1 : 0.21470\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 55s/5294s\n",
      "TRAIN    loss : 0.56757    f1 : 0.25282\n",
      "Val    loss : 0.48879    f1 : 0.30319\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 57s/5474s\n",
      "TRAIN    loss : 0.45406    f1 : 0.37971\n",
      "Val    loss : 0.39622    f1 : 0.39563\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 56s/5296s\n",
      "TRAIN    loss : 0.37699    f1 : 0.49125\n",
      "Val    loss : 0.33309    f1 : 0.47703\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 54s/5106s\n",
      "TRAIN    loss : 0.30059    f1 : 0.57745\n",
      "Val    loss : 0.34577    f1 : 0.50008\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 56s/5229s\n",
      "TRAIN    loss : 0.24571    f1 : 0.64931\n",
      "Val    loss : 0.31011    f1 : 0.60494\n",
      "epoch : 8/100    time : 56s/5111s\n",
      "TRAIN    loss : 0.20615    f1 : 0.71592\n",
      "Val    loss : 0.24891    f1 : 0.60103\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 54s/4904s\n",
      "TRAIN    loss : 0.17811    f1 : 0.76156\n",
      "Val    loss : 0.21644    f1 : 0.66332\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/100    time : 57s/5158s\n",
      "TRAIN    loss : 0.13583    f1 : 0.84189\n",
      "Val    loss : 0.19319    f1 : 0.71751\n",
      "epoch : 11/100    time : 54s/4808s\n",
      "TRAIN    loss : 0.10995    f1 : 0.85767\n",
      "Val    loss : 0.18905    f1 : 0.71443\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 55s/4801s\n",
      "TRAIN    loss : 0.10644    f1 : 0.87249\n",
      "Val    loss : 0.17966    f1 : 0.74372\n",
      "epoch : 13/100    time : 54s/4687s\n",
      "TRAIN    loss : 0.08758    f1 : 0.90473\n",
      "Val    loss : 0.17399    f1 : 0.71944\n",
      "epoch : 14/100    time : 57s/4869s\n",
      "TRAIN    loss : 0.09464    f1 : 0.88112\n",
      "Val    loss : 0.20035    f1 : 0.70491\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/100    time : 55s/4649s\n",
      "TRAIN    loss : 0.08583    f1 : 0.90191\n",
      "Val    loss : 0.19247    f1 : 0.76302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 16/100    time : 55s/4591s\n",
      "TRAIN    loss : 0.06421    f1 : 0.93001\n",
      "Val    loss : 0.20594    f1 : 0.71795\n",
      "epoch : 17/100    time : 56s/4614s\n",
      "TRAIN    loss : 0.06039    f1 : 0.93674\n",
      "Val    loss : 0.27679    f1 : 0.75842\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/100    time : 54s/4444s\n",
      "TRAIN    loss : 0.05362    f1 : 0.94809\n",
      "Val    loss : 0.19344    f1 : 0.77759\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/100    time : 55s/4429s\n",
      "TRAIN    loss : 0.04878    f1 : 0.96229\n",
      "Val    loss : 0.18492    f1 : 0.77973\n",
      "epoch : 20/100    time : 57s/4556s\n",
      "TRAIN    loss : 0.03979    f1 : 0.96559\n",
      "Val    loss : 0.22037    f1 : 0.75125\n",
      "epoch : 21/100    time : 56s/4390s\n",
      "TRAIN    loss : 0.04639    f1 : 0.94884\n",
      "Val    loss : 0.22804    f1 : 0.73957\n",
      "-----------------SAVE:22 epoch----------------\n",
      "epoch : 22/100    time : 55s/4286s\n",
      "TRAIN    loss : 0.03536    f1 : 0.96560\n",
      "Val    loss : 0.18182    f1 : 0.79652\n",
      "epoch : 23/100    time : 56s/4329s\n",
      "TRAIN    loss : 0.03897    f1 : 0.95758\n",
      "Val    loss : 0.19983    f1 : 0.74536\n",
      "epoch : 24/100    time : 54s/4088s\n",
      "TRAIN    loss : 0.05027    f1 : 0.95920\n",
      "Val    loss : 0.21651    f1 : 0.75142\n",
      "epoch : 25/100    time : 54s/4075s\n",
      "TRAIN    loss : 0.04426    f1 : 0.96095\n",
      "Val    loss : 0.27101    f1 : 0.70582\n",
      "epoch : 26/100    time : 55s/4037s\n",
      "TRAIN    loss : 0.03772    f1 : 0.98129\n",
      "Val    loss : 0.23775    f1 : 0.73003\n",
      "epoch : 27/100    time : 56s/4093s\n",
      "TRAIN    loss : 0.03477    f1 : 0.96722\n",
      "Val    loss : 0.20631    f1 : 0.76119\n",
      "epoch : 28/100    time : 54s/3871s\n",
      "TRAIN    loss : 0.03703    f1 : 0.96679\n",
      "Val    loss : 0.18562    f1 : 0.75039\n",
      "epoch : 29/100    time : 54s/3832s\n",
      "TRAIN    loss : 0.03136    f1 : 0.96831\n",
      "Val    loss : 0.22409    f1 : 0.75873\n",
      "epoch : 30/100    time : 55s/3881s\n",
      "TRAIN    loss : 0.01521    f1 : 0.97985\n",
      "Val    loss : 0.21112    f1 : 0.78488\n",
      "epoch : 31/100    time : 55s/3776s\n",
      "TRAIN    loss : 0.02477    f1 : 0.97052\n",
      "Val    loss : 0.25819    f1 : 0.74491\n",
      "epoch : 32/100    time : 54s/3701s\n",
      "TRAIN    loss : 0.02216    f1 : 0.98309\n",
      "Val    loss : 0.18802    f1 : 0.77948\n",
      "-----------------SAVE:33 epoch----------------\n",
      "epoch : 33/100    time : 56s/3775s\n",
      "TRAIN    loss : 0.02456    f1 : 0.97671\n",
      "Val    loss : 0.22085    f1 : 0.80526\n",
      "epoch : 34/100    time : 55s/3632s\n",
      "TRAIN    loss : 0.02126    f1 : 0.98178\n",
      "Val    loss : 0.23992    f1 : 0.78263\n",
      "epoch : 35/100    time : 55s/3544s\n",
      "TRAIN    loss : 0.03746    f1 : 0.96852\n",
      "Val    loss : 0.25875    f1 : 0.78745\n",
      "epoch : 36/100    time : 55s/3511s\n",
      "TRAIN    loss : 0.03781    f1 : 0.95737\n",
      "Val    loss : 0.26808    f1 : 0.71673\n",
      "epoch : 37/100    time : 55s/3496s\n",
      "TRAIN    loss : 0.02523    f1 : 0.97796\n",
      "Val    loss : 0.23987    f1 : 0.73948\n",
      "epoch : 38/100    time : 54s/3366s\n",
      "TRAIN    loss : 0.03256    f1 : 0.97033\n",
      "Val    loss : 0.24538    f1 : 0.74700\n",
      "epoch : 39/100    time : 54s/3294s\n",
      "TRAIN    loss : 0.01636    f1 : 0.98633\n",
      "Val    loss : 0.25435    f1 : 0.75222\n",
      "epoch : 40/100    time : 57s/3421s\n",
      "TRAIN    loss : 0.01304    f1 : 0.98676\n",
      "Val    loss : 0.22730    f1 : 0.77301\n",
      "epoch : 41/100    time : 54s/3191s\n",
      "TRAIN    loss : 0.03611    f1 : 0.96435\n",
      "Val    loss : 0.19886    f1 : 0.75352\n",
      "epoch : 42/100    time : 54s/3123s\n",
      "TRAIN    loss : 0.02485    f1 : 0.97075\n",
      "Val    loss : 0.23965    f1 : 0.72844\n",
      "epoch : 43/100    time : 56s/3207s\n",
      "TRAIN    loss : 0.02463    f1 : 0.97463\n",
      "Val    loss : 0.25019    f1 : 0.78072\n",
      "epoch : 44/100    time : 55s/3058s\n",
      "TRAIN    loss : 0.02038    f1 : 0.98249\n",
      "Val    loss : 0.25754    f1 : 0.77701\n",
      "epoch : 45/100    time : 54s/2990s\n",
      "TRAIN    loss : 0.02215    f1 : 0.97858\n",
      "Val    loss : 0.23998    f1 : 0.77956\n",
      "epoch : 46/100    time : 56s/3028s\n",
      "TRAIN    loss : 0.01917    f1 : 0.98616\n",
      "Val    loss : 0.42462    f1 : 0.74235\n",
      "epoch : 47/100    time : 54s/2872s\n",
      "TRAIN    loss : 0.01878    f1 : 0.97877\n",
      "Val    loss : 0.23333    f1 : 0.71206\n",
      "epoch : 48/100    time : 54s/2792s\n",
      "TRAIN    loss : 0.02906    f1 : 0.97257\n",
      "Val    loss : 0.24540    f1 : 0.74725\n",
      "epoch : 49/100    time : 55s/2784s\n",
      "TRAIN    loss : 0.02487    f1 : 0.97706\n",
      "Val    loss : 0.23364    f1 : 0.74547\n",
      "epoch : 50/100    time : 56s/2792s\n",
      "TRAIN    loss : 0.02757    f1 : 0.96809\n",
      "Val    loss : 0.18875    f1 : 0.76436\n",
      "epoch : 51/100    time : 55s/2718s\n",
      "TRAIN    loss : 0.02296    f1 : 0.98329\n",
      "Val    loss : 0.19573    f1 : 0.79713\n",
      "-----------------SAVE:52 epoch----------------\n",
      "epoch : 52/100    time : 55s/2646s\n",
      "TRAIN    loss : 0.00660    f1 : 0.99395\n",
      "Val    loss : 0.20163    f1 : 0.80571\n",
      "epoch : 53/100    time : 56s/2644s\n",
      "TRAIN    loss : 0.01451    f1 : 0.98163\n",
      "Val    loss : 0.21151    f1 : 0.76535\n",
      "-----------------SAVE:54 epoch----------------\n",
      "epoch : 54/100    time : 55s/2550s\n",
      "TRAIN    loss : 0.02831    f1 : 0.96908\n",
      "Val    loss : 0.17726    f1 : 0.81851\n",
      "epoch : 55/100    time : 54s/2417s\n",
      "TRAIN    loss : 0.02609    f1 : 0.97811\n",
      "Val    loss : 0.22798    f1 : 0.76577\n",
      "epoch : 56/100    time : 57s/2500s\n",
      "TRAIN    loss : 0.02326    f1 : 0.97841\n",
      "Val    loss : 0.20050    f1 : 0.79508\n",
      "epoch : 57/100    time : 55s/2354s\n",
      "TRAIN    loss : 0.03256    f1 : 0.97827\n",
      "Val    loss : 0.17416    f1 : 0.75853\n",
      "epoch : 58/100    time : 55s/2299s\n",
      "TRAIN    loss : 0.01132    f1 : 0.99162\n",
      "Val    loss : 0.18039    f1 : 0.78995\n",
      "epoch : 59/100    time : 56s/2306s\n",
      "TRAIN    loss : 0.01016    f1 : 0.99094\n",
      "Val    loss : 0.20110    f1 : 0.79001\n",
      "epoch : 60/100    time : 54s/2149s\n",
      "TRAIN    loss : 0.01378    f1 : 0.99053\n",
      "Val    loss : 0.17933    f1 : 0.79206\n",
      "epoch : 61/100    time : 55s/2150s\n",
      "TRAIN    loss : 0.00818    f1 : 0.99246\n",
      "Val    loss : 0.18474    f1 : 0.80659\n",
      "epoch : 62/100    time : 54s/2065s\n",
      "TRAIN    loss : 0.00279    f1 : 0.99853\n",
      "Val    loss : 0.17743    f1 : 0.80640\n",
      "epoch : 63/100    time : 56s/2055s\n",
      "TRAIN    loss : 0.01479    f1 : 0.98987\n",
      "Val    loss : 0.21001    f1 : 0.75278\n",
      "epoch : 64/100    time : 54s/1932s\n",
      "TRAIN    loss : 0.02564    f1 : 0.97636\n",
      "Val    loss : 0.25655    f1 : 0.71112\n",
      "epoch : 65/100    time : 55s/1913s\n",
      "TRAIN    loss : 0.02453    f1 : 0.96929\n",
      "Val    loss : 0.25362    f1 : 0.69224\n",
      "epoch : 66/100    time : 56s/1902s\n",
      "TRAIN    loss : 0.03179    f1 : 0.96452\n",
      "Val    loss : 0.23652    f1 : 0.74924\n",
      "epoch : 67/100    time : 55s/1801s\n",
      "TRAIN    loss : 0.01462    f1 : 0.98952\n",
      "Val    loss : 0.22654    f1 : 0.76122\n",
      "epoch : 68/100    time : 54s/1730s\n",
      "TRAIN    loss : 0.02207    f1 : 0.98875\n",
      "Val    loss : 0.21662    f1 : 0.75496\n",
      "epoch : 69/100    time : 56s/1749s\n",
      "TRAIN    loss : 0.01732    f1 : 0.98331\n",
      "Val    loss : 0.24693    f1 : 0.72885\n",
      "epoch : 70/100    time : 55s/1665s\n",
      "TRAIN    loss : 0.01894    f1 : 0.98423\n",
      "Val    loss : 0.26759    f1 : 0.76329\n",
      "epoch : 71/100    time : 54s/1571s\n",
      "TRAIN    loss : 0.01330    f1 : 0.98608\n",
      "Val    loss : 0.28041    f1 : 0.77513\n",
      "epoch : 72/100    time : 54s/1522s\n",
      "TRAIN    loss : 0.01356    f1 : 0.99000\n",
      "Val    loss : 0.24777    f1 : 0.77944\n",
      "-----------------SAVE:73 epoch----------------\n",
      "epoch : 73/100    time : 56s/1522s\n",
      "TRAIN    loss : 0.01574    f1 : 0.98849\n",
      "Val    loss : 0.19472    f1 : 0.82296\n",
      "epoch : 74/100    time : 54s/1393s\n",
      "TRAIN    loss : 0.02764    f1 : 0.97669\n",
      "Val    loss : 0.19167    f1 : 0.81529\n",
      "epoch : 75/100    time : 56s/1394s\n",
      "TRAIN    loss : 0.00830    f1 : 0.99269\n",
      "Val    loss : 0.22407    f1 : 0.75412\n",
      "epoch : 76/100    time : 56s/1333s\n",
      "TRAIN    loss : 0.00673    f1 : 0.99479\n",
      "Val    loss : 0.20896    f1 : 0.79701\n",
      "epoch : 77/100    time : 54s/1253s\n",
      "TRAIN    loss : 0.02209    f1 : 0.98423\n",
      "Val    loss : 0.26831    f1 : 0.76835\n",
      "epoch : 78/100    time : 54s/1192s\n",
      "TRAIN    loss : 0.02060    f1 : 0.98260\n",
      "Val    loss : 0.27618    f1 : 0.76065\n",
      "epoch : 79/100    time : 56s/1174s\n",
      "TRAIN    loss : 0.01150    f1 : 0.99279\n",
      "Val    loss : 0.18916    f1 : 0.80265\n",
      "epoch : 80/100    time : 54s/1087s\n",
      "TRAIN    loss : 0.00798    f1 : 0.99482\n",
      "Val    loss : 0.19987    f1 : 0.80100\n",
      "epoch : 81/100    time : 54s/1028s\n",
      "TRAIN    loss : 0.00869    f1 : 0.99031\n",
      "Val    loss : 0.24189    f1 : 0.77324\n",
      "epoch : 82/100    time : 56s/1004s\n",
      "TRAIN    loss : 0.01291    f1 : 0.98711\n",
      "Val    loss : 0.25519    f1 : 0.74043\n",
      "epoch : 83/100    time : 54s/919s\n",
      "TRAIN    loss : 0.01755    f1 : 0.98548\n",
      "Val    loss : 0.22298    f1 : 0.77606\n",
      "epoch : 84/100    time : 54s/870s\n",
      "TRAIN    loss : 0.01774    f1 : 0.98337\n",
      "Val    loss : 0.20707    f1 : 0.79604\n",
      "epoch : 85/100    time : 54s/816s\n",
      "TRAIN    loss : 0.01041    f1 : 0.99318\n",
      "Val    loss : 0.23326    f1 : 0.75107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 86/100    time : 57s/797s\n",
      "TRAIN    loss : 0.02278    f1 : 0.98683\n",
      "Val    loss : 0.22432    f1 : 0.77066\n",
      "epoch : 87/100    time : 54s/699s\n",
      "TRAIN    loss : 0.00734    f1 : 0.99594\n",
      "Val    loss : 0.22004    f1 : 0.81607\n",
      "epoch : 88/100    time : 54s/645s\n",
      "TRAIN    loss : 0.01021    f1 : 0.99370\n",
      "Val    loss : 0.24329    f1 : 0.75369\n",
      "epoch : 89/100    time : 56s/619s\n",
      "TRAIN    loss : 0.01838    f1 : 0.98170\n",
      "Val    loss : 0.25865    f1 : 0.76142\n",
      "epoch : 90/100    time : 54s/535s\n",
      "TRAIN    loss : 0.01520    f1 : 0.98636\n",
      "Val    loss : 0.18877    f1 : 0.77839\n",
      "epoch : 91/100    time : 54s/488s\n",
      "TRAIN    loss : 0.00372    f1 : 0.99710\n",
      "Val    loss : 0.24814    f1 : 0.77677\n",
      "epoch : 92/100    time : 55s/443s\n",
      "TRAIN    loss : 0.00490    f1 : 0.99353\n",
      "Val    loss : 0.20452    f1 : 0.80234\n",
      "epoch : 93/100    time : 55s/382s\n",
      "TRAIN    loss : 0.00246    f1 : 0.99868\n",
      "Val    loss : 0.21094    f1 : 0.76786\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022,shuffle=True)\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "  print(\"----------fold_{} start!----------\".format(idx))\n",
    "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "  # Train\n",
    "  train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Val\n",
    "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  best=0\n",
    "\n",
    "  model = Network().to(device)\n",
    "\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay = 1e-3)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "  best_f1 = 0\n",
    "  early_stopping = 0\n",
    "  for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss = 0 \n",
    "      val_pred = []\n",
    "      val_y = []\n",
    "      \n",
    "\n",
    "      for batch in (val_loader):\n",
    "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_val = model(x_val)\n",
    "        loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "        val_loss += loss_val.item()/len(val_loader)\n",
    "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "        val_y += y_val.detach().cpu().numpy().tolist()\n",
    "      val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "      if val_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_loss = val_loss\n",
    "        best_f1 = val_f1\n",
    "        early_stopping = 0\n",
    "\n",
    "        torch.save({'epoch':epoch,\n",
    "                    'state_dict':state_dict,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "             }, path +'best_model_{}.pth'.format(idx))\n",
    "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "      else:\n",
    "          early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "      if early_stopping == 20:\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "Jl2OKpQiO5S1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl2OKpQiO5S1",
    "outputId": "e48def07-ef6d-4325-f297-c705088b3eb8"
   },
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 16\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load((path+'best_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "seat84vNOOtT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seat84vNOOtT",
    "outputId": "71c853b2-29c3-430e-e4d0-cb1a66e11196"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "GjsHs-T3SPJq",
   "metadata": {
    "id": "GjsHs-T3SPJq"
   },
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1])+ np.array(pred_ensemble[3]) + np.array(pred_ensemble[4]) )/4\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "UIglTwAV7L54",
   "metadata": {
    "id": "UIglTwAV7L54"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "292QDIS5DOKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "292QDIS5DOKf",
    "outputId": "0e47d38f-d36a-40cd-a925-90e6bce52652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1naZSLGZ7L55",
   "metadata": {
    "id": "1naZSLGZ7L55"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"densenet121_norm_epoch100.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fitted-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSubmitted': True, 'detail': 'Success'}\n"
     ]
    }
   ],
   "source": [
    "# d2b19ece8c7374053ee1fd80cfe419ddfc640c01f9ebe4cbd5caeb9f1906974a\n",
    "\n",
    "from dacon_submit_api import dacon_submit_api \n",
    "\n",
    "result = dacon_submit_api.post_submission_file(\n",
    "'/home/densenet121_norm_epoch100.csv', \n",
    "'d2b19ece8c7374053ee1fd80cfe419ddfc640c01f9ebe4cbd5caeb9f1906974a', \n",
    "'235894', \n",
    "'mean', \n",
    "'densenet121_BS16' )\n",
    "\n",
    "# https://www.dacon.io/competitions/official/235894/overview/rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p87_msjB7L51",
   "metadata": {
    "id": "p87_msjB7L51"
   },
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MW9Fx7QADii5",
   "metadata": {
    "id": "MW9Fx7QADii5"
   },
   "source": [
    "사전 학습 모델의 성능 파악을 할 때 Fold 학습은 실행 시간이 오래걸려서 fold를 나누지 않은 데이터에 대해서 학습을 진행하고 성능을 비교하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "syUpL8e_7L50",
   "metadata": {
    "id": "syUpL8e_7L50"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 30\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cJc8Yj7zrh4g",
   "metadata": {
    "id": "cJc8Yj7zrh4g"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tpCGp41k7L51",
   "metadata": {
    "id": "tpCGp41k7L51"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "\n",
    "best=0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YssPW4xq7L53",
   "metadata": {
    "id": "YssPW4xq7L53"
   },
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1w_VB_PY7L53",
   "metadata": {
    "id": "1w_VB_PY7L53"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "f_pred = []\n",
    "pred_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "            pred_prob.extend(pred.detach().cpu().numpy())\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aZMML2u3DTHx",
   "metadata": {
    "id": "aZMML2u3DTHx"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I4io2mJC7L54",
   "metadata": {
    "id": "I4io2mJC7L54"
   },
   "source": [
    "### 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XCV3FEKe7L55",
   "metadata": {
    "id": "XCV3FEKe7L55"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(path + \"open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jsl6tXbz7L56",
   "metadata": {
    "id": "jsl6tXbz7L56"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"VGG16_norm.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[BASELINE]_EfficientNet_b3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
