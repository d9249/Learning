{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LlcNsGEk7L5r",
   "metadata": {
    "id": "LlcNsGEk7L5r"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "popular-bathroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3',\n",
      " 'bat_resnext26ts',\n",
      " 'beit_base_patch16_224',\n",
      " 'beit_base_patch16_224_in22k',\n",
      " 'beit_base_patch16_384',\n",
      " 'beit_large_patch16_224',\n",
      " 'beit_large_patch16_224_in22k',\n",
      " 'beit_large_patch16_384',\n",
      " 'beit_large_patch16_512',\n",
      " 'botnet26t_256',\n",
      " 'cait_m36_384',\n",
      " 'cait_m48_448',\n",
      " 'cait_s24_224',\n",
      " 'cait_s24_384',\n",
      " 'cait_s36_384',\n",
      " 'cait_xs24_384',\n",
      " 'cait_xxs24_224',\n",
      " 'cait_xxs24_384',\n",
      " 'cait_xxs36_224',\n",
      " 'cait_xxs36_384',\n",
      " 'coat_lite_mini',\n",
      " 'coat_lite_small',\n",
      " 'coat_lite_tiny',\n",
      " 'coat_mini',\n",
      " 'coat_tiny',\n",
      " 'convit_base',\n",
      " 'convit_small',\n",
      " 'convit_tiny',\n",
      " 'convmixer_768_32',\n",
      " 'convmixer_1024_20_ks9_p14',\n",
      " 'convmixer_1536_20',\n",
      " 'convnext_base',\n",
      " 'convnext_base_384_in22ft1k',\n",
      " 'convnext_base_in22ft1k',\n",
      " 'convnext_base_in22k',\n",
      " 'convnext_large',\n",
      " 'convnext_large_384_in22ft1k',\n",
      " 'convnext_large_in22ft1k',\n",
      " 'convnext_large_in22k',\n",
      " 'convnext_small',\n",
      " 'convnext_tiny',\n",
      " 'convnext_xlarge_384_in22ft1k',\n",
      " 'convnext_xlarge_in22ft1k',\n",
      " 'convnext_xlarge_in22k',\n",
      " 'crossvit_9_240',\n",
      " 'crossvit_9_dagger_240',\n",
      " 'crossvit_15_240',\n",
      " 'crossvit_15_dagger_240',\n",
      " 'crossvit_15_dagger_408',\n",
      " 'crossvit_18_240',\n",
      " 'crossvit_18_dagger_240',\n",
      " 'crossvit_18_dagger_408',\n",
      " 'crossvit_base_240',\n",
      " 'crossvit_small_240',\n",
      " 'crossvit_tiny_240',\n",
      " 'cspdarknet53',\n",
      " 'cspresnet50',\n",
      " 'cspresnext50',\n",
      " 'deit_base_distilled_patch16_224',\n",
      " 'deit_base_distilled_patch16_384',\n",
      " 'deit_base_patch16_224',\n",
      " 'deit_base_patch16_384',\n",
      " 'deit_small_distilled_patch16_224',\n",
      " 'deit_small_patch16_224',\n",
      " 'deit_tiny_distilled_patch16_224',\n",
      " 'deit_tiny_patch16_224',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dm_nfnet_f0',\n",
      " 'dm_nfnet_f1',\n",
      " 'dm_nfnet_f2',\n",
      " 'dm_nfnet_f3',\n",
      " 'dm_nfnet_f4',\n",
      " 'dm_nfnet_f5',\n",
      " 'dm_nfnet_f6',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'eca_botnext26ts_256',\n",
      " 'eca_halonext26ts',\n",
      " 'eca_nfnet_l0',\n",
      " 'eca_nfnet_l1',\n",
      " 'eca_nfnet_l2',\n",
      " 'eca_resnet33ts',\n",
      " 'eca_resnext26ts',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b4',\n",
      " 'efficientnet_el',\n",
      " 'efficientnet_el_pruned',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_es_pruned',\n",
      " 'efficientnet_lite0',\n",
      " 'efficientnetv2_rw_m',\n",
      " 'efficientnetv2_rw_s',\n",
      " 'efficientnetv2_rw_t',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'fbnetc_100',\n",
      " 'fbnetv3_b',\n",
      " 'fbnetv3_d',\n",
      " 'fbnetv3_g',\n",
      " 'gc_efficientnetv2_rw_t',\n",
      " 'gcresnet33ts',\n",
      " 'gcresnet50t',\n",
      " 'gcresnext26ts',\n",
      " 'gcresnext50ts',\n",
      " 'gernet_l',\n",
      " 'gernet_m',\n",
      " 'gernet_s',\n",
      " 'ghostnet_100',\n",
      " 'gluon_inception_v3',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_senet154',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'gluon_xception65',\n",
      " 'gmixer_24_224',\n",
      " 'gmlp_s16_224',\n",
      " 'halo2botnet50ts_256',\n",
      " 'halonet26t',\n",
      " 'halonet50ts',\n",
      " 'haloregnetz_b',\n",
      " 'hardcorenas_a',\n",
      " 'hardcorenas_b',\n",
      " 'hardcorenas_c',\n",
      " 'hardcorenas_d',\n",
      " 'hardcorenas_e',\n",
      " 'hardcorenas_f',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w64',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'jx_nest_base',\n",
      " 'jx_nest_small',\n",
      " 'jx_nest_tiny',\n",
      " 'lambda_resnet26rpt_256',\n",
      " 'lambda_resnet26t',\n",
      " 'lambda_resnet50ts',\n",
      " 'lamhalobotnet50ts_256',\n",
      " 'lcnet_050',\n",
      " 'lcnet_075',\n",
      " 'lcnet_100',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'levit_128',\n",
      " 'levit_128s',\n",
      " 'levit_192',\n",
      " 'levit_256',\n",
      " 'levit_384',\n",
      " 'mixer_b16_224',\n",
      " 'mixer_b16_224_in21k',\n",
      " 'mixer_b16_224_miil',\n",
      " 'mixer_b16_224_miil_in21k',\n",
      " 'mixer_l16_224',\n",
      " 'mixer_l16_224_in21k',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mnasnet_100',\n",
      " 'mnasnet_small',\n",
      " 'mobilenetv2_050',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_large_100_miil',\n",
      " 'mobilenetv3_large_100_miil_in21k',\n",
      " 'mobilenetv3_rw',\n",
      " 'nasnetalarge',\n",
      " 'nf_regnet_b1',\n",
      " 'nf_resnet50',\n",
      " 'nfnet_l0',\n",
      " 'pit_b_224',\n",
      " 'pit_b_distilled_224',\n",
      " 'pit_s_224',\n",
      " 'pit_s_distilled_224',\n",
      " 'pit_ti_224',\n",
      " 'pit_ti_distilled_224',\n",
      " 'pit_xs_224',\n",
      " 'pit_xs_distilled_224',\n",
      " 'pnasnet5large',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'regnetz_b16',\n",
      " 'regnetz_c16',\n",
      " 'regnetz_d8',\n",
      " 'regnetz_d32',\n",
      " 'regnetz_e8',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2next50',\n",
      " 'resmlp_12_224',\n",
      " 'resmlp_12_224_dino',\n",
      " 'resmlp_12_distilled_224',\n",
      " 'resmlp_24_224',\n",
      " 'resmlp_24_224_dino',\n",
      " 'resmlp_24_distilled_224',\n",
      " 'resmlp_36_224',\n",
      " 'resmlp_36_distilled_224',\n",
      " 'resmlp_big_24_224',\n",
      " 'resmlp_big_24_224_in22ft1k',\n",
      " 'resmlp_big_24_distilled_224',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet26t',\n",
      " 'resnet32ts',\n",
      " 'resnet33ts',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50_gn',\n",
      " 'resnet50d',\n",
      " 'resnet51q',\n",
      " 'resnet61q',\n",
      " 'resnet101',\n",
      " 'resnet101d',\n",
      " 'resnet152',\n",
      " 'resnet152d',\n",
      " 'resnet200d',\n",
      " 'resnetblur50',\n",
      " 'resnetrs50',\n",
      " 'resnetrs101',\n",
      " 'resnetrs152',\n",
      " 'resnetrs200',\n",
      " 'resnetrs270',\n",
      " 'resnetrs350',\n",
      " 'resnetrs420',\n",
      " 'resnetv2_50',\n",
      " 'resnetv2_50x1_bit_distilled',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bit_teacher',\n",
      " 'resnetv2_152x2_bit_teacher_384',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext26ts',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'sebotnet33ts_256',\n",
      " 'sehalonet33ts',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'semnasnet_075',\n",
      " 'semnasnet_100',\n",
      " 'seresnet33ts',\n",
      " 'seresnet50',\n",
      " 'seresnet152d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext26ts',\n",
      " 'seresnext50_32x4d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swin_base_patch4_window7_224',\n",
      " 'swin_base_patch4_window7_224_in22k',\n",
      " 'swin_base_patch4_window12_384',\n",
      " 'swin_base_patch4_window12_384_in22k',\n",
      " 'swin_large_patch4_window7_224',\n",
      " 'swin_large_patch4_window7_224_in22k',\n",
      " 'swin_large_patch4_window12_384',\n",
      " 'swin_large_patch4_window12_384_in22k',\n",
      " 'swin_small_patch4_window7_224',\n",
      " 'swin_tiny_patch4_window7_224',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b0_ap',\n",
      " 'tf_efficientnet_b0_ns',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b1_ap',\n",
      " 'tf_efficientnet_b1_ns',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b2_ap',\n",
      " 'tf_efficientnet_b2_ns',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b3_ap',\n",
      " 'tf_efficientnet_b3_ns',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b4_ap',\n",
      " 'tf_efficientnet_b4_ns',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b5_ap',\n",
      " 'tf_efficientnet_b5_ns',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b6_ap',\n",
      " 'tf_efficientnet_b6_ns',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b7_ap',\n",
      " 'tf_efficientnet_b7_ns',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_b8_ap',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2_ns',\n",
      " 'tf_efficientnet_l2_ns_475',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_efficientnetv2_b0',\n",
      " 'tf_efficientnetv2_b1',\n",
      " 'tf_efficientnetv2_b2',\n",
      " 'tf_efficientnetv2_b3',\n",
      " 'tf_efficientnetv2_l',\n",
      " 'tf_efficientnetv2_l_in21ft1k',\n",
      " 'tf_efficientnetv2_l_in21k',\n",
      " 'tf_efficientnetv2_m',\n",
      " 'tf_efficientnetv2_m_in21ft1k',\n",
      " 'tf_efficientnetv2_m_in21k',\n",
      " 'tf_efficientnetv2_s',\n",
      " 'tf_efficientnetv2_s_in21ft1k',\n",
      " 'tf_efficientnetv2_s_in21k',\n",
      " 'tf_efficientnetv2_xl_in21ft1k',\n",
      " 'tf_efficientnetv2_xl_in21k',\n",
      " 'tf_inception_v3',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tinynet_a',\n",
      " 'tinynet_b',\n",
      " 'tinynet_c',\n",
      " 'tinynet_d',\n",
      " 'tinynet_e',\n",
      " 'tnt_s_patch16_224',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_m_miil_in21k',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_densenet121',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'twins_pcpvt_base',\n",
      " 'twins_pcpvt_large',\n",
      " 'twins_pcpvt_small',\n",
      " 'twins_svt_base',\n",
      " 'twins_svt_large',\n",
      " 'twins_svt_small',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'visformer_small',\n",
      " 'vit_base_patch8_224',\n",
      " 'vit_base_patch8_224_in21k',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_224_in21k',\n",
      " 'vit_base_patch16_224_miil',\n",
      " 'vit_base_patch16_224_miil_in21k',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch16_sam_224',\n",
      " 'vit_base_patch32_224',\n",
      " 'vit_base_patch32_224_in21k',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_patch32_sam_224',\n",
      " 'vit_base_r50_s16_224_in21k',\n",
      " 'vit_base_r50_s16_384',\n",
      " 'vit_huge_patch14_224_in21k',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_224_in21k',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch32_224_in21k',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_large_r50_s32_224',\n",
      " 'vit_large_r50_s32_224_in21k',\n",
      " 'vit_large_r50_s32_384',\n",
      " 'vit_small_patch16_224',\n",
      " 'vit_small_patch16_224_in21k',\n",
      " 'vit_small_patch16_384',\n",
      " 'vit_small_patch32_224',\n",
      " 'vit_small_patch32_224_in21k',\n",
      " 'vit_small_patch32_384',\n",
      " 'vit_small_r26_s32_224',\n",
      " 'vit_small_r26_s32_224_in21k',\n",
      " 'vit_small_r26_s32_384',\n",
      " 'vit_tiny_patch16_224',\n",
      " 'vit_tiny_patch16_224_in21k',\n",
      " 'vit_tiny_patch16_384',\n",
      " 'vit_tiny_r_s16_p8_224',\n",
      " 'vit_tiny_r_s16_p8_224_in21k',\n",
      " 'vit_tiny_r_s16_p8_384',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception',\n",
      " 'xception41',\n",
      " 'xception65',\n",
      " 'xception71',\n",
      " 'xcit_large_24_p8_224',\n",
      " 'xcit_large_24_p8_224_dist',\n",
      " 'xcit_large_24_p8_384_dist',\n",
      " 'xcit_large_24_p16_224',\n",
      " 'xcit_large_24_p16_224_dist',\n",
      " 'xcit_large_24_p16_384_dist',\n",
      " 'xcit_medium_24_p8_224',\n",
      " 'xcit_medium_24_p8_224_dist',\n",
      " 'xcit_medium_24_p8_384_dist',\n",
      " 'xcit_medium_24_p16_224',\n",
      " 'xcit_medium_24_p16_224_dist',\n",
      " 'xcit_medium_24_p16_384_dist',\n",
      " 'xcit_nano_12_p8_224',\n",
      " 'xcit_nano_12_p8_224_dist',\n",
      " 'xcit_nano_12_p8_384_dist',\n",
      " 'xcit_nano_12_p16_224',\n",
      " 'xcit_nano_12_p16_224_dist',\n",
      " 'xcit_nano_12_p16_384_dist',\n",
      " 'xcit_small_12_p8_224',\n",
      " 'xcit_small_12_p8_224_dist',\n",
      " 'xcit_small_12_p8_384_dist',\n",
      " 'xcit_small_12_p16_224',\n",
      " 'xcit_small_12_p16_224_dist',\n",
      " 'xcit_small_12_p16_384_dist',\n",
      " 'xcit_small_24_p8_224',\n",
      " 'xcit_small_24_p8_224_dist',\n",
      " 'xcit_small_24_p8_384_dist',\n",
      " 'xcit_small_24_p16_224',\n",
      " 'xcit_small_24_p16_224_dist',\n",
      " 'xcit_small_24_p16_384_dist',\n",
      " 'xcit_tiny_12_p8_224',\n",
      " 'xcit_tiny_12_p8_224_dist',\n",
      " 'xcit_tiny_12_p8_384_dist',\n",
      " 'xcit_tiny_12_p16_224',\n",
      " 'xcit_tiny_12_p16_224_dist',\n",
      " 'xcit_tiny_12_p16_384_dist',\n",
      " 'xcit_tiny_24_p8_224',\n",
      " 'xcit_tiny_24_p8_224_dist',\n",
      " 'xcit_tiny_24_p8_384_dist',\n",
      " 'xcit_tiny_24_p16_224',\n",
      " 'xcit_tiny_24_p16_224_dist',\n",
      " 'xcit_tiny_24_p16_384_dist']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lXH5F_hA7uMl",
   "metadata": {
    "id": "lXH5F_hA7uMl"
   },
   "outputs": [],
   "source": [
    "path = '/home/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "FWntO1VD7L5u",
   "metadata": {
    "id": "FWntO1VD7L5u"
   },
   "outputs": [],
   "source": [
    "train_png = sorted(glob(path + 'open/train/*.png'))\n",
    "test_png = sorted(glob(path + 'open/test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atSgPJRn-OCW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atSgPJRn-OCW",
    "outputId": "87b6f90b-5c1c-4a0e-de54-994458543687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4277, 2154)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_png), len(test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "xv0_rDVq7L5v",
   "metadata": {
    "id": "xv0_rDVq7L5v"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(path +\"open/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "iMhC0nPw7L5w",
   "metadata": {
    "id": "iMhC0nPw7L5w"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "zsmJA3E97L5x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsmJA3E97L5x",
    "outputId": "e0dc61fe-5617-42e8-c8b0-0e95b9f60656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4277/4277 [02:50<00:00, 25.02it/s]\n",
      "100%|██████████| 2154/2154 [01:26<00:00, 25.02it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "KA73Lku9A2N9",
   "metadata": {
    "id": "KA73Lku9A2N9"
   },
   "outputs": [],
   "source": [
    "np.save(path + 'train_imgs_384', np.array(train_imgs))\n",
    "np.save(path + 'test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "L6qBdX7nCp8L",
   "metadata": {
    "id": "L6qBdX7nCp8L"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.load(path + 'train_imgs_384.npy')\n",
    "test_imgs = np.load(path + 'test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sscGLiJKPy6H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sscGLiJKPy6H",
    "outputId": "976516c0-507d-458f-f0c4-6695751605d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평균 0.4330380901867049 0.4034575319032911 0.39415050509784405\n",
      "train 표준편차 0.1815717110252788 0.17403455556798705 0.16323395055036488\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"train 평균\",meanR, meanG, meanB)\n",
    "print(\"train 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "JwVIQCrUSCFE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwVIQCrUSCFE",
    "outputId": "293981ef-7f6a-4602-d208-5fd8473d5261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 평균 0.41825619520929724 0.3931011906330291 0.386631764639131\n",
      "test 표준편차 0.19505524270747931 0.19005280951759498 0.18053225852732663\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"test 평균\",meanR, meanG, meanB)\n",
    "print(\"test 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "VFXzojoo7L5y",
   "metadata": {
    "id": "VFXzojoo7L5y"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "                                     std = [0.181572, 0.174035, 0.163234]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
    "                                     std = [0.195055, 0.190053, 0.185323])\n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('densenet169', pretrained=True, num_classes=88)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('densenet169', pretrained=True, num_classes=88)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38qk8sGbYiO_",
   "metadata": {
    "id": "38qk8sGbYiO_"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "EnOG2n30-Dz5",
   "metadata": {
    "id": "EnOG2n30-Dz5"
   },
   "outputs": [],
   "source": [
    "def main(seed = 2022):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "main(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lkNCkyG9RPzX",
   "metadata": {
    "id": "lkNCkyG9RPzX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /root/.cache/torch/hub/checkpoints/densenet169-b2777c0a.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 75s/7426s\n",
      "TRAIN    loss : 1.16104    f1 : 0.15331\n",
      "Val    loss : 0.72507    f1 : 0.18888\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 70s/6908s\n",
      "TRAIN    loss : 0.65932    f1 : 0.21630\n",
      "Val    loss : 0.50614    f1 : 0.24761\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 73s/7083s\n",
      "TRAIN    loss : 0.49948    f1 : 0.29449\n",
      "Val    loss : 0.44304    f1 : 0.32044\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 70s/6753s\n",
      "TRAIN    loss : 0.43251    f1 : 0.38576\n",
      "Val    loss : 0.51275    f1 : 0.36518\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 69s/6554s\n",
      "TRAIN    loss : 0.36727    f1 : 0.46340\n",
      "Val    loss : 0.32421    f1 : 0.52729\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 68s/6409s\n",
      "TRAIN    loss : 0.29649    f1 : 0.55715\n",
      "Val    loss : 0.24254    f1 : 0.58657\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 71s/6633s\n",
      "TRAIN    loss : 0.26533    f1 : 0.62985\n",
      "Val    loss : 0.29148    f1 : 0.58670\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 69s/6352s\n",
      "TRAIN    loss : 0.20373    f1 : 0.70048\n",
      "Val    loss : 0.25085    f1 : 0.61737\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 71s/6454s\n",
      "TRAIN    loss : 0.21051    f1 : 0.72805\n",
      "Val    loss : 0.23158    f1 : 0.63559\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/100    time : 69s/6219s\n",
      "TRAIN    loss : 0.16900    f1 : 0.77018\n",
      "Val    loss : 0.20266    f1 : 0.70626\n",
      "epoch : 11/100    time : 68s/6011s\n",
      "TRAIN    loss : 0.14579    f1 : 0.80452\n",
      "Val    loss : 0.21476    f1 : 0.64623\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 73s/6434s\n",
      "TRAIN    loss : 0.14105    f1 : 0.80268\n",
      "Val    loss : 0.20068    f1 : 0.72438\n",
      "epoch : 13/100    time : 71s/6163s\n",
      "TRAIN    loss : 0.12610    f1 : 0.84121\n",
      "Val    loss : 0.16116    f1 : 0.71064\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/100    time : 69s/5951s\n",
      "TRAIN    loss : 0.09461    f1 : 0.87735\n",
      "Val    loss : 0.16251    f1 : 0.73357\n",
      "epoch : 15/100    time : 71s/6013s\n",
      "TRAIN    loss : 0.10371    f1 : 0.86462\n",
      "Val    loss : 0.21472    f1 : 0.66325\n",
      "epoch : 16/100    time : 68s/5711s\n",
      "TRAIN    loss : 0.09113    f1 : 0.89085\n",
      "Val    loss : 0.17892    f1 : 0.71062\n",
      "-----------------SAVE:17 epoch----------------\n",
      "epoch : 17/100    time : 71s/5854s\n",
      "TRAIN    loss : 0.07834    f1 : 0.91397\n",
      "Val    loss : 0.12036    f1 : 0.83426\n",
      "epoch : 18/100    time : 72s/5934s\n",
      "TRAIN    loss : 0.08288    f1 : 0.91772\n",
      "Val    loss : 0.12896    f1 : 0.79438\n",
      "epoch : 19/100    time : 69s/5566s\n",
      "TRAIN    loss : 0.08719    f1 : 0.90462\n",
      "Val    loss : 0.14360    f1 : 0.78038\n",
      "epoch : 20/100    time : 71s/5655s\n",
      "TRAIN    loss : 0.05723    f1 : 0.94675\n",
      "Val    loss : 0.16027    f1 : 0.77770\n",
      "epoch : 21/100    time : 68s/5393s\n",
      "TRAIN    loss : 0.06518    f1 : 0.94006\n",
      "Val    loss : 0.12113    f1 : 0.81648\n",
      "epoch : 22/100    time : 69s/5406s\n",
      "TRAIN    loss : 0.06626    f1 : 0.93491\n",
      "Val    loss : 0.15944    f1 : 0.76039\n",
      "epoch : 23/100    time : 67s/5158s\n",
      "TRAIN    loss : 0.06047    f1 : 0.93463\n",
      "Val    loss : 0.13982    f1 : 0.75325\n",
      "epoch : 24/100    time : 69s/5242s\n",
      "TRAIN    loss : 0.03731    f1 : 0.95593\n",
      "Val    loss : 0.16100    f1 : 0.75808\n",
      "epoch : 25/100    time : 70s/5267s\n",
      "TRAIN    loss : 0.05005    f1 : 0.95437\n",
      "Val    loss : 0.17076    f1 : 0.70900\n",
      "epoch : 26/100    time : 68s/5041s\n",
      "TRAIN    loss : 0.05561    f1 : 0.94268\n",
      "Val    loss : 0.14574    f1 : 0.74413\n",
      "epoch : 27/100    time : 69s/5073s\n",
      "TRAIN    loss : 0.02863    f1 : 0.96930\n",
      "Val    loss : 0.15136    f1 : 0.76966\n",
      "epoch : 28/100    time : 70s/5020s\n",
      "TRAIN    loss : 0.01887    f1 : 0.97769\n",
      "Val    loss : 0.25589    f1 : 0.73505\n",
      "epoch : 29/100    time : 69s/4906s\n",
      "TRAIN    loss : 0.04742    f1 : 0.93628\n",
      "Val    loss : 0.18665    f1 : 0.71832\n",
      "epoch : 30/100    time : 72s/5046s\n",
      "TRAIN    loss : 0.04150    f1 : 0.95902\n",
      "Val    loss : 0.18408    f1 : 0.72266\n",
      "epoch : 31/100    time : 71s/4927s\n",
      "TRAIN    loss : 0.04570    f1 : 0.95146\n",
      "Val    loss : 0.21562    f1 : 0.73896\n",
      "epoch : 32/100    time : 68s/4656s\n",
      "TRAIN    loss : 0.03475    f1 : 0.96651\n",
      "Val    loss : 0.21929    f1 : 0.73867\n",
      "epoch : 33/100    time : 71s/4774s\n",
      "TRAIN    loss : 0.05273    f1 : 0.94546\n",
      "Val    loss : 0.15730    f1 : 0.77353\n",
      "epoch : 34/100    time : 68s/4482s\n",
      "TRAIN    loss : 0.05069    f1 : 0.95132\n",
      "Val    loss : 0.21263    f1 : 0.67336\n",
      "epoch : 35/100    time : 71s/4595s\n",
      "TRAIN    loss : 0.04838    f1 : 0.94774\n",
      "Val    loss : 0.23837    f1 : 0.72730\n",
      "epoch : 36/100    time : 68s/4322s\n",
      "TRAIN    loss : 0.05232    f1 : 0.94455\n",
      "Val    loss : 0.17392    f1 : 0.75963\n",
      "epoch : 37/100    time : 68s/4272s\n",
      "TRAIN    loss : 0.03715    f1 : 0.95566\n",
      "Val    loss : 0.17236    f1 : 0.75403\n",
      "----------fold_1 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 71s/7076s\n",
      "TRAIN    loss : 1.20132    f1 : 0.15241\n",
      "Val    loss : 0.68143    f1 : 0.16786\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 69s/6764s\n",
      "TRAIN    loss : 0.64959    f1 : 0.21202\n",
      "Val    loss : 0.58884    f1 : 0.23507\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 71s/6919s\n",
      "TRAIN    loss : 0.50687    f1 : 0.29723\n",
      "Val    loss : 0.42507    f1 : 0.29871\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 71s/6822s\n",
      "TRAIN    loss : 0.42504    f1 : 0.39258\n",
      "Val    loss : 0.34025    f1 : 0.50246\n",
      "epoch : 5/100    time : 69s/6576s\n",
      "TRAIN    loss : 0.32311    f1 : 0.51467\n",
      "Val    loss : 0.31919    f1 : 0.45369\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 70s/6614s\n",
      "TRAIN    loss : 0.27738    f1 : 0.58031\n",
      "Val    loss : 0.28550    f1 : 0.56200\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 72s/6699s\n",
      "TRAIN    loss : 0.25859    f1 : 0.61874\n",
      "Val    loss : 0.28186    f1 : 0.57667\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 74s/6766s\n",
      "TRAIN    loss : 0.20367    f1 : 0.68934\n",
      "Val    loss : 0.23108    f1 : 0.63227\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 71s/6487s\n",
      "TRAIN    loss : 0.17607    f1 : 0.75006\n",
      "Val    loss : 0.25799    f1 : 0.69726\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/100    time : 70s/6279s\n",
      "TRAIN    loss : 0.14941    f1 : 0.78535\n",
      "Val    loss : 0.20429    f1 : 0.72719\n",
      "epoch : 11/100    time : 73s/6453s\n",
      "TRAIN    loss : 0.13414    f1 : 0.80331\n",
      "Val    loss : 0.19748    f1 : 0.66235\n",
      "epoch : 12/100    time : 69s/6089s\n",
      "TRAIN    loss : 0.13621    f1 : 0.81443\n",
      "Val    loss : 0.20614    f1 : 0.67019\n",
      "epoch : 13/100    time : 71s/6188s\n",
      "TRAIN    loss : 0.11056    f1 : 0.87538\n",
      "Val    loss : 0.17464    f1 : 0.72138\n",
      "epoch : 14/100    time : 71s/6087s\n",
      "TRAIN    loss : 0.09789    f1 : 0.88033\n",
      "Val    loss : 0.23651    f1 : 0.70665\n",
      "epoch : 15/100    time : 68s/5779s\n",
      "TRAIN    loss : 0.09781    f1 : 0.88383\n",
      "Val    loss : 0.18387    f1 : 0.70453\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/100    time : 72s/6064s\n",
      "TRAIN    loss : 0.11414    f1 : 0.86373\n",
      "Val    loss : 0.18813    f1 : 0.75545\n",
      "-----------------SAVE:17 epoch----------------\n",
      "epoch : 17/100    time : 70s/5769s\n",
      "TRAIN    loss : 0.07727    f1 : 0.89114\n",
      "Val    loss : 0.16577    f1 : 0.77806\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/100    time : 70s/5777s\n",
      "TRAIN    loss : 0.06289    f1 : 0.91726\n",
      "Val    loss : 0.14732    f1 : 0.78773\n",
      "epoch : 19/100    time : 72s/5825s\n",
      "TRAIN    loss : 0.05878    f1 : 0.91632\n",
      "Val    loss : 0.17535    f1 : 0.77806\n",
      "-----------------SAVE:20 epoch----------------\n",
      "epoch : 20/100    time : 69s/5540s\n",
      "TRAIN    loss : 0.05906    f1 : 0.93248\n",
      "Val    loss : 0.16292    f1 : 0.79027\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/100    time : 72s/5655s\n",
      "TRAIN    loss : 0.04851    f1 : 0.93688\n",
      "Val    loss : 0.15409    f1 : 0.79716\n",
      "epoch : 22/100    time : 68s/5318s\n",
      "TRAIN    loss : 0.04375    f1 : 0.96175\n",
      "Val    loss : 0.19326    f1 : 0.73794\n",
      "epoch : 23/100    time : 69s/5341s\n",
      "TRAIN    loss : 0.05257    f1 : 0.93692\n",
      "Val    loss : 0.20501    f1 : 0.74340\n",
      "epoch : 24/100    time : 70s/5346s\n",
      "TRAIN    loss : 0.06571    f1 : 0.94702\n",
      "Val    loss : 0.18215    f1 : 0.75058\n",
      "epoch : 25/100    time : 69s/5157s\n",
      "TRAIN    loss : 0.03942    f1 : 0.96292\n",
      "Val    loss : 0.16055    f1 : 0.79223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:26 epoch----------------\n",
      "epoch : 26/100    time : 73s/5372s\n",
      "TRAIN    loss : 0.01970    f1 : 0.97772\n",
      "Val    loss : 0.13455    f1 : 0.82897\n",
      "epoch : 27/100    time : 70s/5138s\n",
      "TRAIN    loss : 0.04344    f1 : 0.96832\n",
      "Val    loss : 0.23859    f1 : 0.75107\n",
      "epoch : 28/100    time : 69s/4949s\n",
      "TRAIN    loss : 0.04771    f1 : 0.94310\n",
      "Val    loss : 0.20809    f1 : 0.75261\n",
      "epoch : 29/100    time : 71s/5062s\n",
      "TRAIN    loss : 0.03820    f1 : 0.96113\n",
      "Val    loss : 0.19170    f1 : 0.79338\n",
      "epoch : 30/100    time : 70s/4874s\n",
      "TRAIN    loss : 0.05775    f1 : 0.93577\n",
      "Val    loss : 0.33752    f1 : 0.72614\n",
      "epoch : 31/100    time : 72s/4998s\n",
      "TRAIN    loss : 0.05411    f1 : 0.92900\n",
      "Val    loss : 0.16974    f1 : 0.76014\n",
      "epoch : 32/100    time : 68s/4625s\n",
      "TRAIN    loss : 0.03319    f1 : 0.96255\n",
      "Val    loss : 0.35787    f1 : 0.75274\n",
      "epoch : 33/100    time : 69s/4611s\n",
      "TRAIN    loss : 0.04190    f1 : 0.96090\n",
      "Val    loss : 0.17792    f1 : 0.80731\n",
      "epoch : 34/100    time : 71s/4692s\n",
      "TRAIN    loss : 0.02626    f1 : 0.97837\n",
      "Val    loss : 0.73840    f1 : 0.73755\n",
      "epoch : 35/100    time : 70s/4557s\n",
      "TRAIN    loss : 0.06475    f1 : 0.94409\n",
      "Val    loss : 0.27400    f1 : 0.73905\n",
      "epoch : 36/100    time : 69s/4448s\n",
      "TRAIN    loss : 0.02813    f1 : 0.96918\n",
      "Val    loss : 0.18235    f1 : 0.79821\n",
      "epoch : 37/100    time : 70s/4439s\n",
      "TRAIN    loss : 0.02271    f1 : 0.96623\n",
      "Val    loss : 0.20794    f1 : 0.75543\n",
      "epoch : 38/100    time : 69s/4296s\n",
      "TRAIN    loss : 0.02244    f1 : 0.96636\n",
      "Val    loss : 0.17603    f1 : 0.81133\n",
      "-----------------SAVE:39 epoch----------------\n",
      "epoch : 39/100    time : 70s/4291s\n",
      "TRAIN    loss : 0.03089    f1 : 0.97406\n",
      "Val    loss : 0.14861    f1 : 0.84859\n",
      "epoch : 40/100    time : 69s/4123s\n",
      "TRAIN    loss : 0.01666    f1 : 0.98354\n",
      "Val    loss : 0.20836    f1 : 0.80909\n",
      "epoch : 41/100    time : 69s/4072s\n",
      "TRAIN    loss : 0.03153    f1 : 0.97437\n",
      "Val    loss : 0.17910    f1 : 0.79240\n",
      "epoch : 42/100    time : 70s/4081s\n",
      "TRAIN    loss : 0.01113    f1 : 0.98878\n",
      "Val    loss : 0.17674    f1 : 0.81196\n",
      "epoch : 43/100    time : 69s/3943s\n",
      "TRAIN    loss : 0.02769    f1 : 0.97584\n",
      "Val    loss : 0.20138    f1 : 0.77845\n",
      "epoch : 44/100    time : 70s/3928s\n",
      "TRAIN    loss : 0.05178    f1 : 0.94042\n",
      "Val    loss : 0.23321    f1 : 0.76245\n",
      "epoch : 45/100    time : 70s/3826s\n",
      "TRAIN    loss : 0.03692    f1 : 0.96240\n",
      "Val    loss : 0.22905    f1 : 0.78789\n",
      "epoch : 46/100    time : 70s/3788s\n",
      "TRAIN    loss : 0.02999    f1 : 0.97493\n",
      "Val    loss : 0.21187    f1 : 0.78428\n",
      "epoch : 47/100    time : 70s/3735s\n",
      "TRAIN    loss : 0.03075    f1 : 0.97198\n",
      "Val    loss : 0.23612    f1 : 0.72569\n",
      "epoch : 48/100    time : 71s/3667s\n",
      "TRAIN    loss : 0.04247    f1 : 0.95553\n",
      "Val    loss : 0.23366    f1 : 0.81201\n",
      "epoch : 49/100    time : 69s/3510s\n",
      "TRAIN    loss : 0.03289    f1 : 0.96839\n",
      "Val    loss : 0.21892    f1 : 0.77577\n",
      "epoch : 50/100    time : 71s/3537s\n",
      "TRAIN    loss : 0.03262    f1 : 0.96644\n",
      "Val    loss : 0.20413    f1 : 0.76126\n",
      "epoch : 51/100    time : 69s/3371s\n",
      "TRAIN    loss : 0.02083    f1 : 0.98261\n",
      "Val    loss : 0.19337    f1 : 0.76428\n",
      "epoch : 52/100    time : 71s/3385s\n",
      "TRAIN    loss : 0.02994    f1 : 0.96928\n",
      "Val    loss : 0.20805    f1 : 0.80639\n",
      "epoch : 53/100    time : 68s/3218s\n",
      "TRAIN    loss : 0.02580    f1 : 0.96335\n",
      "Val    loss : 0.21592    f1 : 0.78222\n",
      "epoch : 54/100    time : 69s/3153s\n",
      "TRAIN    loss : 0.02411    f1 : 0.97808\n",
      "Val    loss : 0.17266    f1 : 0.81335\n",
      "epoch : 55/100    time : 71s/3178s\n",
      "TRAIN    loss : 0.02358    f1 : 0.97895\n",
      "Val    loss : 0.21271    f1 : 0.79868\n",
      "epoch : 56/100    time : 69s/3032s\n",
      "TRAIN    loss : 0.02824    f1 : 0.97420\n",
      "Val    loss : 0.23751    f1 : 0.74074\n",
      "epoch : 57/100    time : 70s/3029s\n",
      "TRAIN    loss : 0.04348    f1 : 0.96208\n",
      "Val    loss : 0.24824    f1 : 0.75158\n",
      "epoch : 58/100    time : 70s/2923s\n",
      "TRAIN    loss : 0.02068    f1 : 0.97537\n",
      "Val    loss : 0.13444    f1 : 0.81835\n",
      "epoch : 59/100    time : 70s/2878s\n",
      "TRAIN    loss : 0.02929    f1 : 0.97627\n",
      "Val    loss : 0.22960    f1 : 0.75942\n",
      "----------fold_2 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 76s/7491s\n",
      "TRAIN    loss : 1.17394    f1 : 0.15322\n",
      "Val    loss : 0.71398    f1 : 0.18707\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 68s/6659s\n",
      "TRAIN    loss : 0.65167    f1 : 0.21795\n",
      "Val    loss : 0.60355    f1 : 0.23182\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 71s/6844s\n",
      "TRAIN    loss : 0.48854    f1 : 0.29797\n",
      "Val    loss : 0.41278    f1 : 0.31971\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 69s/6585s\n",
      "TRAIN    loss : 0.39170    f1 : 0.40824\n",
      "Val    loss : 0.32767    f1 : 0.50691\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 69s/6592s\n",
      "TRAIN    loss : 0.33379    f1 : 0.47703\n",
      "Val    loss : 0.29337    f1 : 0.52068\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 71s/6666s\n",
      "TRAIN    loss : 0.28453    f1 : 0.60394\n",
      "Val    loss : 0.28758    f1 : 0.57595\n",
      "epoch : 7/100    time : 68s/6324s\n",
      "TRAIN    loss : 0.25627    f1 : 0.60365\n",
      "Val    loss : 0.27135    f1 : 0.55299\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 69s/6336s\n",
      "TRAIN    loss : 0.21229    f1 : 0.68402\n",
      "Val    loss : 0.21260    f1 : 0.59478\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 71s/6427s\n",
      "TRAIN    loss : 0.16181    f1 : 0.75604\n",
      "Val    loss : 0.20935    f1 : 0.64976\n",
      "epoch : 10/100    time : 68s/6140s\n",
      "TRAIN    loss : 0.15037    f1 : 0.77412\n",
      "Val    loss : 0.21135    f1 : 0.63919\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 71s/6279s\n",
      "TRAIN    loss : 0.11815    f1 : 0.80970\n",
      "Val    loss : 0.20949    f1 : 0.68840\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 70s/6163s\n",
      "TRAIN    loss : 0.12749    f1 : 0.82496\n",
      "Val    loss : 0.26962    f1 : 0.68952\n",
      "epoch : 13/100    time : 70s/6049s\n",
      "TRAIN    loss : 0.10908    f1 : 0.83350\n",
      "Val    loss : 0.20328    f1 : 0.68455\n",
      "epoch : 14/100    time : 70s/6013s\n",
      "TRAIN    loss : 0.09357    f1 : 0.88057\n",
      "Val    loss : 0.19578    f1 : 0.67405\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/100    time : 70s/5960s\n",
      "TRAIN    loss : 0.08823    f1 : 0.89223\n",
      "Val    loss : 0.17271    f1 : 0.72900\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/100    time : 71s/5963s\n",
      "TRAIN    loss : 0.07038    f1 : 0.93114\n",
      "Val    loss : 0.13959    f1 : 0.75490\n",
      "epoch : 17/100    time : 69s/5717s\n",
      "TRAIN    loss : 0.07903    f1 : 0.91055\n",
      "Val    loss : 0.19952    f1 : 0.67326\n",
      "epoch : 18/100    time : 69s/5675s\n",
      "TRAIN    loss : 0.08583    f1 : 0.88872\n",
      "Val    loss : 0.25823    f1 : 0.69427\n",
      "epoch : 19/100    time : 69s/5620s\n",
      "TRAIN    loss : 0.08320    f1 : 0.90141\n",
      "Val    loss : 0.17166    f1 : 0.74103\n",
      "epoch : 20/100    time : 68s/5447s\n",
      "TRAIN    loss : 0.06074    f1 : 0.93252\n",
      "Val    loss : 0.18482    f1 : 0.73353\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/100    time : 71s/5639s\n",
      "TRAIN    loss : 0.06568    f1 : 0.91595\n",
      "Val    loss : 0.14933    f1 : 0.80053\n",
      "-----------------SAVE:22 epoch----------------\n",
      "epoch : 22/100    time : 68s/5331s\n",
      "TRAIN    loss : 0.06511    f1 : 0.91897\n",
      "Val    loss : 0.15872    f1 : 0.80520\n",
      "epoch : 23/100    time : 70s/5371s\n",
      "TRAIN    loss : 0.05171    f1 : 0.93660\n",
      "Val    loss : 0.17611    f1 : 0.75784\n",
      "-----------------SAVE:24 epoch----------------\n",
      "epoch : 24/100    time : 71s/5426s\n",
      "TRAIN    loss : 0.02962    f1 : 0.96720\n",
      "Val    loss : 0.12398    f1 : 0.84792\n",
      "epoch : 25/100    time : 69s/5168s\n",
      "TRAIN    loss : 0.08409    f1 : 0.90555\n",
      "Val    loss : 0.16147    f1 : 0.74051\n",
      "epoch : 26/100    time : 69s/5092s\n",
      "TRAIN    loss : 0.03955    f1 : 0.96509\n",
      "Val    loss : 0.16560    f1 : 0.75505\n",
      "epoch : 27/100    time : 70s/5113s\n",
      "TRAIN    loss : 0.03347    f1 : 0.97088\n",
      "Val    loss : 0.13579    f1 : 0.81247\n",
      "epoch : 28/100    time : 68s/4876s\n",
      "TRAIN    loss : 0.03003    f1 : 0.96529\n",
      "Val    loss : 0.16920    f1 : 0.78479\n",
      "epoch : 29/100    time : 70s/4984s\n",
      "TRAIN    loss : 0.02421    f1 : 0.98398\n",
      "Val    loss : 0.18658    f1 : 0.78334\n",
      "epoch : 30/100    time : 67s/4705s\n",
      "TRAIN    loss : 0.03107    f1 : 0.97396\n",
      "Val    loss : 0.17716    f1 : 0.76979\n",
      "epoch : 31/100    time : 68s/4668s\n",
      "TRAIN    loss : 0.06796    f1 : 0.94080\n",
      "Val    loss : 0.22296    f1 : 0.74004\n",
      "epoch : 32/100    time : 69s/4719s\n",
      "TRAIN    loss : 0.05841    f1 : 0.93620\n",
      "Val    loss : 0.19491    f1 : 0.75886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 33/100    time : 68s/4580s\n",
      "TRAIN    loss : 0.04514    f1 : 0.95266\n",
      "Val    loss : 0.18316    f1 : 0.76871\n",
      "epoch : 34/100    time : 71s/4709s\n",
      "TRAIN    loss : 0.03429    f1 : 0.96509\n",
      "Val    loss : 0.16442    f1 : 0.76777\n",
      "epoch : 35/100    time : 68s/4439s\n",
      "TRAIN    loss : 0.03026    f1 : 0.97261\n",
      "Val    loss : 0.15393    f1 : 0.81584\n",
      "epoch : 36/100    time : 69s/4432s\n",
      "TRAIN    loss : 0.05035    f1 : 0.94786\n",
      "Val    loss : 0.19187    f1 : 0.78920\n",
      "epoch : 37/100    time : 71s/4491s\n",
      "TRAIN    loss : 0.02772    f1 : 0.97043\n",
      "Val    loss : 0.19563    f1 : 0.76044\n",
      "epoch : 38/100    time : 69s/4295s\n",
      "TRAIN    loss : 0.04322    f1 : 0.95700\n",
      "Val    loss : 0.19861    f1 : 0.75087\n",
      "epoch : 39/100    time : 70s/4247s\n",
      "TRAIN    loss : 0.06038    f1 : 0.93711\n",
      "Val    loss : 0.18050    f1 : 0.79927\n",
      "epoch : 40/100    time : 71s/4232s\n",
      "TRAIN    loss : 0.01850    f1 : 0.98764\n",
      "Val    loss : 0.16769    f1 : 0.78469\n",
      "epoch : 41/100    time : 68s/4012s\n",
      "TRAIN    loss : 0.02706    f1 : 0.97412\n",
      "Val    loss : 0.14496    f1 : 0.83200\n",
      "epoch : 42/100    time : 70s/4073s\n",
      "TRAIN    loss : 0.00865    f1 : 0.99420\n",
      "Val    loss : 0.14774    f1 : 0.84583\n",
      "epoch : 43/100    time : 69s/3908s\n",
      "TRAIN    loss : 0.01939    f1 : 0.98297\n",
      "Val    loss : 0.15948    f1 : 0.82167\n",
      "epoch : 44/100    time : 69s/3884s\n",
      "TRAIN    loss : 0.02230    f1 : 0.97973\n",
      "Val    loss : 0.19012    f1 : 0.80892\n",
      "----------fold_3 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 73s/7236s\n",
      "TRAIN    loss : 1.15492    f1 : 0.15517\n",
      "Val    loss : 0.69575    f1 : 0.17943\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 70s/6814s\n",
      "TRAIN    loss : 0.65156    f1 : 0.20519\n",
      "Val    loss : 0.45504    f1 : 0.26277\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 71s/6860s\n",
      "TRAIN    loss : 0.48663    f1 : 0.29855\n",
      "Val    loss : 0.41093    f1 : 0.34677\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 70s/6676s\n",
      "TRAIN    loss : 0.39274    f1 : 0.41210\n",
      "Val    loss : 0.36430    f1 : 0.41685\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 71s/6784s\n",
      "TRAIN    loss : 0.32171    f1 : 0.50402\n",
      "Val    loss : 0.37547    f1 : 0.50495\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 71s/6672s\n",
      "TRAIN    loss : 0.28525    f1 : 0.59853\n",
      "Val    loss : 0.28521    f1 : 0.53453\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 70s/6484s\n",
      "TRAIN    loss : 0.22997    f1 : 0.65715\n",
      "Val    loss : 0.23520    f1 : 0.61142\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 71s/6542s\n",
      "TRAIN    loss : 0.19914    f1 : 0.71297\n",
      "Val    loss : 0.25211    f1 : 0.68259\n",
      "epoch : 9/100    time : 70s/6379s\n",
      "TRAIN    loss : 0.18230    f1 : 0.72532\n",
      "Val    loss : 0.21049    f1 : 0.64991\n",
      "epoch : 10/100    time : 68s/6081s\n",
      "TRAIN    loss : 0.17386    f1 : 0.77005\n",
      "Val    loss : 0.21919    f1 : 0.66854\n",
      "epoch : 11/100    time : 71s/6278s\n",
      "TRAIN    loss : 0.15536    f1 : 0.77745\n",
      "Val    loss : 0.26228    f1 : 0.67607\n",
      "epoch : 12/100    time : 68s/5981s\n",
      "TRAIN    loss : 0.12565    f1 : 0.84454\n",
      "Val    loss : 0.22868    f1 : 0.65013\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/100    time : 68s/5951s\n",
      "TRAIN    loss : 0.10967    f1 : 0.86206\n",
      "Val    loss : 0.18729    f1 : 0.73636\n",
      "epoch : 14/100    time : 71s/6080s\n",
      "TRAIN    loss : 0.08894    f1 : 0.89186\n",
      "Val    loss : 0.28670    f1 : 0.71495\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/100    time : 69s/5857s\n",
      "TRAIN    loss : 0.08614    f1 : 0.89200\n",
      "Val    loss : 0.21872    f1 : 0.74610\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/100    time : 72s/6061s\n",
      "TRAIN    loss : 0.08562    f1 : 0.91011\n",
      "Val    loss : 0.20471    f1 : 0.75280\n",
      "epoch : 17/100    time : 68s/5679s\n",
      "TRAIN    loss : 0.07105    f1 : 0.91795\n",
      "Val    loss : 0.22529    f1 : 0.71975\n",
      "epoch : 18/100    time : 68s/5580s\n",
      "TRAIN    loss : 0.07454    f1 : 0.89175\n",
      "Val    loss : 0.20200    f1 : 0.74294\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/100    time : 72s/5796s\n",
      "TRAIN    loss : 0.07351    f1 : 0.92725\n",
      "Val    loss : 0.18772    f1 : 0.78621\n",
      "-----------------SAVE:20 epoch----------------\n",
      "epoch : 20/100    time : 71s/5679s\n",
      "TRAIN    loss : 0.05240    f1 : 0.93847\n",
      "Val    loss : 0.22530    f1 : 0.80549\n",
      "epoch : 21/100    time : 71s/5621s\n",
      "TRAIN    loss : 0.06373    f1 : 0.94157\n",
      "Val    loss : 0.19228    f1 : 0.76190\n",
      "epoch : 22/100    time : 68s/5283s\n",
      "TRAIN    loss : 0.04475    f1 : 0.95640\n",
      "Val    loss : 0.16620    f1 : 0.77310\n",
      "epoch : 23/100    time : 69s/5285s\n",
      "TRAIN    loss : 0.04447    f1 : 0.95691\n",
      "Val    loss : 0.19468    f1 : 0.75966\n",
      "epoch : 24/100    time : 72s/5503s\n",
      "TRAIN    loss : 0.06180    f1 : 0.94350\n",
      "Val    loss : 0.24203    f1 : 0.70817\n",
      "epoch : 25/100    time : 68s/5125s\n",
      "TRAIN    loss : 0.06266    f1 : 0.92957\n",
      "Val    loss : 0.18941    f1 : 0.80144\n",
      "-----------------SAVE:26 epoch----------------\n",
      "epoch : 26/100    time : 71s/5220s\n",
      "TRAIN    loss : 0.04260    f1 : 0.95396\n",
      "Val    loss : 0.16541    f1 : 0.84252\n",
      "epoch : 27/100    time : 68s/4939s\n",
      "TRAIN    loss : 0.05153    f1 : 0.94165\n",
      "Val    loss : 0.18436    f1 : 0.77565\n",
      "epoch : 28/100    time : 68s/4911s\n",
      "TRAIN    loss : 0.03838    f1 : 0.95647\n",
      "Val    loss : 0.22165    f1 : 0.78168\n",
      "epoch : 29/100    time : 72s/5082s\n",
      "TRAIN    loss : 0.04135    f1 : 0.94589\n",
      "Val    loss : 0.18341    f1 : 0.76544\n",
      "epoch : 30/100    time : 69s/4811s\n",
      "TRAIN    loss : 0.04274    f1 : 0.95766\n",
      "Val    loss : 0.17724    f1 : 0.78204\n",
      "epoch : 31/100    time : 70s/4813s\n",
      "TRAIN    loss : 0.06147    f1 : 0.93669\n",
      "Val    loss : 0.29509    f1 : 0.66031\n",
      "epoch : 32/100    time : 71s/4853s\n",
      "TRAIN    loss : 0.06402    f1 : 0.94140\n",
      "Val    loss : 0.21640    f1 : 0.73685\n",
      "epoch : 33/100    time : 71s/4748s\n",
      "TRAIN    loss : 0.02900    f1 : 0.97729\n",
      "Val    loss : 0.19893    f1 : 0.79772\n",
      "epoch : 34/100    time : 71s/4718s\n",
      "TRAIN    loss : 0.03443    f1 : 0.96474\n",
      "Val    loss : 0.19598    f1 : 0.80831\n",
      "epoch : 35/100    time : 69s/4515s\n",
      "TRAIN    loss : 0.02858    f1 : 0.97554\n",
      "Val    loss : 0.17863    f1 : 0.80498\n",
      "epoch : 36/100    time : 67s/4301s\n",
      "TRAIN    loss : 0.04217    f1 : 0.96602\n",
      "Val    loss : 0.17962    f1 : 0.79676\n",
      "epoch : 37/100    time : 70s/4394s\n",
      "TRAIN    loss : 0.02090    f1 : 0.98055\n",
      "Val    loss : 0.18393    f1 : 0.79467\n",
      "epoch : 38/100    time : 69s/4300s\n",
      "TRAIN    loss : 0.04891    f1 : 0.95393\n",
      "Val    loss : 0.17869    f1 : 0.78541\n",
      "epoch : 39/100    time : 72s/4386s\n",
      "TRAIN    loss : 0.01924    f1 : 0.97915\n",
      "Val    loss : 0.25922    f1 : 0.70556\n",
      "epoch : 40/100    time : 69s/4163s\n",
      "TRAIN    loss : 0.03723    f1 : 0.96406\n",
      "Val    loss : 0.45889    f1 : 0.73380\n",
      "epoch : 41/100    time : 68s/4038s\n",
      "TRAIN    loss : 0.05013    f1 : 0.94936\n",
      "Val    loss : 0.20893    f1 : 0.76195\n",
      "epoch : 42/100    time : 70s/4078s\n",
      "TRAIN    loss : 0.04431    f1 : 0.95778\n",
      "Val    loss : 0.24024    f1 : 0.72277\n",
      "epoch : 43/100    time : 68s/3899s\n",
      "TRAIN    loss : 0.02220    f1 : 0.98266\n",
      "Val    loss : 0.22431    f1 : 0.81222\n",
      "epoch : 44/100    time : 69s/3858s\n",
      "TRAIN    loss : 0.03786    f1 : 0.96549\n",
      "Val    loss : 0.22903    f1 : 0.75223\n",
      "epoch : 45/100    time : 70s/3823s\n",
      "TRAIN    loss : 0.05934    f1 : 0.93372\n",
      "Val    loss : 0.18091    f1 : 0.75606\n",
      "epoch : 46/100    time : 67s/3634s\n",
      "TRAIN    loss : 0.02712    f1 : 0.96546\n",
      "Val    loss : 0.21528    f1 : 0.79011\n",
      "----------fold_4 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 71s/7036s\n",
      "TRAIN    loss : 1.19416    f1 : 0.15177\n",
      "Val    loss : 0.79534    f1 : 0.17833\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 69s/6790s\n",
      "TRAIN    loss : 0.67394    f1 : 0.20535\n",
      "Val    loss : 0.71534    f1 : 0.25300\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 70s/6782s\n",
      "TRAIN    loss : 0.50982    f1 : 0.30897\n",
      "Val    loss : 0.59888    f1 : 0.36204\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 71s/6834s\n",
      "TRAIN    loss : 0.40995    f1 : 0.40605\n",
      "Val    loss : 0.47335    f1 : 0.39580\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 69s/6549s\n",
      "TRAIN    loss : 0.33973    f1 : 0.48933\n",
      "Val    loss : 0.43282    f1 : 0.49344\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 73s/6828s\n",
      "TRAIN    loss : 0.29049    f1 : 0.59280\n",
      "Val    loss : 0.42908    f1 : 0.50644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 72s/6659s\n",
      "TRAIN    loss : 0.22914    f1 : 0.65959\n",
      "Val    loss : 0.23400    f1 : 0.60990\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 70s/6418s\n",
      "TRAIN    loss : 0.18860    f1 : 0.73469\n",
      "Val    loss : 0.24111    f1 : 0.68701\n",
      "epoch : 9/100    time : 70s/6413s\n",
      "TRAIN    loss : 0.17390    f1 : 0.73986\n",
      "Val    loss : 0.19399    f1 : 0.63250\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/100    time : 72s/6437s\n",
      "TRAIN    loss : 0.14077    f1 : 0.79045\n",
      "Val    loss : 0.22849    f1 : 0.71354\n",
      "epoch : 11/100    time : 71s/6318s\n",
      "TRAIN    loss : 0.13380    f1 : 0.83493\n",
      "Val    loss : 0.25458    f1 : 0.65347\n",
      "epoch : 12/100    time : 70s/6137s\n",
      "TRAIN    loss : 0.11937    f1 : 0.83978\n",
      "Val    loss : 0.17342    f1 : 0.70465\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/100    time : 70s/6117s\n",
      "TRAIN    loss : 0.09362    f1 : 0.87757\n",
      "Val    loss : 0.18081    f1 : 0.73172\n",
      "epoch : 14/100    time : 71s/6122s\n",
      "TRAIN    loss : 0.10585    f1 : 0.85619\n",
      "Val    loss : 0.18963    f1 : 0.69403\n",
      "epoch : 15/100    time : 69s/5847s\n",
      "TRAIN    loss : 0.08912    f1 : 0.89709\n",
      "Val    loss : 0.43623    f1 : 0.68118\n",
      "epoch : 16/100    time : 71s/5958s\n",
      "TRAIN    loss : 0.07419    f1 : 0.92333\n",
      "Val    loss : 0.25598    f1 : 0.71538\n",
      "epoch : 17/100    time : 68s/5647s\n",
      "TRAIN    loss : 0.09095    f1 : 0.88692\n",
      "Val    loss : 0.24650    f1 : 0.65024\n",
      "epoch : 18/100    time : 69s/5628s\n",
      "TRAIN    loss : 0.07594    f1 : 0.91440\n",
      "Val    loss : 0.22162    f1 : 0.70607\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/100    time : 71s/5732s\n",
      "TRAIN    loss : 0.08122    f1 : 0.91298\n",
      "Val    loss : 0.17552    f1 : 0.78405\n",
      "epoch : 20/100    time : 68s/5434s\n",
      "TRAIN    loss : 0.05651    f1 : 0.94145\n",
      "Val    loss : 0.16249    f1 : 0.77235\n",
      "epoch : 21/100    time : 69s/5481s\n",
      "TRAIN    loss : 0.04140    f1 : 0.95808\n",
      "Val    loss : 0.21664    f1 : 0.73857\n",
      "epoch : 22/100    time : 70s/5437s\n",
      "TRAIN    loss : 0.08327    f1 : 0.90173\n",
      "Val    loss : 0.25719    f1 : 0.74281\n",
      "epoch : 23/100    time : 68s/5255s\n",
      "TRAIN    loss : 0.04437    f1 : 0.96486\n",
      "Val    loss : 0.19668    f1 : 0.74302\n",
      "epoch : 24/100    time : 70s/5348s\n",
      "TRAIN    loss : 0.04408    f1 : 0.94998\n",
      "Val    loss : 0.20615    f1 : 0.75576\n",
      "epoch : 25/100    time : 70s/5246s\n",
      "TRAIN    loss : 0.05693    f1 : 0.93348\n",
      "Val    loss : 0.23866    f1 : 0.71002\n",
      "epoch : 26/100    time : 70s/5175s\n",
      "TRAIN    loss : 0.06374    f1 : 0.93729\n",
      "Val    loss : 0.16643    f1 : 0.75096\n",
      "epoch : 27/100    time : 72s/5227s\n",
      "TRAIN    loss : 0.04742    f1 : 0.95535\n",
      "Val    loss : 0.20156    f1 : 0.77086\n",
      "epoch : 28/100    time : 68s/4924s\n",
      "TRAIN    loss : 0.03777    f1 : 0.95679\n",
      "Val    loss : 0.21511    f1 : 0.71235\n",
      "epoch : 29/100    time : 70s/4986s\n",
      "TRAIN    loss : 0.04743    f1 : 0.95287\n",
      "Val    loss : 0.22465    f1 : 0.74730\n",
      "-----------------SAVE:30 epoch----------------\n",
      "epoch : 30/100    time : 70s/4880s\n",
      "TRAIN    loss : 0.04191    f1 : 0.96223\n",
      "Val    loss : 0.21761    f1 : 0.79625\n",
      "-----------------SAVE:31 epoch----------------\n",
      "epoch : 31/100    time : 69s/4750s\n",
      "TRAIN    loss : 0.02077    f1 : 0.98274\n",
      "Val    loss : 0.14785    f1 : 0.84766\n",
      "epoch : 32/100    time : 70s/4792s\n",
      "TRAIN    loss : 0.04303    f1 : 0.96164\n",
      "Val    loss : 0.20817    f1 : 0.73952\n",
      "epoch : 33/100    time : 69s/4632s\n",
      "TRAIN    loss : 0.05664    f1 : 0.95742\n",
      "Val    loss : 0.18267    f1 : 0.76117\n",
      "epoch : 34/100    time : 69s/4530s\n",
      "TRAIN    loss : 0.03355    f1 : 0.97100\n",
      "Val    loss : 0.27258    f1 : 0.74985\n",
      "epoch : 35/100    time : 70s/4545s\n",
      "TRAIN    loss : 0.06471    f1 : 0.93981\n",
      "Val    loss : 0.16975    f1 : 0.80207\n",
      "epoch : 36/100    time : 70s/4452s\n",
      "TRAIN    loss : 0.02779    f1 : 0.97687\n",
      "Val    loss : 0.29588    f1 : 0.74756\n",
      "epoch : 37/100    time : 70s/4395s\n",
      "TRAIN    loss : 0.03624    f1 : 0.96130\n",
      "Val    loss : 0.15420    f1 : 0.83578\n",
      "epoch : 38/100    time : 69s/4253s\n",
      "TRAIN    loss : 0.04139    f1 : 0.95794\n",
      "Val    loss : 0.20920    f1 : 0.73820\n",
      "epoch : 39/100    time : 71s/4308s\n",
      "TRAIN    loss : 0.02627    f1 : 0.97821\n",
      "Val    loss : 0.43484    f1 : 0.73684\n",
      "epoch : 40/100    time : 71s/4265s\n",
      "TRAIN    loss : 0.02111    f1 : 0.97159\n",
      "Val    loss : 0.22582    f1 : 0.78439\n",
      "epoch : 41/100    time : 69s/4075s\n",
      "TRAIN    loss : 0.01712    f1 : 0.98394\n",
      "Val    loss : 0.21654    f1 : 0.75321\n",
      "epoch : 42/100    time : 70s/4073s\n",
      "TRAIN    loss : 0.00749    f1 : 0.99625\n",
      "Val    loss : 0.21452    f1 : 0.76216\n",
      "epoch : 43/100    time : 69s/3911s\n",
      "TRAIN    loss : 0.01562    f1 : 0.98808\n",
      "Val    loss : 0.20036    f1 : 0.78983\n",
      "epoch : 44/100    time : 68s/3829s\n",
      "TRAIN    loss : 0.04859    f1 : 0.94850\n",
      "Val    loss : 0.33888    f1 : 0.66781\n",
      "epoch : 45/100    time : 70s/3851s\n",
      "TRAIN    loss : 0.06337    f1 : 0.93278\n",
      "Val    loss : 0.25564    f1 : 0.77518\n",
      "epoch : 46/100    time : 69s/3722s\n",
      "TRAIN    loss : 0.02000    f1 : 0.97441\n",
      "Val    loss : 0.23032    f1 : 0.74907\n",
      "epoch : 47/100    time : 71s/3769s\n",
      "TRAIN    loss : 0.04480    f1 : 0.96040\n",
      "Val    loss : 0.24219    f1 : 0.73263\n",
      "epoch : 48/100    time : 69s/3565s\n",
      "TRAIN    loss : 0.02499    f1 : 0.96697\n",
      "Val    loss : 0.23186    f1 : 0.75724\n",
      "epoch : 49/100    time : 70s/3559s\n",
      "TRAIN    loss : 0.01273    f1 : 0.97974\n",
      "Val    loss : 0.19353    f1 : 0.81750\n",
      "epoch : 50/100    time : 71s/3569s\n",
      "TRAIN    loss : 0.03185    f1 : 0.97480\n",
      "Val    loss : 0.32678    f1 : 0.72725\n",
      "epoch : 51/100    time : 72s/3528s\n",
      "TRAIN    loss : 0.03068    f1 : 0.97632\n",
      "Val    loss : 0.21742    f1 : 0.75624\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022,shuffle=True)\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "  print(\"----------fold_{} start!----------\".format(idx))\n",
    "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "  # Train\n",
    "  train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Val\n",
    "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  best=0\n",
    "\n",
    "  model = Network().to(device)\n",
    "\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay = 1e-3)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "  best_f1 = 0\n",
    "  early_stopping = 0\n",
    "  for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss = 0 \n",
    "      val_pred = []\n",
    "      val_y = []\n",
    "      \n",
    "\n",
    "      for batch in (val_loader):\n",
    "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_val = model(x_val)\n",
    "        loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "        val_loss += loss_val.item()/len(val_loader)\n",
    "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "        val_y += y_val.detach().cpu().numpy().tolist()\n",
    "      val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "      if val_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_loss = val_loss\n",
    "        best_f1 = val_f1\n",
    "        early_stopping = 0\n",
    "\n",
    "        torch.save({'epoch':epoch,\n",
    "                    'state_dict':state_dict,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "             }, path +'best_model_{}.pth'.format(idx))\n",
    "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "      else:\n",
    "          early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "      if early_stopping == 20:\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "Jl2OKpQiO5S1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl2OKpQiO5S1",
    "outputId": "e48def07-ef6d-4325-f297-c705088b3eb8"
   },
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 16\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load((path+'best_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "seat84vNOOtT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seat84vNOOtT",
    "outputId": "71c853b2-29c3-430e-e4d0-cb1a66e11196"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "GjsHs-T3SPJq",
   "metadata": {
    "id": "GjsHs-T3SPJq"
   },
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1])+ np.array(pred_ensemble[3]) + np.array(pred_ensemble[4]) )/4\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "UIglTwAV7L54",
   "metadata": {
    "id": "UIglTwAV7L54"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "292QDIS5DOKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "292QDIS5DOKf",
    "outputId": "0e47d38f-d36a-40cd-a925-90e6bce52652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1naZSLGZ7L55",
   "metadata": {
    "id": "1naZSLGZ7L55"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"densenet169_norm_epoch100.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fitted-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"
     ]
    }
   ],
   "source": [
    "# d2b19ece8c7374053ee1fd80cfe419ddfc640c01f9ebe4cbd5caeb9f1906974a\n",
    "\n",
    "from dacon_submit_api import dacon_submit_api \n",
    "\n",
    "result = dacon_submit_api.post_submission_file(\n",
    "'/home/densenet169_norm_epoch100.csv', \n",
    "'d2b19ece8c7374053ee1fd80cfe419ddfc640c01f9ebe4cbd5caeb9f1906974a', \n",
    "'235894', \n",
    "'mean', \n",
    "'densenet169_BS16' )\n",
    "\n",
    "# https://www.dacon.io/competitions/official/235894/overview/rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p87_msjB7L51",
   "metadata": {
    "id": "p87_msjB7L51"
   },
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MW9Fx7QADii5",
   "metadata": {
    "id": "MW9Fx7QADii5"
   },
   "source": [
    "사전 학습 모델의 성능 파악을 할 때 Fold 학습은 실행 시간이 오래걸려서 fold를 나누지 않은 데이터에 대해서 학습을 진행하고 성능을 비교하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "syUpL8e_7L50",
   "metadata": {
    "id": "syUpL8e_7L50"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 30\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cJc8Yj7zrh4g",
   "metadata": {
    "id": "cJc8Yj7zrh4g"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tpCGp41k7L51",
   "metadata": {
    "id": "tpCGp41k7L51"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "\n",
    "best=0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YssPW4xq7L53",
   "metadata": {
    "id": "YssPW4xq7L53"
   },
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1w_VB_PY7L53",
   "metadata": {
    "id": "1w_VB_PY7L53"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "f_pred = []\n",
    "pred_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "            pred_prob.extend(pred.detach().cpu().numpy())\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aZMML2u3DTHx",
   "metadata": {
    "id": "aZMML2u3DTHx"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I4io2mJC7L54",
   "metadata": {
    "id": "I4io2mJC7L54"
   },
   "source": [
    "### 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XCV3FEKe7L55",
   "metadata": {
    "id": "XCV3FEKe7L55"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(path + \"open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jsl6tXbz7L56",
   "metadata": {
    "id": "jsl6tXbz7L56"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"VGG16_norm.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[BASELINE]_EfficientNet_b3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
