{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LlcNsGEk7L5r",
   "metadata": {
    "id": "LlcNsGEk7L5r"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "popular-bathroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3',\n",
      " 'bat_resnext26ts',\n",
      " 'beit_base_patch16_224',\n",
      " 'beit_base_patch16_224_in22k',\n",
      " 'beit_base_patch16_384',\n",
      " 'beit_large_patch16_224',\n",
      " 'beit_large_patch16_224_in22k',\n",
      " 'beit_large_patch16_384',\n",
      " 'beit_large_patch16_512',\n",
      " 'botnet26t_256',\n",
      " 'cait_m36_384',\n",
      " 'cait_m48_448',\n",
      " 'cait_s24_224',\n",
      " 'cait_s24_384',\n",
      " 'cait_s36_384',\n",
      " 'cait_xs24_384',\n",
      " 'cait_xxs24_224',\n",
      " 'cait_xxs24_384',\n",
      " 'cait_xxs36_224',\n",
      " 'cait_xxs36_384',\n",
      " 'coat_lite_mini',\n",
      " 'coat_lite_small',\n",
      " 'coat_lite_tiny',\n",
      " 'coat_mini',\n",
      " 'coat_tiny',\n",
      " 'convit_base',\n",
      " 'convit_small',\n",
      " 'convit_tiny',\n",
      " 'convmixer_768_32',\n",
      " 'convmixer_1024_20_ks9_p14',\n",
      " 'convmixer_1536_20',\n",
      " 'convnext_base',\n",
      " 'convnext_base_384_in22ft1k',\n",
      " 'convnext_base_in22ft1k',\n",
      " 'convnext_base_in22k',\n",
      " 'convnext_large',\n",
      " 'convnext_large_384_in22ft1k',\n",
      " 'convnext_large_in22ft1k',\n",
      " 'convnext_large_in22k',\n",
      " 'convnext_small',\n",
      " 'convnext_tiny',\n",
      " 'convnext_xlarge_384_in22ft1k',\n",
      " 'convnext_xlarge_in22ft1k',\n",
      " 'convnext_xlarge_in22k',\n",
      " 'crossvit_9_240',\n",
      " 'crossvit_9_dagger_240',\n",
      " 'crossvit_15_240',\n",
      " 'crossvit_15_dagger_240',\n",
      " 'crossvit_15_dagger_408',\n",
      " 'crossvit_18_240',\n",
      " 'crossvit_18_dagger_240',\n",
      " 'crossvit_18_dagger_408',\n",
      " 'crossvit_base_240',\n",
      " 'crossvit_small_240',\n",
      " 'crossvit_tiny_240',\n",
      " 'cspdarknet53',\n",
      " 'cspresnet50',\n",
      " 'cspresnext50',\n",
      " 'deit_base_distilled_patch16_224',\n",
      " 'deit_base_distilled_patch16_384',\n",
      " 'deit_base_patch16_224',\n",
      " 'deit_base_patch16_384',\n",
      " 'deit_small_distilled_patch16_224',\n",
      " 'deit_small_patch16_224',\n",
      " 'deit_tiny_distilled_patch16_224',\n",
      " 'deit_tiny_patch16_224',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dm_nfnet_f0',\n",
      " 'dm_nfnet_f1',\n",
      " 'dm_nfnet_f2',\n",
      " 'dm_nfnet_f3',\n",
      " 'dm_nfnet_f4',\n",
      " 'dm_nfnet_f5',\n",
      " 'dm_nfnet_f6',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'eca_botnext26ts_256',\n",
      " 'eca_halonext26ts',\n",
      " 'eca_nfnet_l0',\n",
      " 'eca_nfnet_l1',\n",
      " 'eca_nfnet_l2',\n",
      " 'eca_resnet33ts',\n",
      " 'eca_resnext26ts',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b4',\n",
      " 'efficientnet_el',\n",
      " 'efficientnet_el_pruned',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_es_pruned',\n",
      " 'efficientnet_lite0',\n",
      " 'efficientnetv2_rw_m',\n",
      " 'efficientnetv2_rw_s',\n",
      " 'efficientnetv2_rw_t',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'fbnetc_100',\n",
      " 'fbnetv3_b',\n",
      " 'fbnetv3_d',\n",
      " 'fbnetv3_g',\n",
      " 'gc_efficientnetv2_rw_t',\n",
      " 'gcresnet33ts',\n",
      " 'gcresnet50t',\n",
      " 'gcresnext26ts',\n",
      " 'gcresnext50ts',\n",
      " 'gernet_l',\n",
      " 'gernet_m',\n",
      " 'gernet_s',\n",
      " 'ghostnet_100',\n",
      " 'gluon_inception_v3',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_senet154',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'gluon_xception65',\n",
      " 'gmixer_24_224',\n",
      " 'gmlp_s16_224',\n",
      " 'halo2botnet50ts_256',\n",
      " 'halonet26t',\n",
      " 'halonet50ts',\n",
      " 'haloregnetz_b',\n",
      " 'hardcorenas_a',\n",
      " 'hardcorenas_b',\n",
      " 'hardcorenas_c',\n",
      " 'hardcorenas_d',\n",
      " 'hardcorenas_e',\n",
      " 'hardcorenas_f',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w64',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'jx_nest_base',\n",
      " 'jx_nest_small',\n",
      " 'jx_nest_tiny',\n",
      " 'lambda_resnet26rpt_256',\n",
      " 'lambda_resnet26t',\n",
      " 'lambda_resnet50ts',\n",
      " 'lamhalobotnet50ts_256',\n",
      " 'lcnet_050',\n",
      " 'lcnet_075',\n",
      " 'lcnet_100',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'levit_128',\n",
      " 'levit_128s',\n",
      " 'levit_192',\n",
      " 'levit_256',\n",
      " 'levit_384',\n",
      " 'mixer_b16_224',\n",
      " 'mixer_b16_224_in21k',\n",
      " 'mixer_b16_224_miil',\n",
      " 'mixer_b16_224_miil_in21k',\n",
      " 'mixer_l16_224',\n",
      " 'mixer_l16_224_in21k',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mnasnet_100',\n",
      " 'mnasnet_small',\n",
      " 'mobilenetv2_050',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_large_100_miil',\n",
      " 'mobilenetv3_large_100_miil_in21k',\n",
      " 'mobilenetv3_rw',\n",
      " 'nasnetalarge',\n",
      " 'nf_regnet_b1',\n",
      " 'nf_resnet50',\n",
      " 'nfnet_l0',\n",
      " 'pit_b_224',\n",
      " 'pit_b_distilled_224',\n",
      " 'pit_s_224',\n",
      " 'pit_s_distilled_224',\n",
      " 'pit_ti_224',\n",
      " 'pit_ti_distilled_224',\n",
      " 'pit_xs_224',\n",
      " 'pit_xs_distilled_224',\n",
      " 'pnasnet5large',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'regnetz_b16',\n",
      " 'regnetz_c16',\n",
      " 'regnetz_d8',\n",
      " 'regnetz_d32',\n",
      " 'regnetz_e8',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2next50',\n",
      " 'resmlp_12_224',\n",
      " 'resmlp_12_224_dino',\n",
      " 'resmlp_12_distilled_224',\n",
      " 'resmlp_24_224',\n",
      " 'resmlp_24_224_dino',\n",
      " 'resmlp_24_distilled_224',\n",
      " 'resmlp_36_224',\n",
      " 'resmlp_36_distilled_224',\n",
      " 'resmlp_big_24_224',\n",
      " 'resmlp_big_24_224_in22ft1k',\n",
      " 'resmlp_big_24_distilled_224',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet26t',\n",
      " 'resnet32ts',\n",
      " 'resnet33ts',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50_gn',\n",
      " 'resnet50d',\n",
      " 'resnet51q',\n",
      " 'resnet61q',\n",
      " 'resnet101',\n",
      " 'resnet101d',\n",
      " 'resnet152',\n",
      " 'resnet152d',\n",
      " 'resnet200d',\n",
      " 'resnetblur50',\n",
      " 'resnetrs50',\n",
      " 'resnetrs101',\n",
      " 'resnetrs152',\n",
      " 'resnetrs200',\n",
      " 'resnetrs270',\n",
      " 'resnetrs350',\n",
      " 'resnetrs420',\n",
      " 'resnetv2_50',\n",
      " 'resnetv2_50x1_bit_distilled',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bit_teacher',\n",
      " 'resnetv2_152x2_bit_teacher_384',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext26ts',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'sebotnet33ts_256',\n",
      " 'sehalonet33ts',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'semnasnet_075',\n",
      " 'semnasnet_100',\n",
      " 'seresnet33ts',\n",
      " 'seresnet50',\n",
      " 'seresnet152d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext26ts',\n",
      " 'seresnext50_32x4d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swin_base_patch4_window7_224',\n",
      " 'swin_base_patch4_window7_224_in22k',\n",
      " 'swin_base_patch4_window12_384',\n",
      " 'swin_base_patch4_window12_384_in22k',\n",
      " 'swin_large_patch4_window7_224',\n",
      " 'swin_large_patch4_window7_224_in22k',\n",
      " 'swin_large_patch4_window12_384',\n",
      " 'swin_large_patch4_window12_384_in22k',\n",
      " 'swin_small_patch4_window7_224',\n",
      " 'swin_tiny_patch4_window7_224',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b0_ap',\n",
      " 'tf_efficientnet_b0_ns',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b1_ap',\n",
      " 'tf_efficientnet_b1_ns',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b2_ap',\n",
      " 'tf_efficientnet_b2_ns',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b3_ap',\n",
      " 'tf_efficientnet_b3_ns',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b4_ap',\n",
      " 'tf_efficientnet_b4_ns',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b5_ap',\n",
      " 'tf_efficientnet_b5_ns',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b6_ap',\n",
      " 'tf_efficientnet_b6_ns',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b7_ap',\n",
      " 'tf_efficientnet_b7_ns',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_b8_ap',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2_ns',\n",
      " 'tf_efficientnet_l2_ns_475',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_efficientnetv2_b0',\n",
      " 'tf_efficientnetv2_b1',\n",
      " 'tf_efficientnetv2_b2',\n",
      " 'tf_efficientnetv2_b3',\n",
      " 'tf_efficientnetv2_l',\n",
      " 'tf_efficientnetv2_l_in21ft1k',\n",
      " 'tf_efficientnetv2_l_in21k',\n",
      " 'tf_efficientnetv2_m',\n",
      " 'tf_efficientnetv2_m_in21ft1k',\n",
      " 'tf_efficientnetv2_m_in21k',\n",
      " 'tf_efficientnetv2_s',\n",
      " 'tf_efficientnetv2_s_in21ft1k',\n",
      " 'tf_efficientnetv2_s_in21k',\n",
      " 'tf_efficientnetv2_xl_in21ft1k',\n",
      " 'tf_efficientnetv2_xl_in21k',\n",
      " 'tf_inception_v3',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tinynet_a',\n",
      " 'tinynet_b',\n",
      " 'tinynet_c',\n",
      " 'tinynet_d',\n",
      " 'tinynet_e',\n",
      " 'tnt_s_patch16_224',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_m_miil_in21k',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_densenet121',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'twins_pcpvt_base',\n",
      " 'twins_pcpvt_large',\n",
      " 'twins_pcpvt_small',\n",
      " 'twins_svt_base',\n",
      " 'twins_svt_large',\n",
      " 'twins_svt_small',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'visformer_small',\n",
      " 'vit_base_patch8_224',\n",
      " 'vit_base_patch8_224_in21k',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_224_in21k',\n",
      " 'vit_base_patch16_224_miil',\n",
      " 'vit_base_patch16_224_miil_in21k',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch16_sam_224',\n",
      " 'vit_base_patch32_224',\n",
      " 'vit_base_patch32_224_in21k',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_patch32_sam_224',\n",
      " 'vit_base_r50_s16_224_in21k',\n",
      " 'vit_base_r50_s16_384',\n",
      " 'vit_huge_patch14_224_in21k',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_224_in21k',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch32_224_in21k',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_large_r50_s32_224',\n",
      " 'vit_large_r50_s32_224_in21k',\n",
      " 'vit_large_r50_s32_384',\n",
      " 'vit_small_patch16_224',\n",
      " 'vit_small_patch16_224_in21k',\n",
      " 'vit_small_patch16_384',\n",
      " 'vit_small_patch32_224',\n",
      " 'vit_small_patch32_224_in21k',\n",
      " 'vit_small_patch32_384',\n",
      " 'vit_small_r26_s32_224',\n",
      " 'vit_small_r26_s32_224_in21k',\n",
      " 'vit_small_r26_s32_384',\n",
      " 'vit_tiny_patch16_224',\n",
      " 'vit_tiny_patch16_224_in21k',\n",
      " 'vit_tiny_patch16_384',\n",
      " 'vit_tiny_r_s16_p8_224',\n",
      " 'vit_tiny_r_s16_p8_224_in21k',\n",
      " 'vit_tiny_r_s16_p8_384',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception',\n",
      " 'xception41',\n",
      " 'xception65',\n",
      " 'xception71',\n",
      " 'xcit_large_24_p8_224',\n",
      " 'xcit_large_24_p8_224_dist',\n",
      " 'xcit_large_24_p8_384_dist',\n",
      " 'xcit_large_24_p16_224',\n",
      " 'xcit_large_24_p16_224_dist',\n",
      " 'xcit_large_24_p16_384_dist',\n",
      " 'xcit_medium_24_p8_224',\n",
      " 'xcit_medium_24_p8_224_dist',\n",
      " 'xcit_medium_24_p8_384_dist',\n",
      " 'xcit_medium_24_p16_224',\n",
      " 'xcit_medium_24_p16_224_dist',\n",
      " 'xcit_medium_24_p16_384_dist',\n",
      " 'xcit_nano_12_p8_224',\n",
      " 'xcit_nano_12_p8_224_dist',\n",
      " 'xcit_nano_12_p8_384_dist',\n",
      " 'xcit_nano_12_p16_224',\n",
      " 'xcit_nano_12_p16_224_dist',\n",
      " 'xcit_nano_12_p16_384_dist',\n",
      " 'xcit_small_12_p8_224',\n",
      " 'xcit_small_12_p8_224_dist',\n",
      " 'xcit_small_12_p8_384_dist',\n",
      " 'xcit_small_12_p16_224',\n",
      " 'xcit_small_12_p16_224_dist',\n",
      " 'xcit_small_12_p16_384_dist',\n",
      " 'xcit_small_24_p8_224',\n",
      " 'xcit_small_24_p8_224_dist',\n",
      " 'xcit_small_24_p8_384_dist',\n",
      " 'xcit_small_24_p16_224',\n",
      " 'xcit_small_24_p16_224_dist',\n",
      " 'xcit_small_24_p16_384_dist',\n",
      " 'xcit_tiny_12_p8_224',\n",
      " 'xcit_tiny_12_p8_224_dist',\n",
      " 'xcit_tiny_12_p8_384_dist',\n",
      " 'xcit_tiny_12_p16_224',\n",
      " 'xcit_tiny_12_p16_224_dist',\n",
      " 'xcit_tiny_12_p16_384_dist',\n",
      " 'xcit_tiny_24_p8_224',\n",
      " 'xcit_tiny_24_p8_224_dist',\n",
      " 'xcit_tiny_24_p8_384_dist',\n",
      " 'xcit_tiny_24_p16_224',\n",
      " 'xcit_tiny_24_p16_224_dist',\n",
      " 'xcit_tiny_24_p16_384_dist']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lXH5F_hA7uMl",
   "metadata": {
    "id": "lXH5F_hA7uMl"
   },
   "outputs": [],
   "source": [
    "path = '/home/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "FWntO1VD7L5u",
   "metadata": {
    "id": "FWntO1VD7L5u"
   },
   "outputs": [],
   "source": [
    "train_png = sorted(glob(path + 'open/train/*.png'))\n",
    "test_png = sorted(glob(path + 'open/test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "atSgPJRn-OCW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atSgPJRn-OCW",
    "outputId": "87b6f90b-5c1c-4a0e-de54-994458543687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4277, 2154)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_png), len(test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "xv0_rDVq7L5v",
   "metadata": {
    "id": "xv0_rDVq7L5v"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(path +\"open/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "iMhC0nPw7L5w",
   "metadata": {
    "id": "iMhC0nPw7L5w"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "zsmJA3E97L5x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsmJA3E97L5x",
    "outputId": "e0dc61fe-5617-42e8-c8b0-0e95b9f60656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4277/4277 [03:18<00:00, 21.60it/s]\n",
      "100%|██████████| 2154/2154 [01:38<00:00, 21.92it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "KA73Lku9A2N9",
   "metadata": {
    "id": "KA73Lku9A2N9"
   },
   "outputs": [],
   "source": [
    "np.save(path + 'train_imgs_384', np.array(train_imgs))\n",
    "np.save(path + 'test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "L6qBdX7nCp8L",
   "metadata": {
    "id": "L6qBdX7nCp8L"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.load(path + 'train_imgs_384.npy')\n",
    "test_imgs = np.load(path + 'test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sscGLiJKPy6H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sscGLiJKPy6H",
    "outputId": "976516c0-507d-458f-f0c4-6695751605d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평균 0.4330380901867049 0.4034575319032911 0.39415050509784405\n",
      "train 표준편차 0.1815717110252788 0.17403455556798705 0.16323395055036488\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"train 평균\",meanR, meanG, meanB)\n",
    "print(\"train 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "JwVIQCrUSCFE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwVIQCrUSCFE",
    "outputId": "293981ef-7f6a-4602-d208-5fd8473d5261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 평균 0.41825619520929724 0.3931011906330291 0.386631764639131\n",
      "test 표준편차 0.19505524270747931 0.19005280951759498 0.18053225852732663\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"test 평균\",meanR, meanG, meanB)\n",
    "print(\"test 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "VFXzojoo7L5y",
   "metadata": {
    "id": "VFXzojoo7L5y"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "                                     std = [0.181572, 0.174035, 0.163234]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
    "                                     std = [0.195055, 0.190053, 0.185323])\n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('densenet201', pretrained=True, num_classes=88)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('densenet201', pretrained=True, num_classes=88)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38qk8sGbYiO_",
   "metadata": {
    "id": "38qk8sGbYiO_"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "EnOG2n30-Dz5",
   "metadata": {
    "id": "EnOG2n30-Dz5"
   },
   "outputs": [],
   "source": [
    "def main(seed = 2022):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "main(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lkNCkyG9RPzX",
   "metadata": {
    "id": "lkNCkyG9RPzX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /root/.cache/torch/hub/checkpoints/densenet201-c1103571.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 86s/8537s\n",
      "TRAIN    loss : 1.18249    f1 : 0.15039\n",
      "Val    loss : 0.68536    f1 : 0.18115\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 81s/7973s\n",
      "TRAIN    loss : 0.65202    f1 : 0.19735\n",
      "Val    loss : 0.54040    f1 : 0.30026\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 83s/8070s\n",
      "TRAIN    loss : 0.48170    f1 : 0.34018\n",
      "Val    loss : 0.52257    f1 : 0.35155\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 83s/7926s\n",
      "TRAIN    loss : 0.38577    f1 : 0.44144\n",
      "Val    loss : 0.38071    f1 : 0.49238\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 81s/7655s\n",
      "TRAIN    loss : 0.33787    f1 : 0.51555\n",
      "Val    loss : 0.38526    f1 : 0.49780\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 81s/7631s\n",
      "TRAIN    loss : 0.26477    f1 : 0.60912\n",
      "Val    loss : 0.29453    f1 : 0.55905\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 82s/7632s\n",
      "TRAIN    loss : 0.22173    f1 : 0.68239\n",
      "Val    loss : 0.26805    f1 : 0.58262\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 82s/7560s\n",
      "TRAIN    loss : 0.19223    f1 : 0.72308\n",
      "Val    loss : 0.23429    f1 : 0.62963\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 82s/7456s\n",
      "TRAIN    loss : 0.17964    f1 : 0.75221\n",
      "Val    loss : 0.26209    f1 : 0.66226\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/100    time : 83s/7432s\n",
      "TRAIN    loss : 0.13440    f1 : 0.83105\n",
      "Val    loss : 0.20723    f1 : 0.70668\n",
      "epoch : 11/100    time : 82s/7288s\n",
      "TRAIN    loss : 0.12026    f1 : 0.84129\n",
      "Val    loss : 0.25522    f1 : 0.67007\n",
      "epoch : 12/100    time : 79s/6923s\n",
      "TRAIN    loss : 0.11646    f1 : 0.87422\n",
      "Val    loss : 0.22289    f1 : 0.66327\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/100    time : 81s/7080s\n",
      "TRAIN    loss : 0.14376    f1 : 0.82093\n",
      "Val    loss : 0.17789    f1 : 0.73133\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/100    time : 81s/6928s\n",
      "TRAIN    loss : 0.09093    f1 : 0.89563\n",
      "Val    loss : 0.18072    f1 : 0.73980\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/100    time : 81s/6922s\n",
      "TRAIN    loss : 0.07073    f1 : 0.91123\n",
      "Val    loss : 0.18898    f1 : 0.76035\n",
      "epoch : 16/100    time : 81s/6768s\n",
      "TRAIN    loss : 0.06734    f1 : 0.91895\n",
      "Val    loss : 0.20931    f1 : 0.71663\n",
      "epoch : 17/100    time : 82s/6778s\n",
      "TRAIN    loss : 0.05819    f1 : 0.92697\n",
      "Val    loss : 0.21319    f1 : 0.72045\n",
      "epoch : 18/100    time : 81s/6650s\n",
      "TRAIN    loss : 0.08863    f1 : 0.91431\n",
      "Val    loss : 0.16696    f1 : 0.73237\n",
      "epoch : 19/100    time : 80s/6488s\n",
      "TRAIN    loss : 0.06060    f1 : 0.94018\n",
      "Val    loss : 0.31007    f1 : 0.70287\n",
      "-----------------SAVE:20 epoch----------------\n",
      "epoch : 20/100    time : 82s/6532s\n",
      "TRAIN    loss : 0.04922    f1 : 0.95516\n",
      "Val    loss : 0.15583    f1 : 0.77512\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/100    time : 81s/6396s\n",
      "TRAIN    loss : 0.03645    f1 : 0.97628\n",
      "Val    loss : 0.18241    f1 : 0.81318\n",
      "epoch : 22/100    time : 82s/6422s\n",
      "TRAIN    loss : 0.05658    f1 : 0.95407\n",
      "Val    loss : 0.17083    f1 : 0.75423\n",
      "epoch : 23/100    time : 81s/6246s\n",
      "TRAIN    loss : 0.06374    f1 : 0.93730\n",
      "Val    loss : 0.24554    f1 : 0.70884\n",
      "epoch : 24/100    time : 81s/6184s\n",
      "TRAIN    loss : 0.04633    f1 : 0.94907\n",
      "Val    loss : 0.24058    f1 : 0.71903\n",
      "epoch : 25/100    time : 80s/6012s\n",
      "TRAIN    loss : 0.04923    f1 : 0.95750\n",
      "Val    loss : 0.43303    f1 : 0.75799\n",
      "epoch : 26/100    time : 81s/6018s\n",
      "TRAIN    loss : 0.04753    f1 : 0.96047\n",
      "Val    loss : 0.22684    f1 : 0.73626\n",
      "epoch : 27/100    time : 81s/5915s\n",
      "TRAIN    loss : 0.04477    f1 : 0.94483\n",
      "Val    loss : 0.21074    f1 : 0.77409\n",
      "epoch : 28/100    time : 79s/5672s\n",
      "TRAIN    loss : 0.03851    f1 : 0.96031\n",
      "Val    loss : 0.20860    f1 : 0.77880\n",
      "epoch : 29/100    time : 82s/5819s\n",
      "TRAIN    loss : 0.03977    f1 : 0.95629\n",
      "Val    loss : 0.42331    f1 : 0.75434\n",
      "epoch : 30/100    time : 82s/5735s\n",
      "TRAIN    loss : 0.04148    f1 : 0.95087\n",
      "Val    loss : 0.34560    f1 : 0.77844\n",
      "epoch : 31/100    time : 83s/5758s\n",
      "TRAIN    loss : 0.02267    f1 : 0.97390\n",
      "Val    loss : 0.22245    f1 : 0.78687\n",
      "epoch : 32/100    time : 82s/5542s\n",
      "TRAIN    loss : 0.01964    f1 : 0.97608\n",
      "Val    loss : 0.20468    f1 : 0.75603\n",
      "epoch : 33/100    time : 81s/5453s\n",
      "TRAIN    loss : 0.03656    f1 : 0.97409\n",
      "Val    loss : 0.22399    f1 : 0.78809\n",
      "epoch : 34/100    time : 80s/5264s\n",
      "TRAIN    loss : 0.02754    f1 : 0.98310\n",
      "Val    loss : 0.21766    f1 : 0.78073\n",
      "epoch : 35/100    time : 84s/5428s\n",
      "TRAIN    loss : 0.02850    f1 : 0.97680\n",
      "Val    loss : 0.27026    f1 : 0.77046\n",
      "epoch : 36/100    time : 81s/5160s\n",
      "TRAIN    loss : 0.06975    f1 : 0.92787\n",
      "Val    loss : 0.51915    f1 : 0.67002\n",
      "epoch : 37/100    time : 81s/5083s\n",
      "TRAIN    loss : 0.03799    f1 : 0.95900\n",
      "Val    loss : 0.25958    f1 : 0.69568\n",
      "epoch : 38/100    time : 80s/4961s\n",
      "TRAIN    loss : 0.05544    f1 : 0.94842\n",
      "Val    loss : 0.24400    f1 : 0.76098\n",
      "epoch : 39/100    time : 80s/4856s\n",
      "TRAIN    loss : 0.02201    f1 : 0.98596\n",
      "Val    loss : 0.21346    f1 : 0.77700\n",
      "epoch : 40/100    time : 81s/4883s\n",
      "TRAIN    loss : 0.02732    f1 : 0.97371\n",
      "Val    loss : 0.21036    f1 : 0.76337\n",
      "epoch : 41/100    time : 80s/4707s\n",
      "TRAIN    loss : 0.01630    f1 : 0.99224\n",
      "Val    loss : 0.20711    f1 : 0.80040\n",
      "----------fold_1 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 83s/8173s\n",
      "TRAIN    loss : 1.16857    f1 : 0.15375\n",
      "Val    loss : 0.74564    f1 : 0.20185\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 82s/8025s\n",
      "TRAIN    loss : 0.65830    f1 : 0.21020\n",
      "Val    loss : 0.47288    f1 : 0.28356\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 84s/8173s\n",
      "TRAIN    loss : 0.48010    f1 : 0.30830\n",
      "Val    loss : 0.45461    f1 : 0.31848\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 84s/8032s\n",
      "TRAIN    loss : 0.39778    f1 : 0.41535\n",
      "Val    loss : 0.33289    f1 : 0.45734\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 84s/7962s\n",
      "TRAIN    loss : 0.30951    f1 : 0.53596\n",
      "Val    loss : 0.31434    f1 : 0.50000\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 82s/7751s\n",
      "TRAIN    loss : 0.26528    f1 : 0.62926\n",
      "Val    loss : 0.24620    f1 : 0.65718\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 84s/7796s\n",
      "TRAIN    loss : 0.22398    f1 : 0.66097\n",
      "Val    loss : 0.24207    f1 : 0.67226\n",
      "epoch : 8/100    time : 80s/7374s\n",
      "TRAIN    loss : 0.17999    f1 : 0.74698\n",
      "Val    loss : 0.22792    f1 : 0.65235\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 82s/7421s\n",
      "TRAIN    loss : 0.16384    f1 : 0.76358\n",
      "Val    loss : 0.23122    f1 : 0.67891\n",
      "epoch : 10/100    time : 83s/7426s\n",
      "TRAIN    loss : 0.16465    f1 : 0.78001\n",
      "Val    loss : 0.31880    f1 : 0.64959\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 82s/7327s\n",
      "TRAIN    loss : 0.12777    f1 : 0.82769\n",
      "Val    loss : 0.21746    f1 : 0.73786\n",
      "epoch : 12/100    time : 84s/7406s\n",
      "TRAIN    loss : 0.11598    f1 : 0.84895\n",
      "Val    loss : 0.22222    f1 : 0.70127\n",
      "epoch : 13/100    time : 84s/7289s\n",
      "TRAIN    loss : 0.09339    f1 : 0.88574\n",
      "Val    loss : 0.23510    f1 : 0.70144\n",
      "epoch : 14/100    time : 85s/7323s\n",
      "TRAIN    loss : 0.11629    f1 : 0.86787\n",
      "Val    loss : 0.37173    f1 : 0.71885\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/100    time : 84s/7132s\n",
      "TRAIN    loss : 0.08031    f1 : 0.90696\n",
      "Val    loss : 0.23497    f1 : 0.74979\n",
      "epoch : 16/100    time : 83s/6940s\n",
      "TRAIN    loss : 0.06737    f1 : 0.91385\n",
      "Val    loss : 0.19512    f1 : 0.73621\n",
      "-----------------SAVE:17 epoch----------------\n",
      "epoch : 17/100    time : 84s/6933s\n",
      "TRAIN    loss : 0.07331    f1 : 0.91654\n",
      "Val    loss : 0.19743    f1 : 0.76766\n",
      "epoch : 18/100    time : 82s/6762s\n",
      "TRAIN    loss : 0.08349    f1 : 0.90901\n",
      "Val    loss : 0.23301    f1 : 0.72506\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/100    time : 84s/6828s\n",
      "TRAIN    loss : 0.06582    f1 : 0.93172\n",
      "Val    loss : 0.18736    f1 : 0.81026\n",
      "epoch : 20/100    time : 83s/6632s\n",
      "TRAIN    loss : 0.06128    f1 : 0.93955\n",
      "Val    loss : 0.16807    f1 : 0.77771\n",
      "epoch : 21/100    time : 85s/6679s\n",
      "TRAIN    loss : 0.03828    f1 : 0.96404\n",
      "Val    loss : 0.16949    f1 : 0.78483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 22/100    time : 84s/6531s\n",
      "TRAIN    loss : 0.06506    f1 : 0.94655\n",
      "Val    loss : 0.27854    f1 : 0.73190\n",
      "-----------------SAVE:23 epoch----------------\n",
      "epoch : 23/100    time : 84s/6472s\n",
      "TRAIN    loss : 0.04638    f1 : 0.95056\n",
      "Val    loss : 0.14616    f1 : 0.83123\n",
      "epoch : 24/100    time : 83s/6308s\n",
      "TRAIN    loss : 0.03866    f1 : 0.95094\n",
      "Val    loss : 0.21470    f1 : 0.70688\n",
      "epoch : 25/100    time : 84s/6322s\n",
      "TRAIN    loss : 0.04284    f1 : 0.95340\n",
      "Val    loss : 0.21134    f1 : 0.74819\n",
      "epoch : 26/100    time : 81s/5997s\n",
      "TRAIN    loss : 0.03063    f1 : 0.97021\n",
      "Val    loss : 0.19356    f1 : 0.77036\n",
      "epoch : 27/100    time : 83s/6042s\n",
      "TRAIN    loss : 0.06733    f1 : 0.92847\n",
      "Val    loss : 0.25325    f1 : 0.72929\n",
      "epoch : 28/100    time : 79s/5681s\n",
      "TRAIN    loss : 0.04373    f1 : 0.96668\n",
      "Val    loss : 0.22546    f1 : 0.70782\n",
      "epoch : 29/100    time : 82s/5847s\n",
      "TRAIN    loss : 0.04323    f1 : 0.94911\n",
      "Val    loss : 0.18535    f1 : 0.78369\n",
      "epoch : 30/100    time : 80s/5601s\n",
      "TRAIN    loss : 0.03071    f1 : 0.96994\n",
      "Val    loss : 0.18420    f1 : 0.80841\n",
      "epoch : 31/100    time : 83s/5754s\n",
      "TRAIN    loss : 0.03685    f1 : 0.96554\n",
      "Val    loss : 0.16039    f1 : 0.75956\n",
      "epoch : 32/100    time : 83s/5644s\n",
      "TRAIN    loss : 0.03507    f1 : 0.96986\n",
      "Val    loss : 0.25867    f1 : 0.71700\n",
      "epoch : 33/100    time : 84s/5595s\n",
      "TRAIN    loss : 0.03391    f1 : 0.96643\n",
      "Val    loss : 0.20071    f1 : 0.78490\n",
      "epoch : 34/100    time : 80s/5275s\n",
      "TRAIN    loss : 0.03974    f1 : 0.95621\n",
      "Val    loss : 0.19714    f1 : 0.76987\n",
      "epoch : 35/100    time : 83s/5394s\n",
      "TRAIN    loss : 0.02646    f1 : 0.97174\n",
      "Val    loss : 0.27004    f1 : 0.73884\n",
      "epoch : 36/100    time : 83s/5344s\n",
      "TRAIN    loss : 0.03634    f1 : 0.96505\n",
      "Val    loss : 0.19118    f1 : 0.77518\n",
      "epoch : 37/100    time : 80s/5023s\n",
      "TRAIN    loss : 0.04624    f1 : 0.95293\n",
      "Val    loss : 0.19331    f1 : 0.75117\n",
      "epoch : 38/100    time : 82s/5111s\n",
      "TRAIN    loss : 0.02947    f1 : 0.97663\n",
      "Val    loss : 0.16717    f1 : 0.83011\n",
      "epoch : 39/100    time : 83s/5059s\n",
      "TRAIN    loss : 0.01398    f1 : 0.98497\n",
      "Val    loss : 0.18053    f1 : 0.77479\n",
      "epoch : 40/100    time : 83s/4984s\n",
      "TRAIN    loss : 0.00820    f1 : 0.99083\n",
      "Val    loss : 0.15105    f1 : 0.81930\n",
      "epoch : 41/100    time : 81s/4795s\n",
      "TRAIN    loss : 0.03019    f1 : 0.97410\n",
      "Val    loss : 0.16556    f1 : 0.75755\n",
      "epoch : 42/100    time : 82s/4737s\n",
      "TRAIN    loss : 0.04974    f1 : 0.96196\n",
      "Val    loss : 0.21730    f1 : 0.78407\n",
      "epoch : 43/100    time : 81s/4626s\n",
      "TRAIN    loss : 0.03260    f1 : 0.96958\n",
      "Val    loss : 0.20470    f1 : 0.74347\n",
      "----------fold_2 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 89s/8790s\n",
      "TRAIN    loss : 1.16277    f1 : 0.15249\n",
      "Val    loss : 0.66871    f1 : 0.18699\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 81s/7907s\n",
      "TRAIN    loss : 0.63842    f1 : 0.20554\n",
      "Val    loss : 0.48513    f1 : 0.24287\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 84s/8128s\n",
      "TRAIN    loss : 0.48049    f1 : 0.33442\n",
      "Val    loss : 0.42552    f1 : 0.36531\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 81s/7807s\n",
      "TRAIN    loss : 0.38177    f1 : 0.42979\n",
      "Val    loss : 0.30961    f1 : 0.48041\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 82s/7815s\n",
      "TRAIN    loss : 0.30906    f1 : 0.55347\n",
      "Val    loss : 0.29939    f1 : 0.51369\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 83s/7771s\n",
      "TRAIN    loss : 0.27188    f1 : 0.61454\n",
      "Val    loss : 0.26410    f1 : 0.54604\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 82s/7604s\n",
      "TRAIN    loss : 0.23276    f1 : 0.66007\n",
      "Val    loss : 0.23725    f1 : 0.57789\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 85s/7783s\n",
      "TRAIN    loss : 0.20160    f1 : 0.71878\n",
      "Val    loss : 0.31254    f1 : 0.69131\n",
      "epoch : 9/100    time : 81s/7334s\n",
      "TRAIN    loss : 0.16764    f1 : 0.77359\n",
      "Val    loss : 0.21216    f1 : 0.66274\n",
      "epoch : 10/100    time : 81s/7286s\n",
      "TRAIN    loss : 0.15121    f1 : 0.78577\n",
      "Val    loss : 0.24991    f1 : 0.67886\n",
      "epoch : 11/100    time : 80s/7156s\n",
      "TRAIN    loss : 0.14606    f1 : 0.82998\n",
      "Val    loss : 0.39648    f1 : 0.67577\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 84s/7397s\n",
      "TRAIN    loss : 0.11620    f1 : 0.85619\n",
      "Val    loss : 0.17043    f1 : 0.74819\n",
      "epoch : 13/100    time : 80s/6986s\n",
      "TRAIN    loss : 0.10216    f1 : 0.88450\n",
      "Val    loss : 0.20752    f1 : 0.71322\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/100    time : 82s/7094s\n",
      "TRAIN    loss : 0.08260    f1 : 0.90585\n",
      "Val    loss : 0.15418    f1 : 0.78862\n",
      "epoch : 15/100    time : 81s/6892s\n",
      "TRAIN    loss : 0.07462    f1 : 0.92381\n",
      "Val    loss : 0.15617    f1 : 0.77077\n",
      "epoch : 16/100    time : 80s/6754s\n",
      "TRAIN    loss : 0.08443    f1 : 0.90081\n",
      "Val    loss : 0.17227    f1 : 0.73092\n",
      "-----------------SAVE:17 epoch----------------\n",
      "epoch : 17/100    time : 84s/6952s\n",
      "TRAIN    loss : 0.05480    f1 : 0.94411\n",
      "Val    loss : 0.15837    f1 : 0.80268\n",
      "epoch : 18/100    time : 80s/6576s\n",
      "TRAIN    loss : 0.05743    f1 : 0.93198\n",
      "Val    loss : 0.17517    f1 : 0.76701\n",
      "epoch : 19/100    time : 82s/6623s\n",
      "TRAIN    loss : 0.07502    f1 : 0.91254\n",
      "Val    loss : 0.21513    f1 : 0.77008\n",
      "epoch : 20/100    time : 80s/6430s\n",
      "TRAIN    loss : 0.07209    f1 : 0.92400\n",
      "Val    loss : 0.16061    f1 : 0.80097\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/100    time : 82s/6507s\n",
      "TRAIN    loss : 0.04701    f1 : 0.95638\n",
      "Val    loss : 0.22137    f1 : 0.81484\n",
      "epoch : 22/100    time : 81s/6302s\n",
      "TRAIN    loss : 0.04753    f1 : 0.95326\n",
      "Val    loss : 0.15099    f1 : 0.79084\n",
      "epoch : 23/100    time : 82s/6335s\n",
      "TRAIN    loss : 0.06954    f1 : 0.92924\n",
      "Val    loss : 0.13459    f1 : 0.79878\n",
      "epoch : 24/100    time : 79s/6041s\n",
      "TRAIN    loss : 0.03900    f1 : 0.95473\n",
      "Val    loss : 0.19316    f1 : 0.77980\n",
      "epoch : 25/100    time : 83s/6205s\n",
      "TRAIN    loss : 0.06773    f1 : 0.93108\n",
      "Val    loss : 0.23369    f1 : 0.71521\n",
      "-----------------SAVE:26 epoch----------------\n",
      "epoch : 26/100    time : 81s/5970s\n",
      "TRAIN    loss : 0.04310    f1 : 0.94680\n",
      "Val    loss : 0.14423    f1 : 0.85185\n",
      "epoch : 27/100    time : 81s/5905s\n",
      "TRAIN    loss : 0.04702    f1 : 0.95824\n",
      "Val    loss : 0.14108    f1 : 0.82463\n",
      "epoch : 28/100    time : 82s/5907s\n",
      "TRAIN    loss : 0.01742    f1 : 0.98877\n",
      "Val    loss : 0.11216    f1 : 0.84826\n",
      "epoch : 29/100    time : 80s/5709s\n",
      "TRAIN    loss : 0.02100    f1 : 0.98757\n",
      "Val    loss : 0.14005    f1 : 0.84765\n",
      "epoch : 30/100    time : 83s/5795s\n",
      "TRAIN    loss : 0.01651    f1 : 0.98250\n",
      "Val    loss : 0.18110    f1 : 0.78559\n",
      "-----------------SAVE:31 epoch----------------\n",
      "epoch : 31/100    time : 82s/5679s\n",
      "TRAIN    loss : 0.04826    f1 : 0.95577\n",
      "Val    loss : 0.10683    f1 : 0.88098\n",
      "epoch : 32/100    time : 83s/5634s\n",
      "TRAIN    loss : 0.04388    f1 : 0.94992\n",
      "Val    loss : 0.14032    f1 : 0.81310\n",
      "epoch : 33/100    time : 81s/5412s\n",
      "TRAIN    loss : 0.06471    f1 : 0.93013\n",
      "Val    loss : 0.12940    f1 : 0.82488\n",
      "epoch : 34/100    time : 81s/5373s\n",
      "TRAIN    loss : 0.03496    f1 : 0.97047\n",
      "Val    loss : 0.14022    f1 : 0.82724\n",
      "epoch : 35/100    time : 80s/5224s\n",
      "TRAIN    loss : 0.02372    f1 : 0.98422\n",
      "Val    loss : 0.16061    f1 : 0.87225\n",
      "epoch : 36/100    time : 79s/5063s\n",
      "TRAIN    loss : 0.03973    f1 : 0.96335\n",
      "Val    loss : 0.16237    f1 : 0.80796\n",
      "epoch : 37/100    time : 83s/5222s\n",
      "TRAIN    loss : 0.04986    f1 : 0.95292\n",
      "Val    loss : 0.15318    f1 : 0.82807\n",
      "epoch : 38/100    time : 82s/5084s\n",
      "TRAIN    loss : 0.02680    f1 : 0.97211\n",
      "Val    loss : 0.16217    f1 : 0.78956\n",
      "epoch : 39/100    time : 81s/4963s\n",
      "TRAIN    loss : 0.05524    f1 : 0.93485\n",
      "Val    loss : 0.11930    f1 : 0.83380\n",
      "epoch : 40/100    time : 81s/4848s\n",
      "TRAIN    loss : 0.01778    f1 : 0.98813\n",
      "Val    loss : 0.12345    f1 : 0.86507\n",
      "-----------------SAVE:41 epoch----------------\n",
      "epoch : 41/100    time : 84s/4947s\n",
      "TRAIN    loss : 0.00853    f1 : 0.98971\n",
      "Val    loss : 0.10694    f1 : 0.90120\n",
      "epoch : 42/100    time : 80s/4616s\n",
      "TRAIN    loss : 0.02552    f1 : 0.98111\n",
      "Val    loss : 0.12266    f1 : 0.87180\n",
      "epoch : 43/100    time : 83s/4734s\n",
      "TRAIN    loss : 0.01593    f1 : 0.98654\n",
      "Val    loss : 0.11110    f1 : 0.84352\n",
      "epoch : 44/100    time : 81s/4551s\n",
      "TRAIN    loss : 0.03707    f1 : 0.96523\n",
      "Val    loss : 0.13605    f1 : 0.83065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 45/100    time : 82s/4517s\n",
      "TRAIN    loss : 0.02153    f1 : 0.97669\n",
      "Val    loss : 0.18324    f1 : 0.77036\n",
      "epoch : 46/100    time : 82s/4403s\n",
      "TRAIN    loss : 0.03459    f1 : 0.96543\n",
      "Val    loss : 0.17500    f1 : 0.78847\n",
      "epoch : 47/100    time : 82s/4323s\n",
      "TRAIN    loss : 0.02182    f1 : 0.98526\n",
      "Val    loss : 0.13335    f1 : 0.85430\n",
      "epoch : 48/100    time : 82s/4288s\n",
      "TRAIN    loss : 0.01840    f1 : 0.98940\n",
      "Val    loss : 0.13099    f1 : 0.81958\n",
      "epoch : 49/100    time : 81s/4147s\n",
      "TRAIN    loss : 0.02254    f1 : 0.98220\n",
      "Val    loss : 0.15070    f1 : 0.84253\n",
      "epoch : 50/100    time : 82s/4102s\n",
      "TRAIN    loss : 0.03264    f1 : 0.97161\n",
      "Val    loss : 0.14378    f1 : 0.81692\n",
      "epoch : 51/100    time : 81s/3972s\n",
      "TRAIN    loss : 0.01553    f1 : 0.97621\n",
      "Val    loss : 0.10745    f1 : 0.88486\n",
      "epoch : 52/100    time : 81s/3912s\n",
      "TRAIN    loss : 0.00583    f1 : 0.99637\n",
      "Val    loss : 0.10668    f1 : 0.86783\n",
      "epoch : 53/100    time : 81s/3823s\n",
      "TRAIN    loss : 0.01878    f1 : 0.97613\n",
      "Val    loss : 0.13595    f1 : 0.82170\n",
      "epoch : 54/100    time : 82s/3760s\n",
      "TRAIN    loss : 0.01314    f1 : 0.99130\n",
      "Val    loss : 0.15133    f1 : 0.82616\n",
      "epoch : 55/100    time : 82s/3685s\n",
      "TRAIN    loss : 0.03805    f1 : 0.97179\n",
      "Val    loss : 0.17422    f1 : 0.82190\n",
      "epoch : 56/100    time : 82s/3594s\n",
      "TRAIN    loss : 0.04403    f1 : 0.95270\n",
      "Val    loss : 0.22334    f1 : 0.76532\n",
      "epoch : 57/100    time : 81s/3496s\n",
      "TRAIN    loss : 0.02531    f1 : 0.96808\n",
      "Val    loss : 0.12152    f1 : 0.85403\n",
      "epoch : 58/100    time : 82s/3434s\n",
      "TRAIN    loss : 0.01340    f1 : 0.98808\n",
      "Val    loss : 0.16653    f1 : 0.77080\n",
      "epoch : 59/100    time : 82s/3358s\n",
      "TRAIN    loss : 0.02603    f1 : 0.97730\n",
      "Val    loss : 0.24022    f1 : 0.73608\n",
      "epoch : 60/100    time : 81s/3251s\n",
      "TRAIN    loss : 0.02437    f1 : 0.95432\n",
      "Val    loss : 0.22976    f1 : 0.80296\n",
      "epoch : 61/100    time : 82s/3216s\n",
      "TRAIN    loss : 0.01925    f1 : 0.98043\n",
      "Val    loss : 0.14356    f1 : 0.84089\n",
      "----------fold_3 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 83s/8207s\n",
      "TRAIN    loss : 1.16573    f1 : 0.15206\n",
      "Val    loss : 0.69948    f1 : 0.17366\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 86s/8399s\n",
      "TRAIN    loss : 0.64657    f1 : 0.21986\n",
      "Val    loss : 0.50841    f1 : 0.26359\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 81s/7883s\n",
      "TRAIN    loss : 0.49135    f1 : 0.32967\n",
      "Val    loss : 0.40850    f1 : 0.37545\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 84s/8084s\n",
      "TRAIN    loss : 0.38929    f1 : 0.44908\n",
      "Val    loss : 0.33001    f1 : 0.47762\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 82s/7751s\n",
      "TRAIN    loss : 0.30586    f1 : 0.55717\n",
      "Val    loss : 0.40029    f1 : 0.47921\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 82s/7726s\n",
      "TRAIN    loss : 0.25677    f1 : 0.62180\n",
      "Val    loss : 0.25793    f1 : 0.58115\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 84s/7800s\n",
      "TRAIN    loss : 0.21748    f1 : 0.68647\n",
      "Val    loss : 0.24173    f1 : 0.61941\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 83s/7621s\n",
      "TRAIN    loss : 0.20881    f1 : 0.69394\n",
      "Val    loss : 0.32303    f1 : 0.63114\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 83s/7536s\n",
      "TRAIN    loss : 0.16411    f1 : 0.76966\n",
      "Val    loss : 0.21842    f1 : 0.65923\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/100    time : 82s/7391s\n",
      "TRAIN    loss : 0.15937    f1 : 0.79605\n",
      "Val    loss : 0.19430    f1 : 0.69733\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 83s/7346s\n",
      "TRAIN    loss : 0.13133    f1 : 0.82132\n",
      "Val    loss : 0.16092    f1 : 0.72578\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022,shuffle=True)\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "  print(\"----------fold_{} start!----------\".format(idx))\n",
    "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "  # Train\n",
    "  train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Val\n",
    "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  best=0\n",
    "\n",
    "  model = Network().to(device)\n",
    "\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay = 1e-3)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "  best_f1 = 0\n",
    "  early_stopping = 0\n",
    "  for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss = 0 \n",
    "      val_pred = []\n",
    "      val_y = []\n",
    "      \n",
    "\n",
    "      for batch in (val_loader):\n",
    "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_val = model(x_val)\n",
    "        loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "        val_loss += loss_val.item()/len(val_loader)\n",
    "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "        val_y += y_val.detach().cpu().numpy().tolist()\n",
    "      val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "      if val_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_loss = val_loss\n",
    "        best_f1 = val_f1\n",
    "        early_stopping = 0\n",
    "\n",
    "        torch.save({'epoch':epoch,\n",
    "                    'state_dict':state_dict,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "             }, path +'best_model_{}.pth'.format(idx))\n",
    "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "      else:\n",
    "          early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "      if early_stopping == 20:\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "Jl2OKpQiO5S1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl2OKpQiO5S1",
    "outputId": "e48def07-ef6d-4325-f297-c705088b3eb8"
   },
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 16\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# for i in range(5):\n",
    "model_test = Network(mode = 'test').to(device)\n",
    "model_test.load_state_dict(torch.load((path+'best_model_2.pth'))['state_dict'])\n",
    "model_test.eval()\n",
    "pred_prob = []\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model_test(x)\n",
    "            pred_prob.extend(pred.detach().cpu().numpy())\n",
    "    pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "expensive-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 16\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model_test = Network(mode = 'test').to(device)\n",
    "model_test.load_state_dict(torch.load((path+'best_model_2.pth'))['state_dict'])\n",
    "model_test.eval()\n",
    "f_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model_test(x)\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "GjsHs-T3SPJq",
   "metadata": {
    "id": "GjsHs-T3SPJq"
   },
   "outputs": [],
   "source": [
    "pred = np.array(pred_ensemble)\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "frozen-occupation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -7.137, -14.8  , -12.61 , ..., -10.11 ,  -5.582, -15.36 ],\n",
       "        [ -7.59 ,  -7.52 ,  -7.71 , ...,  -8.266,  -8.06 ,  -7.875],\n",
       "        [-10.586, -12.516, -10.02 , ..., -13.58 , -12.875, -11.016],\n",
       "        ...,\n",
       "        [ -6.566,  -6.1  ,  -6.66 , ...,  -6.934,  -6.81 ,  -7.348],\n",
       "        [-10.3  , -10.78 ,  -8.3  , ..., -12.32 , -13.586, -11.13 ],\n",
       "        [ -7.65 ,  -9.12 ,  -6.65 , ...,  -5.38 ,  -1.095,  -1.917]]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fatty-thursday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2154"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "UIglTwAV7L54",
   "metadata": {
    "id": "UIglTwAV7L54"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "optical-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "292QDIS5DOKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "292QDIS5DOKf",
    "outputId": "0e47d38f-d36a-40cd-a925-90e6bce52652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-poke_insulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                  label\n",
       "0         0        tile-glue_strip\n",
       "1         1              grid-good\n",
       "2         2        transistor-good\n",
       "3         3       tile-gray_stroke\n",
       "4         4              tile-good\n",
       "...     ...                    ...\n",
       "2149   2149       tile-gray_stroke\n",
       "2150   2150             screw-good\n",
       "2151   2151              grid-good\n",
       "2152   2152  cable-poke_insulation\n",
       "2153   2153            zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1naZSLGZ7L55",
   "metadata": {
    "id": "1naZSLGZ7L55"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"densenet201_2_epoch100.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2b19ece8c7374053ee1fd80cfe419ddfc640c01f9ebe4cbd5caeb9f1906974a\n",
    "\n",
    "from dacon_submit_api import dacon_submit_api \n",
    "\n",
    "result = dacon_submit_api.post_submission_file(\n",
    "'/home/densenet201_2_epoch100.csv', \n",
    "'e134e26bd4db1327ed9caad5c47c3d2fc9f161527e3829b0c593ebc832597e1a', \n",
    "'235894', \n",
    "'ideal9', \n",
    "'densenet201_BS16_2' )\n",
    "\n",
    "# https://www.dacon.io/competitions/official/235894/overview/rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p87_msjB7L51",
   "metadata": {
    "id": "p87_msjB7L51"
   },
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MW9Fx7QADii5",
   "metadata": {
    "id": "MW9Fx7QADii5"
   },
   "source": [
    "사전 학습 모델의 성능 파악을 할 때 Fold 학습은 실행 시간이 오래걸려서 fold를 나누지 않은 데이터에 대해서 학습을 진행하고 성능을 비교하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "syUpL8e_7L50",
   "metadata": {
    "id": "syUpL8e_7L50"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 30\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cJc8Yj7zrh4g",
   "metadata": {
    "id": "cJc8Yj7zrh4g"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tpCGp41k7L51",
   "metadata": {
    "id": "tpCGp41k7L51"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "\n",
    "best=0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YssPW4xq7L53",
   "metadata": {
    "id": "YssPW4xq7L53"
   },
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1w_VB_PY7L53",
   "metadata": {
    "id": "1w_VB_PY7L53"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "f_pred = []\n",
    "pred_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "            pred_prob.extend(pred.detach().cpu().numpy())\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aZMML2u3DTHx",
   "metadata": {
    "id": "aZMML2u3DTHx"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I4io2mJC7L54",
   "metadata": {
    "id": "I4io2mJC7L54"
   },
   "source": [
    "### 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XCV3FEKe7L55",
   "metadata": {
    "id": "XCV3FEKe7L55"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(path + \"open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jsl6tXbz7L56",
   "metadata": {
    "id": "jsl6tXbz7L56"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"VGG16_norm.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[BASELINE]_EfficientNet_b3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
