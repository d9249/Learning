{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LlcNsGEk7L5r",
   "metadata": {
    "id": "LlcNsGEk7L5r"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81532144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3',\n",
      " 'bat_resnext26ts',\n",
      " 'beit_base_patch16_224',\n",
      " 'beit_base_patch16_224_in22k',\n",
      " 'beit_base_patch16_384',\n",
      " 'beit_large_patch16_224',\n",
      " 'beit_large_patch16_224_in22k',\n",
      " 'beit_large_patch16_384',\n",
      " 'beit_large_patch16_512',\n",
      " 'botnet26t_256',\n",
      " 'cait_m36_384',\n",
      " 'cait_m48_448',\n",
      " 'cait_s24_224',\n",
      " 'cait_s24_384',\n",
      " 'cait_s36_384',\n",
      " 'cait_xs24_384',\n",
      " 'cait_xxs24_224',\n",
      " 'cait_xxs24_384',\n",
      " 'cait_xxs36_224',\n",
      " 'cait_xxs36_384',\n",
      " 'coat_lite_mini',\n",
      " 'coat_lite_small',\n",
      " 'coat_lite_tiny',\n",
      " 'coat_mini',\n",
      " 'coat_tiny',\n",
      " 'convit_base',\n",
      " 'convit_small',\n",
      " 'convit_tiny',\n",
      " 'convmixer_768_32',\n",
      " 'convmixer_1024_20_ks9_p14',\n",
      " 'convmixer_1536_20',\n",
      " 'convnext_base',\n",
      " 'convnext_base_384_in22ft1k',\n",
      " 'convnext_base_in22ft1k',\n",
      " 'convnext_base_in22k',\n",
      " 'convnext_large',\n",
      " 'convnext_large_384_in22ft1k',\n",
      " 'convnext_large_in22ft1k',\n",
      " 'convnext_large_in22k',\n",
      " 'convnext_small',\n",
      " 'convnext_tiny',\n",
      " 'convnext_xlarge_384_in22ft1k',\n",
      " 'convnext_xlarge_in22ft1k',\n",
      " 'convnext_xlarge_in22k',\n",
      " 'crossvit_9_240',\n",
      " 'crossvit_9_dagger_240',\n",
      " 'crossvit_15_240',\n",
      " 'crossvit_15_dagger_240',\n",
      " 'crossvit_15_dagger_408',\n",
      " 'crossvit_18_240',\n",
      " 'crossvit_18_dagger_240',\n",
      " 'crossvit_18_dagger_408',\n",
      " 'crossvit_base_240',\n",
      " 'crossvit_small_240',\n",
      " 'crossvit_tiny_240',\n",
      " 'cspdarknet53',\n",
      " 'cspresnet50',\n",
      " 'cspresnext50',\n",
      " 'deit_base_distilled_patch16_224',\n",
      " 'deit_base_distilled_patch16_384',\n",
      " 'deit_base_patch16_224',\n",
      " 'deit_base_patch16_384',\n",
      " 'deit_small_distilled_patch16_224',\n",
      " 'deit_small_patch16_224',\n",
      " 'deit_tiny_distilled_patch16_224',\n",
      " 'deit_tiny_patch16_224',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dm_nfnet_f0',\n",
      " 'dm_nfnet_f1',\n",
      " 'dm_nfnet_f2',\n",
      " 'dm_nfnet_f3',\n",
      " 'dm_nfnet_f4',\n",
      " 'dm_nfnet_f5',\n",
      " 'dm_nfnet_f6',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'eca_botnext26ts_256',\n",
      " 'eca_halonext26ts',\n",
      " 'eca_nfnet_l0',\n",
      " 'eca_nfnet_l1',\n",
      " 'eca_nfnet_l2',\n",
      " 'eca_resnet33ts',\n",
      " 'eca_resnext26ts',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b4',\n",
      " 'efficientnet_el',\n",
      " 'efficientnet_el_pruned',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_es_pruned',\n",
      " 'efficientnet_lite0',\n",
      " 'efficientnetv2_rw_m',\n",
      " 'efficientnetv2_rw_s',\n",
      " 'efficientnetv2_rw_t',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'fbnetc_100',\n",
      " 'fbnetv3_b',\n",
      " 'fbnetv3_d',\n",
      " 'fbnetv3_g',\n",
      " 'gc_efficientnetv2_rw_t',\n",
      " 'gcresnet33ts',\n",
      " 'gcresnet50t',\n",
      " 'gcresnext26ts',\n",
      " 'gcresnext50ts',\n",
      " 'gernet_l',\n",
      " 'gernet_m',\n",
      " 'gernet_s',\n",
      " 'ghostnet_100',\n",
      " 'gluon_inception_v3',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_senet154',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'gluon_xception65',\n",
      " 'gmixer_24_224',\n",
      " 'gmlp_s16_224',\n",
      " 'halo2botnet50ts_256',\n",
      " 'halonet26t',\n",
      " 'halonet50ts',\n",
      " 'haloregnetz_b',\n",
      " 'hardcorenas_a',\n",
      " 'hardcorenas_b',\n",
      " 'hardcorenas_c',\n",
      " 'hardcorenas_d',\n",
      " 'hardcorenas_e',\n",
      " 'hardcorenas_f',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w64',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'jx_nest_base',\n",
      " 'jx_nest_small',\n",
      " 'jx_nest_tiny',\n",
      " 'lambda_resnet26rpt_256',\n",
      " 'lambda_resnet26t',\n",
      " 'lambda_resnet50ts',\n",
      " 'lamhalobotnet50ts_256',\n",
      " 'lcnet_050',\n",
      " 'lcnet_075',\n",
      " 'lcnet_100',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'levit_128',\n",
      " 'levit_128s',\n",
      " 'levit_192',\n",
      " 'levit_256',\n",
      " 'levit_384',\n",
      " 'mixer_b16_224',\n",
      " 'mixer_b16_224_in21k',\n",
      " 'mixer_b16_224_miil',\n",
      " 'mixer_b16_224_miil_in21k',\n",
      " 'mixer_l16_224',\n",
      " 'mixer_l16_224_in21k',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mnasnet_100',\n",
      " 'mnasnet_small',\n",
      " 'mobilenetv2_050',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_large_100_miil',\n",
      " 'mobilenetv3_large_100_miil_in21k',\n",
      " 'mobilenetv3_rw',\n",
      " 'nasnetalarge',\n",
      " 'nf_regnet_b1',\n",
      " 'nf_resnet50',\n",
      " 'nfnet_l0',\n",
      " 'pit_b_224',\n",
      " 'pit_b_distilled_224',\n",
      " 'pit_s_224',\n",
      " 'pit_s_distilled_224',\n",
      " 'pit_ti_224',\n",
      " 'pit_ti_distilled_224',\n",
      " 'pit_xs_224',\n",
      " 'pit_xs_distilled_224',\n",
      " 'pnasnet5large',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'regnetz_b16',\n",
      " 'regnetz_c16',\n",
      " 'regnetz_d8',\n",
      " 'regnetz_d32',\n",
      " 'regnetz_e8',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2next50',\n",
      " 'resmlp_12_224',\n",
      " 'resmlp_12_224_dino',\n",
      " 'resmlp_12_distilled_224',\n",
      " 'resmlp_24_224',\n",
      " 'resmlp_24_224_dino',\n",
      " 'resmlp_24_distilled_224',\n",
      " 'resmlp_36_224',\n",
      " 'resmlp_36_distilled_224',\n",
      " 'resmlp_big_24_224',\n",
      " 'resmlp_big_24_224_in22ft1k',\n",
      " 'resmlp_big_24_distilled_224',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet26t',\n",
      " 'resnet32ts',\n",
      " 'resnet33ts',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50_gn',\n",
      " 'resnet50d',\n",
      " 'resnet51q',\n",
      " 'resnet61q',\n",
      " 'resnet101',\n",
      " 'resnet101d',\n",
      " 'resnet152',\n",
      " 'resnet152d',\n",
      " 'resnet200d',\n",
      " 'resnetblur50',\n",
      " 'resnetrs50',\n",
      " 'resnetrs101',\n",
      " 'resnetrs152',\n",
      " 'resnetrs200',\n",
      " 'resnetrs270',\n",
      " 'resnetrs350',\n",
      " 'resnetrs420',\n",
      " 'resnetv2_50',\n",
      " 'resnetv2_50x1_bit_distilled',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bit_teacher',\n",
      " 'resnetv2_152x2_bit_teacher_384',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext26ts',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'sebotnet33ts_256',\n",
      " 'sehalonet33ts',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'semnasnet_075',\n",
      " 'semnasnet_100',\n",
      " 'seresnet33ts',\n",
      " 'seresnet50',\n",
      " 'seresnet152d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext26ts',\n",
      " 'seresnext50_32x4d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swin_base_patch4_window7_224',\n",
      " 'swin_base_patch4_window7_224_in22k',\n",
      " 'swin_base_patch4_window12_384',\n",
      " 'swin_base_patch4_window12_384_in22k',\n",
      " 'swin_large_patch4_window7_224',\n",
      " 'swin_large_patch4_window7_224_in22k',\n",
      " 'swin_large_patch4_window12_384',\n",
      " 'swin_large_patch4_window12_384_in22k',\n",
      " 'swin_small_patch4_window7_224',\n",
      " 'swin_tiny_patch4_window7_224',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b0_ap',\n",
      " 'tf_efficientnet_b0_ns',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b1_ap',\n",
      " 'tf_efficientnet_b1_ns',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b2_ap',\n",
      " 'tf_efficientnet_b2_ns',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b3_ap',\n",
      " 'tf_efficientnet_b3_ns',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b4_ap',\n",
      " 'tf_efficientnet_b4_ns',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b5_ap',\n",
      " 'tf_efficientnet_b5_ns',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b6_ap',\n",
      " 'tf_efficientnet_b6_ns',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b7_ap',\n",
      " 'tf_efficientnet_b7_ns',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_b8_ap',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2_ns',\n",
      " 'tf_efficientnet_l2_ns_475',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_efficientnetv2_b0',\n",
      " 'tf_efficientnetv2_b1',\n",
      " 'tf_efficientnetv2_b2',\n",
      " 'tf_efficientnetv2_b3',\n",
      " 'tf_efficientnetv2_l',\n",
      " 'tf_efficientnetv2_l_in21ft1k',\n",
      " 'tf_efficientnetv2_l_in21k',\n",
      " 'tf_efficientnetv2_m',\n",
      " 'tf_efficientnetv2_m_in21ft1k',\n",
      " 'tf_efficientnetv2_m_in21k',\n",
      " 'tf_efficientnetv2_s',\n",
      " 'tf_efficientnetv2_s_in21ft1k',\n",
      " 'tf_efficientnetv2_s_in21k',\n",
      " 'tf_efficientnetv2_xl_in21ft1k',\n",
      " 'tf_efficientnetv2_xl_in21k',\n",
      " 'tf_inception_v3',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tinynet_a',\n",
      " 'tinynet_b',\n",
      " 'tinynet_c',\n",
      " 'tinynet_d',\n",
      " 'tinynet_e',\n",
      " 'tnt_s_patch16_224',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_m_miil_in21k',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_densenet121',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'twins_pcpvt_base',\n",
      " 'twins_pcpvt_large',\n",
      " 'twins_pcpvt_small',\n",
      " 'twins_svt_base',\n",
      " 'twins_svt_large',\n",
      " 'twins_svt_small',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'visformer_small',\n",
      " 'vit_base_patch8_224',\n",
      " 'vit_base_patch8_224_in21k',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_224_in21k',\n",
      " 'vit_base_patch16_224_miil',\n",
      " 'vit_base_patch16_224_miil_in21k',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch16_sam_224',\n",
      " 'vit_base_patch32_224',\n",
      " 'vit_base_patch32_224_in21k',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_patch32_sam_224',\n",
      " 'vit_base_r50_s16_224_in21k',\n",
      " 'vit_base_r50_s16_384',\n",
      " 'vit_huge_patch14_224_in21k',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_224_in21k',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch32_224_in21k',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_large_r50_s32_224',\n",
      " 'vit_large_r50_s32_224_in21k',\n",
      " 'vit_large_r50_s32_384',\n",
      " 'vit_small_patch16_224',\n",
      " 'vit_small_patch16_224_in21k',\n",
      " 'vit_small_patch16_384',\n",
      " 'vit_small_patch32_224',\n",
      " 'vit_small_patch32_224_in21k',\n",
      " 'vit_small_patch32_384',\n",
      " 'vit_small_r26_s32_224',\n",
      " 'vit_small_r26_s32_224_in21k',\n",
      " 'vit_small_r26_s32_384',\n",
      " 'vit_tiny_patch16_224',\n",
      " 'vit_tiny_patch16_224_in21k',\n",
      " 'vit_tiny_patch16_384',\n",
      " 'vit_tiny_r_s16_p8_224',\n",
      " 'vit_tiny_r_s16_p8_224_in21k',\n",
      " 'vit_tiny_r_s16_p8_384',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception',\n",
      " 'xception41',\n",
      " 'xception65',\n",
      " 'xception71',\n",
      " 'xcit_large_24_p8_224',\n",
      " 'xcit_large_24_p8_224_dist',\n",
      " 'xcit_large_24_p8_384_dist',\n",
      " 'xcit_large_24_p16_224',\n",
      " 'xcit_large_24_p16_224_dist',\n",
      " 'xcit_large_24_p16_384_dist',\n",
      " 'xcit_medium_24_p8_224',\n",
      " 'xcit_medium_24_p8_224_dist',\n",
      " 'xcit_medium_24_p8_384_dist',\n",
      " 'xcit_medium_24_p16_224',\n",
      " 'xcit_medium_24_p16_224_dist',\n",
      " 'xcit_medium_24_p16_384_dist',\n",
      " 'xcit_nano_12_p8_224',\n",
      " 'xcit_nano_12_p8_224_dist',\n",
      " 'xcit_nano_12_p8_384_dist',\n",
      " 'xcit_nano_12_p16_224',\n",
      " 'xcit_nano_12_p16_224_dist',\n",
      " 'xcit_nano_12_p16_384_dist',\n",
      " 'xcit_small_12_p8_224',\n",
      " 'xcit_small_12_p8_224_dist',\n",
      " 'xcit_small_12_p8_384_dist',\n",
      " 'xcit_small_12_p16_224',\n",
      " 'xcit_small_12_p16_224_dist',\n",
      " 'xcit_small_12_p16_384_dist',\n",
      " 'xcit_small_24_p8_224',\n",
      " 'xcit_small_24_p8_224_dist',\n",
      " 'xcit_small_24_p8_384_dist',\n",
      " 'xcit_small_24_p16_224',\n",
      " 'xcit_small_24_p16_224_dist',\n",
      " 'xcit_small_24_p16_384_dist',\n",
      " 'xcit_tiny_12_p8_224',\n",
      " 'xcit_tiny_12_p8_224_dist',\n",
      " 'xcit_tiny_12_p8_384_dist',\n",
      " 'xcit_tiny_12_p16_224',\n",
      " 'xcit_tiny_12_p16_224_dist',\n",
      " 'xcit_tiny_12_p16_384_dist',\n",
      " 'xcit_tiny_24_p8_224',\n",
      " 'xcit_tiny_24_p8_224_dist',\n",
      " 'xcit_tiny_24_p8_384_dist',\n",
      " 'xcit_tiny_24_p16_224',\n",
      " 'xcit_tiny_24_p16_224_dist',\n",
      " 'xcit_tiny_24_p16_384_dist']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lXH5F_hA7uMl",
   "metadata": {
    "id": "lXH5F_hA7uMl"
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/ideal/Downloads/jupyter/user_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "FWntO1VD7L5u",
   "metadata": {
    "id": "FWntO1VD7L5u"
   },
   "outputs": [],
   "source": [
    "train_png = sorted(glob(path + 'train/*.png'))\n",
    "test_png = sorted(glob(path + 'test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atSgPJRn-OCW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atSgPJRn-OCW",
    "outputId": "87b6f90b-5c1c-4a0e-de54-994458543687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(858, 215)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_png), len(test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "xv0_rDVq7L5v",
   "metadata": {
    "id": "xv0_rDVq7L5v"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(path +\"train.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc9232f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0,\n",
       " '10-1': 1,\n",
       " '10-2': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "iMhC0nPw7L5w",
   "metadata": {
    "id": "iMhC0nPw7L5w"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "#     img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "zsmJA3E97L5x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsmJA3E97L5x",
    "outputId": "e0dc61fe-5617-42e8-c8b0-0e95b9f60656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 858/858 [00:01<00:00, 657.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 215/215 [00:00<00:00, 757.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "KA73Lku9A2N9",
   "metadata": {
    "id": "KA73Lku9A2N9"
   },
   "outputs": [],
   "source": [
    "np.save(path + 'train_imgs_384', np.array(train_imgs))\n",
    "np.save(path + 'test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "L6qBdX7nCp8L",
   "metadata": {
    "id": "L6qBdX7nCp8L"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.load(path + 'train_imgs_384.npy')\n",
    "test_imgs = np.load(path + 'test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9207e10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평균 0.587861452947292 0.5398018372012267 0.4853426659853918\n",
      "train 표준편차 0.15058758283288234 0.15921522386293296 0.17031454681984776\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "train_meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "train_meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "train_meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "train_stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "train_stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "train_stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"train 평균\",train_meanR, train_meanG, train_meanB)\n",
    "print(\"train 표준편차\",train_stdR, train_stdG, train_stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "935064b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 평균 0.5915704246815005 0.5468021681783177 0.49356994941872095\n",
      "test 표준편차 0.15494109227168867 0.1642936360901455 0.1756015391157054\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "test_meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "test_meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "test_meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "test_stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "test_stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "test_stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"test 평균\",test_meanR, test_meanG, test_meanB)\n",
    "print(\"test 표준편차\",test_stdR, test_stdG, test_stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "VFXzojoo7L5y",
   "metadata": {
    "id": "VFXzojoo7L5y"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [train_meanR, train_meanG, train_meanB],\n",
    "                                     std = [train_stdR, train_stdG, train_stdB]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [test_meanR, test_meanG, test_meanB],\n",
    "                                     std = [test_stdR, test_stdG, test_stdB])\n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('vgg16', pretrained=True, num_classes=11)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('vgg16', pretrained=True, num_classes=11)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38qk8sGbYiO_",
   "metadata": {
    "id": "38qk8sGbYiO_"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lkNCkyG9RPzX",
   "metadata": {
    "id": "lkNCkyG9RPzX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\ideal/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 13s/1271s\n",
      "TRAIN    loss : 1.59183    f1 : 0.44606\n",
      "Val    loss : 0.80320    f1 : 0.63795\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 11s/1032s\n",
      "TRAIN    loss : 0.89282    f1 : 0.68176\n",
      "Val    loss : 0.81969    f1 : 0.70291\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 11s/1034s\n",
      "TRAIN    loss : 0.52956    f1 : 0.81460\n",
      "Val    loss : 0.45741    f1 : 0.79324\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 11s/1013s\n",
      "TRAIN    loss : 0.36732    f1 : 0.87948\n",
      "Val    loss : 0.47753    f1 : 0.82827\n",
      "epoch : 5/100    time : 8s/804s\n",
      "TRAIN    loss : 0.35039    f1 : 0.88894\n",
      "Val    loss : 0.55347    f1 : 0.80567\n",
      "epoch : 6/100    time : 8s/778s\n",
      "TRAIN    loss : 0.41957    f1 : 0.86775\n",
      "Val    loss : 0.70938    f1 : 0.78008\n",
      "epoch : 7/100    time : 8s/779s\n",
      "TRAIN    loss : 0.29657    f1 : 0.90008\n",
      "Val    loss : 0.48036    f1 : 0.81129\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 11s/977s\n",
      "TRAIN    loss : 0.22344    f1 : 0.91684\n",
      "Val    loss : 0.22589    f1 : 0.93617\n",
      "epoch : 9/100    time : 9s/802s\n",
      "TRAIN    loss : 0.24487    f1 : 0.93110\n",
      "Val    loss : 0.65209    f1 : 0.79136\n",
      "epoch : 10/100    time : 9s/774s\n",
      "TRAIN    loss : 0.16572    f1 : 0.94767\n",
      "Val    loss : 0.41521    f1 : 0.86280\n",
      "epoch : 11/100    time : 8s/736s\n",
      "TRAIN    loss : 0.24458    f1 : 0.91801\n",
      "Val    loss : 0.44038    f1 : 0.87263\n",
      "epoch : 12/100    time : 8s/732s\n",
      "TRAIN    loss : 0.17153    f1 : 0.94185\n",
      "Val    loss : 0.49949    f1 : 0.88260\n",
      "epoch : 13/100    time : 9s/740s\n",
      "TRAIN    loss : 0.11147    f1 : 0.97261\n",
      "Val    loss : 0.51598    f1 : 0.84744\n",
      "epoch : 14/100    time : 9s/739s\n",
      "TRAIN    loss : 0.16678    f1 : 0.95089\n",
      "Val    loss : 0.38115    f1 : 0.89956\n",
      "epoch : 15/100    time : 9s/734s\n",
      "TRAIN    loss : 0.17396    f1 : 0.95098\n",
      "Val    loss : 0.38383    f1 : 0.87160\n",
      "epoch : 16/100    time : 8s/703s\n",
      "TRAIN    loss : 0.07145    f1 : 0.98184\n",
      "Val    loss : 0.32355    f1 : 0.91207\n",
      "epoch : 17/100    time : 8s/704s\n",
      "TRAIN    loss : 0.29140    f1 : 0.90637\n",
      "Val    loss : 0.39556    f1 : 0.89130\n",
      "epoch : 18/100    time : 9s/697s\n",
      "TRAIN    loss : 0.20536    f1 : 0.94305\n",
      "Val    loss : 0.35578    f1 : 0.89633\n",
      "epoch : 19/100    time : 8s/680s\n",
      "TRAIN    loss : 0.11722    f1 : 0.96259\n",
      "Val    loss : 0.61665    f1 : 0.83046\n",
      "epoch : 20/100    time : 8s/677s\n",
      "TRAIN    loss : 0.73175    f1 : 0.91805\n",
      "Val    loss : 0.31635    f1 : 0.90832\n",
      "epoch : 21/100    time : 9s/681s\n",
      "TRAIN    loss : 0.11950    f1 : 0.96464\n",
      "Val    loss : 0.31786    f1 : 0.87583\n",
      "epoch : 22/100    time : 9s/674s\n",
      "TRAIN    loss : 0.07669    f1 : 0.97704\n",
      "Val    loss : 0.76350    f1 : 0.82256\n",
      "epoch : 23/100    time : 9s/665s\n",
      "TRAIN    loss : 0.25362    f1 : 0.94425\n",
      "Val    loss : 0.69094    f1 : 0.73485\n",
      "epoch : 24/100    time : 9s/660s\n",
      "TRAIN    loss : 0.12611    f1 : 0.96596\n",
      "Val    loss : 0.41749    f1 : 0.91209\n",
      "epoch : 25/100    time : 9s/647s\n",
      "TRAIN    loss : 0.11793    f1 : 0.96243\n",
      "Val    loss : 0.23083    f1 : 0.93041\n",
      "epoch : 26/100    time : 9s/632s\n",
      "TRAIN    loss : 0.05054    f1 : 0.98158\n",
      "Val    loss : 0.38003    f1 : 0.90108\n",
      "epoch : 27/100    time : 8s/617s\n",
      "TRAIN    loss : 0.11605    f1 : 0.96435\n",
      "Val    loss : 0.34639    f1 : 0.90964\n",
      "epoch : 28/100    time : 9s/613s\n",
      "TRAIN    loss : 0.02809    f1 : 0.99018\n",
      "Val    loss : 0.21933    f1 : 0.91680\n",
      "----------fold_1 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 11s/1051s\n",
      "TRAIN    loss : 1.57640    f1 : 0.44101\n",
      "Val    loss : 0.70367    f1 : 0.68776\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 11s/1054s\n",
      "TRAIN    loss : 0.81368    f1 : 0.72432\n",
      "Val    loss : 0.44624    f1 : 0.79814\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 11s/1023s\n",
      "TRAIN    loss : 0.46663    f1 : 0.83455\n",
      "Val    loss : 0.44248    f1 : 0.83244\n",
      "epoch : 4/100    time : 8s/807s\n",
      "TRAIN    loss : 0.46319    f1 : 0.82888\n",
      "Val    loss : 0.57614    f1 : 0.76339\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 10s/986s\n",
      "TRAIN    loss : 0.36144    f1 : 0.86746\n",
      "Val    loss : 0.37417    f1 : 0.85663\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 11s/1041s\n",
      "TRAIN    loss : 0.23929    f1 : 0.93219\n",
      "Val    loss : 0.26463    f1 : 0.93676\n",
      "epoch : 7/100    time : 9s/826s\n",
      "TRAIN    loss : 0.23188    f1 : 0.93758\n",
      "Val    loss : 0.27446    f1 : 0.92510\n",
      "epoch : 8/100    time : 9s/795s\n",
      "TRAIN    loss : 0.28503    f1 : 0.90563\n",
      "Val    loss : 0.68872    f1 : 0.86331\n",
      "epoch : 9/100    time : 9s/789s\n",
      "TRAIN    loss : 0.30918    f1 : 0.91917\n",
      "Val    loss : 0.23491    f1 : 0.93577\n",
      "epoch : 10/100    time : 8s/763s\n",
      "TRAIN    loss : 0.14403    f1 : 0.94914\n",
      "Val    loss : 0.48336    f1 : 0.90745\n",
      "epoch : 11/100    time : 9s/759s\n",
      "TRAIN    loss : 0.22415    f1 : 0.93195\n",
      "Val    loss : 0.41070    f1 : 0.88867\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 11s/933s\n",
      "TRAIN    loss : 0.13471    f1 : 0.95600\n",
      "Val    loss : 0.14387    f1 : 0.96546\n",
      "epoch : 13/100    time : 9s/742s\n",
      "TRAIN    loss : 0.12178    f1 : 0.96896\n",
      "Val    loss : 0.49933    f1 : 0.90921\n",
      "epoch : 14/100    time : 8s/714s\n",
      "TRAIN    loss : 0.15206    f1 : 0.94903\n",
      "Val    loss : 0.27638    f1 : 0.93125\n",
      "epoch : 15/100    time : 8s/706s\n",
      "TRAIN    loss : 0.31116    f1 : 0.90706\n",
      "Val    loss : 0.40815    f1 : 0.85956\n",
      "epoch : 16/100    time : 8s/704s\n",
      "TRAIN    loss : 0.12426    f1 : 0.95150\n",
      "Val    loss : 0.47998    f1 : 0.85453\n",
      "epoch : 17/100    time : 8s/700s\n",
      "TRAIN    loss : 0.15421    f1 : 0.94386\n",
      "Val    loss : 0.31119    f1 : 0.92276\n",
      "epoch : 18/100    time : 8s/694s\n",
      "TRAIN    loss : 0.15274    f1 : 0.93859\n",
      "Val    loss : 0.35040    f1 : 0.90957\n",
      "epoch : 19/100    time : 8s/681s\n",
      "TRAIN    loss : 0.12147    f1 : 0.96495\n",
      "Val    loss : 0.20583    f1 : 0.93481\n",
      "-----------------SAVE:20 epoch----------------\n",
      "epoch : 20/100    time : 11s/844s\n",
      "TRAIN    loss : 0.10386    f1 : 0.97407\n",
      "Val    loss : 0.16154    f1 : 0.96618\n",
      "epoch : 21/100    time : 9s/689s\n",
      "TRAIN    loss : 0.11376    f1 : 0.95561\n",
      "Val    loss : 0.12511    f1 : 0.94272\n",
      "epoch : 22/100    time : 8s/661s\n",
      "TRAIN    loss : 0.16666    f1 : 0.94861\n",
      "Val    loss : 0.61650    f1 : 0.85934\n",
      "epoch : 23/100    time : 8s/650s\n",
      "TRAIN    loss : 0.31994    f1 : 0.91114\n",
      "Val    loss : 0.62251    f1 : 0.81168\n",
      "epoch : 24/100    time : 8s/640s\n",
      "TRAIN    loss : 0.22444    f1 : 0.93285\n",
      "Val    loss : 0.23946    f1 : 0.93405\n",
      "epoch : 25/100    time : 8s/621s\n",
      "TRAIN    loss : 0.10675    f1 : 0.96839\n",
      "Val    loss : 0.21352    f1 : 0.93691\n",
      "epoch : 26/100    time : 8s/611s\n",
      "TRAIN    loss : 0.02189    f1 : 0.99575\n",
      "Val    loss : 0.17089    f1 : 0.95911\n",
      "epoch : 27/100    time : 8s/604s\n",
      "TRAIN    loss : 0.02899    f1 : 0.98823\n",
      "Val    loss : 0.18588    f1 : 0.96439\n",
      "-----------------SAVE:28 epoch----------------\n",
      "epoch : 28/100    time : 10s/743s\n",
      "TRAIN    loss : 0.00701    f1 : 0.99716\n",
      "Val    loss : 0.15053    f1 : 0.97006\n",
      "epoch : 29/100    time : 9s/630s\n",
      "TRAIN    loss : 0.02271    f1 : 0.99433\n",
      "Val    loss : 0.20268    f1 : 0.92794\n",
      "epoch : 30/100    time : 8s/583s\n",
      "TRAIN    loss : 0.04907    f1 : 0.98442\n",
      "Val    loss : 0.11259    f1 : 0.96367\n",
      "epoch : 31/100    time : 9s/594s\n",
      "TRAIN    loss : 0.14063    f1 : 0.97304\n",
      "Val    loss : 0.16480    f1 : 0.93042\n",
      "epoch : 32/100    time : 9s/581s\n",
      "TRAIN    loss : 0.27681    f1 : 0.91522\n",
      "Val    loss : 0.68999    f1 : 0.77336\n",
      "epoch : 33/100    time : 9s/575s\n",
      "TRAIN    loss : 0.24419    f1 : 0.92778\n",
      "Val    loss : 0.16275    f1 : 0.95217\n",
      "epoch : 34/100    time : 9s/565s\n",
      "TRAIN    loss : 0.12532    f1 : 0.96113\n",
      "Val    loss : 0.29143    f1 : 0.93241\n",
      "epoch : 35/100    time : 9s/557s\n",
      "TRAIN    loss : 0.07386    f1 : 0.98547\n",
      "Val    loss : 0.16720    f1 : 0.93361\n",
      "epoch : 36/100    time : 8s/531s\n",
      "TRAIN    loss : 0.05722    f1 : 0.98574\n",
      "Val    loss : 0.20585    f1 : 0.93494\n",
      "epoch : 37/100    time : 9s/539s\n",
      "TRAIN    loss : 0.06791    f1 : 0.97602\n",
      "Val    loss : 0.38496    f1 : 0.93092\n",
      "epoch : 38/100    time : 9s/535s\n",
      "TRAIN    loss : 0.03304    f1 : 0.99265\n",
      "Val    loss : 0.15028    f1 : 0.96280\n",
      "epoch : 39/100    time : 9s/528s\n",
      "TRAIN    loss : 0.04380    f1 : 0.98543\n",
      "Val    loss : 0.70365    f1 : 0.83266\n",
      "epoch : 40/100    time : 9s/518s\n",
      "TRAIN    loss : 0.07751    f1 : 0.97853\n",
      "Val    loss : 0.15175    f1 : 0.92823\n",
      "epoch : 41/100    time : 9s/511s\n",
      "TRAIN    loss : 0.16077    f1 : 0.96371\n",
      "Val    loss : 0.35033    f1 : 0.88638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 42/100    time : 9s/505s\n",
      "TRAIN    loss : 0.08209    f1 : 0.97489\n",
      "Val    loss : 0.17078    f1 : 0.95322\n",
      "epoch : 43/100    time : 9s/495s\n",
      "TRAIN    loss : 0.08867    f1 : 0.98070\n",
      "Val    loss : 0.23982    f1 : 0.90221\n",
      "epoch : 44/100    time : 9s/487s\n",
      "TRAIN    loss : 0.06109    f1 : 0.97863\n",
      "Val    loss : 0.13126    f1 : 0.94595\n",
      "epoch : 45/100    time : 9s/478s\n",
      "TRAIN    loss : 0.05608    f1 : 0.99004\n",
      "Val    loss : 0.24507    f1 : 0.93667\n",
      "epoch : 46/100    time : 9s/467s\n",
      "TRAIN    loss : 0.07400    f1 : 0.98429\n",
      "Val    loss : 0.10871    f1 : 0.95844\n",
      "epoch : 47/100    time : 9s/459s\n",
      "TRAIN    loss : 0.00713    f1 : 1.00000\n",
      "Val    loss : 0.16007    f1 : 0.96407\n",
      "-----------------SAVE:48 epoch----------------\n",
      "epoch : 48/100    time : 11s/561s\n",
      "TRAIN    loss : 0.01971    f1 : 0.99443\n",
      "Val    loss : 0.12821    f1 : 0.97549\n",
      "-----------------SAVE:49 epoch----------------\n",
      "epoch : 49/100    time : 11s/564s\n",
      "TRAIN    loss : 0.04090    f1 : 0.99437\n",
      "Val    loss : 0.08481    f1 : 0.97568\n",
      "epoch : 50/100    time : 9s/442s\n",
      "TRAIN    loss : 0.01237    f1 : 0.99577\n",
      "Val    loss : 0.14258    f1 : 0.95119\n",
      "epoch : 51/100    time : 9s/421s\n",
      "TRAIN    loss : 0.09024    f1 : 0.97468\n",
      "Val    loss : 0.09373    f1 : 0.96446\n",
      "epoch : 52/100    time : 8s/404s\n",
      "TRAIN    loss : 0.08752    f1 : 0.97361\n",
      "Val    loss : 0.26430    f1 : 0.94875\n",
      "epoch : 53/100    time : 8s/398s\n",
      "TRAIN    loss : 0.13546    f1 : 0.96038\n",
      "Val    loss : 0.28609    f1 : 0.93601\n",
      "epoch : 54/100    time : 9s/398s\n",
      "TRAIN    loss : 0.04974    f1 : 0.98313\n",
      "Val    loss : 3.22909    f1 : 0.87384\n",
      "epoch : 55/100    time : 9s/388s\n",
      "TRAIN    loss : 0.15340    f1 : 0.96997\n",
      "Val    loss : 0.19070    f1 : 0.94625\n",
      "epoch : 56/100    time : 9s/378s\n",
      "TRAIN    loss : 0.08755    f1 : 0.97125\n",
      "Val    loss : 0.23064    f1 : 0.94675\n",
      "epoch : 57/100    time : 9s/370s\n",
      "TRAIN    loss : 0.19077    f1 : 0.96261\n",
      "Val    loss : 0.20779    f1 : 0.92955\n",
      "epoch : 58/100    time : 8s/347s\n",
      "TRAIN    loss : 0.02530    f1 : 0.99148\n",
      "Val    loss : 0.17821    f1 : 0.95797\n",
      "epoch : 59/100    time : 8s/338s\n",
      "TRAIN    loss : 0.12655    f1 : 0.97143\n",
      "Val    loss : 0.62015    f1 : 0.80187\n",
      "epoch : 60/100    time : 8s/331s\n",
      "TRAIN    loss : 0.12950    f1 : 0.96733\n",
      "Val    loss : 0.42319    f1 : 0.93476\n",
      "epoch : 61/100    time : 8s/323s\n",
      "TRAIN    loss : 0.18361    f1 : 0.94873\n",
      "Val    loss : 0.14271    f1 : 0.95289\n",
      "epoch : 62/100    time : 8s/313s\n",
      "TRAIN    loss : 0.20293    f1 : 0.95195\n",
      "Val    loss : 0.13870    f1 : 0.94626\n",
      "epoch : 63/100    time : 8s/314s\n",
      "TRAIN    loss : 0.02388    f1 : 0.99436\n",
      "Val    loss : 0.13746    f1 : 0.95283\n",
      "epoch : 64/100    time : 8s/301s\n",
      "TRAIN    loss : 0.04804    f1 : 0.99159\n",
      "Val    loss : 0.49010    f1 : 0.91972\n",
      "epoch : 65/100    time : 9s/298s\n",
      "TRAIN    loss : 0.14403    f1 : 0.96085\n",
      "Val    loss : 0.21830    f1 : 0.93668\n",
      "epoch : 66/100    time : 9s/295s\n",
      "TRAIN    loss : 0.00997    f1 : 0.99856\n",
      "Val    loss : 0.28421    f1 : 0.95340\n",
      "epoch : 67/100    time : 9s/286s\n",
      "TRAIN    loss : 0.10398    f1 : 0.97997\n",
      "Val    loss : 0.35857    f1 : 0.91845\n",
      "epoch : 68/100    time : 9s/278s\n",
      "TRAIN    loss : 0.10420    f1 : 0.97583\n",
      "Val    loss : 0.18446    f1 : 0.94322\n",
      "epoch : 69/100    time : 9s/269s\n",
      "TRAIN    loss : 0.07644    f1 : 0.97800\n",
      "Val    loss : 0.17260    f1 : 0.95300\n",
      "----------fold_2 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 11s/1053s\n",
      "TRAIN    loss : 1.89681    f1 : 0.34738\n",
      "Val    loss : 1.34397    f1 : 0.50868\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 11s/1045s\n",
      "TRAIN    loss : 0.99729    f1 : 0.65146\n",
      "Val    loss : 0.79246    f1 : 0.65926\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 11s/1045s\n",
      "TRAIN    loss : 0.60807    f1 : 0.78925\n",
      "Val    loss : 0.56709    f1 : 0.80699\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 11s/1018s\n",
      "TRAIN    loss : 0.49195    f1 : 0.83263\n",
      "Val    loss : 0.42097    f1 : 0.83215\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 11s/1019s\n",
      "TRAIN    loss : 0.37564    f1 : 0.87170\n",
      "Val    loss : 0.26693    f1 : 0.89021\n",
      "epoch : 6/100    time : 9s/801s\n",
      "TRAIN    loss : 0.32638    f1 : 0.89830\n",
      "Val    loss : 0.45802    f1 : 0.84895\n",
      "epoch : 7/100    time : 8s/767s\n",
      "TRAIN    loss : 0.28552    f1 : 0.92508\n",
      "Val    loss : 0.54044    f1 : 0.80174\n",
      "epoch : 8/100    time : 8s/753s\n",
      "TRAIN    loss : 0.24553    f1 : 0.91440\n",
      "Val    loss : 0.47054    f1 : 0.83716\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 10s/931s\n",
      "TRAIN    loss : 0.26588    f1 : 0.91373\n",
      "Val    loss : 0.27703    f1 : 0.94401\n",
      "epoch : 10/100    time : 8s/755s\n",
      "TRAIN    loss : 0.22231    f1 : 0.93393\n",
      "Val    loss : 0.37477    f1 : 0.88208\n",
      "epoch : 11/100    time : 8s/729s\n",
      "TRAIN    loss : 0.18005    f1 : 0.95183\n",
      "Val    loss : 0.44183    f1 : 0.88165\n",
      "epoch : 12/100    time : 8s/720s\n",
      "TRAIN    loss : 0.17648    f1 : 0.94053\n",
      "Val    loss : 0.45037    f1 : 0.86624\n",
      "epoch : 13/100    time : 8s/715s\n",
      "TRAIN    loss : 0.09742    f1 : 0.97169\n",
      "Val    loss : 0.36095    f1 : 0.89422\n",
      "epoch : 14/100    time : 9s/732s\n",
      "TRAIN    loss : 0.15087    f1 : 0.94953\n",
      "Val    loss : 0.29975    f1 : 0.92715\n",
      "epoch : 15/100    time : 8s/708s\n",
      "TRAIN    loss : 0.17913    f1 : 0.95119\n",
      "Val    loss : 0.27368    f1 : 0.91908\n",
      "epoch : 16/100    time : 8s/707s\n",
      "TRAIN    loss : 0.12073    f1 : 0.96039\n",
      "Val    loss : 0.37972    f1 : 0.90851\n",
      "epoch : 17/100    time : 8s/685s\n",
      "TRAIN    loss : 0.17707    f1 : 0.94288\n",
      "Val    loss : 0.29757    f1 : 0.89810\n",
      "epoch : 18/100    time : 8s/672s\n",
      "TRAIN    loss : 0.15022    f1 : 0.96040\n",
      "Val    loss : 0.24962    f1 : 0.92588\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/100    time : 10s/832s\n",
      "TRAIN    loss : 0.03101    f1 : 0.99143\n",
      "Val    loss : 0.17973    f1 : 0.94436\n",
      "epoch : 20/100    time : 8s/676s\n",
      "TRAIN    loss : 0.07163    f1 : 0.98270\n",
      "Val    loss : 0.19819    f1 : 0.93567\n",
      "epoch : 21/100    time : 8s/649s\n",
      "TRAIN    loss : 0.10489    f1 : 0.97100\n",
      "Val    loss : 0.21320    f1 : 0.94412\n",
      "-----------------SAVE:22 epoch----------------\n",
      "epoch : 22/100    time : 10s/797s\n",
      "TRAIN    loss : 0.09708    f1 : 0.97359\n",
      "Val    loss : 0.17602    f1 : 0.94977\n",
      "epoch : 23/100    time : 8s/647s\n",
      "TRAIN    loss : 0.09888    f1 : 0.97422\n",
      "Val    loss : 0.22856    f1 : 0.93652\n",
      "epoch : 24/100    time : 8s/623s\n",
      "TRAIN    loss : 0.16592    f1 : 0.94943\n",
      "Val    loss : 0.33674    f1 : 0.89354\n",
      "epoch : 25/100    time : 8s/615s\n",
      "TRAIN    loss : 0.18098    f1 : 0.95501\n",
      "Val    loss : 0.31225    f1 : 0.89929\n",
      "epoch : 26/100    time : 8s/617s\n",
      "TRAIN    loss : 0.29595    f1 : 0.91903\n",
      "Val    loss : 0.22149    f1 : 0.93081\n",
      "epoch : 27/100    time : 8s/599s\n",
      "TRAIN    loss : 0.15260    f1 : 0.95791\n",
      "Val    loss : 0.15430    f1 : 0.92901\n",
      "epoch : 28/100    time : 8s/593s\n",
      "TRAIN    loss : 0.15028    f1 : 0.96467\n",
      "Val    loss : 0.37661    f1 : 0.90002\n",
      "epoch : 29/100    time : 8s/584s\n",
      "TRAIN    loss : 0.07827    f1 : 0.97752\n",
      "Val    loss : 0.26090    f1 : 0.92664\n",
      "epoch : 30/100    time : 8s/575s\n",
      "TRAIN    loss : 0.08058    f1 : 0.97815\n",
      "Val    loss : 0.22325    f1 : 0.94298\n",
      "epoch : 31/100    time : 8s/575s\n",
      "TRAIN    loss : 0.05336    f1 : 0.98707\n",
      "Val    loss : 0.33945    f1 : 0.92760\n",
      "epoch : 32/100    time : 8s/556s\n",
      "TRAIN    loss : 0.07418    f1 : 0.98140\n",
      "Val    loss : 0.39396    f1 : 0.90067\n",
      "epoch : 33/100    time : 8s/548s\n",
      "TRAIN    loss : 0.26803    f1 : 0.94475\n",
      "Val    loss : 0.25596    f1 : 0.93717\n",
      "epoch : 34/100    time : 8s/540s\n",
      "TRAIN    loss : 0.11003    f1 : 0.97087\n",
      "Val    loss : 0.23127    f1 : 0.94417\n",
      "epoch : 35/100    time : 8s/530s\n",
      "TRAIN    loss : 0.03671    f1 : 0.98972\n",
      "Val    loss : 0.16437    f1 : 0.93261\n",
      "epoch : 36/100    time : 8s/520s\n",
      "TRAIN    loss : 0.00725    f1 : 0.99717\n",
      "Val    loss : 0.18434    f1 : 0.94395\n",
      "epoch : 37/100    time : 8s/518s\n",
      "TRAIN    loss : 0.08293    f1 : 0.97369\n",
      "Val    loss : 0.22491    f1 : 0.93081\n",
      "epoch : 38/100    time : 8s/504s\n",
      "TRAIN    loss : 0.03349    f1 : 0.98867\n",
      "Val    loss : 0.31144    f1 : 0.91497\n",
      "-----------------SAVE:39 epoch----------------\n",
      "epoch : 39/100    time : 10s/638s\n",
      "TRAIN    loss : 0.04865    f1 : 0.99290\n",
      "Val    loss : 0.10756    f1 : 0.96667\n",
      "epoch : 40/100    time : 8s/504s\n",
      "TRAIN    loss : 0.03626    f1 : 0.98759\n",
      "Val    loss : 0.29577    f1 : 0.93375\n",
      "epoch : 41/100    time : 8s/486s\n",
      "TRAIN    loss : 0.04637    f1 : 0.98030\n",
      "Val    loss : 0.32545    f1 : 0.93225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 42/100    time : 8s/474s\n",
      "TRAIN    loss : 0.03756    f1 : 0.98696\n",
      "Val    loss : 0.27643    f1 : 0.93826\n",
      "epoch : 43/100    time : 8s/469s\n",
      "TRAIN    loss : 0.19522    f1 : 0.94858\n",
      "Val    loss : 0.45633    f1 : 0.87325\n",
      "epoch : 44/100    time : 8s/462s\n",
      "TRAIN    loss : 0.07601    f1 : 0.97697\n",
      "Val    loss : 0.16969    f1 : 0.94405\n",
      "epoch : 45/100    time : 8s/449s\n",
      "TRAIN    loss : 0.01474    f1 : 0.99427\n",
      "Val    loss : 0.21240    f1 : 0.93751\n",
      "epoch : 46/100    time : 8s/439s\n",
      "TRAIN    loss : 0.09398    f1 : 0.97286\n",
      "Val    loss : 0.35428    f1 : 0.90441\n",
      "epoch : 47/100    time : 8s/433s\n",
      "TRAIN    loss : 0.09185    f1 : 0.96415\n",
      "Val    loss : 0.15786    f1 : 0.95483\n",
      "epoch : 48/100    time : 8s/437s\n",
      "TRAIN    loss : 0.01953    f1 : 0.99405\n",
      "Val    loss : 0.35812    f1 : 0.88715\n",
      "epoch : 49/100    time : 8s/414s\n",
      "TRAIN    loss : 0.14504    f1 : 0.96285\n",
      "Val    loss : 0.33582    f1 : 0.93822\n",
      "epoch : 50/100    time : 8s/408s\n",
      "TRAIN    loss : 0.10979    f1 : 0.97069\n",
      "Val    loss : 0.53558    f1 : 0.83693\n",
      "epoch : 51/100    time : 8s/399s\n",
      "TRAIN    loss : 0.15306    f1 : 0.96718\n",
      "Val    loss : 0.51045    f1 : 0.86941\n",
      "epoch : 52/100    time : 8s/393s\n",
      "TRAIN    loss : 0.07254    f1 : 0.98370\n",
      "Val    loss : 0.64139    f1 : 0.90976\n",
      "epoch : 53/100    time : 8s/384s\n",
      "TRAIN    loss : 0.14234    f1 : 0.97560\n",
      "Val    loss : 0.35265    f1 : 0.93234\n",
      "epoch : 54/100    time : 8s/376s\n",
      "TRAIN    loss : 0.06741    f1 : 0.97826\n",
      "Val    loss : 0.29097    f1 : 0.90978\n",
      "epoch : 55/100    time : 8s/367s\n",
      "TRAIN    loss : 0.02615    f1 : 0.99258\n",
      "Val    loss : 0.42268    f1 : 0.91494\n",
      "epoch : 56/100    time : 8s/359s\n",
      "TRAIN    loss : 0.10337    f1 : 0.97004\n",
      "Val    loss : 0.40294    f1 : 0.89322\n",
      "epoch : 57/100    time : 8s/350s\n",
      "TRAIN    loss : 0.07423    f1 : 0.98437\n",
      "Val    loss : 0.88565    f1 : 0.87133\n",
      "epoch : 58/100    time : 8s/343s\n",
      "TRAIN    loss : 0.06469    f1 : 0.97558\n",
      "Val    loss : 0.41375    f1 : 0.91603\n",
      "epoch : 59/100    time : 8s/334s\n",
      "TRAIN    loss : 0.02442    f1 : 0.99293\n",
      "Val    loss : 0.31316    f1 : 0.94349\n",
      "----------fold_3 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 10s/1017s\n",
      "TRAIN    loss : 2.11433    f1 : 0.26618\n",
      "Val    loss : 1.57753    f1 : 0.31444\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 10s/1020s\n",
      "TRAIN    loss : 1.17111    f1 : 0.54722\n",
      "Val    loss : 1.15379    f1 : 0.60270\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 10s/1003s\n",
      "TRAIN    loss : 0.75006    f1 : 0.72324\n",
      "Val    loss : 1.30245    f1 : 0.64879\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 10s/992s\n",
      "TRAIN    loss : 0.73663    f1 : 0.75644\n",
      "Val    loss : 1.03633    f1 : 0.68898\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 11s/999s\n",
      "TRAIN    loss : 0.47329    f1 : 0.83076\n",
      "Val    loss : 0.33721    f1 : 0.85909\n",
      "epoch : 6/100    time : 8s/782s\n",
      "TRAIN    loss : 0.39210    f1 : 0.87438\n",
      "Val    loss : 0.43493    f1 : 0.79782\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 10s/948s\n",
      "TRAIN    loss : 0.22836    f1 : 0.92034\n",
      "Val    loss : 0.36061    f1 : 0.88119\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 10s/960s\n",
      "TRAIN    loss : 0.46943    f1 : 0.85124\n",
      "Val    loss : 0.21065    f1 : 0.94977\n",
      "epoch : 9/100    time : 8s/769s\n",
      "TRAIN    loss : 0.31306    f1 : 0.89666\n",
      "Val    loss : 0.30863    f1 : 0.90520\n",
      "epoch : 10/100    time : 8s/735s\n",
      "TRAIN    loss : 0.27959    f1 : 0.92364\n",
      "Val    loss : 0.20015    f1 : 0.93837\n",
      "epoch : 11/100    time : 8s/725s\n",
      "TRAIN    loss : 0.22289    f1 : 0.91920\n",
      "Val    loss : 0.24809    f1 : 0.93282\n",
      "epoch : 12/100    time : 8s/719s\n",
      "TRAIN    loss : 0.24244    f1 : 0.93559\n",
      "Val    loss : 0.27655    f1 : 0.91907\n",
      "epoch : 13/100    time : 8s/710s\n",
      "TRAIN    loss : 0.12468    f1 : 0.95096\n",
      "Val    loss : 0.64480    f1 : 0.84960\n",
      "epoch : 14/100    time : 8s/706s\n",
      "TRAIN    loss : 0.23425    f1 : 0.91739\n",
      "Val    loss : 0.22185    f1 : 0.94325\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/100    time : 10s/867s\n",
      "TRAIN    loss : 0.11980    f1 : 0.96961\n",
      "Val    loss : 0.14768    f1 : 0.95452\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/100    time : 10s/878s\n",
      "TRAIN    loss : 0.16248    f1 : 0.94099\n",
      "Val    loss : 0.19847    f1 : 0.95992\n",
      "epoch : 17/100    time : 8s/697s\n",
      "TRAIN    loss : 0.08085    f1 : 0.96852\n",
      "Val    loss : 0.30324    f1 : 0.92666\n",
      "epoch : 18/100    time : 8s/670s\n",
      "TRAIN    loss : 0.19564    f1 : 0.94705\n",
      "Val    loss : 0.54799    f1 : 0.76954\n",
      "epoch : 19/100    time : 8s/662s\n",
      "TRAIN    loss : 0.19536    f1 : 0.92748\n",
      "Val    loss : 0.17921    f1 : 0.94241\n",
      "epoch : 20/100    time : 8s/652s\n",
      "TRAIN    loss : 0.16041    f1 : 0.95015\n",
      "Val    loss : 0.55088    f1 : 0.81160\n",
      "epoch : 21/100    time : 8s/648s\n",
      "TRAIN    loss : 0.16600    f1 : 0.94572\n",
      "Val    loss : 0.44380    f1 : 0.87122\n",
      "epoch : 22/100    time : 8s/637s\n",
      "TRAIN    loss : 0.09173    f1 : 0.96695\n",
      "Val    loss : 0.29010    f1 : 0.93260\n",
      "epoch : 23/100    time : 8s/629s\n",
      "TRAIN    loss : 0.09598    f1 : 0.96439\n",
      "Val    loss : 0.20876    f1 : 0.95304\n",
      "-----------------SAVE:24 epoch----------------\n",
      "epoch : 24/100    time : 10s/782s\n",
      "TRAIN    loss : 0.04140    f1 : 0.98292\n",
      "Val    loss : 0.13649    f1 : 0.96602\n",
      "-----------------SAVE:25 epoch----------------\n",
      "epoch : 25/100    time : 10s/784s\n",
      "TRAIN    loss : 0.03577    f1 : 0.99145\n",
      "Val    loss : 0.16708    f1 : 0.96635\n",
      "epoch : 26/100    time : 8s/621s\n",
      "TRAIN    loss : 0.17132    f1 : 0.94882\n",
      "Val    loss : 0.28009    f1 : 0.91992\n",
      "epoch : 27/100    time : 8s/597s\n",
      "TRAIN    loss : 0.08032    f1 : 0.98952\n",
      "Val    loss : 0.21120    f1 : 0.92735\n",
      "epoch : 28/100    time : 8s/592s\n",
      "TRAIN    loss : 0.14221    f1 : 0.96101\n",
      "Val    loss : 0.12680    f1 : 0.95623\n",
      "epoch : 29/100    time : 8s/582s\n",
      "TRAIN    loss : 0.08159    f1 : 0.97397\n",
      "Val    loss : 0.16933    f1 : 0.94973\n",
      "-----------------SAVE:30 epoch----------------\n",
      "epoch : 30/100    time : 10s/714s\n",
      "TRAIN    loss : 0.14654    f1 : 0.95728\n",
      "Val    loss : 0.12737    f1 : 0.97218\n",
      "epoch : 31/100    time : 8s/583s\n",
      "TRAIN    loss : 0.02453    f1 : 0.99432\n",
      "Val    loss : 0.10242    f1 : 0.96590\n",
      "epoch : 32/100    time : 8s/554s\n",
      "TRAIN    loss : 0.05620    f1 : 0.98860\n",
      "Val    loss : 0.12580    f1 : 0.95500\n",
      "epoch : 33/100    time : 8s/550s\n",
      "TRAIN    loss : 0.05976    f1 : 0.98003\n",
      "Val    loss : 0.24567    f1 : 0.93693\n",
      "epoch : 34/100    time : 8s/541s\n",
      "TRAIN    loss : 0.13169    f1 : 0.96357\n",
      "Val    loss : 0.16538    f1 : 0.94118\n",
      "epoch : 35/100    time : 8s/536s\n",
      "TRAIN    loss : 0.05594    f1 : 0.98253\n",
      "Val    loss : 0.13862    f1 : 0.94910\n",
      "epoch : 36/100    time : 8s/535s\n",
      "TRAIN    loss : 0.06403    f1 : 0.97681\n",
      "Val    loss : 0.13982    f1 : 0.95416\n",
      "epoch : 37/100    time : 8s/524s\n",
      "TRAIN    loss : 0.13353    f1 : 0.96974\n",
      "Val    loss : 0.31416    f1 : 0.88988\n",
      "epoch : 38/100    time : 8s/523s\n",
      "TRAIN    loss : 0.18167    f1 : 0.94075\n",
      "Val    loss : 0.33949    f1 : 0.90966\n",
      "epoch : 39/100    time : 8s/505s\n",
      "TRAIN    loss : 0.04502    f1 : 0.98548\n",
      "Val    loss : 0.27069    f1 : 0.94173\n",
      "epoch : 40/100    time : 8s/502s\n",
      "TRAIN    loss : 0.15084    f1 : 0.96819\n",
      "Val    loss : 0.28229    f1 : 0.90472\n",
      "epoch : 41/100    time : 8s/492s\n",
      "TRAIN    loss : 0.12808    f1 : 0.97405\n",
      "Val    loss : 0.21720    f1 : 0.94778\n",
      "epoch : 42/100    time : 8s/489s\n",
      "TRAIN    loss : 0.03958    f1 : 0.98857\n",
      "Val    loss : 0.21624    f1 : 0.95467\n",
      "epoch : 43/100    time : 8s/474s\n",
      "TRAIN    loss : 0.09418    f1 : 0.97787\n",
      "Val    loss : 0.51155    f1 : 0.86220\n",
      "epoch : 44/100    time : 8s/464s\n",
      "TRAIN    loss : 0.10502    f1 : 0.96463\n",
      "Val    loss : 0.23014    f1 : 0.96008\n",
      "epoch : 45/100    time : 8s/450s\n",
      "TRAIN    loss : 0.11170    f1 : 0.97276\n",
      "Val    loss : 0.11847    f1 : 0.94898\n",
      "epoch : 46/100    time : 8s/443s\n",
      "TRAIN    loss : 0.03007    f1 : 0.99286\n",
      "Val    loss : 0.12832    f1 : 0.96125\n",
      "-----------------SAVE:47 epoch----------------\n",
      "epoch : 47/100    time : 10s/544s\n",
      "TRAIN    loss : 0.01706    f1 : 0.99145\n",
      "Val    loss : 0.11367    f1 : 0.97793\n",
      "epoch : 48/100    time : 8s/435s\n",
      "TRAIN    loss : 0.03174    f1 : 0.99285\n",
      "Val    loss : 0.09101    f1 : 0.96697\n",
      "epoch : 49/100    time : 8s/419s\n",
      "TRAIN    loss : 0.14559    f1 : 0.96561\n",
      "Val    loss : 0.31082    f1 : 0.91067\n",
      "epoch : 50/100    time : 8s/411s\n",
      "TRAIN    loss : 0.07005    f1 : 0.98410\n",
      "Val    loss : 0.16398    f1 : 0.95435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 51/100    time : 8s/407s\n",
      "TRAIN    loss : 0.06984    f1 : 0.98037\n",
      "Val    loss : 0.25781    f1 : 0.90595\n",
      "epoch : 52/100    time : 8s/404s\n",
      "TRAIN    loss : 0.18126    f1 : 0.95353\n",
      "Val    loss : 0.25848    f1 : 0.92656\n",
      "epoch : 53/100    time : 8s/393s\n",
      "TRAIN    loss : 0.13580    f1 : 0.96353\n",
      "Val    loss : 0.45107    f1 : 0.88288\n",
      "epoch : 54/100    time : 8s/383s\n",
      "TRAIN    loss : 0.16002    f1 : 0.95037\n",
      "Val    loss : 0.24680    f1 : 0.93216\n",
      "epoch : 55/100    time : 8s/376s\n",
      "TRAIN    loss : 0.07505    f1 : 0.97851\n",
      "Val    loss : 0.31500    f1 : 0.89549\n",
      "epoch : 56/100    time : 8s/368s\n",
      "TRAIN    loss : 0.06366    f1 : 0.98344\n",
      "Val    loss : 0.13390    f1 : 0.96668\n",
      "epoch : 57/100    time : 8s/361s\n",
      "TRAIN    loss : 0.06098    f1 : 0.98512\n",
      "Val    loss : 0.19789    f1 : 0.96605\n",
      "epoch : 58/100    time : 8s/351s\n",
      "TRAIN    loss : 0.04932    f1 : 0.98399\n",
      "Val    loss : 0.30245    f1 : 0.91755\n",
      "epoch : 59/100    time : 8s/342s\n",
      "TRAIN    loss : 0.12816    f1 : 0.96870\n",
      "Val    loss : 0.38878    f1 : 0.91057\n",
      "epoch : 60/100    time : 8s/334s\n",
      "TRAIN    loss : 0.04862    f1 : 0.99149\n",
      "Val    loss : 0.09631    f1 : 0.97191\n",
      "epoch : 61/100    time : 8s/326s\n",
      "TRAIN    loss : 0.01129    f1 : 0.99571\n",
      "Val    loss : 0.09341    f1 : 0.97077\n",
      "epoch : 62/100    time : 8s/318s\n",
      "TRAIN    loss : 0.01481    f1 : 0.99428\n",
      "Val    loss : 0.13013    f1 : 0.95040\n",
      "epoch : 63/100    time : 8s/310s\n",
      "TRAIN    loss : 0.02481    f1 : 0.99429\n",
      "Val    loss : 0.11894    f1 : 0.95913\n",
      "epoch : 64/100    time : 8s/302s\n",
      "TRAIN    loss : 0.02842    f1 : 0.99397\n",
      "Val    loss : 0.40263    f1 : 0.91163\n",
      "epoch : 65/100    time : 8s/292s\n",
      "TRAIN    loss : 0.06349    f1 : 0.97880\n",
      "Val    loss : 0.21096    f1 : 0.96086\n",
      "epoch : 66/100    time : 8s/278s\n",
      "TRAIN    loss : 0.07816    f1 : 0.98226\n",
      "Val    loss : 0.18633    f1 : 0.95014\n",
      "epoch : 67/100    time : 8s/275s\n",
      "TRAIN    loss : 0.20732    f1 : 0.94794\n",
      "Val    loss : 0.23060    f1 : 0.92591\n",
      "----------fold_4 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 10s/1008s\n",
      "TRAIN    loss : 2.07437    f1 : 0.26894\n",
      "Val    loss : 1.52399    f1 : 0.32921\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 10s/1025s\n",
      "TRAIN    loss : 1.05383    f1 : 0.59929\n",
      "Val    loss : 0.88743    f1 : 0.68306\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 10s/1016s\n",
      "TRAIN    loss : 0.62648    f1 : 0.74781\n",
      "Val    loss : 0.58315    f1 : 0.84064\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 11s/1010s\n",
      "TRAIN    loss : 0.47310    f1 : 0.83189\n",
      "Val    loss : 0.36836    f1 : 0.85896\n",
      "epoch : 5/100    time : 9s/820s\n",
      "TRAIN    loss : 0.41464    f1 : 0.83712\n",
      "Val    loss : 0.42205    f1 : 0.85711\n",
      "epoch : 6/100    time : 8s/778s\n",
      "TRAIN    loss : 0.39617    f1 : 0.87553\n",
      "Val    loss : 0.56114    f1 : 0.84567\n",
      "epoch : 7/100    time : 8s/773s\n",
      "TRAIN    loss : 0.33905    f1 : 0.88231\n",
      "Val    loss : 0.43129    f1 : 0.81768\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 11s/974s\n",
      "TRAIN    loss : 0.28725    f1 : 0.91091\n",
      "Val    loss : 0.31335    f1 : 0.90533\n",
      "epoch : 9/100    time : 9s/787s\n",
      "TRAIN    loss : 0.17316    f1 : 0.94206\n",
      "Val    loss : 0.31544    f1 : 0.88433\n",
      "epoch : 10/100    time : 8s/743s\n",
      "TRAIN    loss : 0.21670    f1 : 0.93173\n",
      "Val    loss : 0.35350    f1 : 0.88270\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 10s/927s\n",
      "TRAIN    loss : 0.14030    f1 : 0.95280\n",
      "Val    loss : 0.20442    f1 : 0.92810\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 10s/923s\n",
      "TRAIN    loss : 0.09443    f1 : 0.97593\n",
      "Val    loss : 0.28964    f1 : 0.94092\n",
      "epoch : 13/100    time : 8s/738s\n",
      "TRAIN    loss : 0.11525    f1 : 0.96099\n",
      "Val    loss : 0.43357    f1 : 0.91556\n",
      "epoch : 14/100    time : 8s/713s\n",
      "TRAIN    loss : 0.12464    f1 : 0.96732\n",
      "Val    loss : 0.25556    f1 : 0.92645\n",
      "epoch : 15/100    time : 8s/709s\n",
      "TRAIN    loss : 0.17854    f1 : 0.94554\n",
      "Val    loss : 0.24309    f1 : 0.91528\n",
      "epoch : 16/100    time : 8s/693s\n",
      "TRAIN    loss : 0.21276    f1 : 0.94257\n",
      "Val    loss : 0.51148    f1 : 0.88151\n",
      "epoch : 17/100    time : 8s/680s\n",
      "TRAIN    loss : 0.48231    f1 : 0.85326\n",
      "Val    loss : 0.32938    f1 : 0.89687\n",
      "epoch : 18/100    time : 8s/674s\n",
      "TRAIN    loss : 0.24136    f1 : 0.91756\n",
      "Val    loss : 0.95110    f1 : 0.81181\n",
      "epoch : 19/100    time : 8s/672s\n",
      "TRAIN    loss : 0.26708    f1 : 0.91899\n",
      "Val    loss : 0.27213    f1 : 0.89734\n",
      "epoch : 20/100    time : 8s/656s\n",
      "TRAIN    loss : 0.11923    f1 : 0.95408\n",
      "Val    loss : 0.23838    f1 : 0.92780\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/100    time : 10s/811s\n",
      "TRAIN    loss : 0.05500    f1 : 0.97955\n",
      "Val    loss : 0.26618    f1 : 0.95775\n",
      "epoch : 22/100    time : 8s/656s\n",
      "TRAIN    loss : 0.09247    f1 : 0.97067\n",
      "Val    loss : 0.40881    f1 : 0.91397\n",
      "epoch : 23/100    time : 8s/632s\n",
      "TRAIN    loss : 0.04035    f1 : 0.99219\n",
      "Val    loss : 0.23085    f1 : 0.94211\n",
      "epoch : 24/100    time : 8s/622s\n",
      "TRAIN    loss : 0.13865    f1 : 0.96706\n",
      "Val    loss : 0.38202    f1 : 0.89942\n",
      "-----------------SAVE:25 epoch----------------\n",
      "epoch : 25/100    time : 10s/770s\n",
      "TRAIN    loss : 0.06419    f1 : 0.98378\n",
      "Val    loss : 0.19054    f1 : 0.95901\n",
      "epoch : 26/100    time : 9s/630s\n",
      "TRAIN    loss : 0.06595    f1 : 0.98019\n",
      "Val    loss : 0.40519    f1 : 0.90095\n",
      "epoch : 27/100    time : 8s/605s\n",
      "TRAIN    loss : 0.11760    f1 : 0.96315\n",
      "Val    loss : 0.24044    f1 : 0.91790\n",
      "epoch : 28/100    time : 8s/607s\n",
      "TRAIN    loss : 0.19361    f1 : 0.95154\n",
      "Val    loss : 0.36158    f1 : 0.89988\n",
      "epoch : 29/100    time : 8s/602s\n",
      "TRAIN    loss : 0.18471    f1 : 0.95356\n",
      "Val    loss : 0.26694    f1 : 0.94096\n",
      "epoch : 30/100    time : 9s/596s\n",
      "TRAIN    loss : 0.04148    f1 : 0.98840\n",
      "Val    loss : 0.26711    f1 : 0.95260\n",
      "epoch : 31/100    time : 8s/579s\n",
      "TRAIN    loss : 0.14561    f1 : 0.95385\n",
      "Val    loss : 0.45149    f1 : 0.88653\n",
      "-----------------SAVE:32 epoch----------------\n",
      "epoch : 32/100    time : 10s/702s\n",
      "TRAIN    loss : 0.06015    f1 : 0.97592\n",
      "Val    loss : 0.23174    f1 : 0.95964\n",
      "epoch : 33/100    time : 9s/571s\n",
      "TRAIN    loss : 0.03064    f1 : 0.99117\n",
      "Val    loss : 0.35278    f1 : 0.93446\n",
      "-----------------SAVE:34 epoch----------------\n",
      "epoch : 34/100    time : 10s/686s\n",
      "TRAIN    loss : 0.05006    f1 : 0.98860\n",
      "Val    loss : 0.18161    f1 : 0.96444\n",
      "epoch : 35/100    time : 9s/558s\n",
      "TRAIN    loss : 0.07017    f1 : 0.97367\n",
      "Val    loss : 0.37306    f1 : 0.91719\n",
      "epoch : 36/100    time : 8s/528s\n",
      "TRAIN    loss : 0.03939    f1 : 0.98834\n",
      "Val    loss : 0.27253    f1 : 0.94726\n",
      "epoch : 37/100    time : 8s/529s\n",
      "TRAIN    loss : 0.19081    f1 : 0.95671\n",
      "Val    loss : 0.27562    f1 : 0.92882\n",
      "epoch : 38/100    time : 8s/520s\n",
      "TRAIN    loss : 0.16740    f1 : 0.95530\n",
      "Val    loss : 0.62953    f1 : 0.86982\n",
      "epoch : 39/100    time : 8s/512s\n",
      "TRAIN    loss : 0.15212    f1 : 0.95469\n",
      "Val    loss : 0.41854    f1 : 0.91672\n",
      "epoch : 40/100    time : 8s/493s\n",
      "TRAIN    loss : 0.04917    f1 : 0.98551\n",
      "Val    loss : 0.27986    f1 : 0.94498\n",
      "epoch : 41/100    time : 8s/485s\n",
      "TRAIN    loss : 0.12480    f1 : 0.96506\n",
      "Val    loss : 0.37309    f1 : 0.92191\n",
      "epoch : 42/100    time : 8s/480s\n",
      "TRAIN    loss : 0.07596    f1 : 0.98107\n",
      "Val    loss : 0.41957    f1 : 0.87926\n",
      "epoch : 43/100    time : 8s/468s\n",
      "TRAIN    loss : 0.04871    f1 : 0.98414\n",
      "Val    loss : 0.29783    f1 : 0.92448\n",
      "epoch : 44/100    time : 8s/465s\n",
      "TRAIN    loss : 0.02852    f1 : 0.99153\n",
      "Val    loss : 0.23351    f1 : 0.92852\n",
      "epoch : 45/100    time : 8s/457s\n",
      "TRAIN    loss : 0.00248    f1 : 1.00000\n",
      "Val    loss : 0.20714    f1 : 0.96301\n",
      "epoch : 46/100    time : 8s/449s\n",
      "TRAIN    loss : 0.08008    f1 : 0.97835\n",
      "Val    loss : 0.19786    f1 : 0.95251\n",
      "epoch : 47/100    time : 8s/437s\n",
      "TRAIN    loss : 0.13112    f1 : 0.97000\n",
      "Val    loss : 0.28291    f1 : 0.92961\n",
      "epoch : 48/100    time : 8s/434s\n",
      "TRAIN    loss : 0.17124    f1 : 0.94869\n",
      "Val    loss : 0.21562    f1 : 0.94471\n",
      "epoch : 49/100    time : 8s/420s\n",
      "TRAIN    loss : 0.03828    f1 : 0.99007\n",
      "Val    loss : 0.29442    f1 : 0.91823\n",
      "epoch : 50/100    time : 8s/420s\n",
      "TRAIN    loss : 0.05193    f1 : 0.98967\n",
      "Val    loss : 0.29600    f1 : 0.91409\n",
      "epoch : 51/100    time : 8s/404s\n",
      "TRAIN    loss : 0.15192    f1 : 0.96090\n",
      "Val    loss : 0.13133    f1 : 0.95754\n",
      "epoch : 52/100    time : 8s/394s\n",
      "TRAIN    loss : 0.06578    f1 : 0.97837\n",
      "Val    loss : 0.16041    f1 : 0.92691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 53/100    time : 8s/386s\n",
      "TRAIN    loss : 0.06530    f1 : 0.98506\n",
      "Val    loss : 0.23610    f1 : 0.93373\n",
      "epoch : 54/100    time : 8s/380s\n",
      "TRAIN    loss : 0.04271    f1 : 0.98285\n",
      "Val    loss : 0.53503    f1 : 0.89276\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022, shuffle = True)\n",
    "batch_size = 8\n",
    "epochs = 100\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "  print(\"----------fold_{} start!----------\".format(idx))\n",
    "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "  # Train\n",
    "  train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Val\n",
    "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  best=0\n",
    "\n",
    "  model = Network().to(device)\n",
    "\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay = 1e-3)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "  best_f1 = 0\n",
    "  early_stopping = 0\n",
    "  for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss = 0 \n",
    "      val_pred = []\n",
    "      val_y = []\n",
    "      \n",
    "\n",
    "      for batch in (val_loader):\n",
    "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_val = model(x_val)\n",
    "        loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "        val_loss += loss_val.item()/len(val_loader)\n",
    "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "        val_y += y_val.detach().cpu().numpy().tolist()\n",
    "      val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "      if val_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_loss = val_loss\n",
    "        best_f1 = val_f1\n",
    "        early_stopping = 0\n",
    "\n",
    "        torch.save({'epoch':epoch,\n",
    "                    'state_dict':state_dict,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "             }, path +'best_model_{}.pth'.format(idx))\n",
    "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "      else:\n",
    "          early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "      if early_stopping == 20:\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "Jl2OKpQiO5S1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl2OKpQiO5S1",
    "outputId": "e48def07-ef6d-4325-f297-c705088b3eb8"
   },
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 8\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load((path+'best_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "GjsHs-T3SPJq",
   "metadata": {
    "id": "GjsHs-T3SPJq"
   },
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1])+ np.array(pred_ensemble[3]) + np.array(pred_ensemble[4]) )/4\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "UIglTwAV7L54",
   "metadata": {
    "id": "UIglTwAV7L54"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "292QDIS5DOKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "292QDIS5DOKf",
    "outputId": "0e47d38f-d36a-40cd-a925-90e6bce52652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name label\n",
       "0     001.png     1\n",
       "1     002.png     2\n",
       "2     003.png     1\n",
       "3     004.png     6\n",
       "4     005.png     8\n",
       "..        ...   ...\n",
       "210   211.png     5\n",
       "211   212.png     8\n",
       "212   213.png     3\n",
       "213   214.png     6\n",
       "214   215.png     1\n",
       "\n",
       "[215 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"sample_submission.csv\")\n",
    "submission[\"label\"] = f_result\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1naZSLGZ7L55",
   "metadata": {
    "id": "1naZSLGZ7L55"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"submit.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fitted-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"
     ]
    }
   ],
   "source": [
    "# d9249@kyonggi.ac.kr\n",
    "\n",
    "from dacon_submit_api import dacon_submit_api \n",
    "\n",
    "result = dacon_submit_api.post_submission_file(\n",
    "'C:/Users/ideal/Downloads/jupyter/user_data/submit.csv', \n",
    "'02438df9bd0f6300dae6ddea845e7e01d2cb1881849c166bfce504164e1507d5', \n",
    "'235896', \n",
    "'iDeal', \n",
    "'test' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca15b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fedc192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[BASELINE]_EfficientNet_b3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
