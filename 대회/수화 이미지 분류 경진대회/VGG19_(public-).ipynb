{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LlcNsGEk7L5r",
   "metadata": {
    "id": "LlcNsGEk7L5r"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81532144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3',\n",
      " 'bat_resnext26ts',\n",
      " 'beit_base_patch16_224',\n",
      " 'beit_base_patch16_224_in22k',\n",
      " 'beit_base_patch16_384',\n",
      " 'beit_large_patch16_224',\n",
      " 'beit_large_patch16_224_in22k',\n",
      " 'beit_large_patch16_384',\n",
      " 'beit_large_patch16_512',\n",
      " 'botnet26t_256',\n",
      " 'cait_m36_384',\n",
      " 'cait_m48_448',\n",
      " 'cait_s24_224',\n",
      " 'cait_s24_384',\n",
      " 'cait_s36_384',\n",
      " 'cait_xs24_384',\n",
      " 'cait_xxs24_224',\n",
      " 'cait_xxs24_384',\n",
      " 'cait_xxs36_224',\n",
      " 'cait_xxs36_384',\n",
      " 'coat_lite_mini',\n",
      " 'coat_lite_small',\n",
      " 'coat_lite_tiny',\n",
      " 'coat_mini',\n",
      " 'coat_tiny',\n",
      " 'convit_base',\n",
      " 'convit_small',\n",
      " 'convit_tiny',\n",
      " 'convmixer_768_32',\n",
      " 'convmixer_1024_20_ks9_p14',\n",
      " 'convmixer_1536_20',\n",
      " 'convnext_base',\n",
      " 'convnext_base_384_in22ft1k',\n",
      " 'convnext_base_in22ft1k',\n",
      " 'convnext_base_in22k',\n",
      " 'convnext_large',\n",
      " 'convnext_large_384_in22ft1k',\n",
      " 'convnext_large_in22ft1k',\n",
      " 'convnext_large_in22k',\n",
      " 'convnext_small',\n",
      " 'convnext_tiny',\n",
      " 'convnext_xlarge_384_in22ft1k',\n",
      " 'convnext_xlarge_in22ft1k',\n",
      " 'convnext_xlarge_in22k',\n",
      " 'crossvit_9_240',\n",
      " 'crossvit_9_dagger_240',\n",
      " 'crossvit_15_240',\n",
      " 'crossvit_15_dagger_240',\n",
      " 'crossvit_15_dagger_408',\n",
      " 'crossvit_18_240',\n",
      " 'crossvit_18_dagger_240',\n",
      " 'crossvit_18_dagger_408',\n",
      " 'crossvit_base_240',\n",
      " 'crossvit_small_240',\n",
      " 'crossvit_tiny_240',\n",
      " 'cspdarknet53',\n",
      " 'cspresnet50',\n",
      " 'cspresnext50',\n",
      " 'deit_base_distilled_patch16_224',\n",
      " 'deit_base_distilled_patch16_384',\n",
      " 'deit_base_patch16_224',\n",
      " 'deit_base_patch16_384',\n",
      " 'deit_small_distilled_patch16_224',\n",
      " 'deit_small_patch16_224',\n",
      " 'deit_tiny_distilled_patch16_224',\n",
      " 'deit_tiny_patch16_224',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dm_nfnet_f0',\n",
      " 'dm_nfnet_f1',\n",
      " 'dm_nfnet_f2',\n",
      " 'dm_nfnet_f3',\n",
      " 'dm_nfnet_f4',\n",
      " 'dm_nfnet_f5',\n",
      " 'dm_nfnet_f6',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'eca_botnext26ts_256',\n",
      " 'eca_halonext26ts',\n",
      " 'eca_nfnet_l0',\n",
      " 'eca_nfnet_l1',\n",
      " 'eca_nfnet_l2',\n",
      " 'eca_resnet33ts',\n",
      " 'eca_resnext26ts',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b4',\n",
      " 'efficientnet_el',\n",
      " 'efficientnet_el_pruned',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_es_pruned',\n",
      " 'efficientnet_lite0',\n",
      " 'efficientnetv2_rw_m',\n",
      " 'efficientnetv2_rw_s',\n",
      " 'efficientnetv2_rw_t',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'fbnetc_100',\n",
      " 'fbnetv3_b',\n",
      " 'fbnetv3_d',\n",
      " 'fbnetv3_g',\n",
      " 'gc_efficientnetv2_rw_t',\n",
      " 'gcresnet33ts',\n",
      " 'gcresnet50t',\n",
      " 'gcresnext26ts',\n",
      " 'gcresnext50ts',\n",
      " 'gernet_l',\n",
      " 'gernet_m',\n",
      " 'gernet_s',\n",
      " 'ghostnet_100',\n",
      " 'gluon_inception_v3',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_senet154',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'gluon_xception65',\n",
      " 'gmixer_24_224',\n",
      " 'gmlp_s16_224',\n",
      " 'halo2botnet50ts_256',\n",
      " 'halonet26t',\n",
      " 'halonet50ts',\n",
      " 'haloregnetz_b',\n",
      " 'hardcorenas_a',\n",
      " 'hardcorenas_b',\n",
      " 'hardcorenas_c',\n",
      " 'hardcorenas_d',\n",
      " 'hardcorenas_e',\n",
      " 'hardcorenas_f',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w64',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'jx_nest_base',\n",
      " 'jx_nest_small',\n",
      " 'jx_nest_tiny',\n",
      " 'lambda_resnet26rpt_256',\n",
      " 'lambda_resnet26t',\n",
      " 'lambda_resnet50ts',\n",
      " 'lamhalobotnet50ts_256',\n",
      " 'lcnet_050',\n",
      " 'lcnet_075',\n",
      " 'lcnet_100',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'levit_128',\n",
      " 'levit_128s',\n",
      " 'levit_192',\n",
      " 'levit_256',\n",
      " 'levit_384',\n",
      " 'mixer_b16_224',\n",
      " 'mixer_b16_224_in21k',\n",
      " 'mixer_b16_224_miil',\n",
      " 'mixer_b16_224_miil_in21k',\n",
      " 'mixer_l16_224',\n",
      " 'mixer_l16_224_in21k',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mnasnet_100',\n",
      " 'mnasnet_small',\n",
      " 'mobilenetv2_050',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_large_100_miil',\n",
      " 'mobilenetv3_large_100_miil_in21k',\n",
      " 'mobilenetv3_rw',\n",
      " 'nasnetalarge',\n",
      " 'nf_regnet_b1',\n",
      " 'nf_resnet50',\n",
      " 'nfnet_l0',\n",
      " 'pit_b_224',\n",
      " 'pit_b_distilled_224',\n",
      " 'pit_s_224',\n",
      " 'pit_s_distilled_224',\n",
      " 'pit_ti_224',\n",
      " 'pit_ti_distilled_224',\n",
      " 'pit_xs_224',\n",
      " 'pit_xs_distilled_224',\n",
      " 'pnasnet5large',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'regnetz_b16',\n",
      " 'regnetz_c16',\n",
      " 'regnetz_d8',\n",
      " 'regnetz_d32',\n",
      " 'regnetz_e8',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2next50',\n",
      " 'resmlp_12_224',\n",
      " 'resmlp_12_224_dino',\n",
      " 'resmlp_12_distilled_224',\n",
      " 'resmlp_24_224',\n",
      " 'resmlp_24_224_dino',\n",
      " 'resmlp_24_distilled_224',\n",
      " 'resmlp_36_224',\n",
      " 'resmlp_36_distilled_224',\n",
      " 'resmlp_big_24_224',\n",
      " 'resmlp_big_24_224_in22ft1k',\n",
      " 'resmlp_big_24_distilled_224',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet26t',\n",
      " 'resnet32ts',\n",
      " 'resnet33ts',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50_gn',\n",
      " 'resnet50d',\n",
      " 'resnet51q',\n",
      " 'resnet61q',\n",
      " 'resnet101',\n",
      " 'resnet101d',\n",
      " 'resnet152',\n",
      " 'resnet152d',\n",
      " 'resnet200d',\n",
      " 'resnetblur50',\n",
      " 'resnetrs50',\n",
      " 'resnetrs101',\n",
      " 'resnetrs152',\n",
      " 'resnetrs200',\n",
      " 'resnetrs270',\n",
      " 'resnetrs350',\n",
      " 'resnetrs420',\n",
      " 'resnetv2_50',\n",
      " 'resnetv2_50x1_bit_distilled',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bit_teacher',\n",
      " 'resnetv2_152x2_bit_teacher_384',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext26ts',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'sebotnet33ts_256',\n",
      " 'sehalonet33ts',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'semnasnet_075',\n",
      " 'semnasnet_100',\n",
      " 'seresnet33ts',\n",
      " 'seresnet50',\n",
      " 'seresnet152d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext26ts',\n",
      " 'seresnext50_32x4d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swin_base_patch4_window7_224',\n",
      " 'swin_base_patch4_window7_224_in22k',\n",
      " 'swin_base_patch4_window12_384',\n",
      " 'swin_base_patch4_window12_384_in22k',\n",
      " 'swin_large_patch4_window7_224',\n",
      " 'swin_large_patch4_window7_224_in22k',\n",
      " 'swin_large_patch4_window12_384',\n",
      " 'swin_large_patch4_window12_384_in22k',\n",
      " 'swin_small_patch4_window7_224',\n",
      " 'swin_tiny_patch4_window7_224',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b0_ap',\n",
      " 'tf_efficientnet_b0_ns',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b1_ap',\n",
      " 'tf_efficientnet_b1_ns',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b2_ap',\n",
      " 'tf_efficientnet_b2_ns',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b3_ap',\n",
      " 'tf_efficientnet_b3_ns',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b4_ap',\n",
      " 'tf_efficientnet_b4_ns',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b5_ap',\n",
      " 'tf_efficientnet_b5_ns',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b6_ap',\n",
      " 'tf_efficientnet_b6_ns',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b7_ap',\n",
      " 'tf_efficientnet_b7_ns',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_b8_ap',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2_ns',\n",
      " 'tf_efficientnet_l2_ns_475',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_efficientnetv2_b0',\n",
      " 'tf_efficientnetv2_b1',\n",
      " 'tf_efficientnetv2_b2',\n",
      " 'tf_efficientnetv2_b3',\n",
      " 'tf_efficientnetv2_l',\n",
      " 'tf_efficientnetv2_l_in21ft1k',\n",
      " 'tf_efficientnetv2_l_in21k',\n",
      " 'tf_efficientnetv2_m',\n",
      " 'tf_efficientnetv2_m_in21ft1k',\n",
      " 'tf_efficientnetv2_m_in21k',\n",
      " 'tf_efficientnetv2_s',\n",
      " 'tf_efficientnetv2_s_in21ft1k',\n",
      " 'tf_efficientnetv2_s_in21k',\n",
      " 'tf_efficientnetv2_xl_in21ft1k',\n",
      " 'tf_efficientnetv2_xl_in21k',\n",
      " 'tf_inception_v3',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tinynet_a',\n",
      " 'tinynet_b',\n",
      " 'tinynet_c',\n",
      " 'tinynet_d',\n",
      " 'tinynet_e',\n",
      " 'tnt_s_patch16_224',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_m_miil_in21k',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_densenet121',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'twins_pcpvt_base',\n",
      " 'twins_pcpvt_large',\n",
      " 'twins_pcpvt_small',\n",
      " 'twins_svt_base',\n",
      " 'twins_svt_large',\n",
      " 'twins_svt_small',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'visformer_small',\n",
      " 'vit_base_patch8_224',\n",
      " 'vit_base_patch8_224_in21k',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_224_in21k',\n",
      " 'vit_base_patch16_224_miil',\n",
      " 'vit_base_patch16_224_miil_in21k',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch16_sam_224',\n",
      " 'vit_base_patch32_224',\n",
      " 'vit_base_patch32_224_in21k',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_patch32_sam_224',\n",
      " 'vit_base_r50_s16_224_in21k',\n",
      " 'vit_base_r50_s16_384',\n",
      " 'vit_huge_patch14_224_in21k',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_224_in21k',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch32_224_in21k',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_large_r50_s32_224',\n",
      " 'vit_large_r50_s32_224_in21k',\n",
      " 'vit_large_r50_s32_384',\n",
      " 'vit_small_patch16_224',\n",
      " 'vit_small_patch16_224_in21k',\n",
      " 'vit_small_patch16_384',\n",
      " 'vit_small_patch32_224',\n",
      " 'vit_small_patch32_224_in21k',\n",
      " 'vit_small_patch32_384',\n",
      " 'vit_small_r26_s32_224',\n",
      " 'vit_small_r26_s32_224_in21k',\n",
      " 'vit_small_r26_s32_384',\n",
      " 'vit_tiny_patch16_224',\n",
      " 'vit_tiny_patch16_224_in21k',\n",
      " 'vit_tiny_patch16_384',\n",
      " 'vit_tiny_r_s16_p8_224',\n",
      " 'vit_tiny_r_s16_p8_224_in21k',\n",
      " 'vit_tiny_r_s16_p8_384',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception',\n",
      " 'xception41',\n",
      " 'xception65',\n",
      " 'xception71',\n",
      " 'xcit_large_24_p8_224',\n",
      " 'xcit_large_24_p8_224_dist',\n",
      " 'xcit_large_24_p8_384_dist',\n",
      " 'xcit_large_24_p16_224',\n",
      " 'xcit_large_24_p16_224_dist',\n",
      " 'xcit_large_24_p16_384_dist',\n",
      " 'xcit_medium_24_p8_224',\n",
      " 'xcit_medium_24_p8_224_dist',\n",
      " 'xcit_medium_24_p8_384_dist',\n",
      " 'xcit_medium_24_p16_224',\n",
      " 'xcit_medium_24_p16_224_dist',\n",
      " 'xcit_medium_24_p16_384_dist',\n",
      " 'xcit_nano_12_p8_224',\n",
      " 'xcit_nano_12_p8_224_dist',\n",
      " 'xcit_nano_12_p8_384_dist',\n",
      " 'xcit_nano_12_p16_224',\n",
      " 'xcit_nano_12_p16_224_dist',\n",
      " 'xcit_nano_12_p16_384_dist',\n",
      " 'xcit_small_12_p8_224',\n",
      " 'xcit_small_12_p8_224_dist',\n",
      " 'xcit_small_12_p8_384_dist',\n",
      " 'xcit_small_12_p16_224',\n",
      " 'xcit_small_12_p16_224_dist',\n",
      " 'xcit_small_12_p16_384_dist',\n",
      " 'xcit_small_24_p8_224',\n",
      " 'xcit_small_24_p8_224_dist',\n",
      " 'xcit_small_24_p8_384_dist',\n",
      " 'xcit_small_24_p16_224',\n",
      " 'xcit_small_24_p16_224_dist',\n",
      " 'xcit_small_24_p16_384_dist',\n",
      " 'xcit_tiny_12_p8_224',\n",
      " 'xcit_tiny_12_p8_224_dist',\n",
      " 'xcit_tiny_12_p8_384_dist',\n",
      " 'xcit_tiny_12_p16_224',\n",
      " 'xcit_tiny_12_p16_224_dist',\n",
      " 'xcit_tiny_12_p16_384_dist',\n",
      " 'xcit_tiny_24_p8_224',\n",
      " 'xcit_tiny_24_p8_224_dist',\n",
      " 'xcit_tiny_24_p8_384_dist',\n",
      " 'xcit_tiny_24_p16_224',\n",
      " 'xcit_tiny_24_p16_224_dist',\n",
      " 'xcit_tiny_24_p16_384_dist']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lXH5F_hA7uMl",
   "metadata": {
    "id": "lXH5F_hA7uMl"
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/ideal/Downloads/jupyter/user_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "FWntO1VD7L5u",
   "metadata": {
    "id": "FWntO1VD7L5u"
   },
   "outputs": [],
   "source": [
    "train_png = sorted(glob(path + 'train/*.png'))\n",
    "test_png = sorted(glob(path + 'test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atSgPJRn-OCW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atSgPJRn-OCW",
    "outputId": "87b6f90b-5c1c-4a0e-de54-994458543687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(858, 215)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_png), len(test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "xv0_rDVq7L5v",
   "metadata": {
    "id": "xv0_rDVq7L5v"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(path +\"train.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc9232f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0,\n",
       " '10-1': 1,\n",
       " '10-2': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "iMhC0nPw7L5w",
   "metadata": {
    "id": "iMhC0nPw7L5w"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "#     img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "zsmJA3E97L5x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsmJA3E97L5x",
    "outputId": "e0dc61fe-5617-42e8-c8b0-0e95b9f60656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 858/858 [00:00<00:00, 1092.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 215/215 [00:00<00:00, 1102.56it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "KA73Lku9A2N9",
   "metadata": {
    "id": "KA73Lku9A2N9"
   },
   "outputs": [],
   "source": [
    "np.save(path + 'train_imgs_384', np.array(train_imgs))\n",
    "np.save(path + 'test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "L6qBdX7nCp8L",
   "metadata": {
    "id": "L6qBdX7nCp8L"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.load(path + 'train_imgs_384.npy')\n",
    "test_imgs = np.load(path + 'test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9207e10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평균 0.587861452947292 0.5398018372012267 0.4853426659853918\n",
      "train 표준편차 0.15058758283288234 0.15921522386293296 0.17031454681984776\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "train_meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "train_meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "train_meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "train_stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "train_stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "train_stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"train 평균\",train_meanR, train_meanG, train_meanB)\n",
    "print(\"train 표준편차\",train_stdR, train_stdG, train_stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "935064b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 평균 0.5915704246815005 0.5468021681783177 0.49356994941872095\n",
      "test 표준편차 0.15494109227168867 0.1642936360901455 0.1756015391157054\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "test_meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "test_meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "test_meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "test_stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "test_stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "test_stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"test 평균\",test_meanR, test_meanG, test_meanB)\n",
    "print(\"test 표준편차\",test_stdR, test_stdG, test_stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "VFXzojoo7L5y",
   "metadata": {
    "id": "VFXzojoo7L5y"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [train_meanR, train_meanG, train_meanB],\n",
    "                                     std = [train_stdR, train_stdG, train_stdB]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [test_meanR, test_meanG, test_meanB],\n",
    "                                     std = [test_stdR, test_stdG, test_stdB])\n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('vgg19', pretrained=True, num_classes=11)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('vgg19', pretrained=True, num_classes=11)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38qk8sGbYiO_",
   "metadata": {
    "id": "38qk8sGbYiO_"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lkNCkyG9RPzX",
   "metadata": {
    "id": "lkNCkyG9RPzX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to C:\\Users\\ideal/.cache\\torch\\hub\\checkpoints\\vgg19-dcbb9e9d.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 14s/1387s\n",
      "TRAIN    loss : 2.07121    f1 : 0.22273\n",
      "Val    loss : 4.34206    f1 : 0.20080\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 11s/1117s\n",
      "TRAIN    loss : 1.48478    f1 : 0.44841\n",
      "Val    loss : 0.92063    f1 : 0.61089\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 12s/1119s\n",
      "TRAIN    loss : 1.05397    f1 : 0.60147\n",
      "Val    loss : 0.64823    f1 : 0.71355\n",
      "epoch : 4/100    time : 9s/888s\n",
      "TRAIN    loss : 0.71094    f1 : 0.72691\n",
      "Val    loss : 1.09377    f1 : 0.68596\n",
      "epoch : 5/100    time : 9s/856s\n",
      "TRAIN    loss : 0.56646    f1 : 0.81589\n",
      "Val    loss : 1.05803    f1 : 0.61414\n",
      "epoch : 6/100    time : 9s/850s\n",
      "TRAIN    loss : 0.61242    f1 : 0.78609\n",
      "Val    loss : 0.72281    f1 : 0.71233\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 11s/1030s\n",
      "TRAIN    loss : 0.38418    f1 : 0.86756\n",
      "Val    loss : 0.42411    f1 : 0.87919\n",
      "epoch : 8/100    time : 9s/838s\n",
      "TRAIN    loss : 0.47570    f1 : 0.85354\n",
      "Val    loss : 0.61699    f1 : 0.86088\n",
      "epoch : 9/100    time : 9s/822s\n",
      "TRAIN    loss : 0.44968    f1 : 0.85350\n",
      "Val    loss : 0.35984    f1 : 0.85908\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/100    time : 11s/1009s\n",
      "TRAIN    loss : 0.27076    f1 : 0.90169\n",
      "Val    loss : 0.40764    f1 : 0.88177\n",
      "epoch : 11/100    time : 9s/819s\n",
      "TRAIN    loss : 0.24121    f1 : 0.92486\n",
      "Val    loss : 0.58035    f1 : 0.83280\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 11s/980s\n",
      "TRAIN    loss : 0.47525    f1 : 0.87568\n",
      "Val    loss : 0.25746    f1 : 0.91817\n",
      "epoch : 13/100    time : 9s/806s\n",
      "TRAIN    loss : 0.16452    f1 : 0.93910\n",
      "Val    loss : 0.40195    f1 : 0.89715\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/100    time : 11s/968s\n",
      "TRAIN    loss : 0.12274    f1 : 0.95764\n",
      "Val    loss : 0.14989    f1 : 0.95259\n",
      "epoch : 15/100    time : 9s/779s\n",
      "TRAIN    loss : 0.09499    f1 : 0.97599\n",
      "Val    loss : 0.37097    f1 : 0.91768\n",
      "epoch : 16/100    time : 9s/756s\n",
      "TRAIN    loss : 0.25620    f1 : 0.91870\n",
      "Val    loss : 0.31270    f1 : 0.91805\n",
      "epoch : 17/100    time : 9s/749s\n",
      "TRAIN    loss : 0.18624    f1 : 0.94464\n",
      "Val    loss : 0.39310    f1 : 0.90966\n",
      "epoch : 18/100    time : 9s/734s\n",
      "TRAIN    loss : 0.10778    f1 : 0.96308\n",
      "Val    loss : 0.29570    f1 : 0.92190\n",
      "epoch : 19/100    time : 9s/728s\n",
      "TRAIN    loss : 0.27731    f1 : 0.95727\n",
      "Val    loss : 0.64742    f1 : 0.82385\n",
      "epoch : 20/100    time : 9s/716s\n",
      "TRAIN    loss : 0.30006    f1 : 0.91013\n",
      "Val    loss : 0.25807    f1 : 0.92363\n",
      "epoch : 21/100    time : 9s/715s\n",
      "TRAIN    loss : 0.20890    f1 : 0.93062\n",
      "Val    loss : 0.51187    f1 : 0.84544\n",
      "epoch : 22/100    time : 9s/697s\n",
      "TRAIN    loss : 0.18607    f1 : 0.94429\n",
      "Val    loss : 0.28237    f1 : 0.90543\n",
      "epoch : 23/100    time : 9s/690s\n",
      "TRAIN    loss : 0.26331    f1 : 0.92077\n",
      "Val    loss : 0.28012    f1 : 0.90533\n",
      "epoch : 24/100    time : 9s/685s\n",
      "TRAIN    loss : 0.07880    f1 : 0.97421\n",
      "Val    loss : 0.29392    f1 : 0.94060\n",
      "epoch : 25/100    time : 9s/670s\n",
      "TRAIN    loss : 0.02179    f1 : 0.99435\n",
      "Val    loss : 0.25232    f1 : 0.94637\n",
      "epoch : 26/100    time : 9s/670s\n",
      "TRAIN    loss : 0.10570    f1 : 0.96554\n",
      "Val    loss : 0.62289    f1 : 0.84389\n",
      "epoch : 27/100    time : 9s/656s\n",
      "TRAIN    loss : 0.25308    f1 : 0.91357\n",
      "Val    loss : 0.24881    f1 : 0.90177\n",
      "epoch : 28/100    time : 9s/649s\n",
      "TRAIN    loss : 0.12237    f1 : 0.96805\n",
      "Val    loss : 0.27972    f1 : 0.91530\n",
      "epoch : 29/100    time : 9s/639s\n",
      "TRAIN    loss : 0.06593    f1 : 0.97871\n",
      "Val    loss : 0.25253    f1 : 0.91754\n",
      "epoch : 30/100    time : 9s/632s\n",
      "TRAIN    loss : 0.10850    f1 : 0.97668\n",
      "Val    loss : 0.30979    f1 : 0.91901\n",
      "epoch : 31/100    time : 9s/622s\n",
      "TRAIN    loss : 0.20417    f1 : 0.95107\n",
      "Val    loss : 0.33363    f1 : 0.91208\n",
      "epoch : 32/100    time : 9s/613s\n",
      "TRAIN    loss : 0.06879    f1 : 0.98298\n",
      "Val    loss : 0.36726    f1 : 0.89915\n",
      "epoch : 33/100    time : 9s/602s\n",
      "TRAIN    loss : 0.09055    f1 : 0.97025\n",
      "Val    loss : 0.27500    f1 : 0.89396\n",
      "epoch : 34/100    time : 9s/595s\n",
      "TRAIN    loss : 0.08498    f1 : 0.97403\n",
      "Val    loss : 0.30973    f1 : 0.90694\n",
      "----------fold_1 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 11s/1099s\n",
      "TRAIN    loss : 1.78664    f1 : 0.34841\n",
      "Val    loss : 1.44141    f1 : 0.38499\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 12s/1132s\n",
      "TRAIN    loss : 1.32418    f1 : 0.55360\n",
      "Val    loss : 0.66319    f1 : 0.75688\n",
      "epoch : 3/100    time : 9s/885s\n",
      "TRAIN    loss : 0.76911    f1 : 0.73051\n",
      "Val    loss : 0.82640    f1 : 0.70964\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 11s/1084s\n",
      "TRAIN    loss : 0.54893    f1 : 0.80715\n",
      "Val    loss : 0.29748    f1 : 0.91050\n",
      "epoch : 5/100    time : 9s/873s\n",
      "TRAIN    loss : 0.56721    f1 : 0.81866\n",
      "Val    loss : 0.37145    f1 : 0.86695\n",
      "epoch : 6/100    time : 9s/843s\n",
      "TRAIN    loss : 0.41046    f1 : 0.85447\n",
      "Val    loss : 0.52580    f1 : 0.85194\n",
      "epoch : 7/100    time : 9s/835s\n",
      "TRAIN    loss : 0.35085    f1 : 0.88995\n",
      "Val    loss : 0.28637    f1 : 0.89178\n",
      "epoch : 8/100    time : 9s/830s\n",
      "TRAIN    loss : 0.39294    f1 : 0.87594\n",
      "Val    loss : 0.28078    f1 : 0.88436\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 11s/1012s\n",
      "TRAIN    loss : 0.24916    f1 : 0.92726\n",
      "Val    loss : 0.16815    f1 : 0.95039\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/100    time : 11s/1019s\n",
      "TRAIN    loss : 0.33846    f1 : 0.90589\n",
      "Val    loss : 0.17162    f1 : 0.95907\n",
      "epoch : 11/100    time : 9s/818s\n",
      "TRAIN    loss : 0.29333    f1 : 0.90545\n",
      "Val    loss : 0.24102    f1 : 0.95293\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 11s/977s\n",
      "TRAIN    loss : 0.23145    f1 : 0.91908\n",
      "Val    loss : 0.13526    f1 : 0.95975\n",
      "epoch : 13/100    time : 9s/803s\n",
      "TRAIN    loss : 0.20694    f1 : 0.93177\n",
      "Val    loss : 0.18089    f1 : 0.95873\n",
      "epoch : 14/100    time : 9s/772s\n",
      "TRAIN    loss : 0.12450    f1 : 0.96131\n",
      "Val    loss : 0.20790    f1 : 0.93989\n",
      "epoch : 15/100    time : 9s/762s\n",
      "TRAIN    loss : 0.17563    f1 : 0.94750\n",
      "Val    loss : 0.18354    f1 : 0.95888\n",
      "epoch : 16/100    time : 9s/754s\n",
      "TRAIN    loss : 0.32455    f1 : 0.91113\n",
      "Val    loss : 0.16333    f1 : 0.94376\n",
      "epoch : 17/100    time : 9s/743s\n",
      "TRAIN    loss : 0.21169    f1 : 0.92869\n",
      "Val    loss : 0.35971    f1 : 0.87011\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/100    time : 12s/949s\n",
      "TRAIN    loss : 0.12415    f1 : 0.95725\n",
      "Val    loss : 0.09661    f1 : 0.96052\n",
      "epoch : 19/100    time : 9s/745s\n",
      "TRAIN    loss : 0.05289    f1 : 0.98515\n",
      "Val    loss : 0.26117    f1 : 0.94108\n",
      "epoch : 20/100    time : 9s/718s\n",
      "TRAIN    loss : 0.21959    f1 : 0.92873\n",
      "Val    loss : 0.21769    f1 : 0.92331\n",
      "epoch : 21/100    time : 9s/708s\n",
      "TRAIN    loss : 0.18337    f1 : 0.94680\n",
      "Val    loss : 0.20890    f1 : 0.93743\n",
      "epoch : 22/100    time : 9s/703s\n",
      "TRAIN    loss : 0.14235    f1 : 0.95202\n",
      "Val    loss : 0.15796    f1 : 0.94665\n",
      "-----------------SAVE:23 epoch----------------\n",
      "epoch : 23/100    time : 11s/874s\n",
      "TRAIN    loss : 0.11413    f1 : 0.97030\n",
      "Val    loss : 0.08470    f1 : 0.97189\n",
      "epoch : 24/100    time : 9s/699s\n",
      "TRAIN    loss : 0.04496    f1 : 0.98293\n",
      "Val    loss : 0.15447    f1 : 0.96612\n",
      "epoch : 25/100    time : 9s/672s\n",
      "TRAIN    loss : 0.10342    f1 : 0.96700\n",
      "Val    loss : 0.36552    f1 : 0.86945\n",
      "epoch : 26/100    time : 9s/663s\n",
      "TRAIN    loss : 0.06089    f1 : 0.98105\n",
      "Val    loss : 0.24625    f1 : 0.93092\n",
      "epoch : 27/100    time : 9s/674s\n",
      "TRAIN    loss : 0.14164    f1 : 0.95547\n",
      "Val    loss : 0.23317    f1 : 0.90186\n",
      "epoch : 28/100    time : 9s/661s\n",
      "TRAIN    loss : 0.10921    f1 : 0.96870\n",
      "Val    loss : 0.44284    f1 : 0.86292\n",
      "epoch : 29/100    time : 9s/661s\n",
      "TRAIN    loss : 0.18998    f1 : 0.94942\n",
      "Val    loss : 0.29274    f1 : 0.93018\n",
      "epoch : 30/100    time : 9s/644s\n",
      "TRAIN    loss : 0.08549    f1 : 0.97596\n",
      "Val    loss : 0.33354    f1 : 0.88944\n",
      "epoch : 31/100    time : 9s/623s\n",
      "TRAIN    loss : 0.20371    f1 : 0.94188\n",
      "Val    loss : 0.60686    f1 : 0.82992\n",
      "epoch : 32/100    time : 9s/627s\n",
      "TRAIN    loss : 0.14916    f1 : 0.95908\n",
      "Val    loss : 0.19350    f1 : 0.94165\n",
      "epoch : 33/100    time : 9s/621s\n",
      "TRAIN    loss : 0.18462    f1 : 0.94791\n",
      "Val    loss : 0.19607    f1 : 0.96470\n",
      "epoch : 34/100    time : 9s/612s\n",
      "TRAIN    loss : 0.16790    f1 : 0.96315\n",
      "Val    loss : 0.14478    f1 : 0.96477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:35 epoch----------------\n",
      "epoch : 35/100    time : 11s/733s\n",
      "TRAIN    loss : 0.13725    f1 : 0.95376\n",
      "Val    loss : 0.09012    f1 : 0.97627\n",
      "epoch : 36/100    time : 10s/613s\n",
      "TRAIN    loss : 0.19272    f1 : 0.94067\n",
      "Val    loss : 0.12342    f1 : 0.97584\n",
      "epoch : 37/100    time : 9s/578s\n",
      "TRAIN    loss : 0.11110    f1 : 0.97592\n",
      "Val    loss : 0.13219    f1 : 0.95748\n",
      "epoch : 38/100    time : 9s/570s\n",
      "TRAIN    loss : 0.07604    f1 : 0.98415\n",
      "Val    loss : 0.11135    f1 : 0.95729\n",
      "epoch : 39/100    time : 9s/559s\n",
      "TRAIN    loss : 0.01822    f1 : 0.99436\n",
      "Val    loss : 0.09966    f1 : 0.96298\n",
      "-----------------SAVE:40 epoch----------------\n",
      "epoch : 40/100    time : 11s/682s\n",
      "TRAIN    loss : 0.02495    f1 : 0.99291\n",
      "Val    loss : 0.05177    f1 : 0.98137\n",
      "epoch : 41/100    time : 9s/544s\n",
      "TRAIN    loss : 0.12937    f1 : 0.96379\n",
      "Val    loss : 0.21767    f1 : 0.90978\n",
      "epoch : 42/100    time : 9s/524s\n",
      "TRAIN    loss : 0.06730    f1 : 0.97050\n",
      "Val    loss : 0.12830    f1 : 0.97059\n",
      "epoch : 43/100    time : 9s/537s\n",
      "TRAIN    loss : 0.08676    f1 : 0.97025\n",
      "Val    loss : 0.24589    f1 : 0.93587\n",
      "epoch : 44/100    time : 9s/504s\n",
      "TRAIN    loss : 0.02893    f1 : 0.99300\n",
      "Val    loss : 0.17857    f1 : 0.95925\n",
      "epoch : 45/100    time : 9s/500s\n",
      "TRAIN    loss : 0.04922    f1 : 0.99134\n",
      "Val    loss : 0.09682    f1 : 0.97587\n",
      "epoch : 46/100    time : 9s/483s\n",
      "TRAIN    loss : 0.27387    f1 : 0.94550\n",
      "Val    loss : 0.42310    f1 : 0.86160\n",
      "epoch : 47/100    time : 9s/478s\n",
      "TRAIN    loss : 0.05647    f1 : 0.98439\n",
      "Val    loss : 0.15846    f1 : 0.94856\n",
      "epoch : 48/100    time : 9s/464s\n",
      "TRAIN    loss : 0.02965    f1 : 0.99292\n",
      "Val    loss : 0.25521    f1 : 0.95123\n",
      "epoch : 49/100    time : 9s/456s\n",
      "TRAIN    loss : 0.09861    f1 : 0.97311\n",
      "Val    loss : 0.16848    f1 : 0.94292\n",
      "epoch : 50/100    time : 9s/446s\n",
      "TRAIN    loss : 0.09630    f1 : 0.97288\n",
      "Val    loss : 0.09766    f1 : 0.95285\n",
      "epoch : 51/100    time : 9s/458s\n",
      "TRAIN    loss : 0.04652    f1 : 0.98461\n",
      "Val    loss : 0.12554    f1 : 0.95837\n",
      "epoch : 52/100    time : 9s/437s\n",
      "TRAIN    loss : 0.26256    f1 : 0.91439\n",
      "Val    loss : 0.13827    f1 : 0.96997\n",
      "epoch : 53/100    time : 9s/436s\n",
      "TRAIN    loss : 0.13403    f1 : 0.96090\n",
      "Val    loss : 0.17477    f1 : 0.94787\n",
      "epoch : 54/100    time : 9s/434s\n",
      "TRAIN    loss : 0.08061    f1 : 0.97668\n",
      "Val    loss : 0.18928    f1 : 0.96559\n",
      "epoch : 55/100    time : 9s/420s\n",
      "TRAIN    loss : 0.17824    f1 : 0.95281\n",
      "Val    loss : 0.30762    f1 : 0.89133\n",
      "epoch : 56/100    time : 9s/401s\n",
      "TRAIN    loss : 0.05671    f1 : 0.98264\n",
      "Val    loss : 0.25342    f1 : 0.92341\n",
      "epoch : 57/100    time : 9s/392s\n",
      "TRAIN    loss : 0.16351    f1 : 0.94932\n",
      "Val    loss : 0.16300    f1 : 0.94768\n",
      "epoch : 58/100    time : 9s/386s\n",
      "TRAIN    loss : 0.08646    f1 : 0.98021\n",
      "Val    loss : 0.12873    f1 : 0.95272\n",
      "epoch : 59/100    time : 9s/382s\n",
      "TRAIN    loss : 0.02539    f1 : 0.99294\n",
      "Val    loss : 0.13074    f1 : 0.97017\n",
      "epoch : 60/100    time : 9s/360s\n",
      "TRAIN    loss : 0.04804    f1 : 0.99151\n",
      "Val    loss : 0.39440    f1 : 0.93329\n",
      "----------fold_2 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 11s/1118s\n",
      "TRAIN    loss : 2.11803    f1 : 0.21329\n",
      "Val    loss : 1.47519    f1 : 0.39254\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 11s/1125s\n",
      "TRAIN    loss : 1.32702    f1 : 0.48319\n",
      "Val    loss : 1.26769    f1 : 0.48028\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 12s/1148s\n",
      "TRAIN    loss : 1.14668    f1 : 0.56429\n",
      "Val    loss : 0.74364    f1 : 0.69406\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 12s/1104s\n",
      "TRAIN    loss : 0.75742    f1 : 0.70752\n",
      "Val    loss : 0.72917    f1 : 0.80783\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 12s/1097s\n",
      "TRAIN    loss : 0.58643    f1 : 0.80053\n",
      "Val    loss : 0.38624    f1 : 0.87107\n",
      "epoch : 6/100    time : 9s/877s\n",
      "TRAIN    loss : 0.43377    f1 : 0.85118\n",
      "Val    loss : 0.46475    f1 : 0.87035\n",
      "epoch : 7/100    time : 9s/872s\n",
      "TRAIN    loss : 0.36088    f1 : 0.87099\n",
      "Val    loss : 0.39555    f1 : 0.85386\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 12s/1063s\n",
      "TRAIN    loss : 0.38209    f1 : 0.87744\n",
      "Val    loss : 0.34641    f1 : 0.89274\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 11s/1033s\n",
      "TRAIN    loss : 0.28316    f1 : 0.89764\n",
      "Val    loss : 0.40281    f1 : 0.89615\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/100    time : 11s/1018s\n",
      "TRAIN    loss : 0.26121    f1 : 0.90738\n",
      "Val    loss : 0.26598    f1 : 0.93000\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 11s/1015s\n",
      "TRAIN    loss : 0.25561    f1 : 0.90745\n",
      "Val    loss : 0.24845    f1 : 0.93861\n",
      "epoch : 12/100    time : 9s/811s\n",
      "TRAIN    loss : 0.20358    f1 : 0.94062\n",
      "Val    loss : 0.25435    f1 : 0.91496\n",
      "epoch : 13/100    time : 9s/785s\n",
      "TRAIN    loss : 0.18743    f1 : 0.94639\n",
      "Val    loss : 0.28060    f1 : 0.92401\n",
      "epoch : 14/100    time : 9s/776s\n",
      "TRAIN    loss : 0.14210    f1 : 0.95181\n",
      "Val    loss : 0.34929    f1 : 0.89885\n",
      "epoch : 15/100    time : 9s/765s\n",
      "TRAIN    loss : 0.14304    f1 : 0.94288\n",
      "Val    loss : 0.26341    f1 : 0.93743\n",
      "epoch : 16/100    time : 9s/752s\n",
      "TRAIN    loss : 0.12835    f1 : 0.95724\n",
      "Val    loss : 0.21868    f1 : 0.93798\n",
      "epoch : 17/100    time : 9s/747s\n",
      "TRAIN    loss : 0.18528    f1 : 0.94737\n",
      "Val    loss : 0.26173    f1 : 0.92978\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/100    time : 11s/918s\n",
      "TRAIN    loss : 0.13357    f1 : 0.95041\n",
      "Val    loss : 0.17368    f1 : 0.96654\n",
      "epoch : 19/100    time : 9s/768s\n",
      "TRAIN    loss : 0.21644    f1 : 0.92861\n",
      "Val    loss : 0.25436    f1 : 0.93250\n",
      "epoch : 20/100    time : 9s/730s\n",
      "TRAIN    loss : 0.07128    f1 : 0.97548\n",
      "Val    loss : 0.25498    f1 : 0.93876\n",
      "epoch : 21/100    time : 9s/710s\n",
      "TRAIN    loss : 0.16544    f1 : 0.93734\n",
      "Val    loss : 0.33488    f1 : 0.88165\n",
      "epoch : 22/100    time : 9s/704s\n",
      "TRAIN    loss : 0.12768    f1 : 0.96517\n",
      "Val    loss : 0.22003    f1 : 0.94891\n",
      "epoch : 23/100    time : 9s/694s\n",
      "TRAIN    loss : 0.19456    f1 : 0.94537\n",
      "Val    loss : 0.16423    f1 : 0.94322\n",
      "epoch : 24/100    time : 9s/684s\n",
      "TRAIN    loss : 0.17933    f1 : 0.94695\n",
      "Val    loss : 0.26391    f1 : 0.92630\n",
      "epoch : 25/100    time : 9s/672s\n",
      "TRAIN    loss : 0.14102    f1 : 0.96793\n",
      "Val    loss : 0.27993    f1 : 0.93014\n",
      "epoch : 26/100    time : 9s/678s\n",
      "TRAIN    loss : 0.21127    f1 : 0.93843\n",
      "Val    loss : 0.22573    f1 : 0.93624\n",
      "-----------------SAVE:27 epoch----------------\n",
      "epoch : 27/100    time : 12s/842s\n",
      "TRAIN    loss : 0.22339    f1 : 0.94782\n",
      "Val    loss : 0.13986    f1 : 0.97742\n",
      "epoch : 28/100    time : 9s/658s\n",
      "TRAIN    loss : 0.12130    f1 : 0.96815\n",
      "Val    loss : 0.17600    f1 : 0.94774\n",
      "epoch : 29/100    time : 9s/648s\n",
      "TRAIN    loss : 0.02476    f1 : 0.99140\n",
      "Val    loss : 0.26919    f1 : 0.93083\n",
      "epoch : 30/100    time : 9s/635s\n",
      "TRAIN    loss : 0.14864    f1 : 0.95935\n",
      "Val    loss : 0.27414    f1 : 0.92603\n",
      "epoch : 31/100    time : 9s/621s\n",
      "TRAIN    loss : 0.16204    f1 : 0.94854\n",
      "Val    loss : 0.15294    f1 : 0.94689\n",
      "epoch : 32/100    time : 9s/617s\n",
      "TRAIN    loss : 0.03683    f1 : 0.98576\n",
      "Val    loss : 0.22374    f1 : 0.94934\n",
      "epoch : 33/100    time : 9s/609s\n",
      "TRAIN    loss : 0.05319    f1 : 0.98290\n",
      "Val    loss : 0.36246    f1 : 0.92193\n",
      "epoch : 34/100    time : 9s/600s\n",
      "TRAIN    loss : 0.07057    f1 : 0.98996\n",
      "Val    loss : 0.16288    f1 : 0.94321\n",
      "epoch : 35/100    time : 9s/586s\n",
      "TRAIN    loss : 0.14509    f1 : 0.96883\n",
      "Val    loss : 0.25934    f1 : 0.92222\n",
      "epoch : 36/100    time : 9s/579s\n",
      "TRAIN    loss : 0.09545    f1 : 0.97418\n",
      "Val    loss : 0.42074    f1 : 0.92438\n",
      "epoch : 37/100    time : 9s/568s\n",
      "TRAIN    loss : 0.07660    f1 : 0.97840\n",
      "Val    loss : 0.29525    f1 : 0.93801\n",
      "epoch : 38/100    time : 9s/579s\n",
      "TRAIN    loss : 0.12250    f1 : 0.96170\n",
      "Val    loss : 0.24576    f1 : 0.93231\n",
      "epoch : 39/100    time : 9s/573s\n",
      "TRAIN    loss : 0.07093    f1 : 0.97587\n",
      "Val    loss : 0.30210    f1 : 0.91865\n",
      "epoch : 40/100    time : 9s/556s\n",
      "TRAIN    loss : 0.00564    f1 : 1.00000\n",
      "Val    loss : 0.35844    f1 : 0.93779\n",
      "epoch : 41/100    time : 9s/528s\n",
      "TRAIN    loss : 0.00229    f1 : 1.00000\n",
      "Val    loss : 0.41694    f1 : 0.93812\n",
      "epoch : 42/100    time : 9s/520s\n",
      "TRAIN    loss : 0.00527    f1 : 0.99858\n",
      "Val    loss : 0.24729    f1 : 0.96606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 43/100    time : 9s/516s\n",
      "TRAIN    loss : 0.06630    f1 : 0.98532\n",
      "Val    loss : 0.25625    f1 : 0.94927\n",
      "epoch : 44/100    time : 9s/500s\n",
      "TRAIN    loss : 0.01416    f1 : 0.99716\n",
      "Val    loss : 0.21685    f1 : 0.96081\n",
      "epoch : 45/100    time : 9s/492s\n",
      "TRAIN    loss : 0.09069    f1 : 0.98294\n",
      "Val    loss : 0.52183    f1 : 0.88398\n",
      "epoch : 46/100    time : 9s/484s\n",
      "TRAIN    loss : 0.41421    f1 : 0.87758\n",
      "Val    loss : 0.32785    f1 : 0.92342\n",
      "epoch : 47/100    time : 9s/478s\n",
      "TRAIN    loss : 0.17672    f1 : 0.94789\n",
      "Val    loss : 0.26307    f1 : 0.93217\n",
      "----------fold_3 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 11s/1107s\n",
      "TRAIN    loss : 1.82856    f1 : 0.36037\n",
      "Val    loss : 1.01150    f1 : 0.62593\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 11s/1126s\n",
      "TRAIN    loss : 0.97654    f1 : 0.62245\n",
      "Val    loss : 0.73135    f1 : 0.76054\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 12s/1123s\n",
      "TRAIN    loss : 0.78283    f1 : 0.73458\n",
      "Val    loss : 0.55980    f1 : 0.76970\n",
      "epoch : 4/100    time : 9s/893s\n",
      "TRAIN    loss : 0.60782    f1 : 0.78202\n",
      "Val    loss : 0.60277    f1 : 0.74398\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 11s/1068s\n",
      "TRAIN    loss : 0.52765    f1 : 0.81847\n",
      "Val    loss : 0.40619    f1 : 0.84387\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 11s/1058s\n",
      "TRAIN    loss : 0.34580    f1 : 0.88532\n",
      "Val    loss : 0.38430    f1 : 0.87979\n",
      "epoch : 7/100    time : 9s/858s\n",
      "TRAIN    loss : 0.37832    f1 : 0.87830\n",
      "Val    loss : 0.59740    f1 : 0.76442\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 11s/1023s\n",
      "TRAIN    loss : 0.36179    f1 : 0.88584\n",
      "Val    loss : 0.26395    f1 : 0.89365\n",
      "epoch : 9/100    time : 9s/832s\n",
      "TRAIN    loss : 0.24993    f1 : 0.92023\n",
      "Val    loss : 0.44396    f1 : 0.87441\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/100    time : 11s/1015s\n",
      "TRAIN    loss : 0.26971    f1 : 0.91616\n",
      "Val    loss : 0.17068    f1 : 0.94687\n",
      "epoch : 11/100    time : 9s/822s\n",
      "TRAIN    loss : 0.24371    f1 : 0.91419\n",
      "Val    loss : 0.44517    f1 : 0.86424\n",
      "epoch : 12/100    time : 9s/788s\n",
      "TRAIN    loss : 0.26044    f1 : 0.91198\n",
      "Val    loss : 0.19967    f1 : 0.94657\n",
      "epoch : 13/100    time : 9s/781s\n",
      "TRAIN    loss : 0.28432    f1 : 0.91454\n",
      "Val    loss : 0.34607    f1 : 0.88891\n",
      "epoch : 14/100    time : 9s/773s\n",
      "TRAIN    loss : 0.18918    f1 : 0.94953\n",
      "Val    loss : 0.30004    f1 : 0.89032\n",
      "epoch : 15/100    time : 9s/761s\n",
      "TRAIN    loss : 0.14092    f1 : 0.95548\n",
      "Val    loss : 0.18029    f1 : 0.94085\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/100    time : 11s/939s\n",
      "TRAIN    loss : 0.12405    f1 : 0.95895\n",
      "Val    loss : 0.20280    f1 : 0.96470\n",
      "epoch : 17/100    time : 9s/766s\n",
      "TRAIN    loss : 0.17587    f1 : 0.94245\n",
      "Val    loss : 0.52227    f1 : 0.85206\n",
      "epoch : 18/100    time : 9s/736s\n",
      "TRAIN    loss : 0.12474    f1 : 0.96298\n",
      "Val    loss : 0.25652    f1 : 0.94604\n",
      "epoch : 19/100    time : 9s/728s\n",
      "TRAIN    loss : 0.07553    f1 : 0.97568\n",
      "Val    loss : 0.14904    f1 : 0.95247\n",
      "-----------------SAVE:20 epoch----------------\n",
      "epoch : 20/100    time : 11s/912s\n",
      "TRAIN    loss : 0.06162    f1 : 0.98147\n",
      "Val    loss : 0.09428    f1 : 0.98280\n",
      "epoch : 21/100    time : 9s/733s\n",
      "TRAIN    loss : 0.20123    f1 : 0.92616\n",
      "Val    loss : 0.38075    f1 : 0.89526\n",
      "epoch : 22/100    time : 9s/702s\n",
      "TRAIN    loss : 0.26601    f1 : 0.90309\n",
      "Val    loss : 0.22277    f1 : 0.93909\n",
      "epoch : 23/100    time : 9s/693s\n",
      "TRAIN    loss : 0.19498    f1 : 0.93744\n",
      "Val    loss : 0.35116    f1 : 0.91856\n",
      "epoch : 24/100    time : 9s/686s\n",
      "TRAIN    loss : 0.21015    f1 : 0.93686\n",
      "Val    loss : 0.13113    f1 : 0.95384\n",
      "epoch : 25/100    time : 9s/678s\n",
      "TRAIN    loss : 0.05678    f1 : 0.98291\n",
      "Val    loss : 0.33312    f1 : 0.90049\n",
      "epoch : 26/100    time : 9s/673s\n",
      "TRAIN    loss : 0.16555    f1 : 0.94842\n",
      "Val    loss : 0.27577    f1 : 0.90506\n",
      "epoch : 27/100    time : 9s/658s\n",
      "TRAIN    loss : 0.09026    f1 : 0.97276\n",
      "Val    loss : 0.14718    f1 : 0.96635\n",
      "epoch : 28/100    time : 9s/651s\n",
      "TRAIN    loss : 0.03572    f1 : 0.98843\n",
      "Val    loss : 0.18194    f1 : 0.98172\n",
      "epoch : 29/100    time : 9s/642s\n",
      "TRAIN    loss : 0.10067    f1 : 0.97002\n",
      "Val    loss : 0.35966    f1 : 0.91722\n",
      "epoch : 30/100    time : 9s/634s\n",
      "TRAIN    loss : 0.14609    f1 : 0.96324\n",
      "Val    loss : 0.16141    f1 : 0.97744\n",
      "epoch : 31/100    time : 9s/620s\n",
      "TRAIN    loss : 0.09633    f1 : 0.97737\n",
      "Val    loss : 0.44051    f1 : 0.88302\n",
      "epoch : 32/100    time : 9s/610s\n",
      "TRAIN    loss : 0.05976    f1 : 0.98974\n",
      "Val    loss : 0.17441    f1 : 0.96346\n",
      "epoch : 33/100    time : 9s/602s\n",
      "TRAIN    loss : 0.01875    f1 : 0.99285\n",
      "Val    loss : 0.18211    f1 : 0.93805\n",
      "epoch : 34/100    time : 9s/591s\n",
      "TRAIN    loss : 0.08699    f1 : 0.97659\n",
      "Val    loss : 0.23262    f1 : 0.93511\n",
      "epoch : 35/100    time : 9s/583s\n",
      "TRAIN    loss : 0.09379    f1 : 0.97669\n",
      "Val    loss : 0.59498    f1 : 0.84485\n",
      "epoch : 36/100    time : 9s/574s\n",
      "TRAIN    loss : 0.57104    f1 : 0.88706\n",
      "Val    loss : 0.91629    f1 : 0.72763\n",
      "epoch : 37/100    time : 9s/565s\n",
      "TRAIN    loss : 0.40560    f1 : 0.85776\n",
      "Val    loss : 0.28966    f1 : 0.87659\n",
      "epoch : 38/100    time : 9s/560s\n",
      "TRAIN    loss : 0.21265    f1 : 0.93164\n",
      "Val    loss : 0.35426    f1 : 0.91276\n",
      "epoch : 39/100    time : 9s/547s\n",
      "TRAIN    loss : 0.12119    f1 : 0.96652\n",
      "Val    loss : 0.34319    f1 : 0.91080\n",
      "epoch : 40/100    time : 9s/536s\n",
      "TRAIN    loss : 0.13845    f1 : 0.96181\n",
      "Val    loss : 0.45766    f1 : 0.86095\n",
      "----------fold_4 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 11s/1103s\n",
      "TRAIN    loss : 2.29891    f1 : 0.14022\n",
      "Val    loss : 1.67358    f1 : 0.22867\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 11s/1121s\n",
      "TRAIN    loss : 1.64588    f1 : 0.33431\n",
      "Val    loss : 1.47359    f1 : 0.31079\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 11s/1090s\n",
      "TRAIN    loss : 1.17028    f1 : 0.58994\n",
      "Val    loss : 0.98406    f1 : 0.62886\n",
      "epoch : 4/100    time : 9s/888s\n",
      "TRAIN    loss : 0.94443    f1 : 0.65470\n",
      "Val    loss : 1.00625    f1 : 0.58465\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 11s/1065s\n",
      "TRAIN    loss : 0.82324    f1 : 0.67133\n",
      "Val    loss : 1.00076    f1 : 0.78128\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 12s/1085s\n",
      "TRAIN    loss : 0.72673    f1 : 0.77835\n",
      "Val    loss : 0.59714    f1 : 0.81292\n",
      "epoch : 7/100    time : 9s/860s\n",
      "TRAIN    loss : 0.66708    f1 : 0.77138\n",
      "Val    loss : 0.75009    f1 : 0.77123\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 11s/1027s\n",
      "TRAIN    loss : 0.39114    f1 : 0.86242\n",
      "Val    loss : 0.40773    f1 : 0.84392\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 11s/1040s\n",
      "TRAIN    loss : 0.32784    f1 : 0.89899\n",
      "Val    loss : 0.32476    f1 : 0.90225\n",
      "epoch : 10/100    time : 9s/845s\n",
      "TRAIN    loss : 0.26749    f1 : 0.90627\n",
      "Val    loss : 0.32365    f1 : 0.90152\n",
      "epoch : 11/100    time : 9s/814s\n",
      "TRAIN    loss : 0.31362    f1 : 0.90295\n",
      "Val    loss : 0.41326    f1 : 0.87141\n",
      "epoch : 12/100    time : 9s/801s\n",
      "TRAIN    loss : 0.28023    f1 : 0.90069\n",
      "Val    loss : 0.29758    f1 : 0.89160\n",
      "epoch : 13/100    time : 9s/795s\n",
      "TRAIN    loss : 0.23274    f1 : 0.92547\n",
      "Val    loss : 0.32019    f1 : 0.86179\n",
      "epoch : 14/100    time : 9s/792s\n",
      "TRAIN    loss : 0.26402    f1 : 0.92225\n",
      "Val    loss : 0.34751    f1 : 0.89491\n",
      "epoch : 15/100    time : 9s/790s\n",
      "TRAIN    loss : 0.11763    f1 : 0.96863\n",
      "Val    loss : 0.95672    f1 : 0.78339\n",
      "epoch : 16/100    time : 9s/780s\n",
      "TRAIN    loss : 0.29304    f1 : 0.91265\n",
      "Val    loss : 0.50414    f1 : 0.86523\n",
      "epoch : 17/100    time : 9s/772s\n",
      "TRAIN    loss : 0.25692    f1 : 0.93118\n",
      "Val    loss : 0.32870    f1 : 0.87834\n",
      "epoch : 18/100    time : 10s/782s\n",
      "TRAIN    loss : 0.29916    f1 : 0.91906\n",
      "Val    loss : 0.29355    f1 : 0.88949\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/100    time : 12s/934s\n",
      "TRAIN    loss : 0.27929    f1 : 0.91066\n",
      "Val    loss : 0.26715    f1 : 0.92592\n",
      "epoch : 20/100    time : 9s/754s\n",
      "TRAIN    loss : 0.19829    f1 : 0.94291\n",
      "Val    loss : 0.27399    f1 : 0.91768\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/100    time : 11s/903s\n",
      "TRAIN    loss : 0.10274    f1 : 0.96149\n",
      "Val    loss : 0.20844    f1 : 0.92872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:22 epoch----------------\n",
      "epoch : 22/100    time : 12s/920s\n",
      "TRAIN    loss : 0.16597    f1 : 0.95678\n",
      "Val    loss : 0.18759    f1 : 0.93133\n",
      "epoch : 23/100    time : 9s/730s\n",
      "TRAIN    loss : 0.13395    f1 : 0.95974\n",
      "Val    loss : 0.47379    f1 : 0.89316\n",
      "-----------------SAVE:24 epoch----------------\n",
      "epoch : 24/100    time : 12s/882s\n",
      "TRAIN    loss : 0.10176    f1 : 0.96712\n",
      "Val    loss : 0.13375    f1 : 0.95048\n",
      "epoch : 25/100    time : 10s/718s\n",
      "TRAIN    loss : 0.15884    f1 : 0.95327\n",
      "Val    loss : 0.44025    f1 : 0.87740\n",
      "epoch : 26/100    time : 9s/687s\n",
      "TRAIN    loss : 0.13669    f1 : 0.95866\n",
      "Val    loss : 0.40878    f1 : 0.90229\n",
      "epoch : 27/100    time : 9s/667s\n",
      "TRAIN    loss : 0.27217    f1 : 0.93530\n",
      "Val    loss : 0.30816    f1 : 0.89780\n",
      "epoch : 28/100    time : 9s/661s\n",
      "TRAIN    loss : 0.18775    f1 : 0.94696\n",
      "Val    loss : 0.34777    f1 : 0.86698\n",
      "epoch : 29/100    time : 9s/645s\n",
      "TRAIN    loss : 0.15696    f1 : 0.95299\n",
      "Val    loss : 0.24942    f1 : 0.94061\n",
      "epoch : 30/100    time : 9s/637s\n",
      "TRAIN    loss : 0.12972    f1 : 0.96191\n",
      "Val    loss : 0.20334    f1 : 0.94324\n",
      "epoch : 31/100    time : 9s/636s\n",
      "TRAIN    loss : 0.11632    f1 : 0.97267\n",
      "Val    loss : 0.37566    f1 : 0.93519\n",
      "epoch : 32/100    time : 9s/614s\n",
      "TRAIN    loss : 0.08981    f1 : 0.97576\n",
      "Val    loss : 0.19075    f1 : 0.92876\n",
      "epoch : 33/100    time : 9s/625s\n",
      "TRAIN    loss : 0.08555    f1 : 0.97455\n",
      "Val    loss : 0.24072    f1 : 0.91683\n",
      "epoch : 34/100    time : 9s/595s\n",
      "TRAIN    loss : 0.10110    f1 : 0.97145\n",
      "Val    loss : 0.44901    f1 : 0.88384\n",
      "epoch : 35/100    time : 9s/605s\n",
      "TRAIN    loss : 0.10191    f1 : 0.96851\n",
      "Val    loss : 0.28051    f1 : 0.93367\n",
      "epoch : 36/100    time : 9s/601s\n",
      "TRAIN    loss : 0.07095    f1 : 0.98516\n",
      "Val    loss : 0.45134    f1 : 0.88310\n",
      "epoch : 37/100    time : 9s/589s\n",
      "TRAIN    loss : 0.34813    f1 : 0.90669\n",
      "Val    loss : 0.29969    f1 : 0.90009\n",
      "epoch : 38/100    time : 9s/564s\n",
      "TRAIN    loss : 0.09848    f1 : 0.97097\n",
      "Val    loss : 0.19793    f1 : 0.94619\n",
      "epoch : 39/100    time : 9s/549s\n",
      "TRAIN    loss : 0.08599    f1 : 0.97412\n",
      "Val    loss : 0.23345    f1 : 0.92946\n",
      "epoch : 40/100    time : 9s/547s\n",
      "TRAIN    loss : 0.21528    f1 : 0.93906\n",
      "Val    loss : 0.30654    f1 : 0.91862\n",
      "epoch : 41/100    time : 9s/534s\n",
      "TRAIN    loss : 0.15409    f1 : 0.95560\n",
      "Val    loss : 0.18168    f1 : 0.93203\n",
      "-----------------SAVE:42 epoch----------------\n",
      "epoch : 42/100    time : 12s/667s\n",
      "TRAIN    loss : 0.03789    f1 : 0.98866\n",
      "Val    loss : 0.18269    f1 : 0.95175\n",
      "-----------------SAVE:43 epoch----------------\n",
      "epoch : 43/100    time : 11s/651s\n",
      "TRAIN    loss : 0.18931    f1 : 0.94718\n",
      "Val    loss : 0.21808    f1 : 0.95995\n",
      "-----------------SAVE:44 epoch----------------\n",
      "epoch : 44/100    time : 11s/635s\n",
      "TRAIN    loss : 0.07355    f1 : 0.97834\n",
      "Val    loss : 0.15453    f1 : 0.96360\n",
      "-----------------SAVE:45 epoch----------------\n",
      "epoch : 45/100    time : 11s/626s\n",
      "TRAIN    loss : 0.05264    f1 : 0.98711\n",
      "Val    loss : 0.11287    f1 : 0.97565\n",
      "epoch : 46/100    time : 9s/500s\n",
      "TRAIN    loss : 0.01124    f1 : 0.99544\n",
      "Val    loss : 0.41837    f1 : 0.95091\n",
      "epoch : 47/100    time : 9s/477s\n",
      "TRAIN    loss : 0.00320    f1 : 0.99857\n",
      "Val    loss : 0.30677    f1 : 0.95045\n",
      "epoch : 48/100    time : 9s/468s\n",
      "TRAIN    loss : 0.04482    f1 : 0.98668\n",
      "Val    loss : 0.37200    f1 : 0.91266\n",
      "epoch : 49/100    time : 9s/464s\n",
      "TRAIN    loss : 0.23664    f1 : 0.95632\n",
      "Val    loss : 0.45265    f1 : 0.91743\n",
      "epoch : 50/100    time : 9s/457s\n",
      "TRAIN    loss : 0.18128    f1 : 0.95492\n",
      "Val    loss : 0.19624    f1 : 0.94001\n",
      "epoch : 51/100    time : 9s/444s\n",
      "TRAIN    loss : 0.08197    f1 : 0.98436\n",
      "Val    loss : 0.21624    f1 : 0.92995\n",
      "epoch : 52/100    time : 9s/435s\n",
      "TRAIN    loss : 0.04055    f1 : 0.99144\n",
      "Val    loss : 0.16759    f1 : 0.95204\n",
      "epoch : 53/100    time : 9s/428s\n",
      "TRAIN    loss : 0.09242    f1 : 0.97431\n",
      "Val    loss : 0.55710    f1 : 0.85835\n",
      "epoch : 54/100    time : 9s/415s\n",
      "TRAIN    loss : 0.14895    f1 : 0.96656\n",
      "Val    loss : 0.24141    f1 : 0.92759\n",
      "epoch : 55/100    time : 9s/403s\n",
      "TRAIN    loss : 0.05883    f1 : 0.98439\n",
      "Val    loss : 0.14431    f1 : 0.95696\n",
      "epoch : 56/100    time : 9s/397s\n",
      "TRAIN    loss : 0.01272    f1 : 0.99427\n",
      "Val    loss : 0.15763    f1 : 0.96996\n",
      "epoch : 57/100    time : 9s/391s\n",
      "TRAIN    loss : 0.00347    f1 : 0.99858\n",
      "Val    loss : 0.16667    f1 : 0.96291\n",
      "epoch : 58/100    time : 9s/384s\n",
      "TRAIN    loss : 0.03900    f1 : 0.99143\n",
      "Val    loss : 0.39566    f1 : 0.90930\n",
      "epoch : 59/100    time : 9s/371s\n",
      "TRAIN    loss : 0.11629    f1 : 0.96166\n",
      "Val    loss : 0.15027    f1 : 0.95191\n",
      "epoch : 60/100    time : 9s/364s\n",
      "TRAIN    loss : 0.02650    f1 : 0.99293\n",
      "Val    loss : 0.24733    f1 : 0.94573\n",
      "epoch : 61/100    time : 9s/350s\n",
      "TRAIN    loss : 0.22252    f1 : 0.93777\n",
      "Val    loss : 1.02328    f1 : 0.92728\n",
      "epoch : 62/100    time : 9s/343s\n",
      "TRAIN    loss : 0.19712    f1 : 0.95191\n",
      "Val    loss : 0.40107    f1 : 0.86884\n",
      "epoch : 63/100    time : 9s/333s\n",
      "TRAIN    loss : 0.11421    f1 : 0.96589\n",
      "Val    loss : 0.38045    f1 : 0.90692\n",
      "epoch : 64/100    time : 9s/324s\n",
      "TRAIN    loss : 0.06208    f1 : 0.98262\n",
      "Val    loss : 0.33638    f1 : 0.94427\n",
      "epoch : 65/100    time : 9s/315s\n",
      "TRAIN    loss : 0.00593    f1 : 0.99857\n",
      "Val    loss : 0.19874    f1 : 0.94398\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022, shuffle = True)\n",
    "batch_size = 8\n",
    "epochs = 100\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "  print(\"----------fold_{} start!----------\".format(idx))\n",
    "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "  # Train\n",
    "  train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Val\n",
    "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  best=0\n",
    "\n",
    "  model = Network().to(device)\n",
    "\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay = 1e-3)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "  best_f1 = 0\n",
    "  early_stopping = 0\n",
    "  for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss = 0 \n",
    "      val_pred = []\n",
    "      val_y = []\n",
    "      \n",
    "\n",
    "      for batch in (val_loader):\n",
    "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_val = model(x_val)\n",
    "        loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "        val_loss += loss_val.item()/len(val_loader)\n",
    "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "        val_y += y_val.detach().cpu().numpy().tolist()\n",
    "      val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "      if val_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_loss = val_loss\n",
    "        best_f1 = val_f1\n",
    "        early_stopping = 0\n",
    "\n",
    "        torch.save({'epoch':epoch,\n",
    "                    'state_dict':state_dict,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "             }, path +'best_model_{}.pth'.format(idx))\n",
    "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "      else:\n",
    "          early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "      if early_stopping == 20:\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "Jl2OKpQiO5S1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl2OKpQiO5S1",
    "outputId": "e48def07-ef6d-4325-f297-c705088b3eb8"
   },
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 8\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load((path+'best_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "GjsHs-T3SPJq",
   "metadata": {
    "id": "GjsHs-T3SPJq"
   },
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1])+ np.array(pred_ensemble[3]) + np.array(pred_ensemble[4]) )/4\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "UIglTwAV7L54",
   "metadata": {
    "id": "UIglTwAV7L54"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "292QDIS5DOKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "292QDIS5DOKf",
    "outputId": "0e47d38f-d36a-40cd-a925-90e6bce52652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name label\n",
       "0     001.png     1\n",
       "1     002.png     2\n",
       "2     003.png     1\n",
       "3     004.png     6\n",
       "4     005.png     8\n",
       "..        ...   ...\n",
       "210   211.png     5\n",
       "211   212.png     8\n",
       "212   213.png     3\n",
       "213   214.png     6\n",
       "214   215.png     1\n",
       "\n",
       "[215 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"sample_submission.csv\")\n",
    "submission[\"label\"] = f_result\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1naZSLGZ7L55",
   "metadata": {
    "id": "1naZSLGZ7L55"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"submit.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fitted-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"
     ]
    }
   ],
   "source": [
    "# d9249@kyonggi.ac.kr\n",
    "\n",
    "from dacon_submit_api import dacon_submit_api \n",
    "\n",
    "result = dacon_submit_api.post_submission_file(\n",
    "'C:/Users/ideal/Downloads/jupyter/user_data/submit.csv', \n",
    "'02438df9bd0f6300dae6ddea845e7e01d2cb1881849c166bfce504164e1507d5', \n",
    "'235896', \n",
    "'iDeal', \n",
    "'test' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca15b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fedc192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae26638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[BASELINE]_EfficientNet_b3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
