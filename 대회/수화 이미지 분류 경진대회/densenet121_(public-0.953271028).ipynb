{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LlcNsGEk7L5r",
   "metadata": {
    "id": "LlcNsGEk7L5r"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81532144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3',\n",
      " 'bat_resnext26ts',\n",
      " 'beit_base_patch16_224',\n",
      " 'beit_base_patch16_224_in22k',\n",
      " 'beit_base_patch16_384',\n",
      " 'beit_large_patch16_224',\n",
      " 'beit_large_patch16_224_in22k',\n",
      " 'beit_large_patch16_384',\n",
      " 'beit_large_patch16_512',\n",
      " 'botnet26t_256',\n",
      " 'cait_m36_384',\n",
      " 'cait_m48_448',\n",
      " 'cait_s24_224',\n",
      " 'cait_s24_384',\n",
      " 'cait_s36_384',\n",
      " 'cait_xs24_384',\n",
      " 'cait_xxs24_224',\n",
      " 'cait_xxs24_384',\n",
      " 'cait_xxs36_224',\n",
      " 'cait_xxs36_384',\n",
      " 'coat_lite_mini',\n",
      " 'coat_lite_small',\n",
      " 'coat_lite_tiny',\n",
      " 'coat_mini',\n",
      " 'coat_tiny',\n",
      " 'convit_base',\n",
      " 'convit_small',\n",
      " 'convit_tiny',\n",
      " 'convmixer_768_32',\n",
      " 'convmixer_1024_20_ks9_p14',\n",
      " 'convmixer_1536_20',\n",
      " 'convnext_base',\n",
      " 'convnext_base_384_in22ft1k',\n",
      " 'convnext_base_in22ft1k',\n",
      " 'convnext_base_in22k',\n",
      " 'convnext_large',\n",
      " 'convnext_large_384_in22ft1k',\n",
      " 'convnext_large_in22ft1k',\n",
      " 'convnext_large_in22k',\n",
      " 'convnext_small',\n",
      " 'convnext_tiny',\n",
      " 'convnext_xlarge_384_in22ft1k',\n",
      " 'convnext_xlarge_in22ft1k',\n",
      " 'convnext_xlarge_in22k',\n",
      " 'crossvit_9_240',\n",
      " 'crossvit_9_dagger_240',\n",
      " 'crossvit_15_240',\n",
      " 'crossvit_15_dagger_240',\n",
      " 'crossvit_15_dagger_408',\n",
      " 'crossvit_18_240',\n",
      " 'crossvit_18_dagger_240',\n",
      " 'crossvit_18_dagger_408',\n",
      " 'crossvit_base_240',\n",
      " 'crossvit_small_240',\n",
      " 'crossvit_tiny_240',\n",
      " 'cspdarknet53',\n",
      " 'cspresnet50',\n",
      " 'cspresnext50',\n",
      " 'deit_base_distilled_patch16_224',\n",
      " 'deit_base_distilled_patch16_384',\n",
      " 'deit_base_patch16_224',\n",
      " 'deit_base_patch16_384',\n",
      " 'deit_small_distilled_patch16_224',\n",
      " 'deit_small_patch16_224',\n",
      " 'deit_tiny_distilled_patch16_224',\n",
      " 'deit_tiny_patch16_224',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dm_nfnet_f0',\n",
      " 'dm_nfnet_f1',\n",
      " 'dm_nfnet_f2',\n",
      " 'dm_nfnet_f3',\n",
      " 'dm_nfnet_f4',\n",
      " 'dm_nfnet_f5',\n",
      " 'dm_nfnet_f6',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'eca_botnext26ts_256',\n",
      " 'eca_halonext26ts',\n",
      " 'eca_nfnet_l0',\n",
      " 'eca_nfnet_l1',\n",
      " 'eca_nfnet_l2',\n",
      " 'eca_resnet33ts',\n",
      " 'eca_resnext26ts',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b4',\n",
      " 'efficientnet_el',\n",
      " 'efficientnet_el_pruned',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_es_pruned',\n",
      " 'efficientnet_lite0',\n",
      " 'efficientnetv2_rw_m',\n",
      " 'efficientnetv2_rw_s',\n",
      " 'efficientnetv2_rw_t',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'fbnetc_100',\n",
      " 'fbnetv3_b',\n",
      " 'fbnetv3_d',\n",
      " 'fbnetv3_g',\n",
      " 'gc_efficientnetv2_rw_t',\n",
      " 'gcresnet33ts',\n",
      " 'gcresnet50t',\n",
      " 'gcresnext26ts',\n",
      " 'gcresnext50ts',\n",
      " 'gernet_l',\n",
      " 'gernet_m',\n",
      " 'gernet_s',\n",
      " 'ghostnet_100',\n",
      " 'gluon_inception_v3',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_senet154',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'gluon_xception65',\n",
      " 'gmixer_24_224',\n",
      " 'gmlp_s16_224',\n",
      " 'halo2botnet50ts_256',\n",
      " 'halonet26t',\n",
      " 'halonet50ts',\n",
      " 'haloregnetz_b',\n",
      " 'hardcorenas_a',\n",
      " 'hardcorenas_b',\n",
      " 'hardcorenas_c',\n",
      " 'hardcorenas_d',\n",
      " 'hardcorenas_e',\n",
      " 'hardcorenas_f',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w64',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'jx_nest_base',\n",
      " 'jx_nest_small',\n",
      " 'jx_nest_tiny',\n",
      " 'lambda_resnet26rpt_256',\n",
      " 'lambda_resnet26t',\n",
      " 'lambda_resnet50ts',\n",
      " 'lamhalobotnet50ts_256',\n",
      " 'lcnet_050',\n",
      " 'lcnet_075',\n",
      " 'lcnet_100',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'levit_128',\n",
      " 'levit_128s',\n",
      " 'levit_192',\n",
      " 'levit_256',\n",
      " 'levit_384',\n",
      " 'mixer_b16_224',\n",
      " 'mixer_b16_224_in21k',\n",
      " 'mixer_b16_224_miil',\n",
      " 'mixer_b16_224_miil_in21k',\n",
      " 'mixer_l16_224',\n",
      " 'mixer_l16_224_in21k',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mnasnet_100',\n",
      " 'mnasnet_small',\n",
      " 'mobilenetv2_050',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_large_100_miil',\n",
      " 'mobilenetv3_large_100_miil_in21k',\n",
      " 'mobilenetv3_rw',\n",
      " 'nasnetalarge',\n",
      " 'nf_regnet_b1',\n",
      " 'nf_resnet50',\n",
      " 'nfnet_l0',\n",
      " 'pit_b_224',\n",
      " 'pit_b_distilled_224',\n",
      " 'pit_s_224',\n",
      " 'pit_s_distilled_224',\n",
      " 'pit_ti_224',\n",
      " 'pit_ti_distilled_224',\n",
      " 'pit_xs_224',\n",
      " 'pit_xs_distilled_224',\n",
      " 'pnasnet5large',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'regnetz_b16',\n",
      " 'regnetz_c16',\n",
      " 'regnetz_d8',\n",
      " 'regnetz_d32',\n",
      " 'regnetz_e8',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2next50',\n",
      " 'resmlp_12_224',\n",
      " 'resmlp_12_224_dino',\n",
      " 'resmlp_12_distilled_224',\n",
      " 'resmlp_24_224',\n",
      " 'resmlp_24_224_dino',\n",
      " 'resmlp_24_distilled_224',\n",
      " 'resmlp_36_224',\n",
      " 'resmlp_36_distilled_224',\n",
      " 'resmlp_big_24_224',\n",
      " 'resmlp_big_24_224_in22ft1k',\n",
      " 'resmlp_big_24_distilled_224',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet26t',\n",
      " 'resnet32ts',\n",
      " 'resnet33ts',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50_gn',\n",
      " 'resnet50d',\n",
      " 'resnet51q',\n",
      " 'resnet61q',\n",
      " 'resnet101',\n",
      " 'resnet101d',\n",
      " 'resnet152',\n",
      " 'resnet152d',\n",
      " 'resnet200d',\n",
      " 'resnetblur50',\n",
      " 'resnetrs50',\n",
      " 'resnetrs101',\n",
      " 'resnetrs152',\n",
      " 'resnetrs200',\n",
      " 'resnetrs270',\n",
      " 'resnetrs350',\n",
      " 'resnetrs420',\n",
      " 'resnetv2_50',\n",
      " 'resnetv2_50x1_bit_distilled',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bit_teacher',\n",
      " 'resnetv2_152x2_bit_teacher_384',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext26ts',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'sebotnet33ts_256',\n",
      " 'sehalonet33ts',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'semnasnet_075',\n",
      " 'semnasnet_100',\n",
      " 'seresnet33ts',\n",
      " 'seresnet50',\n",
      " 'seresnet152d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext26ts',\n",
      " 'seresnext50_32x4d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swin_base_patch4_window7_224',\n",
      " 'swin_base_patch4_window7_224_in22k',\n",
      " 'swin_base_patch4_window12_384',\n",
      " 'swin_base_patch4_window12_384_in22k',\n",
      " 'swin_large_patch4_window7_224',\n",
      " 'swin_large_patch4_window7_224_in22k',\n",
      " 'swin_large_patch4_window12_384',\n",
      " 'swin_large_patch4_window12_384_in22k',\n",
      " 'swin_small_patch4_window7_224',\n",
      " 'swin_tiny_patch4_window7_224',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b0_ap',\n",
      " 'tf_efficientnet_b0_ns',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b1_ap',\n",
      " 'tf_efficientnet_b1_ns',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b2_ap',\n",
      " 'tf_efficientnet_b2_ns',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b3_ap',\n",
      " 'tf_efficientnet_b3_ns',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b4_ap',\n",
      " 'tf_efficientnet_b4_ns',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b5_ap',\n",
      " 'tf_efficientnet_b5_ns',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b6_ap',\n",
      " 'tf_efficientnet_b6_ns',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b7_ap',\n",
      " 'tf_efficientnet_b7_ns',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_b8_ap',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2_ns',\n",
      " 'tf_efficientnet_l2_ns_475',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_efficientnetv2_b0',\n",
      " 'tf_efficientnetv2_b1',\n",
      " 'tf_efficientnetv2_b2',\n",
      " 'tf_efficientnetv2_b3',\n",
      " 'tf_efficientnetv2_l',\n",
      " 'tf_efficientnetv2_l_in21ft1k',\n",
      " 'tf_efficientnetv2_l_in21k',\n",
      " 'tf_efficientnetv2_m',\n",
      " 'tf_efficientnetv2_m_in21ft1k',\n",
      " 'tf_efficientnetv2_m_in21k',\n",
      " 'tf_efficientnetv2_s',\n",
      " 'tf_efficientnetv2_s_in21ft1k',\n",
      " 'tf_efficientnetv2_s_in21k',\n",
      " 'tf_efficientnetv2_xl_in21ft1k',\n",
      " 'tf_efficientnetv2_xl_in21k',\n",
      " 'tf_inception_v3',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tinynet_a',\n",
      " 'tinynet_b',\n",
      " 'tinynet_c',\n",
      " 'tinynet_d',\n",
      " 'tinynet_e',\n",
      " 'tnt_s_patch16_224',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_m_miil_in21k',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_densenet121',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'twins_pcpvt_base',\n",
      " 'twins_pcpvt_large',\n",
      " 'twins_pcpvt_small',\n",
      " 'twins_svt_base',\n",
      " 'twins_svt_large',\n",
      " 'twins_svt_small',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'visformer_small',\n",
      " 'vit_base_patch8_224',\n",
      " 'vit_base_patch8_224_in21k',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_224_in21k',\n",
      " 'vit_base_patch16_224_miil',\n",
      " 'vit_base_patch16_224_miil_in21k',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch16_sam_224',\n",
      " 'vit_base_patch32_224',\n",
      " 'vit_base_patch32_224_in21k',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_patch32_sam_224',\n",
      " 'vit_base_r50_s16_224_in21k',\n",
      " 'vit_base_r50_s16_384',\n",
      " 'vit_huge_patch14_224_in21k',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_224_in21k',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch32_224_in21k',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_large_r50_s32_224',\n",
      " 'vit_large_r50_s32_224_in21k',\n",
      " 'vit_large_r50_s32_384',\n",
      " 'vit_small_patch16_224',\n",
      " 'vit_small_patch16_224_in21k',\n",
      " 'vit_small_patch16_384',\n",
      " 'vit_small_patch32_224',\n",
      " 'vit_small_patch32_224_in21k',\n",
      " 'vit_small_patch32_384',\n",
      " 'vit_small_r26_s32_224',\n",
      " 'vit_small_r26_s32_224_in21k',\n",
      " 'vit_small_r26_s32_384',\n",
      " 'vit_tiny_patch16_224',\n",
      " 'vit_tiny_patch16_224_in21k',\n",
      " 'vit_tiny_patch16_384',\n",
      " 'vit_tiny_r_s16_p8_224',\n",
      " 'vit_tiny_r_s16_p8_224_in21k',\n",
      " 'vit_tiny_r_s16_p8_384',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception',\n",
      " 'xception41',\n",
      " 'xception65',\n",
      " 'xception71',\n",
      " 'xcit_large_24_p8_224',\n",
      " 'xcit_large_24_p8_224_dist',\n",
      " 'xcit_large_24_p8_384_dist',\n",
      " 'xcit_large_24_p16_224',\n",
      " 'xcit_large_24_p16_224_dist',\n",
      " 'xcit_large_24_p16_384_dist',\n",
      " 'xcit_medium_24_p8_224',\n",
      " 'xcit_medium_24_p8_224_dist',\n",
      " 'xcit_medium_24_p8_384_dist',\n",
      " 'xcit_medium_24_p16_224',\n",
      " 'xcit_medium_24_p16_224_dist',\n",
      " 'xcit_medium_24_p16_384_dist',\n",
      " 'xcit_nano_12_p8_224',\n",
      " 'xcit_nano_12_p8_224_dist',\n",
      " 'xcit_nano_12_p8_384_dist',\n",
      " 'xcit_nano_12_p16_224',\n",
      " 'xcit_nano_12_p16_224_dist',\n",
      " 'xcit_nano_12_p16_384_dist',\n",
      " 'xcit_small_12_p8_224',\n",
      " 'xcit_small_12_p8_224_dist',\n",
      " 'xcit_small_12_p8_384_dist',\n",
      " 'xcit_small_12_p16_224',\n",
      " 'xcit_small_12_p16_224_dist',\n",
      " 'xcit_small_12_p16_384_dist',\n",
      " 'xcit_small_24_p8_224',\n",
      " 'xcit_small_24_p8_224_dist',\n",
      " 'xcit_small_24_p8_384_dist',\n",
      " 'xcit_small_24_p16_224',\n",
      " 'xcit_small_24_p16_224_dist',\n",
      " 'xcit_small_24_p16_384_dist',\n",
      " 'xcit_tiny_12_p8_224',\n",
      " 'xcit_tiny_12_p8_224_dist',\n",
      " 'xcit_tiny_12_p8_384_dist',\n",
      " 'xcit_tiny_12_p16_224',\n",
      " 'xcit_tiny_12_p16_224_dist',\n",
      " 'xcit_tiny_12_p16_384_dist',\n",
      " 'xcit_tiny_24_p8_224',\n",
      " 'xcit_tiny_24_p8_224_dist',\n",
      " 'xcit_tiny_24_p8_384_dist',\n",
      " 'xcit_tiny_24_p16_224',\n",
      " 'xcit_tiny_24_p16_224_dist',\n",
      " 'xcit_tiny_24_p16_384_dist']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lXH5F_hA7uMl",
   "metadata": {
    "id": "lXH5F_hA7uMl"
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/ideal/Downloads/jupyter/user_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "FWntO1VD7L5u",
   "metadata": {
    "id": "FWntO1VD7L5u"
   },
   "outputs": [],
   "source": [
    "train_png = sorted(glob(path + 'train/*.png'))\n",
    "test_png = sorted(glob(path + 'test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atSgPJRn-OCW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atSgPJRn-OCW",
    "outputId": "87b6f90b-5c1c-4a0e-de54-994458543687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(858, 215)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_png), len(test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "xv0_rDVq7L5v",
   "metadata": {
    "id": "xv0_rDVq7L5v"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(path +\"train.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "iMhC0nPw7L5w",
   "metadata": {
    "id": "iMhC0nPw7L5w"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "#     img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "zsmJA3E97L5x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsmJA3E97L5x",
    "outputId": "e0dc61fe-5617-42e8-c8b0-0e95b9f60656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 858/858 [00:00<00:00, 1034.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 215/215 [00:00<00:00, 934.95it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "KA73Lku9A2N9",
   "metadata": {
    "id": "KA73Lku9A2N9"
   },
   "outputs": [],
   "source": [
    "np.save(path + 'train_imgs_384', np.array(train_imgs))\n",
    "np.save(path + 'test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "L6qBdX7nCp8L",
   "metadata": {
    "id": "L6qBdX7nCp8L"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.load(path + 'train_imgs_384.npy')\n",
    "test_imgs = np.load(path + 'test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "VFXzojoo7L5y",
   "metadata": {
    "id": "VFXzojoo7L5y"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "                                     std = [0.181572, 0.174035, 0.163234]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
    "                                     std = [0.195055, 0.190053, 0.185323])\n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('densenet121', pretrained=True)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('densenet121', pretrained=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38qk8sGbYiO_",
   "metadata": {
    "id": "38qk8sGbYiO_"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lkNCkyG9RPzX",
   "metadata": {
    "id": "lkNCkyG9RPzX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 31s/3077s\n",
      "TRAIN    loss : 4.35489    f1 : 0.01822\n",
      "Val    loss : 1.65452    f1 : 0.60067\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 29s/2854s\n",
      "TRAIN    loss : 1.12157    f1 : 0.68459\n",
      "Val    loss : 0.76054    f1 : 0.79702\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 30s/2902s\n",
      "TRAIN    loss : 0.68063    f1 : 0.79297\n",
      "Val    loss : 0.48298    f1 : 0.84864\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 29s/2819s\n",
      "TRAIN    loss : 0.48256    f1 : 0.87138\n",
      "Val    loss : 0.30362    f1 : 0.90505\n",
      "epoch : 5/100    time : 30s/2807s\n",
      "TRAIN    loss : 0.33780    f1 : 0.90997\n",
      "Val    loss : 0.33350    f1 : 0.88822\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 29s/2706s\n",
      "TRAIN    loss : 0.30725    f1 : 0.90521\n",
      "Val    loss : 0.22649    f1 : 0.92196\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 29s/2700s\n",
      "TRAIN    loss : 0.24310    f1 : 0.93947\n",
      "Val    loss : 0.19647    f1 : 0.93975\n",
      "epoch : 8/100    time : 29s/2704s\n",
      "TRAIN    loss : 0.20489    f1 : 0.95919\n",
      "Val    loss : 0.21871    f1 : 0.91841\n",
      "epoch : 9/100    time : 30s/2712s\n",
      "TRAIN    loss : 0.13880    f1 : 0.97559\n",
      "Val    loss : 0.24069    f1 : 0.90309\n",
      "epoch : 10/100    time : 30s/2680s\n",
      "TRAIN    loss : 0.18042    f1 : 0.94942\n",
      "Val    loss : 0.23778    f1 : 0.92089\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 30s/2627s\n",
      "TRAIN    loss : 0.15452    f1 : 0.95234\n",
      "Val    loss : 0.16506    f1 : 0.94561\n",
      "epoch : 12/100    time : 29s/2516s\n",
      "TRAIN    loss : 0.13358    f1 : 0.96426\n",
      "Val    loss : 0.18850    f1 : 0.94038\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/100    time : 30s/2590s\n",
      "TRAIN    loss : 0.10721    f1 : 0.97453\n",
      "Val    loss : 0.14214    f1 : 0.94588\n",
      "epoch : 14/100    time : 30s/2547s\n",
      "TRAIN    loss : 0.10582    f1 : 0.97160\n",
      "Val    loss : 0.15814    f1 : 0.93337\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/100    time : 30s/2551s\n",
      "TRAIN    loss : 0.08425    f1 : 0.97171\n",
      "Val    loss : 0.12876    f1 : 0.96559\n",
      "epoch : 16/100    time : 30s/2486s\n",
      "TRAIN    loss : 0.06932    f1 : 0.98427\n",
      "Val    loss : 0.14576    f1 : 0.95411\n",
      "epoch : 17/100    time : 29s/2438s\n",
      "TRAIN    loss : 0.06496    f1 : 0.98584\n",
      "Val    loss : 0.12136    f1 : 0.95378\n",
      "epoch : 18/100    time : 30s/2434s\n",
      "TRAIN    loss : 0.05603    f1 : 0.99019\n",
      "Val    loss : 0.15854    f1 : 0.94634\n",
      "epoch : 19/100    time : 29s/2374s\n",
      "TRAIN    loss : 0.05494    f1 : 0.98582\n",
      "Val    loss : 0.14364    f1 : 0.95366\n",
      "epoch : 20/100    time : 29s/2342s\n",
      "TRAIN    loss : 0.06348    f1 : 0.99149\n",
      "Val    loss : 0.14299    f1 : 0.94776\n",
      "epoch : 21/100    time : 30s/2362s\n",
      "TRAIN    loss : 0.04785    f1 : 0.99289\n",
      "Val    loss : 0.11926    f1 : 0.95681\n",
      "epoch : 22/100    time : 29s/2273s\n",
      "TRAIN    loss : 0.08014    f1 : 0.97857\n",
      "Val    loss : 0.15315    f1 : 0.95368\n",
      "epoch : 23/100    time : 29s/2270s\n",
      "TRAIN    loss : 0.06754    f1 : 0.97991\n",
      "Val    loss : 0.12873    f1 : 0.95316\n",
      "epoch : 24/100    time : 29s/2208s\n",
      "TRAIN    loss : 0.03412    f1 : 0.99434\n",
      "Val    loss : 0.12550    f1 : 0.94712\n",
      "epoch : 25/100    time : 29s/2209s\n",
      "TRAIN    loss : 0.04315    f1 : 0.98871\n",
      "Val    loss : 0.12534    f1 : 0.95341\n",
      "epoch : 26/100    time : 29s/2116s\n",
      "TRAIN    loss : 0.06320    f1 : 0.98580\n",
      "Val    loss : 0.11920    f1 : 0.96498\n",
      "epoch : 27/100    time : 29s/2096s\n",
      "TRAIN    loss : 0.02723    f1 : 0.99576\n",
      "Val    loss : 0.12487    f1 : 0.95859\n",
      "epoch : 28/100    time : 29s/2082s\n",
      "TRAIN    loss : 0.04556    f1 : 0.98699\n",
      "Val    loss : 0.11724    f1 : 0.95211\n",
      "-----------------SAVE:29 epoch----------------\n",
      "epoch : 29/100    time : 30s/2110s\n",
      "TRAIN    loss : 0.04947    f1 : 0.98663\n",
      "Val    loss : 0.13528    f1 : 0.97013\n",
      "epoch : 30/100    time : 29s/2052s\n",
      "TRAIN    loss : 0.06035    f1 : 0.98437\n",
      "Val    loss : 0.15947    f1 : 0.95267\n",
      "epoch : 31/100    time : 30s/2051s\n",
      "TRAIN    loss : 0.04558    f1 : 0.98970\n",
      "Val    loss : 0.13185    f1 : 0.95867\n",
      "epoch : 32/100    time : 29s/1955s\n",
      "TRAIN    loss : 0.06177    f1 : 0.98591\n",
      "Val    loss : 0.12862    f1 : 0.96465\n",
      "epoch : 33/100    time : 29s/1953s\n",
      "TRAIN    loss : 0.02935    f1 : 0.99718\n",
      "Val    loss : 0.12893    f1 : 0.94751\n",
      "epoch : 34/100    time : 29s/1944s\n",
      "TRAIN    loss : 0.03338    f1 : 0.98835\n",
      "Val    loss : 0.15914    f1 : 0.95209\n",
      "epoch : 35/100    time : 29s/1896s\n",
      "TRAIN    loss : 0.03312    f1 : 0.98948\n",
      "Val    loss : 0.12046    f1 : 0.94971\n",
      "epoch : 36/100    time : 29s/1854s\n",
      "TRAIN    loss : 0.04824    f1 : 0.98588\n",
      "Val    loss : 0.12009    f1 : 0.94979\n",
      "-----------------SAVE:37 epoch----------------\n",
      "epoch : 37/100    time : 29s/1844s\n",
      "TRAIN    loss : 0.04390    f1 : 0.99009\n",
      "Val    loss : 0.07503    f1 : 0.97532\n",
      "-----------------SAVE:38 epoch----------------\n",
      "epoch : 38/100    time : 30s/1829s\n",
      "TRAIN    loss : 0.03711    f1 : 0.98725\n",
      "Val    loss : 0.09008    f1 : 0.97701\n",
      "-----------------SAVE:39 epoch----------------\n",
      "epoch : 39/100    time : 29s/1777s\n",
      "TRAIN    loss : 0.03334    f1 : 0.99013\n",
      "Val    loss : 0.06761    f1 : 0.97706\n",
      "epoch : 40/100    time : 29s/1748s\n",
      "TRAIN    loss : 0.02406    f1 : 0.99436\n",
      "Val    loss : 0.09904    f1 : 0.96382\n",
      "epoch : 41/100    time : 29s/1702s\n",
      "TRAIN    loss : 0.02337    f1 : 0.99423\n",
      "Val    loss : 0.21696    f1 : 0.94915\n",
      "epoch : 42/100    time : 29s/1675s\n",
      "TRAIN    loss : 0.02770    f1 : 0.99290\n",
      "Val    loss : 0.13527    f1 : 0.95752\n",
      "epoch : 43/100    time : 29s/1641s\n",
      "TRAIN    loss : 0.01775    f1 : 0.99717\n",
      "Val    loss : 0.12986    f1 : 0.96500\n",
      "epoch : 44/100    time : 29s/1626s\n",
      "TRAIN    loss : 0.04919    f1 : 0.98854\n",
      "Val    loss : 0.14887    f1 : 0.94188\n",
      "epoch : 45/100    time : 29s/1598s\n",
      "TRAIN    loss : 0.05165    f1 : 0.98995\n",
      "Val    loss : 0.15295    f1 : 0.95890\n",
      "epoch : 46/100    time : 29s/1578s\n",
      "TRAIN    loss : 0.01383    f1 : 1.00000\n",
      "Val    loss : 0.09789    f1 : 0.96390\n",
      "epoch : 47/100    time : 29s/1530s\n",
      "TRAIN    loss : 0.03757    f1 : 0.98720\n",
      "Val    loss : 0.16056    f1 : 0.94474\n",
      "epoch : 48/100    time : 29s/1524s\n",
      "TRAIN    loss : 0.03813    f1 : 0.98865\n",
      "Val    loss : 0.23026    f1 : 0.95277\n",
      "epoch : 49/100    time : 29s/1486s\n",
      "TRAIN    loss : 0.01912    f1 : 0.99572\n",
      "Val    loss : 0.19022    f1 : 0.96030\n",
      "epoch : 50/100    time : 30s/1492s\n",
      "TRAIN    loss : 0.00898    f1 : 1.00000\n",
      "Val    loss : 0.13447    f1 : 0.93888\n",
      "epoch : 51/100    time : 29s/1431s\n",
      "TRAIN    loss : 0.03533    f1 : 0.98878\n",
      "Val    loss : 0.15479    f1 : 0.96477\n",
      "epoch : 52/100    time : 29s/1386s\n",
      "TRAIN    loss : 0.04193    f1 : 0.99123\n",
      "Val    loss : 0.19942    f1 : 0.94772\n",
      "epoch : 53/100    time : 29s/1368s\n",
      "TRAIN    loss : 0.01631    f1 : 0.99856\n",
      "Val    loss : 0.11802    f1 : 0.95746\n",
      "epoch : 54/100    time : 29s/1347s\n",
      "TRAIN    loss : 0.03239    f1 : 0.99011\n",
      "Val    loss : 0.17923    f1 : 0.94724\n",
      "epoch : 55/100    time : 30s/1338s\n",
      "TRAIN    loss : 0.04277    f1 : 0.98726\n",
      "Val    loss : 0.22859    f1 : 0.92857\n",
      "epoch : 56/100    time : 29s/1286s\n",
      "TRAIN    loss : 0.05059    f1 : 0.98733\n",
      "Val    loss : 0.15217    f1 : 0.95096\n",
      "epoch : 57/100    time : 29s/1234s\n",
      "TRAIN    loss : 0.07293    f1 : 0.97629\n",
      "Val    loss : 0.14558    f1 : 0.95398\n",
      "epoch : 58/100    time : 29s/1207s\n",
      "TRAIN    loss : 0.01937    f1 : 0.99713\n",
      "Val    loss : 0.08730    f1 : 0.96501\n",
      "epoch : 59/100    time : 30s/1225s\n",
      "TRAIN    loss : 0.03287    f1 : 0.99018\n",
      "Val    loss : 0.08588    f1 : 0.97095\n",
      "----------fold_1 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 30s/2947s\n",
      "TRAIN    loss : 4.30967    f1 : 0.01691\n",
      "Val    loss : 1.73548    f1 : 0.51484\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 30s/2892s\n",
      "TRAIN    loss : 1.14281    f1 : 0.66612\n",
      "Val    loss : 0.79019    f1 : 0.79785\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 29s/2839s\n",
      "TRAIN    loss : 0.65605    f1 : 0.80449\n",
      "Val    loss : 0.58254    f1 : 0.81690\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 29s/2805s\n",
      "TRAIN    loss : 0.48572    f1 : 0.87142\n",
      "Val    loss : 0.34575    f1 : 0.90479\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 30s/2819s\n",
      "TRAIN    loss : 0.35428    f1 : 0.89323\n",
      "Val    loss : 0.29588    f1 : 0.93727\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 30s/2799s\n",
      "TRAIN    loss : 0.29251    f1 : 0.92689\n",
      "Val    loss : 0.17760    f1 : 0.95878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 7/100    time : 29s/2730s\n",
      "TRAIN    loss : 0.22213    f1 : 0.93939\n",
      "Val    loss : 0.17349    f1 : 0.94683\n",
      "epoch : 8/100    time : 29s/2651s\n",
      "TRAIN    loss : 0.16557    f1 : 0.96022\n",
      "Val    loss : 0.18058    f1 : 0.94063\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 29s/2643s\n",
      "TRAIN    loss : 0.18521    f1 : 0.95607\n",
      "Val    loss : 0.17114    f1 : 0.96555\n",
      "epoch : 10/100    time : 28s/2516s\n",
      "TRAIN    loss : 0.14681    f1 : 0.96002\n",
      "Val    loss : 0.14922    f1 : 0.94681\n",
      "epoch : 11/100    time : 29s/2570s\n",
      "TRAIN    loss : 0.15767    f1 : 0.95168\n",
      "Val    loss : 0.15878    f1 : 0.95384\n",
      "epoch : 12/100    time : 29s/2591s\n",
      "TRAIN    loss : 0.12535    f1 : 0.96354\n",
      "Val    loss : 0.12888    f1 : 0.96538\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/100    time : 29s/2548s\n",
      "TRAIN    loss : 0.12163    f1 : 0.97251\n",
      "Val    loss : 0.09764    f1 : 0.97658\n",
      "epoch : 14/100    time : 29s/2536s\n",
      "TRAIN    loss : 0.11303    f1 : 0.97149\n",
      "Val    loss : 0.14182    f1 : 0.95247\n",
      "epoch : 15/100    time : 29s/2493s\n",
      "TRAIN    loss : 0.12109    f1 : 0.97124\n",
      "Val    loss : 0.12974    f1 : 0.96539\n",
      "epoch : 16/100    time : 29s/2470s\n",
      "TRAIN    loss : 0.09415    f1 : 0.97587\n",
      "Val    loss : 0.13225    f1 : 0.96558\n",
      "epoch : 17/100    time : 29s/2413s\n",
      "TRAIN    loss : 0.07632    f1 : 0.98161\n",
      "Val    loss : 0.11837    f1 : 0.95933\n",
      "epoch : 18/100    time : 29s/2376s\n",
      "TRAIN    loss : 0.06675    f1 : 0.98441\n",
      "Val    loss : 0.18615    f1 : 0.95901\n",
      "epoch : 19/100    time : 29s/2384s\n",
      "TRAIN    loss : 0.07535    f1 : 0.97925\n",
      "Val    loss : 0.10393    f1 : 0.96530\n",
      "epoch : 20/100    time : 30s/2366s\n",
      "TRAIN    loss : 0.05674    f1 : 0.98839\n",
      "Val    loss : 0.12312    f1 : 0.95901\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/100    time : 29s/2308s\n",
      "TRAIN    loss : 0.07519    f1 : 0.98129\n",
      "Val    loss : 0.06301    f1 : 0.98842\n",
      "epoch : 22/100    time : 30s/2312s\n",
      "TRAIN    loss : 0.07769    f1 : 0.98012\n",
      "Val    loss : 0.11335    f1 : 0.97092\n",
      "epoch : 23/100    time : 29s/2267s\n",
      "TRAIN    loss : 0.04011    f1 : 0.99148\n",
      "Val    loss : 0.09156    f1 : 0.97688\n",
      "epoch : 24/100    time : 28s/2140s\n",
      "TRAIN    loss : 0.05766    f1 : 0.98497\n",
      "Val    loss : 0.09811    f1 : 0.96486\n",
      "epoch : 25/100    time : 29s/2193s\n",
      "TRAIN    loss : 0.05437    f1 : 0.98722\n",
      "Val    loss : 0.07404    f1 : 0.97120\n",
      "epoch : 26/100    time : 29s/2129s\n",
      "TRAIN    loss : 0.04290    f1 : 0.98725\n",
      "Val    loss : 0.07804    f1 : 0.97658\n",
      "epoch : 27/100    time : 30s/2154s\n",
      "TRAIN    loss : 0.03654    f1 : 0.99291\n",
      "Val    loss : 0.07658    f1 : 0.98247\n",
      "epoch : 28/100    time : 29s/2110s\n",
      "TRAIN    loss : 0.02758    f1 : 0.99571\n",
      "Val    loss : 0.08829    f1 : 0.97135\n",
      "epoch : 29/100    time : 29s/2058s\n",
      "TRAIN    loss : 0.03905    f1 : 0.99430\n",
      "Val    loss : 0.13918    f1 : 0.94698\n",
      "epoch : 30/100    time : 29s/2031s\n",
      "TRAIN    loss : 0.02975    f1 : 0.99372\n",
      "Val    loss : 0.10900    f1 : 0.97658\n",
      "epoch : 31/100    time : 29s/2016s\n",
      "TRAIN    loss : 0.01501    f1 : 1.00000\n",
      "Val    loss : 0.15003    f1 : 0.97065\n",
      "epoch : 32/100    time : 29s/1977s\n",
      "TRAIN    loss : 0.03569    f1 : 0.99122\n",
      "Val    loss : 0.11674    f1 : 0.95894\n",
      "epoch : 33/100    time : 29s/1956s\n",
      "TRAIN    loss : 0.05197    f1 : 0.99010\n",
      "Val    loss : 0.17287    f1 : 0.97078\n",
      "epoch : 34/100    time : 30s/1954s\n",
      "TRAIN    loss : 0.07265    f1 : 0.98098\n",
      "Val    loss : 0.13353    f1 : 0.95431\n",
      "epoch : 35/100    time : 29s/1916s\n",
      "TRAIN    loss : 0.05927    f1 : 0.98272\n",
      "Val    loss : 0.11077    f1 : 0.96523\n",
      "epoch : 36/100    time : 30s/1904s\n",
      "TRAIN    loss : 0.03690    f1 : 0.99157\n",
      "Val    loss : 0.10407    f1 : 0.97092\n",
      "epoch : 37/100    time : 29s/1830s\n",
      "TRAIN    loss : 0.04798    f1 : 0.98555\n",
      "Val    loss : 0.11195    f1 : 0.96500\n",
      "epoch : 38/100    time : 29s/1786s\n",
      "TRAIN    loss : 0.05201    f1 : 0.98559\n",
      "Val    loss : 0.12251    f1 : 0.96400\n",
      "epoch : 39/100    time : 29s/1767s\n",
      "TRAIN    loss : 0.03394    f1 : 0.99435\n",
      "Val    loss : 0.07776    f1 : 0.97582\n",
      "epoch : 40/100    time : 28s/1692s\n",
      "TRAIN    loss : 0.02801    f1 : 0.99718\n",
      "Val    loss : 0.17265    f1 : 0.94718\n",
      "epoch : 41/100    time : 29s/1736s\n",
      "TRAIN    loss : 0.04762    f1 : 0.99146\n",
      "Val    loss : 0.06327    f1 : 0.98256\n",
      "----------fold_2 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 29s/2901s\n",
      "TRAIN    loss : 4.25215    f1 : 0.01949\n",
      "Val    loss : 1.55629    f1 : 0.59798\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 29s/2850s\n",
      "TRAIN    loss : 1.14619    f1 : 0.66283\n",
      "Val    loss : 0.74802    f1 : 0.79411\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 28s/2764s\n",
      "TRAIN    loss : 0.72125    f1 : 0.77455\n",
      "Val    loss : 0.53001    f1 : 0.84619\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 28s/2685s\n",
      "TRAIN    loss : 0.48567    f1 : 0.86765\n",
      "Val    loss : 0.43751    f1 : 0.85432\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 29s/2749s\n",
      "TRAIN    loss : 0.37560    f1 : 0.89836\n",
      "Val    loss : 0.34567    f1 : 0.92086\n",
      "epoch : 6/100    time : 29s/2717s\n",
      "TRAIN    loss : 0.29503    f1 : 0.92126\n",
      "Val    loss : 0.31491    f1 : 0.90393\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 29s/2738s\n",
      "TRAIN    loss : 0.22447    f1 : 0.94506\n",
      "Val    loss : 0.26497    f1 : 0.93248\n",
      "epoch : 8/100    time : 30s/2743s\n",
      "TRAIN    loss : 0.23408    f1 : 0.93494\n",
      "Val    loss : 0.28041    f1 : 0.92634\n",
      "epoch : 9/100    time : 29s/2654s\n",
      "TRAIN    loss : 0.19564    f1 : 0.94204\n",
      "Val    loss : 0.25628    f1 : 0.91516\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/100    time : 30s/2687s\n",
      "TRAIN    loss : 0.14094    f1 : 0.96689\n",
      "Val    loss : 0.23691    f1 : 0.94348\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 29s/2609s\n",
      "TRAIN    loss : 0.14554    f1 : 0.95570\n",
      "Val    loss : 0.24441    f1 : 0.94378\n",
      "epoch : 12/100    time : 29s/2582s\n",
      "TRAIN    loss : 0.10626    f1 : 0.97691\n",
      "Val    loss : 0.21671    f1 : 0.94318\n",
      "epoch : 13/100    time : 29s/2556s\n",
      "TRAIN    loss : 0.10436    f1 : 0.97206\n",
      "Val    loss : 0.25374    f1 : 0.91383\n",
      "epoch : 14/100    time : 29s/2488s\n",
      "TRAIN    loss : 0.11235    f1 : 0.97178\n",
      "Val    loss : 0.21480    f1 : 0.93131\n",
      "epoch : 15/100    time : 29s/2474s\n",
      "TRAIN    loss : 0.08822    f1 : 0.97581\n",
      "Val    loss : 0.22804    f1 : 0.92547\n",
      "epoch : 16/100    time : 29s/2470s\n",
      "TRAIN    loss : 0.06461    f1 : 0.98697\n",
      "Val    loss : 0.20016    f1 : 0.93779\n",
      "-----------------SAVE:17 epoch----------------\n",
      "epoch : 17/100    time : 29s/2435s\n",
      "TRAIN    loss : 0.07536    f1 : 0.98442\n",
      "Val    loss : 0.16390    f1 : 0.96013\n",
      "epoch : 18/100    time : 29s/2366s\n",
      "TRAIN    loss : 0.06321    f1 : 0.99000\n",
      "Val    loss : 0.30594    f1 : 0.92192\n",
      "epoch : 19/100    time : 29s/2328s\n",
      "TRAIN    loss : 0.05404    f1 : 0.98860\n",
      "Val    loss : 0.21879    f1 : 0.94333\n",
      "epoch : 20/100    time : 29s/2322s\n",
      "TRAIN    loss : 0.07182    f1 : 0.98672\n",
      "Val    loss : 0.20476    f1 : 0.94924\n",
      "epoch : 21/100    time : 29s/2297s\n",
      "TRAIN    loss : 0.06589    f1 : 0.98288\n",
      "Val    loss : 0.18879    f1 : 0.94932\n",
      "-----------------SAVE:22 epoch----------------\n",
      "epoch : 22/100    time : 29s/2255s\n",
      "TRAIN    loss : 0.03184    f1 : 0.99436\n",
      "Val    loss : 0.13723    f1 : 0.96062\n",
      "epoch : 23/100    time : 28s/2189s\n",
      "TRAIN    loss : 0.04588    f1 : 0.98576\n",
      "Val    loss : 0.20272    f1 : 0.94309\n",
      "epoch : 24/100    time : 29s/2170s\n",
      "TRAIN    loss : 0.07797    f1 : 0.97701\n",
      "Val    loss : 0.24880    f1 : 0.91591\n",
      "epoch : 25/100    time : 29s/2205s\n",
      "TRAIN    loss : 0.05687    f1 : 0.98441\n",
      "Val    loss : 0.26960    f1 : 0.93842\n",
      "epoch : 26/100    time : 28s/2083s\n",
      "TRAIN    loss : 0.04271    f1 : 0.98550\n",
      "Val    loss : 0.25995    f1 : 0.93223\n",
      "epoch : 27/100    time : 29s/2125s\n",
      "TRAIN    loss : 0.06205    f1 : 0.98557\n",
      "Val    loss : 0.26284    f1 : 0.93845\n",
      "epoch : 28/100    time : 29s/2066s\n",
      "TRAIN    loss : 0.07045    f1 : 0.98859\n",
      "Val    loss : 0.25508    f1 : 0.92150\n",
      "epoch : 29/100    time : 30s/2148s\n",
      "TRAIN    loss : 0.03568    f1 : 0.99260\n",
      "Val    loss : 0.21809    f1 : 0.94363\n",
      "epoch : 30/100    time : 30s/2100s\n",
      "TRAIN    loss : 0.04330    f1 : 0.98691\n",
      "Val    loss : 0.35187    f1 : 0.90869\n",
      "epoch : 31/100    time : 29s/1987s\n",
      "TRAIN    loss : 0.03815    f1 : 0.99147\n",
      "Val    loss : 0.29758    f1 : 0.92045\n",
      "epoch : 32/100    time : 29s/1982s\n",
      "TRAIN    loss : 0.04378    f1 : 0.99294\n",
      "Val    loss : 0.24238    f1 : 0.94924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 33/100    time : 29s/1944s\n",
      "TRAIN    loss : 0.07556    f1 : 0.97860\n",
      "Val    loss : 0.26948    f1 : 0.93150\n",
      "epoch : 34/100    time : 29s/1909s\n",
      "TRAIN    loss : 0.04446    f1 : 0.99157\n",
      "Val    loss : 0.21077    f1 : 0.94322\n",
      "epoch : 35/100    time : 28s/1849s\n",
      "TRAIN    loss : 0.04131    f1 : 0.98719\n",
      "Val    loss : 0.19508    f1 : 0.94870\n",
      "epoch : 36/100    time : 29s/1870s\n",
      "TRAIN    loss : 0.06002    f1 : 0.97734\n",
      "Val    loss : 0.21825    f1 : 0.94309\n",
      "epoch : 37/100    time : 30s/1881s\n",
      "TRAIN    loss : 0.05143    f1 : 0.98479\n",
      "Val    loss : 0.27390    f1 : 0.93771\n",
      "epoch : 38/100    time : 29s/1808s\n",
      "TRAIN    loss : 0.02612    f1 : 0.99572\n",
      "Val    loss : 0.27853    f1 : 0.93786\n",
      "epoch : 39/100    time : 30s/1802s\n",
      "TRAIN    loss : 0.02339    f1 : 0.99575\n",
      "Val    loss : 0.24305    f1 : 0.93143\n",
      "epoch : 40/100    time : 29s/1734s\n",
      "TRAIN    loss : 0.01759    f1 : 0.99725\n",
      "Val    loss : 0.20796    f1 : 0.95513\n",
      "epoch : 41/100    time : 27s/1610s\n",
      "TRAIN    loss : 0.01067    f1 : 0.99862\n",
      "Val    loss : 0.22734    f1 : 0.93771\n",
      "epoch : 42/100    time : 29s/1706s\n",
      "TRAIN    loss : 0.07420    f1 : 0.97679\n",
      "Val    loss : 0.30554    f1 : 0.91983\n",
      "----------fold_3 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 29s/2833s\n",
      "TRAIN    loss : 4.26578    f1 : 0.01842\n",
      "Val    loss : 1.57884    f1 : 0.48048\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 30s/2917s\n",
      "TRAIN    loss : 1.15055    f1 : 0.63659\n",
      "Val    loss : 0.78309    f1 : 0.77631\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 29s/2852s\n",
      "TRAIN    loss : 0.68961    f1 : 0.77502\n",
      "Val    loss : 0.43417    f1 : 0.87448\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 29s/2818s\n",
      "TRAIN    loss : 0.49457    f1 : 0.86167\n",
      "Val    loss : 0.30464    f1 : 0.91893\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 30s/2812s\n",
      "TRAIN    loss : 0.40270    f1 : 0.88565\n",
      "Val    loss : 0.26249    f1 : 0.92092\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 29s/2772s\n",
      "TRAIN    loss : 0.29281    f1 : 0.92648\n",
      "Val    loss : 0.21324    f1 : 0.94257\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 30s/2826s\n",
      "TRAIN    loss : 0.27591    f1 : 0.92634\n",
      "Val    loss : 0.18691    f1 : 0.94436\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 29s/2694s\n",
      "TRAIN    loss : 0.22536    f1 : 0.94052\n",
      "Val    loss : 0.15168    f1 : 0.96040\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 29s/2670s\n",
      "TRAIN    loss : 0.17144    f1 : 0.95324\n",
      "Val    loss : 0.15425    f1 : 0.96633\n",
      "epoch : 10/100    time : 30s/2692s\n",
      "TRAIN    loss : 0.16397    f1 : 0.96130\n",
      "Val    loss : 0.14196    f1 : 0.95470\n",
      "epoch : 11/100    time : 30s/2642s\n",
      "TRAIN    loss : 0.13515    f1 : 0.96878\n",
      "Val    loss : 0.11909    f1 : 0.96577\n",
      "epoch : 12/100    time : 29s/2593s\n",
      "TRAIN    loss : 0.16254    f1 : 0.95507\n",
      "Val    loss : 0.15002    f1 : 0.95437\n",
      "epoch : 13/100    time : 30s/2579s\n",
      "TRAIN    loss : 0.12006    f1 : 0.96987\n",
      "Val    loss : 0.17151    f1 : 0.94349\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/100    time : 30s/2537s\n",
      "TRAIN    loss : 0.08663    f1 : 0.98010\n",
      "Val    loss : 0.09568    f1 : 0.97756\n",
      "epoch : 15/100    time : 30s/2534s\n",
      "TRAIN    loss : 0.08755    f1 : 0.97846\n",
      "Val    loss : 0.14050    f1 : 0.96696\n",
      "epoch : 16/100    time : 30s/2499s\n",
      "TRAIN    loss : 0.06531    f1 : 0.98258\n",
      "Val    loss : 0.11945    f1 : 0.97220\n",
      "epoch : 17/100    time : 29s/2444s\n",
      "TRAIN    loss : 0.05366    f1 : 0.99115\n",
      "Val    loss : 0.15544    f1 : 0.96079\n",
      "epoch : 18/100    time : 30s/2466s\n",
      "TRAIN    loss : 0.04557    f1 : 0.99140\n",
      "Val    loss : 0.15013    f1 : 0.96644\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/100    time : 30s/2441s\n",
      "TRAIN    loss : 0.06360    f1 : 0.98025\n",
      "Val    loss : 0.17045    f1 : 0.98306\n",
      "epoch : 20/100    time : 29s/2357s\n",
      "TRAIN    loss : 0.05622    f1 : 0.98690\n",
      "Val    loss : 0.14903    f1 : 0.96135\n",
      "epoch : 21/100    time : 29s/2321s\n",
      "TRAIN    loss : 0.05064    f1 : 0.98695\n",
      "Val    loss : 0.11811    f1 : 0.95431\n",
      "epoch : 22/100    time : 29s/2293s\n",
      "TRAIN    loss : 0.09702    f1 : 0.97735\n",
      "Val    loss : 0.17525    f1 : 0.95526\n",
      "-----------------SAVE:23 epoch----------------\n",
      "epoch : 23/100    time : 29s/2258s\n",
      "TRAIN    loss : 0.04217    f1 : 0.99006\n",
      "Val    loss : 0.09775    f1 : 0.98346\n",
      "epoch : 24/100    time : 30s/2265s\n",
      "TRAIN    loss : 0.04279    f1 : 0.98976\n",
      "Val    loss : 0.11684    f1 : 0.97756\n",
      "epoch : 25/100    time : 30s/2219s\n",
      "TRAIN    loss : 0.07728    f1 : 0.97985\n",
      "Val    loss : 0.16841    f1 : 0.96080\n",
      "epoch : 26/100    time : 30s/2194s\n",
      "TRAIN    loss : 0.07827    f1 : 0.97984\n",
      "Val    loss : 0.19246    f1 : 0.95000\n",
      "epoch : 27/100    time : 30s/2174s\n",
      "TRAIN    loss : 0.05333    f1 : 0.98865\n",
      "Val    loss : 0.19407    f1 : 0.92691\n",
      "epoch : 28/100    time : 29s/2111s\n",
      "TRAIN    loss : 0.06675    f1 : 0.98296\n",
      "Val    loss : 0.13088    f1 : 0.97199\n",
      "epoch : 29/100    time : 30s/2096s\n",
      "TRAIN    loss : 0.05029    f1 : 0.99001\n",
      "Val    loss : 0.15748    f1 : 0.95593\n",
      "epoch : 30/100    time : 30s/2067s\n",
      "TRAIN    loss : 0.04013    f1 : 0.99426\n",
      "Val    loss : 0.12883    f1 : 0.97700\n",
      "epoch : 31/100    time : 30s/2075s\n",
      "TRAIN    loss : 0.04701    f1 : 0.99427\n",
      "Val    loss : 0.15092    f1 : 0.95995\n",
      "epoch : 32/100    time : 30s/2007s\n",
      "TRAIN    loss : 0.05625    f1 : 0.98576\n",
      "Val    loss : 0.13494    f1 : 0.96623\n",
      "epoch : 33/100    time : 29s/1948s\n",
      "TRAIN    loss : 0.02480    f1 : 0.99857\n",
      "Val    loss : 0.13130    f1 : 0.96151\n",
      "epoch : 34/100    time : 29s/1907s\n",
      "TRAIN    loss : 0.01988    f1 : 0.99430\n",
      "Val    loss : 0.11492    f1 : 0.97228\n",
      "epoch : 35/100    time : 29s/1870s\n",
      "TRAIN    loss : 0.04728    f1 : 0.98836\n",
      "Val    loss : 0.12372    f1 : 0.97200\n",
      "epoch : 36/100    time : 30s/1915s\n",
      "TRAIN    loss : 0.03756    f1 : 0.99290\n",
      "Val    loss : 0.09413    f1 : 0.98308\n",
      "epoch : 37/100    time : 28s/1795s\n",
      "TRAIN    loss : 0.04095    f1 : 0.98940\n",
      "Val    loss : 0.10343    f1 : 0.97205\n",
      "epoch : 38/100    time : 30s/1869s\n",
      "TRAIN    loss : 0.03470    f1 : 0.99295\n",
      "Val    loss : 0.15253    f1 : 0.96550\n",
      "epoch : 39/100    time : 30s/1821s\n",
      "TRAIN    loss : 0.04196    f1 : 0.98720\n",
      "Val    loss : 0.17563    f1 : 0.94494\n",
      "epoch : 40/100    time : 30s/1816s\n",
      "TRAIN    loss : 0.05103    f1 : 0.98439\n",
      "Val    loss : 0.24522    f1 : 0.93860\n",
      "epoch : 41/100    time : 30s/1773s\n",
      "TRAIN    loss : 0.04712    f1 : 0.98999\n",
      "Val    loss : 0.11942    f1 : 0.97748\n",
      "epoch : 42/100    time : 29s/1704s\n",
      "TRAIN    loss : 0.03268    f1 : 0.99121\n",
      "Val    loss : 0.12358    f1 : 0.98306\n",
      "epoch : 43/100    time : 29s/1674s\n",
      "TRAIN    loss : 0.03353    f1 : 0.98982\n",
      "Val    loss : 0.17835    f1 : 0.97748\n",
      "----------fold_4 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 29s/2874s\n",
      "TRAIN    loss : 4.41991    f1 : 0.01568\n",
      "Val    loss : 1.65208    f1 : 0.56510\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 29s/2863s\n",
      "TRAIN    loss : 1.16412    f1 : 0.68892\n",
      "Val    loss : 0.81709    f1 : 0.78582\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 30s/2914s\n",
      "TRAIN    loss : 0.69117    f1 : 0.79365\n",
      "Val    loss : 0.57675    f1 : 0.79841\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 30s/2870s\n",
      "TRAIN    loss : 0.46093    f1 : 0.84838\n",
      "Val    loss : 0.45102    f1 : 0.80146\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 29s/2789s\n",
      "TRAIN    loss : 0.39766    f1 : 0.87443\n",
      "Val    loss : 0.38631    f1 : 0.88018\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 30s/2794s\n",
      "TRAIN    loss : 0.27219    f1 : 0.93451\n",
      "Val    loss : 0.23953    f1 : 0.90787\n",
      "epoch : 7/100    time : 30s/2771s\n",
      "TRAIN    loss : 0.21751    f1 : 0.94075\n",
      "Val    loss : 0.27469    f1 : 0.89602\n",
      "epoch : 8/100    time : 29s/2699s\n",
      "TRAIN    loss : 0.16729    f1 : 0.95696\n",
      "Val    loss : 0.28383    f1 : 0.88525\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 29s/2675s\n",
      "TRAIN    loss : 0.18362    f1 : 0.95714\n",
      "Val    loss : 0.22405    f1 : 0.94178\n",
      "epoch : 10/100    time : 30s/2699s\n",
      "TRAIN    loss : 0.16556    f1 : 0.95847\n",
      "Val    loss : 0.20461    f1 : 0.92945\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 30s/2650s\n",
      "TRAIN    loss : 0.12442    f1 : 0.97140\n",
      "Val    loss : 0.23575    f1 : 0.94773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 29s/2592s\n",
      "TRAIN    loss : 0.17625    f1 : 0.95039\n",
      "Val    loss : 0.16164    f1 : 0.96600\n",
      "epoch : 13/100    time : 29s/2556s\n",
      "TRAIN    loss : 0.10870    f1 : 0.97356\n",
      "Val    loss : 0.18966    f1 : 0.93666\n",
      "epoch : 14/100    time : 30s/2609s\n",
      "TRAIN    loss : 0.10287    f1 : 0.97981\n",
      "Val    loss : 0.27446    f1 : 0.93844\n",
      "epoch : 15/100    time : 30s/2515s\n",
      "TRAIN    loss : 0.07419    f1 : 0.99005\n",
      "Val    loss : 0.21380    f1 : 0.94928\n",
      "epoch : 16/100    time : 30s/2502s\n",
      "TRAIN    loss : 0.07023    f1 : 0.98310\n",
      "Val    loss : 0.18339    f1 : 0.94680\n",
      "epoch : 17/100    time : 30s/2463s\n",
      "TRAIN    loss : 0.07069    f1 : 0.98151\n",
      "Val    loss : 0.19370    f1 : 0.94924\n",
      "epoch : 18/100    time : 30s/2428s\n",
      "TRAIN    loss : 0.03559    f1 : 0.99859\n",
      "Val    loss : 0.13443    f1 : 0.95346\n",
      "epoch : 19/100    time : 29s/2358s\n",
      "TRAIN    loss : 0.06537    f1 : 0.98584\n",
      "Val    loss : 0.12681    f1 : 0.95871\n",
      "epoch : 20/100    time : 30s/2392s\n",
      "TRAIN    loss : 0.07120    f1 : 0.98159\n",
      "Val    loss : 0.24877    f1 : 0.93633\n",
      "epoch : 21/100    time : 29s/2284s\n",
      "TRAIN    loss : 0.06703    f1 : 0.98565\n",
      "Val    loss : 0.16550    f1 : 0.94190\n",
      "epoch : 22/100    time : 29s/2292s\n",
      "TRAIN    loss : 0.03875    f1 : 0.99435\n",
      "Val    loss : 0.13786    f1 : 0.95832\n",
      "epoch : 23/100    time : 29s/2257s\n",
      "TRAIN    loss : 0.08122    f1 : 0.97299\n",
      "Val    loss : 0.20859    f1 : 0.93651\n",
      "epoch : 24/100    time : 29s/2217s\n",
      "TRAIN    loss : 0.05478    f1 : 0.99002\n",
      "Val    loss : 0.19421    f1 : 0.93956\n",
      "epoch : 25/100    time : 29s/2195s\n",
      "TRAIN    loss : 0.06743    f1 : 0.98669\n",
      "Val    loss : 0.18909    f1 : 0.95832\n",
      "epoch : 26/100    time : 29s/2143s\n",
      "TRAIN    loss : 0.02572    f1 : 0.99859\n",
      "Val    loss : 0.19204    f1 : 0.95441\n",
      "epoch : 27/100    time : 30s/2165s\n",
      "TRAIN    loss : 0.04614    f1 : 0.98402\n",
      "Val    loss : 0.22129    f1 : 0.95775\n",
      "epoch : 28/100    time : 29s/2074s\n",
      "TRAIN    loss : 0.05792    f1 : 0.98442\n",
      "Val    loss : 0.20285    f1 : 0.93522\n",
      "epoch : 29/100    time : 30s/2125s\n",
      "TRAIN    loss : 0.05139    f1 : 0.98840\n",
      "Val    loss : 0.15509    f1 : 0.95793\n",
      "epoch : 30/100    time : 29s/2054s\n",
      "TRAIN    loss : 0.04044    f1 : 0.98705\n",
      "Val    loss : 0.16931    f1 : 0.93023\n",
      "epoch : 31/100    time : 29s/2019s\n",
      "TRAIN    loss : 0.03532    f1 : 0.98655\n",
      "Val    loss : 0.13190    f1 : 0.95225\n",
      "epoch : 32/100    time : 30s/2020s\n",
      "TRAIN    loss : 0.04976    f1 : 0.98149\n",
      "Val    loss : 0.20797    f1 : 0.94580\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022, shuffle = True)\n",
    "batch_size = 8\n",
    "epochs = 100\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "  print(\"----------fold_{} start!----------\".format(idx))\n",
    "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "  # Train\n",
    "  train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Val\n",
    "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  best=0\n",
    "\n",
    "  model = Network().to(device)\n",
    "\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay = 1e-3)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "  best_f1 = 0\n",
    "  early_stopping = 0\n",
    "  for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss = 0 \n",
    "      val_pred = []\n",
    "      val_y = []\n",
    "      \n",
    "\n",
    "      for batch in (val_loader):\n",
    "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_val = model(x_val)\n",
    "        loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "        val_loss += loss_val.item()/len(val_loader)\n",
    "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "        val_y += y_val.detach().cpu().numpy().tolist()\n",
    "      val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "      if val_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_loss = val_loss\n",
    "        best_f1 = val_f1\n",
    "        early_stopping = 0\n",
    "\n",
    "        torch.save({'epoch':epoch,\n",
    "                    'state_dict':state_dict,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "             }, path +'best_model_{}.pth'.format(idx))\n",
    "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "      else:\n",
    "          early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "      if early_stopping == 20:\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Jl2OKpQiO5S1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl2OKpQiO5S1",
    "outputId": "e48def07-ef6d-4325-f297-c705088b3eb8"
   },
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 8\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load((path+'best_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "GjsHs-T3SPJq",
   "metadata": {
    "id": "GjsHs-T3SPJq"
   },
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1])+ np.array(pred_ensemble[3]) + np.array(pred_ensemble[4]) )/4\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "UIglTwAV7L54",
   "metadata": {
    "id": "UIglTwAV7L54"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "292QDIS5DOKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "292QDIS5DOKf",
    "outputId": "0e47d38f-d36a-40cd-a925-90e6bce52652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name label\n",
       "0     001.png     1\n",
       "1     002.png     2\n",
       "2     003.png     1\n",
       "3     004.png     6\n",
       "4     005.png     8\n",
       "..        ...   ...\n",
       "210   211.png     5\n",
       "211   212.png     8\n",
       "212   213.png     3\n",
       "213   214.png     6\n",
       "214   215.png     1\n",
       "\n",
       "[215 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"sample_submission.csv\")\n",
    "submission[\"label\"] = f_result\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1naZSLGZ7L55",
   "metadata": {
    "id": "1naZSLGZ7L55"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"submit.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fitted-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSubmitted': True, 'detail': 'Success'}\n"
     ]
    }
   ],
   "source": [
    "# d9249@kyonggi.ac.kr\n",
    "\n",
    "from dacon_submit_api import dacon_submit_api \n",
    "\n",
    "result = dacon_submit_api.post_submission_file(\n",
    "'C:/Users/ideal/Downloads/jupyter/user_data/submit.csv', \n",
    "'02438df9bd0f6300dae6ddea845e7e01d2cb1881849c166bfce504164e1507d5', \n",
    "'235896', \n",
    "'iDeal', \n",
    "'test' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8dd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[BASELINE]_EfficientNet_b3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
