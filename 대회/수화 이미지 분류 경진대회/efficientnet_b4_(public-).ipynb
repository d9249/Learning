{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LlcNsGEk7L5r",
   "metadata": {
    "id": "LlcNsGEk7L5r"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81532144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3',\n",
      " 'bat_resnext26ts',\n",
      " 'beit_base_patch16_224',\n",
      " 'beit_base_patch16_224_in22k',\n",
      " 'beit_base_patch16_384',\n",
      " 'beit_large_patch16_224',\n",
      " 'beit_large_patch16_224_in22k',\n",
      " 'beit_large_patch16_384',\n",
      " 'beit_large_patch16_512',\n",
      " 'botnet26t_256',\n",
      " 'cait_m36_384',\n",
      " 'cait_m48_448',\n",
      " 'cait_s24_224',\n",
      " 'cait_s24_384',\n",
      " 'cait_s36_384',\n",
      " 'cait_xs24_384',\n",
      " 'cait_xxs24_224',\n",
      " 'cait_xxs24_384',\n",
      " 'cait_xxs36_224',\n",
      " 'cait_xxs36_384',\n",
      " 'coat_lite_mini',\n",
      " 'coat_lite_small',\n",
      " 'coat_lite_tiny',\n",
      " 'coat_mini',\n",
      " 'coat_tiny',\n",
      " 'convit_base',\n",
      " 'convit_small',\n",
      " 'convit_tiny',\n",
      " 'convmixer_768_32',\n",
      " 'convmixer_1024_20_ks9_p14',\n",
      " 'convmixer_1536_20',\n",
      " 'convnext_base',\n",
      " 'convnext_base_384_in22ft1k',\n",
      " 'convnext_base_in22ft1k',\n",
      " 'convnext_base_in22k',\n",
      " 'convnext_large',\n",
      " 'convnext_large_384_in22ft1k',\n",
      " 'convnext_large_in22ft1k',\n",
      " 'convnext_large_in22k',\n",
      " 'convnext_small',\n",
      " 'convnext_tiny',\n",
      " 'convnext_xlarge_384_in22ft1k',\n",
      " 'convnext_xlarge_in22ft1k',\n",
      " 'convnext_xlarge_in22k',\n",
      " 'crossvit_9_240',\n",
      " 'crossvit_9_dagger_240',\n",
      " 'crossvit_15_240',\n",
      " 'crossvit_15_dagger_240',\n",
      " 'crossvit_15_dagger_408',\n",
      " 'crossvit_18_240',\n",
      " 'crossvit_18_dagger_240',\n",
      " 'crossvit_18_dagger_408',\n",
      " 'crossvit_base_240',\n",
      " 'crossvit_small_240',\n",
      " 'crossvit_tiny_240',\n",
      " 'cspdarknet53',\n",
      " 'cspresnet50',\n",
      " 'cspresnext50',\n",
      " 'deit_base_distilled_patch16_224',\n",
      " 'deit_base_distilled_patch16_384',\n",
      " 'deit_base_patch16_224',\n",
      " 'deit_base_patch16_384',\n",
      " 'deit_small_distilled_patch16_224',\n",
      " 'deit_small_patch16_224',\n",
      " 'deit_tiny_distilled_patch16_224',\n",
      " 'deit_tiny_patch16_224',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dm_nfnet_f0',\n",
      " 'dm_nfnet_f1',\n",
      " 'dm_nfnet_f2',\n",
      " 'dm_nfnet_f3',\n",
      " 'dm_nfnet_f4',\n",
      " 'dm_nfnet_f5',\n",
      " 'dm_nfnet_f6',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'eca_botnext26ts_256',\n",
      " 'eca_halonext26ts',\n",
      " 'eca_nfnet_l0',\n",
      " 'eca_nfnet_l1',\n",
      " 'eca_nfnet_l2',\n",
      " 'eca_resnet33ts',\n",
      " 'eca_resnext26ts',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b4',\n",
      " 'efficientnet_el',\n",
      " 'efficientnet_el_pruned',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_es_pruned',\n",
      " 'efficientnet_lite0',\n",
      " 'efficientnetv2_rw_m',\n",
      " 'efficientnetv2_rw_s',\n",
      " 'efficientnetv2_rw_t',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'fbnetc_100',\n",
      " 'fbnetv3_b',\n",
      " 'fbnetv3_d',\n",
      " 'fbnetv3_g',\n",
      " 'gc_efficientnetv2_rw_t',\n",
      " 'gcresnet33ts',\n",
      " 'gcresnet50t',\n",
      " 'gcresnext26ts',\n",
      " 'gcresnext50ts',\n",
      " 'gernet_l',\n",
      " 'gernet_m',\n",
      " 'gernet_s',\n",
      " 'ghostnet_100',\n",
      " 'gluon_inception_v3',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_senet154',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'gluon_xception65',\n",
      " 'gmixer_24_224',\n",
      " 'gmlp_s16_224',\n",
      " 'halo2botnet50ts_256',\n",
      " 'halonet26t',\n",
      " 'halonet50ts',\n",
      " 'haloregnetz_b',\n",
      " 'hardcorenas_a',\n",
      " 'hardcorenas_b',\n",
      " 'hardcorenas_c',\n",
      " 'hardcorenas_d',\n",
      " 'hardcorenas_e',\n",
      " 'hardcorenas_f',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w64',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'jx_nest_base',\n",
      " 'jx_nest_small',\n",
      " 'jx_nest_tiny',\n",
      " 'lambda_resnet26rpt_256',\n",
      " 'lambda_resnet26t',\n",
      " 'lambda_resnet50ts',\n",
      " 'lamhalobotnet50ts_256',\n",
      " 'lcnet_050',\n",
      " 'lcnet_075',\n",
      " 'lcnet_100',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'levit_128',\n",
      " 'levit_128s',\n",
      " 'levit_192',\n",
      " 'levit_256',\n",
      " 'levit_384',\n",
      " 'mixer_b16_224',\n",
      " 'mixer_b16_224_in21k',\n",
      " 'mixer_b16_224_miil',\n",
      " 'mixer_b16_224_miil_in21k',\n",
      " 'mixer_l16_224',\n",
      " 'mixer_l16_224_in21k',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mnasnet_100',\n",
      " 'mnasnet_small',\n",
      " 'mobilenetv2_050',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_large_100_miil',\n",
      " 'mobilenetv3_large_100_miil_in21k',\n",
      " 'mobilenetv3_rw',\n",
      " 'nasnetalarge',\n",
      " 'nf_regnet_b1',\n",
      " 'nf_resnet50',\n",
      " 'nfnet_l0',\n",
      " 'pit_b_224',\n",
      " 'pit_b_distilled_224',\n",
      " 'pit_s_224',\n",
      " 'pit_s_distilled_224',\n",
      " 'pit_ti_224',\n",
      " 'pit_ti_distilled_224',\n",
      " 'pit_xs_224',\n",
      " 'pit_xs_distilled_224',\n",
      " 'pnasnet5large',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'regnetz_b16',\n",
      " 'regnetz_c16',\n",
      " 'regnetz_d8',\n",
      " 'regnetz_d32',\n",
      " 'regnetz_e8',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2next50',\n",
      " 'resmlp_12_224',\n",
      " 'resmlp_12_224_dino',\n",
      " 'resmlp_12_distilled_224',\n",
      " 'resmlp_24_224',\n",
      " 'resmlp_24_224_dino',\n",
      " 'resmlp_24_distilled_224',\n",
      " 'resmlp_36_224',\n",
      " 'resmlp_36_distilled_224',\n",
      " 'resmlp_big_24_224',\n",
      " 'resmlp_big_24_224_in22ft1k',\n",
      " 'resmlp_big_24_distilled_224',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet26t',\n",
      " 'resnet32ts',\n",
      " 'resnet33ts',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50_gn',\n",
      " 'resnet50d',\n",
      " 'resnet51q',\n",
      " 'resnet61q',\n",
      " 'resnet101',\n",
      " 'resnet101d',\n",
      " 'resnet152',\n",
      " 'resnet152d',\n",
      " 'resnet200d',\n",
      " 'resnetblur50',\n",
      " 'resnetrs50',\n",
      " 'resnetrs101',\n",
      " 'resnetrs152',\n",
      " 'resnetrs200',\n",
      " 'resnetrs270',\n",
      " 'resnetrs350',\n",
      " 'resnetrs420',\n",
      " 'resnetv2_50',\n",
      " 'resnetv2_50x1_bit_distilled',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bit_teacher',\n",
      " 'resnetv2_152x2_bit_teacher_384',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext26ts',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'sebotnet33ts_256',\n",
      " 'sehalonet33ts',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'semnasnet_075',\n",
      " 'semnasnet_100',\n",
      " 'seresnet33ts',\n",
      " 'seresnet50',\n",
      " 'seresnet152d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext26ts',\n",
      " 'seresnext50_32x4d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swin_base_patch4_window7_224',\n",
      " 'swin_base_patch4_window7_224_in22k',\n",
      " 'swin_base_patch4_window12_384',\n",
      " 'swin_base_patch4_window12_384_in22k',\n",
      " 'swin_large_patch4_window7_224',\n",
      " 'swin_large_patch4_window7_224_in22k',\n",
      " 'swin_large_patch4_window12_384',\n",
      " 'swin_large_patch4_window12_384_in22k',\n",
      " 'swin_small_patch4_window7_224',\n",
      " 'swin_tiny_patch4_window7_224',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b0_ap',\n",
      " 'tf_efficientnet_b0_ns',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b1_ap',\n",
      " 'tf_efficientnet_b1_ns',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b2_ap',\n",
      " 'tf_efficientnet_b2_ns',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b3_ap',\n",
      " 'tf_efficientnet_b3_ns',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b4_ap',\n",
      " 'tf_efficientnet_b4_ns',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b5_ap',\n",
      " 'tf_efficientnet_b5_ns',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b6_ap',\n",
      " 'tf_efficientnet_b6_ns',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b7_ap',\n",
      " 'tf_efficientnet_b7_ns',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_b8_ap',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2_ns',\n",
      " 'tf_efficientnet_l2_ns_475',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_efficientnetv2_b0',\n",
      " 'tf_efficientnetv2_b1',\n",
      " 'tf_efficientnetv2_b2',\n",
      " 'tf_efficientnetv2_b3',\n",
      " 'tf_efficientnetv2_l',\n",
      " 'tf_efficientnetv2_l_in21ft1k',\n",
      " 'tf_efficientnetv2_l_in21k',\n",
      " 'tf_efficientnetv2_m',\n",
      " 'tf_efficientnetv2_m_in21ft1k',\n",
      " 'tf_efficientnetv2_m_in21k',\n",
      " 'tf_efficientnetv2_s',\n",
      " 'tf_efficientnetv2_s_in21ft1k',\n",
      " 'tf_efficientnetv2_s_in21k',\n",
      " 'tf_efficientnetv2_xl_in21ft1k',\n",
      " 'tf_efficientnetv2_xl_in21k',\n",
      " 'tf_inception_v3',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tinynet_a',\n",
      " 'tinynet_b',\n",
      " 'tinynet_c',\n",
      " 'tinynet_d',\n",
      " 'tinynet_e',\n",
      " 'tnt_s_patch16_224',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_m_miil_in21k',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_densenet121',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'twins_pcpvt_base',\n",
      " 'twins_pcpvt_large',\n",
      " 'twins_pcpvt_small',\n",
      " 'twins_svt_base',\n",
      " 'twins_svt_large',\n",
      " 'twins_svt_small',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'visformer_small',\n",
      " 'vit_base_patch8_224',\n",
      " 'vit_base_patch8_224_in21k',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_224_in21k',\n",
      " 'vit_base_patch16_224_miil',\n",
      " 'vit_base_patch16_224_miil_in21k',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch16_sam_224',\n",
      " 'vit_base_patch32_224',\n",
      " 'vit_base_patch32_224_in21k',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_patch32_sam_224',\n",
      " 'vit_base_r50_s16_224_in21k',\n",
      " 'vit_base_r50_s16_384',\n",
      " 'vit_huge_patch14_224_in21k',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_224_in21k',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch32_224_in21k',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_large_r50_s32_224',\n",
      " 'vit_large_r50_s32_224_in21k',\n",
      " 'vit_large_r50_s32_384',\n",
      " 'vit_small_patch16_224',\n",
      " 'vit_small_patch16_224_in21k',\n",
      " 'vit_small_patch16_384',\n",
      " 'vit_small_patch32_224',\n",
      " 'vit_small_patch32_224_in21k',\n",
      " 'vit_small_patch32_384',\n",
      " 'vit_small_r26_s32_224',\n",
      " 'vit_small_r26_s32_224_in21k',\n",
      " 'vit_small_r26_s32_384',\n",
      " 'vit_tiny_patch16_224',\n",
      " 'vit_tiny_patch16_224_in21k',\n",
      " 'vit_tiny_patch16_384',\n",
      " 'vit_tiny_r_s16_p8_224',\n",
      " 'vit_tiny_r_s16_p8_224_in21k',\n",
      " 'vit_tiny_r_s16_p8_384',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception',\n",
      " 'xception41',\n",
      " 'xception65',\n",
      " 'xception71',\n",
      " 'xcit_large_24_p8_224',\n",
      " 'xcit_large_24_p8_224_dist',\n",
      " 'xcit_large_24_p8_384_dist',\n",
      " 'xcit_large_24_p16_224',\n",
      " 'xcit_large_24_p16_224_dist',\n",
      " 'xcit_large_24_p16_384_dist',\n",
      " 'xcit_medium_24_p8_224',\n",
      " 'xcit_medium_24_p8_224_dist',\n",
      " 'xcit_medium_24_p8_384_dist',\n",
      " 'xcit_medium_24_p16_224',\n",
      " 'xcit_medium_24_p16_224_dist',\n",
      " 'xcit_medium_24_p16_384_dist',\n",
      " 'xcit_nano_12_p8_224',\n",
      " 'xcit_nano_12_p8_224_dist',\n",
      " 'xcit_nano_12_p8_384_dist',\n",
      " 'xcit_nano_12_p16_224',\n",
      " 'xcit_nano_12_p16_224_dist',\n",
      " 'xcit_nano_12_p16_384_dist',\n",
      " 'xcit_small_12_p8_224',\n",
      " 'xcit_small_12_p8_224_dist',\n",
      " 'xcit_small_12_p8_384_dist',\n",
      " 'xcit_small_12_p16_224',\n",
      " 'xcit_small_12_p16_224_dist',\n",
      " 'xcit_small_12_p16_384_dist',\n",
      " 'xcit_small_24_p8_224',\n",
      " 'xcit_small_24_p8_224_dist',\n",
      " 'xcit_small_24_p8_384_dist',\n",
      " 'xcit_small_24_p16_224',\n",
      " 'xcit_small_24_p16_224_dist',\n",
      " 'xcit_small_24_p16_384_dist',\n",
      " 'xcit_tiny_12_p8_224',\n",
      " 'xcit_tiny_12_p8_224_dist',\n",
      " 'xcit_tiny_12_p8_384_dist',\n",
      " 'xcit_tiny_12_p16_224',\n",
      " 'xcit_tiny_12_p16_224_dist',\n",
      " 'xcit_tiny_12_p16_384_dist',\n",
      " 'xcit_tiny_24_p8_224',\n",
      " 'xcit_tiny_24_p8_224_dist',\n",
      " 'xcit_tiny_24_p8_384_dist',\n",
      " 'xcit_tiny_24_p16_224',\n",
      " 'xcit_tiny_24_p16_224_dist',\n",
      " 'xcit_tiny_24_p16_384_dist']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lXH5F_hA7uMl",
   "metadata": {
    "id": "lXH5F_hA7uMl"
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/ideal/Downloads/jupyter/user_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "FWntO1VD7L5u",
   "metadata": {
    "id": "FWntO1VD7L5u"
   },
   "outputs": [],
   "source": [
    "train_png = sorted(glob(path + 'train/*.png'))\n",
    "test_png = sorted(glob(path + 'test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atSgPJRn-OCW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atSgPJRn-OCW",
    "outputId": "87b6f90b-5c1c-4a0e-de54-994458543687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(858, 215)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_png), len(test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "xv0_rDVq7L5v",
   "metadata": {
    "id": "xv0_rDVq7L5v"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(path +\"train.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc9232f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0,\n",
       " '10-1': 1,\n",
       " '10-2': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "iMhC0nPw7L5w",
   "metadata": {
    "id": "iMhC0nPw7L5w"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "#     img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "zsmJA3E97L5x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsmJA3E97L5x",
    "outputId": "e0dc61fe-5617-42e8-c8b0-0e95b9f60656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 858/858 [00:00<00:00, 954.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 215/215 [00:00<00:00, 908.85it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "KA73Lku9A2N9",
   "metadata": {
    "id": "KA73Lku9A2N9"
   },
   "outputs": [],
   "source": [
    "np.save(path + 'train_imgs_384', np.array(train_imgs))\n",
    "np.save(path + 'test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "L6qBdX7nCp8L",
   "metadata": {
    "id": "L6qBdX7nCp8L"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.load(path + 'train_imgs_384.npy')\n",
    "test_imgs = np.load(path + 'test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9207e10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평균 0.587861452947292 0.5398018372012267 0.4853426659853918\n",
      "train 표준편차 0.15058758283288234 0.15921522386293296 0.17031454681984776\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "train_meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "train_meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "train_meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "train_stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "train_stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "train_stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"train 평균\",train_meanR, train_meanG, train_meanB)\n",
    "print(\"train 표준편차\",train_stdR, train_stdG, train_stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "935064b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 평균 0.5915704246815005 0.5468021681783177 0.49356994941872095\n",
      "test 표준편차 0.15494109227168867 0.1642936360901455 0.1756015391157054\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "test_meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "test_meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "test_meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "test_stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "test_stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "test_stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"test 평균\",test_meanR, test_meanG, test_meanB)\n",
    "print(\"test 표준편차\",test_stdR, test_stdG, test_stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "VFXzojoo7L5y",
   "metadata": {
    "id": "VFXzojoo7L5y"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [train_meanR, train_meanG, train_meanB],\n",
    "                                     std = [train_stdR, train_stdG, train_stdB]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [test_meanR, test_meanG, test_meanB],\n",
    "                                     std = [test_stdR, test_stdG, test_stdB])\n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=11, drop_path_rate = 0)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=11, drop_path_rate = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38qk8sGbYiO_",
   "metadata": {
    "id": "38qk8sGbYiO_"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lkNCkyG9RPzX",
   "metadata": {
    "id": "lkNCkyG9RPzX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth\" to C:\\Users\\ideal/.cache\\torch\\hub\\checkpoints\\efficientnet_b4_ra2_320-7eb33cd5.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 37s/3625s\n",
      "TRAIN    loss : 2.47995    f1 : 0.15298\n",
      "Val    loss : 2.27708    f1 : 0.27660\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 34s/3381s\n",
      "TRAIN    loss : 1.57382    f1 : 0.47584\n",
      "Val    loss : 1.47692    f1 : 0.55027\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 36s/3497s\n",
      "TRAIN    loss : 1.04203    f1 : 0.68191\n",
      "Val    loss : 0.90050    f1 : 0.67157\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 36s/3475s\n",
      "TRAIN    loss : 0.76599    f1 : 0.75346\n",
      "Val    loss : 0.92111    f1 : 0.73207\n",
      "epoch : 5/100    time : 34s/3257s\n",
      "TRAIN    loss : 0.49768    f1 : 0.84455\n",
      "Val    loss : 0.92573    f1 : 0.71932\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 36s/3363s\n",
      "TRAIN    loss : 0.42476    f1 : 0.86257\n",
      "Val    loss : 0.67691    f1 : 0.76222\n",
      "epoch : 7/100    time : 36s/3320s\n",
      "TRAIN    loss : 0.29713    f1 : 0.92260\n",
      "Val    loss : 1.12745    f1 : 0.73479\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 36s/3283s\n",
      "TRAIN    loss : 0.25996    f1 : 0.91522\n",
      "Val    loss : 0.35402    f1 : 0.85171\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 36s/3268s\n",
      "TRAIN    loss : 0.22655    f1 : 0.92449\n",
      "Val    loss : 0.28004    f1 : 0.89095\n",
      "epoch : 10/100    time : 35s/3167s\n",
      "TRAIN    loss : 0.16902    f1 : 0.94211\n",
      "Val    loss : 0.55141    f1 : 0.81680\n",
      "epoch : 11/100    time : 35s/3134s\n",
      "TRAIN    loss : 0.13387    f1 : 0.96110\n",
      "Val    loss : 1.28092    f1 : 0.76650\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 36s/3200s\n",
      "TRAIN    loss : 0.12144    f1 : 0.96434\n",
      "Val    loss : 0.24983    f1 : 0.92514\n",
      "epoch : 13/100    time : 37s/3198s\n",
      "TRAIN    loss : 0.10009    f1 : 0.96568\n",
      "Val    loss : 0.39060    f1 : 0.83324\n",
      "epoch : 14/100    time : 37s/3189s\n",
      "TRAIN    loss : 0.10198    f1 : 0.97157\n",
      "Val    loss : 0.33984    f1 : 0.87991\n",
      "epoch : 15/100    time : 35s/3009s\n",
      "TRAIN    loss : 0.08578    f1 : 0.97093\n",
      "Val    loss : 0.95498    f1 : 0.81628\n",
      "epoch : 16/100    time : 35s/2957s\n",
      "TRAIN    loss : 0.06996    f1 : 0.98066\n",
      "Val    loss : 0.26174    f1 : 0.89166\n",
      "epoch : 17/100    time : 35s/2926s\n",
      "TRAIN    loss : 0.07302    f1 : 0.98025\n",
      "Val    loss : 0.19428    f1 : 0.92513\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/100    time : 35s/2903s\n",
      "TRAIN    loss : 0.04911    f1 : 0.99006\n",
      "Val    loss : 0.21137    f1 : 0.92535\n",
      "epoch : 19/100    time : 35s/2824s\n",
      "TRAIN    loss : 0.06180    f1 : 0.98095\n",
      "Val    loss : 0.36349    f1 : 0.87351\n",
      "epoch : 20/100    time : 35s/2778s\n",
      "TRAIN    loss : 0.06786    f1 : 0.97240\n",
      "Val    loss : 0.25539    f1 : 0.87511\n",
      "epoch : 21/100    time : 35s/2755s\n",
      "TRAIN    loss : 0.05162    f1 : 0.98301\n",
      "Val    loss : 0.26050    f1 : 0.89565\n",
      "epoch : 22/100    time : 35s/2743s\n",
      "TRAIN    loss : 0.05034    f1 : 0.98301\n",
      "Val    loss : 0.21003    f1 : 0.90697\n",
      "epoch : 23/100    time : 35s/2674s\n",
      "TRAIN    loss : 0.08405    f1 : 0.97572\n",
      "Val    loss : 0.36558    f1 : 0.87350\n",
      "-----------------SAVE:24 epoch----------------\n",
      "epoch : 24/100    time : 35s/2638s\n",
      "TRAIN    loss : 0.03857    f1 : 0.99148\n",
      "Val    loss : 0.18862    f1 : 0.93384\n",
      "epoch : 25/100    time : 35s/2612s\n",
      "TRAIN    loss : 0.04691    f1 : 0.97983\n",
      "Val    loss : 0.19099    f1 : 0.92557\n",
      "epoch : 26/100    time : 35s/2568s\n",
      "TRAIN    loss : 0.05306    f1 : 0.98303\n",
      "Val    loss : 0.20457    f1 : 0.93056\n",
      "-----------------SAVE:27 epoch----------------\n",
      "epoch : 27/100    time : 35s/2543s\n",
      "TRAIN    loss : 0.01981    f1 : 0.99858\n",
      "Val    loss : 0.18371    f1 : 0.93660\n",
      "epoch : 28/100    time : 35s/2535s\n",
      "TRAIN    loss : 0.03256    f1 : 0.99153\n",
      "Val    loss : 0.16435    f1 : 0.92916\n",
      "epoch : 29/100    time : 35s/2488s\n",
      "TRAIN    loss : 0.04824    f1 : 0.98434\n",
      "Val    loss : 0.17169    f1 : 0.92199\n",
      "epoch : 30/100    time : 35s/2462s\n",
      "TRAIN    loss : 0.05850    f1 : 0.98159\n",
      "Val    loss : 0.23029    f1 : 0.90094\n",
      "epoch : 31/100    time : 36s/2472s\n",
      "TRAIN    loss : 0.03711    f1 : 0.98866\n",
      "Val    loss : 0.20962    f1 : 0.93007\n",
      "-----------------SAVE:32 epoch----------------\n",
      "epoch : 32/100    time : 36s/2417s\n",
      "TRAIN    loss : 0.03740    f1 : 0.99151\n",
      "Val    loss : 0.17626    f1 : 0.93701\n",
      "epoch : 33/100    time : 36s/2397s\n",
      "TRAIN    loss : 0.02730    f1 : 0.99292\n",
      "Val    loss : 0.22455    f1 : 0.90880\n",
      "epoch : 34/100    time : 35s/2305s\n",
      "TRAIN    loss : 0.01973    f1 : 0.99205\n",
      "Val    loss : 0.20685    f1 : 0.93008\n",
      "epoch : 35/100    time : 35s/2278s\n",
      "TRAIN    loss : 0.01627    f1 : 0.99433\n",
      "Val    loss : 0.22223    f1 : 0.91810\n",
      "epoch : 36/100    time : 35s/2217s\n",
      "TRAIN    loss : 0.01624    f1 : 0.99436\n",
      "Val    loss : 0.22114    f1 : 0.92741\n",
      "epoch : 37/100    time : 35s/2212s\n",
      "TRAIN    loss : 0.01412    f1 : 0.99856\n",
      "Val    loss : 0.18963    f1 : 0.92373\n",
      "epoch : 38/100    time : 34s/2130s\n",
      "TRAIN    loss : 0.01040    f1 : 0.99717\n",
      "Val    loss : 0.21333    f1 : 0.92423\n",
      "epoch : 39/100    time : 35s/2150s\n",
      "TRAIN    loss : 0.00802    f1 : 1.00000\n",
      "Val    loss : 0.20199    f1 : 0.92974\n",
      "epoch : 40/100    time : 35s/2119s\n",
      "TRAIN    loss : 0.00960    f1 : 0.99717\n",
      "Val    loss : 0.18640    f1 : 0.92269\n",
      "epoch : 41/100    time : 35s/2072s\n",
      "TRAIN    loss : 0.01707    f1 : 0.99436\n",
      "Val    loss : 0.18645    f1 : 0.93135\n",
      "epoch : 42/100    time : 35s/2004s\n",
      "TRAIN    loss : 0.03197    f1 : 0.99152\n",
      "Val    loss : 0.21520    f1 : 0.93043\n",
      "epoch : 43/100    time : 35s/1994s\n",
      "TRAIN    loss : 0.01589    f1 : 0.99435\n",
      "Val    loss : 0.19945    f1 : 0.92423\n",
      "-----------------SAVE:44 epoch----------------\n",
      "epoch : 44/100    time : 35s/1975s\n",
      "TRAIN    loss : 0.01384    f1 : 0.99858\n",
      "Val    loss : 0.16981    f1 : 0.94294\n",
      "epoch : 45/100    time : 35s/1934s\n",
      "TRAIN    loss : 0.02051    f1 : 0.99295\n",
      "Val    loss : 0.17790    f1 : 0.93053\n",
      "epoch : 46/100    time : 34s/1863s\n",
      "TRAIN    loss : 0.00820    f1 : 0.99859\n",
      "Val    loss : 0.18787    f1 : 0.92653\n",
      "epoch : 47/100    time : 34s/1808s\n",
      "TRAIN    loss : 0.01628    f1 : 0.99127\n",
      "Val    loss : 0.22856    f1 : 0.90042\n",
      "epoch : 48/100    time : 35s/1832s\n",
      "TRAIN    loss : 0.01213    f1 : 0.99718\n",
      "Val    loss : 0.18589    f1 : 0.93610\n",
      "epoch : 49/100    time : 33s/1676s\n",
      "TRAIN    loss : 0.01041    f1 : 0.99719\n",
      "Val    loss : 0.20970    f1 : 0.93631\n",
      "epoch : 50/100    time : 35s/1754s\n",
      "TRAIN    loss : 0.01502    f1 : 0.99543\n",
      "Val    loss : 0.26935    f1 : 0.93090\n",
      "epoch : 51/100    time : 36s/1740s\n",
      "TRAIN    loss : 0.00955    f1 : 0.99718\n",
      "Val    loss : 0.22625    f1 : 0.92483\n",
      "epoch : 52/100    time : 33s/1599s\n",
      "TRAIN    loss : 0.01716    f1 : 0.99577\n",
      "Val    loss : 0.23383    f1 : 0.93693\n",
      "epoch : 53/100    time : 34s/1581s\n",
      "TRAIN    loss : 0.00417    f1 : 1.00000\n",
      "Val    loss : 0.22848    f1 : 0.92995\n",
      "epoch : 54/100    time : 35s/1603s\n",
      "TRAIN    loss : 0.02007    f1 : 0.99298\n",
      "Val    loss : 0.25063    f1 : 0.91957\n",
      "epoch : 55/100    time : 35s/1556s\n",
      "TRAIN    loss : 0.02426    f1 : 0.99237\n",
      "Val    loss : 0.21132    f1 : 0.94191\n",
      "epoch : 56/100    time : 35s/1524s\n",
      "TRAIN    loss : 0.02595    f1 : 0.99436\n",
      "Val    loss : 0.23569    f1 : 0.94191\n",
      "epoch : 57/100    time : 35s/1496s\n",
      "TRAIN    loss : 0.00379    f1 : 1.00000\n",
      "Val    loss : 0.23980    f1 : 0.91713\n",
      "epoch : 58/100    time : 35s/1469s\n",
      "TRAIN    loss : 0.00486    f1 : 1.00000\n",
      "Val    loss : 0.23381    f1 : 0.94122\n",
      "epoch : 59/100    time : 35s/1433s\n",
      "TRAIN    loss : 0.00625    f1 : 0.99856\n",
      "Val    loss : 0.23614    f1 : 0.93107\n",
      "epoch : 60/100    time : 33s/1330s\n",
      "TRAIN    loss : 0.00259    f1 : 1.00000\n",
      "Val    loss : 0.35278    f1 : 0.88406\n",
      "epoch : 61/100    time : 35s/1357s\n",
      "TRAIN    loss : 0.00926    f1 : 0.99578\n",
      "Val    loss : 0.23010    f1 : 0.91906\n",
      "epoch : 62/100    time : 35s/1330s\n",
      "TRAIN    loss : 0.00873    f1 : 0.99580\n",
      "Val    loss : 0.24981    f1 : 0.91226\n",
      "epoch : 63/100    time : 35s/1287s\n",
      "TRAIN    loss : 0.01405    f1 : 0.99547\n",
      "Val    loss : 0.21984    f1 : 0.91655\n",
      "epoch : 64/100    time : 35s/1257s\n",
      "TRAIN    loss : 0.02602    f1 : 0.99405\n",
      "Val    loss : 0.27064    f1 : 0.89561\n",
      "----------fold_1 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 34s/3393s\n",
      "TRAIN    loss : 2.35632    f1 : 0.19919\n",
      "Val    loss : 1.81152    f1 : 0.35775\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 35s/3459s\n",
      "TRAIN    loss : 1.54996    f1 : 0.48161\n",
      "Val    loss : 1.30282    f1 : 0.51034\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 35s/3411s\n",
      "TRAIN    loss : 1.06820    f1 : 0.65599\n",
      "Val    loss : 0.96688    f1 : 0.65489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 35s/3382s\n",
      "TRAIN    loss : 0.70875    f1 : 0.77039\n",
      "Val    loss : 0.55902    f1 : 0.81215\n",
      "epoch : 5/100    time : 35s/3339s\n",
      "TRAIN    loss : 0.53060    f1 : 0.82940\n",
      "Val    loss : 0.49351    f1 : 0.81140\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 35s/3304s\n",
      "TRAIN    loss : 0.38336    f1 : 0.87076\n",
      "Val    loss : 0.31619    f1 : 0.87030\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 35s/3270s\n",
      "TRAIN    loss : 0.33079    f1 : 0.88915\n",
      "Val    loss : 0.29869    f1 : 0.89670\n",
      "epoch : 8/100    time : 35s/3196s\n",
      "TRAIN    loss : 0.25612    f1 : 0.91590\n",
      "Val    loss : 0.33471    f1 : 0.87351\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 34s/3080s\n",
      "TRAIN    loss : 0.21713    f1 : 0.92295\n",
      "Val    loss : 0.21708    f1 : 0.90535\n",
      "epoch : 10/100    time : 36s/3212s\n",
      "TRAIN    loss : 0.18414    f1 : 0.93483\n",
      "Val    loss : 0.29167    f1 : 0.90360\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 36s/3165s\n",
      "TRAIN    loss : 0.15095    f1 : 0.95439\n",
      "Val    loss : 0.16325    f1 : 0.93475\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 36s/3173s\n",
      "TRAIN    loss : 0.13117    f1 : 0.96172\n",
      "Val    loss : 0.14946    f1 : 0.95394\n",
      "epoch : 13/100    time : 34s/2975s\n",
      "TRAIN    loss : 0.12777    f1 : 0.95834\n",
      "Val    loss : 0.18177    f1 : 0.92525\n",
      "epoch : 14/100    time : 34s/2959s\n",
      "TRAIN    loss : 0.12833    f1 : 0.96359\n",
      "Val    loss : 0.66235    f1 : 0.87343\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/100    time : 35s/2940s\n",
      "TRAIN    loss : 0.09291    f1 : 0.97382\n",
      "Val    loss : 0.11087    f1 : 0.96021\n",
      "epoch : 16/100    time : 34s/2893s\n",
      "TRAIN    loss : 0.07408    f1 : 0.98132\n",
      "Val    loss : 0.58122    f1 : 0.86891\n",
      "-----------------SAVE:17 epoch----------------\n",
      "epoch : 17/100    time : 34s/2836s\n",
      "TRAIN    loss : 0.10510    f1 : 0.96756\n",
      "Val    loss : 0.13429    f1 : 0.96530\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/100    time : 34s/2819s\n",
      "TRAIN    loss : 0.07446    f1 : 0.98102\n",
      "Val    loss : 0.12430    f1 : 0.96594\n",
      "epoch : 19/100    time : 34s/2743s\n",
      "TRAIN    loss : 0.05447    f1 : 0.98153\n",
      "Val    loss : 0.16407    f1 : 0.94291\n",
      "epoch : 20/100    time : 34s/2726s\n",
      "TRAIN    loss : 0.04357    f1 : 0.99013\n",
      "Val    loss : 0.12441    f1 : 0.96538\n",
      "epoch : 21/100    time : 34s/2658s\n",
      "TRAIN    loss : 0.04439    f1 : 0.98860\n",
      "Val    loss : 0.24868    f1 : 0.90867\n",
      "epoch : 22/100    time : 34s/2666s\n",
      "TRAIN    loss : 0.06144    f1 : 0.98445\n",
      "Val    loss : 0.13548    f1 : 0.94832\n",
      "epoch : 23/100    time : 34s/2607s\n",
      "TRAIN    loss : 0.07308    f1 : 0.97531\n",
      "Val    loss : 0.68504    f1 : 0.85700\n",
      "epoch : 24/100    time : 33s/2544s\n",
      "TRAIN    loss : 0.05370    f1 : 0.98860\n",
      "Val    loss : 0.27548    f1 : 0.90299\n",
      "epoch : 25/100    time : 33s/2501s\n",
      "TRAIN    loss : 0.02280    f1 : 0.99433\n",
      "Val    loss : 0.15762    f1 : 0.94259\n",
      "epoch : 26/100    time : 33s/2470s\n",
      "TRAIN    loss : 0.03115    f1 : 0.99149\n",
      "Val    loss : 0.14769    f1 : 0.95394\n",
      "epoch : 27/100    time : 34s/2466s\n",
      "TRAIN    loss : 0.02694    f1 : 0.99129\n",
      "Val    loss : 0.13547    f1 : 0.94807\n",
      "epoch : 28/100    time : 34s/2420s\n",
      "TRAIN    loss : 0.02196    f1 : 0.99711\n",
      "Val    loss : 0.24480    f1 : 0.92052\n",
      "-----------------SAVE:29 epoch----------------\n",
      "epoch : 29/100    time : 34s/2440s\n",
      "TRAIN    loss : 0.03696    f1 : 0.98289\n",
      "Val    loss : 0.15025    f1 : 0.97151\n",
      "epoch : 30/100    time : 34s/2373s\n",
      "TRAIN    loss : 0.03124    f1 : 0.99287\n",
      "Val    loss : 0.13281    f1 : 0.95969\n",
      "epoch : 31/100    time : 34s/2345s\n",
      "TRAIN    loss : 0.02826    f1 : 0.99153\n",
      "Val    loss : 0.36408    f1 : 0.92028\n",
      "epoch : 32/100    time : 34s/2310s\n",
      "TRAIN    loss : 0.02796    f1 : 0.99016\n",
      "Val    loss : 0.14656    f1 : 0.95352\n",
      "epoch : 33/100    time : 34s/2273s\n",
      "TRAIN    loss : 0.01998    f1 : 0.99433\n",
      "Val    loss : 0.26742    f1 : 0.92950\n",
      "epoch : 34/100    time : 35s/2323s\n",
      "TRAIN    loss : 0.01100    f1 : 0.99856\n",
      "Val    loss : 0.36553    f1 : 0.90306\n",
      "epoch : 35/100    time : 36s/2352s\n",
      "TRAIN    loss : 0.03996    f1 : 0.98271\n",
      "Val    loss : 0.18984    f1 : 0.93059\n",
      "epoch : 36/100    time : 33s/2127s\n",
      "TRAIN    loss : 0.03175    f1 : 0.98860\n",
      "Val    loss : 0.13505    f1 : 0.96486\n",
      "epoch : 37/100    time : 34s/2126s\n",
      "TRAIN    loss : 0.02695    f1 : 0.99154\n",
      "Val    loss : 0.19771    f1 : 0.94622\n",
      "epoch : 38/100    time : 34s/2108s\n",
      "TRAIN    loss : 0.02980    f1 : 0.99005\n",
      "Val    loss : 0.20432    f1 : 0.95286\n",
      "epoch : 39/100    time : 34s/2093s\n",
      "TRAIN    loss : 0.01604    f1 : 0.99577\n",
      "Val    loss : 0.18218    f1 : 0.94741\n",
      "epoch : 40/100    time : 33s/1973s\n",
      "TRAIN    loss : 0.03711    f1 : 0.98863\n",
      "Val    loss : 0.15743    f1 : 0.96539\n",
      "epoch : 41/100    time : 34s/1987s\n",
      "TRAIN    loss : 0.02285    f1 : 0.99425\n",
      "Val    loss : 0.15105    f1 : 0.95933\n",
      "epoch : 42/100    time : 34s/1991s\n",
      "TRAIN    loss : 0.01398    f1 : 0.99544\n",
      "Val    loss : 0.17467    f1 : 0.95343\n",
      "epoch : 43/100    time : 31s/1795s\n",
      "TRAIN    loss : 0.00626    f1 : 0.99859\n",
      "Val    loss : 0.15413    f1 : 0.95963\n",
      "epoch : 44/100    time : 34s/1883s\n",
      "TRAIN    loss : 0.01491    f1 : 0.99575\n",
      "Val    loss : 0.14435    f1 : 0.95933\n",
      "epoch : 45/100    time : 36s/1958s\n",
      "TRAIN    loss : 0.01261    f1 : 0.99718\n",
      "Val    loss : 0.14848    f1 : 0.96512\n",
      "epoch : 46/100    time : 34s/1818s\n",
      "TRAIN    loss : 0.01533    f1 : 0.99718\n",
      "Val    loss : 0.25679    f1 : 0.93262\n",
      "epoch : 47/100    time : 33s/1732s\n",
      "TRAIN    loss : 0.02748    f1 : 0.99263\n",
      "Val    loss : 0.15870    f1 : 0.95362\n",
      "epoch : 48/100    time : 35s/1810s\n",
      "TRAIN    loss : 0.01032    f1 : 0.99577\n",
      "Val    loss : 0.10985    f1 : 0.96539\n",
      "-----------------SAVE:49 epoch----------------\n",
      "epoch : 49/100    time : 34s/1723s\n",
      "TRAIN    loss : 0.00614    f1 : 1.00000\n",
      "Val    loss : 0.11813    f1 : 0.97703\n",
      "epoch : 50/100    time : 34s/1684s\n",
      "TRAIN    loss : 0.00633    f1 : 0.99859\n",
      "Val    loss : 0.11972    f1 : 0.97110\n",
      "epoch : 51/100    time : 34s/1667s\n",
      "TRAIN    loss : 0.02119    f1 : 0.98984\n",
      "Val    loss : 0.14929    f1 : 0.95208\n",
      "epoch : 52/100    time : 35s/1683s\n",
      "TRAIN    loss : 0.00670    f1 : 0.99858\n",
      "Val    loss : 0.30851    f1 : 0.91846\n",
      "epoch : 53/100    time : 35s/1630s\n",
      "TRAIN    loss : 0.01012    f1 : 0.99717\n",
      "Val    loss : 0.12275    f1 : 0.95982\n",
      "epoch : 54/100    time : 34s/1578s\n",
      "TRAIN    loss : 0.00643    f1 : 0.99859\n",
      "Val    loss : 0.11068    f1 : 0.96539\n",
      "epoch : 55/100    time : 35s/1563s\n",
      "TRAIN    loss : 0.01508    f1 : 0.99718\n",
      "Val    loss : 0.14820    f1 : 0.95905\n",
      "epoch : 56/100    time : 35s/1520s\n",
      "TRAIN    loss : 0.02061    f1 : 0.99575\n",
      "Val    loss : 0.16662    f1 : 0.95268\n",
      "-----------------SAVE:57 epoch----------------\n",
      "epoch : 57/100    time : 35s/1491s\n",
      "TRAIN    loss : 0.02157    f1 : 0.99263\n",
      "Val    loss : 0.12149    f1 : 0.97717\n",
      "epoch : 58/100    time : 34s/1447s\n",
      "TRAIN    loss : 0.02586    f1 : 0.99010\n",
      "Val    loss : 0.15788    f1 : 0.94088\n",
      "epoch : 59/100    time : 34s/1413s\n",
      "TRAIN    loss : 0.00807    f1 : 0.99858\n",
      "Val    loss : 0.13560    f1 : 0.95963\n",
      "epoch : 60/100    time : 35s/1387s\n",
      "TRAIN    loss : 0.00529    f1 : 0.99858\n",
      "Val    loss : 0.11479    f1 : 0.96574\n",
      "epoch : 61/100    time : 34s/1342s\n",
      "TRAIN    loss : 0.01174    f1 : 0.99718\n",
      "Val    loss : 0.18808    f1 : 0.96030\n",
      "epoch : 62/100    time : 34s/1306s\n",
      "TRAIN    loss : 0.01358    f1 : 0.99571\n",
      "Val    loss : 0.14250    f1 : 0.96009\n",
      "epoch : 63/100    time : 34s/1276s\n",
      "TRAIN    loss : 0.02910    f1 : 0.99433\n",
      "Val    loss : 0.15468    f1 : 0.96574\n",
      "epoch : 64/100    time : 34s/1240s\n",
      "TRAIN    loss : 0.01879    f1 : 0.99381\n",
      "Val    loss : 0.12754    f1 : 0.96574\n",
      "epoch : 65/100    time : 35s/1222s\n",
      "TRAIN    loss : 0.02229    f1 : 0.99127\n",
      "Val    loss : 0.14299    f1 : 0.96539\n",
      "epoch : 66/100    time : 33s/1117s\n",
      "TRAIN    loss : 0.01173    f1 : 0.99546\n",
      "Val    loss : 0.13707    f1 : 0.95963\n",
      "epoch : 67/100    time : 34s/1109s\n",
      "TRAIN    loss : 0.00823    f1 : 0.99577\n",
      "Val    loss : 0.15868    f1 : 0.95407\n",
      "epoch : 68/100    time : 34s/1083s\n",
      "TRAIN    loss : 0.01226    f1 : 0.99576\n",
      "Val    loss : 0.14623    f1 : 0.96500\n",
      "epoch : 69/100    time : 34s/1052s\n",
      "TRAIN    loss : 0.00317    f1 : 1.00000\n",
      "Val    loss : 0.14513    f1 : 0.97717\n",
      "epoch : 70/100    time : 34s/1009s\n",
      "TRAIN    loss : 0.01072    f1 : 0.99718\n",
      "Val    loss : 0.15057    f1 : 0.96490\n",
      "epoch : 71/100    time : 34s/976s\n",
      "TRAIN    loss : 0.00404    f1 : 0.99858\n",
      "Val    loss : 0.13127    f1 : 0.97110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 72/100    time : 33s/928s\n",
      "TRAIN    loss : 0.00230    f1 : 1.00000\n",
      "Val    loss : 0.14592    f1 : 0.96574\n",
      "epoch : 73/100    time : 34s/911s\n",
      "TRAIN    loss : 0.01024    f1 : 0.99716\n",
      "Val    loss : 0.14189    f1 : 0.96539\n",
      "epoch : 74/100    time : 34s/893s\n",
      "TRAIN    loss : 0.00176    f1 : 1.00000\n",
      "Val    loss : 0.15472    f1 : 0.97151\n",
      "-----------------SAVE:75 epoch----------------\n",
      "epoch : 75/100    time : 34s/842s\n",
      "TRAIN    loss : 0.00289    f1 : 1.00000\n",
      "Val    loss : 0.11494    f1 : 0.97722\n",
      "epoch : 76/100    time : 34s/821s\n",
      "TRAIN    loss : 0.00552    f1 : 0.99859\n",
      "Val    loss : 0.13953    f1 : 0.96539\n",
      "epoch : 77/100    time : 34s/780s\n",
      "TRAIN    loss : 0.00746    f1 : 0.99858\n",
      "Val    loss : 0.13248    f1 : 0.97110\n",
      "epoch : 78/100    time : 34s/751s\n",
      "TRAIN    loss : 0.00346    f1 : 1.00000\n",
      "Val    loss : 0.18539    f1 : 0.94846\n",
      "epoch : 79/100    time : 34s/707s\n",
      "TRAIN    loss : 0.00610    f1 : 0.99859\n",
      "Val    loss : 0.14626    f1 : 0.95974\n",
      "epoch : 80/100    time : 33s/654s\n",
      "TRAIN    loss : 0.01085    f1 : 0.99718\n",
      "Val    loss : 0.20949    f1 : 0.95341\n",
      "epoch : 81/100    time : 33s/628s\n",
      "TRAIN    loss : 0.02209    f1 : 0.99262\n",
      "Val    loss : 0.30948    f1 : 0.94840\n",
      "epoch : 82/100    time : 33s/596s\n",
      "TRAIN    loss : 0.00335    f1 : 1.00000\n",
      "Val    loss : 0.26556    f1 : 0.94754\n",
      "epoch : 83/100    time : 33s/560s\n",
      "TRAIN    loss : 0.00725    f1 : 0.99545\n",
      "Val    loss : 0.16989    f1 : 0.96539\n",
      "epoch : 84/100    time : 33s/532s\n",
      "TRAIN    loss : 0.01189    f1 : 0.99576\n",
      "Val    loss : 0.17254    f1 : 0.95348\n",
      "epoch : 85/100    time : 33s/496s\n",
      "TRAIN    loss : 0.00228    f1 : 1.00000\n",
      "Val    loss : 0.16182    f1 : 0.95376\n",
      "epoch : 86/100    time : 33s/465s\n",
      "TRAIN    loss : 0.00215    f1 : 1.00000\n",
      "Val    loss : 0.21444    f1 : 0.94736\n",
      "epoch : 87/100    time : 33s/432s\n",
      "TRAIN    loss : 0.00256    f1 : 0.99858\n",
      "Val    loss : 0.22440    f1 : 0.95974\n",
      "epoch : 88/100    time : 33s/397s\n",
      "TRAIN    loss : 0.00652    f1 : 0.99716\n",
      "Val    loss : 0.18604    f1 : 0.96539\n",
      "epoch : 89/100    time : 34s/369s\n",
      "TRAIN    loss : 0.00687    f1 : 0.99718\n",
      "Val    loss : 0.14725    f1 : 0.96574\n",
      "epoch : 90/100    time : 33s/334s\n",
      "TRAIN    loss : 0.06207    f1 : 0.98864\n",
      "Val    loss : 0.21285    f1 : 0.94262\n",
      "epoch : 91/100    time : 33s/299s\n",
      "TRAIN    loss : 0.01598    f1 : 0.99575\n",
      "Val    loss : 0.19872    f1 : 0.96543\n",
      "epoch : 92/100    time : 33s/265s\n",
      "TRAIN    loss : 0.01307    f1 : 0.99573\n",
      "Val    loss : 0.52499    f1 : 0.93666\n",
      "epoch : 93/100    time : 33s/231s\n",
      "TRAIN    loss : 0.00728    f1 : 0.99859\n",
      "Val    loss : 0.44974    f1 : 0.94300\n",
      "epoch : 94/100    time : 33s/198s\n",
      "TRAIN    loss : 0.03105    f1 : 0.99436\n",
      "Val    loss : 0.71836    f1 : 0.91638\n",
      "epoch : 95/100    time : 33s/165s\n",
      "TRAIN    loss : 0.00201    f1 : 1.00000\n",
      "Val    loss : 0.49394    f1 : 0.94979\n",
      "----------fold_2 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 33s/3223s\n",
      "TRAIN    loss : 2.49919    f1 : 0.16340\n",
      "Val    loss : 2.10689    f1 : 0.28539\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 33s/3259s\n",
      "TRAIN    loss : 1.56240    f1 : 0.47118\n",
      "Val    loss : 1.56618    f1 : 0.50226\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 33s/3242s\n",
      "TRAIN    loss : 0.99377    f1 : 0.69346\n",
      "Val    loss : 1.07355    f1 : 0.64799\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 33s/3149s\n",
      "TRAIN    loss : 0.65631    f1 : 0.78040\n",
      "Val    loss : 1.09157    f1 : 0.69484\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 33s/3139s\n",
      "TRAIN    loss : 0.49332    f1 : 0.86443\n",
      "Val    loss : 0.57425    f1 : 0.81079\n",
      "epoch : 6/100    time : 33s/3076s\n",
      "TRAIN    loss : 0.39895    f1 : 0.87053\n",
      "Val    loss : 0.78333    f1 : 0.79694\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 33s/3096s\n",
      "TRAIN    loss : 0.25550    f1 : 0.91559\n",
      "Val    loss : 0.50495    f1 : 0.84773\n",
      "epoch : 8/100    time : 33s/3028s\n",
      "TRAIN    loss : 0.23802    f1 : 0.93604\n",
      "Val    loss : 0.59255    f1 : 0.82174\n",
      "epoch : 9/100    time : 33s/3030s\n",
      "TRAIN    loss : 0.18057    f1 : 0.93541\n",
      "Val    loss : 1.39445    f1 : 0.73198\n",
      "epoch : 10/100    time : 34s/3046s\n",
      "TRAIN    loss : 0.15637    f1 : 0.95639\n",
      "Val    loss : 0.76921    f1 : 0.82137\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 34s/3032s\n",
      "TRAIN    loss : 0.13689    f1 : 0.95561\n",
      "Val    loss : 0.42136    f1 : 0.84784\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 34s/2987s\n",
      "TRAIN    loss : 0.15202    f1 : 0.94996\n",
      "Val    loss : 0.50257    f1 : 0.87209\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/100    time : 34s/2973s\n",
      "TRAIN    loss : 0.11440    f1 : 0.96078\n",
      "Val    loss : 0.35692    f1 : 0.89750\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/100    time : 34s/2937s\n",
      "TRAIN    loss : 0.12650    f1 : 0.96213\n",
      "Val    loss : 0.32042    f1 : 0.91529\n",
      "epoch : 15/100    time : 33s/2830s\n",
      "TRAIN    loss : 0.06888    f1 : 0.97555\n",
      "Val    loss : 0.39160    f1 : 0.88797\n",
      "epoch : 16/100    time : 34s/2823s\n",
      "TRAIN    loss : 0.05666    f1 : 0.99007\n",
      "Val    loss : 0.32978    f1 : 0.90296\n",
      "-----------------SAVE:17 epoch----------------\n",
      "epoch : 17/100    time : 33s/2749s\n",
      "TRAIN    loss : 0.07952    f1 : 0.97729\n",
      "Val    loss : 0.34146    f1 : 0.92729\n",
      "epoch : 18/100    time : 33s/2717s\n",
      "TRAIN    loss : 0.06154    f1 : 0.97702\n",
      "Val    loss : 0.35604    f1 : 0.89327\n",
      "epoch : 19/100    time : 32s/2576s\n",
      "TRAIN    loss : 0.06842    f1 : 0.98106\n",
      "Val    loss : 0.37837    f1 : 0.90955\n",
      "epoch : 20/100    time : 33s/2629s\n",
      "TRAIN    loss : 0.06457    f1 : 0.97818\n",
      "Val    loss : 0.39316    f1 : 0.89935\n",
      "epoch : 21/100    time : 33s/2591s\n",
      "TRAIN    loss : 0.05507    f1 : 0.98271\n",
      "Val    loss : 0.37631    f1 : 0.90971\n",
      "epoch : 22/100    time : 33s/2586s\n",
      "TRAIN    loss : 0.05168    f1 : 0.98132\n",
      "Val    loss : 0.37555    f1 : 0.90962\n",
      "epoch : 23/100    time : 33s/2563s\n",
      "TRAIN    loss : 0.03534    f1 : 0.98577\n",
      "Val    loss : 0.26283    f1 : 0.91042\n",
      "epoch : 24/100    time : 33s/2492s\n",
      "TRAIN    loss : 0.03750    f1 : 0.99146\n",
      "Val    loss : 1.73324    f1 : 0.80064\n",
      "epoch : 25/100    time : 33s/2457s\n",
      "TRAIN    loss : 0.03016    f1 : 0.99004\n",
      "Val    loss : 1.92995    f1 : 0.80156\n",
      "epoch : 26/100    time : 33s/2424s\n",
      "TRAIN    loss : 0.03715    f1 : 0.99010\n",
      "Val    loss : 1.46837    f1 : 0.82536\n",
      "epoch : 27/100    time : 33s/2394s\n",
      "TRAIN    loss : 0.03300    f1 : 0.99003\n",
      "Val    loss : 0.76482    f1 : 0.87037\n",
      "epoch : 28/100    time : 33s/2344s\n",
      "TRAIN    loss : 0.02875    f1 : 0.99000\n",
      "Val    loss : 1.24199    f1 : 0.83628\n",
      "epoch : 29/100    time : 33s/2328s\n",
      "TRAIN    loss : 0.03143    f1 : 0.99434\n",
      "Val    loss : 0.59113    f1 : 0.89473\n",
      "epoch : 30/100    time : 33s/2283s\n",
      "TRAIN    loss : 0.04383    f1 : 0.98584\n",
      "Val    loss : 0.49943    f1 : 0.90375\n",
      "epoch : 31/100    time : 32s/2240s\n",
      "TRAIN    loss : 0.04251    f1 : 0.98546\n",
      "Val    loss : 1.46803    f1 : 0.84189\n",
      "epoch : 32/100    time : 33s/2226s\n",
      "TRAIN    loss : 0.01852    f1 : 0.99435\n",
      "Val    loss : nan    f1 : 0.68882\n",
      "epoch : 33/100    time : 32s/2132s\n",
      "TRAIN    loss : 0.04169    f1 : 0.98690\n",
      "Val    loss : 0.35384    f1 : 0.90546\n",
      "epoch : 34/100    time : 34s/2216s\n",
      "TRAIN    loss : 0.03337    f1 : 0.98836\n",
      "Val    loss : 2.73465    f1 : 0.79018\n",
      "epoch : 35/100    time : 34s/2198s\n",
      "TRAIN    loss : 0.01049    f1 : 0.99858\n",
      "Val    loss : 0.30878    f1 : 0.91418\n",
      "epoch : 36/100    time : 35s/2218s\n",
      "TRAIN    loss : 0.02916    f1 : 0.98997\n",
      "Val    loss : 0.32145    f1 : 0.91617\n",
      "epoch : 37/100    time : 33s/2105s\n",
      "TRAIN    loss : 0.01816    f1 : 0.99575\n",
      "Val    loss : 0.39086    f1 : 0.89875\n",
      "----------fold_3 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 32s/3205s\n",
      "TRAIN    loss : 2.31165    f1 : 0.21134\n",
      "Val    loss : 2.28760    f1 : 0.23832\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 32s/3112s\n",
      "TRAIN    loss : 1.49154    f1 : 0.50370\n",
      "Val    loss : 1.39131    f1 : 0.54671\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 32s/3146s\n",
      "TRAIN    loss : 1.01146    f1 : 0.69566\n",
      "Val    loss : 1.02104    f1 : 0.65263\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 32s/3087s\n",
      "TRAIN    loss : 0.68057    f1 : 0.77407\n",
      "Val    loss : 0.76940    f1 : 0.80868\n",
      "epoch : 5/100    time : 33s/3089s\n",
      "TRAIN    loss : 0.51075    f1 : 0.84010\n",
      "Val    loss : 1.32530    f1 : 0.69548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 6/100    time : 32s/2965s\n",
      "TRAIN    loss : 0.35047    f1 : 0.88891\n",
      "Val    loss : 0.69736    f1 : 0.80494\n",
      "epoch : 7/100    time : 32s/2944s\n",
      "TRAIN    loss : 0.31351    f1 : 0.90781\n",
      "Val    loss : 1.27798    f1 : 0.76896\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 32s/2965s\n",
      "TRAIN    loss : 0.23258    f1 : 0.92670\n",
      "Val    loss : 0.93233    f1 : 0.81438\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 32s/2913s\n",
      "TRAIN    loss : 0.23100    f1 : 0.93057\n",
      "Val    loss : 0.42235    f1 : 0.87940\n",
      "epoch : 10/100    time : 32s/2862s\n",
      "TRAIN    loss : 0.17909    f1 : 0.94489\n",
      "Val    loss : 0.35237    f1 : 0.87924\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 32s/2847s\n",
      "TRAIN    loss : 0.12048    f1 : 0.96490\n",
      "Val    loss : 0.31516    f1 : 0.88462\n",
      "epoch : 12/100    time : 32s/2831s\n",
      "TRAIN    loss : 0.15720    f1 : 0.94564\n",
      "Val    loss : 0.47351    f1 : 0.86936\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/100    time : 33s/2834s\n",
      "TRAIN    loss : 0.10493    f1 : 0.96260\n",
      "Val    loss : 0.18571    f1 : 0.94726\n",
      "epoch : 14/100    time : 32s/2743s\n",
      "TRAIN    loss : 0.10249    f1 : 0.96941\n",
      "Val    loss : 0.34972    f1 : 0.90093\n",
      "epoch : 15/100    time : 32s/2736s\n",
      "TRAIN    loss : 0.07308    f1 : 0.98145\n",
      "Val    loss : 1.68491    f1 : 0.79678\n",
      "epoch : 16/100    time : 32s/2697s\n",
      "TRAIN    loss : 0.07466    f1 : 0.97840\n",
      "Val    loss : 0.19294    f1 : 0.94183\n",
      "epoch : 17/100    time : 32s/2687s\n",
      "TRAIN    loss : 0.07546    f1 : 0.97410\n",
      "Val    loss : 0.63794    f1 : 0.88373\n",
      "epoch : 18/100    time : 32s/2632s\n",
      "TRAIN    loss : 0.06947    f1 : 0.97817\n",
      "Val    loss : 0.52626    f1 : 0.88319\n",
      "epoch : 19/100    time : 32s/2591s\n",
      "TRAIN    loss : 0.07445    f1 : 0.97118\n",
      "Val    loss : 0.26586    f1 : 0.91268\n",
      "epoch : 20/100    time : 32s/2565s\n",
      "TRAIN    loss : 0.07294    f1 : 0.97828\n",
      "Val    loss : 0.32175    f1 : 0.91069\n",
      "epoch : 21/100    time : 32s/2554s\n",
      "TRAIN    loss : 0.05555    f1 : 0.98264\n",
      "Val    loss : 0.18864    f1 : 0.92541\n",
      "epoch : 22/100    time : 32s/2485s\n",
      "TRAIN    loss : 0.04586    f1 : 0.99000\n",
      "Val    loss : 0.44213    f1 : 0.88848\n",
      "epoch : 23/100    time : 33s/2510s\n",
      "TRAIN    loss : 0.04807    f1 : 0.98288\n",
      "Val    loss : 0.77521    f1 : 0.88199\n",
      "epoch : 24/100    time : 32s/2445s\n",
      "TRAIN    loss : 0.04015    f1 : 0.98406\n",
      "Val    loss : 0.34725    f1 : 0.90849\n",
      "-----------------SAVE:25 epoch----------------\n",
      "epoch : 25/100    time : 33s/2453s\n",
      "TRAIN    loss : 0.05471    f1 : 0.98235\n",
      "Val    loss : 0.13660    f1 : 0.95469\n",
      "epoch : 26/100    time : 32s/2389s\n",
      "TRAIN    loss : 0.04343    f1 : 0.98294\n",
      "Val    loss : 0.33114    f1 : 0.92383\n",
      "epoch : 27/100    time : 32s/2337s\n",
      "TRAIN    loss : 0.03857    f1 : 0.98719\n",
      "Val    loss : 0.41359    f1 : 0.89456\n",
      "epoch : 28/100    time : 32s/2285s\n",
      "TRAIN    loss : 0.06521    f1 : 0.98228\n",
      "Val    loss : 0.81706    f1 : 0.87033\n",
      "epoch : 29/100    time : 32s/2267s\n",
      "TRAIN    loss : 0.01726    f1 : 0.99718\n",
      "Val    loss : 0.20094    f1 : 0.94738\n",
      "epoch : 30/100    time : 32s/2257s\n",
      "TRAIN    loss : 0.01432    f1 : 0.99715\n",
      "Val    loss : 0.32597    f1 : 0.92345\n",
      "epoch : 31/100    time : 32s/2209s\n",
      "TRAIN    loss : 0.02825    f1 : 0.99427\n",
      "Val    loss : 0.25381    f1 : 0.93588\n",
      "epoch : 32/100    time : 32s/2205s\n",
      "TRAIN    loss : 0.02645    f1 : 0.99000\n",
      "Val    loss : 0.68245    f1 : 0.89316\n",
      "epoch : 33/100    time : 32s/2149s\n",
      "TRAIN    loss : 0.02013    f1 : 0.99571\n",
      "Val    loss : 0.15324    f1 : 0.93090\n",
      "epoch : 34/100    time : 32s/2142s\n",
      "TRAIN    loss : 0.03275    f1 : 0.99143\n",
      "Val    loss : 0.56949    f1 : 0.89847\n",
      "epoch : 35/100    time : 32s/2090s\n",
      "TRAIN    loss : 0.03310    f1 : 0.99287\n",
      "Val    loss : 0.52081    f1 : 0.91790\n",
      "epoch : 36/100    time : 32s/2064s\n",
      "TRAIN    loss : 0.01108    f1 : 0.99715\n",
      "Val    loss : 0.22456    f1 : 0.93052\n",
      "epoch : 37/100    time : 32s/2044s\n",
      "TRAIN    loss : 0.01840    f1 : 0.99574\n",
      "Val    loss : 0.44277    f1 : 0.92341\n",
      "epoch : 38/100    time : 32s/2005s\n",
      "TRAIN    loss : 0.01302    f1 : 0.99540\n",
      "Val    loss : 0.24740    f1 : 0.92894\n",
      "epoch : 39/100    time : 32s/1957s\n",
      "TRAIN    loss : 0.02459    f1 : 0.99574\n",
      "Val    loss : 1.49328    f1 : 0.87681\n",
      "epoch : 40/100    time : 32s/1909s\n",
      "TRAIN    loss : 0.03122    f1 : 0.98574\n",
      "Val    loss : 0.19277    f1 : 0.94784\n",
      "epoch : 41/100    time : 33s/1931s\n",
      "TRAIN    loss : 0.02500    f1 : 0.99241\n",
      "Val    loss : 0.14654    f1 : 0.94740\n",
      "epoch : 42/100    time : 33s/1894s\n",
      "TRAIN    loss : 0.01600    f1 : 0.99118\n",
      "Val    loss : 0.64842    f1 : 0.90826\n",
      "epoch : 43/100    time : 32s/1823s\n",
      "TRAIN    loss : 0.01116    f1 : 0.99574\n",
      "Val    loss : 0.25519    f1 : 0.92393\n",
      "epoch : 44/100    time : 32s/1787s\n",
      "TRAIN    loss : 0.02196    f1 : 0.98864\n",
      "Val    loss : 0.21190    f1 : 0.94144\n",
      "epoch : 45/100    time : 32s/1768s\n",
      "TRAIN    loss : 0.02317    f1 : 0.99109\n",
      "Val    loss : 0.25595    f1 : 0.94109\n",
      "----------fold_4 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 33s/3219s\n",
      "TRAIN    loss : 2.36514    f1 : 0.17455\n",
      "Val    loss : 1.90057    f1 : 0.38423\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 35s/3389s\n",
      "TRAIN    loss : 1.59623    f1 : 0.45845\n",
      "Val    loss : 1.40796    f1 : 0.54098\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 34s/3318s\n",
      "TRAIN    loss : 1.03658    f1 : 0.67545\n",
      "Val    loss : 0.78843    f1 : 0.73325\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 34s/3300s\n",
      "TRAIN    loss : 0.70285    f1 : 0.77769\n",
      "Val    loss : 0.97786    f1 : 0.78008\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 34s/3262s\n",
      "TRAIN    loss : 0.48611    f1 : 0.84832\n",
      "Val    loss : 0.46219    f1 : 0.86530\n",
      "epoch : 6/100    time : 35s/3294s\n",
      "TRAIN    loss : 0.37550    f1 : 0.87815\n",
      "Val    loss : 0.45033    f1 : 0.85256\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 34s/3146s\n",
      "TRAIN    loss : 0.29954    f1 : 0.91002\n",
      "Val    loss : 0.38230    f1 : 0.88901\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 34s/3095s\n",
      "TRAIN    loss : 0.23516    f1 : 0.92485\n",
      "Val    loss : 0.48372    f1 : 0.90017\n",
      "epoch : 9/100    time : 35s/3193s\n",
      "TRAIN    loss : 0.21165    f1 : 0.92703\n",
      "Val    loss : 0.38336    f1 : 0.89526\n",
      "epoch : 10/100    time : 33s/2995s\n",
      "TRAIN    loss : 0.15255    f1 : 0.95645\n",
      "Val    loss : 0.77575    f1 : 0.85391\n",
      "epoch : 11/100    time : 33s/2965s\n",
      "TRAIN    loss : 0.14701    f1 : 0.95482\n",
      "Val    loss : nan    f1 : 0.69088\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 33s/2936s\n",
      "TRAIN    loss : 0.12496    f1 : 0.96558\n",
      "Val    loss : 0.19974    f1 : 0.93828\n",
      "epoch : 13/100    time : 33s/2863s\n",
      "TRAIN    loss : 0.11543    f1 : 0.97120\n",
      "Val    loss : 0.55023    f1 : 0.89199\n",
      "epoch : 14/100    time : 33s/2807s\n",
      "TRAIN    loss : 0.11267    f1 : 0.95733\n",
      "Val    loss : 0.94133    f1 : 0.90088\n",
      "epoch : 15/100    time : 32s/2738s\n",
      "TRAIN    loss : 0.07705    f1 : 0.97772\n",
      "Val    loss : 0.35324    f1 : 0.91136\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/100    time : 32s/2710s\n",
      "TRAIN    loss : 0.06948    f1 : 0.98719\n",
      "Val    loss : 0.14596    f1 : 0.95242\n",
      "epoch : 17/100    time : 32s/2652s\n",
      "TRAIN    loss : 0.06682    f1 : 0.98156\n",
      "Val    loss : 1.58551    f1 : 0.86788\n",
      "epoch : 18/100    time : 32s/2643s\n",
      "TRAIN    loss : 0.07417    f1 : 0.97292\n",
      "Val    loss : 1.28543    f1 : 0.86410\n",
      "epoch : 19/100    time : 32s/2600s\n",
      "TRAIN    loss : 0.05784    f1 : 0.98128\n",
      "Val    loss : 0.83346    f1 : 0.91372\n",
      "epoch : 20/100    time : 33s/2601s\n",
      "TRAIN    loss : 0.05288    f1 : 0.98728\n",
      "Val    loss : 0.73560    f1 : 0.91417\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/100    time : 32s/2563s\n",
      "TRAIN    loss : 0.04358    f1 : 0.98866\n",
      "Val    loss : 0.11705    f1 : 0.96512\n",
      "-----------------SAVE:22 epoch----------------\n",
      "epoch : 22/100    time : 36s/2813s\n",
      "TRAIN    loss : 0.04125    f1 : 0.98828\n",
      "Val    loss : 0.12162    f1 : 0.96587\n",
      "epoch : 23/100    time : 34s/2644s\n",
      "TRAIN    loss : 0.02622    f1 : 0.99284\n",
      "Val    loss : 0.16781    f1 : 0.95381\n",
      "epoch : 24/100    time : 34s/2610s\n",
      "TRAIN    loss : 0.05080    f1 : 0.98659\n",
      "Val    loss : 0.76995    f1 : 0.92549\n",
      "epoch : 25/100    time : 34s/2573s\n",
      "TRAIN    loss : 0.04680    f1 : 0.98585\n",
      "Val    loss : 0.17174    f1 : 0.94274\n",
      "epoch : 26/100    time : 34s/2480s\n",
      "TRAIN    loss : 0.03643    f1 : 0.98690\n",
      "Val    loss : 1.54114    f1 : 0.86587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 27/100    time : 34s/2469s\n",
      "TRAIN    loss : 0.04731    f1 : 0.98298\n",
      "Val    loss : 1.47980    f1 : 0.90281\n",
      "epoch : 28/100    time : 34s/2429s\n",
      "TRAIN    loss : 0.02981    f1 : 0.99261\n",
      "Val    loss : 0.62062    f1 : 0.92126\n",
      "epoch : 29/100    time : 34s/2398s\n",
      "TRAIN    loss : 0.02168    f1 : 0.99434\n",
      "Val    loss : 0.69903    f1 : 0.92022\n",
      "epoch : 30/100    time : 34s/2348s\n",
      "TRAIN    loss : 0.03110    f1 : 0.98524\n",
      "Val    loss : 0.14004    f1 : 0.94750\n",
      "epoch : 31/100    time : 33s/2292s\n",
      "TRAIN    loss : 0.03999    f1 : 0.98721\n",
      "Val    loss : 0.95678    f1 : 0.92905\n",
      "epoch : 32/100    time : 34s/2308s\n",
      "TRAIN    loss : 0.04457    f1 : 0.98724\n",
      "Val    loss : 1.36547    f1 : 0.86888\n",
      "epoch : 33/100    time : 34s/2310s\n",
      "TRAIN    loss : 0.03307    f1 : 0.99152\n",
      "Val    loss : 0.86616    f1 : 0.91580\n",
      "epoch : 34/100    time : 35s/2291s\n",
      "TRAIN    loss : 0.02760    f1 : 0.99431\n",
      "Val    loss : 1.27400    f1 : 0.89460\n",
      "epoch : 35/100    time : 33s/2144s\n",
      "TRAIN    loss : 0.03519    f1 : 0.99288\n",
      "Val    loss : 0.71353    f1 : 0.89875\n",
      "epoch : 36/100    time : 33s/2133s\n",
      "TRAIN    loss : 0.01994    f1 : 0.99574\n",
      "Val    loss : 1.12694    f1 : 0.88442\n",
      "epoch : 37/100    time : 34s/2121s\n",
      "TRAIN    loss : 0.02825    f1 : 0.99143\n",
      "Val    loss : 0.18012    f1 : 0.94221\n",
      "epoch : 38/100    time : 33s/2050s\n",
      "TRAIN    loss : 0.01622    f1 : 0.99859\n",
      "Val    loss : 0.24065    f1 : 0.93753\n",
      "epoch : 39/100    time : 32s/1949s\n",
      "TRAIN    loss : 0.01839    f1 : 0.99429\n",
      "Val    loss : 0.53575    f1 : 0.91850\n",
      "epoch : 40/100    time : 33s/1993s\n",
      "TRAIN    loss : 0.01376    f1 : 0.99859\n",
      "Val    loss : 0.62582    f1 : 0.91596\n",
      "-----------------SAVE:41 epoch----------------\n",
      "epoch : 41/100    time : 35s/2061s\n",
      "TRAIN    loss : 0.01321    f1 : 0.99859\n",
      "Val    loss : 0.12191    f1 : 0.96623\n",
      "epoch : 42/100    time : 32s/1866s\n",
      "TRAIN    loss : 0.00776    f1 : 0.99857\n",
      "Val    loss : 0.46830    f1 : 0.92727\n",
      "epoch : 43/100    time : 34s/1958s\n",
      "TRAIN    loss : 0.01832    f1 : 0.99298\n",
      "Val    loss : 0.40248    f1 : 0.92066\n",
      "epoch : 44/100    time : 35s/1935s\n",
      "TRAIN    loss : 0.01197    f1 : 0.99716\n",
      "Val    loss : 0.70485    f1 : 0.90509\n",
      "epoch : 45/100    time : 35s/1902s\n",
      "TRAIN    loss : 0.01517    f1 : 0.99433\n",
      "Val    loss : 0.43502    f1 : 0.93251\n",
      "epoch : 46/100    time : 34s/1852s\n",
      "TRAIN    loss : 0.02647    f1 : 0.99267\n",
      "Val    loss : 0.45000    f1 : 0.93371\n",
      "epoch : 47/100    time : 34s/1828s\n",
      "TRAIN    loss : 0.02011    f1 : 0.99294\n",
      "Val    loss : 0.53637    f1 : 0.92247\n",
      "epoch : 48/100    time : 35s/1824s\n",
      "TRAIN    loss : 0.00983    f1 : 0.99537\n",
      "Val    loss : 1.21792    f1 : 0.91951\n",
      "epoch : 49/100    time : 34s/1755s\n",
      "TRAIN    loss : 0.01449    f1 : 0.99573\n",
      "Val    loss : 0.59404    f1 : 0.92820\n",
      "epoch : 50/100    time : 34s/1713s\n",
      "TRAIN    loss : 0.02641    f1 : 0.99431\n",
      "Val    loss : 0.74370    f1 : 0.92894\n",
      "epoch : 51/100    time : 34s/1664s\n",
      "TRAIN    loss : 0.01343    f1 : 0.99576\n",
      "Val    loss : 0.18506    f1 : 0.93780\n",
      "epoch : 52/100    time : 34s/1608s\n",
      "TRAIN    loss : 0.01815    f1 : 0.99517\n",
      "Val    loss : 0.78136    f1 : 0.90927\n",
      "epoch : 53/100    time : 33s/1551s\n",
      "TRAIN    loss : 0.02133    f1 : 0.99007\n",
      "Val    loss : 0.71379    f1 : 0.88521\n",
      "-----------------SAVE:54 epoch----------------\n",
      "epoch : 54/100    time : 33s/1518s\n",
      "TRAIN    loss : 0.00829    f1 : 0.99715\n",
      "Val    loss : 0.24605    f1 : 0.96640\n",
      "epoch : 55/100    time : 33s/1469s\n",
      "TRAIN    loss : 0.01037    f1 : 0.99714\n",
      "Val    loss : 0.73061    f1 : 0.89236\n",
      "epoch : 56/100    time : 34s/1475s\n",
      "TRAIN    loss : 0.00973    f1 : 0.99717\n",
      "Val    loss : 0.33174    f1 : 0.93132\n",
      "epoch : 57/100    time : 34s/1472s\n",
      "TRAIN    loss : 0.01694    f1 : 0.99578\n",
      "Val    loss : 0.23768    f1 : 0.93713\n",
      "epoch : 58/100    time : 36s/1504s\n",
      "TRAIN    loss : 0.01283    f1 : 0.99296\n",
      "Val    loss : 0.18262    f1 : 0.94413\n",
      "epoch : 59/100    time : 34s/1399s\n",
      "TRAIN    loss : 0.03136    f1 : 0.99289\n",
      "Val    loss : 0.32064    f1 : 0.92138\n",
      "epoch : 60/100    time : 33s/1334s\n",
      "TRAIN    loss : 0.02432    f1 : 0.99113\n",
      "Val    loss : 0.66808    f1 : 0.90333\n",
      "epoch : 61/100    time : 33s/1295s\n",
      "TRAIN    loss : 0.01267    f1 : 0.99717\n",
      "Val    loss : 0.97431    f1 : 0.90445\n",
      "epoch : 62/100    time : 33s/1251s\n",
      "TRAIN    loss : 0.01243    f1 : 0.99579\n",
      "Val    loss : 0.89104    f1 : 0.89067\n",
      "epoch : 63/100    time : 34s/1264s\n",
      "TRAIN    loss : 0.01023    f1 : 0.99720\n",
      "Val    loss : 0.68436    f1 : 0.91943\n",
      "epoch : 64/100    time : 34s/1231s\n",
      "TRAIN    loss : 0.01322    f1 : 0.99580\n",
      "Val    loss : 0.52644    f1 : 0.91554\n",
      "epoch : 65/100    time : 33s/1158s\n",
      "TRAIN    loss : 0.00465    f1 : 0.99859\n",
      "Val    loss : 0.30287    f1 : 0.93157\n",
      "epoch : 66/100    time : 32s/1103s\n",
      "TRAIN    loss : 0.02577    f1 : 0.99292\n",
      "Val    loss : 0.30500    f1 : 0.93814\n",
      "epoch : 67/100    time : 33s/1102s\n",
      "TRAIN    loss : 0.02340    f1 : 0.99115\n",
      "Val    loss : 0.18904    f1 : 0.94382\n",
      "epoch : 68/100    time : 33s/1068s\n",
      "TRAIN    loss : 0.01019    f1 : 0.99713\n",
      "Val    loss : 0.16818    f1 : 0.96484\n",
      "epoch : 69/100    time : 32s/1005s\n",
      "TRAIN    loss : 0.00777    f1 : 0.99714\n",
      "Val    loss : 0.13402    f1 : 0.95951\n",
      "epoch : 70/100    time : 32s/973s\n",
      "TRAIN    loss : 0.01091    f1 : 0.99572\n",
      "Val    loss : 0.19741    f1 : 0.94353\n",
      "epoch : 71/100    time : 32s/918s\n",
      "TRAIN    loss : 0.01502    f1 : 0.99400\n",
      "Val    loss : 0.14990    f1 : 0.95503\n",
      "epoch : 72/100    time : 33s/931s\n",
      "TRAIN    loss : 0.00570    f1 : 0.99825\n",
      "Val    loss : 0.16378    f1 : 0.96568\n",
      "epoch : 73/100    time : 33s/896s\n",
      "TRAIN    loss : 0.00580    f1 : 0.99687\n",
      "Val    loss : 0.15894    f1 : 0.96015\n",
      "epoch : 74/100    time : 34s/885s\n",
      "TRAIN    loss : 0.00216    f1 : 1.00000\n",
      "Val    loss : 0.15568    f1 : 0.95456\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022, shuffle = True)\n",
    "batch_size = 8\n",
    "epochs = 100\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "  print(\"----------fold_{} start!----------\".format(idx))\n",
    "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "  # Train\n",
    "  train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Val\n",
    "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  best=0\n",
    "\n",
    "  model = Network().to(device)\n",
    "\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay = 1e-3)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "  best_f1 = 0\n",
    "  early_stopping = 0\n",
    "  for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss = 0 \n",
    "      val_pred = []\n",
    "      val_y = []\n",
    "      \n",
    "\n",
    "      for batch in (val_loader):\n",
    "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_val = model(x_val)\n",
    "        loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "        val_loss += loss_val.item()/len(val_loader)\n",
    "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "        val_y += y_val.detach().cpu().numpy().tolist()\n",
    "      val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "      if val_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_loss = val_loss\n",
    "        best_f1 = val_f1\n",
    "        early_stopping = 0\n",
    "\n",
    "        torch.save({'epoch':epoch,\n",
    "                    'state_dict':state_dict,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "             }, path +'best_model_{}.pth'.format(idx))\n",
    "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "      else:\n",
    "          early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "      if early_stopping == 20:\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "Jl2OKpQiO5S1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl2OKpQiO5S1",
    "outputId": "e48def07-ef6d-4325-f297-c705088b3eb8"
   },
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 8\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load((path+'best_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "GjsHs-T3SPJq",
   "metadata": {
    "id": "GjsHs-T3SPJq"
   },
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1])+ np.array(pred_ensemble[3]) + np.array(pred_ensemble[4]) )/4\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "UIglTwAV7L54",
   "metadata": {
    "id": "UIglTwAV7L54"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "292QDIS5DOKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "292QDIS5DOKf",
    "outputId": "0e47d38f-d36a-40cd-a925-90e6bce52652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name label\n",
       "0     001.png     1\n",
       "1     002.png     2\n",
       "2     003.png     1\n",
       "3     004.png     6\n",
       "4     005.png     8\n",
       "..        ...   ...\n",
       "210   211.png     5\n",
       "211   212.png     8\n",
       "212   213.png     3\n",
       "213   214.png     6\n",
       "214   215.png     1\n",
       "\n",
       "[215 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"sample_submission.csv\")\n",
    "submission[\"label\"] = f_result\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1naZSLGZ7L55",
   "metadata": {
    "id": "1naZSLGZ7L55"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"submit.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fitted-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSubmitted': True, 'detail': 'Success'}\n"
     ]
    }
   ],
   "source": [
    "# d9249@kyonggi.ac.kr\n",
    "\n",
    "from dacon_submit_api import dacon_submit_api \n",
    "\n",
    "result = dacon_submit_api.post_submission_file(\n",
    "'C:/Users/ideal/Downloads/jupyter/user_data/submit.csv', \n",
    "'02438df9bd0f6300dae6ddea845e7e01d2cb1881849c166bfce504164e1507d5', \n",
    "'235896', \n",
    "'iDeal', \n",
    "'test' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca15b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[BASELINE]_EfficientNet_b3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
