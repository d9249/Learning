{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LlcNsGEk7L5r",
   "metadata": {
    "id": "LlcNsGEk7L5r"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81532144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3',\n",
      " 'bat_resnext26ts',\n",
      " 'beit_base_patch16_224',\n",
      " 'beit_base_patch16_224_in22k',\n",
      " 'beit_base_patch16_384',\n",
      " 'beit_large_patch16_224',\n",
      " 'beit_large_patch16_224_in22k',\n",
      " 'beit_large_patch16_384',\n",
      " 'beit_large_patch16_512',\n",
      " 'botnet26t_256',\n",
      " 'cait_m36_384',\n",
      " 'cait_m48_448',\n",
      " 'cait_s24_224',\n",
      " 'cait_s24_384',\n",
      " 'cait_s36_384',\n",
      " 'cait_xs24_384',\n",
      " 'cait_xxs24_224',\n",
      " 'cait_xxs24_384',\n",
      " 'cait_xxs36_224',\n",
      " 'cait_xxs36_384',\n",
      " 'coat_lite_mini',\n",
      " 'coat_lite_small',\n",
      " 'coat_lite_tiny',\n",
      " 'coat_mini',\n",
      " 'coat_tiny',\n",
      " 'convit_base',\n",
      " 'convit_small',\n",
      " 'convit_tiny',\n",
      " 'convmixer_768_32',\n",
      " 'convmixer_1024_20_ks9_p14',\n",
      " 'convmixer_1536_20',\n",
      " 'convnext_base',\n",
      " 'convnext_base_384_in22ft1k',\n",
      " 'convnext_base_in22ft1k',\n",
      " 'convnext_base_in22k',\n",
      " 'convnext_large',\n",
      " 'convnext_large_384_in22ft1k',\n",
      " 'convnext_large_in22ft1k',\n",
      " 'convnext_large_in22k',\n",
      " 'convnext_small',\n",
      " 'convnext_tiny',\n",
      " 'convnext_xlarge_384_in22ft1k',\n",
      " 'convnext_xlarge_in22ft1k',\n",
      " 'convnext_xlarge_in22k',\n",
      " 'crossvit_9_240',\n",
      " 'crossvit_9_dagger_240',\n",
      " 'crossvit_15_240',\n",
      " 'crossvit_15_dagger_240',\n",
      " 'crossvit_15_dagger_408',\n",
      " 'crossvit_18_240',\n",
      " 'crossvit_18_dagger_240',\n",
      " 'crossvit_18_dagger_408',\n",
      " 'crossvit_base_240',\n",
      " 'crossvit_small_240',\n",
      " 'crossvit_tiny_240',\n",
      " 'cspdarknet53',\n",
      " 'cspresnet50',\n",
      " 'cspresnext50',\n",
      " 'deit_base_distilled_patch16_224',\n",
      " 'deit_base_distilled_patch16_384',\n",
      " 'deit_base_patch16_224',\n",
      " 'deit_base_patch16_384',\n",
      " 'deit_small_distilled_patch16_224',\n",
      " 'deit_small_patch16_224',\n",
      " 'deit_tiny_distilled_patch16_224',\n",
      " 'deit_tiny_patch16_224',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dm_nfnet_f0',\n",
      " 'dm_nfnet_f1',\n",
      " 'dm_nfnet_f2',\n",
      " 'dm_nfnet_f3',\n",
      " 'dm_nfnet_f4',\n",
      " 'dm_nfnet_f5',\n",
      " 'dm_nfnet_f6',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'eca_botnext26ts_256',\n",
      " 'eca_halonext26ts',\n",
      " 'eca_nfnet_l0',\n",
      " 'eca_nfnet_l1',\n",
      " 'eca_nfnet_l2',\n",
      " 'eca_resnet33ts',\n",
      " 'eca_resnext26ts',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b4',\n",
      " 'efficientnet_el',\n",
      " 'efficientnet_el_pruned',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_es_pruned',\n",
      " 'efficientnet_lite0',\n",
      " 'efficientnetv2_rw_m',\n",
      " 'efficientnetv2_rw_s',\n",
      " 'efficientnetv2_rw_t',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'fbnetc_100',\n",
      " 'fbnetv3_b',\n",
      " 'fbnetv3_d',\n",
      " 'fbnetv3_g',\n",
      " 'gc_efficientnetv2_rw_t',\n",
      " 'gcresnet33ts',\n",
      " 'gcresnet50t',\n",
      " 'gcresnext26ts',\n",
      " 'gcresnext50ts',\n",
      " 'gernet_l',\n",
      " 'gernet_m',\n",
      " 'gernet_s',\n",
      " 'ghostnet_100',\n",
      " 'gluon_inception_v3',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_senet154',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'gluon_xception65',\n",
      " 'gmixer_24_224',\n",
      " 'gmlp_s16_224',\n",
      " 'halo2botnet50ts_256',\n",
      " 'halonet26t',\n",
      " 'halonet50ts',\n",
      " 'haloregnetz_b',\n",
      " 'hardcorenas_a',\n",
      " 'hardcorenas_b',\n",
      " 'hardcorenas_c',\n",
      " 'hardcorenas_d',\n",
      " 'hardcorenas_e',\n",
      " 'hardcorenas_f',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w64',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'jx_nest_base',\n",
      " 'jx_nest_small',\n",
      " 'jx_nest_tiny',\n",
      " 'lambda_resnet26rpt_256',\n",
      " 'lambda_resnet26t',\n",
      " 'lambda_resnet50ts',\n",
      " 'lamhalobotnet50ts_256',\n",
      " 'lcnet_050',\n",
      " 'lcnet_075',\n",
      " 'lcnet_100',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'levit_128',\n",
      " 'levit_128s',\n",
      " 'levit_192',\n",
      " 'levit_256',\n",
      " 'levit_384',\n",
      " 'mixer_b16_224',\n",
      " 'mixer_b16_224_in21k',\n",
      " 'mixer_b16_224_miil',\n",
      " 'mixer_b16_224_miil_in21k',\n",
      " 'mixer_l16_224',\n",
      " 'mixer_l16_224_in21k',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mnasnet_100',\n",
      " 'mnasnet_small',\n",
      " 'mobilenetv2_050',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_large_100_miil',\n",
      " 'mobilenetv3_large_100_miil_in21k',\n",
      " 'mobilenetv3_rw',\n",
      " 'nasnetalarge',\n",
      " 'nf_regnet_b1',\n",
      " 'nf_resnet50',\n",
      " 'nfnet_l0',\n",
      " 'pit_b_224',\n",
      " 'pit_b_distilled_224',\n",
      " 'pit_s_224',\n",
      " 'pit_s_distilled_224',\n",
      " 'pit_ti_224',\n",
      " 'pit_ti_distilled_224',\n",
      " 'pit_xs_224',\n",
      " 'pit_xs_distilled_224',\n",
      " 'pnasnet5large',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'regnetz_b16',\n",
      " 'regnetz_c16',\n",
      " 'regnetz_d8',\n",
      " 'regnetz_d32',\n",
      " 'regnetz_e8',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2next50',\n",
      " 'resmlp_12_224',\n",
      " 'resmlp_12_224_dino',\n",
      " 'resmlp_12_distilled_224',\n",
      " 'resmlp_24_224',\n",
      " 'resmlp_24_224_dino',\n",
      " 'resmlp_24_distilled_224',\n",
      " 'resmlp_36_224',\n",
      " 'resmlp_36_distilled_224',\n",
      " 'resmlp_big_24_224',\n",
      " 'resmlp_big_24_224_in22ft1k',\n",
      " 'resmlp_big_24_distilled_224',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet26t',\n",
      " 'resnet32ts',\n",
      " 'resnet33ts',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50_gn',\n",
      " 'resnet50d',\n",
      " 'resnet51q',\n",
      " 'resnet61q',\n",
      " 'resnet101',\n",
      " 'resnet101d',\n",
      " 'resnet152',\n",
      " 'resnet152d',\n",
      " 'resnet200d',\n",
      " 'resnetblur50',\n",
      " 'resnetrs50',\n",
      " 'resnetrs101',\n",
      " 'resnetrs152',\n",
      " 'resnetrs200',\n",
      " 'resnetrs270',\n",
      " 'resnetrs350',\n",
      " 'resnetrs420',\n",
      " 'resnetv2_50',\n",
      " 'resnetv2_50x1_bit_distilled',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bit_teacher',\n",
      " 'resnetv2_152x2_bit_teacher_384',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext26ts',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'sebotnet33ts_256',\n",
      " 'sehalonet33ts',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'semnasnet_075',\n",
      " 'semnasnet_100',\n",
      " 'seresnet33ts',\n",
      " 'seresnet50',\n",
      " 'seresnet152d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext26ts',\n",
      " 'seresnext50_32x4d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swin_base_patch4_window7_224',\n",
      " 'swin_base_patch4_window7_224_in22k',\n",
      " 'swin_base_patch4_window12_384',\n",
      " 'swin_base_patch4_window12_384_in22k',\n",
      " 'swin_large_patch4_window7_224',\n",
      " 'swin_large_patch4_window7_224_in22k',\n",
      " 'swin_large_patch4_window12_384',\n",
      " 'swin_large_patch4_window12_384_in22k',\n",
      " 'swin_small_patch4_window7_224',\n",
      " 'swin_tiny_patch4_window7_224',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b0_ap',\n",
      " 'tf_efficientnet_b0_ns',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b1_ap',\n",
      " 'tf_efficientnet_b1_ns',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b2_ap',\n",
      " 'tf_efficientnet_b2_ns',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b3_ap',\n",
      " 'tf_efficientnet_b3_ns',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b4_ap',\n",
      " 'tf_efficientnet_b4_ns',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b5_ap',\n",
      " 'tf_efficientnet_b5_ns',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b6_ap',\n",
      " 'tf_efficientnet_b6_ns',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b7_ap',\n",
      " 'tf_efficientnet_b7_ns',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_b8_ap',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2_ns',\n",
      " 'tf_efficientnet_l2_ns_475',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_efficientnetv2_b0',\n",
      " 'tf_efficientnetv2_b1',\n",
      " 'tf_efficientnetv2_b2',\n",
      " 'tf_efficientnetv2_b3',\n",
      " 'tf_efficientnetv2_l',\n",
      " 'tf_efficientnetv2_l_in21ft1k',\n",
      " 'tf_efficientnetv2_l_in21k',\n",
      " 'tf_efficientnetv2_m',\n",
      " 'tf_efficientnetv2_m_in21ft1k',\n",
      " 'tf_efficientnetv2_m_in21k',\n",
      " 'tf_efficientnetv2_s',\n",
      " 'tf_efficientnetv2_s_in21ft1k',\n",
      " 'tf_efficientnetv2_s_in21k',\n",
      " 'tf_efficientnetv2_xl_in21ft1k',\n",
      " 'tf_efficientnetv2_xl_in21k',\n",
      " 'tf_inception_v3',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tinynet_a',\n",
      " 'tinynet_b',\n",
      " 'tinynet_c',\n",
      " 'tinynet_d',\n",
      " 'tinynet_e',\n",
      " 'tnt_s_patch16_224',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_m_miil_in21k',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_densenet121',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'twins_pcpvt_base',\n",
      " 'twins_pcpvt_large',\n",
      " 'twins_pcpvt_small',\n",
      " 'twins_svt_base',\n",
      " 'twins_svt_large',\n",
      " 'twins_svt_small',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'visformer_small',\n",
      " 'vit_base_patch8_224',\n",
      " 'vit_base_patch8_224_in21k',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_224_in21k',\n",
      " 'vit_base_patch16_224_miil',\n",
      " 'vit_base_patch16_224_miil_in21k',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch16_sam_224',\n",
      " 'vit_base_patch32_224',\n",
      " 'vit_base_patch32_224_in21k',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_patch32_sam_224',\n",
      " 'vit_base_r50_s16_224_in21k',\n",
      " 'vit_base_r50_s16_384',\n",
      " 'vit_huge_patch14_224_in21k',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_224_in21k',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch32_224_in21k',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_large_r50_s32_224',\n",
      " 'vit_large_r50_s32_224_in21k',\n",
      " 'vit_large_r50_s32_384',\n",
      " 'vit_small_patch16_224',\n",
      " 'vit_small_patch16_224_in21k',\n",
      " 'vit_small_patch16_384',\n",
      " 'vit_small_patch32_224',\n",
      " 'vit_small_patch32_224_in21k',\n",
      " 'vit_small_patch32_384',\n",
      " 'vit_small_r26_s32_224',\n",
      " 'vit_small_r26_s32_224_in21k',\n",
      " 'vit_small_r26_s32_384',\n",
      " 'vit_tiny_patch16_224',\n",
      " 'vit_tiny_patch16_224_in21k',\n",
      " 'vit_tiny_patch16_384',\n",
      " 'vit_tiny_r_s16_p8_224',\n",
      " 'vit_tiny_r_s16_p8_224_in21k',\n",
      " 'vit_tiny_r_s16_p8_384',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception',\n",
      " 'xception41',\n",
      " 'xception65',\n",
      " 'xception71',\n",
      " 'xcit_large_24_p8_224',\n",
      " 'xcit_large_24_p8_224_dist',\n",
      " 'xcit_large_24_p8_384_dist',\n",
      " 'xcit_large_24_p16_224',\n",
      " 'xcit_large_24_p16_224_dist',\n",
      " 'xcit_large_24_p16_384_dist',\n",
      " 'xcit_medium_24_p8_224',\n",
      " 'xcit_medium_24_p8_224_dist',\n",
      " 'xcit_medium_24_p8_384_dist',\n",
      " 'xcit_medium_24_p16_224',\n",
      " 'xcit_medium_24_p16_224_dist',\n",
      " 'xcit_medium_24_p16_384_dist',\n",
      " 'xcit_nano_12_p8_224',\n",
      " 'xcit_nano_12_p8_224_dist',\n",
      " 'xcit_nano_12_p8_384_dist',\n",
      " 'xcit_nano_12_p16_224',\n",
      " 'xcit_nano_12_p16_224_dist',\n",
      " 'xcit_nano_12_p16_384_dist',\n",
      " 'xcit_small_12_p8_224',\n",
      " 'xcit_small_12_p8_224_dist',\n",
      " 'xcit_small_12_p8_384_dist',\n",
      " 'xcit_small_12_p16_224',\n",
      " 'xcit_small_12_p16_224_dist',\n",
      " 'xcit_small_12_p16_384_dist',\n",
      " 'xcit_small_24_p8_224',\n",
      " 'xcit_small_24_p8_224_dist',\n",
      " 'xcit_small_24_p8_384_dist',\n",
      " 'xcit_small_24_p16_224',\n",
      " 'xcit_small_24_p16_224_dist',\n",
      " 'xcit_small_24_p16_384_dist',\n",
      " 'xcit_tiny_12_p8_224',\n",
      " 'xcit_tiny_12_p8_224_dist',\n",
      " 'xcit_tiny_12_p8_384_dist',\n",
      " 'xcit_tiny_12_p16_224',\n",
      " 'xcit_tiny_12_p16_224_dist',\n",
      " 'xcit_tiny_12_p16_384_dist',\n",
      " 'xcit_tiny_24_p8_224',\n",
      " 'xcit_tiny_24_p8_224_dist',\n",
      " 'xcit_tiny_24_p8_384_dist',\n",
      " 'xcit_tiny_24_p16_224',\n",
      " 'xcit_tiny_24_p16_224_dist',\n",
      " 'xcit_tiny_24_p16_384_dist']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lXH5F_hA7uMl",
   "metadata": {
    "id": "lXH5F_hA7uMl"
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/ideal/Downloads/jupyter/user_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "FWntO1VD7L5u",
   "metadata": {
    "id": "FWntO1VD7L5u"
   },
   "outputs": [],
   "source": [
    "train_png = sorted(glob(path + 'train/*.png'))\n",
    "test_png = sorted(glob(path + 'test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atSgPJRn-OCW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atSgPJRn-OCW",
    "outputId": "87b6f90b-5c1c-4a0e-de54-994458543687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(858, 215)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_png), len(test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "xv0_rDVq7L5v",
   "metadata": {
    "id": "xv0_rDVq7L5v"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(path +\"train.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc9232f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0,\n",
       " '10-1': 1,\n",
       " '10-2': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "iMhC0nPw7L5w",
   "metadata": {
    "id": "iMhC0nPw7L5w"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "#     img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "zsmJA3E97L5x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsmJA3E97L5x",
    "outputId": "e0dc61fe-5617-42e8-c8b0-0e95b9f60656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 858/858 [00:00<00:00, 1070.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 215/215 [00:00<00:00, 1080.38it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "KA73Lku9A2N9",
   "metadata": {
    "id": "KA73Lku9A2N9"
   },
   "outputs": [],
   "source": [
    "np.save(path + 'train_imgs_384', np.array(train_imgs))\n",
    "np.save(path + 'test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "L6qBdX7nCp8L",
   "metadata": {
    "id": "L6qBdX7nCp8L"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.load(path + 'train_imgs_384.npy')\n",
    "test_imgs = np.load(path + 'test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9207e10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평균 0.587861452947292 0.5398018372012267 0.4853426659853918\n",
      "train 표준편차 0.15058758283288234 0.15921522386293296 0.17031454681984776\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "train_meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "train_meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "train_meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "train_stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "train_stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "train_stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"train 평균\",train_meanR, train_meanG, train_meanB)\n",
    "print(\"train 표준편차\",train_stdR, train_stdG, train_stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "935064b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 평균 0.5915704246815005 0.5468021681783177 0.49356994941872095\n",
      "test 표준편차 0.15494109227168867 0.1642936360901455 0.1756015391157054\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "test_meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "test_meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "test_meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "test_stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "test_stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "test_stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"test 평균\",test_meanR, test_meanG, test_meanB)\n",
    "print(\"test 표준편차\",test_stdR, test_stdG, test_stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "VFXzojoo7L5y",
   "metadata": {
    "id": "VFXzojoo7L5y"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [train_meanR, train_meanG, train_meanB],\n",
    "                                     std = [train_stdR, train_stdG, train_stdB]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [test_meanR, test_meanG, test_meanB],\n",
    "                                     std = [test_stdR, test_stdG, test_stdB])\n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('resnet34', pretrained=True, num_classes=11)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('resnet34', pretrained=True, num_classes=11)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38qk8sGbYiO_",
   "metadata": {
    "id": "38qk8sGbYiO_"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lkNCkyG9RPzX",
   "metadata": {
    "id": "lkNCkyG9RPzX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet34-43635321.pth\" to C:\\Users\\ideal/.cache\\torch\\hub\\checkpoints\\resnet34-43635321.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 13s/1286s\n",
      "TRAIN    loss : 1.62549    f1 : 0.46980\n",
      "Val    loss : 0.83261    f1 : 0.73444\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 12s/1155s\n",
      "TRAIN    loss : 0.74099    f1 : 0.74982\n",
      "Val    loss : 0.52565    f1 : 0.82016\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 12s/1148s\n",
      "TRAIN    loss : 0.44355    f1 : 0.85748\n",
      "Val    loss : 0.37140    f1 : 0.87893\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 12s/1129s\n",
      "TRAIN    loss : 0.37303    f1 : 0.88726\n",
      "Val    loss : 0.36460    f1 : 0.89435\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 12s/1132s\n",
      "TRAIN    loss : 0.32303    f1 : 0.89617\n",
      "Val    loss : 0.24003    f1 : 0.95311\n",
      "epoch : 6/100    time : 12s/1100s\n",
      "TRAIN    loss : 0.27515    f1 : 0.91505\n",
      "Val    loss : 0.22981    f1 : 0.90527\n",
      "epoch : 7/100    time : 12s/1106s\n",
      "TRAIN    loss : 0.20308    f1 : 0.94206\n",
      "Val    loss : 0.20915    f1 : 0.93573\n",
      "epoch : 8/100    time : 12s/1107s\n",
      "TRAIN    loss : 0.19976    f1 : 0.93786\n",
      "Val    loss : 0.23727    f1 : 0.93469\n",
      "epoch : 9/100    time : 12s/1092s\n",
      "TRAIN    loss : 0.16083    f1 : 0.95305\n",
      "Val    loss : 0.24560    f1 : 0.93776\n",
      "epoch : 10/100    time : 11s/984s\n",
      "TRAIN    loss : 0.20066    f1 : 0.92648\n",
      "Val    loss : 0.18731    f1 : 0.94684\n",
      "epoch : 11/100    time : 11s/1009s\n",
      "TRAIN    loss : 0.14175    f1 : 0.96278\n",
      "Val    loss : 0.27890    f1 : 0.93514\n",
      "epoch : 12/100    time : 11s/979s\n",
      "TRAIN    loss : 0.19777    f1 : 0.93926\n",
      "Val    loss : 0.42046    f1 : 0.86118\n",
      "epoch : 13/100    time : 12s/1021s\n",
      "TRAIN    loss : 0.16885    f1 : 0.94955\n",
      "Val    loss : 0.37720    f1 : 0.89457\n",
      "epoch : 14/100    time : 11s/985s\n",
      "TRAIN    loss : 0.12756    f1 : 0.96577\n",
      "Val    loss : 0.16509    f1 : 0.93909\n",
      "epoch : 15/100    time : 12s/1022s\n",
      "TRAIN    loss : 0.11167    f1 : 0.96981\n",
      "Val    loss : 0.20436    f1 : 0.95177\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/100    time : 12s/1026s\n",
      "TRAIN    loss : 0.10960    f1 : 0.96426\n",
      "Val    loss : 0.12830    f1 : 0.96988\n",
      "epoch : 17/100    time : 12s/975s\n",
      "TRAIN    loss : 0.14679    f1 : 0.95448\n",
      "Val    loss : 0.22718    f1 : 0.93908\n",
      "epoch : 18/100    time : 12s/985s\n",
      "TRAIN    loss : 0.11230    f1 : 0.96388\n",
      "Val    loss : 0.21577    f1 : 0.94556\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/100    time : 12s/995s\n",
      "TRAIN    loss : 0.05641    f1 : 0.98664\n",
      "Val    loss : 0.12029    f1 : 0.97533\n",
      "epoch : 20/100    time : 12s/938s\n",
      "TRAIN    loss : 0.07143    f1 : 0.97594\n",
      "Val    loss : 0.12965    f1 : 0.96456\n",
      "epoch : 21/100    time : 12s/924s\n",
      "TRAIN    loss : 0.06697    f1 : 0.97884\n",
      "Val    loss : 0.13104    f1 : 0.97047\n",
      "epoch : 22/100    time : 12s/912s\n",
      "TRAIN    loss : 0.05470    f1 : 0.98069\n",
      "Val    loss : 0.19925    f1 : 0.94015\n",
      "epoch : 23/100    time : 12s/914s\n",
      "TRAIN    loss : 0.07070    f1 : 0.98028\n",
      "Val    loss : 0.14944    f1 : 0.96464\n",
      "epoch : 24/100    time : 12s/891s\n",
      "TRAIN    loss : 0.07625    f1 : 0.98020\n",
      "Val    loss : 0.22473    f1 : 0.94059\n",
      "epoch : 25/100    time : 12s/899s\n",
      "TRAIN    loss : 0.08411    f1 : 0.97170\n",
      "Val    loss : 0.19315    f1 : 0.94039\n",
      "epoch : 26/100    time : 12s/886s\n",
      "TRAIN    loss : 0.08321    f1 : 0.97734\n",
      "Val    loss : 0.37051    f1 : 0.89300\n",
      "epoch : 27/100    time : 12s/863s\n",
      "TRAIN    loss : 0.01995    f1 : 0.99574\n",
      "Val    loss : 0.27628    f1 : 0.93015\n",
      "epoch : 28/100    time : 12s/844s\n",
      "TRAIN    loss : 0.11914    f1 : 0.96134\n",
      "Val    loss : 0.36285    f1 : 0.87678\n",
      "epoch : 29/100    time : 12s/853s\n",
      "TRAIN    loss : 0.07448    f1 : 0.97865\n",
      "Val    loss : 0.38707    f1 : 0.89461\n",
      "epoch : 30/100    time : 12s/842s\n",
      "TRAIN    loss : 0.16545    f1 : 0.95433\n",
      "Val    loss : 0.27683    f1 : 0.89200\n",
      "epoch : 31/100    time : 12s/833s\n",
      "TRAIN    loss : 0.05256    f1 : 0.98499\n",
      "Val    loss : 0.13844    f1 : 0.94760\n",
      "epoch : 32/100    time : 12s/820s\n",
      "TRAIN    loss : 0.03417    f1 : 0.98972\n",
      "Val    loss : 0.15566    f1 : 0.95914\n",
      "epoch : 33/100    time : 12s/793s\n",
      "TRAIN    loss : 0.02237    f1 : 0.99430\n",
      "Val    loss : 0.36091    f1 : 0.93059\n",
      "epoch : 34/100    time : 12s/797s\n",
      "TRAIN    loss : 0.07730    f1 : 0.97447\n",
      "Val    loss : 0.16384    f1 : 0.95257\n",
      "epoch : 35/100    time : 12s/789s\n",
      "TRAIN    loss : 0.09184    f1 : 0.98005\n",
      "Val    loss : 0.23539    f1 : 0.93981\n",
      "epoch : 36/100    time : 12s/771s\n",
      "TRAIN    loss : 0.03549    f1 : 0.99151\n",
      "Val    loss : 0.26581    f1 : 0.93930\n",
      "epoch : 37/100    time : 12s/769s\n",
      "TRAIN    loss : 0.05502    f1 : 0.98560\n",
      "Val    loss : 0.19198    f1 : 0.93973\n",
      "epoch : 38/100    time : 12s/738s\n",
      "TRAIN    loss : 0.04897    f1 : 0.98688\n",
      "Val    loss : 0.27457    f1 : 0.94199\n",
      "epoch : 39/100    time : 12s/734s\n",
      "TRAIN    loss : 0.05572    f1 : 0.98576\n",
      "Val    loss : 0.18285    f1 : 0.94530\n",
      "----------fold_1 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 12s/1185s\n",
      "TRAIN    loss : 1.71663    f1 : 0.43969\n",
      "Val    loss : 0.85909    f1 : 0.66454\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 12s/1165s\n",
      "TRAIN    loss : 0.81149    f1 : 0.72182\n",
      "Val    loss : 0.52507    f1 : 0.81154\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 12s/1186s\n",
      "TRAIN    loss : 0.52664    f1 : 0.83589\n",
      "Val    loss : 0.45144    f1 : 0.82341\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 11s/1094s\n",
      "TRAIN    loss : 0.41361    f1 : 0.88745\n",
      "Val    loss : 0.36861    f1 : 0.88947\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 12s/1156s\n",
      "TRAIN    loss : 0.27813    f1 : 0.91857\n",
      "Val    loss : 0.23016    f1 : 0.92620\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 11s/1079s\n",
      "TRAIN    loss : 0.28068    f1 : 0.91223\n",
      "Val    loss : 0.19955    f1 : 0.93636\n",
      "epoch : 7/100    time : 12s/1099s\n",
      "TRAIN    loss : 0.28789    f1 : 0.91671\n",
      "Val    loss : 0.26469    f1 : 0.90895\n",
      "epoch : 8/100    time : 12s/1110s\n",
      "TRAIN    loss : 0.23205    f1 : 0.93464\n",
      "Val    loss : 0.13466    f1 : 0.93499\n",
      "epoch : 9/100    time : 12s/1075s\n",
      "TRAIN    loss : 0.15035    f1 : 0.95784\n",
      "Val    loss : 0.21823    f1 : 0.92461\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/100    time : 12s/1083s\n",
      "TRAIN    loss : 0.18315    f1 : 0.94794\n",
      "Val    loss : 0.20174    f1 : 0.95271\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 12s/1067s\n",
      "TRAIN    loss : 0.16123    f1 : 0.95145\n",
      "Val    loss : 0.12502    f1 : 0.95972\n",
      "epoch : 12/100    time : 12s/1033s\n",
      "TRAIN    loss : 0.16939    f1 : 0.95082\n",
      "Val    loss : 0.25718    f1 : 0.94017\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/100    time : 12s/1073s\n",
      "TRAIN    loss : 0.10490    f1 : 0.97569\n",
      "Val    loss : 0.14986    f1 : 0.96455\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/100    time : 12s/1044s\n",
      "TRAIN    loss : 0.14965    f1 : 0.95396\n",
      "Val    loss : 0.13987    f1 : 0.96474\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/100    time : 12s/1003s\n",
      "TRAIN    loss : 0.10004    f1 : 0.96733\n",
      "Val    loss : 0.14519    f1 : 0.97136\n",
      "epoch : 16/100    time : 12s/980s\n",
      "TRAIN    loss : 0.15185    f1 : 0.95212\n",
      "Val    loss : 0.14581    f1 : 0.96525\n",
      "epoch : 17/100    time : 12s/966s\n",
      "TRAIN    loss : 0.08615    f1 : 0.97298\n",
      "Val    loss : 0.52675    f1 : 0.91216\n",
      "epoch : 18/100    time : 12s/965s\n",
      "TRAIN    loss : 0.14643    f1 : 0.96449\n",
      "Val    loss : 0.15038    f1 : 0.96044\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/100    time : 12s/976s\n",
      "TRAIN    loss : 0.07489    f1 : 0.97464\n",
      "Val    loss : 0.11391    f1 : 0.97706\n",
      "epoch : 20/100    time : 12s/924s\n",
      "TRAIN    loss : 0.08412    f1 : 0.97603\n",
      "Val    loss : 0.17512    f1 : 0.94088\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/100    time : 12s/944s\n",
      "TRAIN    loss : 0.03910    f1 : 0.99296\n",
      "Val    loss : 0.07291    f1 : 0.98275\n",
      "epoch : 22/100    time : 12s/902s\n",
      "TRAIN    loss : 0.04761    f1 : 0.98409\n",
      "Val    loss : 0.20025    f1 : 0.94610\n",
      "epoch : 23/100    time : 12s/914s\n",
      "TRAIN    loss : 0.06288    f1 : 0.98440\n",
      "Val    loss : 0.10044    f1 : 0.98275\n",
      "epoch : 24/100    time : 12s/895s\n",
      "TRAIN    loss : 0.09886    f1 : 0.97725\n",
      "Val    loss : 0.12899    f1 : 0.97705\n",
      "epoch : 25/100    time : 12s/895s\n",
      "TRAIN    loss : 0.03868    f1 : 0.99292\n",
      "Val    loss : 0.10533    f1 : 0.97707\n",
      "epoch : 26/100    time : 12s/877s\n",
      "TRAIN    loss : 0.04093    f1 : 0.98999\n",
      "Val    loss : 0.11034    f1 : 0.97685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 27/100    time : 12s/861s\n",
      "TRAIN    loss : 0.02435    f1 : 0.99576\n",
      "Val    loss : 0.19566    f1 : 0.93515\n",
      "epoch : 28/100    time : 12s/855s\n",
      "TRAIN    loss : 0.12828    f1 : 0.96459\n",
      "Val    loss : 0.09855    f1 : 0.97065\n",
      "epoch : 29/100    time : 12s/846s\n",
      "TRAIN    loss : 0.06798    f1 : 0.98267\n",
      "Val    loss : 0.31467    f1 : 0.89667\n",
      "epoch : 30/100    time : 12s/823s\n",
      "TRAIN    loss : 0.07544    f1 : 0.98132\n",
      "Val    loss : 0.10229    f1 : 0.96336\n",
      "epoch : 31/100    time : 13s/868s\n",
      "TRAIN    loss : 0.09633    f1 : 0.97394\n",
      "Val    loss : 0.15915    f1 : 0.92255\n",
      "epoch : 32/100    time : 15s/1038s\n",
      "TRAIN    loss : 0.12344    f1 : 0.96652\n",
      "Val    loss : 0.17586    f1 : 0.94030\n",
      "epoch : 33/100    time : 16s/1048s\n",
      "TRAIN    loss : 0.07641    f1 : 0.97872\n",
      "Val    loss : 0.14567    f1 : 0.96569\n",
      "epoch : 34/100    time : 15s/986s\n",
      "TRAIN    loss : 0.06917    f1 : 0.97956\n",
      "Val    loss : 0.41461    f1 : 0.90472\n",
      "epoch : 35/100    time : 15s/1002s\n",
      "TRAIN    loss : 0.08374    f1 : 0.98146\n",
      "Val    loss : 0.15504    f1 : 0.96050\n",
      "epoch : 36/100    time : 16s/996s\n",
      "TRAIN    loss : 0.07578    f1 : 0.97584\n",
      "Val    loss : 0.14679    f1 : 0.95912\n",
      "epoch : 37/100    time : 15s/972s\n",
      "TRAIN    loss : 0.07056    f1 : 0.98304\n",
      "Val    loss : 0.14361    f1 : 0.96005\n",
      "epoch : 38/100    time : 15s/934s\n",
      "TRAIN    loss : 0.05508    f1 : 0.98836\n",
      "Val    loss : 0.14539    f1 : 0.94006\n",
      "epoch : 39/100    time : 16s/952s\n",
      "TRAIN    loss : 0.03768    f1 : 0.98833\n",
      "Val    loss : 0.12360    f1 : 0.96543\n",
      "epoch : 40/100    time : 16s/948s\n",
      "TRAIN    loss : 0.05580    f1 : 0.98295\n",
      "Val    loss : 0.17321    f1 : 0.96024\n",
      "epoch : 41/100    time : 15s/893s\n",
      "TRAIN    loss : 0.07373    f1 : 0.98165\n",
      "Val    loss : 0.16343    f1 : 0.96523\n",
      "----------fold_2 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 16s/1598s\n",
      "TRAIN    loss : 1.60183    f1 : 0.46899\n",
      "Val    loss : 0.77134    f1 : 0.75664\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 17s/1624s\n",
      "TRAIN    loss : 0.66847    f1 : 0.78192\n",
      "Val    loss : 0.52739    f1 : 0.80503\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 16s/1580s\n",
      "TRAIN    loss : 0.50505    f1 : 0.83048\n",
      "Val    loss : 0.44859    f1 : 0.86390\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 15s/1453s\n",
      "TRAIN    loss : 0.40805    f1 : 0.85822\n",
      "Val    loss : 0.26947    f1 : 0.93222\n",
      "epoch : 5/100    time : 15s/1470s\n",
      "TRAIN    loss : 0.25256    f1 : 0.93266\n",
      "Val    loss : 0.33598    f1 : 0.91580\n",
      "epoch : 6/100    time : 15s/1426s\n",
      "TRAIN    loss : 0.31280    f1 : 0.90942\n",
      "Val    loss : 0.25657    f1 : 0.92314\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 16s/1451s\n",
      "TRAIN    loss : 0.25126    f1 : 0.92475\n",
      "Val    loss : 0.16264    f1 : 0.95007\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 17s/1568s\n",
      "TRAIN    loss : 0.17034    f1 : 0.94896\n",
      "Val    loss : 0.13280    f1 : 0.97046\n",
      "epoch : 9/100    time : 18s/1666s\n",
      "TRAIN    loss : 0.24243    f1 : 0.93049\n",
      "Val    loss : 0.29165    f1 : 0.88991\n",
      "epoch : 10/100    time : 18s/1607s\n",
      "TRAIN    loss : 0.15632    f1 : 0.94996\n",
      "Val    loss : 0.22450    f1 : 0.93852\n",
      "epoch : 11/100    time : 18s/1634s\n",
      "TRAIN    loss : 0.16196    f1 : 0.95172\n",
      "Val    loss : 0.20125    f1 : 0.92977\n",
      "epoch : 12/100    time : 18s/1599s\n",
      "TRAIN    loss : 0.11123    f1 : 0.96981\n",
      "Val    loss : 0.22099    f1 : 0.93786\n",
      "epoch : 13/100    time : 17s/1504s\n",
      "TRAIN    loss : 0.10895    f1 : 0.96908\n",
      "Val    loss : 0.22996    f1 : 0.92101\n",
      "epoch : 14/100    time : 17s/1491s\n",
      "TRAIN    loss : 0.09936    f1 : 0.97163\n",
      "Val    loss : 0.19883    f1 : 0.94912\n",
      "epoch : 15/100    time : 17s/1446s\n",
      "TRAIN    loss : 0.12083    f1 : 0.96682\n",
      "Val    loss : 0.33977    f1 : 0.92406\n",
      "epoch : 16/100    time : 16s/1368s\n",
      "TRAIN    loss : 0.10962    f1 : 0.96573\n",
      "Val    loss : 0.16794    f1 : 0.95462\n",
      "epoch : 17/100    time : 15s/1238s\n",
      "TRAIN    loss : 0.07297    f1 : 0.98594\n",
      "Val    loss : 0.16623    f1 : 0.96599\n",
      "epoch : 18/100    time : 16s/1272s\n",
      "TRAIN    loss : 0.04568    f1 : 0.98589\n",
      "Val    loss : 0.15631    f1 : 0.96068\n",
      "epoch : 19/100    time : 15s/1218s\n",
      "TRAIN    loss : 0.04385    f1 : 0.98865\n",
      "Val    loss : 0.10835    f1 : 0.95335\n",
      "epoch : 20/100    time : 15s/1195s\n",
      "TRAIN    loss : 0.07653    f1 : 0.97873\n",
      "Val    loss : 0.21739    f1 : 0.92686\n",
      "epoch : 21/100    time : 15s/1184s\n",
      "TRAIN    loss : 0.06469    f1 : 0.98156\n",
      "Val    loss : 0.13472    f1 : 0.94706\n",
      "epoch : 22/100    time : 15s/1134s\n",
      "TRAIN    loss : 0.08982    f1 : 0.98151\n",
      "Val    loss : 0.24215    f1 : 0.92025\n",
      "epoch : 23/100    time : 16s/1196s\n",
      "TRAIN    loss : 0.05312    f1 : 0.99004\n",
      "Val    loss : 0.16968    f1 : 0.94758\n",
      "epoch : 24/100    time : 15s/1133s\n",
      "TRAIN    loss : 0.05736    f1 : 0.98441\n",
      "Val    loss : 0.18582    f1 : 0.93916\n",
      "epoch : 25/100    time : 14s/1087s\n",
      "TRAIN    loss : 0.07748    f1 : 0.97427\n",
      "Val    loss : 0.30757    f1 : 0.91549\n",
      "epoch : 26/100    time : 15s/1094s\n",
      "TRAIN    loss : 0.10430    f1 : 0.96962\n",
      "Val    loss : 0.15718    f1 : 0.95511\n",
      "epoch : 27/100    time : 15s/1101s\n",
      "TRAIN    loss : 0.12192    f1 : 0.97152\n",
      "Val    loss : 0.21172    f1 : 0.93258\n",
      "epoch : 28/100    time : 15s/1066s\n",
      "TRAIN    loss : 0.09723    f1 : 0.97611\n",
      "Val    loss : 0.33589    f1 : 0.88019\n",
      "----------fold_3 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 15s/1526s\n",
      "TRAIN    loss : 1.59762    f1 : 0.45515\n",
      "Val    loss : 0.80432    f1 : 0.70404\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 15s/1513s\n",
      "TRAIN    loss : 0.70162    f1 : 0.77567\n",
      "Val    loss : 0.66231    f1 : 0.75441\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 15s/1467s\n",
      "TRAIN    loss : 0.52235    f1 : 0.84041\n",
      "Val    loss : 0.43889    f1 : 0.80994\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 17s/1621s\n",
      "TRAIN    loss : 0.47260    f1 : 0.85316\n",
      "Val    loss : 0.46520    f1 : 0.82751\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/100    time : 16s/1521s\n",
      "TRAIN    loss : 0.32109    f1 : 0.89756\n",
      "Val    loss : 0.21715    f1 : 0.90987\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/100    time : 15s/1392s\n",
      "TRAIN    loss : 0.23257    f1 : 0.93540\n",
      "Val    loss : 0.37072    f1 : 0.90989\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 15s/1439s\n",
      "TRAIN    loss : 0.32275    f1 : 0.89048\n",
      "Val    loss : 0.18870    f1 : 0.93686\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/100    time : 15s/1414s\n",
      "TRAIN    loss : 0.24106    f1 : 0.93312\n",
      "Val    loss : 0.26274    f1 : 0.94786\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/100    time : 15s/1410s\n",
      "TRAIN    loss : 0.17458    f1 : 0.95331\n",
      "Val    loss : 0.11195    f1 : 0.96639\n",
      "epoch : 10/100    time : 15s/1336s\n",
      "TRAIN    loss : 0.17676    f1 : 0.95683\n",
      "Val    loss : 0.31961    f1 : 0.87306\n",
      "epoch : 11/100    time : 15s/1378s\n",
      "TRAIN    loss : 0.15431    f1 : 0.95491\n",
      "Val    loss : 0.16475    f1 : 0.94170\n",
      "epoch : 12/100    time : 15s/1306s\n",
      "TRAIN    loss : 0.17678    f1 : 0.94516\n",
      "Val    loss : 0.17012    f1 : 0.92518\n",
      "epoch : 13/100    time : 15s/1293s\n",
      "TRAIN    loss : 0.13961    f1 : 0.95378\n",
      "Val    loss : 0.13606    f1 : 0.96513\n",
      "epoch : 14/100    time : 15s/1289s\n",
      "TRAIN    loss : 0.09380    f1 : 0.97171\n",
      "Val    loss : 0.15844    f1 : 0.96379\n",
      "epoch : 15/100    time : 15s/1251s\n",
      "TRAIN    loss : 0.05151    f1 : 0.98835\n",
      "Val    loss : 0.18640    f1 : 0.95189\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/100    time : 15s/1301s\n",
      "TRAIN    loss : 0.07044    f1 : 0.98089\n",
      "Val    loss : 0.12392    f1 : 0.97208\n",
      "epoch : 17/100    time : 15s/1223s\n",
      "TRAIN    loss : 0.09307    f1 : 0.97857\n",
      "Val    loss : 0.10343    f1 : 0.96068\n",
      "epoch : 18/100    time : 15s/1222s\n",
      "TRAIN    loss : 0.09310    f1 : 0.97177\n",
      "Val    loss : 0.09710    f1 : 0.96088\n",
      "epoch : 19/100    time : 16s/1290s\n",
      "TRAIN    loss : 0.11338    f1 : 0.96870\n",
      "Val    loss : 0.11009    f1 : 0.96028\n",
      "epoch : 20/100    time : 15s/1201s\n",
      "TRAIN    loss : 0.08858    f1 : 0.97230\n",
      "Val    loss : 0.16942    f1 : 0.94868\n",
      "epoch : 21/100    time : 15s/1149s\n",
      "TRAIN    loss : 0.16073    f1 : 0.95793\n",
      "Val    loss : 0.16233    f1 : 0.95329\n",
      "-----------------SAVE:22 epoch----------------\n",
      "epoch : 22/100    time : 15s/1193s\n",
      "TRAIN    loss : 0.06550    f1 : 0.98055\n",
      "Val    loss : 0.16468    f1 : 0.97211\n",
      "-----------------SAVE:23 epoch----------------\n",
      "epoch : 23/100    time : 16s/1194s\n",
      "TRAIN    loss : 0.05827    f1 : 0.99285\n",
      "Val    loss : 0.09055    f1 : 0.97756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:24 epoch----------------\n",
      "epoch : 24/100    time : 16s/1184s\n",
      "TRAIN    loss : 0.01862    f1 : 0.99713\n",
      "Val    loss : 0.07336    f1 : 0.98328\n",
      "epoch : 25/100    time : 15s/1126s\n",
      "TRAIN    loss : 0.06202    f1 : 0.98288\n",
      "Val    loss : 0.30920    f1 : 0.91785\n",
      "epoch : 26/100    time : 16s/1200s\n",
      "TRAIN    loss : 0.07327    f1 : 0.98291\n",
      "Val    loss : 0.11544    f1 : 0.97794\n",
      "-----------------SAVE:27 epoch----------------\n",
      "epoch : 27/100    time : 15s/1088s\n",
      "TRAIN    loss : 0.04200    f1 : 0.98969\n",
      "Val    loss : 0.13004    f1 : 0.98344\n",
      "epoch : 28/100    time : 15s/1092s\n",
      "TRAIN    loss : 0.06239    f1 : 0.97981\n",
      "Val    loss : 0.18661    f1 : 0.94154\n",
      "epoch : 29/100    time : 15s/1078s\n",
      "TRAIN    loss : 0.10459    f1 : 0.97007\n",
      "Val    loss : 0.18848    f1 : 0.93516\n",
      "epoch : 30/100    time : 15s/1039s\n",
      "TRAIN    loss : 0.08948    f1 : 0.97497\n",
      "Val    loss : 0.15702    f1 : 0.96096\n",
      "epoch : 31/100    time : 15s/1039s\n",
      "TRAIN    loss : 0.06209    f1 : 0.98416\n",
      "Val    loss : 0.22395    f1 : 0.94267\n",
      "epoch : 32/100    time : 15s/1022s\n",
      "TRAIN    loss : 0.12910    f1 : 0.96434\n",
      "Val    loss : 0.13725    f1 : 0.95571\n",
      "epoch : 33/100    time : 15s/1000s\n",
      "TRAIN    loss : 0.09022    f1 : 0.97553\n",
      "Val    loss : 0.20779    f1 : 0.94875\n",
      "epoch : 34/100    time : 16s/1046s\n",
      "TRAIN    loss : 0.07856    f1 : 0.98238\n",
      "Val    loss : 0.13239    f1 : 0.96680\n",
      "epoch : 35/100    time : 15s/963s\n",
      "TRAIN    loss : 0.09056    f1 : 0.97293\n",
      "Val    loss : 0.11066    f1 : 0.95352\n",
      "epoch : 36/100    time : 15s/979s\n",
      "TRAIN    loss : 0.02755    f1 : 0.99433\n",
      "Val    loss : 0.10516    f1 : 0.96531\n",
      "epoch : 37/100    time : 15s/956s\n",
      "TRAIN    loss : 0.05072    f1 : 0.98869\n",
      "Val    loss : 0.18378    f1 : 0.97159\n",
      "epoch : 38/100    time : 15s/937s\n",
      "TRAIN    loss : 0.05870    f1 : 0.98435\n",
      "Val    loss : 0.23188    f1 : 0.93775\n",
      "epoch : 39/100    time : 15s/942s\n",
      "TRAIN    loss : 0.02368    f1 : 0.99427\n",
      "Val    loss : 0.09683    f1 : 0.98344\n",
      "epoch : 40/100    time : 15s/886s\n",
      "TRAIN    loss : 0.01501    f1 : 0.99575\n",
      "Val    loss : 0.12412    f1 : 0.95952\n",
      "epoch : 41/100    time : 15s/867s\n",
      "TRAIN    loss : 0.03660    f1 : 0.98968\n",
      "Val    loss : 0.23414    f1 : 0.94809\n",
      "epoch : 42/100    time : 15s/852s\n",
      "TRAIN    loss : 0.03614    f1 : 0.99287\n",
      "Val    loss : 0.12999    f1 : 0.97668\n",
      "epoch : 43/100    time : 16s/884s\n",
      "TRAIN    loss : 0.02614    f1 : 0.99435\n",
      "Val    loss : 0.18466    f1 : 0.96096\n",
      "epoch : 44/100    time : 15s/819s\n",
      "TRAIN    loss : 0.03976    f1 : 0.98723\n",
      "Val    loss : 0.08935    f1 : 0.98344\n",
      "epoch : 45/100    time : 15s/814s\n",
      "TRAIN    loss : 0.04326    f1 : 0.98523\n",
      "Val    loss : 0.13355    f1 : 0.95406\n",
      "epoch : 46/100    time : 15s/809s\n",
      "TRAIN    loss : 0.04393    f1 : 0.98977\n",
      "Val    loss : 0.13336    f1 : 0.97775\n",
      "epoch : 47/100    time : 16s/829s\n",
      "TRAIN    loss : 0.06798    f1 : 0.98153\n",
      "Val    loss : 0.14379    f1 : 0.96648\n",
      "----------fold_4 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/100    time : 17s/1703s\n",
      "TRAIN    loss : 1.62203    f1 : 0.46050\n",
      "Val    loss : 0.86879    f1 : 0.68266\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/100    time : 16s/1527s\n",
      "TRAIN    loss : 0.69892    f1 : 0.77942\n",
      "Val    loss : 0.55034    f1 : 0.81309\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/100    time : 15s/1462s\n",
      "TRAIN    loss : 0.45026    f1 : 0.85784\n",
      "Val    loss : 0.41687    f1 : 0.85680\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/100    time : 16s/1571s\n",
      "TRAIN    loss : 0.42543    f1 : 0.86460\n",
      "Val    loss : 0.33257    f1 : 0.88599\n",
      "epoch : 5/100    time : 17s/1586s\n",
      "TRAIN    loss : 0.32666    f1 : 0.91126\n",
      "Val    loss : 0.37748    f1 : 0.85253\n",
      "epoch : 6/100    time : 15s/1451s\n",
      "TRAIN    loss : 0.25830    f1 : 0.92120\n",
      "Val    loss : 0.34852    f1 : 0.85795\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/100    time : 15s/1397s\n",
      "TRAIN    loss : 0.26000    f1 : 0.92261\n",
      "Val    loss : 0.18929    f1 : 0.93954\n",
      "epoch : 8/100    time : 14s/1287s\n",
      "TRAIN    loss : 0.17409    f1 : 0.95380\n",
      "Val    loss : 0.27022    f1 : 0.89104\n",
      "epoch : 9/100    time : 11s/1036s\n",
      "TRAIN    loss : 0.16128    f1 : 0.95138\n",
      "Val    loss : 0.22603    f1 : 0.90715\n",
      "epoch : 10/100    time : 11s/1024s\n",
      "TRAIN    loss : 0.20014    f1 : 0.94859\n",
      "Val    loss : 0.25602    f1 : 0.92268\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 11/100    time : 12s/1061s\n",
      "TRAIN    loss : 0.13228    f1 : 0.96130\n",
      "Val    loss : 0.15163    f1 : 0.95369\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/100    time : 12s/1021s\n",
      "TRAIN    loss : 0.10840    f1 : 0.96615\n",
      "Val    loss : 0.09699    f1 : 0.96502\n",
      "epoch : 13/100    time : 11s/1000s\n",
      "TRAIN    loss : 0.09413    f1 : 0.97575\n",
      "Val    loss : 0.20842    f1 : 0.95425\n",
      "epoch : 14/100    time : 12s/1013s\n",
      "TRAIN    loss : 0.11226    f1 : 0.96606\n",
      "Val    loss : 0.22348    f1 : 0.91774\n",
      "epoch : 15/100    time : 12s/1010s\n",
      "TRAIN    loss : 0.11633    f1 : 0.96999\n",
      "Val    loss : 0.35371    f1 : 0.90403\n",
      "epoch : 16/100    time : 12s/977s\n",
      "TRAIN    loss : 0.09491    f1 : 0.96983\n",
      "Val    loss : 0.15148    f1 : 0.95943\n",
      "epoch : 17/100    time : 12s/969s\n",
      "TRAIN    loss : 0.14242    f1 : 0.95710\n",
      "Val    loss : 0.41311    f1 : 0.93972\n",
      "epoch : 18/100    time : 12s/975s\n",
      "TRAIN    loss : 0.13451    f1 : 0.95570\n",
      "Val    loss : 0.20061    f1 : 0.94530\n",
      "epoch : 19/100    time : 12s/959s\n",
      "TRAIN    loss : 0.07165    f1 : 0.97956\n",
      "Val    loss : 0.19473    f1 : 0.92865\n",
      "epoch : 20/100    time : 12s/937s\n",
      "TRAIN    loss : 0.08705    f1 : 0.97449\n",
      "Val    loss : 0.10590    f1 : 0.96406\n",
      "epoch : 21/100    time : 12s/923s\n",
      "TRAIN    loss : 0.08004    f1 : 0.98148\n",
      "Val    loss : 0.15562    f1 : 0.94195\n",
      "-----------------SAVE:22 epoch----------------\n",
      "epoch : 22/100    time : 12s/939s\n",
      "TRAIN    loss : 0.06677    f1 : 0.98269\n",
      "Val    loss : 0.12269    f1 : 0.96854\n",
      "epoch : 23/100    time : 11s/879s\n",
      "TRAIN    loss : 0.05599    f1 : 0.98716\n",
      "Val    loss : 0.11209    f1 : 0.96444\n",
      "epoch : 24/100    time : 12s/891s\n",
      "TRAIN    loss : 0.05665    f1 : 0.98292\n",
      "Val    loss : 0.13148    f1 : 0.96406\n",
      "epoch : 25/100    time : 12s/896s\n",
      "TRAIN    loss : 0.08718    f1 : 0.97595\n",
      "Val    loss : 0.30925    f1 : 0.89335\n",
      "epoch : 26/100    time : 12s/887s\n",
      "TRAIN    loss : 0.07159    f1 : 0.98161\n",
      "Val    loss : 0.19657    f1 : 0.92213\n",
      "epoch : 27/100    time : 12s/865s\n",
      "TRAIN    loss : 0.04677    f1 : 0.98239\n",
      "Val    loss : 0.18788    f1 : 0.94290\n",
      "-----------------SAVE:28 epoch----------------\n",
      "epoch : 28/100    time : 12s/858s\n",
      "TRAIN    loss : 0.10461    f1 : 0.97325\n",
      "Val    loss : 0.09570    f1 : 0.97570\n",
      "epoch : 29/100    time : 12s/819s\n",
      "TRAIN    loss : 0.08566    f1 : 0.97487\n",
      "Val    loss : 0.27322    f1 : 0.92110\n",
      "epoch : 30/100    time : 12s/827s\n",
      "TRAIN    loss : 0.05741    f1 : 0.98396\n",
      "Val    loss : 0.10732    f1 : 0.96571\n",
      "epoch : 31/100    time : 12s/821s\n",
      "TRAIN    loss : 0.10301    f1 : 0.97317\n",
      "Val    loss : 0.16117    f1 : 0.96435\n",
      "epoch : 32/100    time : 12s/803s\n",
      "TRAIN    loss : 0.08209    f1 : 0.97588\n",
      "Val    loss : 0.11947    f1 : 0.95867\n",
      "epoch : 33/100    time : 12s/790s\n",
      "TRAIN    loss : 0.08883    f1 : 0.97170\n",
      "Val    loss : 0.20415    f1 : 0.95142\n",
      "epoch : 34/100    time : 12s/780s\n",
      "TRAIN    loss : 0.05976    f1 : 0.98021\n",
      "Val    loss : 0.20236    f1 : 0.94802\n",
      "epoch : 35/100    time : 12s/781s\n",
      "TRAIN    loss : 0.05117    f1 : 0.98700\n",
      "Val    loss : 0.16908    f1 : 0.96434\n",
      "epoch : 36/100    time : 12s/768s\n",
      "TRAIN    loss : 0.05106    f1 : 0.98581\n",
      "Val    loss : 0.12526    f1 : 0.97137\n",
      "epoch : 37/100    time : 12s/752s\n",
      "TRAIN    loss : 0.06014    f1 : 0.98873\n",
      "Val    loss : 0.10892    f1 : 0.97027\n",
      "epoch : 38/100    time : 12s/733s\n",
      "TRAIN    loss : 0.04511    f1 : 0.98589\n",
      "Val    loss : 0.12403    f1 : 0.95957\n",
      "epoch : 39/100    time : 12s/718s\n",
      "TRAIN    loss : 0.04733    f1 : 0.99260\n",
      "Val    loss : 0.09111    f1 : 0.97072\n",
      "epoch : 40/100    time : 12s/704s\n",
      "TRAIN    loss : 0.00834    f1 : 0.99860\n",
      "Val    loss : 0.10043    f1 : 0.97153\n",
      "-----------------SAVE:41 epoch----------------\n",
      "epoch : 41/100    time : 12s/713s\n",
      "TRAIN    loss : 0.02135    f1 : 0.99433\n",
      "Val    loss : 0.11178    f1 : 0.97588\n",
      "epoch : 42/100    time : 12s/673s\n",
      "TRAIN    loss : 0.05110    f1 : 0.98831\n",
      "Val    loss : 0.26046    f1 : 0.94999\n",
      "epoch : 43/100    time : 12s/686s\n",
      "TRAIN    loss : 0.06571    f1 : 0.98024\n",
      "Val    loss : 0.12934    f1 : 0.96086\n",
      "epoch : 44/100    time : 12s/670s\n",
      "TRAIN    loss : 0.07141    f1 : 0.97643\n",
      "Val    loss : 0.14366    f1 : 0.95330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 45/100    time : 12s/657s\n",
      "TRAIN    loss : 0.02126    f1 : 0.99411\n",
      "Val    loss : 0.15831    f1 : 0.96520\n",
      "epoch : 46/100    time : 12s/633s\n",
      "TRAIN    loss : 0.04367    f1 : 0.98946\n",
      "Val    loss : 0.21052    f1 : 0.94577\n",
      "epoch : 47/100    time : 12s/630s\n",
      "TRAIN    loss : 0.03934    f1 : 0.99144\n",
      "Val    loss : 0.10371    f1 : 0.96380\n",
      "epoch : 48/100    time : 12s/620s\n",
      "TRAIN    loss : 0.04756    f1 : 0.97996\n",
      "Val    loss : 0.15375    f1 : 0.95150\n",
      "epoch : 49/100    time : 12s/601s\n",
      "TRAIN    loss : 0.07802    f1 : 0.97729\n",
      "Val    loss : 0.20174    f1 : 0.96050\n",
      "epoch : 50/100    time : 12s/589s\n",
      "TRAIN    loss : 0.03909    f1 : 0.99007\n",
      "Val    loss : 0.20609    f1 : 0.95262\n",
      "epoch : 51/100    time : 12s/585s\n",
      "TRAIN    loss : 0.03822    f1 : 0.99301\n",
      "Val    loss : 0.22475    f1 : 0.95444\n",
      "epoch : 52/100    time : 12s/566s\n",
      "TRAIN    loss : 0.02858    f1 : 0.99156\n",
      "Val    loss : 0.12776    f1 : 0.95772\n",
      "epoch : 53/100    time : 12s/562s\n",
      "TRAIN    loss : 0.03951    f1 : 0.99154\n",
      "Val    loss : 0.27619    f1 : 0.92796\n",
      "epoch : 54/100    time : 12s/552s\n",
      "TRAIN    loss : 0.06013    f1 : 0.98303\n",
      "Val    loss : 0.28611    f1 : 0.92291\n",
      "epoch : 55/100    time : 12s/536s\n",
      "TRAIN    loss : 0.04908    f1 : 0.98862\n",
      "Val    loss : 0.20508    f1 : 0.94660\n",
      "epoch : 56/100    time : 12s/528s\n",
      "TRAIN    loss : 0.01203    f1 : 0.99858\n",
      "Val    loss : 0.32776    f1 : 0.94014\n",
      "epoch : 57/100    time : 12s/510s\n",
      "TRAIN    loss : 0.02615    f1 : 0.99286\n",
      "Val    loss : 0.18722    f1 : 0.96657\n",
      "epoch : 58/100    time : 12s/499s\n",
      "TRAIN    loss : 0.00901    f1 : 0.99856\n",
      "Val    loss : 0.22959    f1 : 0.92952\n",
      "epoch : 59/100    time : 12s/487s\n",
      "TRAIN    loss : 0.07844    f1 : 0.97303\n",
      "Val    loss : 0.19026    f1 : 0.95915\n",
      "epoch : 60/100    time : 12s/469s\n",
      "TRAIN    loss : 0.05153    f1 : 0.98849\n",
      "Val    loss : 0.32928    f1 : 0.94321\n",
      "epoch : 61/100    time : 12s/463s\n",
      "TRAIN    loss : 0.04163    f1 : 0.99145\n",
      "Val    loss : 0.10422    f1 : 0.95863\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022, shuffle = True)\n",
    "batch_size = 8\n",
    "epochs = 100\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "  print(\"----------fold_{} start!----------\".format(idx))\n",
    "  t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "  t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "  # Train\n",
    "  train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "  train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  # Val\n",
    "  val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "  val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  best=0\n",
    "\n",
    "  model = Network().to(device)\n",
    "\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay = 1e-3)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "  best_f1 = 0\n",
    "  early_stopping = 0\n",
    "  for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_loss = 0 \n",
    "      val_pred = []\n",
    "      val_y = []\n",
    "      \n",
    "\n",
    "      for batch in (val_loader):\n",
    "        x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred_val = model(x_val)\n",
    "        loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "        val_loss += loss_val.item()/len(val_loader)\n",
    "        val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "        val_y += y_val.detach().cpu().numpy().tolist()\n",
    "      val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "      if val_f1 > best_f1:\n",
    "        best_epoch = epoch\n",
    "        best_loss = val_loss\n",
    "        best_f1 = val_f1\n",
    "        early_stopping = 0\n",
    "\n",
    "        torch.save({'epoch':epoch,\n",
    "                    'state_dict':state_dict,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "             }, path +'best_model_{}.pth'.format(idx))\n",
    "        print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "      else:\n",
    "          early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "      if early_stopping == 20:\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "Jl2OKpQiO5S1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl2OKpQiO5S1",
    "outputId": "e48def07-ef6d-4325-f297-c705088b3eb8"
   },
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 8\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load((path+'best_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "GjsHs-T3SPJq",
   "metadata": {
    "id": "GjsHs-T3SPJq"
   },
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1])+ np.array(pred_ensemble[3]) + np.array(pred_ensemble[4]) )/4\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "UIglTwAV7L54",
   "metadata": {
    "id": "UIglTwAV7L54"
   },
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "292QDIS5DOKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "292QDIS5DOKf",
    "outputId": "0e47d38f-d36a-40cd-a925-90e6bce52652",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name label\n",
       "0     001.png     1\n",
       "1     002.png     2\n",
       "2     003.png     1\n",
       "3     004.png     6\n",
       "4     005.png     8\n",
       "..        ...   ...\n",
       "210   211.png     5\n",
       "211   212.png     8\n",
       "212   213.png     3\n",
       "213   214.png     6\n",
       "214   215.png     1\n",
       "\n",
       "[215 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"sample_submission.csv\")\n",
    "submission[\"label\"] = f_result\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1naZSLGZ7L55",
   "metadata": {
    "id": "1naZSLGZ7L55"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"submit.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fitted-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"
     ]
    }
   ],
   "source": [
    "# d9249@kyonggi.ac.kr\n",
    "\n",
    "from dacon_submit_api import dacon_submit_api \n",
    "\n",
    "result = dacon_submit_api.post_submission_file(\n",
    "'C:/Users/ideal/Downloads/jupyter/user_data/submit.csv', \n",
    "'02438df9bd0f6300dae6ddea845e7e01d2cb1881849c166bfce504164e1507d5', \n",
    "'235896', \n",
    "'iDeal', \n",
    "'test' )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[BASELINE]_EfficientNet_b3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
