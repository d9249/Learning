{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amateur-flexibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 17 04:21:33 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.01       Driver Version: 516.01       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   47C    P8    26W / 350W |    482MiB / 24576MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      8556    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     10068    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10580    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11032    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     12308    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12336    C+G   ...werToys.PowerLauncher.exe    N/A      |\n",
      "|    0   N/A  N/A     12752    C+G   ...werToys.ColorPickerUI.exe    N/A      |\n",
      "|    0   N/A  N/A     12892    C+G   ...ion\\3.14.134.62\\whale.exe    N/A      |\n",
      "|    0   N/A  N/A     14384    C+G   ...\\PowerToys.FancyZones.exe    N/A      |\n",
      "|    0   N/A  N/A     14572    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15448    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     20044    C+G   ...210.47\\msedgewebview2.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910728fe-552e-49e7-a506-f348cbd6a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os, json, PIL\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') #GPU 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "functional-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(output, target):\n",
    "    with torch.no_grad():\n",
    "        predict = torch.argmax(output, 1)\n",
    "        correct = (predict == target).sum().item()\n",
    "        return correct\n",
    "\n",
    "def select_model(model, num_classes):\n",
    "    if model == 'densenet121':\n",
    "        model_ = models.densenet121(pretrained=True)\n",
    "        model_.classifier = nn.Linear(1024, num_classes)\n",
    "    elif model == 'densenet161':\n",
    "        model_ = models.densenet161(pretrained=True)\n",
    "        model_.classifier = nn.Linear(2208, num_classes)\n",
    "    return model_\n",
    "\n",
    "class Baseline():\n",
    "    def __init__(self, model, num_classes, gpu_id=0, epoch_print=1, print_freq=10, save=False):\n",
    "        self.gpu = gpu_id\n",
    "        self.epoch_print = epoch_print\n",
    "        self.print_freq = print_freq\n",
    "        self.save = save\n",
    "\n",
    "        torch.cuda.set_device(self.gpu)\n",
    "\n",
    "        self.loss_function = nn.CrossEntropyLoss().cuda(self.gpu)\n",
    "\n",
    "        model = select_model(model, num_classes)\n",
    "        self.model = model.cuda(self.gpu)\n",
    "\n",
    "        self.train_losses, self.test_losses = [], []\n",
    "        self.train_acc, self.test_acc = [], []\n",
    "        self.best_acc = None\n",
    "        self.best_loss = None\n",
    "\n",
    "    def train(self, train_data, test_data, epochs=100, lr=0.1, weight_decay=0.0001):\n",
    "        self.model.train()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr, weight_decay=weight_decay)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            if epoch % self.epoch_print == 0: print('Epoch {} Started...'.format(epoch+1))\n",
    "            for i, (X, y) in enumerate(train_data):\n",
    "                X, y = X.cuda(self.gpu), y.cuda(self.gpu)\n",
    "                output = self.model(X)\n",
    "                loss = self.loss_function(output, y)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if (epoch % self.epoch_print == 0) and (i % self.print_freq == 0):\n",
    "                    train_acc = 100 * count(output, y) / y.size(0)\n",
    "                    test_acc, test_loss = self.test(test_data)\n",
    "                    \n",
    "                    if self.save and ((self.best_acc == None) or (self.best_acc < test_acc) or (test_loss < self.best_loss)):\n",
    "                        torch.save(self.model.state_dict(), '{}_{}.pt'.format(epoch, i))\n",
    "                        self.best_acc = test_acc\n",
    "                        self.best_loss = test_loss\n",
    "                        print('Best Model Saved')\n",
    "\n",
    "                    self.train_losses.append(loss.item())\n",
    "                    self.train_acc.append(train_acc)\n",
    "                    self.test_losses.append(test_loss)\n",
    "                    self.test_acc.append(test_acc)\n",
    "\n",
    "                    print('Iteration : {} - Train Loss : {:.6f}, Test Loss : {:.6f}, '\n",
    "                          'Train Acc : {:.6f}, Test Acc : {:.6f}'.format(i+1, loss.item(), test_loss, train_acc, test_acc))\n",
    "            print()\n",
    "\n",
    "    def test(self, test_data):\n",
    "        correct, total = 0, 0\n",
    "        losses = []\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (X, y) in enumerate(test_data):\n",
    "                X, y = X.cuda(self.gpu), y.cuda(self.gpu)\n",
    "                output = self.model(X)\n",
    "\n",
    "                loss = self.loss_function(output, y)\n",
    "                losses.append(loss.item())\n",
    "                \n",
    "                correct += count(output, y)\n",
    "                total += y.size(0)\n",
    "        self.model.train()\n",
    "        return (100*correct/total, sum(losses)/len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "expanded-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "label_df = pd.read_csv('C:/Users/ideal/Downloads/jupyter/user_data/train.csv')\n",
    "\n",
    "data_dir = 'C:/Users/ideal/Downloads/jupyter/user_data/train/'\n",
    "imgs, labels = [], []\n",
    "for num in sorted(os.listdir(data_dir)):\n",
    "        imgs.extend(glob(os.path.join(data_dir, '*.png')))\n",
    "#         imgs.sort(key=lambda x:int(x.split('/')[-1].split('.')[0]))\n",
    "        \n",
    "        labels.extend(label_df['label'])\n",
    "\n",
    "label_info = {label:i for i, label in enumerate(sorted(set(labels)))}\n",
    "train_imgs, val_imgs, train_labels, val_labels = train_test_split(imgs, labels, random_state=0, stratify=labels)\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.imgs = train_imgs\n",
    "        self.labels = train_labels\n",
    "        self.label_info = label_info\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = PIL.Image.open(self.imgs[idx]).convert('RGB')\n",
    "        if self.transform: img = self.transform(img)\n",
    "\n",
    "        label = self.label_info[self.labels[idx]]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "class ValDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.imgs = val_imgs\n",
    "        self.labels = val_labels\n",
    "        self.label_info = label_info\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = PIL.Image.open(self.imgs[idx]).convert('RGB')\n",
    "        if self.transform: img = self.transform(img)\n",
    "\n",
    "        label = self.label_info[self.labels[idx]]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a992c974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0,\n",
       " '10-1': 1,\n",
       " '10-2': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b8ca352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552123"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1887881d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "736164"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75698174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184041"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85cf8b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10-2',\n",
       " '10-1',\n",
       " '3',\n",
       " '8',\n",
       " '9',\n",
       " '9',\n",
       " '8',\n",
       " '10-2',\n",
       " '5',\n",
       " '5',\n",
       " '9',\n",
       " '2',\n",
       " '4',\n",
       " '10-1',\n",
       " '9',\n",
       " '2',\n",
       " '10-2',\n",
       " '7',\n",
       " '4',\n",
       " '2',\n",
       " '6',\n",
       " '10-1',\n",
       " '10-1',\n",
       " '6',\n",
       " '10-1',\n",
       " '5',\n",
       " '6',\n",
       " '3',\n",
       " '10-2',\n",
       " '8',\n",
       " '1',\n",
       " '2',\n",
       " '8',\n",
       " '2',\n",
       " '5',\n",
       " '10-1',\n",
       " '6',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '4',\n",
       " '10-2',\n",
       " '7',\n",
       " '4',\n",
       " '4',\n",
       " '9',\n",
       " '10-2',\n",
       " '9',\n",
       " '8',\n",
       " '2',\n",
       " '6',\n",
       " '10-1',\n",
       " '9',\n",
       " '5',\n",
       " '3',\n",
       " '3',\n",
       " '6',\n",
       " '2',\n",
       " '1',\n",
       " '2',\n",
       " '10-1',\n",
       " '10-2',\n",
       " '5',\n",
       " '3',\n",
       " '4',\n",
       " '6',\n",
       " '6',\n",
       " '7',\n",
       " '2',\n",
       " '8',\n",
       " '6',\n",
       " '10-2',\n",
       " '9',\n",
       " '10-2',\n",
       " '6',\n",
       " '3',\n",
       " '8',\n",
       " '10-2',\n",
       " '1',\n",
       " '7',\n",
       " '6',\n",
       " '1',\n",
       " '6',\n",
       " '9',\n",
       " '6',\n",
       " '7',\n",
       " '3',\n",
       " '10-1',\n",
       " '3',\n",
       " '10-1',\n",
       " '10-1',\n",
       " '4',\n",
       " '3',\n",
       " '1',\n",
       " '6',\n",
       " '6',\n",
       " '2',\n",
       " '6',\n",
       " '9',\n",
       " '7',\n",
       " '9',\n",
       " '4',\n",
       " '2',\n",
       " '7',\n",
       " '10-1',\n",
       " '4',\n",
       " '3',\n",
       " '2',\n",
       " '6',\n",
       " '4',\n",
       " '3',\n",
       " '10-1',\n",
       " '9',\n",
       " '2',\n",
       " '7',\n",
       " '10-2',\n",
       " '8',\n",
       " '10-1',\n",
       " '5',\n",
       " '5',\n",
       " '6',\n",
       " '10-2',\n",
       " '9',\n",
       " '10-2',\n",
       " '7',\n",
       " '6',\n",
       " '2',\n",
       " '10-2',\n",
       " '1',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '4',\n",
       " '6',\n",
       " '4',\n",
       " '9',\n",
       " '10-1',\n",
       " '6',\n",
       " '1',\n",
       " '7',\n",
       " '2',\n",
       " '9',\n",
       " '4',\n",
       " '3',\n",
       " '1',\n",
       " '4',\n",
       " '3',\n",
       " '6',\n",
       " '2',\n",
       " '10-1',\n",
       " '7',\n",
       " '10-1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '6',\n",
       " '4',\n",
       " '5',\n",
       " '5',\n",
       " '2',\n",
       " '5',\n",
       " '6',\n",
       " '9',\n",
       " '8',\n",
       " '7',\n",
       " '4',\n",
       " '3',\n",
       " '7',\n",
       " '1',\n",
       " '9',\n",
       " '10-1',\n",
       " '2',\n",
       " '6',\n",
       " '7',\n",
       " '3',\n",
       " '7',\n",
       " '6',\n",
       " '9',\n",
       " '2',\n",
       " '2',\n",
       " '10-1',\n",
       " '8',\n",
       " '8',\n",
       " '9',\n",
       " '8',\n",
       " '4',\n",
       " '4',\n",
       " '5',\n",
       " '4',\n",
       " '10-1',\n",
       " '10-1',\n",
       " '6',\n",
       " '1',\n",
       " '6',\n",
       " '4',\n",
       " '1',\n",
       " '4',\n",
       " '6',\n",
       " '1',\n",
       " '4',\n",
       " '6',\n",
       " '2',\n",
       " '3',\n",
       " '8',\n",
       " '1',\n",
       " '5',\n",
       " '9',\n",
       " '10-1',\n",
       " '9',\n",
       " '3',\n",
       " '7',\n",
       " '1',\n",
       " '4',\n",
       " '8',\n",
       " '2',\n",
       " '10-1',\n",
       " '6',\n",
       " '5',\n",
       " '7',\n",
       " '10-1',\n",
       " '4',\n",
       " '1',\n",
       " '5',\n",
       " '7',\n",
       " '4',\n",
       " '2',\n",
       " '7',\n",
       " '1',\n",
       " '9',\n",
       " '1',\n",
       " '8',\n",
       " '4',\n",
       " '6',\n",
       " '10-2',\n",
       " '4',\n",
       " '6',\n",
       " '2',\n",
       " '3',\n",
       " '7',\n",
       " '2',\n",
       " '2',\n",
       " '1',\n",
       " '10-2',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '8',\n",
       " '2',\n",
       " '1',\n",
       " '10-1',\n",
       " '1',\n",
       " '5',\n",
       " '2',\n",
       " '5',\n",
       " '7',\n",
       " '6',\n",
       " '8',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '5',\n",
       " '8',\n",
       " '8',\n",
       " '10-2',\n",
       " '7',\n",
       " '9',\n",
       " '10-1',\n",
       " '9',\n",
       " '3',\n",
       " '4',\n",
       " '2',\n",
       " '6',\n",
       " '10-2',\n",
       " '9',\n",
       " '5',\n",
       " '5',\n",
       " '7',\n",
       " '5',\n",
       " '7',\n",
       " '2',\n",
       " '8',\n",
       " '6',\n",
       " '10-2',\n",
       " '1',\n",
       " '10-2',\n",
       " '2',\n",
       " '9',\n",
       " '7',\n",
       " '9',\n",
       " '10-2',\n",
       " '2',\n",
       " '5',\n",
       " '10-2',\n",
       " '10-1',\n",
       " '4',\n",
       " '10-1',\n",
       " '9',\n",
       " '5',\n",
       " '4',\n",
       " '2',\n",
       " '8',\n",
       " '4',\n",
       " '2',\n",
       " '8',\n",
       " '2',\n",
       " '8',\n",
       " '3',\n",
       " '2',\n",
       " '6',\n",
       " '8',\n",
       " '10-1',\n",
       " '10-1',\n",
       " '3',\n",
       " '8',\n",
       " '7',\n",
       " '3',\n",
       " '2',\n",
       " '5',\n",
       " '6',\n",
       " '2',\n",
       " '8',\n",
       " '8',\n",
       " '4',\n",
       " '9',\n",
       " '4',\n",
       " '2',\n",
       " '6',\n",
       " '10-1',\n",
       " '7',\n",
       " '1',\n",
       " '9',\n",
       " '8',\n",
       " '10-2',\n",
       " '2',\n",
       " '5',\n",
       " '9',\n",
       " '5',\n",
       " '7',\n",
       " '7',\n",
       " '8',\n",
       " '10-2',\n",
       " '4',\n",
       " '5',\n",
       " '10-1',\n",
       " '3',\n",
       " '5',\n",
       " '8',\n",
       " '8',\n",
       " '4',\n",
       " '8',\n",
       " '8',\n",
       " '3',\n",
       " '9',\n",
       " '8',\n",
       " '5',\n",
       " '3',\n",
       " '4',\n",
       " '3',\n",
       " '10-2',\n",
       " '1',\n",
       " '6',\n",
       " '10-1',\n",
       " '6',\n",
       " '8',\n",
       " '10-1',\n",
       " '5',\n",
       " '1',\n",
       " '5',\n",
       " '7',\n",
       " '10-1',\n",
       " '10-1',\n",
       " '10-2',\n",
       " '9',\n",
       " '6',\n",
       " '4',\n",
       " '10-1',\n",
       " '6',\n",
       " '9',\n",
       " '2',\n",
       " '3',\n",
       " '8',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '6',\n",
       " '9',\n",
       " '8',\n",
       " '10-1',\n",
       " '10-1',\n",
       " '8',\n",
       " '5',\n",
       " '9',\n",
       " '7',\n",
       " '9',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '2',\n",
       " '1',\n",
       " '5',\n",
       " '10-1',\n",
       " '10-1',\n",
       " '6',\n",
       " '1',\n",
       " '7',\n",
       " '2',\n",
       " '4',\n",
       " '10-2',\n",
       " '9',\n",
       " '2',\n",
       " '10-1',\n",
       " '6',\n",
       " '7',\n",
       " '7',\n",
       " '1',\n",
       " '6',\n",
       " '5',\n",
       " '2',\n",
       " '3',\n",
       " '2',\n",
       " '9',\n",
       " '10-1',\n",
       " '1',\n",
       " '2',\n",
       " '7',\n",
       " '7',\n",
       " '10-2',\n",
       " '1',\n",
       " '7',\n",
       " '5',\n",
       " '8',\n",
       " '9',\n",
       " '7',\n",
       " '8',\n",
       " '8',\n",
       " '2',\n",
       " '10-1',\n",
       " '9',\n",
       " '3',\n",
       " '8',\n",
       " '5',\n",
       " '4',\n",
       " '9',\n",
       " '3',\n",
       " '7',\n",
       " '4',\n",
       " '4',\n",
       " '5',\n",
       " '7',\n",
       " '8',\n",
       " '8',\n",
       " '10-1',\n",
       " '6',\n",
       " '10-1',\n",
       " '8',\n",
       " '1',\n",
       " '7',\n",
       " '9',\n",
       " '6',\n",
       " '10-1',\n",
       " '7',\n",
       " '7',\n",
       " '7',\n",
       " '10-1',\n",
       " '7',\n",
       " '7',\n",
       " '2',\n",
       " '5',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '10-1',\n",
       " '6',\n",
       " '10-2',\n",
       " '7',\n",
       " '10-2',\n",
       " '1',\n",
       " '5',\n",
       " '4',\n",
       " '1',\n",
       " '7',\n",
       " '7',\n",
       " '2',\n",
       " '7',\n",
       " '2',\n",
       " '4',\n",
       " '3',\n",
       " '1',\n",
       " '4',\n",
       " '9',\n",
       " '10-1',\n",
       " '1',\n",
       " '6',\n",
       " '3',\n",
       " '8',\n",
       " '4',\n",
       " '6',\n",
       " '9',\n",
       " '7',\n",
       " '3',\n",
       " '2',\n",
       " '10-1',\n",
       " '4',\n",
       " '10-1',\n",
       " '1',\n",
       " '3',\n",
       " '5',\n",
       " '1',\n",
       " '4',\n",
       " '5',\n",
       " '9',\n",
       " '5',\n",
       " '5',\n",
       " '2',\n",
       " '10-2',\n",
       " '10-1',\n",
       " '4',\n",
       " '7',\n",
       " '5',\n",
       " '3',\n",
       " '1',\n",
       " '5',\n",
       " '8',\n",
       " '9',\n",
       " '6',\n",
       " '1',\n",
       " '4',\n",
       " '4',\n",
       " '7',\n",
       " '3',\n",
       " '1',\n",
       " '2',\n",
       " '5',\n",
       " '9',\n",
       " '6',\n",
       " '1',\n",
       " '9',\n",
       " '6',\n",
       " '3',\n",
       " '8',\n",
       " '4',\n",
       " '7',\n",
       " '6',\n",
       " '10-2',\n",
       " '8',\n",
       " '10-1',\n",
       " '5',\n",
       " '10-1',\n",
       " '2',\n",
       " '6',\n",
       " '6',\n",
       " '4',\n",
       " '5',\n",
       " '9',\n",
       " '3',\n",
       " '9',\n",
       " '8',\n",
       " '8',\n",
       " '9',\n",
       " '4',\n",
       " '9',\n",
       " '6',\n",
       " '1',\n",
       " '4',\n",
       " '6',\n",
       " '10-1',\n",
       " '10-1',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '10-2',\n",
       " '3',\n",
       " '1',\n",
       " '6',\n",
       " '10-1',\n",
       " '2',\n",
       " '10-2',\n",
       " '3',\n",
       " '9',\n",
       " '2',\n",
       " '10-2',\n",
       " '3',\n",
       " '10-2',\n",
       " '4',\n",
       " '10-2',\n",
       " '9',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '9',\n",
       " '5',\n",
       " '1',\n",
       " '6',\n",
       " '1',\n",
       " '10-2',\n",
       " '3',\n",
       " '10-1',\n",
       " '1',\n",
       " '9',\n",
       " '3',\n",
       " '10-1',\n",
       " '10-1',\n",
       " '1',\n",
       " '8',\n",
       " '10-1',\n",
       " '2',\n",
       " '3',\n",
       " '8',\n",
       " '10-1',\n",
       " '5',\n",
       " '8',\n",
       " '2',\n",
       " '8',\n",
       " '2',\n",
       " '9',\n",
       " '5',\n",
       " '6',\n",
       " '4',\n",
       " '9',\n",
       " '3',\n",
       " '10-2',\n",
       " '2',\n",
       " '7',\n",
       " '3',\n",
       " '1',\n",
       " '10-1',\n",
       " '10-2',\n",
       " '6',\n",
       " '1',\n",
       " '8',\n",
       " '6',\n",
       " '3',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '9',\n",
       " '1',\n",
       " '7',\n",
       " '8',\n",
       " '1',\n",
       " '9',\n",
       " '8',\n",
       " '9',\n",
       " '5',\n",
       " '7',\n",
       " '4',\n",
       " '4',\n",
       " '1',\n",
       " '5',\n",
       " '7',\n",
       " '5',\n",
       " '6',\n",
       " '8',\n",
       " '10-1',\n",
       " '4',\n",
       " '8',\n",
       " '9',\n",
       " '7',\n",
       " '2',\n",
       " '7',\n",
       " '4',\n",
       " '9',\n",
       " '6',\n",
       " '1',\n",
       " '9',\n",
       " '10-2',\n",
       " '9',\n",
       " '2',\n",
       " '1',\n",
       " '3',\n",
       " '10-2',\n",
       " '3',\n",
       " '2',\n",
       " '6',\n",
       " '5',\n",
       " '5',\n",
       " '1',\n",
       " '8',\n",
       " '8',\n",
       " '4',\n",
       " '7',\n",
       " '3',\n",
       " '10-2',\n",
       " '5',\n",
       " '4',\n",
       " '3',\n",
       " '7',\n",
       " '10-1',\n",
       " '5',\n",
       " '9',\n",
       " '8',\n",
       " '6',\n",
       " '5',\n",
       " '10-1',\n",
       " '7',\n",
       " '6',\n",
       " '3',\n",
       " '7',\n",
       " '7',\n",
       " '7',\n",
       " '8',\n",
       " '8',\n",
       " '6',\n",
       " '5',\n",
       " '5',\n",
       " '4',\n",
       " '4',\n",
       " '9',\n",
       " '10-2',\n",
       " '8',\n",
       " '2',\n",
       " '10-1',\n",
       " '3',\n",
       " '6',\n",
       " '6',\n",
       " '10-2',\n",
       " '7',\n",
       " '7',\n",
       " '3',\n",
       " '4',\n",
       " '10-1',\n",
       " '6',\n",
       " '9',\n",
       " '3',\n",
       " '9',\n",
       " '7',\n",
       " '8',\n",
       " '2',\n",
       " '3',\n",
       " '2',\n",
       " '10-2',\n",
       " '5',\n",
       " '9',\n",
       " '9',\n",
       " '2',\n",
       " '4',\n",
       " '7',\n",
       " '8',\n",
       " '10-2',\n",
       " '10-2',\n",
       " '3',\n",
       " '10-2',\n",
       " '3',\n",
       " '6',\n",
       " '3',\n",
       " '10-1',\n",
       " '10-2',\n",
       " '8',\n",
       " '5',\n",
       " '2',\n",
       " '1',\n",
       " '4',\n",
       " '2',\n",
       " '10-1',\n",
       " '10-1',\n",
       " '8',\n",
       " '10-1',\n",
       " '6',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '10-2',\n",
       " '9',\n",
       " '5',\n",
       " '5',\n",
       " '10-1',\n",
       " '8',\n",
       " '5',\n",
       " '6',\n",
       " '5',\n",
       " '7',\n",
       " '4',\n",
       " '10-1',\n",
       " '4',\n",
       " '8',\n",
       " '1',\n",
       " '4',\n",
       " '5',\n",
       " '1',\n",
       " '2',\n",
       " '10-1',\n",
       " '2',\n",
       " '2',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '8',\n",
       " '4',\n",
       " '2',\n",
       " '3',\n",
       " '5',\n",
       " '8',\n",
       " '1',\n",
       " '4',\n",
       " '4',\n",
       " '5',\n",
       " '9',\n",
       " '3',\n",
       " '3',\n",
       " '2',\n",
       " '7',\n",
       " '4',\n",
       " '8',\n",
       " '3',\n",
       " '7',\n",
       " '6',\n",
       " '10-2',\n",
       " '7',\n",
       " '3',\n",
       " '4',\n",
       " '7',\n",
       " '2',\n",
       " '4',\n",
       " '2',\n",
       " '7',\n",
       " '5',\n",
       " '1',\n",
       " '10-1',\n",
       " '2',\n",
       " '9',\n",
       " '10-2',\n",
       " '9',\n",
       " '3',\n",
       " '10-1',\n",
       " '10-1',\n",
       " '3',\n",
       " '3',\n",
       " '5',\n",
       " '7',\n",
       " '7',\n",
       " '1',\n",
       " '6',\n",
       " '3',\n",
       " '7',\n",
       " '2',\n",
       " '8',\n",
       " '10-1',\n",
       " '10-2',\n",
       " '5',\n",
       " '10-1',\n",
       " '3',\n",
       " '4',\n",
       " '9',\n",
       " '5',\n",
       " '4',\n",
       " '8',\n",
       " '3',\n",
       " '2',\n",
       " '10-2',\n",
       " '5',\n",
       " '10-2',\n",
       " '9',\n",
       " '1',\n",
       " '4',\n",
       " '10-1',\n",
       " '7',\n",
       " '10-2',\n",
       " '10-1',\n",
       " '3',\n",
       " '8',\n",
       " '9',\n",
       " '9',\n",
       " '8',\n",
       " '10-2',\n",
       " '5',\n",
       " '5',\n",
       " '9',\n",
       " '2',\n",
       " '4',\n",
       " '10-1',\n",
       " '9',\n",
       " '2',\n",
       " '10-2',\n",
       " '7',\n",
       " '4',\n",
       " '2',\n",
       " '6',\n",
       " '10-1',\n",
       " '10-1',\n",
       " '6',\n",
       " '10-1',\n",
       " '5',\n",
       " '6',\n",
       " '3',\n",
       " '10-2',\n",
       " '8',\n",
       " '1',\n",
       " '2',\n",
       " '8',\n",
       " '2',\n",
       " '5',\n",
       " '10-1',\n",
       " '6',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '4',\n",
       " '10-2',\n",
       " '7',\n",
       " '4',\n",
       " '4',\n",
       " '9',\n",
       " '10-2',\n",
       " '9',\n",
       " '8',\n",
       " '2',\n",
       " '6',\n",
       " '10-1',\n",
       " '9',\n",
       " '5',\n",
       " '3',\n",
       " '3',\n",
       " '6',\n",
       " '2',\n",
       " '1',\n",
       " '2',\n",
       " '10-1',\n",
       " '10-2',\n",
       " '5',\n",
       " '3',\n",
       " '4',\n",
       " '6',\n",
       " '6',\n",
       " '7',\n",
       " '2',\n",
       " '8',\n",
       " '6',\n",
       " '10-2',\n",
       " '9',\n",
       " '10-2',\n",
       " '6',\n",
       " '3',\n",
       " '8',\n",
       " '10-2',\n",
       " '1',\n",
       " '7',\n",
       " '6',\n",
       " '1',\n",
       " '6',\n",
       " '9',\n",
       " '6',\n",
       " '7',\n",
       " '3',\n",
       " '10-1',\n",
       " '3',\n",
       " '10-1',\n",
       " '10-1',\n",
       " '4',\n",
       " '3',\n",
       " '1',\n",
       " '6',\n",
       " '6',\n",
       " '2',\n",
       " '6',\n",
       " '9',\n",
       " '7',\n",
       " '9',\n",
       " '4',\n",
       " '2',\n",
       " '7',\n",
       " '10-1',\n",
       " '4',\n",
       " '3',\n",
       " '2',\n",
       " '6',\n",
       " '4',\n",
       " '3',\n",
       " '10-1',\n",
       " '9',\n",
       " '2',\n",
       " '7',\n",
       " '10-2',\n",
       " '8',\n",
       " '10-1',\n",
       " '5',\n",
       " '5',\n",
       " '6',\n",
       " '10-2',\n",
       " '9',\n",
       " '10-2',\n",
       " '7',\n",
       " '6',\n",
       " '2',\n",
       " '10-2',\n",
       " '1',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '4',\n",
       " '6',\n",
       " '4',\n",
       " '9',\n",
       " '10-1',\n",
       " '6',\n",
       " '1',\n",
       " '7',\n",
       " '2',\n",
       " '9',\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "personal-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "african-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(transform=train_transform)\n",
    "val_dataset = ValDataset(transform=val_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "valuable-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline(model='densenet121', num_classes=len(train_dataset.label_info), print_freq=5, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "tropical-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 0.0005\n",
    "weight_decay = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "crazy-broad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Started...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36mBaseline.train\u001b[1;34m(self, train_data, test_data, epochs, lr, weight_decay)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_print \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (i \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     51\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m count(output, y) \u001b[38;5;241m/\u001b[39m y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m     test_acc, test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_acc \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_acc \u001b[38;5;241m<\u001b[39m test_acc) \u001b[38;5;129;01mor\u001b[39;00m (test_loss \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_loss)):\n\u001b[0;32m     55\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, i))\n",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36mBaseline.test\u001b[1;34m(self, test_data)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_data):\n\u001b[0;32m     76\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcuda(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu), y\u001b[38;5;241m.\u001b[39mcuda(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu)\n\u001b[0;32m     77\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(X)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mValDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     42\u001b[0m     img \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs[idx])\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform: img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_info[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]]\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img, label\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:155\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    153\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(train_loader, val_loader, epochs=epochs, lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e837a3b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_fontsize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m test_lossline, \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mplot(model\u001b[38;5;241m.\u001b[39mtest_losses, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend(handles\u001b[38;5;241m=\u001b[39m[train_lossline, test_lossline], fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStep\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[43mlabel_fontsize\u001b[49m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39mlabel_fontsize)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'label_fontsize' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label_fontsize = 25\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "train_lossline, = plt.plot(model.train_losses, label='Train')\n",
    "test_lossline, = plt.plot(model.test_losses, color='red', label='Test')\n",
    "plt.legend(handles=[train_lossline, test_lossline], fontsize=20)\n",
    "plt.xlabel('Step', fontsize=label_fontsize)\n",
    "plt.ylabel('Loss', fontsize=label_fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "train_accline, = plt.plot(model.train_acc, label='Train')\n",
    "test_accline, = plt.plot(model.test_acc, color='red', label='Test')\n",
    "plt.legend(handles=[train_accline, test_accline], fontsize=20)\n",
    "plt.xlabel('Step', fontsize=label_fontsize)\n",
    "plt.ylabel('Acc', fontsize=label_fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline(model='densenet161', num_classes=10)\n",
    "model.model.load_state_dict(torch.load('./8_225.pt'))\n",
    "model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256), transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "test_df = pd.read_csv('/home/hand image/test.csv')\n",
    "test_data_dir = '/home/hand image/test/'\n",
    "predictions, test_img = [], []\n",
    "for num in sorted(os.listdir(test_data_dir)):\n",
    "        test_img.extend(glob(os.path.join(test_data_dir, '*.png')))\n",
    "        test_img.sort(key=lambda x:int(x.split('/')[-1].split('.')[0]))\n",
    "        predictions.extend(test_df['file_name'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for num in sorted(os.listdir(test_data_dir)):\n",
    "        imgs = torch.stack(imgs).cuda()\n",
    "        prediction = torch.nn.Softmax(dim=1)(model.model(imgs))\n",
    "        prediction = torch.mean(prediction, dim=0)\n",
    "            \n",
    "        if torch.sum(prediction) != 1: print(torch.sum(prediction))\n",
    "        predictions.append(prediction.cpu().numpy())\n",
    "\n",
    "print(len(predictions))\n",
    "print(len(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53c2aa28-0420-403a-ac72-6137a0b2cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/home/hand image/sample_submission.csv')\n",
    "submission['label'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82456b3b-7288-4759-8539-cbd3cf69079f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name label\n",
       "0   001.png     1\n",
       "1   002.png     2\n",
       "2   003.png     1\n",
       "3   004.png     6\n",
       "4   005.png     7"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1b1f36f-d1b2-43b7-8acf-1cff3f3be8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
