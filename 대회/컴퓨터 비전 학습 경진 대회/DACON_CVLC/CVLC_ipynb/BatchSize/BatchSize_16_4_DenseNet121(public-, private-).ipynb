{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BatchSize_16_4_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1QnPclrYnKmBsAWRJ51Rre-PMBgVa9Cl3","timestamp":1630760206258},{"file_id":"1K7n8RRDie4UKR4IX4z4XcOvrqBpuzCX2","timestamp":1630760179968},{"file_id":"18NxWLqCn6GIqSPUVwANqnaPRMf5i0YEt","timestamp":1630745018066},{"file_id":"1EDWcCOn_TRgBJv_ZMCvsd_r1unwaZzE7","timestamp":1630744974962},{"file_id":"1JA5LGhrhW19laOkeoR8qPDaFWjoqSMzr","timestamp":1630744944221},{"file_id":"1PtmJdXo9AY1M6u1bHhpUHKQ0PGMoOPWZ","timestamp":1630744160988},{"file_id":"1q8viSykqnipNZ_WZtwFtIvj_ZdVFX4vC","timestamp":1630699910907},{"file_id":"1I9ElhTSO4vKs1a5lfr-r0PB1MndT08Nr","timestamp":1630699885519},{"file_id":"14FhoIy7URVKqSDzemys-qARDeDRrpK5D","timestamp":1630676044569},{"file_id":"1SyIKO_pcFSLG_l2VOhA42Qj1Sfgu9xJ5","timestamp":1630675996818},{"file_id":"1bR6CC08w6e4QxXCvbI1hPuVGX4Xr2aS6","timestamp":1630675972365},{"file_id":"1m9zTT841JY7COW8wa0uLUmdxh4mwTROg","timestamp":1630675935279},{"file_id":"1K-M0y6ngoFlaXHKpD1A2obin5bN69rOP","timestamp":1630668564612},{"file_id":"1blwd04nWkDbZIiyYRsoikGHv7D2lN1M7","timestamp":1630663027637},{"file_id":"1OWcGKJuP-Tlx2cd7fYiEF4iFQBw_jTaV","timestamp":1630663004855},{"file_id":"1iIv2T-FeMWjlLKmFmVia0cp_FsKKhP6n","timestamp":1630662692922},{"file_id":"122a3KanHz7tYxI2RkTyd5CDHFsGXxRcD","timestamp":1630652306408},{"file_id":"1rmWpSzQjpXc4LfrgWir30dbjafFqnlzh","timestamp":1630652271928},{"file_id":"1LZU500qd_mzkL28Su52XN_qaRf_yaHht","timestamp":1630646510103},{"file_id":"16JOqSkO3uC_jfclj81AzxJShlzoOMH_B","timestamp":1630613714759},{"file_id":"1eaN7vOK3RK8eeKTKP85BVew6KGSCyH_6","timestamp":1630613687181},{"file_id":"1hFz_giaup3ft5PdsqD18owTBdvEk-9En","timestamp":1630613648785},{"file_id":"15fNytZzTcRPBSdHijbaWLKC0KR8SWzhp","timestamp":1630612864615},{"file_id":"1C8ZNqu7Eb5heuVECStaVKpkxyihLmMkO","timestamp":1630602470521},{"file_id":"1DN9Efw8q90g7HCJ5VhXJYn57jItRUHnr","timestamp":1630602447501},{"file_id":"1ZYwQgfbGvCmGKmNM25goBD839_1yJrul","timestamp":1630602408672},{"file_id":"1_j6u69eFZFR-bV-7FdC_KmRhJ8AI-Ifh","timestamp":1630602370180},{"file_id":"1unjV74CiTTQsLla4T4r8Xawlb_l1_ego","timestamp":1630602293534},{"file_id":"1MSEaTlfMh47aob3-U8yPBQNcpxSO0RC6","timestamp":1630524166308},{"file_id":"1uj1q7VaxDNJ4v0Qnpewz9OO5vDawvGL1","timestamp":1630524142681},{"file_id":"1SXi4BHkyVdQzSXMkx23PhKLYG_cgy9Ne","timestamp":1630524118198},{"file_id":"1ktumtKU2gng5uaTndy4q6ORrf_vm1MB5","timestamp":1630516331014},{"file_id":"19fk2AWJq9X3zvPm2WSAtKO7ljZBPUG5l","timestamp":1630516290119},{"file_id":"1ZOrlvLwHgJ8yqXlMzsUBuNpAS1leHpTw","timestamp":1630516251869},{"file_id":"1lrAXMllo7_hAtAVIxPhE7Xno3vS6aFxT","timestamp":1630515420255},{"file_id":"17dTh7DEVFlzrmiHY5X5ldlDVaanaV9e-","timestamp":1630504418101},{"file_id":"1mqEzmVKqNVAF_0chUK1joEpZK_PYc0_4","timestamp":1630504394196},{"file_id":"1mzp8pt1OJt9CAaiKKe25s3yNAqrGew9R","timestamp":1630504147646},{"file_id":"1FMgk3jn7Q2dQ8p_Hu7bJRfcSBb13Rnvo","timestamp":1630504098889},{"file_id":"1hhBZ077MXyvhUnuxI7SD86ahYiLsCzOG","timestamp":1630500513841},{"file_id":"1EEfvNr8ZybJmpeRuKJ-r7__rhnDnaIM7","timestamp":1630495179853},{"file_id":"17e4zKJb3AvCBXA5MdPqutbvT9s1-CP6A","timestamp":1630484224103},{"file_id":"1ZyJ9--fiBCqqZIpZYXBwYIGMXZPnoPvu","timestamp":1630484173863},{"file_id":"1abkZGMd_cSctW05mIZfosyOPOLNr-LK9","timestamp":1630484131331},{"file_id":"1fKp4Svl_srbEAv_YpXTvSwqDozb4bj9H","timestamp":1630484105207},{"file_id":"1y9kcnOXGhn5ArjCk66kqJCIvgyfTRSkk","timestamp":1630483907553},{"file_id":"1o9CD4AI2tKzcdbdLJ4A6xkENgqmZG7oW","timestamp":1630475138628},{"file_id":"17KUAlMIBl9TgxSnuNYcPwx2zScEUw5W-","timestamp":1630475103015},{"file_id":"12cn5R3wN6-IWoeS68BSqi4LxqlCxJxYt","timestamp":1630464969114},{"file_id":"1KLLc8roFaz12DcPj1WHhuKt9ZBQqi76a","timestamp":1630464678834},{"file_id":"1VZIQ1plZ8Dw3dEaOdrcDkgTjXOv0OcTp","timestamp":1630464589009},{"file_id":"1HiqQpOR-bo5ZelQ96RenE8K365HqE7Lv","timestamp":1630438189228},{"file_id":"1ltViornnQGTXyCDuiYgIGfZy1m46LTW_","timestamp":1630438122242},{"file_id":"12vcTsqE7nuRUe3r9-4k5efqml3ud1k9Z","timestamp":1630438078632},{"file_id":"1EdFynNtlBeF206lf5xA2umzEqK_Pjyi5","timestamp":1630437839162},{"file_id":"1pKJK3lnnRPxX28V0U_A45uk_SI4WlDZr","timestamp":1630432659647},{"file_id":"1soBcJ0zzhkPsMINjzGMbYGcga7VX-2Be","timestamp":1630432634550},{"file_id":"12jPQ_wSDDvGyzTBUV-h-pRZ8N-lp9bkW","timestamp":1630425888718},{"file_id":"1ik1ECJq6EbWwGegXLisYoxytv0-7JQcn","timestamp":1630425853722},{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPol8GUvL0FtnFW/JTurFTs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630776741526,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d7c9d9d7-8135-4ec3-e09b-41c13d5de7d4"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Sep  4 17:32:21 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630776757945,"user_tz":-540,"elapsed":16423,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"7b564b78-bb5f-45b1-b761-03d1ac550363"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1630776761370,"user_tz":-540,"elapsed":3064,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1630776762820,"user_tz":-540,"elapsed":1457,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1630776765554,"user_tz":-540,"elapsed":2737,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1630776785130,"user_tz":-540,"elapsed":19578,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1630776793257,"user_tz":-540,"elapsed":8130,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630776793258,"user_tz":-540,"elapsed":10,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"65f1dc0f-71d8-471f-b3e6-1b76b1e034d9"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630776793732,"user_tz":-540,"elapsed":481,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"a1a8ae5e-5b60-4f5c-91bd-6ed071d069d8"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","batch_size = 16\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size,  color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1630776793733,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630783924490,"user_tz":-540,"elapsed":7130765,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c3a5c181-9ed2-4a16-9b40-03bf279de094"},"source":["DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","103/103 [==============================] - 44s 163ms/step - loss: 1.9768 - accuracy: 0.3015 - val_loss: 18.8539 - val_accuracy: 0.0985\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 2/500\n","103/103 [==============================] - 14s 132ms/step - loss: 1.3715 - accuracy: 0.5311 - val_loss: 7.8921 - val_accuracy: 0.1453\n","\n","Epoch 00002: val_accuracy improved from 0.09852 to 0.14532, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 3/500\n","103/103 [==============================] - 14s 132ms/step - loss: 1.1229 - accuracy: 0.6248 - val_loss: 4.1239 - val_accuracy: 0.2857\n","\n","Epoch 00003: val_accuracy improved from 0.14532 to 0.28571, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 4/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.9189 - accuracy: 0.6918 - val_loss: 3.5805 - val_accuracy: 0.3374\n","\n","Epoch 00004: val_accuracy improved from 0.28571 to 0.33744, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 5/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.8485 - accuracy: 0.7266 - val_loss: 2.0677 - val_accuracy: 0.5123\n","\n","Epoch 00005: val_accuracy improved from 0.33744 to 0.51232, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 6/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.7878 - accuracy: 0.7314 - val_loss: 1.5155 - val_accuracy: 0.6158\n","\n","Epoch 00006: val_accuracy improved from 0.51232 to 0.61576, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 7/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.6510 - accuracy: 0.7765 - val_loss: 1.3404 - val_accuracy: 0.6379\n","\n","Epoch 00007: val_accuracy improved from 0.61576 to 0.63793, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 8/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.6172 - accuracy: 0.7996 - val_loss: 1.0715 - val_accuracy: 0.7340\n","\n","Epoch 00008: val_accuracy improved from 0.63793 to 0.73399, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 9/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.5741 - accuracy: 0.8057 - val_loss: 1.0649 - val_accuracy: 0.6970\n","\n","Epoch 00009: val_accuracy did not improve from 0.73399\n","Epoch 10/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.5399 - accuracy: 0.8222 - val_loss: 1.5880 - val_accuracy: 0.6281\n","\n","Epoch 00010: val_accuracy did not improve from 0.73399\n","Epoch 11/500\n","103/103 [==============================] - 13s 131ms/step - loss: 0.5245 - accuracy: 0.8283 - val_loss: 0.5860 - val_accuracy: 0.8079\n","\n","Epoch 00011: val_accuracy improved from 0.73399 to 0.80788, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 12/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.4363 - accuracy: 0.8514 - val_loss: 1.0031 - val_accuracy: 0.6872\n","\n","Epoch 00012: val_accuracy did not improve from 0.80788\n","Epoch 13/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.4314 - accuracy: 0.8587 - val_loss: 1.0215 - val_accuracy: 0.7094\n","\n","Epoch 00013: val_accuracy did not improve from 0.80788\n","Epoch 14/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.4508 - accuracy: 0.8496 - val_loss: 0.9284 - val_accuracy: 0.7167\n","\n","Epoch 00014: val_accuracy did not improve from 0.80788\n","Epoch 15/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.4083 - accuracy: 0.8605 - val_loss: 0.7221 - val_accuracy: 0.7882\n","\n","Epoch 00015: val_accuracy did not improve from 0.80788\n","Epoch 16/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.4162 - accuracy: 0.8599 - val_loss: 1.3308 - val_accuracy: 0.6675\n","\n","Epoch 00016: val_accuracy did not improve from 0.80788\n","Epoch 17/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.3445 - accuracy: 0.8886 - val_loss: 0.6936 - val_accuracy: 0.7956\n","\n","Epoch 00017: val_accuracy did not improve from 0.80788\n","Epoch 18/500\n","103/103 [==============================] - 14s 131ms/step - loss: 0.3466 - accuracy: 0.8788 - val_loss: 0.8271 - val_accuracy: 0.7512\n","\n","Epoch 00018: val_accuracy did not improve from 0.80788\n","Epoch 19/500\n","103/103 [==============================] - 14s 131ms/step - loss: 0.3450 - accuracy: 0.8800 - val_loss: 0.7215 - val_accuracy: 0.7980\n","\n","Epoch 00019: val_accuracy did not improve from 0.80788\n","Epoch 20/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.3140 - accuracy: 0.8910 - val_loss: 0.6769 - val_accuracy: 0.8128\n","\n","Epoch 00020: val_accuracy improved from 0.80788 to 0.81281, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 21/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.2603 - accuracy: 0.9086 - val_loss: 0.4897 - val_accuracy: 0.8399\n","\n","Epoch 00021: val_accuracy improved from 0.81281 to 0.83990, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 22/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.2894 - accuracy: 0.8971 - val_loss: 3.7432 - val_accuracy: 0.4089\n","\n","Epoch 00022: val_accuracy did not improve from 0.83990\n","Epoch 23/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.2744 - accuracy: 0.9050 - val_loss: 0.5499 - val_accuracy: 0.8448\n","\n","Epoch 00023: val_accuracy improved from 0.83990 to 0.84483, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 24/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.2273 - accuracy: 0.9257 - val_loss: 0.4572 - val_accuracy: 0.8670\n","\n","Epoch 00024: val_accuracy improved from 0.84483 to 0.86700, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 25/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.2302 - accuracy: 0.9220 - val_loss: 0.6647 - val_accuracy: 0.8325\n","\n","Epoch 00025: val_accuracy did not improve from 0.86700\n","Epoch 26/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.2213 - accuracy: 0.9294 - val_loss: 0.6774 - val_accuracy: 0.8424\n","\n","Epoch 00026: val_accuracy did not improve from 0.86700\n","Epoch 27/500\n","103/103 [==============================] - 14s 131ms/step - loss: 0.2083 - accuracy: 0.9245 - val_loss: 1.2563 - val_accuracy: 0.7143\n","\n","Epoch 00027: val_accuracy did not improve from 0.86700\n","Epoch 28/500\n","103/103 [==============================] - 14s 131ms/step - loss: 0.2025 - accuracy: 0.9336 - val_loss: 0.6343 - val_accuracy: 0.8300\n","\n","Epoch 00028: val_accuracy did not improve from 0.86700\n","Epoch 29/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.2465 - accuracy: 0.9184 - val_loss: 0.7152 - val_accuracy: 0.8128\n","\n","Epoch 00029: val_accuracy did not improve from 0.86700\n","Epoch 30/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1730 - accuracy: 0.9409 - val_loss: 0.3822 - val_accuracy: 0.8892\n","\n","Epoch 00030: val_accuracy improved from 0.86700 to 0.88916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 31/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.1583 - accuracy: 0.9464 - val_loss: 0.6897 - val_accuracy: 0.7783\n","\n","Epoch 00031: val_accuracy did not improve from 0.88916\n","Epoch 32/500\n","103/103 [==============================] - 14s 131ms/step - loss: 0.1858 - accuracy: 0.9403 - val_loss: 0.9960 - val_accuracy: 0.7857\n","\n","Epoch 00032: val_accuracy did not improve from 0.88916\n","Epoch 33/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1931 - accuracy: 0.9294 - val_loss: 0.6605 - val_accuracy: 0.8399\n","\n","Epoch 00033: val_accuracy did not improve from 0.88916\n","Epoch 34/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1732 - accuracy: 0.9403 - val_loss: 0.5345 - val_accuracy: 0.8645\n","\n","Epoch 00034: val_accuracy did not improve from 0.88916\n","Epoch 35/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.1820 - accuracy: 0.9336 - val_loss: 1.0297 - val_accuracy: 0.7956\n","\n","Epoch 00035: val_accuracy did not improve from 0.88916\n","Epoch 36/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1782 - accuracy: 0.9421 - val_loss: 0.5773 - val_accuracy: 0.8547\n","\n","Epoch 00036: val_accuracy did not improve from 0.88916\n","Epoch 37/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1633 - accuracy: 0.9428 - val_loss: 0.4834 - val_accuracy: 0.8670\n","\n","Epoch 00037: val_accuracy did not improve from 0.88916\n","Epoch 38/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1235 - accuracy: 0.9598 - val_loss: 0.4314 - val_accuracy: 0.8818\n","\n","Epoch 00038: val_accuracy did not improve from 0.88916\n","Epoch 39/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.1330 - accuracy: 0.9568 - val_loss: 0.8244 - val_accuracy: 0.7906\n","\n","Epoch 00039: val_accuracy did not improve from 0.88916\n","Epoch 40/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.1764 - accuracy: 0.9391 - val_loss: 0.7840 - val_accuracy: 0.8153\n","\n","Epoch 00040: val_accuracy did not improve from 0.88916\n","Epoch 41/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1581 - accuracy: 0.9415 - val_loss: 0.7524 - val_accuracy: 0.8448\n","\n","Epoch 00041: val_accuracy did not improve from 0.88916\n","Epoch 42/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.1350 - accuracy: 0.9513 - val_loss: 0.3887 - val_accuracy: 0.8842\n","\n","Epoch 00042: val_accuracy did not improve from 0.88916\n","Epoch 43/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1087 - accuracy: 0.9610 - val_loss: 0.4714 - val_accuracy: 0.8695\n","\n","Epoch 00043: val_accuracy did not improve from 0.88916\n","Epoch 44/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0948 - accuracy: 0.9629 - val_loss: 0.5109 - val_accuracy: 0.8719\n","\n","Epoch 00044: val_accuracy did not improve from 0.88916\n","Epoch 45/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1057 - accuracy: 0.9683 - val_loss: 0.5453 - val_accuracy: 0.8818\n","\n","Epoch 00045: val_accuracy did not improve from 0.88916\n","Epoch 46/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1124 - accuracy: 0.9641 - val_loss: 0.5963 - val_accuracy: 0.8498\n","\n","Epoch 00046: val_accuracy did not improve from 0.88916\n","Epoch 47/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.1004 - accuracy: 0.9665 - val_loss: 0.4030 - val_accuracy: 0.9064\n","\n","Epoch 00047: val_accuracy improved from 0.88916 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 48/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0957 - accuracy: 0.9647 - val_loss: 1.2918 - val_accuracy: 0.7438\n","\n","Epoch 00048: val_accuracy did not improve from 0.90640\n","Epoch 49/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1316 - accuracy: 0.9562 - val_loss: 0.6829 - val_accuracy: 0.8498\n","\n","Epoch 00049: val_accuracy did not improve from 0.90640\n","Epoch 50/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1221 - accuracy: 0.9586 - val_loss: 0.5348 - val_accuracy: 0.8719\n","\n","Epoch 00050: val_accuracy did not improve from 0.90640\n","Epoch 51/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1352 - accuracy: 0.9610 - val_loss: 0.4471 - val_accuracy: 0.8916\n","\n","Epoch 00051: val_accuracy did not improve from 0.90640\n","Epoch 52/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0952 - accuracy: 0.9689 - val_loss: 0.6533 - val_accuracy: 0.8374\n","\n","Epoch 00052: val_accuracy did not improve from 0.90640\n","Epoch 53/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0862 - accuracy: 0.9702 - val_loss: 0.6179 - val_accuracy: 0.8596\n","\n","Epoch 00053: val_accuracy did not improve from 0.90640\n","Epoch 54/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0961 - accuracy: 0.9622 - val_loss: 0.3534 - val_accuracy: 0.8966\n","\n","Epoch 00054: val_accuracy did not improve from 0.90640\n","Epoch 55/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0678 - accuracy: 0.9769 - val_loss: 0.4724 - val_accuracy: 0.8916\n","\n","Epoch 00055: val_accuracy did not improve from 0.90640\n","Epoch 56/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0680 - accuracy: 0.9781 - val_loss: 0.4471 - val_accuracy: 0.8966\n","\n","Epoch 00056: val_accuracy did not improve from 0.90640\n","Epoch 57/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0696 - accuracy: 0.9744 - val_loss: 0.7405 - val_accuracy: 0.8128\n","\n","Epoch 00057: val_accuracy did not improve from 0.90640\n","Epoch 58/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1220 - accuracy: 0.9562 - val_loss: 1.0209 - val_accuracy: 0.8128\n","\n","Epoch 00058: val_accuracy did not improve from 0.90640\n","Epoch 59/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.1068 - accuracy: 0.9683 - val_loss: 0.6539 - val_accuracy: 0.8276\n","\n","Epoch 00059: val_accuracy did not improve from 0.90640\n","Epoch 60/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0960 - accuracy: 0.9641 - val_loss: 0.5605 - val_accuracy: 0.8645\n","\n","Epoch 00060: val_accuracy did not improve from 0.90640\n","Epoch 61/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0743 - accuracy: 0.9738 - val_loss: 0.4255 - val_accuracy: 0.8793\n","\n","Epoch 00061: val_accuracy did not improve from 0.90640\n","Epoch 62/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0618 - accuracy: 0.9738 - val_loss: 0.4340 - val_accuracy: 0.9015\n","\n","Epoch 00062: val_accuracy did not improve from 0.90640\n","Epoch 63/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0956 - accuracy: 0.9683 - val_loss: 0.6999 - val_accuracy: 0.8596\n","\n","Epoch 00063: val_accuracy did not improve from 0.90640\n","Epoch 64/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0833 - accuracy: 0.9726 - val_loss: 0.5163 - val_accuracy: 0.8867\n","\n","Epoch 00064: val_accuracy did not improve from 0.90640\n","Epoch 65/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0756 - accuracy: 0.9775 - val_loss: 0.7123 - val_accuracy: 0.8695\n","\n","Epoch 00065: val_accuracy did not improve from 0.90640\n","Epoch 66/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0646 - accuracy: 0.9829 - val_loss: 0.4481 - val_accuracy: 0.9015\n","\n","Epoch 00066: val_accuracy did not improve from 0.90640\n","Epoch 67/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0719 - accuracy: 0.9750 - val_loss: 0.4395 - val_accuracy: 0.8990\n","\n","Epoch 00067: val_accuracy did not improve from 0.90640\n","Epoch 68/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0586 - accuracy: 0.9811 - val_loss: 0.4798 - val_accuracy: 0.8744\n","\n","Epoch 00068: val_accuracy did not improve from 0.90640\n","Epoch 69/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.1015 - accuracy: 0.9689 - val_loss: 0.7795 - val_accuracy: 0.8522\n","\n","Epoch 00069: val_accuracy did not improve from 0.90640\n","Epoch 70/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1563 - accuracy: 0.9513 - val_loss: 0.8624 - val_accuracy: 0.8547\n","\n","Epoch 00070: val_accuracy did not improve from 0.90640\n","Epoch 71/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0637 - accuracy: 0.9769 - val_loss: 0.5449 - val_accuracy: 0.8842\n","\n","Epoch 00071: val_accuracy did not improve from 0.90640\n","Epoch 72/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0598 - accuracy: 0.9799 - val_loss: 0.4073 - val_accuracy: 0.8966\n","\n","Epoch 00072: val_accuracy did not improve from 0.90640\n","Epoch 73/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.4028 - val_accuracy: 0.8990\n","\n","Epoch 00073: val_accuracy did not improve from 0.90640\n","Epoch 74/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0573 - accuracy: 0.9793 - val_loss: 0.4866 - val_accuracy: 0.9064\n","\n","Epoch 00074: val_accuracy did not improve from 0.90640\n","Epoch 75/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0649 - accuracy: 0.9787 - val_loss: 0.5393 - val_accuracy: 0.8719\n","\n","Epoch 00075: val_accuracy did not improve from 0.90640\n","Epoch 76/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0790 - accuracy: 0.9732 - val_loss: 0.6114 - val_accuracy: 0.8818\n","\n","Epoch 00076: val_accuracy did not improve from 0.90640\n","Epoch 77/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0546 - accuracy: 0.9805 - val_loss: 0.5749 - val_accuracy: 0.8744\n","\n","Epoch 00077: val_accuracy did not improve from 0.90640\n","Epoch 78/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0779 - accuracy: 0.9726 - val_loss: 0.5941 - val_accuracy: 0.8719\n","\n","Epoch 00078: val_accuracy did not improve from 0.90640\n","Epoch 79/500\n","103/103 [==============================] - 14s 131ms/step - loss: 0.0958 - accuracy: 0.9665 - val_loss: 0.6756 - val_accuracy: 0.8645\n","\n","Epoch 00079: val_accuracy did not improve from 0.90640\n","Epoch 80/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0653 - accuracy: 0.9811 - val_loss: 0.5018 - val_accuracy: 0.8744\n","\n","Epoch 00080: val_accuracy did not improve from 0.90640\n","Epoch 81/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0526 - accuracy: 0.9799 - val_loss: 0.4710 - val_accuracy: 0.8892\n","\n","Epoch 00081: val_accuracy did not improve from 0.90640\n","Epoch 82/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0799 - accuracy: 0.9726 - val_loss: 0.5623 - val_accuracy: 0.8719\n","\n","Epoch 00082: val_accuracy did not improve from 0.90640\n","Epoch 83/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0478 - accuracy: 0.9848 - val_loss: 0.6238 - val_accuracy: 0.8670\n","\n","Epoch 00083: val_accuracy did not improve from 0.90640\n","Epoch 84/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0432 - accuracy: 0.9842 - val_loss: 0.5144 - val_accuracy: 0.8818\n","\n","Epoch 00084: val_accuracy did not improve from 0.90640\n","Epoch 85/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0384 - accuracy: 0.9848 - val_loss: 0.6448 - val_accuracy: 0.8719\n","\n","Epoch 00085: val_accuracy did not improve from 0.90640\n","Epoch 86/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0517 - accuracy: 0.9775 - val_loss: 0.4645 - val_accuracy: 0.8867\n","\n","Epoch 00086: val_accuracy did not improve from 0.90640\n","Epoch 87/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0643 - accuracy: 0.9793 - val_loss: 0.5825 - val_accuracy: 0.8842\n","\n","Epoch 00087: val_accuracy did not improve from 0.90640\n","Epoch 88/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0406 - accuracy: 0.9872 - val_loss: 0.4286 - val_accuracy: 0.9113\n","\n","Epoch 00088: val_accuracy improved from 0.90640 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 89/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0315 - accuracy: 0.9915 - val_loss: 0.5684 - val_accuracy: 0.8867\n","\n","Epoch 00089: val_accuracy did not improve from 0.91133\n","Epoch 90/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.5669 - val_accuracy: 0.8916\n","\n","Epoch 00090: val_accuracy did not improve from 0.91133\n","Epoch 91/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0661 - accuracy: 0.9781 - val_loss: 1.2502 - val_accuracy: 0.7956\n","\n","Epoch 00091: val_accuracy did not improve from 0.91133\n","Epoch 92/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0814 - accuracy: 0.9708 - val_loss: 0.5081 - val_accuracy: 0.8695\n","\n","Epoch 00092: val_accuracy did not improve from 0.91133\n","Epoch 93/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0495 - accuracy: 0.9836 - val_loss: 0.5225 - val_accuracy: 0.8966\n","\n","Epoch 00093: val_accuracy did not improve from 0.91133\n","Epoch 94/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0572 - accuracy: 0.9836 - val_loss: 0.4799 - val_accuracy: 0.8744\n","\n","Epoch 00094: val_accuracy did not improve from 0.91133\n","Epoch 95/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0472 - accuracy: 0.9848 - val_loss: 0.5508 - val_accuracy: 0.8818\n","\n","Epoch 00095: val_accuracy did not improve from 0.91133\n","Epoch 96/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0614 - accuracy: 0.9775 - val_loss: 0.4988 - val_accuracy: 0.8966\n","\n","Epoch 00096: val_accuracy did not improve from 0.91133\n","Epoch 97/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0347 - accuracy: 0.9896 - val_loss: 0.4855 - val_accuracy: 0.9064\n","\n","Epoch 00097: val_accuracy did not improve from 0.91133\n","Epoch 98/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.5864 - val_accuracy: 0.8695\n","\n","Epoch 00098: val_accuracy did not improve from 0.91133\n","Epoch 99/500\n","103/103 [==============================] - 14s 131ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 0.4726 - val_accuracy: 0.8892\n","\n","Epoch 00099: val_accuracy did not improve from 0.91133\n","Epoch 100/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0264 - accuracy: 0.9933 - val_loss: 0.4466 - val_accuracy: 0.8941\n","\n","Epoch 00100: val_accuracy did not improve from 0.91133\n","Epoch 101/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0395 - accuracy: 0.9884 - val_loss: 0.6348 - val_accuracy: 0.8744\n","\n","Epoch 00101: val_accuracy did not improve from 0.91133\n","Epoch 102/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0273 - accuracy: 0.9933 - val_loss: 0.4813 - val_accuracy: 0.8867\n","\n","Epoch 00102: val_accuracy did not improve from 0.91133\n","Epoch 103/500\n","103/103 [==============================] - 14s 131ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.3437 - val_accuracy: 0.9064\n","\n","Epoch 00103: val_accuracy did not improve from 0.91133\n","Epoch 104/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0142 - accuracy: 0.9939 - val_loss: 0.4832 - val_accuracy: 0.8916\n","\n","Epoch 00104: val_accuracy did not improve from 0.91133\n","Epoch 105/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0277 - accuracy: 0.9890 - val_loss: 0.4742 - val_accuracy: 0.8966\n","\n","Epoch 00105: val_accuracy did not improve from 0.91133\n","Epoch 106/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0362 - accuracy: 0.9896 - val_loss: 1.0711 - val_accuracy: 0.8251\n","\n","Epoch 00106: val_accuracy did not improve from 0.91133\n","Epoch 107/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.1205 - accuracy: 0.9604 - val_loss: 1.0694 - val_accuracy: 0.8276\n","\n","Epoch 00107: val_accuracy did not improve from 0.91133\n","Epoch 108/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0932 - accuracy: 0.9695 - val_loss: 0.5625 - val_accuracy: 0.8719\n","\n","Epoch 00108: val_accuracy did not improve from 0.91133\n","Epoch 109/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0620 - accuracy: 0.9787 - val_loss: 0.3912 - val_accuracy: 0.8966\n","\n","Epoch 00109: val_accuracy did not improve from 0.91133\n","Epoch 110/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0339 - accuracy: 0.9878 - val_loss: 0.4144 - val_accuracy: 0.9113\n","\n","Epoch 00110: val_accuracy did not improve from 0.91133\n","Epoch 111/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.3881 - val_accuracy: 0.9187\n","\n","Epoch 00111: val_accuracy improved from 0.91133 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 112/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0201 - accuracy: 0.9951 - val_loss: 0.4240 - val_accuracy: 0.9089\n","\n","Epoch 00112: val_accuracy did not improve from 0.91872\n","Epoch 113/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.6033 - val_accuracy: 0.8695\n","\n","Epoch 00113: val_accuracy did not improve from 0.91872\n","Epoch 114/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0358 - accuracy: 0.9890 - val_loss: 0.7016 - val_accuracy: 0.8793\n","\n","Epoch 00114: val_accuracy did not improve from 0.91872\n","Epoch 115/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0334 - accuracy: 0.9878 - val_loss: 0.6016 - val_accuracy: 0.8670\n","\n","Epoch 00115: val_accuracy did not improve from 0.91872\n","Epoch 116/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0436 - accuracy: 0.9836 - val_loss: 0.7077 - val_accuracy: 0.8695\n","\n","Epoch 00116: val_accuracy did not improve from 0.91872\n","Epoch 117/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0313 - accuracy: 0.9896 - val_loss: 0.5095 - val_accuracy: 0.8941\n","\n","Epoch 00117: val_accuracy did not improve from 0.91872\n","Epoch 118/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0158 - accuracy: 0.9970 - val_loss: 0.4712 - val_accuracy: 0.9015\n","\n","Epoch 00118: val_accuracy did not improve from 0.91872\n","Epoch 119/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0571 - accuracy: 0.9829 - val_loss: 0.5126 - val_accuracy: 0.9015\n","\n","Epoch 00119: val_accuracy did not improve from 0.91872\n","Epoch 120/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.6936 - val_accuracy: 0.8547\n","\n","Epoch 00120: val_accuracy did not improve from 0.91872\n","Epoch 121/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0306 - accuracy: 0.9878 - val_loss: 0.5011 - val_accuracy: 0.8768\n","\n","Epoch 00121: val_accuracy did not improve from 0.91872\n","Epoch 122/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0768 - accuracy: 0.9750 - val_loss: 0.7035 - val_accuracy: 0.8522\n","\n","Epoch 00122: val_accuracy did not improve from 0.91872\n","Epoch 123/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0259 - accuracy: 0.9909 - val_loss: 0.5365 - val_accuracy: 0.9015\n","\n","Epoch 00123: val_accuracy did not improve from 0.91872\n","Epoch 124/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.3890 - val_accuracy: 0.9113\n","\n","Epoch 00124: val_accuracy did not improve from 0.91872\n","Epoch 125/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0302 - accuracy: 0.9903 - val_loss: 0.3912 - val_accuracy: 0.9138\n","\n","Epoch 00125: val_accuracy did not improve from 0.91872\n","Epoch 126/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0399 - accuracy: 0.9890 - val_loss: 0.6262 - val_accuracy: 0.8892\n","\n","Epoch 00126: val_accuracy did not improve from 0.91872\n","Epoch 127/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0371 - accuracy: 0.9872 - val_loss: 0.4587 - val_accuracy: 0.9064\n","\n","Epoch 00127: val_accuracy did not improve from 0.91872\n","Epoch 128/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0445 - accuracy: 0.9860 - val_loss: 0.5422 - val_accuracy: 0.8818\n","\n","Epoch 00128: val_accuracy did not improve from 0.91872\n","Epoch 129/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0439 - accuracy: 0.9854 - val_loss: 0.7021 - val_accuracy: 0.8670\n","\n","Epoch 00129: val_accuracy did not improve from 0.91872\n","Epoch 130/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0504 - accuracy: 0.9805 - val_loss: 0.5761 - val_accuracy: 0.8793\n","\n","Epoch 00130: val_accuracy did not improve from 0.91872\n","Epoch 131/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0232 - accuracy: 0.9915 - val_loss: 0.5670 - val_accuracy: 0.8867\n","\n","Epoch 00131: val_accuracy did not improve from 0.91872\n","Epoch 132/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0294 - accuracy: 0.9927 - val_loss: 0.4348 - val_accuracy: 0.9039\n","\n","Epoch 00132: val_accuracy did not improve from 0.91872\n","Epoch 133/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.5289 - val_accuracy: 0.8867\n","\n","Epoch 00133: val_accuracy did not improve from 0.91872\n","Epoch 134/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.4082 - val_accuracy: 0.8990\n","\n","Epoch 00134: val_accuracy did not improve from 0.91872\n","Epoch 135/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.4160 - val_accuracy: 0.9212\n","\n","Epoch 00135: val_accuracy improved from 0.91872 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 136/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.6203 - val_accuracy: 0.8941\n","\n","Epoch 00136: val_accuracy did not improve from 0.92118\n","Epoch 137/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0256 - accuracy: 0.9939 - val_loss: 0.6216 - val_accuracy: 0.8892\n","\n","Epoch 00137: val_accuracy did not improve from 0.92118\n","Epoch 138/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0767 - accuracy: 0.9769 - val_loss: 0.6966 - val_accuracy: 0.8399\n","\n","Epoch 00138: val_accuracy did not improve from 0.92118\n","Epoch 139/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0611 - accuracy: 0.9817 - val_loss: 0.6584 - val_accuracy: 0.8744\n","\n","Epoch 00139: val_accuracy did not improve from 0.92118\n","Epoch 140/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0411 - accuracy: 0.9866 - val_loss: 0.5202 - val_accuracy: 0.8990\n","\n","Epoch 00140: val_accuracy did not improve from 0.92118\n","Epoch 141/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.4915 - val_accuracy: 0.8966\n","\n","Epoch 00141: val_accuracy did not improve from 0.92118\n","Epoch 142/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0141 - accuracy: 0.9976 - val_loss: 0.4350 - val_accuracy: 0.9138\n","\n","Epoch 00142: val_accuracy did not improve from 0.92118\n","Epoch 143/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.3720 - val_accuracy: 0.9286\n","\n","Epoch 00143: val_accuracy improved from 0.92118 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 144/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.3666 - val_accuracy: 0.9089\n","\n","Epoch 00144: val_accuracy did not improve from 0.92857\n","Epoch 145/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0274 - accuracy: 0.9933 - val_loss: 0.4747 - val_accuracy: 0.8916\n","\n","Epoch 00145: val_accuracy did not improve from 0.92857\n","Epoch 146/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0218 - accuracy: 0.9945 - val_loss: 0.5078 - val_accuracy: 0.8916\n","\n","Epoch 00146: val_accuracy did not improve from 0.92857\n","Epoch 147/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 0.7314 - val_accuracy: 0.8621\n","\n","Epoch 00147: val_accuracy did not improve from 0.92857\n","Epoch 148/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0628 - accuracy: 0.9805 - val_loss: 0.6479 - val_accuracy: 0.8424\n","\n","Epoch 00148: val_accuracy did not improve from 0.92857\n","Epoch 149/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0528 - accuracy: 0.9811 - val_loss: 0.7036 - val_accuracy: 0.8842\n","\n","Epoch 00149: val_accuracy did not improve from 0.92857\n","Epoch 150/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.5943 - val_accuracy: 0.8892\n","\n","Epoch 00150: val_accuracy did not improve from 0.92857\n","Epoch 151/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.5183 - val_accuracy: 0.9015\n","\n","Epoch 00151: val_accuracy did not improve from 0.92857\n","Epoch 152/500\n","103/103 [==============================] - 14s 132ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.5202 - val_accuracy: 0.9039\n","\n","Epoch 00152: val_accuracy did not improve from 0.92857\n","Epoch 153/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0230 - accuracy: 0.9915 - val_loss: 0.4019 - val_accuracy: 0.9113\n","\n","Epoch 00153: val_accuracy did not improve from 0.92857\n","Epoch 154/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0175 - accuracy: 0.9927 - val_loss: 0.6406 - val_accuracy: 0.8793\n","\n","Epoch 00154: val_accuracy did not improve from 0.92857\n","Epoch 155/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.4211 - val_accuracy: 0.9212\n","\n","Epoch 00155: val_accuracy did not improve from 0.92857\n","Epoch 156/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0221 - accuracy: 0.9915 - val_loss: 0.5230 - val_accuracy: 0.8941\n","\n","Epoch 00156: val_accuracy did not improve from 0.92857\n","Epoch 157/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0403 - accuracy: 0.9866 - val_loss: 0.5384 - val_accuracy: 0.8941\n","\n","Epoch 00157: val_accuracy did not improve from 0.92857\n","Epoch 158/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.6123 - val_accuracy: 0.8596\n","\n","Epoch 00158: val_accuracy did not improve from 0.92857\n","Epoch 159/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.4730 - val_accuracy: 0.9113\n","\n","Epoch 00159: val_accuracy did not improve from 0.92857\n","Epoch 160/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.5016 - val_accuracy: 0.8966\n","\n","Epoch 00160: val_accuracy did not improve from 0.92857\n","Epoch 161/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0473 - accuracy: 0.9823 - val_loss: 0.5189 - val_accuracy: 0.8842\n","\n","Epoch 00161: val_accuracy did not improve from 0.92857\n","Epoch 162/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0274 - accuracy: 0.9927 - val_loss: 0.4844 - val_accuracy: 0.9064\n","\n","Epoch 00162: val_accuracy did not improve from 0.92857\n","Epoch 163/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.4827 - val_accuracy: 0.9089\n","\n","Epoch 00163: val_accuracy did not improve from 0.92857\n","Epoch 164/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.4567 - val_accuracy: 0.9015\n","\n","Epoch 00164: val_accuracy did not improve from 0.92857\n","Epoch 165/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9236\n","\n","Epoch 00165: val_accuracy did not improve from 0.92857\n","Epoch 166/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.9138\n","\n","Epoch 00166: val_accuracy did not improve from 0.92857\n","Epoch 167/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.5189 - val_accuracy: 0.9163\n","\n","Epoch 00167: val_accuracy did not improve from 0.92857\n","Epoch 168/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0598 - accuracy: 0.9866 - val_loss: 0.7126 - val_accuracy: 0.8744\n","\n","Epoch 00168: val_accuracy did not improve from 0.92857\n","Epoch 169/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0509 - accuracy: 0.9848 - val_loss: 0.6441 - val_accuracy: 0.8916\n","\n","Epoch 00169: val_accuracy did not improve from 0.92857\n","Epoch 170/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0288 - accuracy: 0.9903 - val_loss: 0.5075 - val_accuracy: 0.9089\n","\n","Epoch 00170: val_accuracy did not improve from 0.92857\n","Epoch 171/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.4532 - val_accuracy: 0.9138\n","\n","Epoch 00171: val_accuracy did not improve from 0.92857\n","Epoch 172/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.4689 - val_accuracy: 0.9015\n","\n","Epoch 00172: val_accuracy did not improve from 0.92857\n","Epoch 173/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4196 - val_accuracy: 0.9015\n","\n","Epoch 00173: val_accuracy did not improve from 0.92857\n","Epoch 174/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.3601 - val_accuracy: 0.9360\n","\n","Epoch 00174: val_accuracy improved from 0.92857 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 175/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0293 - accuracy: 0.9896 - val_loss: 0.6091 - val_accuracy: 0.8916\n","\n","Epoch 00175: val_accuracy did not improve from 0.93596\n","Epoch 176/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.4157 - val_accuracy: 0.9113\n","\n","Epoch 00176: val_accuracy did not improve from 0.93596\n","Epoch 177/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0344 - accuracy: 0.9890 - val_loss: 0.5871 - val_accuracy: 0.8842\n","\n","Epoch 00177: val_accuracy did not improve from 0.93596\n","Epoch 178/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.5021 - val_accuracy: 0.8990\n","\n","Epoch 00178: val_accuracy did not improve from 0.93596\n","Epoch 179/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0221 - accuracy: 0.9921 - val_loss: 0.4435 - val_accuracy: 0.9187\n","\n","Epoch 00179: val_accuracy did not improve from 0.93596\n","Epoch 180/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.7465 - val_accuracy: 0.8670\n","\n","Epoch 00180: val_accuracy did not improve from 0.93596\n","Epoch 181/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0213 - accuracy: 0.9909 - val_loss: 0.5892 - val_accuracy: 0.8941\n","\n","Epoch 00181: val_accuracy did not improve from 0.93596\n","Epoch 182/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.4425 - val_accuracy: 0.8793\n","\n","Epoch 00182: val_accuracy did not improve from 0.93596\n","Epoch 183/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.4324 - val_accuracy: 0.9138\n","\n","Epoch 00183: val_accuracy did not improve from 0.93596\n","Epoch 184/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0336 - accuracy: 0.9896 - val_loss: 0.7591 - val_accuracy: 0.8793\n","\n","Epoch 00184: val_accuracy did not improve from 0.93596\n","Epoch 185/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0601 - accuracy: 0.9829 - val_loss: 0.6350 - val_accuracy: 0.8695\n","\n","Epoch 00185: val_accuracy did not improve from 0.93596\n","Epoch 186/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0409 - accuracy: 0.9848 - val_loss: 0.7300 - val_accuracy: 0.8399\n","\n","Epoch 00186: val_accuracy did not improve from 0.93596\n","Epoch 187/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.6456 - val_accuracy: 0.8768\n","\n","Epoch 00187: val_accuracy did not improve from 0.93596\n","Epoch 188/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.4835 - val_accuracy: 0.9089\n","\n","Epoch 00188: val_accuracy did not improve from 0.93596\n","Epoch 189/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.5790 - val_accuracy: 0.8768\n","\n","Epoch 00189: val_accuracy did not improve from 0.93596\n","Epoch 190/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.4723 - val_accuracy: 0.9113\n","\n","Epoch 00190: val_accuracy did not improve from 0.93596\n","Epoch 191/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.5017 - val_accuracy: 0.8892\n","\n","Epoch 00191: val_accuracy did not improve from 0.93596\n","Epoch 192/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.5168 - val_accuracy: 0.9015\n","\n","Epoch 00192: val_accuracy did not improve from 0.93596\n","Epoch 193/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.4251 - val_accuracy: 0.9064\n","\n","Epoch 00193: val_accuracy did not improve from 0.93596\n","Epoch 194/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.5972 - val_accuracy: 0.8818\n","\n","Epoch 00194: val_accuracy did not improve from 0.93596\n","Epoch 195/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.6058 - val_accuracy: 0.8842\n","\n","Epoch 00195: val_accuracy did not improve from 0.93596\n","Epoch 196/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.4110 - val_accuracy: 0.9089\n","\n","Epoch 00196: val_accuracy did not improve from 0.93596\n","Epoch 197/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.4893 - val_accuracy: 0.9039\n","\n","Epoch 00197: val_accuracy did not improve from 0.93596\n","Epoch 198/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.4971 - val_accuracy: 0.9187\n","\n","Epoch 00198: val_accuracy did not improve from 0.93596\n","Epoch 199/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0209 - accuracy: 0.9921 - val_loss: 0.4483 - val_accuracy: 0.9138\n","\n","Epoch 00199: val_accuracy did not improve from 0.93596\n","Epoch 200/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.8790 - val_accuracy: 0.8645\n","\n","Epoch 00200: val_accuracy did not improve from 0.93596\n","Epoch 201/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 0.7869 - val_accuracy: 0.8818\n","\n","Epoch 00201: val_accuracy did not improve from 0.93596\n","Epoch 202/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0465 - accuracy: 0.9878 - val_loss: 0.5920 - val_accuracy: 0.8768\n","\n","Epoch 00202: val_accuracy did not improve from 0.93596\n","Epoch 203/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.5780 - val_accuracy: 0.8966\n","\n","Epoch 00203: val_accuracy did not improve from 0.93596\n","Epoch 204/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0274 - accuracy: 0.9927 - val_loss: 0.7570 - val_accuracy: 0.8719\n","\n","Epoch 00204: val_accuracy did not improve from 0.93596\n","Epoch 205/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.4946 - val_accuracy: 0.8941\n","\n","Epoch 00205: val_accuracy did not improve from 0.93596\n","Epoch 206/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.4982 - val_accuracy: 0.9015\n","\n","Epoch 00206: val_accuracy did not improve from 0.93596\n","Epoch 207/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.4223 - val_accuracy: 0.9138\n","\n","Epoch 00207: val_accuracy did not improve from 0.93596\n","Epoch 208/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0161 - accuracy: 0.9939 - val_loss: 0.5607 - val_accuracy: 0.8892\n","\n","Epoch 00208: val_accuracy did not improve from 0.93596\n","Epoch 209/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.5221 - val_accuracy: 0.8990\n","\n","Epoch 00209: val_accuracy did not improve from 0.93596\n","Epoch 210/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.6009 - val_accuracy: 0.8966\n","\n","Epoch 00210: val_accuracy did not improve from 0.93596\n","Epoch 211/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 0.4304 - val_accuracy: 0.9236\n","\n","Epoch 00211: val_accuracy did not improve from 0.93596\n","Epoch 212/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.5002 - val_accuracy: 0.9064\n","\n","Epoch 00212: val_accuracy did not improve from 0.93596\n","Epoch 213/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.5924 - val_accuracy: 0.9064\n","\n","Epoch 00213: val_accuracy did not improve from 0.93596\n","Epoch 214/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.5299 - val_accuracy: 0.9039\n","\n","Epoch 00214: val_accuracy did not improve from 0.93596\n","Epoch 215/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0208 - accuracy: 0.9945 - val_loss: 0.6319 - val_accuracy: 0.8867\n","\n","Epoch 00215: val_accuracy did not improve from 0.93596\n","Epoch 216/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0152 - accuracy: 0.9927 - val_loss: 0.6800 - val_accuracy: 0.8941\n","\n","Epoch 00216: val_accuracy did not improve from 0.93596\n","Epoch 217/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.5335 - val_accuracy: 0.9039\n","\n","Epoch 00217: val_accuracy did not improve from 0.93596\n","Epoch 218/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.6564 - val_accuracy: 0.8744\n","\n","Epoch 00218: val_accuracy did not improve from 0.93596\n","Epoch 219/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0451 - accuracy: 0.9872 - val_loss: 0.6513 - val_accuracy: 0.8916\n","\n","Epoch 00219: val_accuracy did not improve from 0.93596\n","Epoch 220/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0430 - accuracy: 0.9872 - val_loss: 0.8744 - val_accuracy: 0.8695\n","\n","Epoch 00220: val_accuracy did not improve from 0.93596\n","Epoch 221/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0452 - accuracy: 0.9872 - val_loss: 0.5603 - val_accuracy: 0.8892\n","\n","Epoch 00221: val_accuracy did not improve from 0.93596\n","Epoch 222/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0231 - accuracy: 0.9909 - val_loss: 0.5865 - val_accuracy: 0.8842\n","\n","Epoch 00222: val_accuracy did not improve from 0.93596\n","Epoch 223/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0191 - accuracy: 0.9921 - val_loss: 0.6136 - val_accuracy: 0.8842\n","\n","Epoch 00223: val_accuracy did not improve from 0.93596\n","Epoch 224/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 0.4152 - val_accuracy: 0.9064\n","\n","Epoch 00224: val_accuracy did not improve from 0.93596\n","Epoch 225/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.4497 - val_accuracy: 0.8990\n","\n","Epoch 00225: val_accuracy did not improve from 0.93596\n","Epoch 226/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9064\n","\n","Epoch 00226: val_accuracy did not improve from 0.93596\n","Epoch 227/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.4709 - val_accuracy: 0.8990\n","\n","Epoch 00227: val_accuracy did not improve from 0.93596\n","Epoch 228/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4030 - val_accuracy: 0.9138\n","\n","Epoch 00228: val_accuracy did not improve from 0.93596\n","Epoch 229/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.9236\n","\n","Epoch 00229: val_accuracy did not improve from 0.93596\n","Epoch 230/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4861 - val_accuracy: 0.9015\n","\n","Epoch 00230: val_accuracy did not improve from 0.93596\n","Epoch 231/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3866 - val_accuracy: 0.9286\n","\n","Epoch 00231: val_accuracy did not improve from 0.93596\n","Epoch 232/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4891 - val_accuracy: 0.9039\n","\n","Epoch 00232: val_accuracy did not improve from 0.93596\n","Epoch 233/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0148 - accuracy: 0.9939 - val_loss: 0.5378 - val_accuracy: 0.8842\n","\n","Epoch 00233: val_accuracy did not improve from 0.93596\n","Epoch 234/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0288 - accuracy: 0.9921 - val_loss: 0.8952 - val_accuracy: 0.8522\n","\n","Epoch 00234: val_accuracy did not improve from 0.93596\n","Epoch 235/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0628 - accuracy: 0.9829 - val_loss: 0.9238 - val_accuracy: 0.8374\n","\n","Epoch 00235: val_accuracy did not improve from 0.93596\n","Epoch 236/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0462 - accuracy: 0.9866 - val_loss: 0.5413 - val_accuracy: 0.8892\n","\n","Epoch 00236: val_accuracy did not improve from 0.93596\n","Epoch 237/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0267 - accuracy: 0.9896 - val_loss: 0.4540 - val_accuracy: 0.9039\n","\n","Epoch 00237: val_accuracy did not improve from 0.93596\n","Epoch 238/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0187 - accuracy: 0.9921 - val_loss: 0.5678 - val_accuracy: 0.9015\n","\n","Epoch 00238: val_accuracy did not improve from 0.93596\n","Epoch 239/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0305 - accuracy: 0.9909 - val_loss: 0.4926 - val_accuracy: 0.9039\n","\n","Epoch 00239: val_accuracy did not improve from 0.93596\n","Epoch 240/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.5676 - val_accuracy: 0.8916\n","\n","Epoch 00240: val_accuracy did not improve from 0.93596\n","Epoch 241/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.4167 - val_accuracy: 0.9187\n","\n","Epoch 00241: val_accuracy did not improve from 0.93596\n","Epoch 242/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.5554 - val_accuracy: 0.8966\n","\n","Epoch 00242: val_accuracy did not improve from 0.93596\n","Epoch 243/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0103 - accuracy: 0.9957 - val_loss: 0.4699 - val_accuracy: 0.9015\n","\n","Epoch 00243: val_accuracy did not improve from 0.93596\n","Epoch 244/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.7353 - val_accuracy: 0.8473\n","\n","Epoch 00244: val_accuracy did not improve from 0.93596\n","Epoch 245/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0240 - accuracy: 0.9945 - val_loss: 0.5462 - val_accuracy: 0.8966\n","\n","Epoch 00245: val_accuracy did not improve from 0.93596\n","Epoch 246/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.5116 - val_accuracy: 0.9089\n","\n","Epoch 00246: val_accuracy did not improve from 0.93596\n","Epoch 247/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4706 - val_accuracy: 0.9138\n","\n","Epoch 00247: val_accuracy did not improve from 0.93596\n","Epoch 248/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.9163\n","\n","Epoch 00248: val_accuracy did not improve from 0.93596\n","Epoch 249/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.6473 - val_accuracy: 0.8990\n","\n","Epoch 00249: val_accuracy did not improve from 0.93596\n","Epoch 250/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0326 - accuracy: 0.9933 - val_loss: 0.7098 - val_accuracy: 0.8768\n","\n","Epoch 00250: val_accuracy did not improve from 0.93596\n","Epoch 251/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0441 - accuracy: 0.9848 - val_loss: 0.5493 - val_accuracy: 0.8818\n","\n","Epoch 00251: val_accuracy did not improve from 0.93596\n","Epoch 252/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.5801 - val_accuracy: 0.9039\n","\n","Epoch 00252: val_accuracy did not improve from 0.93596\n","Epoch 253/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0204 - accuracy: 0.9915 - val_loss: 0.5979 - val_accuracy: 0.8867\n","\n","Epoch 00253: val_accuracy did not improve from 0.93596\n","Epoch 254/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.5313 - val_accuracy: 0.9015\n","\n","Epoch 00254: val_accuracy did not improve from 0.93596\n","Epoch 255/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.5310 - val_accuracy: 0.9015\n","\n","Epoch 00255: val_accuracy did not improve from 0.93596\n","Epoch 256/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.4710 - val_accuracy: 0.9089\n","\n","Epoch 00256: val_accuracy did not improve from 0.93596\n","Epoch 257/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4090 - val_accuracy: 0.9163\n","\n","Epoch 00257: val_accuracy did not improve from 0.93596\n","Epoch 258/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9113\n","\n","Epoch 00258: val_accuracy did not improve from 0.93596\n","Epoch 259/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4309 - val_accuracy: 0.9187\n","\n","Epoch 00259: val_accuracy did not improve from 0.93596\n","Epoch 260/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.4829 - val_accuracy: 0.9187\n","\n","Epoch 00260: val_accuracy did not improve from 0.93596\n","Epoch 261/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.6911 - val_accuracy: 0.8892\n","\n","Epoch 00261: val_accuracy did not improve from 0.93596\n","Epoch 262/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.4248 - val_accuracy: 0.9039\n","\n","Epoch 00262: val_accuracy did not improve from 0.93596\n","Epoch 263/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.6479 - val_accuracy: 0.8744\n","\n","Epoch 00263: val_accuracy did not improve from 0.93596\n","Epoch 264/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0274 - accuracy: 0.9896 - val_loss: 0.9872 - val_accuracy: 0.8054\n","\n","Epoch 00264: val_accuracy did not improve from 0.93596\n","Epoch 265/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0394 - accuracy: 0.9884 - val_loss: 0.6687 - val_accuracy: 0.8719\n","\n","Epoch 00265: val_accuracy did not improve from 0.93596\n","Epoch 266/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.4282 - val_accuracy: 0.9212\n","\n","Epoch 00266: val_accuracy did not improve from 0.93596\n","Epoch 267/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4533 - val_accuracy: 0.9310\n","\n","Epoch 00267: val_accuracy did not improve from 0.93596\n","Epoch 268/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5149 - val_accuracy: 0.9039\n","\n","Epoch 00268: val_accuracy did not improve from 0.93596\n","Epoch 269/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.5618 - val_accuracy: 0.8990\n","\n","Epoch 00269: val_accuracy did not improve from 0.93596\n","Epoch 270/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4052 - val_accuracy: 0.9286\n","\n","Epoch 00270: val_accuracy did not improve from 0.93596\n","Epoch 271/500\n","103/103 [==============================] - 14s 134ms/step - loss: 8.4498e-04 - accuracy: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.9212\n","\n","Epoch 00271: val_accuracy did not improve from 0.93596\n","Epoch 272/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5132 - val_accuracy: 0.9113\n","\n","Epoch 00272: val_accuracy did not improve from 0.93596\n","Epoch 273/500\n","103/103 [==============================] - 14s 134ms/step - loss: 6.1440e-04 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9335\n","\n","Epoch 00273: val_accuracy did not improve from 0.93596\n","Epoch 274/500\n","103/103 [==============================] - 14s 137ms/step - loss: 8.1779e-04 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.9335\n","\n","Epoch 00274: val_accuracy did not improve from 0.93596\n","Epoch 275/500\n","103/103 [==============================] - 14s 135ms/step - loss: 3.4895e-04 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.9335\n","\n","Epoch 00275: val_accuracy did not improve from 0.93596\n","Epoch 276/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.6494 - val_accuracy: 0.8941\n","\n","Epoch 00276: val_accuracy did not improve from 0.93596\n","Epoch 277/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0238 - accuracy: 0.9951 - val_loss: 0.6868 - val_accuracy: 0.8867\n","\n","Epoch 00277: val_accuracy did not improve from 0.93596\n","Epoch 278/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0229 - accuracy: 0.9951 - val_loss: 0.5970 - val_accuracy: 0.9187\n","\n","Epoch 00278: val_accuracy did not improve from 0.93596\n","Epoch 279/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.5749 - val_accuracy: 0.9113\n","\n","Epoch 00279: val_accuracy did not improve from 0.93596\n","Epoch 280/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.5116 - val_accuracy: 0.9064\n","\n","Epoch 00280: val_accuracy did not improve from 0.93596\n","Epoch 281/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.8386 - val_accuracy: 0.8621\n","\n","Epoch 00281: val_accuracy did not improve from 0.93596\n","Epoch 282/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0271 - accuracy: 0.9909 - val_loss: 0.5981 - val_accuracy: 0.8768\n","\n","Epoch 00282: val_accuracy did not improve from 0.93596\n","Epoch 283/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0420 - accuracy: 0.9860 - val_loss: 0.7091 - val_accuracy: 0.8768\n","\n","Epoch 00283: val_accuracy did not improve from 0.93596\n","Epoch 284/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.4261 - val_accuracy: 0.9187\n","\n","Epoch 00284: val_accuracy did not improve from 0.93596\n","Epoch 285/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.5824 - val_accuracy: 0.8892\n","\n","Epoch 00285: val_accuracy did not improve from 0.93596\n","Epoch 286/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 0.5990 - val_accuracy: 0.8842\n","\n","Epoch 00286: val_accuracy did not improve from 0.93596\n","Epoch 287/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0261 - accuracy: 0.9927 - val_loss: 0.6263 - val_accuracy: 0.8744\n","\n","Epoch 00287: val_accuracy did not improve from 0.93596\n","Epoch 288/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.4800 - val_accuracy: 0.9138\n","\n","Epoch 00288: val_accuracy did not improve from 0.93596\n","Epoch 289/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0091 - accuracy: 0.9988 - val_loss: 0.4938 - val_accuracy: 0.9064\n","\n","Epoch 00289: val_accuracy did not improve from 0.93596\n","Epoch 290/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.4574 - val_accuracy: 0.9064\n","\n","Epoch 00290: val_accuracy did not improve from 0.93596\n","Epoch 291/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.4842 - val_accuracy: 0.9039\n","\n","Epoch 00291: val_accuracy did not improve from 0.93596\n","Epoch 292/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.5240 - val_accuracy: 0.8990\n","\n","Epoch 00292: val_accuracy did not improve from 0.93596\n","Epoch 293/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.4504 - val_accuracy: 0.8966\n","\n","Epoch 00293: val_accuracy did not improve from 0.93596\n","Epoch 294/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5180 - val_accuracy: 0.9064\n","\n","Epoch 00294: val_accuracy did not improve from 0.93596\n","Epoch 295/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0099 - accuracy: 0.9951 - val_loss: 0.5047 - val_accuracy: 0.9039\n","\n","Epoch 00295: val_accuracy did not improve from 0.93596\n","Epoch 296/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0217 - accuracy: 0.9909 - val_loss: 0.6060 - val_accuracy: 0.8916\n","\n","Epoch 00296: val_accuracy did not improve from 0.93596\n","Epoch 297/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.6788 - val_accuracy: 0.8892\n","\n","Epoch 00297: val_accuracy did not improve from 0.93596\n","Epoch 298/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.6386 - val_accuracy: 0.8867\n","\n","Epoch 00298: val_accuracy did not improve from 0.93596\n","Epoch 299/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.4620 - val_accuracy: 0.9064\n","\n","Epoch 00299: val_accuracy did not improve from 0.93596\n","Epoch 300/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.5557 - val_accuracy: 0.8842\n","\n","Epoch 00300: val_accuracy did not improve from 0.93596\n","Epoch 301/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.9163\n","\n","Epoch 00301: val_accuracy did not improve from 0.93596\n","Epoch 302/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4930 - val_accuracy: 0.9138\n","\n","Epoch 00302: val_accuracy did not improve from 0.93596\n","Epoch 303/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.4963 - val_accuracy: 0.9015\n","\n","Epoch 00303: val_accuracy did not improve from 0.93596\n","Epoch 304/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.5754 - val_accuracy: 0.8892\n","\n","Epoch 00304: val_accuracy did not improve from 0.93596\n","Epoch 305/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.4794 - val_accuracy: 0.9015\n","\n","Epoch 00305: val_accuracy did not improve from 0.93596\n","Epoch 306/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.5515 - val_accuracy: 0.8916\n","\n","Epoch 00306: val_accuracy did not improve from 0.93596\n","Epoch 307/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.5729 - val_accuracy: 0.8941\n","\n","Epoch 00307: val_accuracy did not improve from 0.93596\n","Epoch 308/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.6113 - val_accuracy: 0.8719\n","\n","Epoch 00308: val_accuracy did not improve from 0.93596\n","Epoch 309/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.5748 - val_accuracy: 0.8966\n","\n","Epoch 00309: val_accuracy did not improve from 0.93596\n","Epoch 310/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0367 - accuracy: 0.9896 - val_loss: 0.7127 - val_accuracy: 0.8892\n","\n","Epoch 00310: val_accuracy did not improve from 0.93596\n","Epoch 311/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.5401 - val_accuracy: 0.9015\n","\n","Epoch 00311: val_accuracy did not improve from 0.93596\n","Epoch 312/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.4430 - val_accuracy: 0.9163\n","\n","Epoch 00312: val_accuracy did not improve from 0.93596\n","Epoch 313/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5745 - val_accuracy: 0.8892\n","\n","Epoch 00313: val_accuracy did not improve from 0.93596\n","Epoch 314/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.5982 - val_accuracy: 0.8990\n","\n","Epoch 00314: val_accuracy did not improve from 0.93596\n","Epoch 315/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.7990 - val_accuracy: 0.8892\n","\n","Epoch 00315: val_accuracy did not improve from 0.93596\n","Epoch 316/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0159 - accuracy: 0.9939 - val_loss: 0.5656 - val_accuracy: 0.9015\n","\n","Epoch 00316: val_accuracy did not improve from 0.93596\n","Epoch 317/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.5831 - val_accuracy: 0.8867\n","\n","Epoch 00317: val_accuracy did not improve from 0.93596\n","Epoch 318/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0186 - accuracy: 0.9927 - val_loss: 0.5117 - val_accuracy: 0.9039\n","\n","Epoch 00318: val_accuracy did not improve from 0.93596\n","Epoch 319/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.6135 - val_accuracy: 0.8990\n","\n","Epoch 00319: val_accuracy did not improve from 0.93596\n","Epoch 320/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 0.4688 - val_accuracy: 0.9039\n","\n","Epoch 00320: val_accuracy did not improve from 0.93596\n","Epoch 321/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.9985 - val_accuracy: 0.8227\n","\n","Epoch 00321: val_accuracy did not improve from 0.93596\n","Epoch 322/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0369 - accuracy: 0.9872 - val_loss: 0.6505 - val_accuracy: 0.8645\n","\n","Epoch 00322: val_accuracy did not improve from 0.93596\n","Epoch 323/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.4073 - val_accuracy: 0.9212\n","\n","Epoch 00323: val_accuracy did not improve from 0.93596\n","Epoch 324/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.4938 - val_accuracy: 0.9236\n","\n","Epoch 00324: val_accuracy did not improve from 0.93596\n","Epoch 325/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4725 - val_accuracy: 0.9064\n","\n","Epoch 00325: val_accuracy did not improve from 0.93596\n","Epoch 326/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5119 - val_accuracy: 0.9089\n","\n","Epoch 00326: val_accuracy did not improve from 0.93596\n","Epoch 327/500\n","103/103 [==============================] - 14s 134ms/step - loss: 8.2039e-04 - accuracy: 1.0000 - val_loss: 0.3893 - val_accuracy: 0.9360\n","\n","Epoch 00327: val_accuracy did not improve from 0.93596\n","Epoch 328/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.9236\n","\n","Epoch 00328: val_accuracy did not improve from 0.93596\n","Epoch 329/500\n","103/103 [==============================] - 14s 134ms/step - loss: 5.9049e-04 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9360\n","\n","Epoch 00329: val_accuracy did not improve from 0.93596\n","Epoch 330/500\n","103/103 [==============================] - 14s 134ms/step - loss: 5.9691e-04 - accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9138\n","\n","Epoch 00330: val_accuracy did not improve from 0.93596\n","Epoch 331/500\n","103/103 [==============================] - 14s 134ms/step - loss: 1.9857e-04 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9310\n","\n","Epoch 00331: val_accuracy did not improve from 0.93596\n","Epoch 332/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.8069 - val_accuracy: 0.8892\n","\n","Epoch 00332: val_accuracy did not improve from 0.93596\n","Epoch 333/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0304 - accuracy: 0.9909 - val_loss: 1.0284 - val_accuracy: 0.8374\n","\n","Epoch 00333: val_accuracy did not improve from 0.93596\n","Epoch 334/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0496 - accuracy: 0.9866 - val_loss: 0.7943 - val_accuracy: 0.8793\n","\n","Epoch 00334: val_accuracy did not improve from 0.93596\n","Epoch 335/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0190 - accuracy: 0.9921 - val_loss: 0.5656 - val_accuracy: 0.9138\n","\n","Epoch 00335: val_accuracy did not improve from 0.93596\n","Epoch 336/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.6303 - val_accuracy: 0.8966\n","\n","Epoch 00336: val_accuracy did not improve from 0.93596\n","Epoch 337/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.6705 - val_accuracy: 0.8941\n","\n","Epoch 00337: val_accuracy did not improve from 0.93596\n","Epoch 338/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0290 - accuracy: 0.9909 - val_loss: 0.6182 - val_accuracy: 0.8966\n","\n","Epoch 00338: val_accuracy did not improve from 0.93596\n","Epoch 339/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.5124 - val_accuracy: 0.9089\n","\n","Epoch 00339: val_accuracy did not improve from 0.93596\n","Epoch 340/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.4704 - val_accuracy: 0.9089\n","\n","Epoch 00340: val_accuracy did not improve from 0.93596\n","Epoch 341/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.9163\n","\n","Epoch 00341: val_accuracy did not improve from 0.93596\n","Epoch 342/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4519 - val_accuracy: 0.9212\n","\n","Epoch 00342: val_accuracy did not improve from 0.93596\n","Epoch 343/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5721 - val_accuracy: 0.9039\n","\n","Epoch 00343: val_accuracy did not improve from 0.93596\n","Epoch 344/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.9187\n","\n","Epoch 00344: val_accuracy did not improve from 0.93596\n","Epoch 345/500\n","103/103 [==============================] - 14s 134ms/step - loss: 8.4836e-04 - accuracy: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.9089\n","\n","Epoch 00345: val_accuracy did not improve from 0.93596\n","Epoch 346/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.7158 - val_accuracy: 0.8916\n","\n","Epoch 00346: val_accuracy did not improve from 0.93596\n","Epoch 347/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.4724 - val_accuracy: 0.9113\n","\n","Epoch 00347: val_accuracy did not improve from 0.93596\n","Epoch 348/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.9089\n","\n","Epoch 00348: val_accuracy did not improve from 0.93596\n","Epoch 349/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5001 - val_accuracy: 0.9187\n","\n","Epoch 00349: val_accuracy did not improve from 0.93596\n","Epoch 350/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4561 - val_accuracy: 0.9212\n","\n","Epoch 00350: val_accuracy did not improve from 0.93596\n","Epoch 351/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0087 - accuracy: 0.9945 - val_loss: 0.5624 - val_accuracy: 0.9064\n","\n","Epoch 00351: val_accuracy did not improve from 0.93596\n","Epoch 352/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4440 - val_accuracy: 0.9163\n","\n","Epoch 00352: val_accuracy did not improve from 0.93596\n","Epoch 353/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.4855 - val_accuracy: 0.9261\n","\n","Epoch 00353: val_accuracy did not improve from 0.93596\n","Epoch 354/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.8282 - val_accuracy: 0.8374\n","\n","Epoch 00354: val_accuracy did not improve from 0.93596\n","Epoch 355/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.6413 - val_accuracy: 0.8842\n","\n","Epoch 00355: val_accuracy did not improve from 0.93596\n","Epoch 356/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0328 - accuracy: 0.9878 - val_loss: 0.9915 - val_accuracy: 0.8670\n","\n","Epoch 00356: val_accuracy did not improve from 0.93596\n","Epoch 357/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0376 - accuracy: 0.9890 - val_loss: 0.7106 - val_accuracy: 0.8916\n","\n","Epoch 00357: val_accuracy did not improve from 0.93596\n","Epoch 358/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.5004 - val_accuracy: 0.9286\n","\n","Epoch 00358: val_accuracy did not improve from 0.93596\n","Epoch 359/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4758 - val_accuracy: 0.9187\n","\n","Epoch 00359: val_accuracy did not improve from 0.93596\n","Epoch 360/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9261\n","\n","Epoch 00360: val_accuracy did not improve from 0.93596\n","Epoch 361/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6187 - val_accuracy: 0.9113\n","\n","Epoch 00361: val_accuracy did not improve from 0.93596\n","Epoch 362/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5425 - val_accuracy: 0.9212\n","\n","Epoch 00362: val_accuracy did not improve from 0.93596\n","Epoch 363/500\n","103/103 [==============================] - 14s 135ms/step - loss: 5.3064e-04 - accuracy: 1.0000 - val_loss: 0.5328 - val_accuracy: 0.9039\n","\n","Epoch 00363: val_accuracy did not improve from 0.93596\n","Epoch 364/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0059 - accuracy: 0.9970 - val_loss: 0.5071 - val_accuracy: 0.9039\n","\n","Epoch 00364: val_accuracy did not improve from 0.93596\n","Epoch 365/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.6373 - val_accuracy: 0.8990\n","\n","Epoch 00365: val_accuracy did not improve from 0.93596\n","Epoch 366/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0251 - accuracy: 0.9957 - val_loss: 0.5552 - val_accuracy: 0.9089\n","\n","Epoch 00366: val_accuracy did not improve from 0.93596\n","Epoch 367/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.5740 - val_accuracy: 0.9039\n","\n","Epoch 00367: val_accuracy did not improve from 0.93596\n","Epoch 368/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.7073 - val_accuracy: 0.9039\n","\n","Epoch 00368: val_accuracy did not improve from 0.93596\n","Epoch 369/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 0.4109 - val_accuracy: 0.9212\n","\n","Epoch 00369: val_accuracy did not improve from 0.93596\n","Epoch 370/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.6351 - val_accuracy: 0.8842\n","\n","Epoch 00370: val_accuracy did not improve from 0.93596\n","Epoch 371/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.5570 - val_accuracy: 0.9113\n","\n","Epoch 00371: val_accuracy did not improve from 0.93596\n","Epoch 372/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4756 - val_accuracy: 0.9187\n","\n","Epoch 00372: val_accuracy did not improve from 0.93596\n","Epoch 373/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.4479 - val_accuracy: 0.9113\n","\n","Epoch 00373: val_accuracy did not improve from 0.93596\n","Epoch 374/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 0.5349 - val_accuracy: 0.9039\n","\n","Epoch 00374: val_accuracy did not improve from 0.93596\n","Epoch 375/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9138\n","\n","Epoch 00375: val_accuracy did not improve from 0.93596\n","Epoch 376/500\n","103/103 [==============================] - 14s 135ms/step - loss: 7.9637e-04 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.9335\n","\n","Epoch 00376: val_accuracy did not improve from 0.93596\n","Epoch 377/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.4267 - val_accuracy: 0.9286\n","\n","Epoch 00377: val_accuracy did not improve from 0.93596\n","Epoch 378/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0057 - accuracy: 0.9970 - val_loss: 0.5208 - val_accuracy: 0.9064\n","\n","Epoch 00378: val_accuracy did not improve from 0.93596\n","Epoch 379/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5464 - val_accuracy: 0.8966\n","\n","Epoch 00379: val_accuracy did not improve from 0.93596\n","Epoch 380/500\n","103/103 [==============================] - 14s 136ms/step - loss: 3.1131e-04 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.9089\n","\n","Epoch 00380: val_accuracy did not improve from 0.93596\n","Epoch 381/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.6176 - val_accuracy: 0.8941\n","\n","Epoch 00381: val_accuracy did not improve from 0.93596\n","Epoch 382/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.5114 - val_accuracy: 0.9039\n","\n","Epoch 00382: val_accuracy did not improve from 0.93596\n","Epoch 383/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0257 - accuracy: 0.9909 - val_loss: 0.7664 - val_accuracy: 0.9064\n","\n","Epoch 00383: val_accuracy did not improve from 0.93596\n","Epoch 384/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.5092 - val_accuracy: 0.9138\n","\n","Epoch 00384: val_accuracy did not improve from 0.93596\n","Epoch 385/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0153 - accuracy: 0.9939 - val_loss: 0.6858 - val_accuracy: 0.8867\n","\n","Epoch 00385: val_accuracy did not improve from 0.93596\n","Epoch 386/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.6473 - val_accuracy: 0.8867\n","\n","Epoch 00386: val_accuracy did not improve from 0.93596\n","Epoch 387/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.5212 - val_accuracy: 0.9064\n","\n","Epoch 00387: val_accuracy did not improve from 0.93596\n","Epoch 388/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.5835 - val_accuracy: 0.8916\n","\n","Epoch 00388: val_accuracy did not improve from 0.93596\n","Epoch 389/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.7539 - val_accuracy: 0.8695\n","\n","Epoch 00389: val_accuracy did not improve from 0.93596\n","Epoch 390/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.7735 - val_accuracy: 0.8966\n","\n","Epoch 00390: val_accuracy did not improve from 0.93596\n","Epoch 391/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.5985 - val_accuracy: 0.9187\n","\n","Epoch 00391: val_accuracy did not improve from 0.93596\n","Epoch 392/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 1.4081 - val_accuracy: 0.7980\n","\n","Epoch 00392: val_accuracy did not improve from 0.93596\n","Epoch 393/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.5185 - val_accuracy: 0.9138\n","\n","Epoch 00393: val_accuracy did not improve from 0.93596\n","Epoch 394/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.4961 - val_accuracy: 0.9163\n","\n","Epoch 00394: val_accuracy did not improve from 0.93596\n","Epoch 395/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.3920 - val_accuracy: 0.9261\n","\n","Epoch 00395: val_accuracy did not improve from 0.93596\n","Epoch 396/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.4507 - val_accuracy: 0.9310\n","\n","Epoch 00396: val_accuracy did not improve from 0.93596\n","Epoch 397/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.9113\n","\n","Epoch 00397: val_accuracy did not improve from 0.93596\n","Epoch 398/500\n","103/103 [==============================] - 14s 135ms/step - loss: 7.8839e-04 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.9113\n","\n","Epoch 00398: val_accuracy did not improve from 0.93596\n","Epoch 399/500\n","103/103 [==============================] - 14s 135ms/step - loss: 4.0988e-04 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.9335\n","\n","Epoch 00399: val_accuracy did not improve from 0.93596\n","Epoch 400/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.6287 - val_accuracy: 0.8990\n","\n","Epoch 00400: val_accuracy did not improve from 0.93596\n","Epoch 401/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.7409 - val_accuracy: 0.8768\n","\n","Epoch 00401: val_accuracy did not improve from 0.93596\n","Epoch 402/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0111 - accuracy: 0.9951 - val_loss: 0.5587 - val_accuracy: 0.9163\n","\n","Epoch 00402: val_accuracy did not improve from 0.93596\n","Epoch 403/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0246 - accuracy: 0.9945 - val_loss: 1.4053 - val_accuracy: 0.7192\n","\n","Epoch 00403: val_accuracy did not improve from 0.93596\n","Epoch 404/500\n","103/103 [==============================] - 14s 137ms/step - loss: 0.0180 - accuracy: 0.9963 - val_loss: 1.0202 - val_accuracy: 0.8005\n","\n","Epoch 00404: val_accuracy did not improve from 0.93596\n","Epoch 405/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 0.6634 - val_accuracy: 0.8990\n","\n","Epoch 00405: val_accuracy did not improve from 0.93596\n","Epoch 406/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.6256 - val_accuracy: 0.8916\n","\n","Epoch 00406: val_accuracy did not improve from 0.93596\n","Epoch 407/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5446 - val_accuracy: 0.9089\n","\n","Epoch 00407: val_accuracy did not improve from 0.93596\n","Epoch 408/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.6386 - val_accuracy: 0.8867\n","\n","Epoch 00408: val_accuracy did not improve from 0.93596\n","Epoch 409/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0098 - accuracy: 0.9957 - val_loss: 0.4697 - val_accuracy: 0.9212\n","\n","Epoch 00409: val_accuracy did not improve from 0.93596\n","Epoch 410/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.5825 - val_accuracy: 0.8966\n","\n","Epoch 00410: val_accuracy did not improve from 0.93596\n","Epoch 411/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5243 - val_accuracy: 0.9039\n","\n","Epoch 00411: val_accuracy did not improve from 0.93596\n","Epoch 412/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4575 - val_accuracy: 0.9089\n","\n","Epoch 00412: val_accuracy did not improve from 0.93596\n","Epoch 413/500\n","103/103 [==============================] - 14s 135ms/step - loss: 6.1785e-04 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.9064\n","\n","Epoch 00413: val_accuracy did not improve from 0.93596\n","Epoch 414/500\n","103/103 [==============================] - 14s 135ms/step - loss: 6.4205e-04 - accuracy: 1.0000 - val_loss: 0.4483 - val_accuracy: 0.9138\n","\n","Epoch 00414: val_accuracy did not improve from 0.93596\n","Epoch 415/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5188 - val_accuracy: 0.9064\n","\n","Epoch 00415: val_accuracy did not improve from 0.93596\n","Epoch 416/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.5543 - val_accuracy: 0.9113\n","\n","Epoch 00416: val_accuracy did not improve from 0.93596\n","Epoch 417/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.4221 - val_accuracy: 0.9187\n","\n","Epoch 00417: val_accuracy did not improve from 0.93596\n","Epoch 418/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.3849 - val_accuracy: 0.9261\n","\n","Epoch 00418: val_accuracy did not improve from 0.93596\n","Epoch 419/500\n","103/103 [==============================] - 14s 135ms/step - loss: 4.3124e-04 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.9212\n","\n","Epoch 00419: val_accuracy did not improve from 0.93596\n","Epoch 420/500\n","103/103 [==============================] - 14s 136ms/step - loss: 4.4821e-04 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9335\n","\n","Epoch 00420: val_accuracy did not improve from 0.93596\n","Epoch 421/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0167 - accuracy: 0.9933 - val_loss: 0.7497 - val_accuracy: 0.8522\n","\n","Epoch 00421: val_accuracy did not improve from 0.93596\n","Epoch 422/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0466 - accuracy: 0.9866 - val_loss: 1.1767 - val_accuracy: 0.7857\n","\n","Epoch 00422: val_accuracy did not improve from 0.93596\n","Epoch 423/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0434 - accuracy: 0.9896 - val_loss: 0.5820 - val_accuracy: 0.9039\n","\n","Epoch 00423: val_accuracy did not improve from 0.93596\n","Epoch 424/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.6062 - val_accuracy: 0.9089\n","\n","Epoch 00424: val_accuracy did not improve from 0.93596\n","Epoch 425/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.4810 - val_accuracy: 0.9039\n","\n","Epoch 00425: val_accuracy did not improve from 0.93596\n","Epoch 426/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.4026 - val_accuracy: 0.9212\n","\n","Epoch 00426: val_accuracy did not improve from 0.93596\n","Epoch 427/500\n","103/103 [==============================] - 14s 134ms/step - loss: 9.6559e-04 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.9187\n","\n","Epoch 00427: val_accuracy did not improve from 0.93596\n","Epoch 428/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.9187\n","\n","Epoch 00428: val_accuracy did not improve from 0.93596\n","Epoch 429/500\n","103/103 [==============================] - 14s 135ms/step - loss: 6.3170e-04 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9187\n","\n","Epoch 00429: val_accuracy did not improve from 0.93596\n","Epoch 430/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.3919 - val_accuracy: 0.9212\n","\n","Epoch 00430: val_accuracy did not improve from 0.93596\n","Epoch 431/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4255 - val_accuracy: 0.9212\n","\n","Epoch 00431: val_accuracy did not improve from 0.93596\n","Epoch 432/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.6276 - val_accuracy: 0.8990\n","\n","Epoch 00432: val_accuracy did not improve from 0.93596\n","Epoch 433/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.6853 - val_accuracy: 0.8793\n","\n","Epoch 00433: val_accuracy did not improve from 0.93596\n","Epoch 434/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0234 - accuracy: 0.9915 - val_loss: 0.6177 - val_accuracy: 0.8990\n","\n","Epoch 00434: val_accuracy did not improve from 0.93596\n","Epoch 435/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.6649 - val_accuracy: 0.8892\n","\n","Epoch 00435: val_accuracy did not improve from 0.93596\n","Epoch 436/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0091 - accuracy: 0.9957 - val_loss: 0.5793 - val_accuracy: 0.8966\n","\n","Epoch 00436: val_accuracy did not improve from 0.93596\n","Epoch 437/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 0.6470 - val_accuracy: 0.8916\n","\n","Epoch 00437: val_accuracy did not improve from 0.93596\n","Epoch 438/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.5742 - val_accuracy: 0.8916\n","\n","Epoch 00438: val_accuracy did not improve from 0.93596\n","Epoch 439/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.5584 - val_accuracy: 0.8966\n","\n","Epoch 00439: val_accuracy did not improve from 0.93596\n","Epoch 440/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 0.4326 - val_accuracy: 0.9335\n","\n","Epoch 00440: val_accuracy did not improve from 0.93596\n","Epoch 441/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4649 - val_accuracy: 0.9236\n","\n","Epoch 00441: val_accuracy did not improve from 0.93596\n","Epoch 442/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.5783 - val_accuracy: 0.9089\n","\n","Epoch 00442: val_accuracy did not improve from 0.93596\n","Epoch 443/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.4740 - val_accuracy: 0.9015\n","\n","Epoch 00443: val_accuracy did not improve from 0.93596\n","Epoch 444/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.5457 - val_accuracy: 0.9212\n","\n","Epoch 00444: val_accuracy did not improve from 0.93596\n","Epoch 445/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9212\n","\n","Epoch 00445: val_accuracy did not improve from 0.93596\n","Epoch 446/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4330 - val_accuracy: 0.9138\n","\n","Epoch 00446: val_accuracy did not improve from 0.93596\n","Epoch 447/500\n","103/103 [==============================] - 14s 136ms/step - loss: 7.3471e-04 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.9163\n","\n","Epoch 00447: val_accuracy did not improve from 0.93596\n","Epoch 448/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5681 - val_accuracy: 0.9113\n","\n","Epoch 00448: val_accuracy did not improve from 0.93596\n","Epoch 449/500\n","103/103 [==============================] - 14s 136ms/step - loss: 7.7773e-04 - accuracy: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.9212\n","\n","Epoch 00449: val_accuracy did not improve from 0.93596\n","Epoch 450/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.5892 - val_accuracy: 0.9113\n","\n","Epoch 00450: val_accuracy did not improve from 0.93596\n","Epoch 451/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.5858 - val_accuracy: 0.9138\n","\n","Epoch 00451: val_accuracy did not improve from 0.93596\n","Epoch 452/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.6720 - val_accuracy: 0.8916\n","\n","Epoch 00452: val_accuracy did not improve from 0.93596\n","Epoch 453/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5944 - val_accuracy: 0.9089\n","\n","Epoch 00453: val_accuracy did not improve from 0.93596\n","Epoch 454/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0054 - accuracy: 0.9963 - val_loss: 0.8803 - val_accuracy: 0.8842\n","\n","Epoch 00454: val_accuracy did not improve from 0.93596\n","Epoch 455/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.5331 - val_accuracy: 0.9113\n","\n","Epoch 00455: val_accuracy did not improve from 0.93596\n","Epoch 456/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.5332 - val_accuracy: 0.9138\n","\n","Epoch 00456: val_accuracy did not improve from 0.93596\n","Epoch 457/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5689 - val_accuracy: 0.9015\n","\n","Epoch 00457: val_accuracy did not improve from 0.93596\n","Epoch 458/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4847 - val_accuracy: 0.9138\n","\n","Epoch 00458: val_accuracy did not improve from 0.93596\n","Epoch 459/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4547 - val_accuracy: 0.9163\n","\n","Epoch 00459: val_accuracy did not improve from 0.93596\n","Epoch 460/500\n","103/103 [==============================] - 14s 135ms/step - loss: 2.9578e-04 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9310\n","\n","Epoch 00460: val_accuracy did not improve from 0.93596\n","Epoch 461/500\n","103/103 [==============================] - 14s 136ms/step - loss: 7.2457e-04 - accuracy: 1.0000 - val_loss: 0.5148 - val_accuracy: 0.9089\n","\n","Epoch 00461: val_accuracy did not improve from 0.93596\n","Epoch 462/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5321 - val_accuracy: 0.9113\n","\n","Epoch 00462: val_accuracy did not improve from 0.93596\n","Epoch 463/500\n","103/103 [==============================] - 14s 135ms/step - loss: 4.4532e-04 - accuracy: 1.0000 - val_loss: 0.4813 - val_accuracy: 0.9163\n","\n","Epoch 00463: val_accuracy did not improve from 0.93596\n","Epoch 464/500\n","103/103 [==============================] - 14s 135ms/step - loss: 5.6195e-04 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.9187\n","\n","Epoch 00464: val_accuracy did not improve from 0.93596\n","Epoch 465/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.6497 - val_accuracy: 0.8818\n","\n","Epoch 00465: val_accuracy did not improve from 0.93596\n","Epoch 466/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 2.2010 - val_accuracy: 0.5961\n","\n","Epoch 00466: val_accuracy did not improve from 0.93596\n","Epoch 467/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0409 - accuracy: 0.9878 - val_loss: 0.6527 - val_accuracy: 0.8990\n","\n","Epoch 00467: val_accuracy did not improve from 0.93596\n","Epoch 468/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.5151 - val_accuracy: 0.9212\n","\n","Epoch 00468: val_accuracy did not improve from 0.93596\n","Epoch 469/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 0.7334 - val_accuracy: 0.8867\n","\n","Epoch 00469: val_accuracy did not improve from 0.93596\n","Epoch 470/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.6350 - val_accuracy: 0.9113\n","\n","Epoch 00470: val_accuracy did not improve from 0.93596\n","Epoch 471/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.4715 - val_accuracy: 0.9089\n","\n","Epoch 00471: val_accuracy did not improve from 0.93596\n","Epoch 472/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4688 - val_accuracy: 0.9163\n","\n","Epoch 00472: val_accuracy did not improve from 0.93596\n","Epoch 473/500\n","103/103 [==============================] - 14s 135ms/step - loss: 8.6995e-04 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9212\n","\n","Epoch 00473: val_accuracy did not improve from 0.93596\n","Epoch 474/500\n","103/103 [==============================] - 14s 135ms/step - loss: 3.5828e-04 - accuracy: 1.0000 - val_loss: 0.4101 - val_accuracy: 0.9384\n","\n","Epoch 00474: val_accuracy improved from 0.93596 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5\n","Epoch 475/500\n","103/103 [==============================] - 14s 136ms/step - loss: 4.3014e-04 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9335\n","\n","Epoch 00475: val_accuracy did not improve from 0.93842\n","Epoch 476/500\n","103/103 [==============================] - 14s 135ms/step - loss: 5.3576e-04 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9261\n","\n","Epoch 00476: val_accuracy did not improve from 0.93842\n","Epoch 477/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4618 - val_accuracy: 0.9138\n","\n","Epoch 00477: val_accuracy did not improve from 0.93842\n","Epoch 478/500\n","103/103 [==============================] - 14s 136ms/step - loss: 5.0683e-04 - accuracy: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.9187\n","\n","Epoch 00478: val_accuracy did not improve from 0.93842\n","Epoch 479/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3477 - val_accuracy: 0.9384\n","\n","Epoch 00479: val_accuracy did not improve from 0.93842\n","Epoch 480/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.4935 - val_accuracy: 0.9113\n","\n","Epoch 00480: val_accuracy did not improve from 0.93842\n","Epoch 481/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0127 - accuracy: 0.9982 - val_loss: 0.5587 - val_accuracy: 0.8966\n","\n","Epoch 00481: val_accuracy did not improve from 0.93842\n","Epoch 482/500\n","103/103 [==============================] - 14s 133ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.5407 - val_accuracy: 0.9015\n","\n","Epoch 00482: val_accuracy did not improve from 0.93842\n","Epoch 483/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.8312 - val_accuracy: 0.8966\n","\n","Epoch 00483: val_accuracy did not improve from 0.93842\n","Epoch 484/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.6002 - val_accuracy: 0.9163\n","\n","Epoch 00484: val_accuracy did not improve from 0.93842\n","Epoch 485/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.6834 - val_accuracy: 0.9089\n","\n","Epoch 00485: val_accuracy did not improve from 0.93842\n","Epoch 486/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0078 - accuracy: 0.9994 - val_loss: 0.6514 - val_accuracy: 0.9113\n","\n","Epoch 00486: val_accuracy did not improve from 0.93842\n","Epoch 487/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.6535 - val_accuracy: 0.9113\n","\n","Epoch 00487: val_accuracy did not improve from 0.93842\n","Epoch 488/500\n","103/103 [==============================] - 14s 136ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.6102 - val_accuracy: 0.9113\n","\n","Epoch 00488: val_accuracy did not improve from 0.93842\n","Epoch 489/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.7226 - val_accuracy: 0.8916\n","\n","Epoch 00489: val_accuracy did not improve from 0.93842\n","Epoch 490/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0083 - accuracy: 0.9957 - val_loss: 0.8075 - val_accuracy: 0.8818\n","\n","Epoch 00490: val_accuracy did not improve from 0.93842\n","Epoch 491/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.7117 - val_accuracy: 0.8916\n","\n","Epoch 00491: val_accuracy did not improve from 0.93842\n","Epoch 492/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0217 - accuracy: 0.9951 - val_loss: 0.9499 - val_accuracy: 0.7980\n","\n","Epoch 00492: val_accuracy did not improve from 0.93842\n","Epoch 493/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.7436 - val_accuracy: 0.8867\n","\n","Epoch 00493: val_accuracy did not improve from 0.93842\n","Epoch 494/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.5159 - val_accuracy: 0.9015\n","\n","Epoch 00494: val_accuracy did not improve from 0.93842\n","Epoch 495/500\n","103/103 [==============================] - 14s 135ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.5116 - val_accuracy: 0.9163\n","\n","Epoch 00495: val_accuracy did not improve from 0.93842\n","Epoch 496/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.5784 - val_accuracy: 0.8842\n","\n","Epoch 00496: val_accuracy did not improve from 0.93842\n","Epoch 497/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.5995 - val_accuracy: 0.8990\n","\n","Epoch 00497: val_accuracy did not improve from 0.93842\n","Epoch 498/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.6441 - val_accuracy: 0.8966\n","\n","Epoch 00498: val_accuracy did not improve from 0.93842\n","Epoch 499/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.5168 - val_accuracy: 0.9064\n","\n","Epoch 00499: val_accuracy did not improve from 0.93842\n","Epoch 500/500\n","103/103 [==============================] - 14s 134ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5454 - val_accuracy: 0.9064\n","\n","Epoch 00500: val_accuracy did not improve from 0.93842\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbd921ca410>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1630783924491,"user_tz":-540,"elapsed":21,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"11621239-aab0-43f2-b21e-28f86eb8fa6e"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd3hUVfrHP2fSKyGE0EIv0kEITVRAqopt167r6trLrrqurq77s+uuDV3LKrqWtetaUXFVEFnEAqgU6R1CSwiB9DZzfn+ce2fuTGaSIaQw4f08T57MrXPOnXu/9z3v+55zlNYaQRAEIfJxNXcBBEEQhIZBBF0QBKGFIIIuCILQQhBBFwRBaCGIoAuCILQQopvrizMyMnS3bt2a6+sFQRAikh9//HGv1rptsG3NJujdunVjyZIlzfX1giAIEYlSamuobeJyEQRBaCGIoAuCILQQRNAFQRBaCCLogiAILQQRdEEQhBZCnYKulHpRKZWrlPolxHallHpCKbVBKbVcKTWs4YspCIIg1EU4FvrLwLRatp8I9Lb+rgCeOfRiCYIgCAdLnXnoWuv/KaW61bLLacAr2ozD+71SKk0p1UFrvauByig0ER6PZsGGvRzbK4Mol6pzf7dHs3lvMbNX7GZMzzaM6JYOQG5ROfnFlfRtn4JStZ+npKKafSWVdE5PbJA6AJRXufnw5x10bZPEih37aZsSR3bXdL/vKCqvoqLaQ2JsFFEuxfo9xcxZvYeOrRL49fAsolwKrTV5xRW8/9MOEmKi+NWwTsTHRBETZeygDblFbMorYU9hOWVVborLq0mIjeaMozvRvlW897uq3R6iXAqlFHlFFSgFaQkxbMgrpntGEnHRUQDkFJTy2YrdHNs7gy7piSxYv5dR3dNpnRQLwJa9JXROT6zx22zNL2HJlgLySyooLq8GIC4minNHdKZNchwAWmtW7DjAz9v2ExftIreogsyUOGKjXewtrqBdajwp8dEc0zOD+JgoqtweFm3ex8a8YpRSdGuTyHG9fX1ZPB7N/HV5dExLYM7qPQzs1IqyymrW7ylmQKdUxvfJxGWVs7LaQ2y0uWYFJZV8tymfnfvLKCyrol+HVKYNbO+9T+atzSUuysWYnm34aVsB323Mp9KtGdAxlZKKarbkl3LiwPb062CWf9pWwOLN+0iKiyardSKT+md6r2dJRTVb80vJK64gu2trNu8t4buN+Xi0JsqlSE2IIT4mimN6tqHK7WHu6lwykuNYtasQtCY6ysU5IzrTLjXeW483ftjKvpJKAJLjo1EoxvRsQ592KcREKdbtKaa4ohrQ9GmXQkp8jN9vtbe4gmq3JjUhmsTYhu8G1BBn7ARsdyznWOtqCLpS6gqMFU+XLl0a4KuPDLTWlFS6mbcml1E90slM8YnFuj1FuBT0ykyhpKKa37/5M9dP7M2QzmlorSksq6ZVov9NlVtYzs3vLmdjXjH3nj6QCUdlMmvZTv7w5s8A/GpYJ+4/fRAJsVG892MOz87fyCuXjqR9ajyzV+zm520FXDOhF/d8vJIPl+4EIGqu4qNrx1JW5eaC53+g0u3hxkl9uHJcD7btK6VX22Semb+R3QfKuevUAVS5Pbz/0w6e/Go9uw6Uk5kSx8R+7ejZNomcgjL+MLE36ZaQrd1dxNb8El74ZjOb9paQHBdNtcfDwI6t6J2ZTEmlmxsn9yE5ztzOd3+8ijcXbfOrc3JcNHNvGud9OG94aylz1+QGvd6F5VWcN7ILv31xEUu2FnjX3zlrJVEuxQNnDGT1riJe/nZL0ONf+W4LF43pxupdhUwZ0I5XvjMi8NjZQ7nk5UXsL62iVUIM+SXmpTfj7KHM/N9Gvt2YT15Rhd+52qfGc8cp/Xnwv2vYml/KiG6tOSu7M/3ap3LHrF9IS4hh/ro8PI5pDZQCreGjpTt48/LR3PD2Uhas3xu0rME4ZUhHYqIU7/+0w2/9r4Z1okdGEkM7t+aT5Tt5a/H2EGcwnDy4AxVVHuas3sMJfTP5ZccBcgPqB3Dm8CwyU+L4YfM+frSud3JctCWMNVmwPo+rx/Xkmtd/otrjP59D+9R47jp1AOv3FDHzf5tCnsNJlEsR7VJUVHu86+xrOHvFLh49ewjfbsjnqXkbOFBW5d0WiEtBQHHo2z6FcX3asiG3mLziCpbnHADgvtMHcuHornWW7WBR4UxwYVnon2itBwbZ9gnwd631N9byXODPWutau4FmZ2frI6Gn6D/mrOe5/23kl7un1mqtvrxwMzO+XMe/fzeSo7u0BmBPYTkLN+zljo9Wem/M1Pho3rlqDH3bp7KnsJxRD8wFYNkdU/hkxU5u/+AXTuibyQNnDOKxL9fxwc87+Ndvszm+T1sqqz3c8u4yZq/YjcsFKfExlFe6+f4vExnzt7kUlvtu/t+M7kr/jqnc9v4K77qM5Dj2FpsHMik2ipJKN70yk3nozMGc+cy3XDK2O//9ZTcAsdEuNu8t8R7bv0OqsXyAf12UzS87D/D4nPWAefB37i9j1c5Cv4fqvJFd2H2gjHlr87zrhndtjUdr8osr2bav1Lv+9yf04oS+mdz/6WqWbC2gR9skpg/qwHmjurApr4RLXlpM1zaJvH75KP76wS98sWoPAD3bJrExr4S2KXF8+vtjueq1H1m6fT+9M1NYu6eIAR1TufTY7kS5FNe/tdTvNzt5UAdOGtSBo9qn0DoxhtaJsSzL2c9FLy6iyLqW0S7lFZ1olyImysW0ge2p9mg6tIrnxW82e7dnJMfxpyl9OFBWxd8+W8PI7ums2lno/e07pydQVunx/gZOrp3Qk4uP6U5GcixKKT5auoPr31pKj7ZJbMrz/Q7PX5RNTJRiVPc2rM8tIq+ogk6tE5j2+IIa5zy+T1uuGteDuOgoXvxmM5/9sstPsKYP7sCQrDRGdE9nwbo83Fpz6bHdGf3AXEoq3TXOZ3Pz1KMY3rU1I7qlM+Wx+Wx0lC8jOY4JR7VlxY4DXDi6K6cf3QmtNQvW76Vn22QWrM/jvk9XkxwXjVJwz2kDmDagA/klFTw9bwNvLvJ/yZyT3Zk9ReUs276f0ko3f53enyn923GgrIrcwgriYlzMnL+RDq0SOGVIR9wezdFd0oiPiWL+ujyueGWJ957MSI7l4mO6cd0JvdFas6+kkmqPZtbSnTw1bwMju6czpkcbNMYIe2nhFnbsLwPMc9u+VTynDe1EelIs2V1b07tdSshrVBtKqR+11tlBtzWAoM8EvtZav2ktrwXG1+VyOVIEvdutnwKw4JYJfk1+j0ezp6gchWJfSSUnPWEeqJsm9+H3E3uzt7iC7Pvm+J3r7Ows3lmSA8DP/zeZi19axDLrjV8Xpw3tSKe0BP759UZOGtSeP07uw/KcA/zxnWVcNKYrr3y3lWcvHE63jETOe+57SivddGuTRKXbw+T+7Vi/p8grrH3aJbNuTzEAP/xlIu1S4znlyW9YscOU5b2rjyGnoNQrgPaLYHjX1mzfV0rPtsnsLixn894SHj5zMGdldwaMa+LhL9ayOa+ElTsLvQ/Dpcd2p2/7FNqlxnNMzzZEWy6PLXtLmLVsJ/PX5bExrxi3R6OAfh1SeeHiEV6LHeDDn3dww9tLaZcax57CClLiopn1+2PpnpFEldtDWZWb1PgY3vsxh5v+swwwL4mbphzl/b3O/9f3tEmK49MV5tb++LpjGZTVqsa1rqh2U17loaLazQmPzKe4oprkuGg8WvPm5aMZ0jnNu+/T8zYwc/5G/nJSP84d6Wu1FpRUkpYYw6xlO7n+raX8bmx37jilP+VVbhZu2MvP2/YzqX87Tn96IQBr75vmdTUAVLk9DLv3S4rKq/nV0Z3Yuq+UE/pmcu2EXkHvjwNlVcTHuJjxxTpm/m8TAG9cNopjemV493F7NAfKqnj0i7UM6ZzGWcOzghopHy3dwYwv13H7Sf3olpHEgbIqALqkJ7K3uIIBHX3XbHnOft5evJ2LxnRjwfo8JvZrR/eMpKBltMs55O4vAN+z4mTp9v08MHs1I7q1Zu3uImb+JtvrovJ4tNcNFC7/mLOex+asY2LfTGb+Zrj33gvE7dFB3ZSb95bw6fKdXHZcD+JjooIcefA0tqCfDFwHnASMAp7QWo+s65wtVdCf+mo9LpdiXJ+29O+QSvfbZgPwzwuGMahTKzqmJbBww17W7C7kgdlrAMhqncC+kkpio12kxsdQWe1hd2G595wv/DabwvIqTh/aids//IU3ftjGI2cN4U//Wca9pw2gTXIcj36x1s/SsXn+omyWbi/g+QWbqbQsjTX3TiM+JorlOfs59SkjCKO6p/PWFaNRSrEi5wCnPPUNAJcf153bT+4PwI9bC7jt/eU8ds5QTn7CbN/y95MBePGbzdzzySpOHdKRJ847Gq01G3KL2XmgnJHd0tmYV0y/Dqk89dUGHpuzDoArx/XgthP7Bb2OWmue+98memUmM7Ffu1qv+Tfr9/Lw52tIiY/h/jMG0rVNTUHweDQjH5jL3uIKHjhjEOePCu7yswVjeNfWvHf1MUH3+WlbAet2F3HOiM51xgheXriZJ7/awBc3Ho/bo8lMja91/2Bs31dKu9R4rx/ayTuLt7Njfxk3Tu5TY9vCDXt5+PO1/POCYXRMSwj7+/61YBNxMVFcOKpLnfVrDp6cu54VOw7wj3OPJiG2YUQyFIXlVcz4Yh2/P6GXNx7R3BySoCul3gTGAxnAHuBOIAZAa/2sMr/4U5hMmFLgkrrcLRDZgp5fXMHjc9ZzfJ+2TO7vE5s1uwv9mq4zfzOcK1/90e/Yo7uk8fO2/TXOefrQjpRVufl85R6/9V/ceDx9HE2zJVv2ceaz3zG8a2t+2lbAor9Mom2KsYBf/W4rY3tlMHvFLq9/d+kdk0lLjGV/aSVD7/mSHm2T+Oqm8YAJGg2483OUMtbmwE7GctJac8Kj89m8t4RXfjeS4/vUHNjtrx+uoH+HVn7CuGz7fnplJpMUFzo0U1BSyX2frmZUj3ROHNi+RtCoMfng5xz2l1Zxydjute63ZnchndISGqxs9bEMBSEUh2yhNwaRLOh3f7ySlxZuIS7axYJbJvDKd1tZlrOfHQVlbHL4jeNjXHRMS+D8kV2479PVNc7TPSOJC0Z14b+/7OaRs4Ywd00u936yipgoxUNnDubtxdt547LRfmKwNb+EcQ9/DcCwLmm8f83YoGW0XT22BQ2QV1RBlEt5g40Apz31DYOz0rj3dP/GV25hOYXl1fTKTD74CyQIQqNRm6A32/C5kcCqnYVsyS9hdI82pCfFklNQyrWv/8SynAO4FFRUe7j030u8vmOAe08bwL6SKh6bs47yKg/ZXVtz2XE9KK6o5qmvNngDYJkpcdwy9ShOHNSBy47rARg/972frGJIVhpnHJ3FGUdn1ShT2xRfs29S/9CuiLk3jWN/aWXIY20+uGYswVrVmanxZKbWfn0EQTi8EEEPQXmV2xuoBLjrlP5sLyjzBiGP692W+evyvGI+sW8mMVEuzh/VFZcyfsiiimratzK+yxsm9eF3x3Zn8F1fMKRzGh9dW9OyzkiO472rx9AlPXRQKDE22pvSNbkW33LPtuFZ1uIKEISWgwi6g5nzN9K1TSLTBnbg2td/8tv2xFcbALxZEsf3MYIOJnofGAFPTYihqKKaDo4OJqnxMcy9aRxpCaF9s8O7ptdZzrYpcbRJjhV3iCAIfoigW7g9mr99ZrJO3rv6GL5am+tNFftk+U6ue+NnMpJjefmSkcREueiekcS9n6wCYP7N42tkAyRa0Xdnj0EI33KujT9M7EVSbPRhmYEgCELzIYJukVPg66Ty1Ffr0RpOP7ojAFP6t+eWaUcxfVBHurTx5ZK/cfkoCsuqggpr+1bxrM8tJjW+4S9xMN+6IAjCETt87oGyKv7w5s9syjMdZNZbHWUA5q3NIyM5loFWB4jYaBfXjO/lJ+YAx/TMYNrADkHP//CZQ7jy+B4MyUoLul0QBKGhOWIt9Of/t4lZy3aSX1LB2dmdud9KK4yJUlS5Ncf3bntIAcP2reK57aTgnWYEQRAagyPWQrcHZlq4IZ/r31pKblEFlx/XnWN6mq7OZ4/o3JzFi3w2L4ADO+reT2g49m2G9V/Cqo+auyQtF61h5jiYe69ZfnwQzLmrWYvk5IgT9Gq3h+lPLmD1rsIaY0bcemI/HjlrCF//aTyje7RpphK2EP49HWYe39ylaDy0ho1fgccahGrpm/Bgd3jiaCjd1zxlem4cvH4mvHMRLHkR3HWPNNggfHUffHht+PuX7oPti+Dz2+GDqw7uu/59Cix6Pvz9FzwK7/4u/P3LD8D2xaG3l+yFXUthwSNQsBX2b4NvHgv//I3MESPo1W4P327cS6/bP+OXHWbUv9OGdvRuf+V3I4lyKdqmxNGtlsGBWjRf3gk/vXLo56m0Asyl4Q/Z2miUF8Irp0H+xoY977I34dUz4Iv/g9fOhFUfQtk+2Lep4b8rXModA7V9ciN8/8+DO75oNxRZQ0/88Bx88VfIXVP3cf97GJa+Blu/De97Hh8ML0yG754y1zFcNn0Nm/8Hs/8U/jFz74Ff3oOKovD2f+NceGGS7x4OZO9a3+f5D4ZfjibiiBH0txZv5/znf/Bb16ddCi9fMoIFt0wIOl5Ji6a80F8APB5j+Sx7K/j+1RVQnFdz/e5f4KNrwV3lW9eYQr5vE3xwtSlPXeSthYd7GiGYc2fDlmPd5+b/90/Dhi9h3X8h2hoAq6wg9HGNwdrPYPbNQEDMp3hPzX09bjiQ47+uusJYzY8eZVwIAJ/dDN8+Cf8cZa6j33lzodrqhezxDXfMdv/nKyi7f4HKOsS1qgxK8mse98pp5nOCo69G0R7TWirdB7uWBR+oHGDTfHOOIjO8M/u3Bd9vm/VScl6jylJfqyvPesGldoKlr9dej2bgiBH05TlmQKyBnXz92TOS4xh/VGaDzpbTpBRshc/+HJ64BfJoX/i7Y8TB/VugqgTyNwTf//3L4ZFeNR+Yz/8CP78Ga2f71pUGPIyLnoct34RXrpK98OmfoKzmAGbm+/4Ky94w7o66eONscAcRHnt57j3+1rTH7RMqvzLlG4v3i//z1T/YdeowxPzfPB/mPeDb96dXYcPcusurtXnRBqO6InjZKkvhzXNh0XNAwG8THyTD6u3fwGMDjIukrMBYrrarCMAd5F56eqTv96uuhEd6w4dXmZfIDsd4TKFEEmDbD/DDTFj/Rc1tFUX+7qFXToOHe/jv8/Nrvs+ZVrLBrmXwaB/452hzP8883sQQnNji/8Oz8OxYU5d1n5sX1/J3Qpd3zwrzbOWuhhenwkPWgG6bvoa4VjDkXP/9PR6oKvc3bJxUloR+2TQgR4yg21Oizbr2WD68dizDuqT5iXtE8uHV5kYNJW5aw48vm2ZqIFUBQ+3mWoOHFe+pKSpa+wJtpfv8b8x46xq+c5F5aFd/DMve9j929p/g5ZNh/3bzUNfGiv/A4ucti9PB6k+MqERZvWyLg8825EfBFkc5AgS9YLPxr75zkVnO3wj3toVPb/Tfb+1nRlyWvAjfPuFr1ZQHGYe+TU/z/7unTHN8h9XbeNZ18NqvoHAXfPO4z+8eyJIX4e+dYcOcmttm9INnggznWx7w4pt8j+9zZRFsnOcTucJdsNYM2sbS14zvd+1/zb0QeJ64gHHed1tzxO+zXoC/vGdeIm9d4NvHKegr3oVt3/uWX5wCn90Ci1+A5Pb+5/5bFrx6um/ZtvSrK4xof/8srHgH+kwzxypLtuzrW7gL2pkhnr0WNJh7r9JKR95iDeNRfsC86MEYKbmrze/xw3MmFmDz7u/Ms/XL+7B7uVm3a5m5v0dfDZ1H+dehNN/8Ri+daIwRp5F1YAc81CM8I+QQafGCXu328P5POWzeW0LXNom4XIqhnc0ohY0xp1+9WPY23NXKWKfh4vHATjNlHBvnhTjvW/Dx9TXF0Wmt2p/3rPKty1/vv/+zx/k+79toLLQ1syFnibnBbbYuhLcvhB8c84Q/3NP3+a3zzENdtNtYh/P+Zuq9zrLaCrbA1383n3ct8x2nNbx9gXkpRFkjRe5dF7zONoHXsrLYf9luRZRYbqTZfwLtrulyCvRD2y+SYJZ0627+y4sDgncLHjGun1BZKHtWmv8Ln/Bf7/GY8gb+LgAVAfVK6QBjrjOfy/YboXz9TLPfW+f777vwH/D+Zf7r2litsKoSONbxcivYYloZgW6GEut6dB5tfpPF/zItmvcuNZZtIIU5cOoTNdfbgus0Plb8x1jd//2zqf/wS6D9QKgqNa6Wr+6DmET48xa44mtIaO3/Eq8s8bXQbNoN8l9+57emrJ/dbGIBmf39tzvvGzvIP+pK6DIGskbAKCuou3+biaHkLIYHu5pnxL5HdiyB6vKarqtGoMUL+n9+zOGP7yxj094SutTHtbLqIyM6oZrCdeHxwD+GGsskFD88a/4HitRTI8xDB7B3Pdyd7nvoCzabGxtM1D1U2cFYLbYoF+6Cle/79rGFLXcVuCzr1+mG2L/NND9tdi0zIvj9P+FfE826LGs+E2ezOPD84Au4le2HWb+H+ZZ4v3EWzBgA71/psxSdQSznQ2r7hb97yrhy8tb6i/+6z83v5XyRABTutMqzD1Z+6Ps93JXmmmz8ylh+2mPKt+ZTU94tC6HPiTDpbrP/oueMRVfhuB+OOgnOeR3GXg/xDst22Vv+1zLOas28ewksecm8aF/9lbm3ProOllhl2vGjvwtiv6P+Nqs/NnXNXem/vv1gmHo/ZPTxt7p/eRd2/gRdglj5Iy7H6393V5q6eaohsQ1cOscI5Q/PmFbGt0/6jot1TKGWlW3ulU9vMm4Nm4d71wy0tx8EF30EQwJeMGCyWGw+Csic6T0ZYhKMj/21X5tYTVUpuCwZa93N/14ps/zeHYf51l39DVz2lfl+MEHOlR/4tvc7BXpNhgFnmJdjSUDcKPt3kJhuWqaXzYHsS816pyup/+mmJbDXegHvsiz8kjzjxrm7tWmNNQKHiYnaeDgn3bUncDgo5v3N/N+/zVgHwdi32fj9Lv7UCHBVKZzyD+Me2PI/I77/vQ1GXBr8eJc164rTqszfaAT+yzuMUKz6yFiQP/4bTnoIdlsim9bV528uLzRNvrhU+O0sf2tn93Lzcnlxin/TuGiXsR5Wvg89TzA+QvtG1NpY3E7sl84WxxyUcdaDva+W7A6nP7d0r3G/OCnM8XdjOAV923e+z5vnG6FJ62quqcfyWd5lHRto3docyDH1/+pe/4eprMA0vcFYW9//07hhNs/37TPlXiPic+40Vnf7QYD2vQAqi6HfdLNvQmtTj7hUI4zOl61dp6yR8MkNvvXL3oSfX/UtVxabeMWvnjciZgsCmBfB3LtrBl7H/wV6TYTMvmY5Ps0/DrHsbfOyufhTeGKI7x5IbAMnPwLdjzPuuT0rfQHAhHToPMII7/dP17ymw35jyj76GmPZ2ziD4iW55uXtJCoWeoyH5HYmHmKz6eua3zHmOuMzzxppnpPoBPNStw2F0Q7Rb93NvAy3fgtdj/Htk/07mOUYbC9ruPnfe0pNn35mP5jwF/N55vE+A8pmekCKou1ms42Tiz+FxAyT9bRvk/ku+1ndPN+UL64VtB9Ss64NQIu30J0TCU+qYyqzoFRbU8FFW4NsVZXB62fBM2N9FvCi52H/Vp//d+nrxg9qW14AnWuZlU9Zgl64w9wEb54Hq2eZdWldIW+daT4CLJpprMbdK8xxXY/xPdwr34c9v5hI/f5tptmc5gh8luTWDFwV7YaPrjGf2w0w+9sBv4ItxvqNc8QaAl0SE++Ekx+FGCvVs9Nw01S3Mz68aF/zvGSvzw/qpLIIuo+Dcbeaz0V7zLX+/hn//fqcaMTXEyQAleToPxCTCBe8CwN+ZYJ9RTuDp+FtWWB+34FnmmWnmA88EzJ6Q3Kmb12RNV3uuFvN/16TfNsSzATf3ge9YKtv275NRnTOC7iGTl+zLYxlBcZVsvgF+M9vfds/uSF4Fk3vycZK9pYjzX+/bd9aouiCG1bABe+Z9XZLoP9pxqqvLvdZtonWtZx6P4y62nz+4xpffVt1hls2w7hboOcE//IMDggaOrHjIEmZ/uvtLBYnU++Hoy+EttYUezEJvnqd+DBMe8C3b+tu5v5+6US4r52JD4C5pr9+AS4NCJg66XYcnPBX6Dvdty6xjWm51oZtjNmk97Bcb8r83uAT9B3W7GWnPO57qTQwLdpC11qzMa+YpNgoZpwz1H9qtIpiUApi68g5dwY3vrrPWBX2W33uveZBqLCsw3iH8NlNvwOWJVrpCEJWlhoxspvndmbBf281kfedP/kCWfu3wtMj/Mv040vGYkzrAintzQOotfFr29hpV6lZPhEP1nNz60Kf6GRfaoJEK983Vpd9Qw78lbHewN/VkJQJx/3RfE5IMy+QdgNg0l3mobOPAX/ruzSfoLNqgBEJ2+L/30O+a926u2npgLG4Ah+kz241LZn9241b4TeWWykmwQjIyvfNi2rPSnN8YJM3rYtPhJ2c/IhVv9a+dfa1zegFf9lpXhzOawJGRHb+bH4/m7w15v5JagNXLjCBxfwN/hkwSZn+GTSf/jH4dQITICy20vDiUvy3xaeZGIeNKwZGXuFbtgUy2jHpSXSclcJoCWailSGiFEz7m7Fc41N9Qd2U9r7fMaE1TPu7uYfBGDDLQ6TA2nEQ+/yhuDxIbCgm0Rfgjg6YsMUZw6guN1ZzQrq5J7uOqXkup1ER3wqOD4g1JdRRPptz3zT3aWK6cdMoBakdjXFXmm8MCZvENia420i0WAv9qld/ZNQDc1m9q5CzR3Rm6oDAyHoneCjIAwxGHG0hty30ikITNHGKlJ2mZjelv7jDt23/dhOtd0VDv1P9m6H/muhLGdz2vS+4CUbMIbj1aZPa0VjzrbLMg+SpNs10p/VdaIl3h8G+dbuX+Z9nwBnGJ1xRaEQuvTsMs7I+1nwCaz42zcNuxxEUp/Vvu1QyjjL/x/3ZWCvBKM2nRs603QJq1cn3YnRmsvSxAmxT7jPWTYb/bO/88AzM6GuuX9s+RshjrFZCuvU7b/3WvHwz+xuLberfoKcVB4hLNS+l+AC3nC3kzsrsy38AACAASURBVBeQ7RePSzUGgXNbt2PNf1t0nBZ64Q7f+ToMhsl3Q/Yl/hlH1WXQKsgE1oHBPIA0x/AUgYZJQprP0j7lH3DDcugzxbe9VWcj8Oc7RDc63tzvB6z7KMnRN0Mp3+9iBxoDBXn01XDbDhOkTAk+aB3gE/Tahn8edTV0GlZzfYxjOOqoWP9tgUHp7sfD6c/4G1pOpv3NFwcIzIKCul84Nn1PMlb3xDt8dWo/2PjMFwVkdf3mA4htvDTpFivo/125m9yiCsqrPKG78VeX+S+v/MD4K799Au7LND49+6GwrVXnA2pb1rb16XwwD2w3Taz2g8zDs3+bz4K2m3ErPwyeCRCKkVcYQagqM9Z2aiefFVFWYAQjw7K8bCuy73S4yHLf2FZp235wzmsmWFRVao5N7WS29T/NlHe7lYI4+iqfBer0k0Yn+Fu0CZagt7V8uKkd4UJH8NVJyV7/Fssflvryd9O6+qxN2+0EMPDXcNU3vgyO2CQYfrFxpwTSOmAS6NRO5uG3X5xJGTDoTBhzje+77P/Ol5QzBRDghl/MC87ONokLIhTZlxgLbOwNxgK0LfQoy5pMSPPfv9ckOP8daGfFZ9oPgivnm++yMyg6j4JLP4erFsLvf4IJfzV/0Q5xiw0YZ99ZtuR25vdwohSc9LBxkdnYFu8nVnZL4DE2dlkD0w8B4pLNPdppuLm/2g+uuU9g68rJlPugxwQ45vfBtztbQ9G1CPpNa+G3H8NRtVjD6T3gog/N53YDam5PdOhGSkcjxuHSZbT/cop1Le3no5Fo0S4Xm1Hdw3jTetzwn4vNZ9sacvr07ECh3cstub3Pig/seQdG0CuKzA1t+3XfOg9udgQObd9oq87moX4moFmYNRJyFvmWO48y2RcVxcaP26qTz+Kze/j1nGACl19bwdz4VFOGuFTjy0vvAdd8Zx7oJS/5zt3KMcZ6cqYvx7frWN9D1HGYzx1w8Sf+x9gWut2UB2PxXzzbvBzm3u1bX7zbP/slvbtxl+xdZ1oNziCoje1ecnLKP8yYIM6snTNmwlEn+u/nchlRs8vudE/EJfuuE5iMF4CTHoGRlweUobOpX87imufxni8Fzrfy8ONb+QyBsdcbF1JgpyswwcxeE01rrcMQ07JITPcJavvB5gVmB+XHWa4BZ8/MQAvdWTanu6g2nC8IqOnSsJlyr/mdMmsRp5R2cMU8cz1nhCFirhjTKk3p4BPZusoYaKGnWvdjWtea90oosrJNILPz6JrbnNfwzBdMvCpchpzr3zv5Nx+Y1k+oa9pAtEgLXWtNtEsRH+PiP1eNIS0xtu6DnOllTqHybg/oGZja0VjKlaW+h9amwxAj8sW5RkiqHC2B9wLyfsFYi8FuwG4B845mjTAPe8Fmk/GS2qnmw2rn0dpNyLgUI95tLVdI76m+ZqGzKeq0xpLb+VofCWkm0+Gc14yA2nQa7l/mxNYmMJoacO2cdWjb16SEbfnG54IacIb5P+lOOPd10xwNZvkmhwhoB/o5h5xb020Cxiq3fyfn+WMDLPTjbzYuGtv1VFs5QjXlbZyprnbPwtp6C3YZ7XMTgU+wPCEG2bLdDzGJNa3eOIfFHq4vOFyxiY4L7pMORqjfzeYkK0Zh17WuMgS7Pt7laNMa/d3n4ZXNptux5thAnD72YEH82khpb4KszuWOQw/uHPWgRQp6QWkV1R7NLVP7MqKbdTNXlcPOEPna4OsN1rqb/01j4xT0mCTzMFdXGPdJoP/N9p9VFBprt7vVIaFNb9gUJNBz1En+N2e7gaa5aDfTj78ZTn8WWnc1ZdtnBQdTOtS0zOxu0TZ2jz/7hnRmQgQ2y72fHdkHtuXd7xR/31+g//OYPxgrxhUse8XqnDHgV+blVZpvrtnUv8FZL9fc3ymU/U417oRQ/tY2PeGUEKmKTpz+4GAWun0tRl8Ff/gptLD4vQzqmE5QW8HDy+aacv7qeTj9IAbM6jHe/LdfeoHYmUTByuEsZ30t9IYg2P3gZOTlpp52rCqqLkF33IN2toyTHuMgtRb//cGgooJ/DhdnXRrj2gahRbpc7NzzzFTHBf34ehN1/9MGSHY83AVbzKhytqCldfV1yBh8ri9S77TgE9PNw1Sa73sR2Ey43bhQ7Lzi5HZG0O8oMNHuxyxf3YjLTRT8z1uNFezsSNJ7ijmm4zAjZMf+0ecvjEn0ZTYktDY+1/G3mQ4fye2M/9GJLV6DzzZNdGf6pFPYEjN8n53iHujzDUXbo3ytgEC6HmO62fcYF/CdIWIb9kPbujuc82rwfWyUguG/NS+6UEFY8E+Rc5bB/i5XmI+C82VfV4aUjd1qGnx2ePt7j+vny68PWpb40OU4VJdLsNhEfTnndZMKuui54Ntd0b6XX6BfPJDagqINjdOIOFgLHfyvZyO7Wrxf0yTf0kS4PZo3F23zzj6UmeK4oBusNMDSfNP8tpl9s3/nAu2B0gNGVI++0CfozhHiElr7UrwO5Ji3t31DjrvFfyAqWxxdLuPKmXyvecB7TYQTbvcJprPJZ4tMXDKMv9W/kk5BiW9lmtrjbzUWckxCTUvWfkCyL4VBZ/m7I/ysOIdwO10psUH8xAdLr0lwW44RGWfnqaQQgp7aydRn+MXhf0ddYun8zYNZtOFOuG23UlwxwS1EJ+k9TWerxspqsAUjmOvHKejB3AlBz2eJTnJ705poKPpNN9cqlKA7rd+6LFk/C72RBd3pxqrPhOzOl1MTTejeogT9y1W7+euHZhChxNgoBjl7htpZFaX5/uM7BE5GUF1hsj7aHuXfTHeS3M7qglxujk9oDdNn+AKnrRzpZMkBnSfG/sH3OZTlFFPLTe28oZ3iXJdoKFXTt+x86J03rzNbILDJfMZzvsyfg8H+Lqc/19kqcOJymcBbQxLK5WK7y8K1wOzrHxOGSF85P/Toew2BV9CDtKLqcgfVdr6EtPBfAuFS28vP2TqqS6T9fOh1vFAPFec9UVtmTiiayM3i95VN/o2NyMfLd3k/v3f1MSTEOn4E20dXutc/SBnY66663HSZTmhdU9Dt7tytu5pAld2rLjHdpPvZOAOMwTqr1EUwH36wbcGCf+Bz59RFqKBeba6LIefUfd7acL4gQrlcGgPni9Xv4bSDlGFaUPb1D8fiCpYF05DYZQl2H9Tnu20LvTHcA67aBN1xT9T13dG1BEUbGj8fen1cLk3jZvH7yib/xkZk7W7jFhnYKZWj2jmtMEdmQWl+gKA7rU1l8rIrDhhBD7SgkzONoKe0NyPKVVsWeqAwRcWYVKg2vcL3szqp0W3egf0Qu6JDn/vkR+DYG+oeUCyUFReYqdJYNKWgZ/QJvt72rYeb5hZTj9+zsYh2ZLkEEixTqC5s0a0rMFkfahNfPwv9ELJcGppDyXKBxrmOddBiBF1rzY6CMi49tjv/N72/c4Pp9WjzyY1woaPziNNCT2zjm9EkId1YDtd8bwbQB5/bJiHd5ILbgh7YQw18PQbrQ60WuvXwxreq3UpslQV1jUUWqhnZ0M3tUDRij7kaBGb/2Bz9G3O9B/46vPMcjIXe2NiCHswSrI+FbrsiG0Mow3W51BkUbUKXi+sQs1yawUJvMWmLBaVVlFW56ZQWIIaLnq85YuCqWQQlsY0vxS7FDmY6bhr7Rrd96O5K48JJDDOLIFxq88/W1syuL/1OqbnuNx+aoVMbA+cASE1FqIfL5TIB1XB9pLW9bJuLYL7aeomJ1ZINt8v7wVDbS+KggqIRZKGLy6X+7CgwbpSOgYLunCLLxvanB+J0AXizUxw329QHTJpin2m+7t/Fe8LvuBEu4QRFG8o/e2eIqd4CR89rSM4JMm56U3D+O6E76YRLfVxojYV3JNAgwqEUnDyj9lE+A+l2vBlB0jmIV0MRtsulLgu9CbNcDlnQJShab7buM+6QrNYBgh5sotzlb9dcB/6WiR1Ec95sqR184147/dwNbdHUZqHbD29D+eeaw3XQXO4Ke4CvQ8FrIR4GLpfAoZ0DCTX+fihcLphw26GVKRS1ulwOJijqzENvyiyXyLDQW4zL5b0fc2iTFEuvzIBAn3PEPntM51A4hdkOlkUFcbmA/4/lTFNsCGpr1tspas4xuIWmI5x0xaaiNgv9cKOhgqK1jeXS0LgOMctFgqL1o7zKzfx1eVw5rifxMQG+UDvICXUHXGyXS3S8r0t4qJvNKbrBRpQ7FGrLchlyrgnwBU5SKzQNh5OgZ//OTJ49NMhUbocb4Qi6K6ZuS9jlMs9HdVkEuFxE0OvFhtxiPBr/jkQ2zrTEut6YtvXrTPkKFYF3/lj1yTWvjbry0AOH5hSajsMpy6V1NzPuTCRQm3vEDoqGK4Ax8WbwuPp09jkYDnUsl8PV5aKUmqaUWquU2qCUujXI9i5KqXlKqZ+VUsuVUic1fFFDs25PEdFUM9gdMP9f4Mh2daZEWdaXMzgaykJv3R1QZmChhr6xDsdMCsHgtdAPA0GPJGr1oVvPT7gWd0xi41vnEJEWep2lVEpFAU8DJwL9gfOUUv0Ddvsr8I7W+mjgXOAghpQ7dFbuLOTPMe+Q9eGv/UdUtGd6t3H633pNrnki+wdwjvsRKgLfcSj8NRcuPIhB78NFBP3wxb4HGrsXaEsjHJdL2BZ6QtMI+qH60JshyyWcUo4ENmitN2mtK4G3gMDZXDVg+ylaAQFK2niUV7l5/6ccRiXbExDn+TYGjoTotLDjgvSStK0Ip4XutCwCLfzo2PpFv+uiGW4EIUwS081UYxe+19wliSxqG83yYC306ITGz3ABf7dafVrhh2lQtBOw3bGcAwRG5O4CvlBK/R5IAoKmYCilrgCuAOjSJci8ifVgxY4DFJRW0aFdEpThG2xp3RdmUmcnzpsgWD6x3VXeaaE738xN9QMdDv5ZIThKwXE3NXcpIg/7ng42P63XQg/TkGkqC/1Qx3KxjT17PoQmoKGCoucBL2utH1VKjQFeVUoN1Np/5get9XPAcwDZ2dm1TN0SPnaHooQ4S6ztr3zjrJo7O9+yzmFhJ95phr+1rfvAyXFtGtsqOOd1WH+Qs60IQqRww4rgI2x6g6Lh+tDjm8hCP0QfOoSucyMRjqDvAJyJ1lnWOieXAtMAtNbfKaXigQwgl0Zmx34j6PGxVlW0B+4K1S3eIc5Ol8uxNxrh3rcJlr9jxkEPengjW879pvs6LglCSyMtRKvcNrRqG5HRSVMFRQ/Vhw6h69xIhFPKxUBvpVR3pVQsJugZOBjKNmAigFKqHxAP5NEE7NhfRnpSLNFR1sUPnA7OifNHcbpcbKFO7wE3rgg+p6ggCI2D7XIJ1+ruPDL4pM4NTUNY6E1MnRa61rpaKXUd8DkQBbyotV6plLoHWKK1ngXcBDyvlLoREyC9WOvaZsNtOHYUlFkDclmi7HH77+CK9o3f4bSwnTPZC4LQfByshd5UMQynD72xc94biLB86Frr2cDsgHV3OD6vAsYGHtcU5BZVGEG336CBA2+Fest2GGJm5R7+u8YvpCAIofFa6IdZP8cItNAjo5S1UFhWRauEGN8Ft4e/9RJiotfoODj+5tDzWgqC0DSog0xbbCpcIuhNTmF5FakJ0b4LXlFUy97OjJXD7OYRhCOVg3W5NBV+FnpkuFwiWtA9Hk1xRTWp8Q4LPXDaNaffXImgC8Jhh3dwrsNMNP3y0COjb0hEC3pRRTVaQ6rT5VJ+IGCvEC4XEXRBODw42J6iTYWfhS6C3ugUllUBkBIfHVrQW3XyfRYLXRAOQ6znsik6Cx0Mh1uLIQwiW9DLjaD7u1wcgh6TBL963rcsFrogHH54zHNc63gvzUGEBEKdRF6JHRSVm/xyExS13vIVDh969iX+A235CfpBWgPJ7etZSkEQasVtCfrhZqFHSCDUyWH2Sjw4bJdLmirxCbrTQndFB7xl6+ly+Wuu/7GCIDQcdse/wy7LJfKe+YgW9ANlVfRTW+n/yvm+kRCdgh4VG7pzwMFYA5EwZ6MgRCqHq4UuPvSmZdaynQyMs8b/cleY/36CHhM6bTECfyxBaJG4K83/w03QxYfedJRUVLNg/V6O6dvZf0NVqe9zVExoC10QhMMDr8vlMHMYRKAPPWIVbl+JeaunpwaZqMLGFUPIPHRBEA4P7JFPE9KbtxyBRKBeHGavxPCxBb1VTC3D5Qb60CWwKQiHHyOvNNbwyMubuyT+RKBbNnIFvdQIemqMO/RONVwuCi77CvLWNHLpBEEIm+hYGHNNc5eiJmKhNx37io2gp0QHsdDjWkHFgSBBURdkDTd/giAItRGBgh55JbYosCz05GAWeuuu5r9yhc5yEQRBqA0R9KYjv6SSmChFPFU1Nzrn8ZMsF0EQ6kME+tAjVuEKSipJS4xF2TmsTuJSHAsqxGdBEIRaiEADMPJKbFFUUW1GWQyccs6J1mKhC4JQPyQPvekor3STGBsF1QEW+kUf+S+LoAuCUB8iUC8ir8QWpZVuEmKifF3+ATplQ4/x+FwrWoKigiDUD/GhNx2lVW4SYqOh2iHowfzpYqELglAfIlAvIq/EFuWVbhJiXAGCHiTjRQRdEIT6EIEt+ohVuNKqahJDWejHXAeJGdB7CpLlIgjCkULE9hQtq3STEBvgQ7cFvd0AuGWj+exx9CSNwDeuIAhCuESshV5mB0Xr9KHLaIuCIBwZRKTCaa0prbLTFit8U1c5xd1GslwEQThCiEhBr6j2oDU+l0tCa7MhmIXuRCx0QRBaMBGpcGWVZkAur8slXEGXoKggCC2YiBT00ioj6ImxUVBVBonWTCf2VFahEAtdEIQWTEQqXFmlEe6E2Ggo3AnpPcM7UARdEIQWTEQqXFmlSUVMUhVQuhfa9DAb6pqTUIKigiC0YCIyD73McrmkVe42K9K6wtmvQIchtR8oFrogCC2YiBT0imoj6KllO8yKtK7QeUTdB4qgC4LQgolIhauoMi6XhPI9ZkWrTs1YGkEQhMODsARdKTVNKbVWKbVBKXVriH3OVkqtUkqtVEq90bDF9Kei2gh6rLbSFGMSwztQLHRBEFowdbpclFJRwNPAZCAHWKyUmqW1XuXYpzdwGzBWa12glMpsrAIDVLqNyyXaFvSo2PAOFEEXBKEFE47CjQQ2aK03aa0rgbeA0wL2uRx4WmtdAKC1zm3YYvpju1yitTVcbnRceAdKlosgCC2YcAS9E7DdsZxjrXPSB+ijlFqolPpeKTUt2ImUUlcopZYopZbk5eXVr8RApdsh6Coq/JlFxEIXBKEF01BZLtFAb2A8kAX8Tyk1SGu937mT1vo54DmA7OxsXd8v87PQw7XOAen6LwjCQXHBe76e6BFAOIK+A+jsWM6y1jnJAX7QWlcBm5VS6zACv7hBShmAnbYYpavC95+DWOiCIBwcvSc1dwkOinAUbjHQWynVXSkVC5wLzArY50OMdY5SKgPjgtnUgOX0o9LKcnG5Kw/OQhdBFwShBVOnwmmtq4HrgM+B1cA7WuuVSql7lFKnWrt9DuQrpVYB84Cbtdb5jVXoimoPcdEulLvyIC10cbkIgtByCcuHrrWeDcwOWHeH47MG/mj9NTq2oOOuEJeLIAiCRUQqXEW1h9hoayx0cbkIgiAAESrolV4L/SBdLoIgCC2YiBT0imq3EXSx0AVBELxEpMIZl4sL3AebtihBUUEQWi4RKeiVzqCoWOiCIAhAhAq6cblEQfXBpi1GZHUFQRDCIiIVrrLaQ1xMPdIWpeu/IAgtmIgU9IpqD7FREhQVBEFwEpEKV+G10MXlIgiCYBORClft9hDtqo+FLi4XQRBaLhEp6G6tiXIpy0IXl4sgCAJEqqC7nYIeE/6BIuiCILRgIlLh3FoTBUbQxeUiCIIARKqgeyBGmUkuDspCFwRBaMFEpKB7tCbGZQm6SwRdEAQBIlTQ3R5NDGbWIlwNNS2qIAhCZBORgu7xaKKUCLogCIKTiBR0t9bEYLtcopq3MIIgCIcJkSnoHk2MWOiCIAh+RKSge7S4XARBEAKJSEGXoKggCEJNIk7QtdZ4NETZeegi6IIgCEAECrrbowGItYOiUSLogiAIEImCro2gR4sPXRAEwY+IE3SPpeNRiMtFEATBScQJutdCF0EXBEHwI/IE3WMLuu1ykY5FgiAIEIGC7rEEXVwugiAI/kScoEtQVBAEITgRJ+heC12LhS4IguAk4gS9poUuPnRBEASIREEXC10QBCEoESfokocuCIIQnIgT9GpL0X0uF5mCThAEASJQ0D2WD90lE1wIgiD4EZagK6WmKaXWKqU2KKVurWW/XyultFIqu+GK6I/bdrmID10QBMGPOtVQKRUFPA1MBnKAxUqpWVrrVQH7pQDXAz80RkFt3PXpWHTpHCja2YilEgRBaH7CsdBHAhu01pu01pXAW8BpQfa7F3gQKG/A8tXAdrlE6WqzIhxB7zwC+gcrsiAIQsshHEHvBGx3LOdY67wopYYBnbXWn9Z2IqXUFUqpJUqpJXl5eQddWKinhS4IgnAEcMhBUaWUC5gB3FTXvlrr57TW2Vrr7LZt29br++yORS4tQVFBEAQn4Qj6DqCzYznLWmeTAgwEvlZKbQFGA7MaKzDqG5xLxnIRBEFwEo6gLwZ6K6W6K6VigXOBWfZGrfUBrXWG1rqb1rob8D1wqtZ6SWMU2Ha5uCTLRRAEwY86BV1rXQ1cB3wOrAbe0VqvVErdo5Q6tbELGEhNl4sIuiAIAoSRtgigtZ4NzA5Yd0eIfccferFCU7Prv/jQBUEQIAJ7itpd/13abaxzpZq5RIIgCIcHESfofl3/xd0iCILgJeIE3e7677XQBUEQBCAiBd0OilaL/1wQBMFBxAm6x5nlIha6IAiCl4gTdL88dBF0QRAELxEn6LaFrkTQBUEQ/Ig4Qfda6J4qEXRBEAQHkSvo1SUQm9zMpREEQTh8iDhB9wZFK4shLqWZSyMIgnD4EHGC7s1DrywSQRcEQXAQgYJudf0XC10QBMGPCBR02+VSBHHiQxcEQbCJPEE3eo6qLIa41OYtjCAIwmFExAm6x6Nx4UFVlYjLRRAEwUHECbpba5IoNwsi6IIgCF4irmfOOdmdmZJVDa8ieeiCIAgOIk7QWyfF0jrFyl0UC10QBMFLxLlcAKgoMv9F0AVBELxEpqBXWz706PjmLYcgCMJhRGQKurvK/I+Kad5yCIIgHEZEpqB7qs1/lwi6IAiCTWQKutdCj7iYriAIQqMRoYJeaf6LhS4IguAlMgXddrmID10QBMFLZAq67XKRGYsEQRC8RKage2wfemzzlkMQBOEwIjIFXdIWBUEQahCZgu5NWxSXiyAIgk1kCrpY6IIgCDWITBPX9qFL2qJwhFBVVUVOTg7l5eXNXRShiYiPjycrK4uYmPB1LjIF3S1pi8KRRU5ODikpKXTr1g2lVHMXR2hktNbk5+eTk5ND9+7dwz4uMl0unipAgSuquUsiCE1CeXk5bdq0ETE/QlBK0aZNm4NukUWmoLurxDoXjjhEzI8s6vN7R6age6rFfy4IghBAWIKulJqmlFqrlNqglLo1yPY/KqVWKaWWK6XmKqW6NnxRHbirZGAuQRCEAOoUdKVUFPA0cCLQHzhPKdU/YLefgWyt9WDgXeChhi6oH54qsdAFoQmJiopi6NChDBgwgCFDhvDoo4/i8Xia5LtffvllXC4Xy5cv964bOHAgW7ZsqfW4xx9/nNLSUu/y7bffTufOnUlO9p+LeMaMGfTv35/BgwczceJEtm7d6t02bdo00tLSmD59esNUppEJx8wdCWzQWm8CUEq9BZwGrLJ30FrPc+z/PXBhQxayBu5K8aELRyx3f7ySVTsLG/Sc/TumcucpA0JuT0hIYOnSpQDk5uZy/vnnU1hYyN13392g5QhFVlYW999/P2+//XbYxzz++ONceOGFJCYmAnDKKadw3XXX0bt3b7/9jj76aJYsWUJiYiLPPPMMt9xyi/d7br75ZkpLS5k5c2bDVaYRCcfl0gnY7ljOsdaF4lLgs2AblFJXKKWWKKWW5OXlhV/KQNziQxeE5iIzM5PnnnuOp556Cq01brebm2++mREjRjB48GCv+H399deMHz+eM888k759+3LBBRegtQbg1ltv9VrFf/rTnwDIy8vj17/+NSNGjGDEiBEsXLjQ+53Tp09n5cqVrF27tkZ5vvjiC8aMGcOwYcM466yzKC4u5oknnmDnzp1MmDCBCRMmADB69Gg6dOhQ4/gJEyZ4RX/06NHk5OR4t02cOJGUlPDmLr7nnnsYMWIEAwcO5IorrvDWdcOGDUyaNIkhQ4YwbNgwNm7cCMCDDz7IoEGDGDJkCLfeWsOTXT+01rX+AWcC/3Is/wZ4KsS+F2Is9Li6zjt8+HBdb/5zidb/GFr/4wUhwli1alWzfn9SUlKNda1atdK7d+/WM2fO1Pfee6/WWuvy8nI9fPhwvWnTJj1v3jydmpqqt2/frt1utx49erResGCB3rt3r+7Tp4/2eDxaa60LCgq01lqfd955esGCBVprrbdu3ar79u2rtdb6pZde0tdee63+97//rS+66CKttdYDBgzQmzdv1nl5efq4447TxcXFWmut//73v+u7775ba611165ddV5eXlh1sbn22mu9dbGZN2+ePvnkk+u8Rvn5+d7PF154oZ41a5bWWuuRI0fq999/X2utdVlZmS4pKdGzZ8/WY8aM0SUlJTWOdRLsdweW6BC6Go7LZQfQ2bGcZa3zQyk1CbgdGKe1rjiEd0zduMWHLgiHC1988QXLly/n3XffBeDAgQOsX7+e2NhYRo4cSVZWFgBDhw5ly5YtjB49mvj4eC699FKmT5/u9U/PmTOHVau8nlwKCwspLi72Lp9//vncf//9bN682bvu+++/Z9WqVYwdOxaAyspKxowZU696vPbaayxZsoT58+fX6/h58+bx0EMPUVpayr59+xgwYADjx49nx44dnHHGGYDp/Qmmrpdccom3355LDQAACi9JREFUZZCenl6v7wwkHEFfDPRWSnXHCPm5wPnOHZRSRwMzgWla69wGKVlteKpl6FxBaEY2bdpEVFQUmZmZaK158sknmTp1qt8+X3/9NXFxcd7lqKgoqquriY6OZtGiRcydO5d3332Xp556iq+++gqPx8P333/vFb1AoqOjuemmm3jwwQe967TWTJ48mTfffPOQ6jNnzhzuv/9+5s+f71fmcCkvL+eaa65hyZIldO7cmbvuuqtZhmmo04euta4GrgM+B1YD72itVyql7lFKnWrt9jCQDPxHKbVUKTWr0UoMkrYoCM1IXl4eV111Fddddx1KKaZOncozzzxDVZUZY2ndunWUlJSEPL64uJgDBw5w0kkn8dhjj7Fs2TIApkyZwpNPPundzw7COrn44ouZM2cOdgxu9OjRLFy4kA0bNgBQUlLCunXrAEhJSaGoqKjO+vz8889ceeWVzJo1i8zMzDCvgj+2eGdkZFBcXOxtraSkpJCVlcWHH34IQEVFBaWlpUyePJmXXnrJm4Wzb9++en1vIGHloWutZ2ut+2ite2qt77fW3aG1nmV9nqS1bqe1Hmr9nVr7GQ8RSVsUhCalrKzMm7Y4adIkpkyZwp133gnAZZddRv/+/Rk2bBgDBw7kyiuvpLq6OuS5ioqKmD59OoMHD+bYY49lxowZADzxxBMsWbKEwYMH079/f5599tkax8bGxvKHP/yB3FzjCGjbti0vv/wy5513HoMHD2bMmDGsWbMGgCuuuIJp06Z5g6K33HILWVlZlJaWkpWVxV133QWYTJbi4mLOOusshg4dyqmn+uTruOOO46yzzmLu3LlkZWXx+eefB61TWloal19+OQMHDmTq1KmMGDHCu+3VV1/liSeeYPDgwRxzzDHs3r2badOmceqpp5Kdnc3QoUN55JFHwv0pakVpKxLb1GRnZ+slS5bU7+CXTgY0XDK7QcskCIcrq1evpl+/fs1dDKGJCfa7K6V+1FpnB9s/Qrv+V8nkFoIgCAFEpiq6qyAuvNxQQRCEhuSMM87wy7QBk1MeGBRuDiJT0MWHLghCM/HBBx80dxFCEpkuF3e1ZLkIgiAEEKGCXikWuiAIQgCRKeiVxeJDFwRBCCAyBb28EOJTm7sUgiAIhxWRJ+jVlVBdBnGtmrskgnDEIOOhN/x46OPHj6fefXFCEHmRxQprHGix0IUjlc9uhd0rGvac7QfBiX8PuVnGQ28546EfXpQfMP/jRNAFoTmQ8dBr8t///pezzjrLu/z11197rfqrr76a7OxsBgwY4B0uobGIYAtdXC7CEUotlnRT0aNHD9xuN7m5uXz00Ue0atWKxYsXU1FRwdixY5kyZQpgBr5auXIlHTt2ZOzYsSxcuJB+/frxwQcfsGbNGpRS7N+/H4Drr7+eG2+8kWOPPZZt27YxdepUVq9eDYDL5eKWW27hgQce4N///re3HHv37uW+++5jzpw5JCUl8eCDDzJjxgzuuOMOZsyYwbx588jIyAi7Xi+88AInnnjiQV+PSZMmccUVV1BSUkJSUhJvv/025557LgD3338/6enpuN1uJk6cyPLlyxk8ePBBf0c4RJ6gl4vLRRAOJ2Q8dDO077Rp0/j4448588wz+fTTT3noITO18jvvvMNzzz1HdXU1u3btYtWqVSLoXsTlIgjNjoyHXpNzzz2Xp556ivT0dLKzs0lJSWHz5s088sgjLF68mNatW3PxxRc36jjpkedDl6CoIDQrMh56cMaNG8dPP/3E888/73W3FBYWkpSURKtWrdizZw+ffRZ0uuUGI/IEvVx86ILQ1Mh46LWPhw6mBTJ9+nQ+++wzrxtpyJAhHH300fTt25fzzz/f6xpqLCJvPPQ1n8LSN+DsV8AV1fAFE4TDEBkP/cjkYMdDjzwfet+TzZ8gCILgR+QJuiAIQjMi46ELgnDIaK1RSjV3MY54mmo89Pq4wyMvKCoIRyDx8fHk5+fX6yEXIg+tNfn5+SFTOEMhFrogRABZWVnk5OR40/WElk98fLy3U1a4iKALQgQQExND9+7dm7sYwmGOuFwEQRBaCCLogiAILQQRdEEQhBZCs/UUVUrlAVvr3DE4GcDeBixOJCB1PjKQOh8ZHEqdu2qt2wbb0GyCfigopZaE6vraUpE6HxlInY8MGqvO4nIRBEFoIYigC4IgtBAiVdCfa+4CNANS5yMDqfORQaPUOSJ96IIgCEJNItVCFwRBEAIQQRcEQWghRJygK6WmKaXWKqU2KKVube7yNBRKqReVUrlKqV8c69KVUl8qpdZb/1tb65VS6gnrGixXSg1rvpLXH6VUZ6XUPKXUKqXUSqXU9db6FltvpVS8UmqRUmqZVee7rfXdlVI/WHV7WykVa62Ps5Y3WNu7NWf564tSKkop9bNS6hNruUXXF0AptUUptUIptVQptcRa16j3dkQJulIqCngaOBHoD5ynlOrfvKVqMF4GpgWsuxWYq7XuDcy1lsHUv7f1dwXwTBOVsaGpBm7SWvcHRgPXWr9nS653BXCC1noIMBSYppQaDTwIPKa17gUUAJda+18KFFjrH7P2i0SuB1Y7llt6fW0maK2HOnLOG/fe1lpHzB8wBvjcsXwbcFtzl6sB69cN+MWxvBboYH3uAKy1Ps8Ezgu2XyT/AR8Bk4+UegOJwE/AKEyvwWhrvfc+Bz4Hxlifo639VHOX/SDrmWWJ1wnAJ4BqyfV11HsLkBGwrlHv7Yiy0IFOwHbHco61rqXSTmu9y/q8G2hnfW5x18FqWh8N/EALr7flflgK5AJfAhuB/VrramsXZ728dba2HwDaNG2JD5nHgVsAj7XchpZdXxsNfKGU+lEpdYW1rlHvbRkPPULQWmulVIvMMVVKJQPvATdorQud06y1xHprrd3AUKVUGvAB0LeZi9RoKKWmA7la6x+VUuObuzxNzLFa6x1KqUzgS6XUGufGxri3I81C3wF0dixnWetaKnuUUh0ArP+51voWcx2UUjEYMX9da/2+tbrF1xtAa70fmIdxOaQppWwDy1kvb52t7a2A/CYu6qEwFjhVKbUFeAvjdvkHLbe+XrTWO6z/uZgX90ga+d6ONEFfDPS2IuSxwLnArGYuU2MyC/it9fm3GB+zvf4iKzI+GjjgaMZFDMqY4i8Aq7XWMxybWmy9lVJtLcscpVQCJmawGiPsZ1q7BdbZvhZnAl9py8kaCWitb9NaZ2mtu2Ge16+01hfQQutro5RKUkql2J+BKcAvNPa93dyBg3oEGk4C1mH8jrc3d3kasF5vAruAKoz/7FKM73AusB6YA6Rb+ypMts9GYAWQ3dzlr2edj8X4GZcDS62/k1pyvYHBwM9WnX8B7rDW9wAWARuA/wBx1vp4a3mDtb1Hc9fhEOo+HvjkSKivVb9l1t9KW6sa+96Wrv+CIAgthEhzuQiCIAghEEEXBEFoIYigC4IgtBBE0AVBEFoIIuiCIAgtBBF0QRCEFoIIuiAIQgvh/wH/setv/8EvjAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1630783945142,"user_tz":-540,"elapsed":20661,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_16_4_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1630783946119,"user_tz":-540,"elapsed":624,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630783946529,"user_tz":-540,"elapsed":413,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"fc382f4a-f885-4f98-d873-d23457186b00"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630783977351,"user_tz":-540,"elapsed":30825,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"af586f21-980d-430f-8adb-8609143bbeb7"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1630783977352,"user_tz":-540,"elapsed":17,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1630783977352,"user_tz":-540,"elapsed":15,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1630783979220,"user_tz":-540,"elapsed":1882,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1630783979221,"user_tz":-540,"elapsed":8,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1630783994096,"user_tz":-540,"elapsed":14881,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1630783994097,"user_tz":-540,"elapsed":13,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"adf3e9f3-1134-4070-d969-0d44be65e765"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1630783997264,"user_tz":-540,"elapsed":3176,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0a04d5d0-268a-4d62-9e78-8f94cf1f3c06"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/BatchSize_16_4_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/BatchSize_16_4_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_901001c5-2e1d-4027-aa13-7f9830be4126\", \"BatchSize_16_4_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}