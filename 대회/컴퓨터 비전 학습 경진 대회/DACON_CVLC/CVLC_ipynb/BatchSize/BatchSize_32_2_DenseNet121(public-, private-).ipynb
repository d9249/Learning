{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BatchSize_32_2_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1vco_0hIBI4evIfDmQDH07Nq5lQJx4Kod","timestamp":1630778923697},{"file_id":"1r3BflNbSZB370f8W3h8PQ5C7NEdbXsJj","timestamp":1630766001155},{"file_id":"1fyedjHIW6-8SHp9ow65apBeykbHxS7oi","timestamp":1630760236494},{"file_id":"1QnPclrYnKmBsAWRJ51Rre-PMBgVa9Cl3","timestamp":1630760206258},{"file_id":"1K7n8RRDie4UKR4IX4z4XcOvrqBpuzCX2","timestamp":1630760179968},{"file_id":"18NxWLqCn6GIqSPUVwANqnaPRMf5i0YEt","timestamp":1630745018066},{"file_id":"1EDWcCOn_TRgBJv_ZMCvsd_r1unwaZzE7","timestamp":1630744974962},{"file_id":"1JA5LGhrhW19laOkeoR8qPDaFWjoqSMzr","timestamp":1630744944221},{"file_id":"1PtmJdXo9AY1M6u1bHhpUHKQ0PGMoOPWZ","timestamp":1630744160988},{"file_id":"1q8viSykqnipNZ_WZtwFtIvj_ZdVFX4vC","timestamp":1630699910907},{"file_id":"1I9ElhTSO4vKs1a5lfr-r0PB1MndT08Nr","timestamp":1630699885519},{"file_id":"14FhoIy7URVKqSDzemys-qARDeDRrpK5D","timestamp":1630676044569},{"file_id":"1SyIKO_pcFSLG_l2VOhA42Qj1Sfgu9xJ5","timestamp":1630675996818},{"file_id":"1bR6CC08w6e4QxXCvbI1hPuVGX4Xr2aS6","timestamp":1630675972365},{"file_id":"1m9zTT841JY7COW8wa0uLUmdxh4mwTROg","timestamp":1630675935279},{"file_id":"1K-M0y6ngoFlaXHKpD1A2obin5bN69rOP","timestamp":1630668564612},{"file_id":"1blwd04nWkDbZIiyYRsoikGHv7D2lN1M7","timestamp":1630663027637},{"file_id":"1OWcGKJuP-Tlx2cd7fYiEF4iFQBw_jTaV","timestamp":1630663004855},{"file_id":"1iIv2T-FeMWjlLKmFmVia0cp_FsKKhP6n","timestamp":1630662692922},{"file_id":"122a3KanHz7tYxI2RkTyd5CDHFsGXxRcD","timestamp":1630652306408},{"file_id":"1rmWpSzQjpXc4LfrgWir30dbjafFqnlzh","timestamp":1630652271928},{"file_id":"1LZU500qd_mzkL28Su52XN_qaRf_yaHht","timestamp":1630646510103},{"file_id":"16JOqSkO3uC_jfclj81AzxJShlzoOMH_B","timestamp":1630613714759},{"file_id":"1eaN7vOK3RK8eeKTKP85BVew6KGSCyH_6","timestamp":1630613687181},{"file_id":"1hFz_giaup3ft5PdsqD18owTBdvEk-9En","timestamp":1630613648785},{"file_id":"15fNytZzTcRPBSdHijbaWLKC0KR8SWzhp","timestamp":1630612864615},{"file_id":"1C8ZNqu7Eb5heuVECStaVKpkxyihLmMkO","timestamp":1630602470521},{"file_id":"1DN9Efw8q90g7HCJ5VhXJYn57jItRUHnr","timestamp":1630602447501},{"file_id":"1ZYwQgfbGvCmGKmNM25goBD839_1yJrul","timestamp":1630602408672},{"file_id":"1_j6u69eFZFR-bV-7FdC_KmRhJ8AI-Ifh","timestamp":1630602370180},{"file_id":"1unjV74CiTTQsLla4T4r8Xawlb_l1_ego","timestamp":1630602293534},{"file_id":"1MSEaTlfMh47aob3-U8yPBQNcpxSO0RC6","timestamp":1630524166308},{"file_id":"1uj1q7VaxDNJ4v0Qnpewz9OO5vDawvGL1","timestamp":1630524142681},{"file_id":"1SXi4BHkyVdQzSXMkx23PhKLYG_cgy9Ne","timestamp":1630524118198},{"file_id":"1ktumtKU2gng5uaTndy4q6ORrf_vm1MB5","timestamp":1630516331014},{"file_id":"19fk2AWJq9X3zvPm2WSAtKO7ljZBPUG5l","timestamp":1630516290119},{"file_id":"1ZOrlvLwHgJ8yqXlMzsUBuNpAS1leHpTw","timestamp":1630516251869},{"file_id":"1lrAXMllo7_hAtAVIxPhE7Xno3vS6aFxT","timestamp":1630515420255},{"file_id":"17dTh7DEVFlzrmiHY5X5ldlDVaanaV9e-","timestamp":1630504418101},{"file_id":"1mqEzmVKqNVAF_0chUK1joEpZK_PYc0_4","timestamp":1630504394196},{"file_id":"1mzp8pt1OJt9CAaiKKe25s3yNAqrGew9R","timestamp":1630504147646},{"file_id":"1FMgk3jn7Q2dQ8p_Hu7bJRfcSBb13Rnvo","timestamp":1630504098889},{"file_id":"1hhBZ077MXyvhUnuxI7SD86ahYiLsCzOG","timestamp":1630500513841},{"file_id":"1EEfvNr8ZybJmpeRuKJ-r7__rhnDnaIM7","timestamp":1630495179853},{"file_id":"17e4zKJb3AvCBXA5MdPqutbvT9s1-CP6A","timestamp":1630484224103},{"file_id":"1ZyJ9--fiBCqqZIpZYXBwYIGMXZPnoPvu","timestamp":1630484173863},{"file_id":"1abkZGMd_cSctW05mIZfosyOPOLNr-LK9","timestamp":1630484131331},{"file_id":"1fKp4Svl_srbEAv_YpXTvSwqDozb4bj9H","timestamp":1630484105207},{"file_id":"1y9kcnOXGhn5ArjCk66kqJCIvgyfTRSkk","timestamp":1630483907553},{"file_id":"1o9CD4AI2tKzcdbdLJ4A6xkENgqmZG7oW","timestamp":1630475138628},{"file_id":"17KUAlMIBl9TgxSnuNYcPwx2zScEUw5W-","timestamp":1630475103015},{"file_id":"12cn5R3wN6-IWoeS68BSqi4LxqlCxJxYt","timestamp":1630464969114},{"file_id":"1KLLc8roFaz12DcPj1WHhuKt9ZBQqi76a","timestamp":1630464678834},{"file_id":"1VZIQ1plZ8Dw3dEaOdrcDkgTjXOv0OcTp","timestamp":1630464589009},{"file_id":"1HiqQpOR-bo5ZelQ96RenE8K365HqE7Lv","timestamp":1630438189228},{"file_id":"1ltViornnQGTXyCDuiYgIGfZy1m46LTW_","timestamp":1630438122242},{"file_id":"12vcTsqE7nuRUe3r9-4k5efqml3ud1k9Z","timestamp":1630438078632},{"file_id":"1EdFynNtlBeF206lf5xA2umzEqK_Pjyi5","timestamp":1630437839162},{"file_id":"1pKJK3lnnRPxX28V0U_A45uk_SI4WlDZr","timestamp":1630432659647},{"file_id":"1soBcJ0zzhkPsMINjzGMbYGcga7VX-2Be","timestamp":1630432634550},{"file_id":"12jPQ_wSDDvGyzTBUV-h-pRZ8N-lp9bkW","timestamp":1630425888718},{"file_id":"1ik1ECJq6EbWwGegXLisYoxytv0-7JQcn","timestamp":1630425853722},{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyMhYXJB4Z4yxH5sp9eUWxNF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630814485016,"user_tz":-540,"elapsed":432,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"3cfb45c9-6321-4666-c09a-cdd48f58993c"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Sep  5 04:01:24 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630814502465,"user_tz":-540,"elapsed":17453,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"2eddbe4d-442d-4c43-fddd-e02440b05c6a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1630814506348,"user_tz":-540,"elapsed":3889,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1630814507778,"user_tz":-540,"elapsed":1436,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1630814509745,"user_tz":-540,"elapsed":1970,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1630814526598,"user_tz":-540,"elapsed":16860,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1630814533346,"user_tz":-540,"elapsed":6750,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630814533347,"user_tz":-540,"elapsed":10,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"70fbc7bc-1f60-4f19-c9cf-a68b2ba858b5"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630814533732,"user_tz":-540,"elapsed":390,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0dec5edb-4232-4b88-c17e-f8ab6fb3fb56"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","batch_size = 32\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size,  color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1630814533732,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630825143796,"user_tz":-540,"elapsed":10610070,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"82844637-3399-4bab-db4b-9135b81d4ffd"},"source":["DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 53s 477ms/step - loss: 1.7764 - accuracy: 0.3691 - val_loss: 3.9182 - val_accuracy: 0.1182\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.11823, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 20s 374ms/step - loss: 1.1848 - accuracy: 0.5956 - val_loss: 3.6394 - val_accuracy: 0.0985\n","\n","Epoch 00002: val_accuracy did not improve from 0.11823\n","Epoch 3/500\n","52/52 [==============================] - 19s 373ms/step - loss: 0.9524 - accuracy: 0.6772 - val_loss: 20.4914 - val_accuracy: 0.1010\n","\n","Epoch 00003: val_accuracy did not improve from 0.11823\n","Epoch 4/500\n","52/52 [==============================] - 20s 376ms/step - loss: 0.8047 - accuracy: 0.7320 - val_loss: 15.8243 - val_accuracy: 0.1010\n","\n","Epoch 00004: val_accuracy did not improve from 0.11823\n","Epoch 5/500\n","52/52 [==============================] - 20s 377ms/step - loss: 0.7802 - accuracy: 0.7333 - val_loss: 10.8916 - val_accuracy: 0.1601\n","\n","Epoch 00005: val_accuracy improved from 0.11823 to 0.16010, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.5935 - accuracy: 0.8002 - val_loss: 5.6881 - val_accuracy: 0.2463\n","\n","Epoch 00006: val_accuracy improved from 0.16010 to 0.24631, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.5802 - accuracy: 0.7996 - val_loss: 6.2704 - val_accuracy: 0.2143\n","\n","Epoch 00007: val_accuracy did not improve from 0.24631\n","Epoch 8/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.5438 - accuracy: 0.8155 - val_loss: 5.1194 - val_accuracy: 0.2709\n","\n","Epoch 00008: val_accuracy improved from 0.24631 to 0.27094, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.4448 - accuracy: 0.8447 - val_loss: 1.8771 - val_accuracy: 0.5591\n","\n","Epoch 00009: val_accuracy improved from 0.27094 to 0.55911, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.4525 - accuracy: 0.8484 - val_loss: 1.2452 - val_accuracy: 0.6601\n","\n","Epoch 00010: val_accuracy improved from 0.55911 to 0.66010, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.4523 - accuracy: 0.8441 - val_loss: 2.5109 - val_accuracy: 0.4975\n","\n","Epoch 00011: val_accuracy did not improve from 0.66010\n","Epoch 12/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.3785 - accuracy: 0.8709 - val_loss: 1.4195 - val_accuracy: 0.6700\n","\n","Epoch 00012: val_accuracy improved from 0.66010 to 0.66995, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 13/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.3720 - accuracy: 0.8776 - val_loss: 1.4685 - val_accuracy: 0.6379\n","\n","Epoch 00013: val_accuracy did not improve from 0.66995\n","Epoch 14/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3756 - accuracy: 0.8672 - val_loss: 2.3879 - val_accuracy: 0.5394\n","\n","Epoch 00014: val_accuracy did not improve from 0.66995\n","Epoch 15/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.3515 - accuracy: 0.8745 - val_loss: 5.0082 - val_accuracy: 0.2586\n","\n","Epoch 00015: val_accuracy did not improve from 0.66995\n","Epoch 16/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.3175 - accuracy: 0.8873 - val_loss: 1.0701 - val_accuracy: 0.7389\n","\n","Epoch 00016: val_accuracy improved from 0.66995 to 0.73892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 17/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.3378 - accuracy: 0.8788 - val_loss: 6.1542 - val_accuracy: 0.2562\n","\n","Epoch 00017: val_accuracy did not improve from 0.73892\n","Epoch 18/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.2572 - accuracy: 0.9099 - val_loss: 0.9380 - val_accuracy: 0.7635\n","\n","Epoch 00018: val_accuracy improved from 0.73892 to 0.76355, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 19/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.2556 - accuracy: 0.9172 - val_loss: 0.6472 - val_accuracy: 0.8128\n","\n","Epoch 00019: val_accuracy improved from 0.76355 to 0.81281, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 20/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2602 - accuracy: 0.9093 - val_loss: 0.8137 - val_accuracy: 0.7857\n","\n","Epoch 00020: val_accuracy did not improve from 0.81281\n","Epoch 21/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2152 - accuracy: 0.9275 - val_loss: 0.9358 - val_accuracy: 0.7709\n","\n","Epoch 00021: val_accuracy did not improve from 0.81281\n","Epoch 22/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.2217 - accuracy: 0.9184 - val_loss: 1.1913 - val_accuracy: 0.7044\n","\n","Epoch 00022: val_accuracy did not improve from 0.81281\n","Epoch 23/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.2353 - accuracy: 0.9190 - val_loss: 0.5903 - val_accuracy: 0.8128\n","\n","Epoch 00023: val_accuracy did not improve from 0.81281\n","Epoch 24/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1795 - accuracy: 0.9354 - val_loss: 0.6382 - val_accuracy: 0.7808\n","\n","Epoch 00024: val_accuracy did not improve from 0.81281\n","Epoch 25/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1924 - accuracy: 0.9324 - val_loss: 0.7919 - val_accuracy: 0.7734\n","\n","Epoch 00025: val_accuracy did not improve from 0.81281\n","Epoch 26/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1294 - accuracy: 0.9537 - val_loss: 0.6271 - val_accuracy: 0.8325\n","\n","Epoch 00026: val_accuracy improved from 0.81281 to 0.83251, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 27/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1673 - accuracy: 0.9379 - val_loss: 0.6243 - val_accuracy: 0.8374\n","\n","Epoch 00027: val_accuracy improved from 0.83251 to 0.83744, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 28/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.1850 - accuracy: 0.9336 - val_loss: 0.6207 - val_accuracy: 0.8153\n","\n","Epoch 00028: val_accuracy did not improve from 0.83744\n","Epoch 29/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.1870 - accuracy: 0.9373 - val_loss: 0.8358 - val_accuracy: 0.7980\n","\n","Epoch 00029: val_accuracy did not improve from 0.83744\n","Epoch 30/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1995 - accuracy: 0.9318 - val_loss: 0.4956 - val_accuracy: 0.8695\n","\n","Epoch 00030: val_accuracy improved from 0.83744 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 31/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1806 - accuracy: 0.9361 - val_loss: 0.6578 - val_accuracy: 0.8079\n","\n","Epoch 00031: val_accuracy did not improve from 0.86946\n","Epoch 32/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1662 - accuracy: 0.9464 - val_loss: 0.5539 - val_accuracy: 0.8177\n","\n","Epoch 00032: val_accuracy did not improve from 0.86946\n","Epoch 33/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1830 - accuracy: 0.9348 - val_loss: 1.0254 - val_accuracy: 0.7463\n","\n","Epoch 00033: val_accuracy did not improve from 0.86946\n","Epoch 34/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1843 - accuracy: 0.9373 - val_loss: 0.7344 - val_accuracy: 0.8276\n","\n","Epoch 00034: val_accuracy did not improve from 0.86946\n","Epoch 35/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1189 - accuracy: 0.9586 - val_loss: 0.5926 - val_accuracy: 0.8350\n","\n","Epoch 00035: val_accuracy did not improve from 0.86946\n","Epoch 36/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1245 - accuracy: 0.9641 - val_loss: 0.8057 - val_accuracy: 0.7980\n","\n","Epoch 00036: val_accuracy did not improve from 0.86946\n","Epoch 37/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1155 - accuracy: 0.9635 - val_loss: 0.7545 - val_accuracy: 0.8153\n","\n","Epoch 00037: val_accuracy did not improve from 0.86946\n","Epoch 38/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1234 - accuracy: 0.9586 - val_loss: 0.6737 - val_accuracy: 0.8054\n","\n","Epoch 00038: val_accuracy did not improve from 0.86946\n","Epoch 39/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1125 - accuracy: 0.9604 - val_loss: 0.5075 - val_accuracy: 0.8498\n","\n","Epoch 00039: val_accuracy did not improve from 0.86946\n","Epoch 40/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1963 - accuracy: 0.9403 - val_loss: 0.7409 - val_accuracy: 0.8079\n","\n","Epoch 00040: val_accuracy did not improve from 0.86946\n","Epoch 41/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1412 - accuracy: 0.9501 - val_loss: 0.5822 - val_accuracy: 0.8325\n","\n","Epoch 00041: val_accuracy did not improve from 0.86946\n","Epoch 42/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0938 - accuracy: 0.9702 - val_loss: 0.4990 - val_accuracy: 0.8867\n","\n","Epoch 00042: val_accuracy improved from 0.86946 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 43/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0767 - accuracy: 0.9762 - val_loss: 0.4149 - val_accuracy: 0.8892\n","\n","Epoch 00043: val_accuracy improved from 0.88670 to 0.88916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 44/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0873 - accuracy: 0.9683 - val_loss: 0.4809 - val_accuracy: 0.8670\n","\n","Epoch 00044: val_accuracy did not improve from 0.88916\n","Epoch 45/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0862 - accuracy: 0.9695 - val_loss: 0.5351 - val_accuracy: 0.8424\n","\n","Epoch 00045: val_accuracy did not improve from 0.88916\n","Epoch 46/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0881 - accuracy: 0.9714 - val_loss: 0.4163 - val_accuracy: 0.8941\n","\n","Epoch 00046: val_accuracy improved from 0.88916 to 0.89409, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 47/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0926 - accuracy: 0.9671 - val_loss: 0.9381 - val_accuracy: 0.7882\n","\n","Epoch 00047: val_accuracy did not improve from 0.89409\n","Epoch 48/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1169 - accuracy: 0.9635 - val_loss: 0.6477 - val_accuracy: 0.8522\n","\n","Epoch 00048: val_accuracy did not improve from 0.89409\n","Epoch 49/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0643 - accuracy: 0.9787 - val_loss: 0.6667 - val_accuracy: 0.8670\n","\n","Epoch 00049: val_accuracy did not improve from 0.89409\n","Epoch 50/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0640 - accuracy: 0.9811 - val_loss: 0.5297 - val_accuracy: 0.8842\n","\n","Epoch 00050: val_accuracy did not improve from 0.89409\n","Epoch 51/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0803 - accuracy: 0.9671 - val_loss: 0.4331 - val_accuracy: 0.8941\n","\n","Epoch 00051: val_accuracy did not improve from 0.89409\n","Epoch 52/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0654 - accuracy: 0.9714 - val_loss: 1.0207 - val_accuracy: 0.8079\n","\n","Epoch 00052: val_accuracy did not improve from 0.89409\n","Epoch 53/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0837 - accuracy: 0.9689 - val_loss: 0.9194 - val_accuracy: 0.8103\n","\n","Epoch 00053: val_accuracy did not improve from 0.89409\n","Epoch 54/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1126 - accuracy: 0.9580 - val_loss: 0.7642 - val_accuracy: 0.8325\n","\n","Epoch 00054: val_accuracy did not improve from 0.89409\n","Epoch 55/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0834 - accuracy: 0.9665 - val_loss: 1.1559 - val_accuracy: 0.7438\n","\n","Epoch 00055: val_accuracy did not improve from 0.89409\n","Epoch 56/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1036 - accuracy: 0.9665 - val_loss: 0.9163 - val_accuracy: 0.8079\n","\n","Epoch 00056: val_accuracy did not improve from 0.89409\n","Epoch 57/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0620 - accuracy: 0.9775 - val_loss: 0.5409 - val_accuracy: 0.8621\n","\n","Epoch 00057: val_accuracy did not improve from 0.89409\n","Epoch 58/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0452 - accuracy: 0.9817 - val_loss: 0.6192 - val_accuracy: 0.8498\n","\n","Epoch 00058: val_accuracy did not improve from 0.89409\n","Epoch 59/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0283 - accuracy: 0.9939 - val_loss: 0.5165 - val_accuracy: 0.8719\n","\n","Epoch 00059: val_accuracy did not improve from 0.89409\n","Epoch 60/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0361 - accuracy: 0.9860 - val_loss: 0.4767 - val_accuracy: 0.8892\n","\n","Epoch 00060: val_accuracy did not improve from 0.89409\n","Epoch 61/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0709 - accuracy: 0.9750 - val_loss: 0.9697 - val_accuracy: 0.8128\n","\n","Epoch 00061: val_accuracy did not improve from 0.89409\n","Epoch 62/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0937 - accuracy: 0.9683 - val_loss: 0.9361 - val_accuracy: 0.8227\n","\n","Epoch 00062: val_accuracy did not improve from 0.89409\n","Epoch 63/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0999 - accuracy: 0.9671 - val_loss: 0.8736 - val_accuracy: 0.8153\n","\n","Epoch 00063: val_accuracy did not improve from 0.89409\n","Epoch 64/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0958 - accuracy: 0.9702 - val_loss: 0.8919 - val_accuracy: 0.8227\n","\n","Epoch 00064: val_accuracy did not improve from 0.89409\n","Epoch 65/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1142 - accuracy: 0.9629 - val_loss: 2.2480 - val_accuracy: 0.6478\n","\n","Epoch 00065: val_accuracy did not improve from 0.89409\n","Epoch 66/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0894 - accuracy: 0.9683 - val_loss: 0.4858 - val_accuracy: 0.8670\n","\n","Epoch 00066: val_accuracy did not improve from 0.89409\n","Epoch 67/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0515 - accuracy: 0.9836 - val_loss: 0.4482 - val_accuracy: 0.8892\n","\n","Epoch 00067: val_accuracy did not improve from 0.89409\n","Epoch 68/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 0.5980 - val_accuracy: 0.8596\n","\n","Epoch 00068: val_accuracy did not improve from 0.89409\n","Epoch 69/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0526 - accuracy: 0.9823 - val_loss: 0.5354 - val_accuracy: 0.8892\n","\n","Epoch 00069: val_accuracy did not improve from 0.89409\n","Epoch 70/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0750 - accuracy: 0.9750 - val_loss: 1.3587 - val_accuracy: 0.7833\n","\n","Epoch 00070: val_accuracy did not improve from 0.89409\n","Epoch 71/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0817 - accuracy: 0.9787 - val_loss: 1.2523 - val_accuracy: 0.7414\n","\n","Epoch 00071: val_accuracy did not improve from 0.89409\n","Epoch 72/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0352 - accuracy: 0.9909 - val_loss: 0.6369 - val_accuracy: 0.8744\n","\n","Epoch 00072: val_accuracy did not improve from 0.89409\n","Epoch 73/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0324 - accuracy: 0.9903 - val_loss: 0.4368 - val_accuracy: 0.9015\n","\n","Epoch 00073: val_accuracy improved from 0.89409 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 74/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0487 - accuracy: 0.9836 - val_loss: 0.3878 - val_accuracy: 0.9039\n","\n","Epoch 00074: val_accuracy improved from 0.90148 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 75/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0480 - accuracy: 0.9817 - val_loss: 0.5884 - val_accuracy: 0.8670\n","\n","Epoch 00075: val_accuracy did not improve from 0.90394\n","Epoch 76/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0363 - accuracy: 0.9872 - val_loss: 0.5111 - val_accuracy: 0.8916\n","\n","Epoch 00076: val_accuracy did not improve from 0.90394\n","Epoch 77/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0300 - accuracy: 0.9878 - val_loss: 0.5415 - val_accuracy: 0.8719\n","\n","Epoch 00077: val_accuracy did not improve from 0.90394\n","Epoch 78/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0536 - accuracy: 0.9805 - val_loss: 0.9288 - val_accuracy: 0.8300\n","\n","Epoch 00078: val_accuracy did not improve from 0.90394\n","Epoch 79/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.1242 - accuracy: 0.9580 - val_loss: 1.0905 - val_accuracy: 0.7833\n","\n","Epoch 00079: val_accuracy did not improve from 0.90394\n","Epoch 80/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1337 - accuracy: 0.9507 - val_loss: 0.9076 - val_accuracy: 0.8276\n","\n","Epoch 00080: val_accuracy did not improve from 0.90394\n","Epoch 81/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1033 - accuracy: 0.9653 - val_loss: 0.8114 - val_accuracy: 0.8202\n","\n","Epoch 00081: val_accuracy did not improve from 0.90394\n","Epoch 82/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0791 - accuracy: 0.9744 - val_loss: 0.9461 - val_accuracy: 0.8227\n","\n","Epoch 00082: val_accuracy did not improve from 0.90394\n","Epoch 83/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0415 - accuracy: 0.9854 - val_loss: 0.5327 - val_accuracy: 0.8818\n","\n","Epoch 00083: val_accuracy did not improve from 0.90394\n","Epoch 84/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 0.4135 - val_accuracy: 0.8916\n","\n","Epoch 00084: val_accuracy did not improve from 0.90394\n","Epoch 85/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.5286 - val_accuracy: 0.8892\n","\n","Epoch 00085: val_accuracy did not improve from 0.90394\n","Epoch 86/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0288 - accuracy: 0.9896 - val_loss: 0.4844 - val_accuracy: 0.8719\n","\n","Epoch 00086: val_accuracy did not improve from 0.90394\n","Epoch 87/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0412 - accuracy: 0.9848 - val_loss: 0.4741 - val_accuracy: 0.8719\n","\n","Epoch 00087: val_accuracy did not improve from 0.90394\n","Epoch 88/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0371 - accuracy: 0.9860 - val_loss: 0.6226 - val_accuracy: 0.8645\n","\n","Epoch 00088: val_accuracy did not improve from 0.90394\n","Epoch 89/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 0.6731 - val_accuracy: 0.8498\n","\n","Epoch 00089: val_accuracy did not improve from 0.90394\n","Epoch 90/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0543 - accuracy: 0.9775 - val_loss: 0.6620 - val_accuracy: 0.8719\n","\n","Epoch 00090: val_accuracy did not improve from 0.90394\n","Epoch 91/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0421 - accuracy: 0.9854 - val_loss: 0.7125 - val_accuracy: 0.8547\n","\n","Epoch 00091: val_accuracy did not improve from 0.90394\n","Epoch 92/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0583 - accuracy: 0.9805 - val_loss: 1.2239 - val_accuracy: 0.7882\n","\n","Epoch 00092: val_accuracy did not improve from 0.90394\n","Epoch 93/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0463 - accuracy: 0.9823 - val_loss: 0.6140 - val_accuracy: 0.8719\n","\n","Epoch 00093: val_accuracy did not improve from 0.90394\n","Epoch 94/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0602 - accuracy: 0.9787 - val_loss: 0.6980 - val_accuracy: 0.8522\n","\n","Epoch 00094: val_accuracy did not improve from 0.90394\n","Epoch 95/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0388 - accuracy: 0.9860 - val_loss: 0.6789 - val_accuracy: 0.8547\n","\n","Epoch 00095: val_accuracy did not improve from 0.90394\n","Epoch 96/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0597 - accuracy: 0.9787 - val_loss: 0.8934 - val_accuracy: 0.8522\n","\n","Epoch 00096: val_accuracy did not improve from 0.90394\n","Epoch 97/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0942 - accuracy: 0.9695 - val_loss: 0.4941 - val_accuracy: 0.8990\n","\n","Epoch 00097: val_accuracy did not improve from 0.90394\n","Epoch 98/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 0.6258 - val_accuracy: 0.8645\n","\n","Epoch 00098: val_accuracy did not improve from 0.90394\n","Epoch 99/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0802 - accuracy: 0.9744 - val_loss: 0.6245 - val_accuracy: 0.8695\n","\n","Epoch 00099: val_accuracy did not improve from 0.90394\n","Epoch 100/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0677 - accuracy: 0.9744 - val_loss: 0.5471 - val_accuracy: 0.8842\n","\n","Epoch 00100: val_accuracy did not improve from 0.90394\n","Epoch 101/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0376 - accuracy: 0.9872 - val_loss: 0.5019 - val_accuracy: 0.9039\n","\n","Epoch 00101: val_accuracy did not improve from 0.90394\n","Epoch 102/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0251 - accuracy: 0.9945 - val_loss: 0.4827 - val_accuracy: 0.8842\n","\n","Epoch 00102: val_accuracy did not improve from 0.90394\n","Epoch 103/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0577 - accuracy: 0.9769 - val_loss: 1.5697 - val_accuracy: 0.7315\n","\n","Epoch 00103: val_accuracy did not improve from 0.90394\n","Epoch 104/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.1229 - accuracy: 0.9641 - val_loss: 4.0469 - val_accuracy: 0.5394\n","\n","Epoch 00104: val_accuracy did not improve from 0.90394\n","Epoch 105/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0694 - accuracy: 0.9756 - val_loss: 0.7581 - val_accuracy: 0.8695\n","\n","Epoch 00105: val_accuracy did not improve from 0.90394\n","Epoch 106/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0430 - accuracy: 0.9872 - val_loss: 0.6122 - val_accuracy: 0.8818\n","\n","Epoch 00106: val_accuracy did not improve from 0.90394\n","Epoch 107/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.5050 - val_accuracy: 0.9015\n","\n","Epoch 00107: val_accuracy did not improve from 0.90394\n","Epoch 108/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.4585 - val_accuracy: 0.8916\n","\n","Epoch 00108: val_accuracy did not improve from 0.90394\n","Epoch 109/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0181 - accuracy: 0.9915 - val_loss: 0.4312 - val_accuracy: 0.9064\n","\n","Epoch 00109: val_accuracy improved from 0.90394 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 110/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0115 - accuracy: 0.9982 - val_loss: 0.5152 - val_accuracy: 0.8818\n","\n","Epoch 00110: val_accuracy did not improve from 0.90640\n","Epoch 111/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.5746 - val_accuracy: 0.8571\n","\n","Epoch 00111: val_accuracy did not improve from 0.90640\n","Epoch 112/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.5188 - val_accuracy: 0.8842\n","\n","Epoch 00112: val_accuracy did not improve from 0.90640\n","Epoch 113/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.5194 - val_accuracy: 0.9015\n","\n","Epoch 00113: val_accuracy did not improve from 0.90640\n","Epoch 114/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0095 - accuracy: 0.9988 - val_loss: 0.5102 - val_accuracy: 0.9039\n","\n","Epoch 00114: val_accuracy did not improve from 0.90640\n","Epoch 115/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.6733 - val_accuracy: 0.8793\n","\n","Epoch 00115: val_accuracy did not improve from 0.90640\n","Epoch 116/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.5303 - val_accuracy: 0.8916\n","\n","Epoch 00116: val_accuracy did not improve from 0.90640\n","Epoch 117/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.4321 - val_accuracy: 0.8990\n","\n","Epoch 00117: val_accuracy did not improve from 0.90640\n","Epoch 118/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0161 - accuracy: 0.9933 - val_loss: 0.6017 - val_accuracy: 0.8744\n","\n","Epoch 00118: val_accuracy did not improve from 0.90640\n","Epoch 119/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0855 - accuracy: 0.9695 - val_loss: 1.5027 - val_accuracy: 0.7562\n","\n","Epoch 00119: val_accuracy did not improve from 0.90640\n","Epoch 120/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1033 - accuracy: 0.9616 - val_loss: 0.9534 - val_accuracy: 0.8325\n","\n","Epoch 00120: val_accuracy did not improve from 0.90640\n","Epoch 121/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1120 - accuracy: 0.9647 - val_loss: 1.3528 - val_accuracy: 0.7537\n","\n","Epoch 00121: val_accuracy did not improve from 0.90640\n","Epoch 122/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0551 - accuracy: 0.9756 - val_loss: 0.9951 - val_accuracy: 0.8350\n","\n","Epoch 00122: val_accuracy did not improve from 0.90640\n","Epoch 123/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.5337 - val_accuracy: 0.8990\n","\n","Epoch 00123: val_accuracy did not improve from 0.90640\n","Epoch 124/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 0.5152 - val_accuracy: 0.8916\n","\n","Epoch 00124: val_accuracy did not improve from 0.90640\n","Epoch 125/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.3516 - val_accuracy: 0.9015\n","\n","Epoch 00125: val_accuracy did not improve from 0.90640\n","Epoch 126/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0152 - accuracy: 0.9976 - val_loss: 0.4392 - val_accuracy: 0.9138\n","\n","Epoch 00126: val_accuracy improved from 0.90640 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 127/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.5961 - val_accuracy: 0.8719\n","\n","Epoch 00127: val_accuracy did not improve from 0.91379\n","Epoch 128/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.5664 - val_accuracy: 0.8867\n","\n","Epoch 00128: val_accuracy did not improve from 0.91379\n","Epoch 129/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.5342 - val_accuracy: 0.9015\n","\n","Epoch 00129: val_accuracy did not improve from 0.91379\n","Epoch 130/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0098 - accuracy: 0.9957 - val_loss: 0.5308 - val_accuracy: 0.8842\n","\n","Epoch 00130: val_accuracy did not improve from 0.91379\n","Epoch 131/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.4806 - val_accuracy: 0.8990\n","\n","Epoch 00131: val_accuracy did not improve from 0.91379\n","Epoch 132/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.5280 - val_accuracy: 0.8916\n","\n","Epoch 00132: val_accuracy did not improve from 0.91379\n","Epoch 133/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0309 - accuracy: 0.9909 - val_loss: 0.7898 - val_accuracy: 0.8719\n","\n","Epoch 00133: val_accuracy did not improve from 0.91379\n","Epoch 134/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0431 - accuracy: 0.9884 - val_loss: 0.5652 - val_accuracy: 0.8818\n","\n","Epoch 00134: val_accuracy did not improve from 0.91379\n","Epoch 135/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0661 - accuracy: 0.9799 - val_loss: 0.8576 - val_accuracy: 0.8522\n","\n","Epoch 00135: val_accuracy did not improve from 0.91379\n","Epoch 136/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0767 - accuracy: 0.9756 - val_loss: 0.9646 - val_accuracy: 0.8596\n","\n","Epoch 00136: val_accuracy did not improve from 0.91379\n","Epoch 137/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1216 - accuracy: 0.9629 - val_loss: 0.6869 - val_accuracy: 0.8744\n","\n","Epoch 00137: val_accuracy did not improve from 0.91379\n","Epoch 138/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 0.7704 - val_accuracy: 0.8621\n","\n","Epoch 00138: val_accuracy did not improve from 0.91379\n","Epoch 139/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0445 - accuracy: 0.9860 - val_loss: 0.6177 - val_accuracy: 0.8892\n","\n","Epoch 00139: val_accuracy did not improve from 0.91379\n","Epoch 140/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0470 - accuracy: 0.9884 - val_loss: 0.5870 - val_accuracy: 0.8744\n","\n","Epoch 00140: val_accuracy did not improve from 0.91379\n","Epoch 141/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0351 - accuracy: 0.9878 - val_loss: 0.3966 - val_accuracy: 0.9113\n","\n","Epoch 00141: val_accuracy did not improve from 0.91379\n","Epoch 142/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.4200 - val_accuracy: 0.9039\n","\n","Epoch 00142: val_accuracy did not improve from 0.91379\n","Epoch 143/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.4139 - val_accuracy: 0.9236\n","\n","Epoch 00143: val_accuracy improved from 0.91379 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 144/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.9212\n","\n","Epoch 00144: val_accuracy did not improve from 0.92365\n","Epoch 145/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.4245 - val_accuracy: 0.9138\n","\n","Epoch 00145: val_accuracy did not improve from 0.92365\n","Epoch 146/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4440 - val_accuracy: 0.9138\n","\n","Epoch 00146: val_accuracy did not improve from 0.92365\n","Epoch 147/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0503 - accuracy: 0.9872 - val_loss: 1.6310 - val_accuracy: 0.7759\n","\n","Epoch 00147: val_accuracy did not improve from 0.92365\n","Epoch 148/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0561 - accuracy: 0.9805 - val_loss: 0.4714 - val_accuracy: 0.8966\n","\n","Epoch 00148: val_accuracy did not improve from 0.92365\n","Epoch 149/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0300 - accuracy: 0.9909 - val_loss: 0.4703 - val_accuracy: 0.9113\n","\n","Epoch 00149: val_accuracy did not improve from 0.92365\n","Epoch 150/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0187 - accuracy: 0.9927 - val_loss: 0.7758 - val_accuracy: 0.8473\n","\n","Epoch 00150: val_accuracy did not improve from 0.92365\n","Epoch 151/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.4896 - val_accuracy: 0.9015\n","\n","Epoch 00151: val_accuracy did not improve from 0.92365\n","Epoch 152/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 0.5796 - val_accuracy: 0.8842\n","\n","Epoch 00152: val_accuracy did not improve from 0.92365\n","Epoch 153/500\n","52/52 [==============================] - 20s 394ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.5772 - val_accuracy: 0.8719\n","\n","Epoch 00153: val_accuracy did not improve from 0.92365\n","Epoch 154/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0443 - accuracy: 0.9829 - val_loss: 0.5785 - val_accuracy: 0.8793\n","\n","Epoch 00154: val_accuracy did not improve from 0.92365\n","Epoch 155/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.4524 - val_accuracy: 0.8842\n","\n","Epoch 00155: val_accuracy did not improve from 0.92365\n","Epoch 156/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0305 - accuracy: 0.9921 - val_loss: 0.5327 - val_accuracy: 0.9039\n","\n","Epoch 00156: val_accuracy did not improve from 0.92365\n","Epoch 157/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0178 - accuracy: 0.9933 - val_loss: 0.7273 - val_accuracy: 0.8498\n","\n","Epoch 00157: val_accuracy did not improve from 0.92365\n","Epoch 158/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.4930 - val_accuracy: 0.8941\n","\n","Epoch 00158: val_accuracy did not improve from 0.92365\n","Epoch 159/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.7412 - val_accuracy: 0.8768\n","\n","Epoch 00159: val_accuracy did not improve from 0.92365\n","Epoch 160/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.7051 - val_accuracy: 0.8744\n","\n","Epoch 00160: val_accuracy did not improve from 0.92365\n","Epoch 161/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.4992 - val_accuracy: 0.9015\n","\n","Epoch 00161: val_accuracy did not improve from 0.92365\n","Epoch 162/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.7590 - val_accuracy: 0.8547\n","\n","Epoch 00162: val_accuracy did not improve from 0.92365\n","Epoch 163/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.6683 - val_accuracy: 0.8842\n","\n","Epoch 00163: val_accuracy did not improve from 0.92365\n","Epoch 164/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 0.6069 - val_accuracy: 0.8818\n","\n","Epoch 00164: val_accuracy did not improve from 0.92365\n","Epoch 165/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.4575 - val_accuracy: 0.8966\n","\n","Epoch 00165: val_accuracy did not improve from 0.92365\n","Epoch 166/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.5362 - val_accuracy: 0.8892\n","\n","Epoch 00166: val_accuracy did not improve from 0.92365\n","Epoch 167/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.6485 - val_accuracy: 0.8818\n","\n","Epoch 00167: val_accuracy did not improve from 0.92365\n","Epoch 168/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0250 - accuracy: 0.9909 - val_loss: 0.5703 - val_accuracy: 0.8941\n","\n","Epoch 00168: val_accuracy did not improve from 0.92365\n","Epoch 169/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.8747 - val_accuracy: 0.8768\n","\n","Epoch 00169: val_accuracy did not improve from 0.92365\n","Epoch 170/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0294 - accuracy: 0.9890 - val_loss: 0.7803 - val_accuracy: 0.8842\n","\n","Epoch 00170: val_accuracy did not improve from 0.92365\n","Epoch 171/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0310 - accuracy: 0.9921 - val_loss: 0.6498 - val_accuracy: 0.8793\n","\n","Epoch 00171: val_accuracy did not improve from 0.92365\n","Epoch 172/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0200 - accuracy: 0.9921 - val_loss: 0.6226 - val_accuracy: 0.8966\n","\n","Epoch 00172: val_accuracy did not improve from 0.92365\n","Epoch 173/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0279 - accuracy: 0.9933 - val_loss: 0.6713 - val_accuracy: 0.8645\n","\n","Epoch 00173: val_accuracy did not improve from 0.92365\n","Epoch 174/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.7643 - val_accuracy: 0.8596\n","\n","Epoch 00174: val_accuracy did not improve from 0.92365\n","Epoch 175/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.7404 - val_accuracy: 0.8719\n","\n","Epoch 00175: val_accuracy did not improve from 0.92365\n","Epoch 176/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 0.6168 - val_accuracy: 0.8842\n","\n","Epoch 00176: val_accuracy did not improve from 0.92365\n","Epoch 177/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 0.5714 - val_accuracy: 0.8990\n","\n","Epoch 00177: val_accuracy did not improve from 0.92365\n","Epoch 178/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 0.6522 - val_accuracy: 0.8842\n","\n","Epoch 00178: val_accuracy did not improve from 0.92365\n","Epoch 179/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.6132 - val_accuracy: 0.8867\n","\n","Epoch 00179: val_accuracy did not improve from 0.92365\n","Epoch 180/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.6317 - val_accuracy: 0.8695\n","\n","Epoch 00180: val_accuracy did not improve from 0.92365\n","Epoch 181/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.6041 - val_accuracy: 0.8966\n","\n","Epoch 00181: val_accuracy did not improve from 0.92365\n","Epoch 182/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.6194 - val_accuracy: 0.8966\n","\n","Epoch 00182: val_accuracy did not improve from 0.92365\n","Epoch 183/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.7827 - val_accuracy: 0.8005\n","\n","Epoch 00183: val_accuracy did not improve from 0.92365\n","Epoch 184/500\n","52/52 [==============================] - 20s 396ms/step - loss: 0.0348 - accuracy: 0.9915 - val_loss: 0.8438 - val_accuracy: 0.8621\n","\n","Epoch 00184: val_accuracy did not improve from 0.92365\n","Epoch 185/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0317 - accuracy: 0.9890 - val_loss: 0.8856 - val_accuracy: 0.8325\n","\n","Epoch 00185: val_accuracy did not improve from 0.92365\n","Epoch 186/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 0.5257 - val_accuracy: 0.8990\n","\n","Epoch 00186: val_accuracy did not improve from 0.92365\n","Epoch 187/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.6177 - val_accuracy: 0.8867\n","\n","Epoch 00187: val_accuracy did not improve from 0.92365\n","Epoch 188/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0486 - accuracy: 0.9860 - val_loss: 0.7552 - val_accuracy: 0.8768\n","\n","Epoch 00188: val_accuracy did not improve from 0.92365\n","Epoch 189/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0676 - accuracy: 0.9775 - val_loss: 1.3156 - val_accuracy: 0.7857\n","\n","Epoch 00189: val_accuracy did not improve from 0.92365\n","Epoch 190/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 1.2193 - val_accuracy: 0.8128\n","\n","Epoch 00190: val_accuracy did not improve from 0.92365\n","Epoch 191/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0882 - accuracy: 0.9738 - val_loss: 0.8976 - val_accuracy: 0.8424\n","\n","Epoch 00191: val_accuracy did not improve from 0.92365\n","Epoch 192/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0382 - accuracy: 0.9860 - val_loss: 0.6132 - val_accuracy: 0.8818\n","\n","Epoch 00192: val_accuracy did not improve from 0.92365\n","Epoch 193/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0181 - accuracy: 0.9921 - val_loss: 0.6064 - val_accuracy: 0.8695\n","\n","Epoch 00193: val_accuracy did not improve from 0.92365\n","Epoch 194/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.5417 - val_accuracy: 0.8966\n","\n","Epoch 00194: val_accuracy did not improve from 0.92365\n","Epoch 195/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 0.5762 - val_accuracy: 0.8818\n","\n","Epoch 00195: val_accuracy did not improve from 0.92365\n","Epoch 196/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0356 - accuracy: 0.9872 - val_loss: 0.5216 - val_accuracy: 0.8645\n","\n","Epoch 00196: val_accuracy did not improve from 0.92365\n","Epoch 197/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0412 - accuracy: 0.9884 - val_loss: 0.8411 - val_accuracy: 0.8719\n","\n","Epoch 00197: val_accuracy did not improve from 0.92365\n","Epoch 198/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.4452 - val_accuracy: 0.9163\n","\n","Epoch 00198: val_accuracy did not improve from 0.92365\n","Epoch 199/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.5748 - val_accuracy: 0.8842\n","\n","Epoch 00199: val_accuracy did not improve from 0.92365\n","Epoch 200/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.8751 - val_accuracy: 0.8547\n","\n","Epoch 00200: val_accuracy did not improve from 0.92365\n","Epoch 201/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.4267 - val_accuracy: 0.9212\n","\n","Epoch 00201: val_accuracy did not improve from 0.92365\n","Epoch 202/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4009 - val_accuracy: 0.9138\n","\n","Epoch 00202: val_accuracy did not improve from 0.92365\n","Epoch 203/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.9310\n","\n","Epoch 00203: val_accuracy improved from 0.92365 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 204/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9261\n","\n","Epoch 00204: val_accuracy did not improve from 0.93103\n","Epoch 205/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4481 - val_accuracy: 0.9015\n","\n","Epoch 00205: val_accuracy did not improve from 0.93103\n","Epoch 206/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3989 - val_accuracy: 0.9236\n","\n","Epoch 00206: val_accuracy did not improve from 0.93103\n","Epoch 207/500\n","52/52 [==============================] - 20s 390ms/step - loss: 5.6133e-04 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9310\n","\n","Epoch 00207: val_accuracy did not improve from 0.93103\n","Epoch 208/500\n","52/52 [==============================] - 20s 389ms/step - loss: 6.8775e-04 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.9286\n","\n","Epoch 00208: val_accuracy did not improve from 0.93103\n","Epoch 209/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.3708 - val_accuracy: 0.9261\n","\n","Epoch 00209: val_accuracy did not improve from 0.93103\n","Epoch 210/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.5185 - val_accuracy: 0.9015\n","\n","Epoch 00210: val_accuracy did not improve from 0.93103\n","Epoch 211/500\n","52/52 [==============================] - 21s 405ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.4923 - val_accuracy: 0.9187\n","\n","Epoch 00211: val_accuracy did not improve from 0.93103\n","Epoch 212/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.5221 - val_accuracy: 0.9039\n","\n","Epoch 00212: val_accuracy did not improve from 0.93103\n","Epoch 213/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.4211 - val_accuracy: 0.9138\n","\n","Epoch 00213: val_accuracy did not improve from 0.93103\n","Epoch 214/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.5503 - val_accuracy: 0.8941\n","\n","Epoch 00214: val_accuracy did not improve from 0.93103\n","Epoch 215/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0103 - accuracy: 0.9951 - val_loss: 0.6773 - val_accuracy: 0.8990\n","\n","Epoch 00215: val_accuracy did not improve from 0.93103\n","Epoch 216/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.7695 - val_accuracy: 0.8670\n","\n","Epoch 00216: val_accuracy did not improve from 0.93103\n","Epoch 217/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0327 - accuracy: 0.9903 - val_loss: 0.7181 - val_accuracy: 0.8621\n","\n","Epoch 00217: val_accuracy did not improve from 0.93103\n","Epoch 218/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0425 - accuracy: 0.9817 - val_loss: 0.8532 - val_accuracy: 0.8621\n","\n","Epoch 00218: val_accuracy did not improve from 0.93103\n","Epoch 219/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.9765 - val_accuracy: 0.8374\n","\n","Epoch 00219: val_accuracy did not improve from 0.93103\n","Epoch 220/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0190 - accuracy: 0.9921 - val_loss: 0.5332 - val_accuracy: 0.8941\n","\n","Epoch 00220: val_accuracy did not improve from 0.93103\n","Epoch 221/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0274 - accuracy: 0.9903 - val_loss: 0.5804 - val_accuracy: 0.8916\n","\n","Epoch 00221: val_accuracy did not improve from 0.93103\n","Epoch 222/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.4357 - val_accuracy: 0.9163\n","\n","Epoch 00222: val_accuracy did not improve from 0.93103\n","Epoch 223/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0073 - accuracy: 0.9963 - val_loss: 0.5118 - val_accuracy: 0.9089\n","\n","Epoch 00223: val_accuracy did not improve from 0.93103\n","Epoch 224/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.4518 - val_accuracy: 0.9113\n","\n","Epoch 00224: val_accuracy did not improve from 0.93103\n","Epoch 225/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5276 - val_accuracy: 0.9089\n","\n","Epoch 00225: val_accuracy did not improve from 0.93103\n","Epoch 226/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9187\n","\n","Epoch 00226: val_accuracy did not improve from 0.93103\n","Epoch 227/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0493 - accuracy: 0.9860 - val_loss: 0.9692 - val_accuracy: 0.8399\n","\n","Epoch 00227: val_accuracy did not improve from 0.93103\n","Epoch 228/500\n","52/52 [==============================] - 20s 396ms/step - loss: 0.0553 - accuracy: 0.9842 - val_loss: 0.8455 - val_accuracy: 0.8522\n","\n","Epoch 00228: val_accuracy did not improve from 0.93103\n","Epoch 229/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0664 - accuracy: 0.9817 - val_loss: 0.8673 - val_accuracy: 0.8621\n","\n","Epoch 00229: val_accuracy did not improve from 0.93103\n","Epoch 230/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0305 - accuracy: 0.9890 - val_loss: 0.5171 - val_accuracy: 0.9039\n","\n","Epoch 00230: val_accuracy did not improve from 0.93103\n","Epoch 231/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0234 - accuracy: 0.9903 - val_loss: 0.4829 - val_accuracy: 0.9089\n","\n","Epoch 00231: val_accuracy did not improve from 0.93103\n","Epoch 232/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.5824 - val_accuracy: 0.8818\n","\n","Epoch 00232: val_accuracy did not improve from 0.93103\n","Epoch 233/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0699 - accuracy: 0.9793 - val_loss: 6.8076 - val_accuracy: 0.4557\n","\n","Epoch 00233: val_accuracy did not improve from 0.93103\n","Epoch 234/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0448 - accuracy: 0.9860 - val_loss: 0.6767 - val_accuracy: 0.8695\n","\n","Epoch 00234: val_accuracy did not improve from 0.93103\n","Epoch 235/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.5135 - val_accuracy: 0.8793\n","\n","Epoch 00235: val_accuracy did not improve from 0.93103\n","Epoch 236/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.3318 - val_accuracy: 0.9236\n","\n","Epoch 00236: val_accuracy did not improve from 0.93103\n","Epoch 237/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.5386 - val_accuracy: 0.8941\n","\n","Epoch 00237: val_accuracy did not improve from 0.93103\n","Epoch 238/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.4304 - val_accuracy: 0.9113\n","\n","Epoch 00238: val_accuracy did not improve from 0.93103\n","Epoch 239/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.4833 - val_accuracy: 0.9236\n","\n","Epoch 00239: val_accuracy did not improve from 0.93103\n","Epoch 240/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5417 - val_accuracy: 0.8966\n","\n","Epoch 00240: val_accuracy did not improve from 0.93103\n","Epoch 241/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9089\n","\n","Epoch 00241: val_accuracy did not improve from 0.93103\n","Epoch 242/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.9163\n","\n","Epoch 00242: val_accuracy did not improve from 0.93103\n","Epoch 243/500\n","52/52 [==============================] - 20s 391ms/step - loss: 8.7546e-04 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.9187\n","\n","Epoch 00243: val_accuracy did not improve from 0.93103\n","Epoch 244/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.9286\n","\n","Epoch 00244: val_accuracy did not improve from 0.93103\n","Epoch 245/500\n","52/52 [==============================] - 20s 390ms/step - loss: 7.1144e-04 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9163\n","\n","Epoch 00245: val_accuracy did not improve from 0.93103\n","Epoch 246/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9138\n","\n","Epoch 00246: val_accuracy did not improve from 0.93103\n","Epoch 247/500\n","52/52 [==============================] - 20s 390ms/step - loss: 6.6852e-04 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9187\n","\n","Epoch 00247: val_accuracy did not improve from 0.93103\n","Epoch 248/500\n","52/52 [==============================] - 20s 391ms/step - loss: 5.9799e-04 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9064\n","\n","Epoch 00248: val_accuracy did not improve from 0.93103\n","Epoch 249/500\n","52/52 [==============================] - 20s 390ms/step - loss: 4.3996e-04 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.9064\n","\n","Epoch 00249: val_accuracy did not improve from 0.93103\n","Epoch 250/500\n","52/52 [==============================] - 20s 389ms/step - loss: 7.3346e-04 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9187\n","\n","Epoch 00250: val_accuracy did not improve from 0.93103\n","Epoch 251/500\n","52/52 [==============================] - 20s 391ms/step - loss: 4.5506e-04 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9187\n","\n","Epoch 00251: val_accuracy did not improve from 0.93103\n","Epoch 252/500\n","52/52 [==============================] - 20s 391ms/step - loss: 7.2749e-04 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.9212\n","\n","Epoch 00252: val_accuracy did not improve from 0.93103\n","Epoch 253/500\n","52/52 [==============================] - 20s 391ms/step - loss: 4.1756e-04 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.9187\n","\n","Epoch 00253: val_accuracy did not improve from 0.93103\n","Epoch 254/500\n","52/52 [==============================] - 20s 390ms/step - loss: 1.6273e-04 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9212\n","\n","Epoch 00254: val_accuracy did not improve from 0.93103\n","Epoch 255/500\n","52/52 [==============================] - 20s 392ms/step - loss: 3.4826e-04 - accuracy: 1.0000 - val_loss: 0.3879 - val_accuracy: 0.9310\n","\n","Epoch 00255: val_accuracy did not improve from 0.93103\n","Epoch 256/500\n","52/52 [==============================] - 20s 389ms/step - loss: 2.2543e-04 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.9310\n","\n","Epoch 00256: val_accuracy did not improve from 0.93103\n","Epoch 257/500\n","52/52 [==============================] - 20s 389ms/step - loss: 1.7365e-04 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.9236\n","\n","Epoch 00257: val_accuracy did not improve from 0.93103\n","Epoch 258/500\n","52/52 [==============================] - 20s 391ms/step - loss: 3.0667e-04 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.9187\n","\n","Epoch 00258: val_accuracy did not improve from 0.93103\n","Epoch 259/500\n","52/52 [==============================] - 20s 392ms/step - loss: 2.7062e-04 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.9335\n","\n","Epoch 00259: val_accuracy improved from 0.93103 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 260/500\n","52/52 [==============================] - 20s 390ms/step - loss: 3.6960e-04 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.9212\n","\n","Epoch 00260: val_accuracy did not improve from 0.93350\n","Epoch 261/500\n","52/52 [==============================] - 20s 390ms/step - loss: 2.3828e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9212\n","\n","Epoch 00261: val_accuracy did not improve from 0.93350\n","Epoch 262/500\n","52/52 [==============================] - 20s 391ms/step - loss: 2.7121e-04 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9310\n","\n","Epoch 00262: val_accuracy did not improve from 0.93350\n","Epoch 263/500\n","52/52 [==============================] - 20s 390ms/step - loss: 1.7635e-04 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.9286\n","\n","Epoch 00263: val_accuracy did not improve from 0.93350\n","Epoch 264/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5137 - val_accuracy: 0.9089\n","\n","Epoch 00264: val_accuracy did not improve from 0.93350\n","Epoch 265/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0517 - accuracy: 0.9854 - val_loss: 1.7492 - val_accuracy: 0.7611\n","\n","Epoch 00265: val_accuracy did not improve from 0.93350\n","Epoch 266/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1229 - accuracy: 0.9665 - val_loss: 1.5399 - val_accuracy: 0.8202\n","\n","Epoch 00266: val_accuracy did not improve from 0.93350\n","Epoch 267/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0962 - accuracy: 0.9738 - val_loss: 0.8412 - val_accuracy: 0.8818\n","\n","Epoch 00267: val_accuracy did not improve from 0.93350\n","Epoch 268/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0420 - accuracy: 0.9872 - val_loss: 0.8265 - val_accuracy: 0.8374\n","\n","Epoch 00268: val_accuracy did not improve from 0.93350\n","Epoch 269/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0740 - accuracy: 0.9756 - val_loss: 1.1863 - val_accuracy: 0.7783\n","\n","Epoch 00269: val_accuracy did not improve from 0.93350\n","Epoch 270/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 0.6913 - val_accuracy: 0.8719\n","\n","Epoch 00270: val_accuracy did not improve from 0.93350\n","Epoch 271/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.4817 - val_accuracy: 0.9015\n","\n","Epoch 00271: val_accuracy did not improve from 0.93350\n","Epoch 272/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.4764 - val_accuracy: 0.9039\n","\n","Epoch 00272: val_accuracy did not improve from 0.93350\n","Epoch 273/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.5089 - val_accuracy: 0.8916\n","\n","Epoch 00273: val_accuracy did not improve from 0.93350\n","Epoch 274/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.4615 - val_accuracy: 0.9138\n","\n","Epoch 00274: val_accuracy did not improve from 0.93350\n","Epoch 275/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4887 - val_accuracy: 0.9089\n","\n","Epoch 00275: val_accuracy did not improve from 0.93350\n","Epoch 276/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4230 - val_accuracy: 0.9113\n","\n","Epoch 00276: val_accuracy did not improve from 0.93350\n","Epoch 277/500\n","52/52 [==============================] - 20s 389ms/step - loss: 8.0069e-04 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9261\n","\n","Epoch 00277: val_accuracy did not improve from 0.93350\n","Epoch 278/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4052 - val_accuracy: 0.9138\n","\n","Epoch 00278: val_accuracy did not improve from 0.93350\n","Epoch 279/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 0.4210 - val_accuracy: 0.9113\n","\n","Epoch 00279: val_accuracy did not improve from 0.93350\n","Epoch 280/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4813 - val_accuracy: 0.9064\n","\n","Epoch 00280: val_accuracy did not improve from 0.93350\n","Epoch 281/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.9163\n","\n","Epoch 00281: val_accuracy did not improve from 0.93350\n","Epoch 282/500\n","52/52 [==============================] - 21s 394ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4668 - val_accuracy: 0.9015\n","\n","Epoch 00282: val_accuracy did not improve from 0.93350\n","Epoch 283/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.5263 - val_accuracy: 0.8966\n","\n","Epoch 00283: val_accuracy did not improve from 0.93350\n","Epoch 284/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.7345 - val_accuracy: 0.8842\n","\n","Epoch 00284: val_accuracy did not improve from 0.93350\n","Epoch 285/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.6578 - val_accuracy: 0.8670\n","\n","Epoch 00285: val_accuracy did not improve from 0.93350\n","Epoch 286/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.7883 - val_accuracy: 0.8719\n","\n","Epoch 00286: val_accuracy did not improve from 0.93350\n","Epoch 287/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0242 - accuracy: 0.9896 - val_loss: 0.5356 - val_accuracy: 0.9039\n","\n","Epoch 00287: val_accuracy did not improve from 0.93350\n","Epoch 288/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.5389 - val_accuracy: 0.8768\n","\n","Epoch 00288: val_accuracy did not improve from 0.93350\n","Epoch 289/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.4903 - val_accuracy: 0.8916\n","\n","Epoch 00289: val_accuracy did not improve from 0.93350\n","Epoch 290/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 0.5493 - val_accuracy: 0.9187\n","\n","Epoch 00290: val_accuracy did not improve from 0.93350\n","Epoch 291/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0107 - accuracy: 0.9988 - val_loss: 0.6176 - val_accuracy: 0.9039\n","\n","Epoch 00291: val_accuracy did not improve from 0.93350\n","Epoch 292/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5954 - val_accuracy: 0.9064\n","\n","Epoch 00292: val_accuracy did not improve from 0.93350\n","Epoch 293/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5461 - val_accuracy: 0.9089\n","\n","Epoch 00293: val_accuracy did not improve from 0.93350\n","Epoch 294/500\n","52/52 [==============================] - 20s 389ms/step - loss: 9.7322e-04 - accuracy: 1.0000 - val_loss: 0.6076 - val_accuracy: 0.9015\n","\n","Epoch 00294: val_accuracy did not improve from 0.93350\n","Epoch 295/500\n","52/52 [==============================] - 20s 391ms/step - loss: 8.5930e-04 - accuracy: 0.9994 - val_loss: 0.4585 - val_accuracy: 0.9212\n","\n","Epoch 00295: val_accuracy did not improve from 0.93350\n","Epoch 296/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5639 - val_accuracy: 0.9039\n","\n","Epoch 00296: val_accuracy did not improve from 0.93350\n","Epoch 297/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.8464 - val_accuracy: 0.8571\n","\n","Epoch 00297: val_accuracy did not improve from 0.93350\n","Epoch 298/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0591 - accuracy: 0.9781 - val_loss: 1.2991 - val_accuracy: 0.8498\n","\n","Epoch 00298: val_accuracy did not improve from 0.93350\n","Epoch 299/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0441 - accuracy: 0.9878 - val_loss: 0.8525 - val_accuracy: 0.8768\n","\n","Epoch 00299: val_accuracy did not improve from 0.93350\n","Epoch 300/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.6576 - val_accuracy: 0.8842\n","\n","Epoch 00300: val_accuracy did not improve from 0.93350\n","Epoch 301/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.6198 - val_accuracy: 0.8916\n","\n","Epoch 00301: val_accuracy did not improve from 0.93350\n","Epoch 302/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.5256 - val_accuracy: 0.9039\n","\n","Epoch 00302: val_accuracy did not improve from 0.93350\n","Epoch 303/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5318 - val_accuracy: 0.9163\n","\n","Epoch 00303: val_accuracy did not improve from 0.93350\n","Epoch 304/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4605 - val_accuracy: 0.9187\n","\n","Epoch 00304: val_accuracy did not improve from 0.93350\n","Epoch 305/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.9286\n","\n","Epoch 00305: val_accuracy did not improve from 0.93350\n","Epoch 306/500\n","52/52 [==============================] - 20s 390ms/step - loss: 5.3129e-04 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9212\n","\n","Epoch 00306: val_accuracy did not improve from 0.93350\n","Epoch 307/500\n","52/52 [==============================] - 20s 389ms/step - loss: 8.3111e-04 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.9236\n","\n","Epoch 00307: val_accuracy did not improve from 0.93350\n","Epoch 308/500\n","52/52 [==============================] - 20s 390ms/step - loss: 6.2614e-04 - accuracy: 1.0000 - val_loss: 0.4956 - val_accuracy: 0.9163\n","\n","Epoch 00308: val_accuracy did not improve from 0.93350\n","Epoch 309/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.3843 - val_accuracy: 0.9212\n","\n","Epoch 00309: val_accuracy did not improve from 0.93350\n","Epoch 310/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.3798 - val_accuracy: 0.9286\n","\n","Epoch 00310: val_accuracy did not improve from 0.93350\n","Epoch 311/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.9187\n","\n","Epoch 00311: val_accuracy did not improve from 0.93350\n","Epoch 312/500\n","52/52 [==============================] - 20s 394ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.7234 - val_accuracy: 0.8670\n","\n","Epoch 00312: val_accuracy did not improve from 0.93350\n","Epoch 313/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 1.0103 - val_accuracy: 0.8498\n","\n","Epoch 00313: val_accuracy did not improve from 0.93350\n","Epoch 314/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0315 - accuracy: 0.9933 - val_loss: 0.7333 - val_accuracy: 0.8818\n","\n","Epoch 00314: val_accuracy did not improve from 0.93350\n","Epoch 315/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.4838 - val_accuracy: 0.9113\n","\n","Epoch 00315: val_accuracy did not improve from 0.93350\n","Epoch 316/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 0.6528 - val_accuracy: 0.8793\n","\n","Epoch 00316: val_accuracy did not improve from 0.93350\n","Epoch 317/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0150 - accuracy: 0.9939 - val_loss: 0.6813 - val_accuracy: 0.8793\n","\n","Epoch 00317: val_accuracy did not improve from 0.93350\n","Epoch 318/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.6143 - val_accuracy: 0.9064\n","\n","Epoch 00318: val_accuracy did not improve from 0.93350\n","Epoch 319/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.5055 - val_accuracy: 0.9064\n","\n","Epoch 00319: val_accuracy did not improve from 0.93350\n","Epoch 320/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5205 - val_accuracy: 0.9015\n","\n","Epoch 00320: val_accuracy did not improve from 0.93350\n","Epoch 321/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5715 - val_accuracy: 0.9064\n","\n","Epoch 00321: val_accuracy did not improve from 0.93350\n","Epoch 322/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.6341 - val_accuracy: 0.8867\n","\n","Epoch 00322: val_accuracy did not improve from 0.93350\n","Epoch 323/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.6502 - val_accuracy: 0.8990\n","\n","Epoch 00323: val_accuracy did not improve from 0.93350\n","Epoch 324/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0191 - accuracy: 0.9915 - val_loss: 1.2930 - val_accuracy: 0.8300\n","\n","Epoch 00324: val_accuracy did not improve from 0.93350\n","Epoch 325/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0422 - accuracy: 0.9890 - val_loss: 0.9083 - val_accuracy: 0.8374\n","\n","Epoch 00325: val_accuracy did not improve from 0.93350\n","Epoch 326/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0581 - accuracy: 0.9842 - val_loss: 0.7101 - val_accuracy: 0.8744\n","\n","Epoch 00326: val_accuracy did not improve from 0.93350\n","Epoch 327/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0342 - accuracy: 0.9878 - val_loss: 0.5867 - val_accuracy: 0.8744\n","\n","Epoch 00327: val_accuracy did not improve from 0.93350\n","Epoch 328/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.6141 - val_accuracy: 0.8892\n","\n","Epoch 00328: val_accuracy did not improve from 0.93350\n","Epoch 329/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.5801 - val_accuracy: 0.9039\n","\n","Epoch 00329: val_accuracy did not improve from 0.93350\n","Epoch 330/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.5860 - val_accuracy: 0.9039\n","\n","Epoch 00330: val_accuracy did not improve from 0.93350\n","Epoch 331/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.5972 - val_accuracy: 0.8892\n","\n","Epoch 00331: val_accuracy did not improve from 0.93350\n","Epoch 332/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0294 - accuracy: 0.9890 - val_loss: 0.5945 - val_accuracy: 0.8892\n","\n","Epoch 00332: val_accuracy did not improve from 0.93350\n","Epoch 333/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 0.5532 - val_accuracy: 0.8818\n","\n","Epoch 00333: val_accuracy did not improve from 0.93350\n","Epoch 334/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0105 - accuracy: 0.9957 - val_loss: 0.5156 - val_accuracy: 0.8793\n","\n","Epoch 00334: val_accuracy did not improve from 0.93350\n","Epoch 335/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.5533 - val_accuracy: 0.8916\n","\n","Epoch 00335: val_accuracy did not improve from 0.93350\n","Epoch 336/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.5591 - val_accuracy: 0.8818\n","\n","Epoch 00336: val_accuracy did not improve from 0.93350\n","Epoch 337/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4252 - val_accuracy: 0.9089\n","\n","Epoch 00337: val_accuracy did not improve from 0.93350\n","Epoch 338/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4856 - val_accuracy: 0.9064\n","\n","Epoch 00338: val_accuracy did not improve from 0.93350\n","Epoch 339/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5686 - val_accuracy: 0.9039\n","\n","Epoch 00339: val_accuracy did not improve from 0.93350\n","Epoch 340/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.8966\n","\n","Epoch 00340: val_accuracy did not improve from 0.93350\n","Epoch 341/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4470 - val_accuracy: 0.9212\n","\n","Epoch 00341: val_accuracy did not improve from 0.93350\n","Epoch 342/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4624 - val_accuracy: 0.9138\n","\n","Epoch 00342: val_accuracy did not improve from 0.93350\n","Epoch 343/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4844 - val_accuracy: 0.9163\n","\n","Epoch 00343: val_accuracy did not improve from 0.93350\n","Epoch 344/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.9113\n","\n","Epoch 00344: val_accuracy did not improve from 0.93350\n","Epoch 345/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5875 - val_accuracy: 0.9064\n","\n","Epoch 00345: val_accuracy did not improve from 0.93350\n","Epoch 346/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0071 - accuracy: 0.9951 - val_loss: 0.5043 - val_accuracy: 0.8966\n","\n","Epoch 00346: val_accuracy did not improve from 0.93350\n","Epoch 347/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.6661 - val_accuracy: 0.8744\n","\n","Epoch 00347: val_accuracy did not improve from 0.93350\n","Epoch 348/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5220 - val_accuracy: 0.9089\n","\n","Epoch 00348: val_accuracy did not improve from 0.93350\n","Epoch 349/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.6341 - val_accuracy: 0.9039\n","\n","Epoch 00349: val_accuracy did not improve from 0.93350\n","Epoch 350/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.5938 - val_accuracy: 0.8966\n","\n","Epoch 00350: val_accuracy did not improve from 0.93350\n","Epoch 351/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.6122 - val_accuracy: 0.9089\n","\n","Epoch 00351: val_accuracy did not improve from 0.93350\n","Epoch 352/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.6115 - val_accuracy: 0.8966\n","\n","Epoch 00352: val_accuracy did not improve from 0.93350\n","Epoch 353/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0026 - accuracy: 0.9982 - val_loss: 0.5735 - val_accuracy: 0.8966\n","\n","Epoch 00353: val_accuracy did not improve from 0.93350\n","Epoch 354/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.5992 - val_accuracy: 0.8941\n","\n","Epoch 00354: val_accuracy did not improve from 0.93350\n","Epoch 355/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.8335 - val_accuracy: 0.8645\n","\n","Epoch 00355: val_accuracy did not improve from 0.93350\n","Epoch 356/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5804 - val_accuracy: 0.9089\n","\n","Epoch 00356: val_accuracy did not improve from 0.93350\n","Epoch 357/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.6100 - val_accuracy: 0.8842\n","\n","Epoch 00357: val_accuracy did not improve from 0.93350\n","Epoch 358/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.6322 - val_accuracy: 0.8941\n","\n","Epoch 00358: val_accuracy did not improve from 0.93350\n","Epoch 359/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 1.0172 - val_accuracy: 0.8227\n","\n","Epoch 00359: val_accuracy did not improve from 0.93350\n","Epoch 360/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0439 - accuracy: 0.9872 - val_loss: 0.8984 - val_accuracy: 0.8473\n","\n","Epoch 00360: val_accuracy did not improve from 0.93350\n","Epoch 361/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 0.7900 - val_accuracy: 0.8473\n","\n","Epoch 00361: val_accuracy did not improve from 0.93350\n","Epoch 362/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.5873 - val_accuracy: 0.8744\n","\n","Epoch 00362: val_accuracy did not improve from 0.93350\n","Epoch 363/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.6392 - val_accuracy: 0.8842\n","\n","Epoch 00363: val_accuracy did not improve from 0.93350\n","Epoch 364/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.5662 - val_accuracy: 0.8916\n","\n","Epoch 00364: val_accuracy did not improve from 0.93350\n","Epoch 365/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0123 - accuracy: 0.9988 - val_loss: 0.5243 - val_accuracy: 0.9039\n","\n","Epoch 00365: val_accuracy did not improve from 0.93350\n","Epoch 366/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0454 - accuracy: 0.9854 - val_loss: 0.5330 - val_accuracy: 0.9138\n","\n","Epoch 00366: val_accuracy did not improve from 0.93350\n","Epoch 367/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0229 - accuracy: 0.9945 - val_loss: 0.5697 - val_accuracy: 0.8744\n","\n","Epoch 00367: val_accuracy did not improve from 0.93350\n","Epoch 368/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0293 - accuracy: 0.9933 - val_loss: 0.7861 - val_accuracy: 0.8818\n","\n","Epoch 00368: val_accuracy did not improve from 0.93350\n","Epoch 369/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.4459 - val_accuracy: 0.9039\n","\n","Epoch 00369: val_accuracy did not improve from 0.93350\n","Epoch 370/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5390 - val_accuracy: 0.9064\n","\n","Epoch 00370: val_accuracy did not improve from 0.93350\n","Epoch 371/500\n","52/52 [==============================] - 21s 405ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4333 - val_accuracy: 0.9187\n","\n","Epoch 00371: val_accuracy did not improve from 0.93350\n","Epoch 372/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4270 - val_accuracy: 0.9286\n","\n","Epoch 00372: val_accuracy did not improve from 0.93350\n","Epoch 373/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5521 - val_accuracy: 0.8990\n","\n","Epoch 00373: val_accuracy did not improve from 0.93350\n","Epoch 374/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5449 - val_accuracy: 0.9113\n","\n","Epoch 00374: val_accuracy did not improve from 0.93350\n","Epoch 375/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4627 - val_accuracy: 0.9113\n","\n","Epoch 00375: val_accuracy did not improve from 0.93350\n","Epoch 376/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5055 - val_accuracy: 0.9064\n","\n","Epoch 00376: val_accuracy did not improve from 0.93350\n","Epoch 377/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5199 - val_accuracy: 0.9064\n","\n","Epoch 00377: val_accuracy did not improve from 0.93350\n","Epoch 378/500\n","52/52 [==============================] - 20s 390ms/step - loss: 5.6545e-04 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.9138\n","\n","Epoch 00378: val_accuracy did not improve from 0.93350\n","Epoch 379/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4295 - val_accuracy: 0.9064\n","\n","Epoch 00379: val_accuracy did not improve from 0.93350\n","Epoch 380/500\n","52/52 [==============================] - 20s 390ms/step - loss: 4.9679e-04 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.9163\n","\n","Epoch 00380: val_accuracy did not improve from 0.93350\n","Epoch 381/500\n","52/52 [==============================] - 20s 390ms/step - loss: 7.1576e-04 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.9212\n","\n","Epoch 00381: val_accuracy did not improve from 0.93350\n","Epoch 382/500\n","52/52 [==============================] - 20s 390ms/step - loss: 2.1319e-04 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9163\n","\n","Epoch 00382: val_accuracy did not improve from 0.93350\n","Epoch 383/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5387 - val_accuracy: 0.8892\n","\n","Epoch 00383: val_accuracy did not improve from 0.93350\n","Epoch 384/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4322 - val_accuracy: 0.9138\n","\n","Epoch 00384: val_accuracy did not improve from 0.93350\n","Epoch 385/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4614 - val_accuracy: 0.8916\n","\n","Epoch 00385: val_accuracy did not improve from 0.93350\n","Epoch 386/500\n","52/52 [==============================] - 20s 391ms/step - loss: 5.6601e-04 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.9089\n","\n","Epoch 00386: val_accuracy did not improve from 0.93350\n","Epoch 387/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5167 - val_accuracy: 0.9089\n","\n","Epoch 00387: val_accuracy did not improve from 0.93350\n","Epoch 388/500\n","52/52 [==============================] - 20s 390ms/step - loss: 5.2680e-04 - accuracy: 1.0000 - val_loss: 0.5225 - val_accuracy: 0.9163\n","\n","Epoch 00388: val_accuracy did not improve from 0.93350\n","Epoch 389/500\n","52/52 [==============================] - 20s 390ms/step - loss: 4.6258e-04 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9286\n","\n","Epoch 00389: val_accuracy did not improve from 0.93350\n","Epoch 390/500\n","52/52 [==============================] - 20s 391ms/step - loss: 4.7887e-04 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.9187\n","\n","Epoch 00390: val_accuracy did not improve from 0.93350\n","Epoch 391/500\n","52/52 [==============================] - 20s 390ms/step - loss: 2.3584e-04 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.9212\n","\n","Epoch 00391: val_accuracy did not improve from 0.93350\n","Epoch 392/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0026 - accuracy: 0.9982 - val_loss: 0.4908 - val_accuracy: 0.8990\n","\n","Epoch 00392: val_accuracy did not improve from 0.93350\n","Epoch 393/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.6361 - val_accuracy: 0.8966\n","\n","Epoch 00393: val_accuracy did not improve from 0.93350\n","Epoch 394/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0384 - accuracy: 0.9903 - val_loss: 1.0244 - val_accuracy: 0.8424\n","\n","Epoch 00394: val_accuracy did not improve from 0.93350\n","Epoch 395/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0995 - accuracy: 0.9726 - val_loss: 1.0616 - val_accuracy: 0.8522\n","\n","Epoch 00395: val_accuracy did not improve from 0.93350\n","Epoch 396/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0529 - accuracy: 0.9805 - val_loss: 0.8211 - val_accuracy: 0.8645\n","\n","Epoch 00396: val_accuracy did not improve from 0.93350\n","Epoch 397/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0581 - accuracy: 0.9854 - val_loss: 0.7281 - val_accuracy: 0.8867\n","\n","Epoch 00397: val_accuracy did not improve from 0.93350\n","Epoch 398/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.5755 - val_accuracy: 0.9039\n","\n","Epoch 00398: val_accuracy did not improve from 0.93350\n","Epoch 399/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.5171 - val_accuracy: 0.9187\n","\n","Epoch 00399: val_accuracy did not improve from 0.93350\n","Epoch 400/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5000 - val_accuracy: 0.9113\n","\n","Epoch 00400: val_accuracy did not improve from 0.93350\n","Epoch 401/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.5514 - val_accuracy: 0.9138\n","\n","Epoch 00401: val_accuracy did not improve from 0.93350\n","Epoch 402/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5006 - val_accuracy: 0.9163\n","\n","Epoch 00402: val_accuracy did not improve from 0.93350\n","Epoch 403/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.4466 - val_accuracy: 0.9039\n","\n","Epoch 00403: val_accuracy did not improve from 0.93350\n","Epoch 404/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.5508 - val_accuracy: 0.9163\n","\n","Epoch 00404: val_accuracy did not improve from 0.93350\n","Epoch 405/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.9113\n","\n","Epoch 00405: val_accuracy did not improve from 0.93350\n","Epoch 406/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4228 - val_accuracy: 0.9163\n","\n","Epoch 00406: val_accuracy did not improve from 0.93350\n","Epoch 407/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4398 - val_accuracy: 0.9163\n","\n","Epoch 00407: val_accuracy did not improve from 0.93350\n","Epoch 408/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4404 - val_accuracy: 0.9236\n","\n","Epoch 00408: val_accuracy did not improve from 0.93350\n","Epoch 409/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.9138\n","\n","Epoch 00409: val_accuracy did not improve from 0.93350\n","Epoch 410/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4096 - val_accuracy: 0.9212\n","\n","Epoch 00410: val_accuracy did not improve from 0.93350\n","Epoch 411/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5253 - val_accuracy: 0.9187\n","\n","Epoch 00411: val_accuracy did not improve from 0.93350\n","Epoch 412/500\n","52/52 [==============================] - 20s 391ms/step - loss: 6.6997e-04 - accuracy: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.9261\n","\n","Epoch 00412: val_accuracy did not improve from 0.93350\n","Epoch 413/500\n","52/52 [==============================] - 20s 391ms/step - loss: 4.9471e-04 - accuracy: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.9187\n","\n","Epoch 00413: val_accuracy did not improve from 0.93350\n","Epoch 414/500\n","52/52 [==============================] - 20s 389ms/step - loss: 4.5077e-04 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.9187\n","\n","Epoch 00414: val_accuracy did not improve from 0.93350\n","Epoch 415/500\n","52/52 [==============================] - 20s 389ms/step - loss: 4.4230e-04 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.9187\n","\n","Epoch 00415: val_accuracy did not improve from 0.93350\n","Epoch 416/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4949 - val_accuracy: 0.9261\n","\n","Epoch 00416: val_accuracy did not improve from 0.93350\n","Epoch 417/500\n","52/52 [==============================] - 20s 392ms/step - loss: 7.5003e-04 - accuracy: 1.0000 - val_loss: 0.5851 - val_accuracy: 0.8941\n","\n","Epoch 00417: val_accuracy did not improve from 0.93350\n","Epoch 418/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.6188 - val_accuracy: 0.9212\n","\n","Epoch 00418: val_accuracy did not improve from 0.93350\n","Epoch 419/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0027 - accuracy: 0.9982 - val_loss: 0.7687 - val_accuracy: 0.8793\n","\n","Epoch 00419: val_accuracy did not improve from 0.93350\n","Epoch 420/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.9158 - val_accuracy: 0.8744\n","\n","Epoch 00420: val_accuracy did not improve from 0.93350\n","Epoch 421/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0475 - accuracy: 0.9854 - val_loss: 5.1278 - val_accuracy: 0.4631\n","\n","Epoch 00421: val_accuracy did not improve from 0.93350\n","Epoch 422/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0343 - accuracy: 0.9878 - val_loss: 0.7960 - val_accuracy: 0.8350\n","\n","Epoch 00422: val_accuracy did not improve from 0.93350\n","Epoch 423/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.6859 - val_accuracy: 0.8547\n","\n","Epoch 00423: val_accuracy did not improve from 0.93350\n","Epoch 424/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.6031 - val_accuracy: 0.8842\n","\n","Epoch 00424: val_accuracy did not improve from 0.93350\n","Epoch 425/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0357 - accuracy: 0.9903 - val_loss: 0.8303 - val_accuracy: 0.8571\n","\n","Epoch 00425: val_accuracy did not improve from 0.93350\n","Epoch 426/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 1.2199 - val_accuracy: 0.7931\n","\n","Epoch 00426: val_accuracy did not improve from 0.93350\n","Epoch 427/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.7333 - val_accuracy: 0.9015\n","\n","Epoch 00427: val_accuracy did not improve from 0.93350\n","Epoch 428/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.7597 - val_accuracy: 0.8892\n","\n","Epoch 00428: val_accuracy did not improve from 0.93350\n","Epoch 429/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.6168 - val_accuracy: 0.9015\n","\n","Epoch 00429: val_accuracy did not improve from 0.93350\n","Epoch 430/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5421 - val_accuracy: 0.9113\n","\n","Epoch 00430: val_accuracy did not improve from 0.93350\n","Epoch 431/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4947 - val_accuracy: 0.9187\n","\n","Epoch 00431: val_accuracy did not improve from 0.93350\n","Epoch 432/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4650 - val_accuracy: 0.9212\n","\n","Epoch 00432: val_accuracy did not improve from 0.93350\n","Epoch 433/500\n","52/52 [==============================] - 20s 392ms/step - loss: 6.8634e-04 - accuracy: 1.0000 - val_loss: 0.3983 - val_accuracy: 0.9310\n","\n","Epoch 00433: val_accuracy did not improve from 0.93350\n","Epoch 434/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4899 - val_accuracy: 0.9212\n","\n","Epoch 00434: val_accuracy did not improve from 0.93350\n","Epoch 435/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.3993 - val_accuracy: 0.9384\n","\n","Epoch 00435: val_accuracy improved from 0.93350 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5\n","Epoch 436/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4427 - val_accuracy: 0.9212\n","\n","Epoch 00436: val_accuracy did not improve from 0.93842\n","Epoch 437/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4323 - val_accuracy: 0.9187\n","\n","Epoch 00437: val_accuracy did not improve from 0.93842\n","Epoch 438/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4783 - val_accuracy: 0.9163\n","\n","Epoch 00438: val_accuracy did not improve from 0.93842\n","Epoch 439/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.6329 - val_accuracy: 0.8966\n","\n","Epoch 00439: val_accuracy did not improve from 0.93842\n","Epoch 440/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.5608 - val_accuracy: 0.8966\n","\n","Epoch 00440: val_accuracy did not improve from 0.93842\n","Epoch 441/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.4775 - val_accuracy: 0.9089\n","\n","Epoch 00441: val_accuracy did not improve from 0.93842\n","Epoch 442/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6167 - val_accuracy: 0.8990\n","\n","Epoch 00442: val_accuracy did not improve from 0.93842\n","Epoch 443/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.4904 - val_accuracy: 0.9286\n","\n","Epoch 00443: val_accuracy did not improve from 0.93842\n","Epoch 444/500\n","52/52 [==============================] - 20s 389ms/step - loss: 3.3203e-04 - accuracy: 1.0000 - val_loss: 0.5699 - val_accuracy: 0.9187\n","\n","Epoch 00444: val_accuracy did not improve from 0.93842\n","Epoch 445/500\n","52/52 [==============================] - 20s 390ms/step - loss: 6.0010e-04 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.9212\n","\n","Epoch 00445: val_accuracy did not improve from 0.93842\n","Epoch 446/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 0.5051 - val_accuracy: 0.9089\n","\n","Epoch 00446: val_accuracy did not improve from 0.93842\n","Epoch 447/500\n","52/52 [==============================] - 20s 390ms/step - loss: 6.1455e-04 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.9113\n","\n","Epoch 00447: val_accuracy did not improve from 0.93842\n","Epoch 448/500\n","52/52 [==============================] - 20s 392ms/step - loss: 5.9110e-04 - accuracy: 1.0000 - val_loss: 0.5368 - val_accuracy: 0.9039\n","\n","Epoch 00448: val_accuracy did not improve from 0.93842\n","Epoch 449/500\n","52/52 [==============================] - 20s 390ms/step - loss: 6.4554e-04 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9113\n","\n","Epoch 00449: val_accuracy did not improve from 0.93842\n","Epoch 450/500\n","52/52 [==============================] - 20s 391ms/step - loss: 4.0214e-04 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.9212\n","\n","Epoch 00450: val_accuracy did not improve from 0.93842\n","Epoch 451/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0573 - accuracy: 0.9872 - val_loss: 1.6369 - val_accuracy: 0.7857\n","\n","Epoch 00451: val_accuracy did not improve from 0.93842\n","Epoch 452/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0379 - accuracy: 0.9884 - val_loss: 1.2096 - val_accuracy: 0.8374\n","\n","Epoch 00452: val_accuracy did not improve from 0.93842\n","Epoch 453/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.9292 - val_accuracy: 0.8596\n","\n","Epoch 00453: val_accuracy did not improve from 0.93842\n","Epoch 454/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.4910 - val_accuracy: 0.9236\n","\n","Epoch 00454: val_accuracy did not improve from 0.93842\n","Epoch 455/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.9163\n","\n","Epoch 00455: val_accuracy did not improve from 0.93842\n","Epoch 456/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.4275 - val_accuracy: 0.9089\n","\n","Epoch 00456: val_accuracy did not improve from 0.93842\n","Epoch 457/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0184 - accuracy: 0.9976 - val_loss: 0.4418 - val_accuracy: 0.9138\n","\n","Epoch 00457: val_accuracy did not improve from 0.93842\n","Epoch 458/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.4414 - val_accuracy: 0.9163\n","\n","Epoch 00458: val_accuracy did not improve from 0.93842\n","Epoch 459/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0046 - accuracy: 0.9976 - val_loss: 0.4692 - val_accuracy: 0.9039\n","\n","Epoch 00459: val_accuracy did not improve from 0.93842\n","Epoch 460/500\n","52/52 [==============================] - 20s 386ms/step - loss: 7.5093e-04 - accuracy: 1.0000 - val_loss: 0.3932 - val_accuracy: 0.9335\n","\n","Epoch 00460: val_accuracy did not improve from 0.93842\n","Epoch 461/500\n","52/52 [==============================] - 20s 388ms/step - loss: 5.2050e-04 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.9236\n","\n","Epoch 00461: val_accuracy did not improve from 0.93842\n","Epoch 462/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5526 - val_accuracy: 0.8966\n","\n","Epoch 00462: val_accuracy did not improve from 0.93842\n","Epoch 463/500\n","52/52 [==============================] - 20s 389ms/step - loss: 6.8604e-04 - accuracy: 1.0000 - val_loss: 0.5153 - val_accuracy: 0.9039\n","\n","Epoch 00463: val_accuracy did not improve from 0.93842\n","Epoch 464/500\n","52/52 [==============================] - 20s 391ms/step - loss: 4.4125e-04 - accuracy: 1.0000 - val_loss: 0.5050 - val_accuracy: 0.9113\n","\n","Epoch 00464: val_accuracy did not improve from 0.93842\n","Epoch 465/500\n","52/52 [==============================] - 20s 388ms/step - loss: 5.4044e-04 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.9163\n","\n","Epoch 00465: val_accuracy did not improve from 0.93842\n","Epoch 466/500\n","52/52 [==============================] - 20s 392ms/step - loss: 2.4032e-04 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9187\n","\n","Epoch 00466: val_accuracy did not improve from 0.93842\n","Epoch 467/500\n","52/52 [==============================] - 20s 385ms/step - loss: 3.3139e-04 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.9163\n","\n","Epoch 00467: val_accuracy did not improve from 0.93842\n","Epoch 468/500\n","52/52 [==============================] - 20s 386ms/step - loss: 6.2586e-04 - accuracy: 1.0000 - val_loss: 0.5272 - val_accuracy: 0.9113\n","\n","Epoch 00468: val_accuracy did not improve from 0.93842\n","Epoch 469/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.6662 - val_accuracy: 0.8867\n","\n","Epoch 00469: val_accuracy did not improve from 0.93842\n","Epoch 470/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5724 - val_accuracy: 0.8941\n","\n","Epoch 00470: val_accuracy did not improve from 0.93842\n","Epoch 471/500\n","52/52 [==============================] - 20s 390ms/step - loss: 6.0640e-04 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9064\n","\n","Epoch 00471: val_accuracy did not improve from 0.93842\n","Epoch 472/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5664 - val_accuracy: 0.9015\n","\n","Epoch 00472: val_accuracy did not improve from 0.93842\n","Epoch 473/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5091 - val_accuracy: 0.9064\n","\n","Epoch 00473: val_accuracy did not improve from 0.93842\n","Epoch 474/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5040 - val_accuracy: 0.9113\n","\n","Epoch 00474: val_accuracy did not improve from 0.93842\n","Epoch 475/500\n","52/52 [==============================] - 20s 389ms/step - loss: 4.6713e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.9261\n","\n","Epoch 00475: val_accuracy did not improve from 0.93842\n","Epoch 476/500\n","52/52 [==============================] - 20s 389ms/step - loss: 3.1880e-04 - accuracy: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.9212\n","\n","Epoch 00476: val_accuracy did not improve from 0.93842\n","Epoch 477/500\n","52/52 [==============================] - 20s 391ms/step - loss: 4.4048e-04 - accuracy: 1.0000 - val_loss: 0.5105 - val_accuracy: 0.9138\n","\n","Epoch 00477: val_accuracy did not improve from 0.93842\n","Epoch 478/500\n","52/52 [==============================] - 20s 391ms/step - loss: 2.7036e-04 - accuracy: 1.0000 - val_loss: 0.4792 - val_accuracy: 0.9236\n","\n","Epoch 00478: val_accuracy did not improve from 0.93842\n","Epoch 479/500\n","52/52 [==============================] - 20s 390ms/step - loss: 1.1568e-04 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.9261\n","\n","Epoch 00479: val_accuracy did not improve from 0.93842\n","Epoch 480/500\n","52/52 [==============================] - 20s 391ms/step - loss: 1.0693e-04 - accuracy: 1.0000 - val_loss: 0.5287 - val_accuracy: 0.9138\n","\n","Epoch 00480: val_accuracy did not improve from 0.93842\n","Epoch 481/500\n","52/52 [==============================] - 20s 391ms/step - loss: 2.1651e-04 - accuracy: 1.0000 - val_loss: 0.4943 - val_accuracy: 0.9187\n","\n","Epoch 00481: val_accuracy did not improve from 0.93842\n","Epoch 482/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.9967 - val_accuracy: 0.8177\n","\n","Epoch 00482: val_accuracy did not improve from 0.93842\n","Epoch 483/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0442 - accuracy: 0.9884 - val_loss: 2.1863 - val_accuracy: 0.7167\n","\n","Epoch 00483: val_accuracy did not improve from 0.93842\n","Epoch 484/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0495 - accuracy: 0.9872 - val_loss: 0.7769 - val_accuracy: 0.8916\n","\n","Epoch 00484: val_accuracy did not improve from 0.93842\n","Epoch 485/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 0.5573 - val_accuracy: 0.9064\n","\n","Epoch 00485: val_accuracy did not improve from 0.93842\n","Epoch 486/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.6523 - val_accuracy: 0.8990\n","\n","Epoch 00486: val_accuracy did not improve from 0.93842\n","Epoch 487/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4853 - val_accuracy: 0.9187\n","\n","Epoch 00487: val_accuracy did not improve from 0.93842\n","Epoch 488/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4733 - val_accuracy: 0.9187\n","\n","Epoch 00488: val_accuracy did not improve from 0.93842\n","Epoch 489/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4482 - val_accuracy: 0.9089\n","\n","Epoch 00489: val_accuracy did not improve from 0.93842\n","Epoch 490/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.5771 - val_accuracy: 0.8916\n","\n","Epoch 00490: val_accuracy did not improve from 0.93842\n","Epoch 491/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.4519 - val_accuracy: 0.9089\n","\n","Epoch 00491: val_accuracy did not improve from 0.93842\n","Epoch 492/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.7230 - val_accuracy: 0.8793\n","\n","Epoch 00492: val_accuracy did not improve from 0.93842\n","Epoch 493/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4251 - val_accuracy: 0.9138\n","\n","Epoch 00493: val_accuracy did not improve from 0.93842\n","Epoch 494/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3711 - val_accuracy: 0.9163\n","\n","Epoch 00494: val_accuracy did not improve from 0.93842\n","Epoch 495/500\n","52/52 [==============================] - 20s 390ms/step - loss: 8.6310e-04 - accuracy: 1.0000 - val_loss: 0.4050 - val_accuracy: 0.9236\n","\n","Epoch 00495: val_accuracy did not improve from 0.93842\n","Epoch 496/500\n","52/52 [==============================] - 20s 391ms/step - loss: 4.0773e-04 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.9261\n","\n","Epoch 00496: val_accuracy did not improve from 0.93842\n","Epoch 497/500\n","52/52 [==============================] - 20s 391ms/step - loss: 7.8093e-04 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9360\n","\n","Epoch 00497: val_accuracy did not improve from 0.93842\n","Epoch 498/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5218 - val_accuracy: 0.9064\n","\n","Epoch 00498: val_accuracy did not improve from 0.93842\n","Epoch 499/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4944 - val_accuracy: 0.9163\n","\n","Epoch 00499: val_accuracy did not improve from 0.93842\n","Epoch 500/500\n","52/52 [==============================] - 20s 392ms/step - loss: 6.0983e-04 - accuracy: 1.0000 - val_loss: 0.4591 - val_accuracy: 0.9064\n","\n","Epoch 00500: val_accuracy did not improve from 0.93842\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff9ca257c50>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1630825143798,"user_tz":-540,"elapsed":35,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d7fb4614-693f-45ea-e382-42e7013531ff"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1630825167156,"user_tz":-540,"elapsed":23007,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_2_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1630825167781,"user_tz":-540,"elapsed":631,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630825168154,"user_tz":-540,"elapsed":375,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"9aad3a4d-df2b-4586-a523-b9aff093add1"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630825223233,"user_tz":-540,"elapsed":55081,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d8e57d5d-e870-4590-f003-912286883403"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1630825223602,"user_tz":-540,"elapsed":386,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1630825223603,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1630825224631,"user_tz":-540,"elapsed":1032,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1630825224632,"user_tz":-540,"elapsed":4,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1630825236119,"user_tz":-540,"elapsed":11490,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1630825236121,"user_tz":-540,"elapsed":15,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"47ad0b4b-7289-40a1-ed8c-d93e3908c839"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1630825236565,"user_tz":-540,"elapsed":452,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"1c109403-14fb-4568-e598-901fe2180437"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/BatchSize_32_2_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/BatchSize_32_2_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_f941b44b-2629-4543-b360-1fd914dc3ce0\", \"BatchSize_32_2_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}