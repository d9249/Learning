{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BatchSize_32_3_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1fiIBRDmLIPxB3JYTePwN6q-04wPwAWWN","timestamp":1630778953404},{"file_id":"1vco_0hIBI4evIfDmQDH07Nq5lQJx4Kod","timestamp":1630778923697},{"file_id":"1r3BflNbSZB370f8W3h8PQ5C7NEdbXsJj","timestamp":1630766001155},{"file_id":"1fyedjHIW6-8SHp9ow65apBeykbHxS7oi","timestamp":1630760236494},{"file_id":"1QnPclrYnKmBsAWRJ51Rre-PMBgVa9Cl3","timestamp":1630760206258},{"file_id":"1K7n8RRDie4UKR4IX4z4XcOvrqBpuzCX2","timestamp":1630760179968},{"file_id":"18NxWLqCn6GIqSPUVwANqnaPRMf5i0YEt","timestamp":1630745018066},{"file_id":"1EDWcCOn_TRgBJv_ZMCvsd_r1unwaZzE7","timestamp":1630744974962},{"file_id":"1JA5LGhrhW19laOkeoR8qPDaFWjoqSMzr","timestamp":1630744944221},{"file_id":"1PtmJdXo9AY1M6u1bHhpUHKQ0PGMoOPWZ","timestamp":1630744160988},{"file_id":"1q8viSykqnipNZ_WZtwFtIvj_ZdVFX4vC","timestamp":1630699910907},{"file_id":"1I9ElhTSO4vKs1a5lfr-r0PB1MndT08Nr","timestamp":1630699885519},{"file_id":"14FhoIy7URVKqSDzemys-qARDeDRrpK5D","timestamp":1630676044569},{"file_id":"1SyIKO_pcFSLG_l2VOhA42Qj1Sfgu9xJ5","timestamp":1630675996818},{"file_id":"1bR6CC08w6e4QxXCvbI1hPuVGX4Xr2aS6","timestamp":1630675972365},{"file_id":"1m9zTT841JY7COW8wa0uLUmdxh4mwTROg","timestamp":1630675935279},{"file_id":"1K-M0y6ngoFlaXHKpD1A2obin5bN69rOP","timestamp":1630668564612},{"file_id":"1blwd04nWkDbZIiyYRsoikGHv7D2lN1M7","timestamp":1630663027637},{"file_id":"1OWcGKJuP-Tlx2cd7fYiEF4iFQBw_jTaV","timestamp":1630663004855},{"file_id":"1iIv2T-FeMWjlLKmFmVia0cp_FsKKhP6n","timestamp":1630662692922},{"file_id":"122a3KanHz7tYxI2RkTyd5CDHFsGXxRcD","timestamp":1630652306408},{"file_id":"1rmWpSzQjpXc4LfrgWir30dbjafFqnlzh","timestamp":1630652271928},{"file_id":"1LZU500qd_mzkL28Su52XN_qaRf_yaHht","timestamp":1630646510103},{"file_id":"16JOqSkO3uC_jfclj81AzxJShlzoOMH_B","timestamp":1630613714759},{"file_id":"1eaN7vOK3RK8eeKTKP85BVew6KGSCyH_6","timestamp":1630613687181},{"file_id":"1hFz_giaup3ft5PdsqD18owTBdvEk-9En","timestamp":1630613648785},{"file_id":"15fNytZzTcRPBSdHijbaWLKC0KR8SWzhp","timestamp":1630612864615},{"file_id":"1C8ZNqu7Eb5heuVECStaVKpkxyihLmMkO","timestamp":1630602470521},{"file_id":"1DN9Efw8q90g7HCJ5VhXJYn57jItRUHnr","timestamp":1630602447501},{"file_id":"1ZYwQgfbGvCmGKmNM25goBD839_1yJrul","timestamp":1630602408672},{"file_id":"1_j6u69eFZFR-bV-7FdC_KmRhJ8AI-Ifh","timestamp":1630602370180},{"file_id":"1unjV74CiTTQsLla4T4r8Xawlb_l1_ego","timestamp":1630602293534},{"file_id":"1MSEaTlfMh47aob3-U8yPBQNcpxSO0RC6","timestamp":1630524166308},{"file_id":"1uj1q7VaxDNJ4v0Qnpewz9OO5vDawvGL1","timestamp":1630524142681},{"file_id":"1SXi4BHkyVdQzSXMkx23PhKLYG_cgy9Ne","timestamp":1630524118198},{"file_id":"1ktumtKU2gng5uaTndy4q6ORrf_vm1MB5","timestamp":1630516331014},{"file_id":"19fk2AWJq9X3zvPm2WSAtKO7ljZBPUG5l","timestamp":1630516290119},{"file_id":"1ZOrlvLwHgJ8yqXlMzsUBuNpAS1leHpTw","timestamp":1630516251869},{"file_id":"1lrAXMllo7_hAtAVIxPhE7Xno3vS6aFxT","timestamp":1630515420255},{"file_id":"17dTh7DEVFlzrmiHY5X5ldlDVaanaV9e-","timestamp":1630504418101},{"file_id":"1mqEzmVKqNVAF_0chUK1joEpZK_PYc0_4","timestamp":1630504394196},{"file_id":"1mzp8pt1OJt9CAaiKKe25s3yNAqrGew9R","timestamp":1630504147646},{"file_id":"1FMgk3jn7Q2dQ8p_Hu7bJRfcSBb13Rnvo","timestamp":1630504098889},{"file_id":"1hhBZ077MXyvhUnuxI7SD86ahYiLsCzOG","timestamp":1630500513841},{"file_id":"1EEfvNr8ZybJmpeRuKJ-r7__rhnDnaIM7","timestamp":1630495179853},{"file_id":"17e4zKJb3AvCBXA5MdPqutbvT9s1-CP6A","timestamp":1630484224103},{"file_id":"1ZyJ9--fiBCqqZIpZYXBwYIGMXZPnoPvu","timestamp":1630484173863},{"file_id":"1abkZGMd_cSctW05mIZfosyOPOLNr-LK9","timestamp":1630484131331},{"file_id":"1fKp4Svl_srbEAv_YpXTvSwqDozb4bj9H","timestamp":1630484105207},{"file_id":"1y9kcnOXGhn5ArjCk66kqJCIvgyfTRSkk","timestamp":1630483907553},{"file_id":"1o9CD4AI2tKzcdbdLJ4A6xkENgqmZG7oW","timestamp":1630475138628},{"file_id":"17KUAlMIBl9TgxSnuNYcPwx2zScEUw5W-","timestamp":1630475103015},{"file_id":"12cn5R3wN6-IWoeS68BSqi4LxqlCxJxYt","timestamp":1630464969114},{"file_id":"1KLLc8roFaz12DcPj1WHhuKt9ZBQqi76a","timestamp":1630464678834},{"file_id":"1VZIQ1plZ8Dw3dEaOdrcDkgTjXOv0OcTp","timestamp":1630464589009},{"file_id":"1HiqQpOR-bo5ZelQ96RenE8K365HqE7Lv","timestamp":1630438189228},{"file_id":"1ltViornnQGTXyCDuiYgIGfZy1m46LTW_","timestamp":1630438122242},{"file_id":"12vcTsqE7nuRUe3r9-4k5efqml3ud1k9Z","timestamp":1630438078632},{"file_id":"1EdFynNtlBeF206lf5xA2umzEqK_Pjyi5","timestamp":1630437839162},{"file_id":"1pKJK3lnnRPxX28V0U_A45uk_SI4WlDZr","timestamp":1630432659647},{"file_id":"1soBcJ0zzhkPsMINjzGMbYGcga7VX-2Be","timestamp":1630432634550},{"file_id":"12jPQ_wSDDvGyzTBUV-h-pRZ8N-lp9bkW","timestamp":1630425888718},{"file_id":"1ik1ECJq6EbWwGegXLisYoxytv0-7JQcn","timestamp":1630425853722},{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyP4InWL92IO3Y8IcmiohA5H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630836004750,"user_tz":-540,"elapsed":362,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"fd3c1252-cbf4-4f91-f9cf-5ec33a807c33"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Sep  5 10:00:04 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630836038953,"user_tz":-540,"elapsed":34206,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"9d23c9eb-6694-4ae8-eb34-0492576cbd74"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1630836042800,"user_tz":-540,"elapsed":3597,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1630836043867,"user_tz":-540,"elapsed":1080,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1630836046724,"user_tz":-540,"elapsed":2861,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1630836068320,"user_tz":-540,"elapsed":21598,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1630836076430,"user_tz":-540,"elapsed":8117,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630836076438,"user_tz":-540,"elapsed":16,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"dc7c1987-e358-4bf2-f280-ca4e6d81a556"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630836076807,"user_tz":-540,"elapsed":379,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ab322548-d0be-4a83-9780-f5d0b7c8262d"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","batch_size = 32\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size,  color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1630836076808,"user_tz":-540,"elapsed":8,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630842136941,"user_tz":-540,"elapsed":6060139,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d02eee59-43cf-4c47-ab1c-7d1e94eaf3b2"},"source":["DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 43s 287ms/step - loss: 1.9386 - accuracy: 0.3082 - val_loss: 3.5312 - val_accuracy: 0.0985\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 12s 221ms/step - loss: 1.1759 - accuracy: 0.6005 - val_loss: 4.8083 - val_accuracy: 0.1084\n","\n","Epoch 00002: val_accuracy improved from 0.09852 to 0.10837, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 3/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.9356 - accuracy: 0.6888 - val_loss: 18.5657 - val_accuracy: 0.0640\n","\n","Epoch 00003: val_accuracy did not improve from 0.10837\n","Epoch 4/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.7980 - accuracy: 0.7375 - val_loss: 8.2440 - val_accuracy: 0.1010\n","\n","Epoch 00004: val_accuracy did not improve from 0.10837\n","Epoch 5/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.7353 - accuracy: 0.7613 - val_loss: 8.4901 - val_accuracy: 0.1084\n","\n","Epoch 00005: val_accuracy did not improve from 0.10837\n","Epoch 6/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.6815 - accuracy: 0.7777 - val_loss: 6.0746 - val_accuracy: 0.1724\n","\n","Epoch 00006: val_accuracy improved from 0.10837 to 0.17241, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.6153 - accuracy: 0.7905 - val_loss: 10.1321 - val_accuracy: 0.1379\n","\n","Epoch 00007: val_accuracy did not improve from 0.17241\n","Epoch 8/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.5780 - accuracy: 0.7978 - val_loss: 3.0398 - val_accuracy: 0.3498\n","\n","Epoch 00008: val_accuracy improved from 0.17241 to 0.34975, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.5086 - accuracy: 0.8331 - val_loss: 1.0811 - val_accuracy: 0.6946\n","\n","Epoch 00009: val_accuracy improved from 0.34975 to 0.69458, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.4538 - accuracy: 0.8526 - val_loss: 3.7235 - val_accuracy: 0.3744\n","\n","Epoch 00010: val_accuracy did not improve from 0.69458\n","Epoch 11/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.4604 - accuracy: 0.8398 - val_loss: 0.6897 - val_accuracy: 0.7956\n","\n","Epoch 00011: val_accuracy improved from 0.69458 to 0.79557, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.4223 - accuracy: 0.8538 - val_loss: 0.7140 - val_accuracy: 0.7906\n","\n","Epoch 00012: val_accuracy did not improve from 0.79557\n","Epoch 13/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.3475 - accuracy: 0.8843 - val_loss: 1.0035 - val_accuracy: 0.7291\n","\n","Epoch 00013: val_accuracy did not improve from 0.79557\n","Epoch 14/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.3578 - accuracy: 0.8825 - val_loss: 1.2027 - val_accuracy: 0.6749\n","\n","Epoch 00014: val_accuracy did not improve from 0.79557\n","Epoch 15/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.3295 - accuracy: 0.8831 - val_loss: 0.9616 - val_accuracy: 0.7217\n","\n","Epoch 00015: val_accuracy did not improve from 0.79557\n","Epoch 16/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.2861 - accuracy: 0.9026 - val_loss: 0.5493 - val_accuracy: 0.8128\n","\n","Epoch 00016: val_accuracy improved from 0.79557 to 0.81281, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 17/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.2933 - accuracy: 0.9044 - val_loss: 1.6189 - val_accuracy: 0.6379\n","\n","Epoch 00017: val_accuracy did not improve from 0.81281\n","Epoch 18/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.2853 - accuracy: 0.9026 - val_loss: 0.7024 - val_accuracy: 0.8153\n","\n","Epoch 00018: val_accuracy improved from 0.81281 to 0.81527, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 19/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.3227 - accuracy: 0.8886 - val_loss: 0.5733 - val_accuracy: 0.8202\n","\n","Epoch 00019: val_accuracy improved from 0.81527 to 0.82020, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 20/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.3011 - accuracy: 0.8977 - val_loss: 1.6243 - val_accuracy: 0.6182\n","\n","Epoch 00020: val_accuracy did not improve from 0.82020\n","Epoch 21/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.2444 - accuracy: 0.9239 - val_loss: 1.1149 - val_accuracy: 0.7069\n","\n","Epoch 00021: val_accuracy did not improve from 0.82020\n","Epoch 22/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.2410 - accuracy: 0.9178 - val_loss: 0.7496 - val_accuracy: 0.7611\n","\n","Epoch 00022: val_accuracy did not improve from 0.82020\n","Epoch 23/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.2107 - accuracy: 0.9275 - val_loss: 0.5584 - val_accuracy: 0.8276\n","\n","Epoch 00023: val_accuracy improved from 0.82020 to 0.82759, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 24/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.2155 - accuracy: 0.9287 - val_loss: 0.8821 - val_accuracy: 0.7882\n","\n","Epoch 00024: val_accuracy did not improve from 0.82759\n","Epoch 25/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.1687 - accuracy: 0.9434 - val_loss: 0.5815 - val_accuracy: 0.8276\n","\n","Epoch 00025: val_accuracy did not improve from 0.82759\n","Epoch 26/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1677 - accuracy: 0.9409 - val_loss: 0.4928 - val_accuracy: 0.8374\n","\n","Epoch 00026: val_accuracy improved from 0.82759 to 0.83744, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 27/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1788 - accuracy: 0.9385 - val_loss: 0.7926 - val_accuracy: 0.7956\n","\n","Epoch 00027: val_accuracy did not improve from 0.83744\n","Epoch 28/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1727 - accuracy: 0.9391 - val_loss: 0.7029 - val_accuracy: 0.8350\n","\n","Epoch 00028: val_accuracy did not improve from 0.83744\n","Epoch 29/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.2008 - accuracy: 0.9354 - val_loss: 0.7001 - val_accuracy: 0.7906\n","\n","Epoch 00029: val_accuracy did not improve from 0.83744\n","Epoch 30/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1856 - accuracy: 0.9379 - val_loss: 0.5707 - val_accuracy: 0.8424\n","\n","Epoch 00030: val_accuracy improved from 0.83744 to 0.84236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 31/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1633 - accuracy: 0.9434 - val_loss: 0.8423 - val_accuracy: 0.7660\n","\n","Epoch 00031: val_accuracy did not improve from 0.84236\n","Epoch 32/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1386 - accuracy: 0.9470 - val_loss: 0.7695 - val_accuracy: 0.8079\n","\n","Epoch 00032: val_accuracy did not improve from 0.84236\n","Epoch 33/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1545 - accuracy: 0.9470 - val_loss: 1.1191 - val_accuracy: 0.7217\n","\n","Epoch 00033: val_accuracy did not improve from 0.84236\n","Epoch 34/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1801 - accuracy: 0.9367 - val_loss: 0.8265 - val_accuracy: 0.8128\n","\n","Epoch 00034: val_accuracy did not improve from 0.84236\n","Epoch 35/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1924 - accuracy: 0.9348 - val_loss: 1.1457 - val_accuracy: 0.7414\n","\n","Epoch 00035: val_accuracy did not improve from 0.84236\n","Epoch 36/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1266 - accuracy: 0.9592 - val_loss: 0.4896 - val_accuracy: 0.8621\n","\n","Epoch 00036: val_accuracy improved from 0.84236 to 0.86207, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 37/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1097 - accuracy: 0.9641 - val_loss: 0.4889 - val_accuracy: 0.8571\n","\n","Epoch 00037: val_accuracy did not improve from 0.86207\n","Epoch 38/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1151 - accuracy: 0.9616 - val_loss: 0.7304 - val_accuracy: 0.8276\n","\n","Epoch 00038: val_accuracy did not improve from 0.86207\n","Epoch 39/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1210 - accuracy: 0.9562 - val_loss: 0.3280 - val_accuracy: 0.8867\n","\n","Epoch 00039: val_accuracy improved from 0.86207 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 40/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1254 - accuracy: 0.9598 - val_loss: 0.4104 - val_accuracy: 0.8793\n","\n","Epoch 00040: val_accuracy did not improve from 0.88670\n","Epoch 41/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1172 - accuracy: 0.9598 - val_loss: 0.6255 - val_accuracy: 0.8473\n","\n","Epoch 00041: val_accuracy did not improve from 0.88670\n","Epoch 42/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0765 - accuracy: 0.9714 - val_loss: 0.4062 - val_accuracy: 0.8916\n","\n","Epoch 00042: val_accuracy improved from 0.88670 to 0.89163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 43/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.1292 - accuracy: 0.9549 - val_loss: 0.9429 - val_accuracy: 0.7685\n","\n","Epoch 00043: val_accuracy did not improve from 0.89163\n","Epoch 44/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1108 - accuracy: 0.9616 - val_loss: 0.5683 - val_accuracy: 0.8473\n","\n","Epoch 00044: val_accuracy did not improve from 0.89163\n","Epoch 45/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0887 - accuracy: 0.9708 - val_loss: 0.4468 - val_accuracy: 0.8842\n","\n","Epoch 00045: val_accuracy did not improve from 0.89163\n","Epoch 46/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0638 - accuracy: 0.9744 - val_loss: 1.3331 - val_accuracy: 0.7340\n","\n","Epoch 00046: val_accuracy did not improve from 0.89163\n","Epoch 47/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1288 - accuracy: 0.9531 - val_loss: 0.9149 - val_accuracy: 0.7906\n","\n","Epoch 00047: val_accuracy did not improve from 0.89163\n","Epoch 48/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1144 - accuracy: 0.9598 - val_loss: 1.3620 - val_accuracy: 0.7488\n","\n","Epoch 00048: val_accuracy did not improve from 0.89163\n","Epoch 49/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0616 - accuracy: 0.9793 - val_loss: 0.6563 - val_accuracy: 0.8399\n","\n","Epoch 00049: val_accuracy did not improve from 0.89163\n","Epoch 50/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0751 - accuracy: 0.9720 - val_loss: 0.6321 - val_accuracy: 0.8300\n","\n","Epoch 00050: val_accuracy did not improve from 0.89163\n","Epoch 51/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0913 - accuracy: 0.9683 - val_loss: 0.5661 - val_accuracy: 0.8325\n","\n","Epoch 00051: val_accuracy did not improve from 0.89163\n","Epoch 52/500\n","52/52 [==============================] - 11s 222ms/step - loss: 0.0794 - accuracy: 0.9665 - val_loss: 0.7080 - val_accuracy: 0.8325\n","\n","Epoch 00052: val_accuracy did not improve from 0.89163\n","Epoch 53/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1285 - accuracy: 0.9568 - val_loss: 0.7108 - val_accuracy: 0.8030\n","\n","Epoch 00053: val_accuracy did not improve from 0.89163\n","Epoch 54/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0791 - accuracy: 0.9720 - val_loss: 0.4860 - val_accuracy: 0.8571\n","\n","Epoch 00054: val_accuracy did not improve from 0.89163\n","Epoch 55/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0881 - accuracy: 0.9677 - val_loss: 0.5671 - val_accuracy: 0.8448\n","\n","Epoch 00055: val_accuracy did not improve from 0.89163\n","Epoch 56/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1102 - accuracy: 0.9635 - val_loss: 0.5828 - val_accuracy: 0.8424\n","\n","Epoch 00056: val_accuracy did not improve from 0.89163\n","Epoch 57/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0766 - accuracy: 0.9720 - val_loss: 0.7749 - val_accuracy: 0.8251\n","\n","Epoch 00057: val_accuracy did not improve from 0.89163\n","Epoch 58/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0394 - accuracy: 0.9884 - val_loss: 0.5169 - val_accuracy: 0.8571\n","\n","Epoch 00058: val_accuracy did not improve from 0.89163\n","Epoch 59/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0413 - accuracy: 0.9903 - val_loss: 0.6517 - val_accuracy: 0.8276\n","\n","Epoch 00059: val_accuracy did not improve from 0.89163\n","Epoch 60/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0317 - accuracy: 0.9872 - val_loss: 0.3556 - val_accuracy: 0.8966\n","\n","Epoch 00060: val_accuracy improved from 0.89163 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 61/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.5154 - val_accuracy: 0.8547\n","\n","Epoch 00061: val_accuracy did not improve from 0.89655\n","Epoch 62/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0679 - accuracy: 0.9793 - val_loss: 0.4397 - val_accuracy: 0.8793\n","\n","Epoch 00062: val_accuracy did not improve from 0.89655\n","Epoch 63/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1338 - accuracy: 0.9531 - val_loss: 0.8397 - val_accuracy: 0.8325\n","\n","Epoch 00063: val_accuracy did not improve from 0.89655\n","Epoch 64/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1447 - accuracy: 0.9555 - val_loss: 0.4920 - val_accuracy: 0.8719\n","\n","Epoch 00064: val_accuracy did not improve from 0.89655\n","Epoch 65/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0772 - accuracy: 0.9695 - val_loss: 0.4406 - val_accuracy: 0.8842\n","\n","Epoch 00065: val_accuracy did not improve from 0.89655\n","Epoch 66/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0597 - accuracy: 0.9817 - val_loss: 0.9057 - val_accuracy: 0.7906\n","\n","Epoch 00066: val_accuracy did not improve from 0.89655\n","Epoch 67/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0643 - accuracy: 0.9781 - val_loss: 0.7057 - val_accuracy: 0.8079\n","\n","Epoch 00067: val_accuracy did not improve from 0.89655\n","Epoch 68/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0487 - accuracy: 0.9860 - val_loss: 0.7202 - val_accuracy: 0.7857\n","\n","Epoch 00068: val_accuracy did not improve from 0.89655\n","Epoch 69/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0513 - accuracy: 0.9793 - val_loss: 0.7892 - val_accuracy: 0.7709\n","\n","Epoch 00069: val_accuracy did not improve from 0.89655\n","Epoch 70/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0293 - accuracy: 0.9915 - val_loss: 0.4140 - val_accuracy: 0.8966\n","\n","Epoch 00070: val_accuracy did not improve from 0.89655\n","Epoch 71/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0374 - accuracy: 0.9860 - val_loss: 0.5602 - val_accuracy: 0.8621\n","\n","Epoch 00071: val_accuracy did not improve from 0.89655\n","Epoch 72/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0353 - accuracy: 0.9896 - val_loss: 0.5047 - val_accuracy: 0.8892\n","\n","Epoch 00072: val_accuracy did not improve from 0.89655\n","Epoch 73/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.6786 - val_accuracy: 0.8227\n","\n","Epoch 00073: val_accuracy did not improve from 0.89655\n","Epoch 74/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.5574 - val_accuracy: 0.8621\n","\n","Epoch 00074: val_accuracy did not improve from 0.89655\n","Epoch 75/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.7421 - val_accuracy: 0.8448\n","\n","Epoch 00075: val_accuracy did not improve from 0.89655\n","Epoch 76/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0925 - accuracy: 0.9683 - val_loss: 1.0187 - val_accuracy: 0.8005\n","\n","Epoch 00076: val_accuracy did not improve from 0.89655\n","Epoch 77/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0773 - accuracy: 0.9683 - val_loss: 0.9344 - val_accuracy: 0.8300\n","\n","Epoch 00077: val_accuracy did not improve from 0.89655\n","Epoch 78/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1509 - accuracy: 0.9525 - val_loss: 0.7203 - val_accuracy: 0.8448\n","\n","Epoch 00078: val_accuracy did not improve from 0.89655\n","Epoch 79/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0855 - accuracy: 0.9671 - val_loss: 0.9716 - val_accuracy: 0.8202\n","\n","Epoch 00079: val_accuracy did not improve from 0.89655\n","Epoch 80/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0724 - accuracy: 0.9738 - val_loss: 0.5838 - val_accuracy: 0.8670\n","\n","Epoch 00080: val_accuracy did not improve from 0.89655\n","Epoch 81/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0921 - accuracy: 0.9671 - val_loss: 0.7346 - val_accuracy: 0.8325\n","\n","Epoch 00081: val_accuracy did not improve from 0.89655\n","Epoch 82/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0776 - accuracy: 0.9714 - val_loss: 0.5643 - val_accuracy: 0.8744\n","\n","Epoch 00082: val_accuracy did not improve from 0.89655\n","Epoch 83/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0658 - accuracy: 0.9799 - val_loss: 0.6860 - val_accuracy: 0.8498\n","\n","Epoch 00083: val_accuracy did not improve from 0.89655\n","Epoch 84/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0501 - accuracy: 0.9836 - val_loss: 0.4819 - val_accuracy: 0.8793\n","\n","Epoch 00084: val_accuracy did not improve from 0.89655\n","Epoch 85/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0430 - accuracy: 0.9854 - val_loss: 0.6627 - val_accuracy: 0.8498\n","\n","Epoch 00085: val_accuracy did not improve from 0.89655\n","Epoch 86/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0267 - accuracy: 0.9927 - val_loss: 0.4115 - val_accuracy: 0.8867\n","\n","Epoch 00086: val_accuracy did not improve from 0.89655\n","Epoch 87/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.3796 - val_accuracy: 0.8966\n","\n","Epoch 00087: val_accuracy did not improve from 0.89655\n","Epoch 88/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.4730 - val_accuracy: 0.8695\n","\n","Epoch 00088: val_accuracy did not improve from 0.89655\n","Epoch 89/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.3386 - val_accuracy: 0.9212\n","\n","Epoch 00089: val_accuracy improved from 0.89655 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 90/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.3691 - val_accuracy: 0.8892\n","\n","Epoch 00090: val_accuracy did not improve from 0.92118\n","Epoch 91/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0216 - accuracy: 0.9945 - val_loss: 0.5763 - val_accuracy: 0.8867\n","\n","Epoch 00091: val_accuracy did not improve from 0.92118\n","Epoch 92/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0272 - accuracy: 0.9927 - val_loss: 0.5399 - val_accuracy: 0.8719\n","\n","Epoch 00092: val_accuracy did not improve from 0.92118\n","Epoch 93/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0150 - accuracy: 0.9939 - val_loss: 0.5496 - val_accuracy: 0.8547\n","\n","Epoch 00093: val_accuracy did not improve from 0.92118\n","Epoch 94/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.5246 - val_accuracy: 0.8842\n","\n","Epoch 00094: val_accuracy did not improve from 0.92118\n","Epoch 95/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0421 - accuracy: 0.9829 - val_loss: 0.7880 - val_accuracy: 0.8596\n","\n","Epoch 00095: val_accuracy did not improve from 0.92118\n","Epoch 96/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0512 - accuracy: 0.9836 - val_loss: 1.4170 - val_accuracy: 0.7759\n","\n","Epoch 00096: val_accuracy did not improve from 0.92118\n","Epoch 97/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0469 - accuracy: 0.9860 - val_loss: 0.5736 - val_accuracy: 0.8793\n","\n","Epoch 00097: val_accuracy did not improve from 0.92118\n","Epoch 98/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0668 - accuracy: 0.9750 - val_loss: 0.7950 - val_accuracy: 0.8128\n","\n","Epoch 00098: val_accuracy did not improve from 0.92118\n","Epoch 99/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0754 - accuracy: 0.9793 - val_loss: 2.6865 - val_accuracy: 0.6010\n","\n","Epoch 00099: val_accuracy did not improve from 0.92118\n","Epoch 100/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0901 - accuracy: 0.9720 - val_loss: 0.5492 - val_accuracy: 0.8695\n","\n","Epoch 00100: val_accuracy did not improve from 0.92118\n","Epoch 101/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0695 - accuracy: 0.9793 - val_loss: 0.8176 - val_accuracy: 0.8227\n","\n","Epoch 00101: val_accuracy did not improve from 0.92118\n","Epoch 102/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0328 - accuracy: 0.9909 - val_loss: 0.5539 - val_accuracy: 0.8818\n","\n","Epoch 00102: val_accuracy did not improve from 0.92118\n","Epoch 103/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.6845 - val_accuracy: 0.8571\n","\n","Epoch 00103: val_accuracy did not improve from 0.92118\n","Epoch 104/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.7244 - val_accuracy: 0.8227\n","\n","Epoch 00104: val_accuracy did not improve from 0.92118\n","Epoch 105/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0159 - accuracy: 0.9939 - val_loss: 0.4997 - val_accuracy: 0.8990\n","\n","Epoch 00105: val_accuracy did not improve from 0.92118\n","Epoch 106/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.4676 - val_accuracy: 0.8941\n","\n","Epoch 00106: val_accuracy did not improve from 0.92118\n","Epoch 107/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.6253 - val_accuracy: 0.8892\n","\n","Epoch 00107: val_accuracy did not improve from 0.92118\n","Epoch 108/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.5999 - val_accuracy: 0.8793\n","\n","Epoch 00108: val_accuracy did not improve from 0.92118\n","Epoch 109/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0324 - accuracy: 0.9878 - val_loss: 0.5936 - val_accuracy: 0.8522\n","\n","Epoch 00109: val_accuracy did not improve from 0.92118\n","Epoch 110/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0760 - accuracy: 0.9732 - val_loss: 0.5678 - val_accuracy: 0.8695\n","\n","Epoch 00110: val_accuracy did not improve from 0.92118\n","Epoch 111/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0634 - accuracy: 0.9805 - val_loss: 0.8338 - val_accuracy: 0.8498\n","\n","Epoch 00111: val_accuracy did not improve from 0.92118\n","Epoch 112/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0769 - accuracy: 0.9720 - val_loss: 0.6778 - val_accuracy: 0.8374\n","\n","Epoch 00112: val_accuracy did not improve from 0.92118\n","Epoch 113/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0960 - accuracy: 0.9732 - val_loss: 1.0471 - val_accuracy: 0.7980\n","\n","Epoch 00113: val_accuracy did not improve from 0.92118\n","Epoch 114/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0696 - accuracy: 0.9781 - val_loss: 0.6722 - val_accuracy: 0.8645\n","\n","Epoch 00114: val_accuracy did not improve from 0.92118\n","Epoch 115/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.5099 - val_accuracy: 0.8744\n","\n","Epoch 00115: val_accuracy did not improve from 0.92118\n","Epoch 116/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0436 - accuracy: 0.9842 - val_loss: 1.5753 - val_accuracy: 0.6897\n","\n","Epoch 00116: val_accuracy did not improve from 0.92118\n","Epoch 117/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0300 - accuracy: 0.9890 - val_loss: 0.3202 - val_accuracy: 0.9310\n","\n","Epoch 00117: val_accuracy improved from 0.92118 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 118/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0294 - accuracy: 0.9872 - val_loss: 0.5801 - val_accuracy: 0.8596\n","\n","Epoch 00118: val_accuracy did not improve from 0.93103\n","Epoch 119/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.5551 - val_accuracy: 0.8916\n","\n","Epoch 00119: val_accuracy did not improve from 0.93103\n","Epoch 120/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0333 - accuracy: 0.9909 - val_loss: 0.5574 - val_accuracy: 0.8695\n","\n","Epoch 00120: val_accuracy did not improve from 0.93103\n","Epoch 121/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0393 - accuracy: 0.9836 - val_loss: 0.6145 - val_accuracy: 0.8818\n","\n","Epoch 00121: val_accuracy did not improve from 0.93103\n","Epoch 122/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0499 - accuracy: 0.9829 - val_loss: 0.5799 - val_accuracy: 0.8399\n","\n","Epoch 00122: val_accuracy did not improve from 0.93103\n","Epoch 123/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 0.6134 - val_accuracy: 0.8695\n","\n","Epoch 00123: val_accuracy did not improve from 0.93103\n","Epoch 124/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0194 - accuracy: 0.9927 - val_loss: 0.9816 - val_accuracy: 0.8374\n","\n","Epoch 00124: val_accuracy did not improve from 0.93103\n","Epoch 125/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1057 - accuracy: 0.9708 - val_loss: 1.0750 - val_accuracy: 0.8128\n","\n","Epoch 00125: val_accuracy did not improve from 0.93103\n","Epoch 126/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0626 - accuracy: 0.9805 - val_loss: 1.2946 - val_accuracy: 0.7611\n","\n","Epoch 00126: val_accuracy did not improve from 0.93103\n","Epoch 127/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0472 - accuracy: 0.9848 - val_loss: 0.5257 - val_accuracy: 0.8719\n","\n","Epoch 00127: val_accuracy did not improve from 0.93103\n","Epoch 128/500\n","52/52 [==============================] - 11s 223ms/step - loss: 0.0372 - accuracy: 0.9866 - val_loss: 0.9439 - val_accuracy: 0.7685\n","\n","Epoch 00128: val_accuracy did not improve from 0.93103\n","Epoch 129/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.7176 - val_accuracy: 0.8227\n","\n","Epoch 00129: val_accuracy did not improve from 0.93103\n","Epoch 130/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0175 - accuracy: 0.9927 - val_loss: 0.5665 - val_accuracy: 0.8547\n","\n","Epoch 00130: val_accuracy did not improve from 0.93103\n","Epoch 131/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.5345 - val_accuracy: 0.8892\n","\n","Epoch 00131: val_accuracy did not improve from 0.93103\n","Epoch 132/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.5427 - val_accuracy: 0.8670\n","\n","Epoch 00132: val_accuracy did not improve from 0.93103\n","Epoch 133/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0209 - accuracy: 0.9951 - val_loss: 0.5350 - val_accuracy: 0.8818\n","\n","Epoch 00133: val_accuracy did not improve from 0.93103\n","Epoch 134/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.4957 - val_accuracy: 0.8892\n","\n","Epoch 00134: val_accuracy did not improve from 0.93103\n","Epoch 135/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 1.0019 - val_accuracy: 0.8202\n","\n","Epoch 00135: val_accuracy did not improve from 0.93103\n","Epoch 136/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0341 - accuracy: 0.9878 - val_loss: 0.5351 - val_accuracy: 0.9039\n","\n","Epoch 00136: val_accuracy did not improve from 0.93103\n","Epoch 137/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 0.6205 - val_accuracy: 0.8621\n","\n","Epoch 00137: val_accuracy did not improve from 0.93103\n","Epoch 138/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.4897 - val_accuracy: 0.8916\n","\n","Epoch 00138: val_accuracy did not improve from 0.93103\n","Epoch 139/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.6178 - val_accuracy: 0.8695\n","\n","Epoch 00139: val_accuracy did not improve from 0.93103\n","Epoch 140/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0287 - accuracy: 0.9896 - val_loss: 0.7781 - val_accuracy: 0.8153\n","\n","Epoch 00140: val_accuracy did not improve from 0.93103\n","Epoch 141/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.4538 - val_accuracy: 0.9064\n","\n","Epoch 00141: val_accuracy did not improve from 0.93103\n","Epoch 142/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0115 - accuracy: 0.9939 - val_loss: 0.7116 - val_accuracy: 0.8744\n","\n","Epoch 00142: val_accuracy did not improve from 0.93103\n","Epoch 143/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.6658 - val_accuracy: 0.8744\n","\n","Epoch 00143: val_accuracy did not improve from 0.93103\n","Epoch 144/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.5760 - val_accuracy: 0.8719\n","\n","Epoch 00144: val_accuracy did not improve from 0.93103\n","Epoch 145/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 0.9179 - val_accuracy: 0.8276\n","\n","Epoch 00145: val_accuracy did not improve from 0.93103\n","Epoch 146/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0922 - accuracy: 0.9683 - val_loss: 3.4344 - val_accuracy: 0.5419\n","\n","Epoch 00146: val_accuracy did not improve from 0.93103\n","Epoch 147/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0459 - accuracy: 0.9884 - val_loss: 0.6255 - val_accuracy: 0.8424\n","\n","Epoch 00147: val_accuracy did not improve from 0.93103\n","Epoch 148/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0571 - accuracy: 0.9787 - val_loss: 0.7722 - val_accuracy: 0.8300\n","\n","Epoch 00148: val_accuracy did not improve from 0.93103\n","Epoch 149/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0649 - accuracy: 0.9775 - val_loss: 0.6195 - val_accuracy: 0.8522\n","\n","Epoch 00149: val_accuracy did not improve from 0.93103\n","Epoch 150/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0253 - accuracy: 0.9903 - val_loss: 0.4593 - val_accuracy: 0.8793\n","\n","Epoch 00150: val_accuracy did not improve from 0.93103\n","Epoch 151/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0115 - accuracy: 0.9939 - val_loss: 0.4388 - val_accuracy: 0.8916\n","\n","Epoch 00151: val_accuracy did not improve from 0.93103\n","Epoch 152/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.4534 - val_accuracy: 0.8818\n","\n","Epoch 00152: val_accuracy did not improve from 0.93103\n","Epoch 153/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.5940 - val_accuracy: 0.8498\n","\n","Epoch 00153: val_accuracy did not improve from 0.93103\n","Epoch 154/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.4769 - val_accuracy: 0.9064\n","\n","Epoch 00154: val_accuracy did not improve from 0.93103\n","Epoch 155/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.5739 - val_accuracy: 0.8793\n","\n","Epoch 00155: val_accuracy did not improve from 0.93103\n","Epoch 156/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.6038 - val_accuracy: 0.8744\n","\n","Epoch 00156: val_accuracy did not improve from 0.93103\n","Epoch 157/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.5567 - val_accuracy: 0.8892\n","\n","Epoch 00157: val_accuracy did not improve from 0.93103\n","Epoch 158/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.4243 - val_accuracy: 0.9064\n","\n","Epoch 00158: val_accuracy did not improve from 0.93103\n","Epoch 159/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0104 - accuracy: 0.9957 - val_loss: 0.5211 - val_accuracy: 0.9015\n","\n","Epoch 00159: val_accuracy did not improve from 0.93103\n","Epoch 160/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 1.0587 - val_accuracy: 0.7660\n","\n","Epoch 00160: val_accuracy did not improve from 0.93103\n","Epoch 161/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.8013 - val_accuracy: 0.8005\n","\n","Epoch 00161: val_accuracy did not improve from 0.93103\n","Epoch 162/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.5718 - val_accuracy: 0.8596\n","\n","Epoch 00162: val_accuracy did not improve from 0.93103\n","Epoch 163/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.8501 - val_accuracy: 0.7857\n","\n","Epoch 00163: val_accuracy did not improve from 0.93103\n","Epoch 164/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.5093 - val_accuracy: 0.9039\n","\n","Epoch 00164: val_accuracy did not improve from 0.93103\n","Epoch 165/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.5348 - val_accuracy: 0.8966\n","\n","Epoch 00165: val_accuracy did not improve from 0.93103\n","Epoch 166/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.4785 - val_accuracy: 0.9064\n","\n","Epoch 00166: val_accuracy did not improve from 0.93103\n","Epoch 167/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.5207 - val_accuracy: 0.8966\n","\n","Epoch 00167: val_accuracy did not improve from 0.93103\n","Epoch 168/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.6541 - val_accuracy: 0.8768\n","\n","Epoch 00168: val_accuracy did not improve from 0.93103\n","Epoch 169/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 0.6157 - val_accuracy: 0.8768\n","\n","Epoch 00169: val_accuracy did not improve from 0.93103\n","Epoch 170/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1653 - accuracy: 0.9531 - val_loss: 1.7244 - val_accuracy: 0.7291\n","\n","Epoch 00170: val_accuracy did not improve from 0.93103\n","Epoch 171/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1707 - accuracy: 0.9495 - val_loss: 1.0650 - val_accuracy: 0.8227\n","\n","Epoch 00171: val_accuracy did not improve from 0.93103\n","Epoch 172/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0500 - accuracy: 0.9823 - val_loss: 0.6248 - val_accuracy: 0.8892\n","\n","Epoch 00172: val_accuracy did not improve from 0.93103\n","Epoch 173/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0269 - accuracy: 0.9896 - val_loss: 0.4694 - val_accuracy: 0.9089\n","\n","Epoch 00173: val_accuracy did not improve from 0.93103\n","Epoch 174/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.4838 - val_accuracy: 0.8941\n","\n","Epoch 00174: val_accuracy did not improve from 0.93103\n","Epoch 175/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0119 - accuracy: 0.9988 - val_loss: 0.5197 - val_accuracy: 0.8966\n","\n","Epoch 00175: val_accuracy did not improve from 0.93103\n","Epoch 176/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0777 - accuracy: 0.9799 - val_loss: 0.6276 - val_accuracy: 0.8621\n","\n","Epoch 00176: val_accuracy did not improve from 0.93103\n","Epoch 177/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.5691 - val_accuracy: 0.8744\n","\n","Epoch 00177: val_accuracy did not improve from 0.93103\n","Epoch 178/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 0.5352 - val_accuracy: 0.8744\n","\n","Epoch 00178: val_accuracy did not improve from 0.93103\n","Epoch 179/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0391 - accuracy: 0.9866 - val_loss: 0.8025 - val_accuracy: 0.8621\n","\n","Epoch 00179: val_accuracy did not improve from 0.93103\n","Epoch 180/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0215 - accuracy: 0.9915 - val_loss: 0.4984 - val_accuracy: 0.8818\n","\n","Epoch 00180: val_accuracy did not improve from 0.93103\n","Epoch 181/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.4677 - val_accuracy: 0.9138\n","\n","Epoch 00181: val_accuracy did not improve from 0.93103\n","Epoch 182/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.4459 - val_accuracy: 0.8990\n","\n","Epoch 00182: val_accuracy did not improve from 0.93103\n","Epoch 183/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0097 - accuracy: 0.9957 - val_loss: 0.4840 - val_accuracy: 0.8818\n","\n","Epoch 00183: val_accuracy did not improve from 0.93103\n","Epoch 184/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.8394 - val_accuracy: 0.8177\n","\n","Epoch 00184: val_accuracy did not improve from 0.93103\n","Epoch 185/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.4784 - val_accuracy: 0.9015\n","\n","Epoch 00185: val_accuracy did not improve from 0.93103\n","Epoch 186/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5568 - val_accuracy: 0.8744\n","\n","Epoch 00186: val_accuracy did not improve from 0.93103\n","Epoch 187/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9212\n","\n","Epoch 00187: val_accuracy did not improve from 0.93103\n","Epoch 188/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4351 - val_accuracy: 0.9064\n","\n","Epoch 00188: val_accuracy did not improve from 0.93103\n","Epoch 189/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.6234 - val_accuracy: 0.8818\n","\n","Epoch 00189: val_accuracy did not improve from 0.93103\n","Epoch 190/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0263 - accuracy: 0.9939 - val_loss: 0.7665 - val_accuracy: 0.8374\n","\n","Epoch 00190: val_accuracy did not improve from 0.93103\n","Epoch 191/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0136 - accuracy: 0.9939 - val_loss: 0.5238 - val_accuracy: 0.8916\n","\n","Epoch 00191: val_accuracy did not improve from 0.93103\n","Epoch 192/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.4896 - val_accuracy: 0.8719\n","\n","Epoch 00192: val_accuracy did not improve from 0.93103\n","Epoch 193/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0098 - accuracy: 0.9951 - val_loss: 0.6010 - val_accuracy: 0.8941\n","\n","Epoch 00193: val_accuracy did not improve from 0.93103\n","Epoch 194/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.8966\n","\n","Epoch 00194: val_accuracy did not improve from 0.93103\n","Epoch 195/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9212\n","\n","Epoch 00195: val_accuracy did not improve from 0.93103\n","Epoch 196/500\n","52/52 [==============================] - 12s 221ms/step - loss: 7.7651e-04 - accuracy: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.9236\n","\n","Epoch 00196: val_accuracy did not improve from 0.93103\n","Epoch 197/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4533 - val_accuracy: 0.9163\n","\n","Epoch 00197: val_accuracy did not improve from 0.93103\n","Epoch 198/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4888 - val_accuracy: 0.9113\n","\n","Epoch 00198: val_accuracy did not improve from 0.93103\n","Epoch 199/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0061 - accuracy: 0.9970 - val_loss: 0.6000 - val_accuracy: 0.8744\n","\n","Epoch 00199: val_accuracy did not improve from 0.93103\n","Epoch 200/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0212 - accuracy: 0.9945 - val_loss: 0.5847 - val_accuracy: 0.8842\n","\n","Epoch 00200: val_accuracy did not improve from 0.93103\n","Epoch 201/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5193 - val_accuracy: 0.9113\n","\n","Epoch 00201: val_accuracy did not improve from 0.93103\n","Epoch 202/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.8990\n","\n","Epoch 00202: val_accuracy did not improve from 0.93103\n","Epoch 203/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.9113\n","\n","Epoch 00203: val_accuracy did not improve from 0.93103\n","Epoch 204/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3864 - val_accuracy: 0.9163\n","\n","Epoch 00204: val_accuracy did not improve from 0.93103\n","Epoch 205/500\n","52/52 [==============================] - 11s 219ms/step - loss: 9.3123e-04 - accuracy: 1.0000 - val_loss: 0.3667 - val_accuracy: 0.9212\n","\n","Epoch 00205: val_accuracy did not improve from 0.93103\n","Epoch 206/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4962 - val_accuracy: 0.8916\n","\n","Epoch 00206: val_accuracy did not improve from 0.93103\n","Epoch 207/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4706 - val_accuracy: 0.9089\n","\n","Epoch 00207: val_accuracy did not improve from 0.93103\n","Epoch 208/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.6429 - val_accuracy: 0.8842\n","\n","Epoch 00208: val_accuracy did not improve from 0.93103\n","Epoch 209/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0613 - accuracy: 0.9811 - val_loss: 1.3914 - val_accuracy: 0.7759\n","\n","Epoch 00209: val_accuracy did not improve from 0.93103\n","Epoch 210/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1703 - accuracy: 0.9543 - val_loss: 1.0034 - val_accuracy: 0.8374\n","\n","Epoch 00210: val_accuracy did not improve from 0.93103\n","Epoch 211/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0688 - accuracy: 0.9793 - val_loss: 0.7081 - val_accuracy: 0.8177\n","\n","Epoch 00211: val_accuracy did not improve from 0.93103\n","Epoch 212/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0382 - accuracy: 0.9909 - val_loss: 0.6892 - val_accuracy: 0.8547\n","\n","Epoch 00212: val_accuracy did not improve from 0.93103\n","Epoch 213/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0191 - accuracy: 0.9963 - val_loss: 0.4152 - val_accuracy: 0.8966\n","\n","Epoch 00213: val_accuracy did not improve from 0.93103\n","Epoch 214/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.4794 - val_accuracy: 0.8916\n","\n","Epoch 00214: val_accuracy did not improve from 0.93103\n","Epoch 215/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0145 - accuracy: 0.9939 - val_loss: 0.4362 - val_accuracy: 0.9015\n","\n","Epoch 00215: val_accuracy did not improve from 0.93103\n","Epoch 216/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.4388 - val_accuracy: 0.9089\n","\n","Epoch 00216: val_accuracy did not improve from 0.93103\n","Epoch 217/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.5227 - val_accuracy: 0.8867\n","\n","Epoch 00217: val_accuracy did not improve from 0.93103\n","Epoch 218/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5198 - val_accuracy: 0.8596\n","\n","Epoch 00218: val_accuracy did not improve from 0.93103\n","Epoch 219/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.5513 - val_accuracy: 0.8621\n","\n","Epoch 00219: val_accuracy did not improve from 0.93103\n","Epoch 220/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.3848 - val_accuracy: 0.9236\n","\n","Epoch 00220: val_accuracy did not improve from 0.93103\n","Epoch 221/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.4208 - val_accuracy: 0.9138\n","\n","Epoch 00221: val_accuracy did not improve from 0.93103\n","Epoch 222/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0385 - accuracy: 0.9884 - val_loss: 0.5286 - val_accuracy: 0.8768\n","\n","Epoch 00222: val_accuracy did not improve from 0.93103\n","Epoch 223/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.7678 - val_accuracy: 0.8670\n","\n","Epoch 00223: val_accuracy did not improve from 0.93103\n","Epoch 224/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.5359 - val_accuracy: 0.9039\n","\n","Epoch 00224: val_accuracy did not improve from 0.93103\n","Epoch 225/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.5881 - val_accuracy: 0.8916\n","\n","Epoch 00225: val_accuracy did not improve from 0.93103\n","Epoch 226/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 0.6765 - val_accuracy: 0.8719\n","\n","Epoch 00226: val_accuracy did not improve from 0.93103\n","Epoch 227/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0756 - accuracy: 0.9787 - val_loss: 1.1878 - val_accuracy: 0.8153\n","\n","Epoch 00227: val_accuracy did not improve from 0.93103\n","Epoch 228/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0277 - accuracy: 0.9933 - val_loss: 0.5535 - val_accuracy: 0.8892\n","\n","Epoch 00228: val_accuracy did not improve from 0.93103\n","Epoch 229/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.5287 - val_accuracy: 0.8818\n","\n","Epoch 00229: val_accuracy did not improve from 0.93103\n","Epoch 230/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.4226 - val_accuracy: 0.9039\n","\n","Epoch 00230: val_accuracy did not improve from 0.93103\n","Epoch 231/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.5718 - val_accuracy: 0.8645\n","\n","Epoch 00231: val_accuracy did not improve from 0.93103\n","Epoch 232/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0164 - accuracy: 0.9927 - val_loss: 0.5026 - val_accuracy: 0.8768\n","\n","Epoch 00232: val_accuracy did not improve from 0.93103\n","Epoch 233/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0180 - accuracy: 0.9963 - val_loss: 0.7250 - val_accuracy: 0.8596\n","\n","Epoch 00233: val_accuracy did not improve from 0.93103\n","Epoch 234/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0111 - accuracy: 0.9982 - val_loss: 0.5215 - val_accuracy: 0.8867\n","\n","Epoch 00234: val_accuracy did not improve from 0.93103\n","Epoch 235/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.9015\n","\n","Epoch 00235: val_accuracy did not improve from 0.93103\n","Epoch 236/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3784 - val_accuracy: 0.9236\n","\n","Epoch 00236: val_accuracy did not improve from 0.93103\n","Epoch 237/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4740 - val_accuracy: 0.8966\n","\n","Epoch 00237: val_accuracy did not improve from 0.93103\n","Epoch 238/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.9138\n","\n","Epoch 00238: val_accuracy did not improve from 0.93103\n","Epoch 239/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.4004 - val_accuracy: 0.9261\n","\n","Epoch 00239: val_accuracy did not improve from 0.93103\n","Epoch 240/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5232 - val_accuracy: 0.8966\n","\n","Epoch 00240: val_accuracy did not improve from 0.93103\n","Epoch 241/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.9138\n","\n","Epoch 00241: val_accuracy did not improve from 0.93103\n","Epoch 242/500\n","52/52 [==============================] - 12s 221ms/step - loss: 5.1652e-04 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.9261\n","\n","Epoch 00242: val_accuracy did not improve from 0.93103\n","Epoch 243/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4582 - val_accuracy: 0.9236\n","\n","Epoch 00243: val_accuracy did not improve from 0.93103\n","Epoch 244/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4649 - val_accuracy: 0.9064\n","\n","Epoch 00244: val_accuracy did not improve from 0.93103\n","Epoch 245/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.9113\n","\n","Epoch 00245: val_accuracy did not improve from 0.93103\n","Epoch 246/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.9212\n","\n","Epoch 00246: val_accuracy did not improve from 0.93103\n","Epoch 247/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.9187\n","\n","Epoch 00247: val_accuracy did not improve from 0.93103\n","Epoch 248/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5180 - val_accuracy: 0.8941\n","\n","Epoch 00248: val_accuracy did not improve from 0.93103\n","Epoch 249/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.6111 - val_accuracy: 0.8818\n","\n","Epoch 00249: val_accuracy did not improve from 0.93103\n","Epoch 250/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0445 - accuracy: 0.9896 - val_loss: 0.8709 - val_accuracy: 0.8177\n","\n","Epoch 00250: val_accuracy did not improve from 0.93103\n","Epoch 251/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0915 - accuracy: 0.9708 - val_loss: 1.0170 - val_accuracy: 0.8103\n","\n","Epoch 00251: val_accuracy did not improve from 0.93103\n","Epoch 252/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1118 - accuracy: 0.9641 - val_loss: 0.9320 - val_accuracy: 0.8202\n","\n","Epoch 00252: val_accuracy did not improve from 0.93103\n","Epoch 253/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0393 - accuracy: 0.9829 - val_loss: 0.6278 - val_accuracy: 0.8645\n","\n","Epoch 00253: val_accuracy did not improve from 0.93103\n","Epoch 254/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 1.0573 - val_accuracy: 0.8103\n","\n","Epoch 00254: val_accuracy did not improve from 0.93103\n","Epoch 255/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0131 - accuracy: 0.9939 - val_loss: 0.6219 - val_accuracy: 0.8941\n","\n","Epoch 00255: val_accuracy did not improve from 0.93103\n","Epoch 256/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.5177 - val_accuracy: 0.8966\n","\n","Epoch 00256: val_accuracy did not improve from 0.93103\n","Epoch 257/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.9039\n","\n","Epoch 00257: val_accuracy did not improve from 0.93103\n","Epoch 258/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4166 - val_accuracy: 0.9113\n","\n","Epoch 00258: val_accuracy did not improve from 0.93103\n","Epoch 259/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4627 - val_accuracy: 0.9089\n","\n","Epoch 00259: val_accuracy did not improve from 0.93103\n","Epoch 260/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.4222 - val_accuracy: 0.8867\n","\n","Epoch 00260: val_accuracy did not improve from 0.93103\n","Epoch 261/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.3768 - val_accuracy: 0.9187\n","\n","Epoch 00261: val_accuracy did not improve from 0.93103\n","Epoch 262/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5046 - val_accuracy: 0.8941\n","\n","Epoch 00262: val_accuracy did not improve from 0.93103\n","Epoch 263/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.4755 - val_accuracy: 0.9113\n","\n","Epoch 00263: val_accuracy did not improve from 0.93103\n","Epoch 264/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4734 - val_accuracy: 0.8990\n","\n","Epoch 00264: val_accuracy did not improve from 0.93103\n","Epoch 265/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.9163\n","\n","Epoch 00265: val_accuracy did not improve from 0.93103\n","Epoch 266/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3810 - val_accuracy: 0.9187\n","\n","Epoch 00266: val_accuracy did not improve from 0.93103\n","Epoch 267/500\n","52/52 [==============================] - 12s 220ms/step - loss: 7.8032e-04 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9039\n","\n","Epoch 00267: val_accuracy did not improve from 0.93103\n","Epoch 268/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.7301 - val_accuracy: 0.8325\n","\n","Epoch 00268: val_accuracy did not improve from 0.93103\n","Epoch 269/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0267 - accuracy: 0.9884 - val_loss: 1.1837 - val_accuracy: 0.7808\n","\n","Epoch 00269: val_accuracy did not improve from 0.93103\n","Epoch 270/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0322 - accuracy: 0.9903 - val_loss: 0.5272 - val_accuracy: 0.9138\n","\n","Epoch 00270: val_accuracy did not improve from 0.93103\n","Epoch 271/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.6200 - val_accuracy: 0.8842\n","\n","Epoch 00271: val_accuracy did not improve from 0.93103\n","Epoch 272/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0317 - accuracy: 0.9890 - val_loss: 0.9011 - val_accuracy: 0.8202\n","\n","Epoch 00272: val_accuracy did not improve from 0.93103\n","Epoch 273/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0358 - accuracy: 0.9903 - val_loss: 0.6891 - val_accuracy: 0.8916\n","\n","Epoch 00273: val_accuracy did not improve from 0.93103\n","Epoch 274/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0414 - accuracy: 0.9872 - val_loss: 0.5510 - val_accuracy: 0.8892\n","\n","Epoch 00274: val_accuracy did not improve from 0.93103\n","Epoch 275/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0954 - accuracy: 0.9762 - val_loss: 0.7474 - val_accuracy: 0.8522\n","\n","Epoch 00275: val_accuracy did not improve from 0.93103\n","Epoch 276/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.5432 - val_accuracy: 0.9015\n","\n","Epoch 00276: val_accuracy did not improve from 0.93103\n","Epoch 277/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0159 - accuracy: 0.9939 - val_loss: 0.5619 - val_accuracy: 0.8867\n","\n","Epoch 00277: val_accuracy did not improve from 0.93103\n","Epoch 278/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.3734 - val_accuracy: 0.9261\n","\n","Epoch 00278: val_accuracy did not improve from 0.93103\n","Epoch 279/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4466 - val_accuracy: 0.9015\n","\n","Epoch 00279: val_accuracy did not improve from 0.93103\n","Epoch 280/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4416 - val_accuracy: 0.9064\n","\n","Epoch 00280: val_accuracy did not improve from 0.93103\n","Epoch 281/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4086 - val_accuracy: 0.8990\n","\n","Epoch 00281: val_accuracy did not improve from 0.93103\n","Epoch 282/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5155 - val_accuracy: 0.8941\n","\n","Epoch 00282: val_accuracy did not improve from 0.93103\n","Epoch 283/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.9138\n","\n","Epoch 00283: val_accuracy did not improve from 0.93103\n","Epoch 284/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.4636 - val_accuracy: 0.8990\n","\n","Epoch 00284: val_accuracy did not improve from 0.93103\n","Epoch 285/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.5466 - val_accuracy: 0.8892\n","\n","Epoch 00285: val_accuracy did not improve from 0.93103\n","Epoch 286/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.5234 - val_accuracy: 0.8768\n","\n","Epoch 00286: val_accuracy did not improve from 0.93103\n","Epoch 287/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4130 - val_accuracy: 0.9064\n","\n","Epoch 00287: val_accuracy did not improve from 0.93103\n","Epoch 288/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4064 - val_accuracy: 0.9286\n","\n","Epoch 00288: val_accuracy did not improve from 0.93103\n","Epoch 289/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4239 - val_accuracy: 0.9187\n","\n","Epoch 00289: val_accuracy did not improve from 0.93103\n","Epoch 290/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9187\n","\n","Epoch 00290: val_accuracy did not improve from 0.93103\n","Epoch 291/500\n","52/52 [==============================] - 12s 220ms/step - loss: 7.4954e-04 - accuracy: 1.0000 - val_loss: 0.3840 - val_accuracy: 0.9286\n","\n","Epoch 00291: val_accuracy did not improve from 0.93103\n","Epoch 292/500\n","52/52 [==============================] - 12s 220ms/step - loss: 8.0299e-04 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.9261\n","\n","Epoch 00292: val_accuracy did not improve from 0.93103\n","Epoch 293/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.4820 - val_accuracy: 0.8941\n","\n","Epoch 00293: val_accuracy did not improve from 0.93103\n","Epoch 294/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 1.0469 - val_accuracy: 0.7709\n","\n","Epoch 00294: val_accuracy did not improve from 0.93103\n","Epoch 295/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.5286 - val_accuracy: 0.8744\n","\n","Epoch 00295: val_accuracy did not improve from 0.93103\n","Epoch 296/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.5784 - val_accuracy: 0.8596\n","\n","Epoch 00296: val_accuracy did not improve from 0.93103\n","Epoch 297/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0269 - accuracy: 0.9903 - val_loss: 1.1779 - val_accuracy: 0.7783\n","\n","Epoch 00297: val_accuracy did not improve from 0.93103\n","Epoch 298/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0531 - accuracy: 0.9829 - val_loss: 1.1594 - val_accuracy: 0.7980\n","\n","Epoch 00298: val_accuracy did not improve from 0.93103\n","Epoch 299/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0351 - accuracy: 0.9903 - val_loss: 1.7939 - val_accuracy: 0.7488\n","\n","Epoch 00299: val_accuracy did not improve from 0.93103\n","Epoch 300/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0546 - accuracy: 0.9836 - val_loss: 0.7001 - val_accuracy: 0.8276\n","\n","Epoch 00300: val_accuracy did not improve from 0.93103\n","Epoch 301/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 1.4701 - val_accuracy: 0.6453\n","\n","Epoch 00301: val_accuracy did not improve from 0.93103\n","Epoch 302/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.8591 - val_accuracy: 0.8177\n","\n","Epoch 00302: val_accuracy did not improve from 0.93103\n","Epoch 303/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.4070 - val_accuracy: 0.9064\n","\n","Epoch 00303: val_accuracy did not improve from 0.93103\n","Epoch 304/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4139 - val_accuracy: 0.9113\n","\n","Epoch 00304: val_accuracy did not improve from 0.93103\n","Epoch 305/500\n","52/52 [==============================] - 12s 220ms/step - loss: 9.4542e-04 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9187\n","\n","Epoch 00305: val_accuracy did not improve from 0.93103\n","Epoch 306/500\n","52/52 [==============================] - 12s 221ms/step - loss: 5.7610e-04 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9212\n","\n","Epoch 00306: val_accuracy did not improve from 0.93103\n","Epoch 307/500\n","52/52 [==============================] - 12s 220ms/step - loss: 5.4061e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9261\n","\n","Epoch 00307: val_accuracy did not improve from 0.93103\n","Epoch 308/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9064\n","\n","Epoch 00308: val_accuracy did not improve from 0.93103\n","Epoch 309/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4081 - val_accuracy: 0.9212\n","\n","Epoch 00309: val_accuracy did not improve from 0.93103\n","Epoch 310/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4108 - val_accuracy: 0.9236\n","\n","Epoch 00310: val_accuracy did not improve from 0.93103\n","Epoch 311/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4096 - val_accuracy: 0.9163\n","\n","Epoch 00311: val_accuracy did not improve from 0.93103\n","Epoch 312/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5940 - val_accuracy: 0.8842\n","\n","Epoch 00312: val_accuracy did not improve from 0.93103\n","Epoch 313/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0115 - accuracy: 0.9951 - val_loss: 0.7859 - val_accuracy: 0.8103\n","\n","Epoch 00313: val_accuracy did not improve from 0.93103\n","Epoch 314/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4496 - val_accuracy: 0.8916\n","\n","Epoch 00314: val_accuracy did not improve from 0.93103\n","Epoch 315/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3737 - val_accuracy: 0.9187\n","\n","Epoch 00315: val_accuracy did not improve from 0.93103\n","Epoch 316/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4697 - val_accuracy: 0.8966\n","\n","Epoch 00316: val_accuracy did not improve from 0.93103\n","Epoch 317/500\n","52/52 [==============================] - 12s 221ms/step - loss: 5.4095e-04 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9187\n","\n","Epoch 00317: val_accuracy did not improve from 0.93103\n","Epoch 318/500\n","52/52 [==============================] - 12s 220ms/step - loss: 9.7597e-04 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.9138\n","\n","Epoch 00318: val_accuracy did not improve from 0.93103\n","Epoch 319/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5821 - val_accuracy: 0.8916\n","\n","Epoch 00319: val_accuracy did not improve from 0.93103\n","Epoch 320/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.5732 - val_accuracy: 0.8990\n","\n","Epoch 00320: val_accuracy did not improve from 0.93103\n","Epoch 321/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5644 - val_accuracy: 0.8941\n","\n","Epoch 00321: val_accuracy did not improve from 0.93103\n","Epoch 322/500\n","52/52 [==============================] - 12s 221ms/step - loss: 9.9823e-04 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.8941\n","\n","Epoch 00322: val_accuracy did not improve from 0.93103\n","Epoch 323/500\n","52/52 [==============================] - 12s 222ms/step - loss: 7.0557e-04 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9113\n","\n","Epoch 00323: val_accuracy did not improve from 0.93103\n","Epoch 324/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.5199 - val_accuracy: 0.9113\n","\n","Epoch 00324: val_accuracy did not improve from 0.93103\n","Epoch 325/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.5700 - val_accuracy: 0.8793\n","\n","Epoch 00325: val_accuracy did not improve from 0.93103\n","Epoch 326/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4362 - val_accuracy: 0.9039\n","\n","Epoch 00326: val_accuracy did not improve from 0.93103\n","Epoch 327/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.5295 - val_accuracy: 0.9113\n","\n","Epoch 00327: val_accuracy did not improve from 0.93103\n","Epoch 328/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.6291 - val_accuracy: 0.8793\n","\n","Epoch 00328: val_accuracy did not improve from 0.93103\n","Epoch 329/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.7951 - val_accuracy: 0.8177\n","\n","Epoch 00329: val_accuracy did not improve from 0.93103\n","Epoch 330/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.5791 - val_accuracy: 0.8916\n","\n","Epoch 00330: val_accuracy did not improve from 0.93103\n","Epoch 331/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.6839 - val_accuracy: 0.8695\n","\n","Epoch 00331: val_accuracy did not improve from 0.93103\n","Epoch 332/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.5966 - val_accuracy: 0.8990\n","\n","Epoch 00332: val_accuracy did not improve from 0.93103\n","Epoch 333/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 1.0434 - val_accuracy: 0.8522\n","\n","Epoch 00333: val_accuracy did not improve from 0.93103\n","Epoch 334/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 0.9216 - val_accuracy: 0.8473\n","\n","Epoch 00334: val_accuracy did not improve from 0.93103\n","Epoch 335/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0791 - accuracy: 0.9775 - val_loss: 1.3771 - val_accuracy: 0.7315\n","\n","Epoch 00335: val_accuracy did not improve from 0.93103\n","Epoch 336/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0485 - accuracy: 0.9836 - val_loss: 1.8225 - val_accuracy: 0.6773\n","\n","Epoch 00336: val_accuracy did not improve from 0.93103\n","Epoch 337/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.8317 - val_accuracy: 0.8596\n","\n","Epoch 00337: val_accuracy did not improve from 0.93103\n","Epoch 338/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0473 - accuracy: 0.9836 - val_loss: 0.5679 - val_accuracy: 0.8842\n","\n","Epoch 00338: val_accuracy did not improve from 0.93103\n","Epoch 339/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.5999 - val_accuracy: 0.8719\n","\n","Epoch 00339: val_accuracy did not improve from 0.93103\n","Epoch 340/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.5756 - val_accuracy: 0.8892\n","\n","Epoch 00340: val_accuracy did not improve from 0.93103\n","Epoch 341/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.5466 - val_accuracy: 0.8990\n","\n","Epoch 00341: val_accuracy did not improve from 0.93103\n","Epoch 342/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.4785 - val_accuracy: 0.9039\n","\n","Epoch 00342: val_accuracy did not improve from 0.93103\n","Epoch 343/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5462 - val_accuracy: 0.8645\n","\n","Epoch 00343: val_accuracy did not improve from 0.93103\n","Epoch 344/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.8990\n","\n","Epoch 00344: val_accuracy did not improve from 0.93103\n","Epoch 345/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.9039\n","\n","Epoch 00345: val_accuracy did not improve from 0.93103\n","Epoch 346/500\n","52/52 [==============================] - 12s 223ms/step - loss: 3.8970e-04 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.9089\n","\n","Epoch 00346: val_accuracy did not improve from 0.93103\n","Epoch 347/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5389 - val_accuracy: 0.9015\n","\n","Epoch 00347: val_accuracy did not improve from 0.93103\n","Epoch 348/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0039 - accuracy: 0.9976 - val_loss: 0.4847 - val_accuracy: 0.8916\n","\n","Epoch 00348: val_accuracy did not improve from 0.93103\n","Epoch 349/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.6000 - val_accuracy: 0.8670\n","\n","Epoch 00349: val_accuracy did not improve from 0.93103\n","Epoch 350/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0116 - accuracy: 0.9945 - val_loss: 0.7571 - val_accuracy: 0.8547\n","\n","Epoch 00350: val_accuracy did not improve from 0.93103\n","Epoch 351/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.6372 - val_accuracy: 0.9039\n","\n","Epoch 00351: val_accuracy did not improve from 0.93103\n","Epoch 352/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.6193 - val_accuracy: 0.8645\n","\n","Epoch 00352: val_accuracy did not improve from 0.93103\n","Epoch 353/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.4780 - val_accuracy: 0.9015\n","\n","Epoch 00353: val_accuracy did not improve from 0.93103\n","Epoch 354/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.8031 - val_accuracy: 0.8793\n","\n","Epoch 00354: val_accuracy did not improve from 0.93103\n","Epoch 355/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.4480 - val_accuracy: 0.9015\n","\n","Epoch 00355: val_accuracy did not improve from 0.93103\n","Epoch 356/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.4612 - val_accuracy: 0.9187\n","\n","Epoch 00356: val_accuracy did not improve from 0.93103\n","Epoch 357/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 1.0128 - val_accuracy: 0.8498\n","\n","Epoch 00357: val_accuracy did not improve from 0.93103\n","Epoch 358/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.4947 - val_accuracy: 0.9163\n","\n","Epoch 00358: val_accuracy did not improve from 0.93103\n","Epoch 359/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4415 - val_accuracy: 0.9163\n","\n","Epoch 00359: val_accuracy did not improve from 0.93103\n","Epoch 360/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0044 - accuracy: 0.9970 - val_loss: 0.5914 - val_accuracy: 0.9039\n","\n","Epoch 00360: val_accuracy did not improve from 0.93103\n","Epoch 361/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.5416 - val_accuracy: 0.8768\n","\n","Epoch 00361: val_accuracy did not improve from 0.93103\n","Epoch 362/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0410 - accuracy: 0.9884 - val_loss: 0.6208 - val_accuracy: 0.8941\n","\n","Epoch 00362: val_accuracy did not improve from 0.93103\n","Epoch 363/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0362 - accuracy: 0.9896 - val_loss: 0.7333 - val_accuracy: 0.8916\n","\n","Epoch 00363: val_accuracy did not improve from 0.93103\n","Epoch 364/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.9016 - val_accuracy: 0.8103\n","\n","Epoch 00364: val_accuracy did not improve from 0.93103\n","Epoch 365/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.5796 - val_accuracy: 0.8645\n","\n","Epoch 00365: val_accuracy did not improve from 0.93103\n","Epoch 366/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.5734 - val_accuracy: 0.8916\n","\n","Epoch 00366: val_accuracy did not improve from 0.93103\n","Epoch 367/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.6339 - val_accuracy: 0.8867\n","\n","Epoch 00367: val_accuracy did not improve from 0.93103\n","Epoch 368/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.7886 - val_accuracy: 0.8596\n","\n","Epoch 00368: val_accuracy did not improve from 0.93103\n","Epoch 369/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0102 - accuracy: 0.9988 - val_loss: 0.4935 - val_accuracy: 0.9089\n","\n","Epoch 00369: val_accuracy did not improve from 0.93103\n","Epoch 370/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0266 - accuracy: 0.9939 - val_loss: 0.7267 - val_accuracy: 0.8768\n","\n","Epoch 00370: val_accuracy did not improve from 0.93103\n","Epoch 371/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0416 - accuracy: 0.9866 - val_loss: 0.7472 - val_accuracy: 0.8153\n","\n","Epoch 00371: val_accuracy did not improve from 0.93103\n","Epoch 372/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.8888 - val_accuracy: 0.8276\n","\n","Epoch 00372: val_accuracy did not improve from 0.93103\n","Epoch 373/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.7472 - val_accuracy: 0.8719\n","\n","Epoch 00373: val_accuracy did not improve from 0.93103\n","Epoch 374/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.9515 - val_accuracy: 0.8498\n","\n","Epoch 00374: val_accuracy did not improve from 0.93103\n","Epoch 375/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5419 - val_accuracy: 0.8990\n","\n","Epoch 00375: val_accuracy did not improve from 0.93103\n","Epoch 376/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4917 - val_accuracy: 0.9089\n","\n","Epoch 00376: val_accuracy did not improve from 0.93103\n","Epoch 377/500\n","52/52 [==============================] - 12s 220ms/step - loss: 9.9000e-04 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9163\n","\n","Epoch 00377: val_accuracy did not improve from 0.93103\n","Epoch 378/500\n","52/52 [==============================] - 12s 220ms/step - loss: 4.3697e-04 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.9089\n","\n","Epoch 00378: val_accuracy did not improve from 0.93103\n","Epoch 379/500\n","52/52 [==============================] - 12s 222ms/step - loss: 6.2984e-04 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.9138\n","\n","Epoch 00379: val_accuracy did not improve from 0.93103\n","Epoch 380/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.0854e-04 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.9089\n","\n","Epoch 00380: val_accuracy did not improve from 0.93103\n","Epoch 381/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.4991e-04 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.9113\n","\n","Epoch 00381: val_accuracy did not improve from 0.93103\n","Epoch 382/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.9163\n","\n","Epoch 00382: val_accuracy did not improve from 0.93103\n","Epoch 383/500\n","52/52 [==============================] - 12s 221ms/step - loss: 5.5214e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9261\n","\n","Epoch 00383: val_accuracy did not improve from 0.93103\n","Epoch 384/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5084 - val_accuracy: 0.9089\n","\n","Epoch 00384: val_accuracy did not improve from 0.93103\n","Epoch 385/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.4563 - val_accuracy: 0.9187\n","\n","Epoch 00385: val_accuracy did not improve from 0.93103\n","Epoch 386/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.7430 - val_accuracy: 0.8645\n","\n","Epoch 00386: val_accuracy did not improve from 0.93103\n","Epoch 387/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.6485 - val_accuracy: 0.8990\n","\n","Epoch 00387: val_accuracy did not improve from 0.93103\n","Epoch 388/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.6280 - val_accuracy: 0.8645\n","\n","Epoch 00388: val_accuracy did not improve from 0.93103\n","Epoch 389/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.5995 - val_accuracy: 0.8867\n","\n","Epoch 00389: val_accuracy did not improve from 0.93103\n","Epoch 390/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.4685 - val_accuracy: 0.8990\n","\n","Epoch 00390: val_accuracy did not improve from 0.93103\n","Epoch 391/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.3910 - val_accuracy: 0.9212\n","\n","Epoch 00391: val_accuracy did not improve from 0.93103\n","Epoch 392/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5945 - val_accuracy: 0.9064\n","\n","Epoch 00392: val_accuracy did not improve from 0.93103\n","Epoch 393/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.8990\n","\n","Epoch 00393: val_accuracy did not improve from 0.93103\n","Epoch 394/500\n","52/52 [==============================] - 12s 222ms/step - loss: 6.8933e-04 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.9113\n","\n","Epoch 00394: val_accuracy did not improve from 0.93103\n","Epoch 395/500\n","52/52 [==============================] - 12s 221ms/step - loss: 4.0469e-04 - accuracy: 1.0000 - val_loss: 0.4582 - val_accuracy: 0.9138\n","\n","Epoch 00395: val_accuracy did not improve from 0.93103\n","Epoch 396/500\n","52/52 [==============================] - 12s 221ms/step - loss: 5.4713e-04 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9236\n","\n","Epoch 00396: val_accuracy did not improve from 0.93103\n","Epoch 397/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3878 - val_accuracy: 0.9286\n","\n","Epoch 00397: val_accuracy did not improve from 0.93103\n","Epoch 398/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4430 - val_accuracy: 0.9335\n","\n","Epoch 00398: val_accuracy improved from 0.93103 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 399/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5363 - val_accuracy: 0.9064\n","\n","Epoch 00399: val_accuracy did not improve from 0.93350\n","Epoch 400/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.5211 - val_accuracy: 0.9039\n","\n","Epoch 00400: val_accuracy did not improve from 0.93350\n","Epoch 401/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.4143 - val_accuracy: 0.9187\n","\n","Epoch 00401: val_accuracy did not improve from 0.93350\n","Epoch 402/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.4813 - val_accuracy: 0.9039\n","\n","Epoch 00402: val_accuracy did not improve from 0.93350\n","Epoch 403/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0046 - accuracy: 0.9970 - val_loss: 0.4501 - val_accuracy: 0.9015\n","\n","Epoch 00403: val_accuracy did not improve from 0.93350\n","Epoch 404/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4714 - val_accuracy: 0.8892\n","\n","Epoch 00404: val_accuracy did not improve from 0.93350\n","Epoch 405/500\n","52/52 [==============================] - 12s 222ms/step - loss: 9.0326e-04 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.9212\n","\n","Epoch 00405: val_accuracy did not improve from 0.93350\n","Epoch 406/500\n","52/52 [==============================] - 12s 222ms/step - loss: 4.7865e-04 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.9212\n","\n","Epoch 00406: val_accuracy did not improve from 0.93350\n","Epoch 407/500\n","52/52 [==============================] - 12s 221ms/step - loss: 4.9087e-04 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9113\n","\n","Epoch 00407: val_accuracy did not improve from 0.93350\n","Epoch 408/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.6307 - val_accuracy: 0.8941\n","\n","Epoch 00408: val_accuracy did not improve from 0.93350\n","Epoch 409/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0560 - accuracy: 0.9848 - val_loss: 1.0314 - val_accuracy: 0.8350\n","\n","Epoch 00409: val_accuracy did not improve from 0.93350\n","Epoch 410/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0432 - accuracy: 0.9872 - val_loss: 1.3064 - val_accuracy: 0.6946\n","\n","Epoch 00410: val_accuracy did not improve from 0.93350\n","Epoch 411/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0466 - accuracy: 0.9811 - val_loss: 2.4092 - val_accuracy: 0.5961\n","\n","Epoch 00411: val_accuracy did not improve from 0.93350\n","Epoch 412/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 1.1856 - val_accuracy: 0.7340\n","\n","Epoch 00412: val_accuracy did not improve from 0.93350\n","Epoch 413/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.9513 - val_accuracy: 0.7611\n","\n","Epoch 00413: val_accuracy did not improve from 0.93350\n","Epoch 414/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 1.2891 - val_accuracy: 0.7562\n","\n","Epoch 00414: val_accuracy did not improve from 0.93350\n","Epoch 415/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.6179 - val_accuracy: 0.8670\n","\n","Epoch 00415: val_accuracy did not improve from 0.93350\n","Epoch 416/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.4631 - val_accuracy: 0.8990\n","\n","Epoch 00416: val_accuracy did not improve from 0.93350\n","Epoch 417/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5387 - val_accuracy: 0.9015\n","\n","Epoch 00417: val_accuracy did not improve from 0.93350\n","Epoch 418/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3631 - val_accuracy: 0.9212\n","\n","Epoch 00418: val_accuracy did not improve from 0.93350\n","Epoch 419/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4422 - val_accuracy: 0.9138\n","\n","Epoch 00419: val_accuracy did not improve from 0.93350\n","Epoch 420/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5563 - val_accuracy: 0.8966\n","\n","Epoch 00420: val_accuracy did not improve from 0.93350\n","Epoch 421/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4417 - val_accuracy: 0.9089\n","\n","Epoch 00421: val_accuracy did not improve from 0.93350\n","Epoch 422/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5517 - val_accuracy: 0.9113\n","\n","Epoch 00422: val_accuracy did not improve from 0.93350\n","Epoch 423/500\n","52/52 [==============================] - 12s 222ms/step - loss: 9.7999e-04 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9187\n","\n","Epoch 00423: val_accuracy did not improve from 0.93350\n","Epoch 424/500\n","52/52 [==============================] - 12s 221ms/step - loss: 7.1755e-04 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9236\n","\n","Epoch 00424: val_accuracy did not improve from 0.93350\n","Epoch 425/500\n","52/52 [==============================] - 12s 222ms/step - loss: 7.2686e-04 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9138\n","\n","Epoch 00425: val_accuracy did not improve from 0.93350\n","Epoch 426/500\n","52/52 [==============================] - 12s 222ms/step - loss: 6.5131e-04 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9286\n","\n","Epoch 00426: val_accuracy did not improve from 0.93350\n","Epoch 427/500\n","52/52 [==============================] - 12s 222ms/step - loss: 4.1141e-04 - accuracy: 1.0000 - val_loss: 0.4025 - val_accuracy: 0.9335\n","\n","Epoch 00427: val_accuracy did not improve from 0.93350\n","Epoch 428/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0551 - accuracy: 0.9866 - val_loss: 3.7757 - val_accuracy: 0.4852\n","\n","Epoch 00428: val_accuracy did not improve from 0.93350\n","Epoch 429/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0416 - accuracy: 0.9860 - val_loss: 0.6413 - val_accuracy: 0.8596\n","\n","Epoch 00429: val_accuracy did not improve from 0.93350\n","Epoch 430/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.4785 - val_accuracy: 0.8966\n","\n","Epoch 00430: val_accuracy did not improve from 0.93350\n","Epoch 431/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4892 - val_accuracy: 0.9015\n","\n","Epoch 00431: val_accuracy did not improve from 0.93350\n","Epoch 432/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4439 - val_accuracy: 0.9113\n","\n","Epoch 00432: val_accuracy did not improve from 0.93350\n","Epoch 433/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4551 - val_accuracy: 0.9039\n","\n","Epoch 00433: val_accuracy did not improve from 0.93350\n","Epoch 434/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.9113\n","\n","Epoch 00434: val_accuracy did not improve from 0.93350\n","Epoch 435/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4221 - val_accuracy: 0.9163\n","\n","Epoch 00435: val_accuracy did not improve from 0.93350\n","Epoch 436/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4946 - val_accuracy: 0.9187\n","\n","Epoch 00436: val_accuracy did not improve from 0.93350\n","Epoch 437/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4316 - val_accuracy: 0.9310\n","\n","Epoch 00437: val_accuracy did not improve from 0.93350\n","Epoch 438/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.4998 - val_accuracy: 0.8966\n","\n","Epoch 00438: val_accuracy did not improve from 0.93350\n","Epoch 439/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3944 - val_accuracy: 0.9236\n","\n","Epoch 00439: val_accuracy did not improve from 0.93350\n","Epoch 440/500\n","52/52 [==============================] - 12s 222ms/step - loss: 4.8067e-04 - accuracy: 1.0000 - val_loss: 0.3710 - val_accuracy: 0.9310\n","\n","Epoch 00440: val_accuracy did not improve from 0.93350\n","Epoch 441/500\n","52/52 [==============================] - 12s 222ms/step - loss: 3.9228e-04 - accuracy: 1.0000 - val_loss: 0.3734 - val_accuracy: 0.9261\n","\n","Epoch 00441: val_accuracy did not improve from 0.93350\n","Epoch 442/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.3358 - val_accuracy: 0.9286\n","\n","Epoch 00442: val_accuracy did not improve from 0.93350\n","Epoch 443/500\n","52/52 [==============================] - 12s 222ms/step - loss: 3.1688e-04 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9384\n","\n","Epoch 00443: val_accuracy improved from 0.93350 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5\n","Epoch 444/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.5091 - val_accuracy: 0.8966\n","\n","Epoch 00444: val_accuracy did not improve from 0.93842\n","Epoch 445/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5611 - val_accuracy: 0.8941\n","\n","Epoch 00445: val_accuracy did not improve from 0.93842\n","Epoch 446/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5661 - val_accuracy: 0.9089\n","\n","Epoch 00446: val_accuracy did not improve from 0.93842\n","Epoch 447/500\n","52/52 [==============================] - 12s 222ms/step - loss: 9.5384e-04 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.9138\n","\n","Epoch 00447: val_accuracy did not improve from 0.93842\n","Epoch 448/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5546 - val_accuracy: 0.9212\n","\n","Epoch 00448: val_accuracy did not improve from 0.93842\n","Epoch 449/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.8064 - val_accuracy: 0.8768\n","\n","Epoch 00449: val_accuracy did not improve from 0.93842\n","Epoch 450/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0749 - accuracy: 0.9799 - val_loss: 1.2553 - val_accuracy: 0.8448\n","\n","Epoch 00450: val_accuracy did not improve from 0.93842\n","Epoch 451/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0287 - accuracy: 0.9915 - val_loss: 0.8427 - val_accuracy: 0.8695\n","\n","Epoch 00451: val_accuracy did not improve from 0.93842\n","Epoch 452/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.5832 - val_accuracy: 0.8892\n","\n","Epoch 00452: val_accuracy did not improve from 0.93842\n","Epoch 453/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.4643 - val_accuracy: 0.9089\n","\n","Epoch 00453: val_accuracy did not improve from 0.93842\n","Epoch 454/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.5277 - val_accuracy: 0.8892\n","\n","Epoch 00454: val_accuracy did not improve from 0.93842\n","Epoch 455/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.5460 - val_accuracy: 0.8941\n","\n","Epoch 00455: val_accuracy did not improve from 0.93842\n","Epoch 456/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.5717 - val_accuracy: 0.8916\n","\n","Epoch 00456: val_accuracy did not improve from 0.93842\n","Epoch 457/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.5479 - val_accuracy: 0.9015\n","\n","Epoch 00457: val_accuracy did not improve from 0.93842\n","Epoch 458/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5790 - val_accuracy: 0.9039\n","\n","Epoch 00458: val_accuracy did not improve from 0.93842\n","Epoch 459/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4213 - val_accuracy: 0.9138\n","\n","Epoch 00459: val_accuracy did not improve from 0.93842\n","Epoch 460/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4077 - val_accuracy: 0.9187\n","\n","Epoch 00460: val_accuracy did not improve from 0.93842\n","Epoch 461/500\n","52/52 [==============================] - 12s 221ms/step - loss: 9.2862e-04 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9138\n","\n","Epoch 00461: val_accuracy did not improve from 0.93842\n","Epoch 462/500\n","52/52 [==============================] - 12s 221ms/step - loss: 6.6315e-04 - accuracy: 0.9994 - val_loss: 0.3795 - val_accuracy: 0.9212\n","\n","Epoch 00462: val_accuracy did not improve from 0.93842\n","Epoch 463/500\n","52/52 [==============================] - 12s 239ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4360 - val_accuracy: 0.9138\n","\n","Epoch 00463: val_accuracy did not improve from 0.93842\n","Epoch 464/500\n","52/52 [==============================] - 12s 222ms/step - loss: 9.9152e-04 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9310\n","\n","Epoch 00464: val_accuracy did not improve from 0.93842\n","Epoch 465/500\n","52/52 [==============================] - 12s 224ms/step - loss: 1.8058e-04 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.9138\n","\n","Epoch 00465: val_accuracy did not improve from 0.93842\n","Epoch 466/500\n","52/52 [==============================] - 12s 221ms/step - loss: 2.3575e-04 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 0.9261\n","\n","Epoch 00466: val_accuracy did not improve from 0.93842\n","Epoch 467/500\n","52/52 [==============================] - 12s 221ms/step - loss: 2.4854e-04 - accuracy: 1.0000 - val_loss: 0.4189 - val_accuracy: 0.9236\n","\n","Epoch 00467: val_accuracy did not improve from 0.93842\n","Epoch 468/500\n","52/52 [==============================] - 12s 222ms/step - loss: 2.5674e-04 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9236\n","\n","Epoch 00468: val_accuracy did not improve from 0.93842\n","Epoch 469/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.3558e-04 - accuracy: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.9335\n","\n","Epoch 00469: val_accuracy did not improve from 0.93842\n","Epoch 470/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.4006e-04 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9261\n","\n","Epoch 00470: val_accuracy did not improve from 0.93842\n","Epoch 471/500\n","52/52 [==============================] - 12s 222ms/step - loss: 9.2572e-04 - accuracy: 0.9994 - val_loss: 0.3958 - val_accuracy: 0.9286\n","\n","Epoch 00471: val_accuracy did not improve from 0.93842\n","Epoch 472/500\n","52/52 [==============================] - 12s 222ms/step - loss: 3.4081e-04 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.9261\n","\n","Epoch 00472: val_accuracy did not improve from 0.93842\n","Epoch 473/500\n","52/52 [==============================] - 12s 221ms/step - loss: 1.9615e-04 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.9310\n","\n","Epoch 00473: val_accuracy did not improve from 0.93842\n","Epoch 474/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.3570 - val_accuracy: 0.9360\n","\n","Epoch 00474: val_accuracy did not improve from 0.93842\n","Epoch 475/500\n","52/52 [==============================] - 12s 223ms/step - loss: 7.5166e-04 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.9212\n","\n","Epoch 00475: val_accuracy did not improve from 0.93842\n","Epoch 476/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.9113\n","\n","Epoch 00476: val_accuracy did not improve from 0.93842\n","Epoch 477/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.5085 - val_accuracy: 0.8990\n","\n","Epoch 00477: val_accuracy did not improve from 0.93842\n","Epoch 478/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.6690 - val_accuracy: 0.8744\n","\n","Epoch 00478: val_accuracy did not improve from 0.93842\n","Epoch 479/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0404 - accuracy: 0.9921 - val_loss: 0.9211 - val_accuracy: 0.8744\n","\n","Epoch 00479: val_accuracy did not improve from 0.93842\n","Epoch 480/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.7883 - val_accuracy: 0.8645\n","\n","Epoch 00480: val_accuracy did not improve from 0.93842\n","Epoch 481/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0485 - accuracy: 0.9909 - val_loss: 0.8007 - val_accuracy: 0.8522\n","\n","Epoch 00481: val_accuracy did not improve from 0.93842\n","Epoch 482/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0367 - accuracy: 0.9909 - val_loss: 0.7375 - val_accuracy: 0.8719\n","\n","Epoch 00482: val_accuracy did not improve from 0.93842\n","Epoch 483/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.5977 - val_accuracy: 0.8768\n","\n","Epoch 00483: val_accuracy did not improve from 0.93842\n","Epoch 484/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 0.5247 - val_accuracy: 0.9039\n","\n","Epoch 00484: val_accuracy did not improve from 0.93842\n","Epoch 485/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4121 - val_accuracy: 0.9089\n","\n","Epoch 00485: val_accuracy did not improve from 0.93842\n","Epoch 486/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.9236\n","\n","Epoch 00486: val_accuracy did not improve from 0.93842\n","Epoch 487/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.7672 - val_accuracy: 0.8744\n","\n","Epoch 00487: val_accuracy did not improve from 0.93842\n","Epoch 488/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.7137 - val_accuracy: 0.8768\n","\n","Epoch 00488: val_accuracy did not improve from 0.93842\n","Epoch 489/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5293 - val_accuracy: 0.9064\n","\n","Epoch 00489: val_accuracy did not improve from 0.93842\n","Epoch 490/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0292 - accuracy: 0.9921 - val_loss: 0.8721 - val_accuracy: 0.8498\n","\n","Epoch 00490: val_accuracy did not improve from 0.93842\n","Epoch 491/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0111 - accuracy: 0.9951 - val_loss: 0.8202 - val_accuracy: 0.8473\n","\n","Epoch 00491: val_accuracy did not improve from 0.93842\n","Epoch 492/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.5096 - val_accuracy: 0.8867\n","\n","Epoch 00492: val_accuracy did not improve from 0.93842\n","Epoch 493/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.4196 - val_accuracy: 0.9039\n","\n","Epoch 00493: val_accuracy did not improve from 0.93842\n","Epoch 494/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5311 - val_accuracy: 0.9039\n","\n","Epoch 00494: val_accuracy did not improve from 0.93842\n","Epoch 495/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5729 - val_accuracy: 0.8818\n","\n","Epoch 00495: val_accuracy did not improve from 0.93842\n","Epoch 496/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.7299 - val_accuracy: 0.8941\n","\n","Epoch 00496: val_accuracy did not improve from 0.93842\n","Epoch 497/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0369 - accuracy: 0.9909 - val_loss: 0.8962 - val_accuracy: 0.8325\n","\n","Epoch 00497: val_accuracy did not improve from 0.93842\n","Epoch 498/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.5688 - val_accuracy: 0.8916\n","\n","Epoch 00498: val_accuracy did not improve from 0.93842\n","Epoch 499/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5090 - val_accuracy: 0.8916\n","\n","Epoch 00499: val_accuracy did not improve from 0.93842\n","Epoch 500/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5106 - val_accuracy: 0.9064\n","\n","Epoch 00500: val_accuracy did not improve from 0.93842\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f47a25a0e10>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1630842136943,"user_tz":-540,"elapsed":23,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"cf32c624-a977-4715-c9fd-4d53455d2a8c"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1630842149036,"user_tz":-540,"elapsed":12104,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_3_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1630842149629,"user_tz":-540,"elapsed":610,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630842150270,"user_tz":-540,"elapsed":645,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"74ceeeb8-a8b5-4e1e-f146-044f4b4e009c"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630842183115,"user_tz":-540,"elapsed":32848,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b73099a7-db3f-4673-e7b8-52cc0643326d"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1630842183116,"user_tz":-540,"elapsed":10,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1630842183117,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1630842185286,"user_tz":-540,"elapsed":2177,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1630842185287,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1630842200928,"user_tz":-540,"elapsed":15646,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1630842200929,"user_tz":-540,"elapsed":28,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"204b24e1-09db-4765-cdc9-6314738f8481"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1630842200929,"user_tz":-540,"elapsed":25,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ab0706c8-1aa8-4784-ae0e-0c7031f17175"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/BatchSize_32_3_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/BatchSize_32_3_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_9526a1af-1aec-4b5e-a240-e659b4ed5d3a\", \"BatchSize_32_3_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}