{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CVLC-07-Eleven model ensemble(public-0.94607, private-0.93317).ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mYaBdU_2v9A3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628156104395,"user_tz":-540,"elapsed":21986,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"bec6af83-dac7-4a24-ebca-2b641858277d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nHkfaJbVq51_","executionInfo":{"status":"ok","timestamp":1628156119374,"user_tz":-540,"elapsed":4619,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1628156127375,"user_tz":-540,"elapsed":1906,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1628156133008,"user_tz":-540,"elapsed":2513,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1628156153136,"user_tz":-540,"elapsed":18313,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ACO-d4DhwS4g","executionInfo":{"status":"ok","timestamp":1628156196676,"user_tz":-540,"elapsed":25813,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","\n","ResNet50_model =  tf.keras.applications.ResNet50(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)\n","ResNet101_model =  tf.keras.applications.ResNet101(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)\n","ResNet152_model =  tf.keras.applications.ResNet152(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)\n","ResNet50V2_model =  tf.keras.applications.ResNet50V2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)\n","ResNet101V2_model =  tf.keras.applications.ResNet101V2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)\n","ResNet152V2_model =  tf.keras.applications.ResNet152V2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)\n","InceptionResNetV2_model = tf.keras.applications.InceptionResNetV2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)\n","InceptionV3_model =  tf.keras.applications.InceptionV3(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)\n","VGG16_model = tf.keras.applications.VGG16(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)\n","VGG19_model = tf.keras.applications.VGG19(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)\n","DenseNet169_model = tf.keras.applications.DenseNet169(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)\n","DenseNet201_model = tf.keras.applications.DenseNet201(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"L_vZLSC7wv1I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628156233404,"user_tz":-540,"elapsed":387,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"de3f3245-1812-4d8c-9306-bd34148d875f"},"source":["from tensorflow.keras.optimizers import Adam\n","ResNet50_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])\n","ResNet101_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])\n","ResNet152_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])\n","ResNet50V2_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])\n","ResNet101V2_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])\n","ResNet152V2_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])\n","VGG16_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])\n","VGG19_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])\n","InceptionV3_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])\n","InceptionResNetV2_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])\n","DenseNet169_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])\n","DenseNet201_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mFfY3blSw62V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628156236958,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c67ba162-02af-443f-a0fa-759746beb01a"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ih_pVNUqyQDE","executionInfo":{"status":"ok","timestamp":1628156239992,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["ResNet50_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n","ResNet101_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n","ResNet152_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n","ResNet50V2_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n","ResNet101V2_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n","ResNet152V2_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n","VGG16_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_VGG16.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n","VGG19_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_VGG19.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n","InceptionV3_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n","InceptionResNetV2_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n","DenseNet121_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n","DenseNet169_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n","DenseNet201_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1628081402063,"user_tz":-540,"elapsed":5308695,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ad9c24c1-7dfd-46fe-8b66-0735f9ff2d35"},"source":["ResNet50_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [ResNet50_checkpoint])\n","# files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5')"],"execution_count":211,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 10s 196ms/step - loss: 1.8661 - accuracy: 0.3459 - val_loss: 5.1434 - val_accuracy: 0.0985\n","\n","Epoch 00001: val_accuracy did not improve from 0.11330\n","Epoch 2/500\n","52/52 [==============================] - 10s 196ms/step - loss: 1.4754 - accuracy: 0.4878 - val_loss: 10.3838 - val_accuracy: 0.0936\n","\n","Epoch 00002: val_accuracy did not improve from 0.11330\n","Epoch 3/500\n","52/52 [==============================] - 10s 195ms/step - loss: 1.2965 - accuracy: 0.5615 - val_loss: 9.3204 - val_accuracy: 0.0936\n","\n","Epoch 00003: val_accuracy did not improve from 0.11330\n","Epoch 4/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.9959 - accuracy: 0.6571 - val_loss: 15.2106 - val_accuracy: 0.0936\n","\n","Epoch 00004: val_accuracy did not improve from 0.11330\n","Epoch 5/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.9414 - accuracy: 0.6754 - val_loss: 8.0241 - val_accuracy: 0.1355\n","\n","Epoch 00005: val_accuracy improved from 0.11330 to 0.13547, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 6/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.8847 - accuracy: 0.7083 - val_loss: 17.3816 - val_accuracy: 0.1798\n","\n","Epoch 00006: val_accuracy improved from 0.13547 to 0.17980, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 7/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.7950 - accuracy: 0.7381 - val_loss: 1.1676 - val_accuracy: 0.6059\n","\n","Epoch 00007: val_accuracy improved from 0.17980 to 0.60591, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 8/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.7204 - accuracy: 0.7686 - val_loss: 1.6986 - val_accuracy: 0.5616\n","\n","Epoch 00008: val_accuracy did not improve from 0.60591\n","Epoch 9/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.6294 - accuracy: 0.7850 - val_loss: 6.0252 - val_accuracy: 0.4483\n","\n","Epoch 00009: val_accuracy did not improve from 0.60591\n","Epoch 10/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.6035 - accuracy: 0.7868 - val_loss: 1.7540 - val_accuracy: 0.6330\n","\n","Epoch 00010: val_accuracy improved from 0.60591 to 0.63300, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 11/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.6093 - accuracy: 0.8015 - val_loss: 16.1873 - val_accuracy: 0.2438\n","\n","Epoch 00011: val_accuracy did not improve from 0.63300\n","Epoch 12/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.5352 - accuracy: 0.8222 - val_loss: 1.0962 - val_accuracy: 0.7340\n","\n","Epoch 00012: val_accuracy improved from 0.63300 to 0.73399, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 13/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.4887 - accuracy: 0.8362 - val_loss: 4.7953 - val_accuracy: 0.5000\n","\n","Epoch 00013: val_accuracy did not improve from 0.73399\n","Epoch 14/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.4894 - accuracy: 0.8313 - val_loss: 1.3934 - val_accuracy: 0.6798\n","\n","Epoch 00014: val_accuracy did not improve from 0.73399\n","Epoch 15/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.4571 - accuracy: 0.8380 - val_loss: 1.8066 - val_accuracy: 0.6626\n","\n","Epoch 00015: val_accuracy did not improve from 0.73399\n","Epoch 16/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.3871 - accuracy: 0.8703 - val_loss: 0.7183 - val_accuracy: 0.7931\n","\n","Epoch 00016: val_accuracy improved from 0.73399 to 0.79310, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 17/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.3602 - accuracy: 0.8788 - val_loss: 9.3558 - val_accuracy: 0.4212\n","\n","Epoch 00017: val_accuracy did not improve from 0.79310\n","Epoch 18/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.4448 - accuracy: 0.8508 - val_loss: 1.3352 - val_accuracy: 0.7438\n","\n","Epoch 00018: val_accuracy did not improve from 0.79310\n","Epoch 19/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.3593 - accuracy: 0.8752 - val_loss: 0.9209 - val_accuracy: 0.7635\n","\n","Epoch 00019: val_accuracy did not improve from 0.79310\n","Epoch 20/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.3213 - accuracy: 0.8910 - val_loss: 1.1679 - val_accuracy: 0.7291\n","\n","Epoch 00020: val_accuracy did not improve from 0.79310\n","Epoch 21/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.3207 - accuracy: 0.8849 - val_loss: 0.8893 - val_accuracy: 0.7808\n","\n","Epoch 00021: val_accuracy did not improve from 0.79310\n","Epoch 22/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.3900 - accuracy: 0.8599 - val_loss: 13.4111 - val_accuracy: 0.1478\n","\n","Epoch 00022: val_accuracy did not improve from 0.79310\n","Epoch 23/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.3762 - accuracy: 0.8715 - val_loss: 1.0100 - val_accuracy: 0.7340\n","\n","Epoch 00023: val_accuracy did not improve from 0.79310\n","Epoch 24/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.3052 - accuracy: 0.8886 - val_loss: 4.3626 - val_accuracy: 0.4409\n","\n","Epoch 00024: val_accuracy did not improve from 0.79310\n","Epoch 25/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.2978 - accuracy: 0.8983 - val_loss: 0.6790 - val_accuracy: 0.7956\n","\n","Epoch 00025: val_accuracy improved from 0.79310 to 0.79557, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 26/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.2831 - accuracy: 0.9032 - val_loss: 7.4809 - val_accuracy: 0.3596\n","\n","Epoch 00026: val_accuracy did not improve from 0.79557\n","Epoch 27/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.2905 - accuracy: 0.8983 - val_loss: 1.0509 - val_accuracy: 0.7759\n","\n","Epoch 00027: val_accuracy did not improve from 0.79557\n","Epoch 28/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.2336 - accuracy: 0.9239 - val_loss: 0.6562 - val_accuracy: 0.8177\n","\n","Epoch 00028: val_accuracy improved from 0.79557 to 0.81773, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 29/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.2826 - accuracy: 0.9080 - val_loss: 18.6075 - val_accuracy: 0.1158\n","\n","Epoch 00029: val_accuracy did not improve from 0.81773\n","Epoch 30/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.2457 - accuracy: 0.9166 - val_loss: 0.5409 - val_accuracy: 0.8547\n","\n","Epoch 00030: val_accuracy improved from 0.81773 to 0.85468, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 31/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.2275 - accuracy: 0.9214 - val_loss: 15.6630 - val_accuracy: 0.1823\n","\n","Epoch 00031: val_accuracy did not improve from 0.85468\n","Epoch 32/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.2520 - accuracy: 0.9099 - val_loss: 3.6912 - val_accuracy: 0.4532\n","\n","Epoch 00032: val_accuracy did not improve from 0.85468\n","Epoch 33/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.2686 - accuracy: 0.9086 - val_loss: 0.8530 - val_accuracy: 0.7685\n","\n","Epoch 00033: val_accuracy did not improve from 0.85468\n","Epoch 34/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.1930 - accuracy: 0.9421 - val_loss: 0.5537 - val_accuracy: 0.8473\n","\n","Epoch 00034: val_accuracy did not improve from 0.85468\n","Epoch 35/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.2390 - accuracy: 0.9172 - val_loss: 0.6325 - val_accuracy: 0.8325\n","\n","Epoch 00035: val_accuracy did not improve from 0.85468\n","Epoch 36/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.2539 - accuracy: 0.9111 - val_loss: 3.8813 - val_accuracy: 0.5887\n","\n","Epoch 00036: val_accuracy did not improve from 0.85468\n","Epoch 37/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.2250 - accuracy: 0.9275 - val_loss: 0.5850 - val_accuracy: 0.8177\n","\n","Epoch 00037: val_accuracy did not improve from 0.85468\n","Epoch 38/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1844 - accuracy: 0.9336 - val_loss: 0.7095 - val_accuracy: 0.8276\n","\n","Epoch 00038: val_accuracy did not improve from 0.85468\n","Epoch 39/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1637 - accuracy: 0.9476 - val_loss: 0.8803 - val_accuracy: 0.8005\n","\n","Epoch 00039: val_accuracy did not improve from 0.85468\n","Epoch 40/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1794 - accuracy: 0.9421 - val_loss: 0.5477 - val_accuracy: 0.8744\n","\n","Epoch 00040: val_accuracy improved from 0.85468 to 0.87438, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 41/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.1460 - accuracy: 0.9519 - val_loss: 0.5220 - val_accuracy: 0.8596\n","\n","Epoch 00041: val_accuracy did not improve from 0.87438\n","Epoch 42/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.1584 - accuracy: 0.9482 - val_loss: 0.6948 - val_accuracy: 0.8030\n","\n","Epoch 00042: val_accuracy did not improve from 0.87438\n","Epoch 43/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.2423 - accuracy: 0.9208 - val_loss: 4.9477 - val_accuracy: 0.4877\n","\n","Epoch 00043: val_accuracy did not improve from 0.87438\n","Epoch 44/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.1561 - accuracy: 0.9482 - val_loss: 0.7687 - val_accuracy: 0.8227\n","\n","Epoch 00044: val_accuracy did not improve from 0.87438\n","Epoch 45/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1170 - accuracy: 0.9616 - val_loss: 0.6058 - val_accuracy: 0.8251\n","\n","Epoch 00045: val_accuracy did not improve from 0.87438\n","Epoch 46/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1400 - accuracy: 0.9482 - val_loss: 0.8952 - val_accuracy: 0.7956\n","\n","Epoch 00046: val_accuracy did not improve from 0.87438\n","Epoch 47/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.1898 - accuracy: 0.9361 - val_loss: 3.0545 - val_accuracy: 0.5222\n","\n","Epoch 00047: val_accuracy did not improve from 0.87438\n","Epoch 48/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.1422 - accuracy: 0.9470 - val_loss: 0.8917 - val_accuracy: 0.8054\n","\n","Epoch 00048: val_accuracy did not improve from 0.87438\n","Epoch 49/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.1352 - accuracy: 0.9568 - val_loss: 0.8573 - val_accuracy: 0.8103\n","\n","Epoch 00049: val_accuracy did not improve from 0.87438\n","Epoch 50/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.1482 - accuracy: 0.9507 - val_loss: 0.6690 - val_accuracy: 0.8374\n","\n","Epoch 00050: val_accuracy did not improve from 0.87438\n","Epoch 51/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1168 - accuracy: 0.9629 - val_loss: 1.0034 - val_accuracy: 0.8374\n","\n","Epoch 00051: val_accuracy did not improve from 0.87438\n","Epoch 52/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1048 - accuracy: 0.9610 - val_loss: 0.6626 - val_accuracy: 0.8473\n","\n","Epoch 00052: val_accuracy did not improve from 0.87438\n","Epoch 53/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.1025 - accuracy: 0.9659 - val_loss: 0.7278 - val_accuracy: 0.8202\n","\n","Epoch 00053: val_accuracy did not improve from 0.87438\n","Epoch 54/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.1161 - accuracy: 0.9562 - val_loss: 0.6456 - val_accuracy: 0.8399\n","\n","Epoch 00054: val_accuracy did not improve from 0.87438\n","Epoch 55/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.1937 - accuracy: 0.9312 - val_loss: 0.9632 - val_accuracy: 0.8054\n","\n","Epoch 00055: val_accuracy did not improve from 0.87438\n","Epoch 56/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.1308 - accuracy: 0.9574 - val_loss: 0.9533 - val_accuracy: 0.7857\n","\n","Epoch 00056: val_accuracy did not improve from 0.87438\n","Epoch 57/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0820 - accuracy: 0.9762 - val_loss: 0.5867 - val_accuracy: 0.8522\n","\n","Epoch 00057: val_accuracy did not improve from 0.87438\n","Epoch 58/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.1322 - accuracy: 0.9568 - val_loss: 1.3023 - val_accuracy: 0.7562\n","\n","Epoch 00058: val_accuracy did not improve from 0.87438\n","Epoch 59/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.2752 - accuracy: 0.9026 - val_loss: 49.4581 - val_accuracy: 0.2562\n","\n","Epoch 00059: val_accuracy did not improve from 0.87438\n","Epoch 60/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.1798 - accuracy: 0.9306 - val_loss: 1.0026 - val_accuracy: 0.8030\n","\n","Epoch 00060: val_accuracy did not improve from 0.87438\n","Epoch 61/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1818 - accuracy: 0.9446 - val_loss: 0.7796 - val_accuracy: 0.8251\n","\n","Epoch 00061: val_accuracy did not improve from 0.87438\n","Epoch 62/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1404 - accuracy: 0.9476 - val_loss: 0.8916 - val_accuracy: 0.7906\n","\n","Epoch 00062: val_accuracy did not improve from 0.87438\n","Epoch 63/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.1291 - accuracy: 0.9586 - val_loss: 0.5198 - val_accuracy: 0.8867\n","\n","Epoch 00063: val_accuracy improved from 0.87438 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 64/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.1360 - accuracy: 0.9562 - val_loss: 0.4876 - val_accuracy: 0.8842\n","\n","Epoch 00064: val_accuracy did not improve from 0.88670\n","Epoch 65/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.1186 - accuracy: 0.9592 - val_loss: 0.6480 - val_accuracy: 0.8522\n","\n","Epoch 00065: val_accuracy did not improve from 0.88670\n","Epoch 66/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.1969 - accuracy: 0.9324 - val_loss: 0.4564 - val_accuracy: 0.8645\n","\n","Epoch 00066: val_accuracy did not improve from 0.88670\n","Epoch 67/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0825 - accuracy: 0.9726 - val_loss: 0.5304 - val_accuracy: 0.8818\n","\n","Epoch 00067: val_accuracy did not improve from 0.88670\n","Epoch 68/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0931 - accuracy: 0.9708 - val_loss: 0.6914 - val_accuracy: 0.8448\n","\n","Epoch 00068: val_accuracy did not improve from 0.88670\n","Epoch 69/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0623 - accuracy: 0.9775 - val_loss: 0.5681 - val_accuracy: 0.8571\n","\n","Epoch 00069: val_accuracy did not improve from 0.88670\n","Epoch 70/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0769 - accuracy: 0.9732 - val_loss: 0.4123 - val_accuracy: 0.8842\n","\n","Epoch 00070: val_accuracy did not improve from 0.88670\n","Epoch 71/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0857 - accuracy: 0.9726 - val_loss: 11.0523 - val_accuracy: 0.2833\n","\n","Epoch 00071: val_accuracy did not improve from 0.88670\n","Epoch 72/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0908 - accuracy: 0.9671 - val_loss: 0.4707 - val_accuracy: 0.8596\n","\n","Epoch 00072: val_accuracy did not improve from 0.88670\n","Epoch 73/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0850 - accuracy: 0.9689 - val_loss: 0.5572 - val_accuracy: 0.8744\n","\n","Epoch 00073: val_accuracy did not improve from 0.88670\n","Epoch 74/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0911 - accuracy: 0.9671 - val_loss: 1.0650 - val_accuracy: 0.7906\n","\n","Epoch 00074: val_accuracy did not improve from 0.88670\n","Epoch 75/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1611 - accuracy: 0.9446 - val_loss: 0.8698 - val_accuracy: 0.8103\n","\n","Epoch 00075: val_accuracy did not improve from 0.88670\n","Epoch 76/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.1505 - accuracy: 0.9543 - val_loss: 0.7365 - val_accuracy: 0.8473\n","\n","Epoch 00076: val_accuracy did not improve from 0.88670\n","Epoch 77/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.1258 - accuracy: 0.9562 - val_loss: 1.1300 - val_accuracy: 0.8030\n","\n","Epoch 00077: val_accuracy did not improve from 0.88670\n","Epoch 78/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0661 - accuracy: 0.9781 - val_loss: 0.6352 - val_accuracy: 0.8695\n","\n","Epoch 00078: val_accuracy did not improve from 0.88670\n","Epoch 79/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0874 - accuracy: 0.9799 - val_loss: 1.8893 - val_accuracy: 0.7315\n","\n","Epoch 00079: val_accuracy did not improve from 0.88670\n","Epoch 80/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1253 - accuracy: 0.9568 - val_loss: 4.3124 - val_accuracy: 0.5345\n","\n","Epoch 00080: val_accuracy did not improve from 0.88670\n","Epoch 81/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0905 - accuracy: 0.9689 - val_loss: 0.7406 - val_accuracy: 0.8424\n","\n","Epoch 00081: val_accuracy did not improve from 0.88670\n","Epoch 82/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0661 - accuracy: 0.9775 - val_loss: 0.8867 - val_accuracy: 0.8424\n","\n","Epoch 00082: val_accuracy did not improve from 0.88670\n","Epoch 83/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0511 - accuracy: 0.9817 - val_loss: 0.5350 - val_accuracy: 0.8867\n","\n","Epoch 00083: val_accuracy did not improve from 0.88670\n","Epoch 84/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0787 - accuracy: 0.9744 - val_loss: 1.2846 - val_accuracy: 0.7709\n","\n","Epoch 00084: val_accuracy did not improve from 0.88670\n","Epoch 85/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.1686 - accuracy: 0.9531 - val_loss: 0.9434 - val_accuracy: 0.8399\n","\n","Epoch 00085: val_accuracy did not improve from 0.88670\n","Epoch 86/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.1124 - accuracy: 0.9641 - val_loss: 0.6436 - val_accuracy: 0.8522\n","\n","Epoch 00086: val_accuracy did not improve from 0.88670\n","Epoch 87/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0906 - accuracy: 0.9689 - val_loss: 4.1007 - val_accuracy: 0.5320\n","\n","Epoch 00087: val_accuracy did not improve from 0.88670\n","Epoch 88/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0717 - accuracy: 0.9726 - val_loss: 0.6551 - val_accuracy: 0.8744\n","\n","Epoch 00088: val_accuracy did not improve from 0.88670\n","Epoch 89/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.1172 - accuracy: 0.9622 - val_loss: 11.9346 - val_accuracy: 0.2167\n","\n","Epoch 00089: val_accuracy did not improve from 0.88670\n","Epoch 90/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0731 - accuracy: 0.9756 - val_loss: 0.5524 - val_accuracy: 0.8498\n","\n","Epoch 00090: val_accuracy did not improve from 0.88670\n","Epoch 91/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.5907 - val_accuracy: 0.8867\n","\n","Epoch 00091: val_accuracy did not improve from 0.88670\n","Epoch 92/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0446 - accuracy: 0.9896 - val_loss: 0.5328 - val_accuracy: 0.8695\n","\n","Epoch 00092: val_accuracy did not improve from 0.88670\n","Epoch 93/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0577 - accuracy: 0.9829 - val_loss: 0.7498 - val_accuracy: 0.8498\n","\n","Epoch 00093: val_accuracy did not improve from 0.88670\n","Epoch 94/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0556 - accuracy: 0.9811 - val_loss: 0.6303 - val_accuracy: 0.8571\n","\n","Epoch 00094: val_accuracy did not improve from 0.88670\n","Epoch 95/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0594 - accuracy: 0.9793 - val_loss: 0.9701 - val_accuracy: 0.8202\n","\n","Epoch 00095: val_accuracy did not improve from 0.88670\n","Epoch 96/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1229 - accuracy: 0.9604 - val_loss: 2.4427 - val_accuracy: 0.6552\n","\n","Epoch 00096: val_accuracy did not improve from 0.88670\n","Epoch 97/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0817 - accuracy: 0.9732 - val_loss: 27.6140 - val_accuracy: 0.1527\n","\n","Epoch 00097: val_accuracy did not improve from 0.88670\n","Epoch 98/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.1373 - accuracy: 0.9549 - val_loss: 27.9655 - val_accuracy: 0.1182\n","\n","Epoch 00098: val_accuracy did not improve from 0.88670\n","Epoch 99/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.1224 - accuracy: 0.9598 - val_loss: 1.3315 - val_accuracy: 0.8030\n","\n","Epoch 00099: val_accuracy did not improve from 0.88670\n","Epoch 100/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.1003 - accuracy: 0.9665 - val_loss: 0.4173 - val_accuracy: 0.9039\n","\n","Epoch 00100: val_accuracy improved from 0.88670 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 101/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0760 - accuracy: 0.9726 - val_loss: 0.8605 - val_accuracy: 0.8325\n","\n","Epoch 00101: val_accuracy did not improve from 0.90394\n","Epoch 102/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0893 - accuracy: 0.9677 - val_loss: 0.6367 - val_accuracy: 0.8818\n","\n","Epoch 00102: val_accuracy did not improve from 0.90394\n","Epoch 103/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0590 - accuracy: 0.9817 - val_loss: 0.6726 - val_accuracy: 0.8547\n","\n","Epoch 00103: val_accuracy did not improve from 0.90394\n","Epoch 104/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0829 - accuracy: 0.9799 - val_loss: 0.6875 - val_accuracy: 0.8547\n","\n","Epoch 00104: val_accuracy did not improve from 0.90394\n","Epoch 105/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0484 - accuracy: 0.9854 - val_loss: 0.6706 - val_accuracy: 0.8621\n","\n","Epoch 00105: val_accuracy did not improve from 0.90394\n","Epoch 106/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0372 - accuracy: 0.9890 - val_loss: 0.4885 - val_accuracy: 0.8916\n","\n","Epoch 00106: val_accuracy did not improve from 0.90394\n","Epoch 107/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0323 - accuracy: 0.9903 - val_loss: 0.5905 - val_accuracy: 0.8695\n","\n","Epoch 00107: val_accuracy did not improve from 0.90394\n","Epoch 108/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0528 - accuracy: 0.9854 - val_loss: 1.3540 - val_accuracy: 0.7980\n","\n","Epoch 00108: val_accuracy did not improve from 0.90394\n","Epoch 109/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0460 - accuracy: 0.9866 - val_loss: 0.7082 - val_accuracy: 0.8522\n","\n","Epoch 00109: val_accuracy did not improve from 0.90394\n","Epoch 110/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0691 - accuracy: 0.9781 - val_loss: 0.5961 - val_accuracy: 0.8916\n","\n","Epoch 00110: val_accuracy did not improve from 0.90394\n","Epoch 111/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0834 - accuracy: 0.9762 - val_loss: 2.4788 - val_accuracy: 0.7734\n","\n","Epoch 00111: val_accuracy did not improve from 0.90394\n","Epoch 112/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0500 - accuracy: 0.9872 - val_loss: 0.6055 - val_accuracy: 0.8916\n","\n","Epoch 00112: val_accuracy did not improve from 0.90394\n","Epoch 113/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0760 - accuracy: 0.9726 - val_loss: 0.6874 - val_accuracy: 0.8719\n","\n","Epoch 00113: val_accuracy did not improve from 0.90394\n","Epoch 114/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0968 - accuracy: 0.9683 - val_loss: 0.6633 - val_accuracy: 0.8621\n","\n","Epoch 00114: val_accuracy did not improve from 0.90394\n","Epoch 115/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 0.6569 - val_accuracy: 0.8547\n","\n","Epoch 00115: val_accuracy did not improve from 0.90394\n","Epoch 116/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.4649 - val_accuracy: 0.8818\n","\n","Epoch 00116: val_accuracy did not improve from 0.90394\n","Epoch 117/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0181 - accuracy: 0.9927 - val_loss: 0.4744 - val_accuracy: 0.9064\n","\n","Epoch 00117: val_accuracy improved from 0.90394 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 118/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0452 - accuracy: 0.9854 - val_loss: 0.4937 - val_accuracy: 0.8990\n","\n","Epoch 00118: val_accuracy did not improve from 0.90640\n","Epoch 119/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.2637 - accuracy: 0.9269 - val_loss: 53.0534 - val_accuracy: 0.1182\n","\n","Epoch 00119: val_accuracy did not improve from 0.90640\n","Epoch 120/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.3098 - accuracy: 0.9135 - val_loss: 46.6241 - val_accuracy: 0.1034\n","\n","Epoch 00120: val_accuracy did not improve from 0.90640\n","Epoch 121/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.1264 - accuracy: 0.9562 - val_loss: 3.6851 - val_accuracy: 0.5665\n","\n","Epoch 00121: val_accuracy did not improve from 0.90640\n","Epoch 122/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0905 - accuracy: 0.9708 - val_loss: 0.6981 - val_accuracy: 0.8276\n","\n","Epoch 00122: val_accuracy did not improve from 0.90640\n","Epoch 123/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0663 - accuracy: 0.9781 - val_loss: 0.5677 - val_accuracy: 0.8768\n","\n","Epoch 00123: val_accuracy did not improve from 0.90640\n","Epoch 124/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0329 - accuracy: 0.9884 - val_loss: 0.4208 - val_accuracy: 0.9138\n","\n","Epoch 00124: val_accuracy improved from 0.90640 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 125/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0394 - accuracy: 0.9854 - val_loss: 0.6714 - val_accuracy: 0.8621\n","\n","Epoch 00125: val_accuracy did not improve from 0.91379\n","Epoch 126/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0280 - accuracy: 0.9903 - val_loss: 0.4745 - val_accuracy: 0.8990\n","\n","Epoch 00126: val_accuracy did not improve from 0.91379\n","Epoch 127/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.3807 - val_accuracy: 0.8990\n","\n","Epoch 00127: val_accuracy did not improve from 0.91379\n","Epoch 128/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 0.4280 - val_accuracy: 0.8867\n","\n","Epoch 00128: val_accuracy did not improve from 0.91379\n","Epoch 129/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0725 - accuracy: 0.9775 - val_loss: 0.5804 - val_accuracy: 0.8596\n","\n","Epoch 00129: val_accuracy did not improve from 0.91379\n","Epoch 130/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0315 - accuracy: 0.9890 - val_loss: 0.6790 - val_accuracy: 0.8596\n","\n","Epoch 00130: val_accuracy did not improve from 0.91379\n","Epoch 131/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0388 - accuracy: 0.9854 - val_loss: 0.5270 - val_accuracy: 0.8941\n","\n","Epoch 00131: val_accuracy did not improve from 0.91379\n","Epoch 132/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0376 - accuracy: 0.9866 - val_loss: 0.5651 - val_accuracy: 0.8695\n","\n","Epoch 00132: val_accuracy did not improve from 0.91379\n","Epoch 133/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0416 - accuracy: 0.9854 - val_loss: 0.7526 - val_accuracy: 0.8522\n","\n","Epoch 00133: val_accuracy did not improve from 0.91379\n","Epoch 134/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0580 - accuracy: 0.9836 - val_loss: 0.9072 - val_accuracy: 0.8276\n","\n","Epoch 00134: val_accuracy did not improve from 0.91379\n","Epoch 135/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0638 - accuracy: 0.9799 - val_loss: 0.6110 - val_accuracy: 0.8793\n","\n","Epoch 00135: val_accuracy did not improve from 0.91379\n","Epoch 136/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0374 - accuracy: 0.9872 - val_loss: 0.7053 - val_accuracy: 0.8842\n","\n","Epoch 00136: val_accuracy did not improve from 0.91379\n","Epoch 137/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0438 - accuracy: 0.9836 - val_loss: 0.7779 - val_accuracy: 0.8695\n","\n","Epoch 00137: val_accuracy did not improve from 0.91379\n","Epoch 138/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0413 - accuracy: 0.9848 - val_loss: 0.5241 - val_accuracy: 0.9089\n","\n","Epoch 00138: val_accuracy did not improve from 0.91379\n","Epoch 139/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0702 - accuracy: 0.9762 - val_loss: 0.7761 - val_accuracy: 0.8473\n","\n","Epoch 00139: val_accuracy did not improve from 0.91379\n","Epoch 140/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0554 - accuracy: 0.9836 - val_loss: 0.5773 - val_accuracy: 0.8842\n","\n","Epoch 00140: val_accuracy did not improve from 0.91379\n","Epoch 141/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0347 - accuracy: 0.9884 - val_loss: 0.5739 - val_accuracy: 0.8842\n","\n","Epoch 00141: val_accuracy did not improve from 0.91379\n","Epoch 142/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0950 - accuracy: 0.9702 - val_loss: 0.5427 - val_accuracy: 0.8670\n","\n","Epoch 00142: val_accuracy did not improve from 0.91379\n","Epoch 143/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0740 - accuracy: 0.9781 - val_loss: 0.7863 - val_accuracy: 0.8448\n","\n","Epoch 00143: val_accuracy did not improve from 0.91379\n","Epoch 144/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0410 - accuracy: 0.9866 - val_loss: 1.0029 - val_accuracy: 0.8153\n","\n","Epoch 00144: val_accuracy did not improve from 0.91379\n","Epoch 145/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0842 - accuracy: 0.9750 - val_loss: 2.5841 - val_accuracy: 0.6970\n","\n","Epoch 00145: val_accuracy did not improve from 0.91379\n","Epoch 146/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0510 - accuracy: 0.9805 - val_loss: 2.4831 - val_accuracy: 0.6330\n","\n","Epoch 00146: val_accuracy did not improve from 0.91379\n","Epoch 147/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0319 - accuracy: 0.9915 - val_loss: 0.7161 - val_accuracy: 0.8670\n","\n","Epoch 00147: val_accuracy did not improve from 0.91379\n","Epoch 148/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0338 - accuracy: 0.9909 - val_loss: 0.6388 - val_accuracy: 0.8842\n","\n","Epoch 00148: val_accuracy did not improve from 0.91379\n","Epoch 149/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.4772 - val_accuracy: 0.8867\n","\n","Epoch 00149: val_accuracy did not improve from 0.91379\n","Epoch 150/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 0.5353 - val_accuracy: 0.8916\n","\n","Epoch 00150: val_accuracy did not improve from 0.91379\n","Epoch 151/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 1.5337 - val_accuracy: 0.7709\n","\n","Epoch 00151: val_accuracy did not improve from 0.91379\n","Epoch 152/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.5609 - val_accuracy: 0.8892\n","\n","Epoch 00152: val_accuracy did not improve from 0.91379\n","Epoch 153/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0409 - accuracy: 0.9878 - val_loss: 0.6289 - val_accuracy: 0.8966\n","\n","Epoch 00153: val_accuracy did not improve from 0.91379\n","Epoch 154/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0286 - accuracy: 0.9896 - val_loss: 0.9917 - val_accuracy: 0.8005\n","\n","Epoch 00154: val_accuracy did not improve from 0.91379\n","Epoch 155/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0482 - accuracy: 0.9866 - val_loss: 0.5884 - val_accuracy: 0.8719\n","\n","Epoch 00155: val_accuracy did not improve from 0.91379\n","Epoch 156/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0544 - accuracy: 0.9823 - val_loss: 0.9719 - val_accuracy: 0.8054\n","\n","Epoch 00156: val_accuracy did not improve from 0.91379\n","Epoch 157/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0705 - accuracy: 0.9805 - val_loss: 0.7060 - val_accuracy: 0.8399\n","\n","Epoch 00157: val_accuracy did not improve from 0.91379\n","Epoch 158/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0797 - accuracy: 0.9720 - val_loss: 0.7911 - val_accuracy: 0.8670\n","\n","Epoch 00158: val_accuracy did not improve from 0.91379\n","Epoch 159/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0461 - accuracy: 0.9836 - val_loss: 0.6958 - val_accuracy: 0.8571\n","\n","Epoch 00159: val_accuracy did not improve from 0.91379\n","Epoch 160/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0246 - accuracy: 0.9903 - val_loss: 0.5387 - val_accuracy: 0.8990\n","\n","Epoch 00160: val_accuracy did not improve from 0.91379\n","Epoch 161/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 0.5285 - val_accuracy: 0.8941\n","\n","Epoch 00161: val_accuracy did not improve from 0.91379\n","Epoch 162/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0494 - accuracy: 0.9817 - val_loss: 1.0122 - val_accuracy: 0.8153\n","\n","Epoch 00162: val_accuracy did not improve from 0.91379\n","Epoch 163/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0472 - accuracy: 0.9842 - val_loss: 1.3501 - val_accuracy: 0.7980\n","\n","Epoch 00163: val_accuracy did not improve from 0.91379\n","Epoch 164/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0463 - accuracy: 0.9860 - val_loss: 0.6151 - val_accuracy: 0.8842\n","\n","Epoch 00164: val_accuracy did not improve from 0.91379\n","Epoch 165/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 0.6737 - val_accuracy: 0.8818\n","\n","Epoch 00165: val_accuracy did not improve from 0.91379\n","Epoch 166/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 9.8924 - val_accuracy: 0.4015\n","\n","Epoch 00166: val_accuracy did not improve from 0.91379\n","Epoch 167/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.5526 - val_accuracy: 0.8941\n","\n","Epoch 00167: val_accuracy did not improve from 0.91379\n","Epoch 168/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0164 - accuracy: 0.9933 - val_loss: 0.6010 - val_accuracy: 0.8842\n","\n","Epoch 00168: val_accuracy did not improve from 0.91379\n","Epoch 169/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0392 - accuracy: 0.9854 - val_loss: 0.6503 - val_accuracy: 0.8768\n","\n","Epoch 00169: val_accuracy did not improve from 0.91379\n","Epoch 170/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0359 - accuracy: 0.9872 - val_loss: 0.5903 - val_accuracy: 0.8670\n","\n","Epoch 00170: val_accuracy did not improve from 0.91379\n","Epoch 171/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 0.7202 - val_accuracy: 0.8768\n","\n","Epoch 00171: val_accuracy did not improve from 0.91379\n","Epoch 172/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0431 - accuracy: 0.9884 - val_loss: 0.5420 - val_accuracy: 0.8941\n","\n","Epoch 00172: val_accuracy did not improve from 0.91379\n","Epoch 173/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0193 - accuracy: 0.9927 - val_loss: 0.5886 - val_accuracy: 0.8768\n","\n","Epoch 00173: val_accuracy did not improve from 0.91379\n","Epoch 174/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.5093 - val_accuracy: 0.9015\n","\n","Epoch 00174: val_accuracy did not improve from 0.91379\n","Epoch 175/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.6028 - val_accuracy: 0.8842\n","\n","Epoch 00175: val_accuracy did not improve from 0.91379\n","Epoch 176/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.5933 - val_accuracy: 0.8867\n","\n","Epoch 00176: val_accuracy did not improve from 0.91379\n","Epoch 177/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0373 - accuracy: 0.9848 - val_loss: 0.6421 - val_accuracy: 0.8793\n","\n","Epoch 00177: val_accuracy did not improve from 0.91379\n","Epoch 178/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 0.4767 - val_accuracy: 0.9089\n","\n","Epoch 00178: val_accuracy did not improve from 0.91379\n","Epoch 179/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.5422 - val_accuracy: 0.8990\n","\n","Epoch 00179: val_accuracy did not improve from 0.91379\n","Epoch 180/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0298 - accuracy: 0.9890 - val_loss: 0.5540 - val_accuracy: 0.8990\n","\n","Epoch 00180: val_accuracy did not improve from 0.91379\n","Epoch 181/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0339 - accuracy: 0.9866 - val_loss: 1.0544 - val_accuracy: 0.8325\n","\n","Epoch 00181: val_accuracy did not improve from 0.91379\n","Epoch 182/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0351 - accuracy: 0.9872 - val_loss: 1.1223 - val_accuracy: 0.8424\n","\n","Epoch 00182: val_accuracy did not improve from 0.91379\n","Epoch 183/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0851 - accuracy: 0.9762 - val_loss: 1.0298 - val_accuracy: 0.8448\n","\n","Epoch 00183: val_accuracy did not improve from 0.91379\n","Epoch 184/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0678 - accuracy: 0.9775 - val_loss: 0.4874 - val_accuracy: 0.8966\n","\n","Epoch 00184: val_accuracy did not improve from 0.91379\n","Epoch 185/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.6866 - val_accuracy: 0.8695\n","\n","Epoch 00185: val_accuracy did not improve from 0.91379\n","Epoch 186/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0483 - accuracy: 0.9848 - val_loss: 0.9365 - val_accuracy: 0.8522\n","\n","Epoch 00186: val_accuracy did not improve from 0.91379\n","Epoch 187/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0337 - accuracy: 0.9896 - val_loss: 0.7787 - val_accuracy: 0.8867\n","\n","Epoch 00187: val_accuracy did not improve from 0.91379\n","Epoch 188/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0626 - accuracy: 0.9817 - val_loss: 5.1485 - val_accuracy: 0.5049\n","\n","Epoch 00188: val_accuracy did not improve from 0.91379\n","Epoch 189/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0498 - accuracy: 0.9805 - val_loss: 0.7182 - val_accuracy: 0.8695\n","\n","Epoch 00189: val_accuracy did not improve from 0.91379\n","Epoch 190/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0594 - accuracy: 0.9793 - val_loss: 2.9056 - val_accuracy: 0.7340\n","\n","Epoch 00190: val_accuracy did not improve from 0.91379\n","Epoch 191/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0354 - accuracy: 0.9903 - val_loss: 0.6113 - val_accuracy: 0.8892\n","\n","Epoch 00191: val_accuracy did not improve from 0.91379\n","Epoch 192/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.4060 - val_accuracy: 0.9089\n","\n","Epoch 00192: val_accuracy did not improve from 0.91379\n","Epoch 193/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0305 - accuracy: 0.9890 - val_loss: 0.5697 - val_accuracy: 0.8941\n","\n","Epoch 00193: val_accuracy did not improve from 0.91379\n","Epoch 194/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.7317 - val_accuracy: 0.8695\n","\n","Epoch 00194: val_accuracy did not improve from 0.91379\n","Epoch 195/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.5308 - val_accuracy: 0.8842\n","\n","Epoch 00195: val_accuracy did not improve from 0.91379\n","Epoch 196/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.5888 - val_accuracy: 0.8768\n","\n","Epoch 00196: val_accuracy did not improve from 0.91379\n","Epoch 197/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0082 - accuracy: 0.9945 - val_loss: 0.5772 - val_accuracy: 0.9064\n","\n","Epoch 00197: val_accuracy did not improve from 0.91379\n","Epoch 198/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.7233 - val_accuracy: 0.8719\n","\n","Epoch 00198: val_accuracy did not improve from 0.91379\n","Epoch 199/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 1.2965 - val_accuracy: 0.8227\n","\n","Epoch 00199: val_accuracy did not improve from 0.91379\n","Epoch 200/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.1162 - accuracy: 0.9689 - val_loss: 2.6818 - val_accuracy: 0.7020\n","\n","Epoch 00200: val_accuracy did not improve from 0.91379\n","Epoch 201/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0837 - accuracy: 0.9762 - val_loss: 1.1340 - val_accuracy: 0.8227\n","\n","Epoch 00201: val_accuracy did not improve from 0.91379\n","Epoch 202/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0446 - accuracy: 0.9836 - val_loss: 0.7276 - val_accuracy: 0.8941\n","\n","Epoch 00202: val_accuracy did not improve from 0.91379\n","Epoch 203/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0286 - accuracy: 0.9878 - val_loss: 0.7504 - val_accuracy: 0.8768\n","\n","Epoch 00203: val_accuracy did not improve from 0.91379\n","Epoch 204/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.4769 - val_accuracy: 0.8892\n","\n","Epoch 00204: val_accuracy did not improve from 0.91379\n","Epoch 205/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0080 - accuracy: 0.9963 - val_loss: 0.4586 - val_accuracy: 0.9113\n","\n","Epoch 00205: val_accuracy did not improve from 0.91379\n","Epoch 206/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5371 - val_accuracy: 0.8916\n","\n","Epoch 00206: val_accuracy did not improve from 0.91379\n","Epoch 207/500\n","52/52 [==============================] - 11s 201ms/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.6300 - val_accuracy: 0.9015\n","\n","Epoch 00207: val_accuracy did not improve from 0.91379\n","Epoch 208/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0571 - accuracy: 0.9817 - val_loss: 0.7835 - val_accuracy: 0.8941\n","\n","Epoch 00208: val_accuracy did not improve from 0.91379\n","Epoch 209/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.6537 - val_accuracy: 0.8867\n","\n","Epoch 00209: val_accuracy did not improve from 0.91379\n","Epoch 210/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.5420 - val_accuracy: 0.9089\n","\n","Epoch 00210: val_accuracy did not improve from 0.91379\n","Epoch 211/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.6058 - val_accuracy: 0.8818\n","\n","Epoch 00211: val_accuracy did not improve from 0.91379\n","Epoch 212/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0152 - accuracy: 0.9927 - val_loss: 0.4717 - val_accuracy: 0.8867\n","\n","Epoch 00212: val_accuracy did not improve from 0.91379\n","Epoch 213/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1448 - accuracy: 0.9555 - val_loss: 1.1776 - val_accuracy: 0.7759\n","\n","Epoch 00213: val_accuracy did not improve from 0.91379\n","Epoch 214/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0230 - accuracy: 0.9903 - val_loss: 0.5314 - val_accuracy: 0.8941\n","\n","Epoch 00214: val_accuracy did not improve from 0.91379\n","Epoch 215/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.4892 - val_accuracy: 0.8966\n","\n","Epoch 00215: val_accuracy did not improve from 0.91379\n","Epoch 216/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0604 - accuracy: 0.9842 - val_loss: 11.5377 - val_accuracy: 0.2906\n","\n","Epoch 00216: val_accuracy did not improve from 0.91379\n","Epoch 217/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0525 - accuracy: 0.9842 - val_loss: 0.9118 - val_accuracy: 0.8424\n","\n","Epoch 00217: val_accuracy did not improve from 0.91379\n","Epoch 218/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0338 - accuracy: 0.9903 - val_loss: 0.6329 - val_accuracy: 0.8941\n","\n","Epoch 00218: val_accuracy did not improve from 0.91379\n","Epoch 219/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.5718 - val_accuracy: 0.8867\n","\n","Epoch 00219: val_accuracy did not improve from 0.91379\n","Epoch 220/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4616 - val_accuracy: 0.9015\n","\n","Epoch 00220: val_accuracy did not improve from 0.91379\n","Epoch 221/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4431 - val_accuracy: 0.9138\n","\n","Epoch 00221: val_accuracy did not improve from 0.91379\n","Epoch 222/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.4166 - val_accuracy: 0.9163\n","\n","Epoch 00222: val_accuracy improved from 0.91379 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 223/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 1.0228 - val_accuracy: 0.8399\n","\n","Epoch 00223: val_accuracy did not improve from 0.91626\n","Epoch 224/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0627 - accuracy: 0.9836 - val_loss: 1.1925 - val_accuracy: 0.8103\n","\n","Epoch 00224: val_accuracy did not improve from 0.91626\n","Epoch 225/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0534 - accuracy: 0.9842 - val_loss: 0.5577 - val_accuracy: 0.8818\n","\n","Epoch 00225: val_accuracy did not improve from 0.91626\n","Epoch 226/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0241 - accuracy: 0.9945 - val_loss: 0.7119 - val_accuracy: 0.8621\n","\n","Epoch 00226: val_accuracy did not improve from 0.91626\n","Epoch 227/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.7600 - val_accuracy: 0.8645\n","\n","Epoch 00227: val_accuracy did not improve from 0.91626\n","Epoch 228/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 8.5301 - val_accuracy: 0.3768\n","\n","Epoch 00228: val_accuracy did not improve from 0.91626\n","Epoch 229/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.7545 - val_accuracy: 0.8670\n","\n","Epoch 00229: val_accuracy did not improve from 0.91626\n","Epoch 230/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0239 - accuracy: 0.9945 - val_loss: 0.5514 - val_accuracy: 0.8867\n","\n","Epoch 00230: val_accuracy did not improve from 0.91626\n","Epoch 231/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0113 - accuracy: 0.9945 - val_loss: 0.5011 - val_accuracy: 0.8966\n","\n","Epoch 00231: val_accuracy did not improve from 0.91626\n","Epoch 232/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.5497 - val_accuracy: 0.8892\n","\n","Epoch 00232: val_accuracy did not improve from 0.91626\n","Epoch 233/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.4825 - val_accuracy: 0.9089\n","\n","Epoch 00233: val_accuracy did not improve from 0.91626\n","Epoch 234/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.5235 - val_accuracy: 0.8867\n","\n","Epoch 00234: val_accuracy did not improve from 0.91626\n","Epoch 235/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 1.4364 - val_accuracy: 0.8054\n","\n","Epoch 00235: val_accuracy did not improve from 0.91626\n","Epoch 236/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0237 - accuracy: 0.9909 - val_loss: 0.6172 - val_accuracy: 0.8867\n","\n","Epoch 00236: val_accuracy did not improve from 0.91626\n","Epoch 237/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.5197 - val_accuracy: 0.9064\n","\n","Epoch 00237: val_accuracy did not improve from 0.91626\n","Epoch 238/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5545 - val_accuracy: 0.8892\n","\n","Epoch 00238: val_accuracy did not improve from 0.91626\n","Epoch 239/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.8175 - val_accuracy: 0.8670\n","\n","Epoch 00239: val_accuracy did not improve from 0.91626\n","Epoch 240/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.6970 - val_accuracy: 0.8892\n","\n","Epoch 00240: val_accuracy did not improve from 0.91626\n","Epoch 241/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.7497 - val_accuracy: 0.8941\n","\n","Epoch 00241: val_accuracy did not improve from 0.91626\n","Epoch 242/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.7967 - val_accuracy: 0.8522\n","\n","Epoch 00242: val_accuracy did not improve from 0.91626\n","Epoch 243/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0218 - accuracy: 0.9903 - val_loss: 0.8775 - val_accuracy: 0.8522\n","\n","Epoch 00243: val_accuracy did not improve from 0.91626\n","Epoch 244/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0427 - accuracy: 0.9890 - val_loss: 2.0073 - val_accuracy: 0.7808\n","\n","Epoch 00244: val_accuracy did not improve from 0.91626\n","Epoch 245/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0694 - accuracy: 0.9769 - val_loss: 3.1927 - val_accuracy: 0.6355\n","\n","Epoch 00245: val_accuracy did not improve from 0.91626\n","Epoch 246/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 4.1320 - val_accuracy: 0.5788\n","\n","Epoch 00246: val_accuracy did not improve from 0.91626\n","Epoch 247/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 1.3481 - val_accuracy: 0.8202\n","\n","Epoch 00247: val_accuracy did not improve from 0.91626\n","Epoch 248/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0756 - accuracy: 0.9744 - val_loss: 22.3874 - val_accuracy: 0.1675\n","\n","Epoch 00248: val_accuracy did not improve from 0.91626\n","Epoch 249/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0362 - accuracy: 0.9866 - val_loss: 0.6629 - val_accuracy: 0.8695\n","\n","Epoch 00249: val_accuracy did not improve from 0.91626\n","Epoch 250/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.5523 - val_accuracy: 0.8990\n","\n","Epoch 00250: val_accuracy did not improve from 0.91626\n","Epoch 251/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0181 - accuracy: 0.9957 - val_loss: 0.5713 - val_accuracy: 0.8941\n","\n","Epoch 00251: val_accuracy did not improve from 0.91626\n","Epoch 252/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.5101 - val_accuracy: 0.8941\n","\n","Epoch 00252: val_accuracy did not improve from 0.91626\n","Epoch 253/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.5588 - val_accuracy: 0.9015\n","\n","Epoch 00253: val_accuracy did not improve from 0.91626\n","Epoch 254/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0211 - accuracy: 0.9945 - val_loss: 6.6375 - val_accuracy: 0.5222\n","\n","Epoch 00254: val_accuracy did not improve from 0.91626\n","Epoch 255/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.6431 - val_accuracy: 0.8892\n","\n","Epoch 00255: val_accuracy did not improve from 0.91626\n","Epoch 256/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.6374 - val_accuracy: 0.8892\n","\n","Epoch 00256: val_accuracy did not improve from 0.91626\n","Epoch 257/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5976 - val_accuracy: 0.8842\n","\n","Epoch 00257: val_accuracy did not improve from 0.91626\n","Epoch 258/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5709 - val_accuracy: 0.9015\n","\n","Epoch 00258: val_accuracy did not improve from 0.91626\n","Epoch 259/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6157 - val_accuracy: 0.9015\n","\n","Epoch 00259: val_accuracy did not improve from 0.91626\n","Epoch 260/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.9064\n","\n","Epoch 00260: val_accuracy did not improve from 0.91626\n","Epoch 261/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.9113\n","\n","Epoch 00261: val_accuracy did not improve from 0.91626\n","Epoch 262/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5003 - val_accuracy: 0.9039\n","\n","Epoch 00262: val_accuracy did not improve from 0.91626\n","Epoch 263/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5287 - val_accuracy: 0.9015\n","\n","Epoch 00263: val_accuracy did not improve from 0.91626\n","Epoch 264/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.5705 - val_accuracy: 0.9015\n","\n","Epoch 00264: val_accuracy did not improve from 0.91626\n","Epoch 265/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.9328 - val_accuracy: 0.8522\n","\n","Epoch 00265: val_accuracy did not improve from 0.91626\n","Epoch 266/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0233 - accuracy: 0.9939 - val_loss: 0.5752 - val_accuracy: 0.9138\n","\n","Epoch 00266: val_accuracy did not improve from 0.91626\n","Epoch 267/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0190 - accuracy: 0.9927 - val_loss: 0.6754 - val_accuracy: 0.8966\n","\n","Epoch 00267: val_accuracy did not improve from 0.91626\n","Epoch 268/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0360 - accuracy: 0.9878 - val_loss: 0.6932 - val_accuracy: 0.9089\n","\n","Epoch 00268: val_accuracy did not improve from 0.91626\n","Epoch 269/500\n","52/52 [==============================] - 10s 202ms/step - loss: 0.0336 - accuracy: 0.9903 - val_loss: 1.0710 - val_accuracy: 0.8399\n","\n","Epoch 00269: val_accuracy did not improve from 0.91626\n","Epoch 270/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.4378 - val_accuracy: 0.9187\n","\n","Epoch 00270: val_accuracy improved from 0.91626 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 271/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 0.6303 - val_accuracy: 0.8818\n","\n","Epoch 00271: val_accuracy did not improve from 0.91872\n","Epoch 272/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0203 - accuracy: 0.9915 - val_loss: 0.6209 - val_accuracy: 0.8842\n","\n","Epoch 00272: val_accuracy did not improve from 0.91872\n","Epoch 273/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0238 - accuracy: 0.9945 - val_loss: 0.7648 - val_accuracy: 0.8571\n","\n","Epoch 00273: val_accuracy did not improve from 0.91872\n","Epoch 274/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0276 - accuracy: 0.9903 - val_loss: 0.7231 - val_accuracy: 0.8719\n","\n","Epoch 00274: val_accuracy did not improve from 0.91872\n","Epoch 275/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0357 - accuracy: 0.9866 - val_loss: 1.0646 - val_accuracy: 0.8251\n","\n","Epoch 00275: val_accuracy did not improve from 0.91872\n","Epoch 276/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0482 - accuracy: 0.9854 - val_loss: 1.0258 - val_accuracy: 0.8374\n","\n","Epoch 00276: val_accuracy did not improve from 0.91872\n","Epoch 277/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.6914 - val_accuracy: 0.8966\n","\n","Epoch 00277: val_accuracy did not improve from 0.91872\n","Epoch 278/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0287 - accuracy: 0.9933 - val_loss: 0.8434 - val_accuracy: 0.8350\n","\n","Epoch 00278: val_accuracy did not improve from 0.91872\n","Epoch 279/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0321 - accuracy: 0.9927 - val_loss: 1.0382 - val_accuracy: 0.8670\n","\n","Epoch 00279: val_accuracy did not improve from 0.91872\n","Epoch 280/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0642 - accuracy: 0.9836 - val_loss: 0.9848 - val_accuracy: 0.8350\n","\n","Epoch 00280: val_accuracy did not improve from 0.91872\n","Epoch 281/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0553 - accuracy: 0.9842 - val_loss: 0.8390 - val_accuracy: 0.8448\n","\n","Epoch 00281: val_accuracy did not improve from 0.91872\n","Epoch 282/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.5715 - val_accuracy: 0.8867\n","\n","Epoch 00282: val_accuracy did not improve from 0.91872\n","Epoch 283/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.4612 - val_accuracy: 0.8990\n","\n","Epoch 00283: val_accuracy did not improve from 0.91872\n","Epoch 284/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0067 - accuracy: 0.9963 - val_loss: 0.5930 - val_accuracy: 0.8892\n","\n","Epoch 00284: val_accuracy did not improve from 0.91872\n","Epoch 285/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.5761 - val_accuracy: 0.8867\n","\n","Epoch 00285: val_accuracy did not improve from 0.91872\n","Epoch 286/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.5224 - val_accuracy: 0.8990\n","\n","Epoch 00286: val_accuracy did not improve from 0.91872\n","Epoch 287/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.5654 - val_accuracy: 0.8916\n","\n","Epoch 00287: val_accuracy did not improve from 0.91872\n","Epoch 288/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.5004 - val_accuracy: 0.9015\n","\n","Epoch 00288: val_accuracy did not improve from 0.91872\n","Epoch 289/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.6761 - val_accuracy: 0.8744\n","\n","Epoch 00289: val_accuracy did not improve from 0.91872\n","Epoch 290/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.6138 - val_accuracy: 0.9039\n","\n","Epoch 00290: val_accuracy did not improve from 0.91872\n","Epoch 291/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.6066 - val_accuracy: 0.8941\n","\n","Epoch 00291: val_accuracy did not improve from 0.91872\n","Epoch 292/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.6711 - val_accuracy: 0.8990\n","\n","Epoch 00292: val_accuracy did not improve from 0.91872\n","Epoch 293/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.7353 - val_accuracy: 0.8695\n","\n","Epoch 00293: val_accuracy did not improve from 0.91872\n","Epoch 294/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.7032 - val_accuracy: 0.9015\n","\n","Epoch 00294: val_accuracy did not improve from 0.91872\n","Epoch 295/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.7209 - val_accuracy: 0.8744\n","\n","Epoch 00295: val_accuracy did not improve from 0.91872\n","Epoch 296/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0336 - accuracy: 0.9884 - val_loss: 0.7130 - val_accuracy: 0.8522\n","\n","Epoch 00296: val_accuracy did not improve from 0.91872\n","Epoch 297/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.7653 - val_accuracy: 0.8818\n","\n","Epoch 00297: val_accuracy did not improve from 0.91872\n","Epoch 298/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.4588 - val_accuracy: 0.9064\n","\n","Epoch 00298: val_accuracy did not improve from 0.91872\n","Epoch 299/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.4939 - val_accuracy: 0.8966\n","\n","Epoch 00299: val_accuracy did not improve from 0.91872\n","Epoch 300/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.7492 - val_accuracy: 0.8867\n","\n","Epoch 00300: val_accuracy did not improve from 0.91872\n","Epoch 301/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.5593 - val_accuracy: 0.8916\n","\n","Epoch 00301: val_accuracy did not improve from 0.91872\n","Epoch 302/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 1.2333 - val_accuracy: 0.8177\n","\n","Epoch 00302: val_accuracy did not improve from 0.91872\n","Epoch 303/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0406 - accuracy: 0.9890 - val_loss: 1.5548 - val_accuracy: 0.7660\n","\n","Epoch 00303: val_accuracy did not improve from 0.91872\n","Epoch 304/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0490 - accuracy: 0.9836 - val_loss: 1.5971 - val_accuracy: 0.8153\n","\n","Epoch 00304: val_accuracy did not improve from 0.91872\n","Epoch 305/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0311 - accuracy: 0.9884 - val_loss: 0.6723 - val_accuracy: 0.8966\n","\n","Epoch 00305: val_accuracy did not improve from 0.91872\n","Epoch 306/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0150 - accuracy: 0.9976 - val_loss: 0.5921 - val_accuracy: 0.9212\n","\n","Epoch 00306: val_accuracy improved from 0.91872 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 307/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0199 - accuracy: 0.9957 - val_loss: 0.5476 - val_accuracy: 0.9187\n","\n","Epoch 00307: val_accuracy did not improve from 0.92118\n","Epoch 308/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.5138 - val_accuracy: 0.9064\n","\n","Epoch 00308: val_accuracy did not improve from 0.92118\n","Epoch 309/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.6561 - val_accuracy: 0.8966\n","\n","Epoch 00309: val_accuracy did not improve from 0.92118\n","Epoch 310/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0383 - accuracy: 0.9872 - val_loss: 0.6319 - val_accuracy: 0.8842\n","\n","Epoch 00310: val_accuracy did not improve from 0.92118\n","Epoch 311/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 0.6742 - val_accuracy: 0.8793\n","\n","Epoch 00311: val_accuracy did not improve from 0.92118\n","Epoch 312/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0079 - accuracy: 0.9957 - val_loss: 0.6626 - val_accuracy: 0.8892\n","\n","Epoch 00312: val_accuracy did not improve from 0.92118\n","Epoch 313/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.7162 - val_accuracy: 0.8768\n","\n","Epoch 00313: val_accuracy did not improve from 0.92118\n","Epoch 314/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0178 - accuracy: 0.9963 - val_loss: 0.6771 - val_accuracy: 0.8670\n","\n","Epoch 00314: val_accuracy did not improve from 0.92118\n","Epoch 315/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.8615 - val_accuracy: 0.8621\n","\n","Epoch 00315: val_accuracy did not improve from 0.92118\n","Epoch 316/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.4598 - val_accuracy: 0.9015\n","\n","Epoch 00316: val_accuracy did not improve from 0.92118\n","Epoch 317/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.6150 - val_accuracy: 0.8892\n","\n","Epoch 00317: val_accuracy did not improve from 0.92118\n","Epoch 318/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.6985 - val_accuracy: 0.8793\n","\n","Epoch 00318: val_accuracy did not improve from 0.92118\n","Epoch 319/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.7403 - val_accuracy: 0.8670\n","\n","Epoch 00319: val_accuracy did not improve from 0.92118\n","Epoch 320/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.5968 - val_accuracy: 0.9039\n","\n","Epoch 00320: val_accuracy did not improve from 0.92118\n","Epoch 321/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.5523 - val_accuracy: 0.8941\n","\n","Epoch 00321: val_accuracy did not improve from 0.92118\n","Epoch 322/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.4863 - val_accuracy: 0.9064\n","\n","Epoch 00322: val_accuracy did not improve from 0.92118\n","Epoch 323/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4761 - val_accuracy: 0.9138\n","\n","Epoch 00323: val_accuracy did not improve from 0.92118\n","Epoch 324/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5994 - val_accuracy: 0.9039\n","\n","Epoch 00324: val_accuracy did not improve from 0.92118\n","Epoch 325/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5023 - val_accuracy: 0.8966\n","\n","Epoch 00325: val_accuracy did not improve from 0.92118\n","Epoch 326/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5017 - val_accuracy: 0.9039\n","\n","Epoch 00326: val_accuracy did not improve from 0.92118\n","Epoch 327/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0035 - accuracy: 0.9976 - val_loss: 0.7756 - val_accuracy: 0.8892\n","\n","Epoch 00327: val_accuracy did not improve from 0.92118\n","Epoch 328/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 0.7343 - val_accuracy: 0.8916\n","\n","Epoch 00328: val_accuracy did not improve from 0.92118\n","Epoch 329/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.7931 - val_accuracy: 0.8645\n","\n","Epoch 00329: val_accuracy did not improve from 0.92118\n","Epoch 330/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.9469 - val_accuracy: 0.8818\n","\n","Epoch 00330: val_accuracy did not improve from 0.92118\n","Epoch 331/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5983 - val_accuracy: 0.8818\n","\n","Epoch 00331: val_accuracy did not improve from 0.92118\n","Epoch 332/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0176 - accuracy: 0.9921 - val_loss: 0.9244 - val_accuracy: 0.8621\n","\n","Epoch 00332: val_accuracy did not improve from 0.92118\n","Epoch 333/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0311 - accuracy: 0.9878 - val_loss: 0.7251 - val_accuracy: 0.8768\n","\n","Epoch 00333: val_accuracy did not improve from 0.92118\n","Epoch 334/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0541 - accuracy: 0.9805 - val_loss: 0.8250 - val_accuracy: 0.8695\n","\n","Epoch 00334: val_accuracy did not improve from 0.92118\n","Epoch 335/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0518 - accuracy: 0.9860 - val_loss: 0.8530 - val_accuracy: 0.8547\n","\n","Epoch 00335: val_accuracy did not improve from 0.92118\n","Epoch 336/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0541 - accuracy: 0.9842 - val_loss: 1.4556 - val_accuracy: 0.8177\n","\n","Epoch 00336: val_accuracy did not improve from 0.92118\n","Epoch 337/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.6271 - val_accuracy: 0.9039\n","\n","Epoch 00337: val_accuracy did not improve from 0.92118\n","Epoch 338/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0177 - accuracy: 0.9927 - val_loss: 0.8141 - val_accuracy: 0.8571\n","\n","Epoch 00338: val_accuracy did not improve from 0.92118\n","Epoch 339/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 1.1212 - val_accuracy: 0.7906\n","\n","Epoch 00339: val_accuracy did not improve from 0.92118\n","Epoch 340/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 1.1010 - val_accuracy: 0.8276\n","\n","Epoch 00340: val_accuracy did not improve from 0.92118\n","Epoch 341/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4564 - val_accuracy: 0.9039\n","\n","Epoch 00341: val_accuracy did not improve from 0.92118\n","Epoch 342/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5240 - val_accuracy: 0.9015\n","\n","Epoch 00342: val_accuracy did not improve from 0.92118\n","Epoch 343/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9261\n","\n","Epoch 00343: val_accuracy improved from 0.92118 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 344/500\n","52/52 [==============================] - 10s 198ms/step - loss: 5.6539e-04 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.9187\n","\n","Epoch 00344: val_accuracy did not improve from 0.92611\n","Epoch 345/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0082 - accuracy: 0.9957 - val_loss: 3.5787 - val_accuracy: 0.6552\n","\n","Epoch 00345: val_accuracy did not improve from 0.92611\n","Epoch 346/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.5195 - val_accuracy: 0.9138\n","\n","Epoch 00346: val_accuracy did not improve from 0.92611\n","Epoch 347/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.6553 - val_accuracy: 0.8768\n","\n","Epoch 00347: val_accuracy did not improve from 0.92611\n","Epoch 348/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.6781 - val_accuracy: 0.8867\n","\n","Epoch 00348: val_accuracy did not improve from 0.92611\n","Epoch 349/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.6495 - val_accuracy: 0.8768\n","\n","Epoch 00349: val_accuracy did not improve from 0.92611\n","Epoch 350/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 0.6046 - val_accuracy: 0.8867\n","\n","Epoch 00350: val_accuracy did not improve from 0.92611\n","Epoch 351/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6571 - val_accuracy: 0.8916\n","\n","Epoch 00351: val_accuracy did not improve from 0.92611\n","Epoch 352/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.6490 - val_accuracy: 0.8892\n","\n","Epoch 00352: val_accuracy did not improve from 0.92611\n","Epoch 353/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5711 - val_accuracy: 0.9064\n","\n","Epoch 00353: val_accuracy did not improve from 0.92611\n","Epoch 354/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.6250 - val_accuracy: 0.8867\n","\n","Epoch 00354: val_accuracy did not improve from 0.92611\n","Epoch 355/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.5817 - val_accuracy: 0.8941\n","\n","Epoch 00355: val_accuracy did not improve from 0.92611\n","Epoch 356/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 2.3175 - val_accuracy: 0.7463\n","\n","Epoch 00356: val_accuracy did not improve from 0.92611\n","Epoch 357/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0360 - accuracy: 0.9890 - val_loss: 28.6643 - val_accuracy: 0.1404\n","\n","Epoch 00357: val_accuracy did not improve from 0.92611\n","Epoch 358/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.1522 - accuracy: 0.9635 - val_loss: 7.2410 - val_accuracy: 0.5394\n","\n","Epoch 00358: val_accuracy did not improve from 0.92611\n","Epoch 359/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0569 - accuracy: 0.9829 - val_loss: 0.5849 - val_accuracy: 0.8842\n","\n","Epoch 00359: val_accuracy did not improve from 0.92611\n","Epoch 360/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.5534 - val_accuracy: 0.8867\n","\n","Epoch 00360: val_accuracy did not improve from 0.92611\n","Epoch 361/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.5402 - val_accuracy: 0.8892\n","\n","Epoch 00361: val_accuracy did not improve from 0.92611\n","Epoch 362/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.4426 - val_accuracy: 0.9138\n","\n","Epoch 00362: val_accuracy did not improve from 0.92611\n","Epoch 363/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4887 - val_accuracy: 0.9113\n","\n","Epoch 00363: val_accuracy did not improve from 0.92611\n","Epoch 364/500\n","52/52 [==============================] - 10s 201ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4505 - val_accuracy: 0.9089\n","\n","Epoch 00364: val_accuracy did not improve from 0.92611\n","Epoch 365/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.6353 - val_accuracy: 0.8941\n","\n","Epoch 00365: val_accuracy did not improve from 0.92611\n","Epoch 366/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5149 - val_accuracy: 0.9015\n","\n","Epoch 00366: val_accuracy did not improve from 0.92611\n","Epoch 367/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5035 - val_accuracy: 0.9039\n","\n","Epoch 00367: val_accuracy did not improve from 0.92611\n","Epoch 368/500\n","52/52 [==============================] - 10s 195ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.5310 - val_accuracy: 0.9015\n","\n","Epoch 00368: val_accuracy did not improve from 0.92611\n","Epoch 369/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5768 - val_accuracy: 0.8916\n","\n","Epoch 00369: val_accuracy did not improve from 0.92611\n","Epoch 370/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5624 - val_accuracy: 0.9039\n","\n","Epoch 00370: val_accuracy did not improve from 0.92611\n","Epoch 371/500\n","52/52 [==============================] - 10s 198ms/step - loss: 9.7955e-04 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.9113\n","\n","Epoch 00371: val_accuracy did not improve from 0.92611\n","Epoch 372/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.9236\n","\n","Epoch 00372: val_accuracy did not improve from 0.92611\n","Epoch 373/500\n","52/52 [==============================] - 10s 199ms/step - loss: 6.2350e-04 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.9138\n","\n","Epoch 00373: val_accuracy did not improve from 0.92611\n","Epoch 374/500\n","52/52 [==============================] - 10s 199ms/step - loss: 8.5521e-04 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9138\n","\n","Epoch 00374: val_accuracy did not improve from 0.92611\n","Epoch 375/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.5148 - val_accuracy: 0.9113\n","\n","Epoch 00375: val_accuracy did not improve from 0.92611\n","Epoch 376/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.6309 - val_accuracy: 0.8892\n","\n","Epoch 00376: val_accuracy did not improve from 0.92611\n","Epoch 377/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.6023 - val_accuracy: 0.9015\n","\n","Epoch 00377: val_accuracy did not improve from 0.92611\n","Epoch 378/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0076 - accuracy: 0.9963 - val_loss: 0.6419 - val_accuracy: 0.9138\n","\n","Epoch 00378: val_accuracy did not improve from 0.92611\n","Epoch 379/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 1.4103 - val_accuracy: 0.8276\n","\n","Epoch 00379: val_accuracy did not improve from 0.92611\n","Epoch 380/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0350 - accuracy: 0.9933 - val_loss: 0.7965 - val_accuracy: 0.8793\n","\n","Epoch 00380: val_accuracy did not improve from 0.92611\n","Epoch 381/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.7075 - val_accuracy: 0.8818\n","\n","Epoch 00381: val_accuracy did not improve from 0.92611\n","Epoch 382/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0225 - accuracy: 0.9909 - val_loss: 0.8711 - val_accuracy: 0.8571\n","\n","Epoch 00382: val_accuracy did not improve from 0.92611\n","Epoch 383/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0311 - accuracy: 0.9921 - val_loss: 0.7156 - val_accuracy: 0.8892\n","\n","Epoch 00383: val_accuracy did not improve from 0.92611\n","Epoch 384/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0472 - accuracy: 0.9860 - val_loss: 1.0115 - val_accuracy: 0.8498\n","\n","Epoch 00384: val_accuracy did not improve from 0.92611\n","Epoch 385/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0146 - accuracy: 0.9933 - val_loss: 0.9805 - val_accuracy: 0.8325\n","\n","Epoch 00385: val_accuracy did not improve from 0.92611\n","Epoch 386/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.8241 - val_accuracy: 0.8768\n","\n","Epoch 00386: val_accuracy did not improve from 0.92611\n","Epoch 387/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.5902 - val_accuracy: 0.9039\n","\n","Epoch 00387: val_accuracy did not improve from 0.92611\n","Epoch 388/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6246 - val_accuracy: 0.8842\n","\n","Epoch 00388: val_accuracy did not improve from 0.92611\n","Epoch 389/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5937 - val_accuracy: 0.9089\n","\n","Epoch 00389: val_accuracy did not improve from 0.92611\n","Epoch 390/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.6484 - val_accuracy: 0.8941\n","\n","Epoch 00390: val_accuracy did not improve from 0.92611\n","Epoch 391/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.6003 - val_accuracy: 0.8990\n","\n","Epoch 00391: val_accuracy did not improve from 0.92611\n","Epoch 392/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.5880 - val_accuracy: 0.8990\n","\n","Epoch 00392: val_accuracy did not improve from 0.92611\n","Epoch 393/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.5987 - val_accuracy: 0.8941\n","\n","Epoch 00393: val_accuracy did not improve from 0.92611\n","Epoch 394/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4471 - val_accuracy: 0.9138\n","\n","Epoch 00394: val_accuracy did not improve from 0.92611\n","Epoch 395/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.5735 - val_accuracy: 0.9015\n","\n","Epoch 00395: val_accuracy did not improve from 0.92611\n","Epoch 396/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.7131 - val_accuracy: 0.8695\n","\n","Epoch 00396: val_accuracy did not improve from 0.92611\n","Epoch 397/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0103 - accuracy: 0.9951 - val_loss: 0.7745 - val_accuracy: 0.8744\n","\n","Epoch 00397: val_accuracy did not improve from 0.92611\n","Epoch 398/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.5571 - val_accuracy: 0.8916\n","\n","Epoch 00398: val_accuracy did not improve from 0.92611\n","Epoch 399/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.7080 - val_accuracy: 0.9015\n","\n","Epoch 00399: val_accuracy did not improve from 0.92611\n","Epoch 400/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.6565 - val_accuracy: 0.8793\n","\n","Epoch 00400: val_accuracy did not improve from 0.92611\n","Epoch 401/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.7085 - val_accuracy: 0.8966\n","\n","Epoch 00401: val_accuracy did not improve from 0.92611\n","Epoch 402/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.8309 - val_accuracy: 0.8966\n","\n","Epoch 00402: val_accuracy did not improve from 0.92611\n","Epoch 403/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0548 - accuracy: 0.9829 - val_loss: 1.8662 - val_accuracy: 0.7512\n","\n","Epoch 00403: val_accuracy did not improve from 0.92611\n","Epoch 404/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0257 - accuracy: 0.9909 - val_loss: 10.8721 - val_accuracy: 0.4212\n","\n","Epoch 00404: val_accuracy did not improve from 0.92611\n","Epoch 405/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.6777 - val_accuracy: 0.8695\n","\n","Epoch 00405: val_accuracy did not improve from 0.92611\n","Epoch 406/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.7798 - val_accuracy: 0.8793\n","\n","Epoch 00406: val_accuracy did not improve from 0.92611\n","Epoch 407/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.6374 - val_accuracy: 0.8966\n","\n","Epoch 00407: val_accuracy did not improve from 0.92611\n","Epoch 408/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.4725 - val_accuracy: 0.9138\n","\n","Epoch 00408: val_accuracy did not improve from 0.92611\n","Epoch 409/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4786 - val_accuracy: 0.9113\n","\n","Epoch 00409: val_accuracy did not improve from 0.92611\n","Epoch 410/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5639 - val_accuracy: 0.9039\n","\n","Epoch 00410: val_accuracy did not improve from 0.92611\n","Epoch 411/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 0.5129 - val_accuracy: 0.9138\n","\n","Epoch 00411: val_accuracy did not improve from 0.92611\n","Epoch 412/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5165 - val_accuracy: 0.9064\n","\n","Epoch 00412: val_accuracy did not improve from 0.92611\n","Epoch 413/500\n","52/52 [==============================] - 10s 201ms/step - loss: 8.4575e-04 - accuracy: 1.0000 - val_loss: 0.5234 - val_accuracy: 0.9089\n","\n","Epoch 00413: val_accuracy did not improve from 0.92611\n","Epoch 414/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.9039\n","\n","Epoch 00414: val_accuracy did not improve from 0.92611\n","Epoch 415/500\n","52/52 [==============================] - 10s 197ms/step - loss: 7.8744e-04 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.8990\n","\n","Epoch 00415: val_accuracy did not improve from 0.92611\n","Epoch 416/500\n","52/52 [==============================] - 10s 196ms/step - loss: 4.6178e-04 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.9236\n","\n","Epoch 00416: val_accuracy did not improve from 0.92611\n","Epoch 417/500\n","52/52 [==============================] - 10s 197ms/step - loss: 3.3704e-04 - accuracy: 1.0000 - val_loss: 0.5162 - val_accuracy: 0.9113\n","\n","Epoch 00417: val_accuracy did not improve from 0.92611\n","Epoch 418/500\n","52/52 [==============================] - 10s 199ms/step - loss: 2.9973e-04 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.9138\n","\n","Epoch 00418: val_accuracy did not improve from 0.92611\n","Epoch 419/500\n","52/52 [==============================] - 10s 199ms/step - loss: 5.7292e-04 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.9015\n","\n","Epoch 00419: val_accuracy did not improve from 0.92611\n","Epoch 420/500\n","52/52 [==============================] - 10s 200ms/step - loss: 5.0475e-04 - accuracy: 1.0000 - val_loss: 0.5443 - val_accuracy: 0.9015\n","\n","Epoch 00420: val_accuracy did not improve from 0.92611\n","Epoch 421/500\n","52/52 [==============================] - 10s 197ms/step - loss: 5.5183e-04 - accuracy: 1.0000 - val_loss: 0.5372 - val_accuracy: 0.9113\n","\n","Epoch 00421: val_accuracy did not improve from 0.92611\n","Epoch 422/500\n","52/52 [==============================] - 10s 196ms/step - loss: 1.0579e-04 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.9163\n","\n","Epoch 00422: val_accuracy did not improve from 0.92611\n","Epoch 423/500\n","52/52 [==============================] - 10s 196ms/step - loss: 9.1299e-05 - accuracy: 1.0000 - val_loss: 0.5015 - val_accuracy: 0.9138\n","\n","Epoch 00423: val_accuracy did not improve from 0.92611\n","Epoch 424/500\n","52/52 [==============================] - 10s 197ms/step - loss: 2.1197e-04 - accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.9089\n","\n","Epoch 00424: val_accuracy did not improve from 0.92611\n","Epoch 425/500\n","52/52 [==============================] - 10s 199ms/step - loss: 2.8615e-04 - accuracy: 1.0000 - val_loss: 0.5156 - val_accuracy: 0.9039\n","\n","Epoch 00425: val_accuracy did not improve from 0.92611\n","Epoch 426/500\n","52/52 [==============================] - 10s 198ms/step - loss: 1.4219e-04 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.9163\n","\n","Epoch 00426: val_accuracy did not improve from 0.92611\n","Epoch 427/500\n","52/52 [==============================] - 10s 197ms/step - loss: 1.2275e-04 - accuracy: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.9187\n","\n","Epoch 00427: val_accuracy did not improve from 0.92611\n","Epoch 428/500\n","52/52 [==============================] - 10s 196ms/step - loss: 1.6771e-04 - accuracy: 1.0000 - val_loss: 0.4826 - val_accuracy: 0.9113\n","\n","Epoch 00428: val_accuracy did not improve from 0.92611\n","Epoch 429/500\n","52/52 [==============================] - 10s 198ms/step - loss: 3.8278e-04 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.9187\n","\n","Epoch 00429: val_accuracy did not improve from 0.92611\n","Epoch 430/500\n","52/52 [==============================] - 10s 197ms/step - loss: 3.6998e-04 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.9015\n","\n","Epoch 00430: val_accuracy did not improve from 0.92611\n","Epoch 431/500\n","52/52 [==============================] - 10s 199ms/step - loss: 3.3637e-04 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.9113\n","\n","Epoch 00431: val_accuracy did not improve from 0.92611\n","Epoch 432/500\n","52/52 [==============================] - 10s 200ms/step - loss: 2.9243e-04 - accuracy: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.9089\n","\n","Epoch 00432: val_accuracy did not improve from 0.92611\n","Epoch 433/500\n","52/52 [==============================] - 10s 198ms/step - loss: 1.3916e-04 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9163\n","\n","Epoch 00433: val_accuracy did not improve from 0.92611\n","Epoch 434/500\n","52/52 [==============================] - 10s 199ms/step - loss: 3.5326e-04 - accuracy: 1.0000 - val_loss: 0.5638 - val_accuracy: 0.9113\n","\n","Epoch 00434: val_accuracy did not improve from 0.92611\n","Epoch 435/500\n","52/52 [==============================] - 10s 200ms/step - loss: 8.4485e-05 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.9039\n","\n","Epoch 00435: val_accuracy did not improve from 0.92611\n","Epoch 436/500\n","52/52 [==============================] - 10s 198ms/step - loss: 3.4417e-04 - accuracy: 1.0000 - val_loss: 0.5789 - val_accuracy: 0.9039\n","\n","Epoch 00436: val_accuracy did not improve from 0.92611\n","Epoch 437/500\n","52/52 [==============================] - 10s 198ms/step - loss: 4.9169e-04 - accuracy: 1.0000 - val_loss: 0.5479 - val_accuracy: 0.9113\n","\n","Epoch 00437: val_accuracy did not improve from 0.92611\n","Epoch 438/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0049 - accuracy: 0.9970 - val_loss: 0.8915 - val_accuracy: 0.8793\n","\n","Epoch 00438: val_accuracy did not improve from 0.92611\n","Epoch 439/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.1447 - accuracy: 0.9635 - val_loss: 2.1874 - val_accuracy: 0.7611\n","\n","Epoch 00439: val_accuracy did not improve from 0.92611\n","Epoch 440/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0716 - accuracy: 0.9762 - val_loss: 0.9605 - val_accuracy: 0.8227\n","\n","Epoch 00440: val_accuracy did not improve from 0.92611\n","Epoch 441/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.8780 - val_accuracy: 0.8818\n","\n","Epoch 00441: val_accuracy did not improve from 0.92611\n","Epoch 442/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.6106 - val_accuracy: 0.8941\n","\n","Epoch 00442: val_accuracy did not improve from 0.92611\n","Epoch 443/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.5399 - val_accuracy: 0.8916\n","\n","Epoch 00443: val_accuracy did not improve from 0.92611\n","Epoch 444/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.6687 - val_accuracy: 0.8842\n","\n","Epoch 00444: val_accuracy did not improve from 0.92611\n","Epoch 445/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0098 - accuracy: 0.9957 - val_loss: 0.6415 - val_accuracy: 0.8892\n","\n","Epoch 00445: val_accuracy did not improve from 0.92611\n","Epoch 446/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0237 - accuracy: 0.9945 - val_loss: 0.5350 - val_accuracy: 0.9039\n","\n","Epoch 00446: val_accuracy did not improve from 0.92611\n","Epoch 447/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 1.0023 - val_accuracy: 0.8670\n","\n","Epoch 00447: val_accuracy did not improve from 0.92611\n","Epoch 448/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0483 - accuracy: 0.9896 - val_loss: 0.7107 - val_accuracy: 0.8818\n","\n","Epoch 00448: val_accuracy did not improve from 0.92611\n","Epoch 449/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0181 - accuracy: 0.9957 - val_loss: 0.6883 - val_accuracy: 0.8818\n","\n","Epoch 00449: val_accuracy did not improve from 0.92611\n","Epoch 450/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 0.6702 - val_accuracy: 0.8892\n","\n","Epoch 00450: val_accuracy did not improve from 0.92611\n","Epoch 451/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.7154 - val_accuracy: 0.9015\n","\n","Epoch 00451: val_accuracy did not improve from 0.92611\n","Epoch 452/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.6062 - val_accuracy: 0.9039\n","\n","Epoch 00452: val_accuracy did not improve from 0.92611\n","Epoch 453/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.5787 - val_accuracy: 0.9015\n","\n","Epoch 00453: val_accuracy did not improve from 0.92611\n","Epoch 454/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4763 - val_accuracy: 0.9236\n","\n","Epoch 00454: val_accuracy did not improve from 0.92611\n","Epoch 455/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5108 - val_accuracy: 0.8990\n","\n","Epoch 00455: val_accuracy did not improve from 0.92611\n","Epoch 456/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.9286\n","\n","Epoch 00456: val_accuracy improved from 0.92611 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5\n","Epoch 457/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5054 - val_accuracy: 0.8990\n","\n","Epoch 00457: val_accuracy did not improve from 0.92857\n","Epoch 458/500\n","52/52 [==============================] - 10s 200ms/step - loss: 7.5363e-04 - accuracy: 1.0000 - val_loss: 0.4895 - val_accuracy: 0.9261\n","\n","Epoch 00458: val_accuracy did not improve from 0.92857\n","Epoch 459/500\n","52/52 [==============================] - 10s 200ms/step - loss: 6.0678e-04 - accuracy: 1.0000 - val_loss: 0.5397 - val_accuracy: 0.9138\n","\n","Epoch 00459: val_accuracy did not improve from 0.92857\n","Epoch 460/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5785 - val_accuracy: 0.9138\n","\n","Epoch 00460: val_accuracy did not improve from 0.92857\n","Epoch 461/500\n","52/52 [==============================] - 11s 201ms/step - loss: 8.0242e-04 - accuracy: 1.0000 - val_loss: 0.5332 - val_accuracy: 0.9187\n","\n","Epoch 00461: val_accuracy did not improve from 0.92857\n","Epoch 462/500\n","52/52 [==============================] - 11s 200ms/step - loss: 4.5870e-04 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9138\n","\n","Epoch 00462: val_accuracy did not improve from 0.92857\n","Epoch 463/500\n","52/52 [==============================] - 10s 199ms/step - loss: 6.2476e-04 - accuracy: 1.0000 - val_loss: 0.5264 - val_accuracy: 0.9163\n","\n","Epoch 00463: val_accuracy did not improve from 0.92857\n","Epoch 464/500\n","52/52 [==============================] - 10s 198ms/step - loss: 3.2216e-04 - accuracy: 1.0000 - val_loss: 0.5409 - val_accuracy: 0.9113\n","\n","Epoch 00464: val_accuracy did not improve from 0.92857\n","Epoch 465/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5314 - val_accuracy: 0.9113\n","\n","Epoch 00465: val_accuracy did not improve from 0.92857\n","Epoch 466/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.6433 - val_accuracy: 0.8867\n","\n","Epoch 00466: val_accuracy did not improve from 0.92857\n","Epoch 467/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.7092 - val_accuracy: 0.8941\n","\n","Epoch 00467: val_accuracy did not improve from 0.92857\n","Epoch 468/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.7587 - val_accuracy: 0.8966\n","\n","Epoch 00468: val_accuracy did not improve from 0.92857\n","Epoch 469/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.5880 - val_accuracy: 0.9064\n","\n","Epoch 00469: val_accuracy did not improve from 0.92857\n","Epoch 470/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 0.6985 - val_accuracy: 0.8842\n","\n","Epoch 00470: val_accuracy did not improve from 0.92857\n","Epoch 471/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0095 - accuracy: 0.9957 - val_loss: 0.7186 - val_accuracy: 0.8990\n","\n","Epoch 00471: val_accuracy did not improve from 0.92857\n","Epoch 472/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0194 - accuracy: 0.9951 - val_loss: 0.6782 - val_accuracy: 0.8966\n","\n","Epoch 00472: val_accuracy did not improve from 0.92857\n","Epoch 473/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0331 - accuracy: 0.9915 - val_loss: 1.0071 - val_accuracy: 0.8645\n","\n","Epoch 00473: val_accuracy did not improve from 0.92857\n","Epoch 474/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0381 - accuracy: 0.9854 - val_loss: 0.7625 - val_accuracy: 0.8867\n","\n","Epoch 00474: val_accuracy did not improve from 0.92857\n","Epoch 475/500\n","52/52 [==============================] - 10s 200ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 1.2446 - val_accuracy: 0.8498\n","\n","Epoch 00475: val_accuracy did not improve from 0.92857\n","Epoch 476/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.8384 - val_accuracy: 0.9015\n","\n","Epoch 00476: val_accuracy did not improve from 0.92857\n","Epoch 477/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 1.1294 - val_accuracy: 0.8547\n","\n","Epoch 00477: val_accuracy did not improve from 0.92857\n","Epoch 478/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.7085 - val_accuracy: 0.8892\n","\n","Epoch 00478: val_accuracy did not improve from 0.92857\n","Epoch 479/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.5303 - val_accuracy: 0.9138\n","\n","Epoch 00479: val_accuracy did not improve from 0.92857\n","Epoch 480/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.6384 - val_accuracy: 0.9039\n","\n","Epoch 00480: val_accuracy did not improve from 0.92857\n","Epoch 481/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5995 - val_accuracy: 0.9138\n","\n","Epoch 00481: val_accuracy did not improve from 0.92857\n","Epoch 482/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.6473 - val_accuracy: 0.8966\n","\n","Epoch 00482: val_accuracy did not improve from 0.92857\n","Epoch 483/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.5011 - val_accuracy: 0.9113\n","\n","Epoch 00483: val_accuracy did not improve from 0.92857\n","Epoch 484/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5318 - val_accuracy: 0.9236\n","\n","Epoch 00484: val_accuracy did not improve from 0.92857\n","Epoch 485/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0343 - accuracy: 0.9909 - val_loss: 0.6703 - val_accuracy: 0.8867\n","\n","Epoch 00485: val_accuracy did not improve from 0.92857\n","Epoch 486/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.6913 - val_accuracy: 0.8867\n","\n","Epoch 00486: val_accuracy did not improve from 0.92857\n","Epoch 487/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.5560 - val_accuracy: 0.9015\n","\n","Epoch 00487: val_accuracy did not improve from 0.92857\n","Epoch 488/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.5423 - val_accuracy: 0.9138\n","\n","Epoch 00488: val_accuracy did not improve from 0.92857\n","Epoch 489/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0073 - accuracy: 0.9963 - val_loss: 0.6811 - val_accuracy: 0.9039\n","\n","Epoch 00489: val_accuracy did not improve from 0.92857\n","Epoch 490/500\n","52/52 [==============================] - 10s 197ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.7203 - val_accuracy: 0.8966\n","\n","Epoch 00490: val_accuracy did not improve from 0.92857\n","Epoch 491/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0072 - accuracy: 0.9963 - val_loss: 0.6964 - val_accuracy: 0.8793\n","\n","Epoch 00491: val_accuracy did not improve from 0.92857\n","Epoch 492/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.6193 - val_accuracy: 0.8916\n","\n","Epoch 00492: val_accuracy did not improve from 0.92857\n","Epoch 493/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.6050 - val_accuracy: 0.8941\n","\n","Epoch 00493: val_accuracy did not improve from 0.92857\n","Epoch 494/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0183 - accuracy: 0.9970 - val_loss: 0.6585 - val_accuracy: 0.8990\n","\n","Epoch 00494: val_accuracy did not improve from 0.92857\n","Epoch 495/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.7618 - val_accuracy: 0.8916\n","\n","Epoch 00495: val_accuracy did not improve from 0.92857\n","Epoch 496/500\n","52/52 [==============================] - 10s 199ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.5290 - val_accuracy: 0.9039\n","\n","Epoch 00496: val_accuracy did not improve from 0.92857\n","Epoch 497/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.8121 - val_accuracy: 0.8892\n","\n","Epoch 00497: val_accuracy did not improve from 0.92857\n","Epoch 498/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0147 - accuracy: 0.9939 - val_loss: 0.6716 - val_accuracy: 0.9138\n","\n","Epoch 00498: val_accuracy did not improve from 0.92857\n","Epoch 499/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5806 - val_accuracy: 0.9089\n","\n","Epoch 00499: val_accuracy did not improve from 0.92857\n","Epoch 500/500\n","52/52 [==============================] - 10s 198ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5459 - val_accuracy: 0.9089\n","\n","Epoch 00500: val_accuracy did not improve from 0.92857\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_52c9ca5d-1bf8-442e-a6b7-39d4f80b3cd9\", \"CVLC_07_ResNet50.h5\", 283826408)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"YJxUYksADFFc","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1628105735814,"user_tz":-540,"elapsed":8481520,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"5634eb06-3f76-41df-8aa2-724692f779cb"},"source":["ResNet101_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [ResNet101_checkpoint])\n","# files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.4471 - accuracy: 0.8496 - val_loss: 7.8791 - val_accuracy: 0.4951\n","\n","Epoch 00001: val_accuracy did not improve from 0.68473\n","Epoch 2/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.4460 - accuracy: 0.8477 - val_loss: 0.8524 - val_accuracy: 0.7512\n","\n","Epoch 00002: val_accuracy improved from 0.68473 to 0.75123, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 3/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.5400 - accuracy: 0.8149 - val_loss: 55.2909 - val_accuracy: 0.1576\n","\n","Epoch 00003: val_accuracy did not improve from 0.75123\n","Epoch 4/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.4981 - accuracy: 0.8350 - val_loss: 0.9006 - val_accuracy: 0.7512\n","\n","Epoch 00004: val_accuracy did not improve from 0.75123\n","Epoch 5/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.5351 - accuracy: 0.8252 - val_loss: 3.6638 - val_accuracy: 0.2906\n","\n","Epoch 00005: val_accuracy did not improve from 0.75123\n","Epoch 6/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.4579 - accuracy: 0.8392 - val_loss: 1.1796 - val_accuracy: 0.7192\n","\n","Epoch 00006: val_accuracy did not improve from 0.75123\n","Epoch 7/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.3161 - accuracy: 0.8898 - val_loss: 0.6059 - val_accuracy: 0.7980\n","\n","Epoch 00007: val_accuracy improved from 0.75123 to 0.79803, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 8/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.3315 - accuracy: 0.8952 - val_loss: 0.5203 - val_accuracy: 0.8424\n","\n","Epoch 00008: val_accuracy improved from 0.79803 to 0.84236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 9/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.3562 - accuracy: 0.8776 - val_loss: 0.4878 - val_accuracy: 0.8399\n","\n","Epoch 00009: val_accuracy did not improve from 0.84236\n","Epoch 10/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.2675 - accuracy: 0.9044 - val_loss: 0.5829 - val_accuracy: 0.8300\n","\n","Epoch 00010: val_accuracy did not improve from 0.84236\n","Epoch 11/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.2769 - accuracy: 0.9032 - val_loss: 11.3355 - val_accuracy: 0.2438\n","\n","Epoch 00011: val_accuracy did not improve from 0.84236\n","Epoch 12/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.4171 - accuracy: 0.8685 - val_loss: 5.2371 - val_accuracy: 0.3079\n","\n","Epoch 00012: val_accuracy did not improve from 0.84236\n","Epoch 13/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.3779 - accuracy: 0.8709 - val_loss: 3.4325 - val_accuracy: 0.4975\n","\n","Epoch 00013: val_accuracy did not improve from 0.84236\n","Epoch 14/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.2727 - accuracy: 0.9007 - val_loss: 0.6865 - val_accuracy: 0.8202\n","\n","Epoch 00014: val_accuracy did not improve from 0.84236\n","Epoch 15/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.2306 - accuracy: 0.9086 - val_loss: 0.9368 - val_accuracy: 0.7438\n","\n","Epoch 00015: val_accuracy did not improve from 0.84236\n","Epoch 16/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.2674 - accuracy: 0.9086 - val_loss: 1.4613 - val_accuracy: 0.6502\n","\n","Epoch 00016: val_accuracy did not improve from 0.84236\n","Epoch 17/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.2812 - accuracy: 0.8989 - val_loss: 0.5566 - val_accuracy: 0.8227\n","\n","Epoch 00017: val_accuracy did not improve from 0.84236\n","Epoch 18/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.2560 - accuracy: 0.9239 - val_loss: 0.5035 - val_accuracy: 0.8374\n","\n","Epoch 00018: val_accuracy did not improve from 0.84236\n","Epoch 19/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.2406 - accuracy: 0.9281 - val_loss: 0.6271 - val_accuracy: 0.8325\n","\n","Epoch 00019: val_accuracy did not improve from 0.84236\n","Epoch 20/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.2021 - accuracy: 0.9342 - val_loss: 1.2533 - val_accuracy: 0.7217\n","\n","Epoch 00020: val_accuracy did not improve from 0.84236\n","Epoch 21/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1560 - accuracy: 0.9495 - val_loss: 0.6991 - val_accuracy: 0.8054\n","\n","Epoch 00021: val_accuracy did not improve from 0.84236\n","Epoch 22/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.1972 - accuracy: 0.9312 - val_loss: 1.5859 - val_accuracy: 0.7414\n","\n","Epoch 00022: val_accuracy did not improve from 0.84236\n","Epoch 23/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.2149 - accuracy: 0.9330 - val_loss: 2.0879 - val_accuracy: 0.6798\n","\n","Epoch 00023: val_accuracy did not improve from 0.84236\n","Epoch 24/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.2145 - accuracy: 0.9269 - val_loss: 0.4478 - val_accuracy: 0.8719\n","\n","Epoch 00024: val_accuracy improved from 0.84236 to 0.87192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 25/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.1681 - accuracy: 0.9428 - val_loss: 0.5425 - val_accuracy: 0.8596\n","\n","Epoch 00025: val_accuracy did not improve from 0.87192\n","Epoch 26/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.2514 - accuracy: 0.9074 - val_loss: 3.2049 - val_accuracy: 0.4433\n","\n","Epoch 00026: val_accuracy did not improve from 0.87192\n","Epoch 27/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.2187 - accuracy: 0.9214 - val_loss: 0.6134 - val_accuracy: 0.8374\n","\n","Epoch 00027: val_accuracy did not improve from 0.87192\n","Epoch 28/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.1516 - accuracy: 0.9421 - val_loss: 0.5595 - val_accuracy: 0.8522\n","\n","Epoch 00028: val_accuracy did not improve from 0.87192\n","Epoch 29/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.1538 - accuracy: 0.9519 - val_loss: 0.6638 - val_accuracy: 0.8498\n","\n","Epoch 00029: val_accuracy did not improve from 0.87192\n","Epoch 30/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.2308 - accuracy: 0.9220 - val_loss: 39.9146 - val_accuracy: 0.1576\n","\n","Epoch 00030: val_accuracy did not improve from 0.87192\n","Epoch 31/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.2593 - accuracy: 0.9074 - val_loss: 0.9761 - val_accuracy: 0.7882\n","\n","Epoch 00031: val_accuracy did not improve from 0.87192\n","Epoch 32/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.2366 - accuracy: 0.9245 - val_loss: 3.4532 - val_accuracy: 0.4926\n","\n","Epoch 00032: val_accuracy did not improve from 0.87192\n","Epoch 33/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1893 - accuracy: 0.9330 - val_loss: 3.5007 - val_accuracy: 0.6034\n","\n","Epoch 00033: val_accuracy did not improve from 0.87192\n","Epoch 34/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.2253 - accuracy: 0.9257 - val_loss: 1.8045 - val_accuracy: 0.7512\n","\n","Epoch 00034: val_accuracy did not improve from 0.87192\n","Epoch 35/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.2542 - accuracy: 0.9099 - val_loss: 0.7268 - val_accuracy: 0.8473\n","\n","Epoch 00035: val_accuracy did not improve from 0.87192\n","Epoch 36/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.2596 - accuracy: 0.9099 - val_loss: 5.6337 - val_accuracy: 0.3818\n","\n","Epoch 00036: val_accuracy did not improve from 0.87192\n","Epoch 37/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1907 - accuracy: 0.9306 - val_loss: 0.4842 - val_accuracy: 0.8547\n","\n","Epoch 00037: val_accuracy did not improve from 0.87192\n","Epoch 38/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.2174 - accuracy: 0.9227 - val_loss: 0.6405 - val_accuracy: 0.8325\n","\n","Epoch 00038: val_accuracy did not improve from 0.87192\n","Epoch 39/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.1843 - accuracy: 0.9415 - val_loss: 0.6524 - val_accuracy: 0.8498\n","\n","Epoch 00039: val_accuracy did not improve from 0.87192\n","Epoch 40/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1234 - accuracy: 0.9562 - val_loss: 0.6427 - val_accuracy: 0.8399\n","\n","Epoch 00040: val_accuracy did not improve from 0.87192\n","Epoch 41/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1522 - accuracy: 0.9440 - val_loss: 0.9592 - val_accuracy: 0.8005\n","\n","Epoch 00041: val_accuracy did not improve from 0.87192\n","Epoch 42/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1530 - accuracy: 0.9495 - val_loss: 2.5204 - val_accuracy: 0.5985\n","\n","Epoch 00042: val_accuracy did not improve from 0.87192\n","Epoch 43/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.1113 - accuracy: 0.9592 - val_loss: 0.5495 - val_accuracy: 0.8719\n","\n","Epoch 00043: val_accuracy did not improve from 0.87192\n","Epoch 44/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1160 - accuracy: 0.9629 - val_loss: 0.6536 - val_accuracy: 0.8719\n","\n","Epoch 00044: val_accuracy did not improve from 0.87192\n","Epoch 45/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.0951 - accuracy: 0.9653 - val_loss: 0.6075 - val_accuracy: 0.8498\n","\n","Epoch 00045: val_accuracy did not improve from 0.87192\n","Epoch 46/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0892 - accuracy: 0.9622 - val_loss: 1.5491 - val_accuracy: 0.7340\n","\n","Epoch 00046: val_accuracy did not improve from 0.87192\n","Epoch 47/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1482 - accuracy: 0.9488 - val_loss: 0.7215 - val_accuracy: 0.8350\n","\n","Epoch 00047: val_accuracy did not improve from 0.87192\n","Epoch 48/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.1400 - accuracy: 0.9507 - val_loss: 0.6328 - val_accuracy: 0.8645\n","\n","Epoch 00048: val_accuracy did not improve from 0.87192\n","Epoch 49/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.1114 - accuracy: 0.9598 - val_loss: 0.6058 - val_accuracy: 0.8670\n","\n","Epoch 00049: val_accuracy did not improve from 0.87192\n","Epoch 50/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.1377 - accuracy: 0.9580 - val_loss: 0.6104 - val_accuracy: 0.8596\n","\n","Epoch 00050: val_accuracy did not improve from 0.87192\n","Epoch 51/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.1387 - accuracy: 0.9568 - val_loss: 0.5783 - val_accuracy: 0.8522\n","\n","Epoch 00051: val_accuracy did not improve from 0.87192\n","Epoch 52/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1104 - accuracy: 0.9616 - val_loss: 0.3999 - val_accuracy: 0.8768\n","\n","Epoch 00052: val_accuracy improved from 0.87192 to 0.87685, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 53/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.1465 - accuracy: 0.9495 - val_loss: 0.6541 - val_accuracy: 0.8424\n","\n","Epoch 00053: val_accuracy did not improve from 0.87685\n","Epoch 54/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.1130 - accuracy: 0.9616 - val_loss: 0.5371 - val_accuracy: 0.8350\n","\n","Epoch 00054: val_accuracy did not improve from 0.87685\n","Epoch 55/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1624 - accuracy: 0.9470 - val_loss: 0.6270 - val_accuracy: 0.8473\n","\n","Epoch 00055: val_accuracy did not improve from 0.87685\n","Epoch 56/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1723 - accuracy: 0.9409 - val_loss: 0.9322 - val_accuracy: 0.8202\n","\n","Epoch 00056: val_accuracy did not improve from 0.87685\n","Epoch 57/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1379 - accuracy: 0.9519 - val_loss: 0.4775 - val_accuracy: 0.8867\n","\n","Epoch 00057: val_accuracy improved from 0.87685 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 58/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0467 - accuracy: 0.9866 - val_loss: 0.4523 - val_accuracy: 0.8966\n","\n","Epoch 00058: val_accuracy improved from 0.88670 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 59/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0489 - accuracy: 0.9829 - val_loss: 1.3813 - val_accuracy: 0.7463\n","\n","Epoch 00059: val_accuracy did not improve from 0.89655\n","Epoch 60/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0757 - accuracy: 0.9726 - val_loss: 0.4512 - val_accuracy: 0.8892\n","\n","Epoch 00060: val_accuracy did not improve from 0.89655\n","Epoch 61/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0956 - accuracy: 0.9659 - val_loss: 0.8316 - val_accuracy: 0.8202\n","\n","Epoch 00061: val_accuracy did not improve from 0.89655\n","Epoch 62/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1175 - accuracy: 0.9629 - val_loss: 0.6890 - val_accuracy: 0.8547\n","\n","Epoch 00062: val_accuracy did not improve from 0.89655\n","Epoch 63/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0959 - accuracy: 0.9635 - val_loss: 0.4140 - val_accuracy: 0.8941\n","\n","Epoch 00063: val_accuracy did not improve from 0.89655\n","Epoch 64/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0704 - accuracy: 0.9793 - val_loss: 0.4796 - val_accuracy: 0.8719\n","\n","Epoch 00064: val_accuracy did not improve from 0.89655\n","Epoch 65/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1101 - accuracy: 0.9653 - val_loss: 0.6104 - val_accuracy: 0.8621\n","\n","Epoch 00065: val_accuracy did not improve from 0.89655\n","Epoch 66/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.1002 - accuracy: 0.9622 - val_loss: 0.5801 - val_accuracy: 0.8621\n","\n","Epoch 00066: val_accuracy did not improve from 0.89655\n","Epoch 67/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0841 - accuracy: 0.9695 - val_loss: 0.6115 - val_accuracy: 0.8522\n","\n","Epoch 00067: val_accuracy did not improve from 0.89655\n","Epoch 68/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.1149 - accuracy: 0.9641 - val_loss: 0.6282 - val_accuracy: 0.8645\n","\n","Epoch 00068: val_accuracy did not improve from 0.89655\n","Epoch 69/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0869 - accuracy: 0.9714 - val_loss: 0.5617 - val_accuracy: 0.8842\n","\n","Epoch 00069: val_accuracy did not improve from 0.89655\n","Epoch 70/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.1419 - accuracy: 0.9488 - val_loss: 1.4936 - val_accuracy: 0.7241\n","\n","Epoch 00070: val_accuracy did not improve from 0.89655\n","Epoch 71/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0840 - accuracy: 0.9683 - val_loss: 0.4861 - val_accuracy: 0.8892\n","\n","Epoch 00071: val_accuracy did not improve from 0.89655\n","Epoch 72/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.0539 - accuracy: 0.9793 - val_loss: 0.5206 - val_accuracy: 0.8670\n","\n","Epoch 00072: val_accuracy did not improve from 0.89655\n","Epoch 73/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.0890 - accuracy: 0.9732 - val_loss: 0.7086 - val_accuracy: 0.8522\n","\n","Epoch 00073: val_accuracy did not improve from 0.89655\n","Epoch 74/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0649 - accuracy: 0.9799 - val_loss: 0.7918 - val_accuracy: 0.8424\n","\n","Epoch 00074: val_accuracy did not improve from 0.89655\n","Epoch 75/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0660 - accuracy: 0.9781 - val_loss: 0.5122 - val_accuracy: 0.8867\n","\n","Epoch 00075: val_accuracy did not improve from 0.89655\n","Epoch 76/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1092 - accuracy: 0.9616 - val_loss: 0.7108 - val_accuracy: 0.8350\n","\n","Epoch 00076: val_accuracy did not improve from 0.89655\n","Epoch 77/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0689 - accuracy: 0.9762 - val_loss: 0.6924 - val_accuracy: 0.8571\n","\n","Epoch 00077: val_accuracy did not improve from 0.89655\n","Epoch 78/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0893 - accuracy: 0.9677 - val_loss: 0.7838 - val_accuracy: 0.8251\n","\n","Epoch 00078: val_accuracy did not improve from 0.89655\n","Epoch 79/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0705 - accuracy: 0.9756 - val_loss: 0.5929 - val_accuracy: 0.8522\n","\n","Epoch 00079: val_accuracy did not improve from 0.89655\n","Epoch 80/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0674 - accuracy: 0.9775 - val_loss: 0.5628 - val_accuracy: 0.8941\n","\n","Epoch 00080: val_accuracy did not improve from 0.89655\n","Epoch 81/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.1021 - accuracy: 0.9616 - val_loss: 1.0656 - val_accuracy: 0.7931\n","\n","Epoch 00081: val_accuracy did not improve from 0.89655\n","Epoch 82/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0794 - accuracy: 0.9756 - val_loss: 0.9424 - val_accuracy: 0.8473\n","\n","Epoch 00082: val_accuracy did not improve from 0.89655\n","Epoch 83/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0937 - accuracy: 0.9695 - val_loss: 0.6080 - val_accuracy: 0.8571\n","\n","Epoch 00083: val_accuracy did not improve from 0.89655\n","Epoch 84/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0718 - accuracy: 0.9799 - val_loss: 0.5010 - val_accuracy: 0.8892\n","\n","Epoch 00084: val_accuracy did not improve from 0.89655\n","Epoch 85/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0504 - accuracy: 0.9829 - val_loss: 0.5480 - val_accuracy: 0.8744\n","\n","Epoch 00085: val_accuracy did not improve from 0.89655\n","Epoch 86/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.1032 - accuracy: 0.9647 - val_loss: 0.7289 - val_accuracy: 0.8571\n","\n","Epoch 00086: val_accuracy did not improve from 0.89655\n","Epoch 87/500\n","52/52 [==============================] - 17s 316ms/step - loss: 0.0618 - accuracy: 0.9769 - val_loss: 0.5488 - val_accuracy: 0.8966\n","\n","Epoch 00087: val_accuracy did not improve from 0.89655\n","Epoch 88/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0773 - accuracy: 0.9641 - val_loss: 0.6996 - val_accuracy: 0.8399\n","\n","Epoch 00088: val_accuracy did not improve from 0.89655\n","Epoch 89/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0769 - accuracy: 0.9708 - val_loss: 0.8104 - val_accuracy: 0.8251\n","\n","Epoch 00089: val_accuracy did not improve from 0.89655\n","Epoch 90/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0966 - accuracy: 0.9695 - val_loss: 1.1677 - val_accuracy: 0.8128\n","\n","Epoch 00090: val_accuracy did not improve from 0.89655\n","Epoch 91/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0646 - accuracy: 0.9787 - val_loss: 0.6780 - val_accuracy: 0.8768\n","\n","Epoch 00091: val_accuracy did not improve from 0.89655\n","Epoch 92/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0994 - accuracy: 0.9702 - val_loss: 2.0049 - val_accuracy: 0.7463\n","\n","Epoch 00092: val_accuracy did not improve from 0.89655\n","Epoch 93/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.1424 - accuracy: 0.9513 - val_loss: 0.8216 - val_accuracy: 0.8300\n","\n","Epoch 00093: val_accuracy did not improve from 0.89655\n","Epoch 94/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0908 - accuracy: 0.9683 - val_loss: 0.5843 - val_accuracy: 0.8719\n","\n","Epoch 00094: val_accuracy did not improve from 0.89655\n","Epoch 95/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.0600 - accuracy: 0.9781 - val_loss: 0.4296 - val_accuracy: 0.8793\n","\n","Epoch 00095: val_accuracy did not improve from 0.89655\n","Epoch 96/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0334 - accuracy: 0.9896 - val_loss: 0.4370 - val_accuracy: 0.8892\n","\n","Epoch 00096: val_accuracy did not improve from 0.89655\n","Epoch 97/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0591 - accuracy: 0.9823 - val_loss: 2.1279 - val_accuracy: 0.7512\n","\n","Epoch 00097: val_accuracy did not improve from 0.89655\n","Epoch 98/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.2328 - accuracy: 0.9373 - val_loss: 0.7613 - val_accuracy: 0.8424\n","\n","Epoch 00098: val_accuracy did not improve from 0.89655\n","Epoch 99/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.0874 - accuracy: 0.9683 - val_loss: 0.4821 - val_accuracy: 0.8768\n","\n","Epoch 00099: val_accuracy did not improve from 0.89655\n","Epoch 100/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0570 - accuracy: 0.9817 - val_loss: 0.4436 - val_accuracy: 0.8867\n","\n","Epoch 00100: val_accuracy did not improve from 0.89655\n","Epoch 101/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0321 - accuracy: 0.9860 - val_loss: 0.4053 - val_accuracy: 0.9015\n","\n","Epoch 00101: val_accuracy improved from 0.89655 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 102/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.5770 - val_accuracy: 0.8621\n","\n","Epoch 00102: val_accuracy did not improve from 0.90148\n","Epoch 103/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0274 - accuracy: 0.9896 - val_loss: 0.4906 - val_accuracy: 0.8793\n","\n","Epoch 00103: val_accuracy did not improve from 0.90148\n","Epoch 104/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1367 - accuracy: 0.9586 - val_loss: 0.9898 - val_accuracy: 0.8251\n","\n","Epoch 00104: val_accuracy did not improve from 0.90148\n","Epoch 105/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0510 - accuracy: 0.9817 - val_loss: 0.4675 - val_accuracy: 0.8892\n","\n","Epoch 00105: val_accuracy did not improve from 0.90148\n","Epoch 106/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0345 - accuracy: 0.9896 - val_loss: 0.4667 - val_accuracy: 0.8966\n","\n","Epoch 00106: val_accuracy did not improve from 0.90148\n","Epoch 107/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0248 - accuracy: 0.9909 - val_loss: 0.4674 - val_accuracy: 0.8941\n","\n","Epoch 00107: val_accuracy did not improve from 0.90148\n","Epoch 108/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.5310 - val_accuracy: 0.9015\n","\n","Epoch 00108: val_accuracy did not improve from 0.90148\n","Epoch 109/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0818 - accuracy: 0.9756 - val_loss: 1.0894 - val_accuracy: 0.7980\n","\n","Epoch 00109: val_accuracy did not improve from 0.90148\n","Epoch 110/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0694 - accuracy: 0.9732 - val_loss: 0.8683 - val_accuracy: 0.8325\n","\n","Epoch 00110: val_accuracy did not improve from 0.90148\n","Epoch 111/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.1061 - accuracy: 0.9671 - val_loss: 0.4780 - val_accuracy: 0.8695\n","\n","Epoch 00111: val_accuracy did not improve from 0.90148\n","Epoch 112/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.1204 - accuracy: 0.9616 - val_loss: 9.6550 - val_accuracy: 0.3941\n","\n","Epoch 00112: val_accuracy did not improve from 0.90148\n","Epoch 113/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0966 - accuracy: 0.9708 - val_loss: 1.8856 - val_accuracy: 0.7020\n","\n","Epoch 00113: val_accuracy did not improve from 0.90148\n","Epoch 114/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0583 - accuracy: 0.9793 - val_loss: 0.9007 - val_accuracy: 0.8177\n","\n","Epoch 00114: val_accuracy did not improve from 0.90148\n","Epoch 115/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0663 - accuracy: 0.9769 - val_loss: 0.5767 - val_accuracy: 0.8842\n","\n","Epoch 00115: val_accuracy did not improve from 0.90148\n","Epoch 116/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0498 - accuracy: 0.9829 - val_loss: 0.5449 - val_accuracy: 0.8916\n","\n","Epoch 00116: val_accuracy did not improve from 0.90148\n","Epoch 117/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0375 - accuracy: 0.9872 - val_loss: 0.6280 - val_accuracy: 0.8719\n","\n","Epoch 00117: val_accuracy did not improve from 0.90148\n","Epoch 118/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.6277 - val_accuracy: 0.8966\n","\n","Epoch 00118: val_accuracy did not improve from 0.90148\n","Epoch 119/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0206 - accuracy: 0.9921 - val_loss: 0.5737 - val_accuracy: 0.8892\n","\n","Epoch 00119: val_accuracy did not improve from 0.90148\n","Epoch 120/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0245 - accuracy: 0.9909 - val_loss: 0.6245 - val_accuracy: 0.8842\n","\n","Epoch 00120: val_accuracy did not improve from 0.90148\n","Epoch 121/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0974 - accuracy: 0.9695 - val_loss: 6.7022 - val_accuracy: 0.6355\n","\n","Epoch 00121: val_accuracy did not improve from 0.90148\n","Epoch 122/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1227 - accuracy: 0.9586 - val_loss: 4.6932 - val_accuracy: 0.6650\n","\n","Epoch 00122: val_accuracy did not improve from 0.90148\n","Epoch 123/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.1357 - accuracy: 0.9598 - val_loss: 0.5676 - val_accuracy: 0.8695\n","\n","Epoch 00123: val_accuracy did not improve from 0.90148\n","Epoch 124/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.1013 - accuracy: 0.9720 - val_loss: 1.1862 - val_accuracy: 0.7611\n","\n","Epoch 00124: val_accuracy did not improve from 0.90148\n","Epoch 125/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0932 - accuracy: 0.9659 - val_loss: 0.9107 - val_accuracy: 0.8005\n","\n","Epoch 00125: val_accuracy did not improve from 0.90148\n","Epoch 126/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0532 - accuracy: 0.9762 - val_loss: 0.9693 - val_accuracy: 0.8473\n","\n","Epoch 00126: val_accuracy did not improve from 0.90148\n","Epoch 127/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0740 - accuracy: 0.9762 - val_loss: 0.6165 - val_accuracy: 0.8596\n","\n","Epoch 00127: val_accuracy did not improve from 0.90148\n","Epoch 128/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0538 - accuracy: 0.9848 - val_loss: 0.5585 - val_accuracy: 0.8916\n","\n","Epoch 00128: val_accuracy did not improve from 0.90148\n","Epoch 129/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.5279 - val_accuracy: 0.8966\n","\n","Epoch 00129: val_accuracy did not improve from 0.90148\n","Epoch 130/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.4932 - val_accuracy: 0.9089\n","\n","Epoch 00130: val_accuracy improved from 0.90148 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 131/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.5216 - val_accuracy: 0.8695\n","\n","Epoch 00131: val_accuracy did not improve from 0.90887\n","Epoch 132/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0596 - accuracy: 0.9775 - val_loss: 0.8560 - val_accuracy: 0.8448\n","\n","Epoch 00132: val_accuracy did not improve from 0.90887\n","Epoch 133/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0553 - accuracy: 0.9793 - val_loss: 0.7262 - val_accuracy: 0.8719\n","\n","Epoch 00133: val_accuracy did not improve from 0.90887\n","Epoch 134/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0505 - accuracy: 0.9848 - val_loss: 0.9009 - val_accuracy: 0.8596\n","\n","Epoch 00134: val_accuracy did not improve from 0.90887\n","Epoch 135/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0416 - accuracy: 0.9872 - val_loss: 0.8062 - val_accuracy: 0.8522\n","\n","Epoch 00135: val_accuracy did not improve from 0.90887\n","Epoch 136/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0388 - accuracy: 0.9872 - val_loss: 0.4501 - val_accuracy: 0.8867\n","\n","Epoch 00136: val_accuracy did not improve from 0.90887\n","Epoch 137/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0495 - accuracy: 0.9842 - val_loss: 0.8133 - val_accuracy: 0.8473\n","\n","Epoch 00137: val_accuracy did not improve from 0.90887\n","Epoch 138/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0472 - accuracy: 0.9848 - val_loss: 0.7792 - val_accuracy: 0.8719\n","\n","Epoch 00138: val_accuracy did not improve from 0.90887\n","Epoch 139/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0490 - accuracy: 0.9836 - val_loss: 0.8076 - val_accuracy: 0.8399\n","\n","Epoch 00139: val_accuracy did not improve from 0.90887\n","Epoch 140/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.4537 - val_accuracy: 0.8990\n","\n","Epoch 00140: val_accuracy did not improve from 0.90887\n","Epoch 141/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.3998 - val_accuracy: 0.9089\n","\n","Epoch 00141: val_accuracy did not improve from 0.90887\n","Epoch 142/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0290 - accuracy: 0.9878 - val_loss: 0.6519 - val_accuracy: 0.8867\n","\n","Epoch 00142: val_accuracy did not improve from 0.90887\n","Epoch 143/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0273 - accuracy: 0.9909 - val_loss: 0.6416 - val_accuracy: 0.8719\n","\n","Epoch 00143: val_accuracy did not improve from 0.90887\n","Epoch 144/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0529 - accuracy: 0.9842 - val_loss: 8.5139 - val_accuracy: 0.3768\n","\n","Epoch 00144: val_accuracy did not improve from 0.90887\n","Epoch 145/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0427 - accuracy: 0.9854 - val_loss: 0.7489 - val_accuracy: 0.8892\n","\n","Epoch 00145: val_accuracy did not improve from 0.90887\n","Epoch 146/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.8840 - val_accuracy: 0.8448\n","\n","Epoch 00146: val_accuracy did not improve from 0.90887\n","Epoch 147/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0332 - accuracy: 0.9872 - val_loss: 2.1875 - val_accuracy: 0.6724\n","\n","Epoch 00147: val_accuracy did not improve from 0.90887\n","Epoch 148/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0533 - accuracy: 0.9781 - val_loss: 1.2429 - val_accuracy: 0.8103\n","\n","Epoch 00148: val_accuracy did not improve from 0.90887\n","Epoch 149/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0625 - accuracy: 0.9799 - val_loss: 0.8189 - val_accuracy: 0.8695\n","\n","Epoch 00149: val_accuracy did not improve from 0.90887\n","Epoch 150/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0587 - accuracy: 0.9775 - val_loss: 0.6947 - val_accuracy: 0.8768\n","\n","Epoch 00150: val_accuracy did not improve from 0.90887\n","Epoch 151/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.1188 - accuracy: 0.9616 - val_loss: 0.8082 - val_accuracy: 0.8498\n","\n","Epoch 00151: val_accuracy did not improve from 0.90887\n","Epoch 152/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0311 - accuracy: 0.9884 - val_loss: 0.6156 - val_accuracy: 0.8670\n","\n","Epoch 00152: val_accuracy did not improve from 0.90887\n","Epoch 153/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 0.5918 - val_accuracy: 0.8990\n","\n","Epoch 00153: val_accuracy did not improve from 0.90887\n","Epoch 154/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0420 - accuracy: 0.9866 - val_loss: 0.5547 - val_accuracy: 0.8768\n","\n","Epoch 00154: val_accuracy did not improve from 0.90887\n","Epoch 155/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0301 - accuracy: 0.9903 - val_loss: 0.5790 - val_accuracy: 0.8916\n","\n","Epoch 00155: val_accuracy did not improve from 0.90887\n","Epoch 156/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.3923 - val_accuracy: 0.9138\n","\n","Epoch 00156: val_accuracy improved from 0.90887 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 157/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4384 - val_accuracy: 0.9113\n","\n","Epoch 00157: val_accuracy did not improve from 0.91379\n","Epoch 158/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.4249 - val_accuracy: 0.9138\n","\n","Epoch 00158: val_accuracy did not improve from 0.91379\n","Epoch 159/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0254 - accuracy: 0.9890 - val_loss: 0.7671 - val_accuracy: 0.8695\n","\n","Epoch 00159: val_accuracy did not improve from 0.91379\n","Epoch 160/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0684 - accuracy: 0.9799 - val_loss: 1.1710 - val_accuracy: 0.8030\n","\n","Epoch 00160: val_accuracy did not improve from 0.91379\n","Epoch 161/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.1523 - accuracy: 0.9586 - val_loss: 29.5237 - val_accuracy: 0.1478\n","\n","Epoch 00161: val_accuracy did not improve from 0.91379\n","Epoch 162/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.1009 - accuracy: 0.9641 - val_loss: 14.8375 - val_accuracy: 0.2020\n","\n","Epoch 00162: val_accuracy did not improve from 0.91379\n","Epoch 163/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0969 - accuracy: 0.9659 - val_loss: 10.3966 - val_accuracy: 0.3399\n","\n","Epoch 00163: val_accuracy did not improve from 0.91379\n","Epoch 164/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0626 - accuracy: 0.9811 - val_loss: 0.7217 - val_accuracy: 0.8571\n","\n","Epoch 00164: val_accuracy did not improve from 0.91379\n","Epoch 165/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.4706 - val_accuracy: 0.8867\n","\n","Epoch 00165: val_accuracy did not improve from 0.91379\n","Epoch 166/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 0.3927 - val_accuracy: 0.9015\n","\n","Epoch 00166: val_accuracy did not improve from 0.91379\n","Epoch 167/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 0.5436 - val_accuracy: 0.8793\n","\n","Epoch 00167: val_accuracy did not improve from 0.91379\n","Epoch 168/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.4572 - val_accuracy: 0.9138\n","\n","Epoch 00168: val_accuracy did not improve from 0.91379\n","Epoch 169/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0233 - accuracy: 0.9945 - val_loss: 0.4387 - val_accuracy: 0.8966\n","\n","Epoch 00169: val_accuracy did not improve from 0.91379\n","Epoch 170/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0270 - accuracy: 0.9927 - val_loss: 2.6852 - val_accuracy: 0.7044\n","\n","Epoch 00170: val_accuracy did not improve from 0.91379\n","Epoch 171/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.7338 - val_accuracy: 0.8768\n","\n","Epoch 00171: val_accuracy did not improve from 0.91379\n","Epoch 172/500\n","52/52 [==============================] - 17s 317ms/step - loss: 0.0337 - accuracy: 0.9903 - val_loss: 0.5616 - val_accuracy: 0.8867\n","\n","Epoch 00172: val_accuracy did not improve from 0.91379\n","Epoch 173/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 0.6338 - val_accuracy: 0.8892\n","\n","Epoch 00173: val_accuracy did not improve from 0.91379\n","Epoch 174/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0375 - accuracy: 0.9915 - val_loss: 0.6991 - val_accuracy: 0.8744\n","\n","Epoch 00174: val_accuracy did not improve from 0.91379\n","Epoch 175/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.4279 - val_accuracy: 0.9064\n","\n","Epoch 00175: val_accuracy did not improve from 0.91379\n","Epoch 176/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0381 - accuracy: 0.9866 - val_loss: 0.6261 - val_accuracy: 0.8695\n","\n","Epoch 00176: val_accuracy did not improve from 0.91379\n","Epoch 177/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0793 - accuracy: 0.9738 - val_loss: 0.7847 - val_accuracy: 0.8596\n","\n","Epoch 00177: val_accuracy did not improve from 0.91379\n","Epoch 178/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0286 - accuracy: 0.9896 - val_loss: 0.6869 - val_accuracy: 0.8670\n","\n","Epoch 00178: val_accuracy did not improve from 0.91379\n","Epoch 179/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0398 - accuracy: 0.9848 - val_loss: 0.6235 - val_accuracy: 0.8818\n","\n","Epoch 00179: val_accuracy did not improve from 0.91379\n","Epoch 180/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0560 - accuracy: 0.9842 - val_loss: 0.7161 - val_accuracy: 0.8547\n","\n","Epoch 00180: val_accuracy did not improve from 0.91379\n","Epoch 181/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0557 - accuracy: 0.9823 - val_loss: 0.7484 - val_accuracy: 0.8793\n","\n","Epoch 00181: val_accuracy did not improve from 0.91379\n","Epoch 182/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.5122 - val_accuracy: 0.8892\n","\n","Epoch 00182: val_accuracy did not improve from 0.91379\n","Epoch 183/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.5012 - val_accuracy: 0.8966\n","\n","Epoch 00183: val_accuracy did not improve from 0.91379\n","Epoch 184/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.6360 - val_accuracy: 0.9015\n","\n","Epoch 00184: val_accuracy did not improve from 0.91379\n","Epoch 185/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.5149 - val_accuracy: 0.9015\n","\n","Epoch 00185: val_accuracy did not improve from 0.91379\n","Epoch 186/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.4823 - val_accuracy: 0.9163\n","\n","Epoch 00186: val_accuracy improved from 0.91379 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 187/500\n","52/52 [==============================] - 17s 325ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.4488 - val_accuracy: 0.9138\n","\n","Epoch 00187: val_accuracy did not improve from 0.91626\n","Epoch 188/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.7644 - val_accuracy: 0.8842\n","\n","Epoch 00188: val_accuracy did not improve from 0.91626\n","Epoch 189/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0122 - accuracy: 0.9939 - val_loss: 0.7128 - val_accuracy: 0.8892\n","\n","Epoch 00189: val_accuracy did not improve from 0.91626\n","Epoch 190/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.5109 - val_accuracy: 0.9039\n","\n","Epoch 00190: val_accuracy did not improve from 0.91626\n","Epoch 191/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0418 - accuracy: 0.9878 - val_loss: 0.5708 - val_accuracy: 0.8916\n","\n","Epoch 00191: val_accuracy did not improve from 0.91626\n","Epoch 192/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.1182 - accuracy: 0.9683 - val_loss: 1.9404 - val_accuracy: 0.7709\n","\n","Epoch 00192: val_accuracy did not improve from 0.91626\n","Epoch 193/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0681 - accuracy: 0.9750 - val_loss: 0.8250 - val_accuracy: 0.8498\n","\n","Epoch 00193: val_accuracy did not improve from 0.91626\n","Epoch 194/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0508 - accuracy: 0.9866 - val_loss: 0.6212 - val_accuracy: 0.8867\n","\n","Epoch 00194: val_accuracy did not improve from 0.91626\n","Epoch 195/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.5450 - val_accuracy: 0.8867\n","\n","Epoch 00195: val_accuracy did not improve from 0.91626\n","Epoch 196/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.5707 - val_accuracy: 0.8818\n","\n","Epoch 00196: val_accuracy did not improve from 0.91626\n","Epoch 197/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0269 - accuracy: 0.9927 - val_loss: 0.7190 - val_accuracy: 0.8744\n","\n","Epoch 00197: val_accuracy did not improve from 0.91626\n","Epoch 198/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 4.0946 - val_accuracy: 0.5813\n","\n","Epoch 00198: val_accuracy did not improve from 0.91626\n","Epoch 199/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 1.2732 - val_accuracy: 0.8153\n","\n","Epoch 00199: val_accuracy did not improve from 0.91626\n","Epoch 200/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.6251 - val_accuracy: 0.8842\n","\n","Epoch 00200: val_accuracy did not improve from 0.91626\n","Epoch 201/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0543 - accuracy: 0.9817 - val_loss: 2.8963 - val_accuracy: 0.6675\n","\n","Epoch 00201: val_accuracy did not improve from 0.91626\n","Epoch 202/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0350 - accuracy: 0.9854 - val_loss: 0.5996 - val_accuracy: 0.8867\n","\n","Epoch 00202: val_accuracy did not improve from 0.91626\n","Epoch 203/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.4409 - val_accuracy: 0.9163\n","\n","Epoch 00203: val_accuracy did not improve from 0.91626\n","Epoch 204/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.4041 - val_accuracy: 0.9064\n","\n","Epoch 00204: val_accuracy did not improve from 0.91626\n","Epoch 205/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.6089 - val_accuracy: 0.8966\n","\n","Epoch 00205: val_accuracy did not improve from 0.91626\n","Epoch 206/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.4532 - val_accuracy: 0.9236\n","\n","Epoch 00206: val_accuracy improved from 0.91626 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 207/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.5873 - val_accuracy: 0.8892\n","\n","Epoch 00207: val_accuracy did not improve from 0.92365\n","Epoch 208/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.4936 - val_accuracy: 0.9089\n","\n","Epoch 00208: val_accuracy did not improve from 0.92365\n","Epoch 209/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0601 - accuracy: 0.9811 - val_loss: 2.8499 - val_accuracy: 0.6847\n","\n","Epoch 00209: val_accuracy did not improve from 0.92365\n","Epoch 210/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0636 - accuracy: 0.9787 - val_loss: 0.5499 - val_accuracy: 0.8719\n","\n","Epoch 00210: val_accuracy did not improve from 0.92365\n","Epoch 211/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0763 - accuracy: 0.9787 - val_loss: 2.2762 - val_accuracy: 0.7389\n","\n","Epoch 00211: val_accuracy did not improve from 0.92365\n","Epoch 212/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0737 - accuracy: 0.9793 - val_loss: 0.5142 - val_accuracy: 0.8941\n","\n","Epoch 00212: val_accuracy did not improve from 0.92365\n","Epoch 213/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0477 - accuracy: 0.9860 - val_loss: 0.5891 - val_accuracy: 0.8892\n","\n","Epoch 00213: val_accuracy did not improve from 0.92365\n","Epoch 214/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0377 - accuracy: 0.9866 - val_loss: 0.6550 - val_accuracy: 0.8744\n","\n","Epoch 00214: val_accuracy did not improve from 0.92365\n","Epoch 215/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 0.7595 - val_accuracy: 0.8818\n","\n","Epoch 00215: val_accuracy did not improve from 0.92365\n","Epoch 216/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.7537 - val_accuracy: 0.8842\n","\n","Epoch 00216: val_accuracy did not improve from 0.92365\n","Epoch 217/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.6060 - val_accuracy: 0.9015\n","\n","Epoch 00217: val_accuracy did not improve from 0.92365\n","Epoch 218/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0221 - accuracy: 0.9921 - val_loss: 0.7139 - val_accuracy: 0.8670\n","\n","Epoch 00218: val_accuracy did not improve from 0.92365\n","Epoch 219/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0166 - accuracy: 0.9957 - val_loss: 0.5410 - val_accuracy: 0.8916\n","\n","Epoch 00219: val_accuracy did not improve from 0.92365\n","Epoch 220/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 0.5998 - val_accuracy: 0.8793\n","\n","Epoch 00220: val_accuracy did not improve from 0.92365\n","Epoch 221/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0179 - accuracy: 0.9921 - val_loss: 0.5900 - val_accuracy: 0.8941\n","\n","Epoch 00221: val_accuracy did not improve from 0.92365\n","Epoch 222/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.5199 - val_accuracy: 0.9039\n","\n","Epoch 00222: val_accuracy did not improve from 0.92365\n","Epoch 223/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.6329 - val_accuracy: 0.8867\n","\n","Epoch 00223: val_accuracy did not improve from 0.92365\n","Epoch 224/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.5274 - val_accuracy: 0.9064\n","\n","Epoch 00224: val_accuracy did not improve from 0.92365\n","Epoch 225/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0144 - accuracy: 0.9945 - val_loss: 0.5547 - val_accuracy: 0.9064\n","\n","Epoch 00225: val_accuracy did not improve from 0.92365\n","Epoch 226/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0361 - accuracy: 0.9848 - val_loss: 0.7368 - val_accuracy: 0.8645\n","\n","Epoch 00226: val_accuracy did not improve from 0.92365\n","Epoch 227/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0427 - accuracy: 0.9860 - val_loss: 13.4111 - val_accuracy: 0.3227\n","\n","Epoch 00227: val_accuracy did not improve from 0.92365\n","Epoch 228/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0896 - accuracy: 0.9756 - val_loss: 1.6105 - val_accuracy: 0.7537\n","\n","Epoch 00228: val_accuracy did not improve from 0.92365\n","Epoch 229/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0944 - accuracy: 0.9775 - val_loss: 1.0106 - val_accuracy: 0.8005\n","\n","Epoch 00229: val_accuracy did not improve from 0.92365\n","Epoch 230/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0923 - accuracy: 0.9702 - val_loss: 1.7564 - val_accuracy: 0.7241\n","\n","Epoch 00230: val_accuracy did not improve from 0.92365\n","Epoch 231/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0825 - accuracy: 0.9781 - val_loss: 0.7821 - val_accuracy: 0.8522\n","\n","Epoch 00231: val_accuracy did not improve from 0.92365\n","Epoch 232/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.8062 - val_accuracy: 0.8571\n","\n","Epoch 00232: val_accuracy did not improve from 0.92365\n","Epoch 233/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.6453 - val_accuracy: 0.8842\n","\n","Epoch 00233: val_accuracy did not improve from 0.92365\n","Epoch 234/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.7807 - val_accuracy: 0.8695\n","\n","Epoch 00234: val_accuracy did not improve from 0.92365\n","Epoch 235/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.5944 - val_accuracy: 0.8916\n","\n","Epoch 00235: val_accuracy did not improve from 0.92365\n","Epoch 236/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.5869 - val_accuracy: 0.8941\n","\n","Epoch 00236: val_accuracy did not improve from 0.92365\n","Epoch 237/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5025 - val_accuracy: 0.9039\n","\n","Epoch 00237: val_accuracy did not improve from 0.92365\n","Epoch 238/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5538 - val_accuracy: 0.9064\n","\n","Epoch 00238: val_accuracy did not improve from 0.92365\n","Epoch 239/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4842 - val_accuracy: 0.9015\n","\n","Epoch 00239: val_accuracy did not improve from 0.92365\n","Epoch 240/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5282 - val_accuracy: 0.8867\n","\n","Epoch 00240: val_accuracy did not improve from 0.92365\n","Epoch 241/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5795 - val_accuracy: 0.8966\n","\n","Epoch 00241: val_accuracy did not improve from 0.92365\n","Epoch 242/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.5193 - val_accuracy: 0.9015\n","\n","Epoch 00242: val_accuracy did not improve from 0.92365\n","Epoch 243/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.6329 - val_accuracy: 0.8867\n","\n","Epoch 00243: val_accuracy did not improve from 0.92365\n","Epoch 244/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0502 - accuracy: 0.9860 - val_loss: 3.3894 - val_accuracy: 0.6453\n","\n","Epoch 00244: val_accuracy did not improve from 0.92365\n","Epoch 245/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0477 - accuracy: 0.9836 - val_loss: 1.0112 - val_accuracy: 0.8522\n","\n","Epoch 00245: val_accuracy did not improve from 0.92365\n","Epoch 246/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0313 - accuracy: 0.9903 - val_loss: 0.7080 - val_accuracy: 0.8818\n","\n","Epoch 00246: val_accuracy did not improve from 0.92365\n","Epoch 247/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0253 - accuracy: 0.9939 - val_loss: 0.7084 - val_accuracy: 0.8818\n","\n","Epoch 00247: val_accuracy did not improve from 0.92365\n","Epoch 248/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.7156 - val_accuracy: 0.8744\n","\n","Epoch 00248: val_accuracy did not improve from 0.92365\n","Epoch 249/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.6511 - val_accuracy: 0.8842\n","\n","Epoch 00249: val_accuracy did not improve from 0.92365\n","Epoch 250/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 0.7879 - val_accuracy: 0.8842\n","\n","Epoch 00250: val_accuracy did not improve from 0.92365\n","Epoch 251/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 0.6720 - val_accuracy: 0.8818\n","\n","Epoch 00251: val_accuracy did not improve from 0.92365\n","Epoch 252/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0227 - accuracy: 0.9909 - val_loss: 0.5104 - val_accuracy: 0.8941\n","\n","Epoch 00252: val_accuracy did not improve from 0.92365\n","Epoch 253/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.5757 - val_accuracy: 0.9015\n","\n","Epoch 00253: val_accuracy did not improve from 0.92365\n","Epoch 254/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.5685 - val_accuracy: 0.9064\n","\n","Epoch 00254: val_accuracy did not improve from 0.92365\n","Epoch 255/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0344 - accuracy: 0.9939 - val_loss: 0.7551 - val_accuracy: 0.8621\n","\n","Epoch 00255: val_accuracy did not improve from 0.92365\n","Epoch 256/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5851 - val_accuracy: 0.8990\n","\n","Epoch 00256: val_accuracy did not improve from 0.92365\n","Epoch 257/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.5514 - val_accuracy: 0.8941\n","\n","Epoch 00257: val_accuracy did not improve from 0.92365\n","Epoch 258/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.4945 - val_accuracy: 0.9163\n","\n","Epoch 00258: val_accuracy did not improve from 0.92365\n","Epoch 259/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.6637 - val_accuracy: 0.8892\n","\n","Epoch 00259: val_accuracy did not improve from 0.92365\n","Epoch 260/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4121 - val_accuracy: 0.9310\n","\n","Epoch 00260: val_accuracy improved from 0.92365 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 261/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.5454 - val_accuracy: 0.9089\n","\n","Epoch 00261: val_accuracy did not improve from 0.93103\n","Epoch 262/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 3.8842 - val_accuracy: 0.6355\n","\n","Epoch 00262: val_accuracy did not improve from 0.93103\n","Epoch 263/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.7099 - val_accuracy: 0.8941\n","\n","Epoch 00263: val_accuracy did not improve from 0.93103\n","Epoch 264/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.5510 - val_accuracy: 0.9015\n","\n","Epoch 00264: val_accuracy did not improve from 0.93103\n","Epoch 265/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0448 - accuracy: 0.9866 - val_loss: 2.3266 - val_accuracy: 0.7217\n","\n","Epoch 00265: val_accuracy did not improve from 0.93103\n","Epoch 266/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0832 - accuracy: 0.9720 - val_loss: 1.1019 - val_accuracy: 0.8276\n","\n","Epoch 00266: val_accuracy did not improve from 0.93103\n","Epoch 267/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 0.8039 - val_accuracy: 0.8842\n","\n","Epoch 00267: val_accuracy did not improve from 0.93103\n","Epoch 268/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.7554 - val_accuracy: 0.8818\n","\n","Epoch 00268: val_accuracy did not improve from 0.93103\n","Epoch 269/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.7004 - val_accuracy: 0.9015\n","\n","Epoch 00269: val_accuracy did not improve from 0.93103\n","Epoch 270/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.5741 - val_accuracy: 0.8916\n","\n","Epoch 00270: val_accuracy did not improve from 0.93103\n","Epoch 271/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0303 - accuracy: 0.9933 - val_loss: 0.6881 - val_accuracy: 0.8818\n","\n","Epoch 00271: val_accuracy did not improve from 0.93103\n","Epoch 272/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.7577 - val_accuracy: 0.8966\n","\n","Epoch 00272: val_accuracy did not improve from 0.93103\n","Epoch 273/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.6406 - val_accuracy: 0.8966\n","\n","Epoch 00273: val_accuracy did not improve from 0.93103\n","Epoch 274/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.6429 - val_accuracy: 0.8818\n","\n","Epoch 00274: val_accuracy did not improve from 0.93103\n","Epoch 275/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.5464 - val_accuracy: 0.8966\n","\n","Epoch 00275: val_accuracy did not improve from 0.93103\n","Epoch 276/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.5510 - val_accuracy: 0.8990\n","\n","Epoch 00276: val_accuracy did not improve from 0.93103\n","Epoch 277/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.6303 - val_accuracy: 0.8990\n","\n","Epoch 00277: val_accuracy did not improve from 0.93103\n","Epoch 278/500\n","52/52 [==============================] - 17s 318ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.9089\n","\n","Epoch 00278: val_accuracy did not improve from 0.93103\n","Epoch 279/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.6709 - val_accuracy: 0.8892\n","\n","Epoch 00279: val_accuracy did not improve from 0.93103\n","Epoch 280/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.1554 - accuracy: 0.9592 - val_loss: 19.2053 - val_accuracy: 0.2611\n","\n","Epoch 00280: val_accuracy did not improve from 0.93103\n","Epoch 281/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0618 - accuracy: 0.9799 - val_loss: 2.8361 - val_accuracy: 0.6429\n","\n","Epoch 00281: val_accuracy did not improve from 0.93103\n","Epoch 282/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0639 - accuracy: 0.9811 - val_loss: 1.3423 - val_accuracy: 0.7660\n","\n","Epoch 00282: val_accuracy did not improve from 0.93103\n","Epoch 283/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0367 - accuracy: 0.9872 - val_loss: 0.6392 - val_accuracy: 0.8744\n","\n","Epoch 00283: val_accuracy did not improve from 0.93103\n","Epoch 284/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.5050 - val_accuracy: 0.8892\n","\n","Epoch 00284: val_accuracy did not improve from 0.93103\n","Epoch 285/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.6944 - val_accuracy: 0.8867\n","\n","Epoch 00285: val_accuracy did not improve from 0.93103\n","Epoch 286/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.6308 - val_accuracy: 0.8818\n","\n","Epoch 00286: val_accuracy did not improve from 0.93103\n","Epoch 287/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0096 - accuracy: 0.9994 - val_loss: 0.5745 - val_accuracy: 0.8916\n","\n","Epoch 00287: val_accuracy did not improve from 0.93103\n","Epoch 288/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.4617 - val_accuracy: 0.9187\n","\n","Epoch 00288: val_accuracy did not improve from 0.93103\n","Epoch 289/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4085 - val_accuracy: 0.9138\n","\n","Epoch 00289: val_accuracy did not improve from 0.93103\n","Epoch 290/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9261\n","\n","Epoch 00290: val_accuracy did not improve from 0.93103\n","Epoch 291/500\n","52/52 [==============================] - 17s 320ms/step - loss: 7.7912e-04 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.9089\n","\n","Epoch 00291: val_accuracy did not improve from 0.93103\n","Epoch 292/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.5357 - val_accuracy: 0.9039\n","\n","Epoch 00292: val_accuracy did not improve from 0.93103\n","Epoch 293/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.9113\n","\n","Epoch 00293: val_accuracy did not improve from 0.93103\n","Epoch 294/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.6059 - val_accuracy: 0.9039\n","\n","Epoch 00294: val_accuracy did not improve from 0.93103\n","Epoch 295/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0163 - accuracy: 0.9933 - val_loss: 0.5877 - val_accuracy: 0.9039\n","\n","Epoch 00295: val_accuracy did not improve from 0.93103\n","Epoch 296/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0424 - accuracy: 0.9878 - val_loss: 0.9356 - val_accuracy: 0.8719\n","\n","Epoch 00296: val_accuracy did not improve from 0.93103\n","Epoch 297/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 1.1461 - val_accuracy: 0.8374\n","\n","Epoch 00297: val_accuracy did not improve from 0.93103\n","Epoch 298/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.6573 - val_accuracy: 0.8916\n","\n","Epoch 00298: val_accuracy did not improve from 0.93103\n","Epoch 299/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 0.5048 - val_accuracy: 0.8941\n","\n","Epoch 00299: val_accuracy did not improve from 0.93103\n","Epoch 300/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0317 - accuracy: 0.9921 - val_loss: 0.9367 - val_accuracy: 0.8621\n","\n","Epoch 00300: val_accuracy did not improve from 0.93103\n","Epoch 301/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.7022 - val_accuracy: 0.8473\n","\n","Epoch 00301: val_accuracy did not improve from 0.93103\n","Epoch 302/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.8016 - val_accuracy: 0.8842\n","\n","Epoch 00302: val_accuracy did not improve from 0.93103\n","Epoch 303/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.7754 - val_accuracy: 0.8719\n","\n","Epoch 00303: val_accuracy did not improve from 0.93103\n","Epoch 304/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.6351 - val_accuracy: 0.8892\n","\n","Epoch 00304: val_accuracy did not improve from 0.93103\n","Epoch 305/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.5688 - val_accuracy: 0.8990\n","\n","Epoch 00305: val_accuracy did not improve from 0.93103\n","Epoch 306/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.5942 - val_accuracy: 0.8892\n","\n","Epoch 00306: val_accuracy did not improve from 0.93103\n","Epoch 307/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.5940 - val_accuracy: 0.8892\n","\n","Epoch 00307: val_accuracy did not improve from 0.93103\n","Epoch 308/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5851 - val_accuracy: 0.8941\n","\n","Epoch 00308: val_accuracy did not improve from 0.93103\n","Epoch 309/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 1.3525 - val_accuracy: 0.8030\n","\n","Epoch 00309: val_accuracy did not improve from 0.93103\n","Epoch 310/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.1034 - accuracy: 0.9702 - val_loss: 28.7117 - val_accuracy: 0.1897\n","\n","Epoch 00310: val_accuracy did not improve from 0.93103\n","Epoch 311/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0499 - accuracy: 0.9878 - val_loss: 0.7532 - val_accuracy: 0.8695\n","\n","Epoch 00311: val_accuracy did not improve from 0.93103\n","Epoch 312/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.8185 - val_accuracy: 0.8719\n","\n","Epoch 00312: val_accuracy did not improve from 0.93103\n","Epoch 313/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 0.6208 - val_accuracy: 0.8892\n","\n","Epoch 00313: val_accuracy did not improve from 0.93103\n","Epoch 314/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.4578 - val_accuracy: 0.9113\n","\n","Epoch 00314: val_accuracy did not improve from 0.93103\n","Epoch 315/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 1.8712 - val_accuracy: 0.7660\n","\n","Epoch 00315: val_accuracy did not improve from 0.93103\n","Epoch 316/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.4906 - val_accuracy: 0.9015\n","\n","Epoch 00316: val_accuracy did not improve from 0.93103\n","Epoch 317/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.9015\n","\n","Epoch 00317: val_accuracy did not improve from 0.93103\n","Epoch 318/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5037 - val_accuracy: 0.9138\n","\n","Epoch 00318: val_accuracy did not improve from 0.93103\n","Epoch 319/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4961 - val_accuracy: 0.9064\n","\n","Epoch 00319: val_accuracy did not improve from 0.93103\n","Epoch 320/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.8246 - val_accuracy: 0.8744\n","\n","Epoch 00320: val_accuracy did not improve from 0.93103\n","Epoch 321/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.5249 - val_accuracy: 0.8842\n","\n","Epoch 00321: val_accuracy did not improve from 0.93103\n","Epoch 322/500\n","52/52 [==============================] - 17s 320ms/step - loss: 9.6508e-04 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.9039\n","\n","Epoch 00322: val_accuracy did not improve from 0.93103\n","Epoch 323/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.8519 - val_accuracy: 0.8744\n","\n","Epoch 00323: val_accuracy did not improve from 0.93103\n","Epoch 324/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.5312 - val_accuracy: 0.9163\n","\n","Epoch 00324: val_accuracy did not improve from 0.93103\n","Epoch 325/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.5977 - val_accuracy: 0.9064\n","\n","Epoch 00325: val_accuracy did not improve from 0.93103\n","Epoch 326/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.7259 - val_accuracy: 0.8916\n","\n","Epoch 00326: val_accuracy did not improve from 0.93103\n","Epoch 327/500\n","52/52 [==============================] - 17s 320ms/step - loss: 8.5262e-04 - accuracy: 1.0000 - val_loss: 0.5727 - val_accuracy: 0.9015\n","\n","Epoch 00327: val_accuracy did not improve from 0.93103\n","Epoch 328/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5028 - val_accuracy: 0.9163\n","\n","Epoch 00328: val_accuracy did not improve from 0.93103\n","Epoch 329/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5910 - val_accuracy: 0.9015\n","\n","Epoch 00329: val_accuracy did not improve from 0.93103\n","Epoch 330/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5626 - val_accuracy: 0.8892\n","\n","Epoch 00330: val_accuracy did not improve from 0.93103\n","Epoch 331/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0417 - accuracy: 0.9848 - val_loss: 0.7554 - val_accuracy: 0.8818\n","\n","Epoch 00331: val_accuracy did not improve from 0.93103\n","Epoch 332/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0813 - accuracy: 0.9762 - val_loss: 3.3586 - val_accuracy: 0.6847\n","\n","Epoch 00332: val_accuracy did not improve from 0.93103\n","Epoch 333/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0806 - accuracy: 0.9805 - val_loss: 1.0532 - val_accuracy: 0.8399\n","\n","Epoch 00333: val_accuracy did not improve from 0.93103\n","Epoch 334/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.7016 - val_accuracy: 0.8916\n","\n","Epoch 00334: val_accuracy did not improve from 0.93103\n","Epoch 335/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.4868 - val_accuracy: 0.9163\n","\n","Epoch 00335: val_accuracy did not improve from 0.93103\n","Epoch 336/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.5091 - val_accuracy: 0.9064\n","\n","Epoch 00336: val_accuracy did not improve from 0.93103\n","Epoch 337/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4493 - val_accuracy: 0.9187\n","\n","Epoch 00337: val_accuracy did not improve from 0.93103\n","Epoch 338/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4666 - val_accuracy: 0.9113\n","\n","Epoch 00338: val_accuracy did not improve from 0.93103\n","Epoch 339/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0201 - accuracy: 0.9957 - val_loss: 0.9631 - val_accuracy: 0.8350\n","\n","Epoch 00339: val_accuracy did not improve from 0.93103\n","Epoch 340/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0306 - accuracy: 0.9909 - val_loss: 0.4568 - val_accuracy: 0.8892\n","\n","Epoch 00340: val_accuracy did not improve from 0.93103\n","Epoch 341/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.5900 - val_accuracy: 0.8695\n","\n","Epoch 00341: val_accuracy did not improve from 0.93103\n","Epoch 342/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.5137 - val_accuracy: 0.9113\n","\n","Epoch 00342: val_accuracy did not improve from 0.93103\n","Epoch 343/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.5429 - val_accuracy: 0.9113\n","\n","Epoch 00343: val_accuracy did not improve from 0.93103\n","Epoch 344/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.9138\n","\n","Epoch 00344: val_accuracy did not improve from 0.93103\n","Epoch 345/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.5627 - val_accuracy: 0.9015\n","\n","Epoch 00345: val_accuracy did not improve from 0.93103\n","Epoch 346/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 0.5918 - val_accuracy: 0.9039\n","\n","Epoch 00346: val_accuracy did not improve from 0.93103\n","Epoch 347/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5351 - val_accuracy: 0.9089\n","\n","Epoch 00347: val_accuracy did not improve from 0.93103\n","Epoch 348/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5404 - val_accuracy: 0.9113\n","\n","Epoch 00348: val_accuracy did not improve from 0.93103\n","Epoch 349/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.6519 - val_accuracy: 0.8892\n","\n","Epoch 00349: val_accuracy did not improve from 0.93103\n","Epoch 350/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.4897 - val_accuracy: 0.9138\n","\n","Epoch 00350: val_accuracy did not improve from 0.93103\n","Epoch 351/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0030 - accuracy: 0.9982 - val_loss: 0.5745 - val_accuracy: 0.9138\n","\n","Epoch 00351: val_accuracy did not improve from 0.93103\n","Epoch 352/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.7269 - val_accuracy: 0.8916\n","\n","Epoch 00352: val_accuracy did not improve from 0.93103\n","Epoch 353/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5551 - val_accuracy: 0.9163\n","\n","Epoch 00353: val_accuracy did not improve from 0.93103\n","Epoch 354/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0662 - accuracy: 0.9793 - val_loss: 4.4492 - val_accuracy: 0.5714\n","\n","Epoch 00354: val_accuracy did not improve from 0.93103\n","Epoch 355/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0519 - accuracy: 0.9866 - val_loss: 0.6921 - val_accuracy: 0.8719\n","\n","Epoch 00355: val_accuracy did not improve from 0.93103\n","Epoch 356/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0564 - accuracy: 0.9836 - val_loss: 0.8098 - val_accuracy: 0.8645\n","\n","Epoch 00356: val_accuracy did not improve from 0.93103\n","Epoch 357/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.6862 - val_accuracy: 0.8941\n","\n","Epoch 00357: val_accuracy did not improve from 0.93103\n","Epoch 358/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.5611 - val_accuracy: 0.9286\n","\n","Epoch 00358: val_accuracy did not improve from 0.93103\n","Epoch 359/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.4917 - val_accuracy: 0.9138\n","\n","Epoch 00359: val_accuracy did not improve from 0.93103\n","Epoch 360/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6416 - val_accuracy: 0.9089\n","\n","Epoch 00360: val_accuracy did not improve from 0.93103\n","Epoch 361/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.4836 - val_accuracy: 0.9163\n","\n","Epoch 00361: val_accuracy did not improve from 0.93103\n","Epoch 362/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9261\n","\n","Epoch 00362: val_accuracy did not improve from 0.93103\n","Epoch 363/500\n","52/52 [==============================] - 17s 320ms/step - loss: 5.4053e-04 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9236\n","\n","Epoch 00363: val_accuracy did not improve from 0.93103\n","Epoch 364/500\n","52/52 [==============================] - 17s 321ms/step - loss: 7.4121e-04 - accuracy: 1.0000 - val_loss: 0.5384 - val_accuracy: 0.9187\n","\n","Epoch 00364: val_accuracy did not improve from 0.93103\n","Epoch 365/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5662 - val_accuracy: 0.9015\n","\n","Epoch 00365: val_accuracy did not improve from 0.93103\n","Epoch 366/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.9236\n","\n","Epoch 00366: val_accuracy did not improve from 0.93103\n","Epoch 367/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.5408 - val_accuracy: 0.9236\n","\n","Epoch 00367: val_accuracy did not improve from 0.93103\n","Epoch 368/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.9236\n","\n","Epoch 00368: val_accuracy did not improve from 0.93103\n","Epoch 369/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.9187\n","\n","Epoch 00369: val_accuracy did not improve from 0.93103\n","Epoch 370/500\n","52/52 [==============================] - 17s 320ms/step - loss: 7.3137e-04 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.9138\n","\n","Epoch 00370: val_accuracy did not improve from 0.93103\n","Epoch 371/500\n","52/52 [==============================] - 17s 321ms/step - loss: 7.2201e-04 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.9138\n","\n","Epoch 00371: val_accuracy did not improve from 0.93103\n","Epoch 372/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.7135 - val_accuracy: 0.9064\n","\n","Epoch 00372: val_accuracy did not improve from 0.93103\n","Epoch 373/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.5608 - val_accuracy: 0.9163\n","\n","Epoch 00373: val_accuracy did not improve from 0.93103\n","Epoch 374/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0216 - accuracy: 0.9945 - val_loss: 0.7571 - val_accuracy: 0.8744\n","\n","Epoch 00374: val_accuracy did not improve from 0.93103\n","Epoch 375/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0424 - accuracy: 0.9872 - val_loss: 0.7389 - val_accuracy: 0.8596\n","\n","Epoch 00375: val_accuracy did not improve from 0.93103\n","Epoch 376/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0362 - accuracy: 0.9896 - val_loss: 0.6164 - val_accuracy: 0.8818\n","\n","Epoch 00376: val_accuracy did not improve from 0.93103\n","Epoch 377/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0520 - accuracy: 0.9866 - val_loss: 0.7091 - val_accuracy: 0.8670\n","\n","Epoch 00377: val_accuracy did not improve from 0.93103\n","Epoch 378/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.5062 - val_accuracy: 0.9113\n","\n","Epoch 00378: val_accuracy did not improve from 0.93103\n","Epoch 379/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4966 - val_accuracy: 0.9064\n","\n","Epoch 00379: val_accuracy did not improve from 0.93103\n","Epoch 380/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.5148 - val_accuracy: 0.9113\n","\n","Epoch 00380: val_accuracy did not improve from 0.93103\n","Epoch 381/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.4673 - val_accuracy: 0.8892\n","\n","Epoch 00381: val_accuracy did not improve from 0.93103\n","Epoch 382/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.9089\n","\n","Epoch 00382: val_accuracy did not improve from 0.93103\n","Epoch 383/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9236\n","\n","Epoch 00383: val_accuracy did not improve from 0.93103\n","Epoch 384/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.6453 - val_accuracy: 0.9015\n","\n","Epoch 00384: val_accuracy did not improve from 0.93103\n","Epoch 385/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.5933 - val_accuracy: 0.9064\n","\n","Epoch 00385: val_accuracy did not improve from 0.93103\n","Epoch 386/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5345 - val_accuracy: 0.9064\n","\n","Epoch 00386: val_accuracy did not improve from 0.93103\n","Epoch 387/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4395 - val_accuracy: 0.9236\n","\n","Epoch 00387: val_accuracy did not improve from 0.93103\n","Epoch 388/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0076 - accuracy: 0.9957 - val_loss: 0.8835 - val_accuracy: 0.8744\n","\n","Epoch 00388: val_accuracy did not improve from 0.93103\n","Epoch 389/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0142 - accuracy: 0.9945 - val_loss: 0.9495 - val_accuracy: 0.8596\n","\n","Epoch 00389: val_accuracy did not improve from 0.93103\n","Epoch 390/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.6801 - val_accuracy: 0.8966\n","\n","Epoch 00390: val_accuracy did not improve from 0.93103\n","Epoch 391/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0236 - accuracy: 0.9896 - val_loss: 0.5562 - val_accuracy: 0.9187\n","\n","Epoch 00391: val_accuracy did not improve from 0.93103\n","Epoch 392/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0374 - accuracy: 0.9872 - val_loss: 0.9363 - val_accuracy: 0.8818\n","\n","Epoch 00392: val_accuracy did not improve from 0.93103\n","Epoch 393/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.5902 - val_accuracy: 0.8941\n","\n","Epoch 00393: val_accuracy did not improve from 0.93103\n","Epoch 394/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 0.7728 - val_accuracy: 0.8670\n","\n","Epoch 00394: val_accuracy did not improve from 0.93103\n","Epoch 395/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0173 - accuracy: 0.9921 - val_loss: 0.5084 - val_accuracy: 0.9064\n","\n","Epoch 00395: val_accuracy did not improve from 0.93103\n","Epoch 396/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4607 - val_accuracy: 0.9261\n","\n","Epoch 00396: val_accuracy did not improve from 0.93103\n","Epoch 397/500\n","52/52 [==============================] - 17s 323ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.9187\n","\n","Epoch 00397: val_accuracy did not improve from 0.93103\n","Epoch 398/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4716 - val_accuracy: 0.9138\n","\n","Epoch 00398: val_accuracy did not improve from 0.93103\n","Epoch 399/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.6567 - val_accuracy: 0.8941\n","\n","Epoch 00399: val_accuracy did not improve from 0.93103\n","Epoch 400/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.9212\n","\n","Epoch 00400: val_accuracy did not improve from 0.93103\n","Epoch 401/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.6599 - val_accuracy: 0.9138\n","\n","Epoch 00401: val_accuracy did not improve from 0.93103\n","Epoch 402/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0334 - accuracy: 0.9915 - val_loss: 0.6900 - val_accuracy: 0.8695\n","\n","Epoch 00402: val_accuracy did not improve from 0.93103\n","Epoch 403/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.6130 - val_accuracy: 0.9015\n","\n","Epoch 00403: val_accuracy did not improve from 0.93103\n","Epoch 404/500\n","52/52 [==============================] - 17s 323ms/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 0.6109 - val_accuracy: 0.9064\n","\n","Epoch 00404: val_accuracy did not improve from 0.93103\n","Epoch 405/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.7900 - val_accuracy: 0.8621\n","\n","Epoch 00405: val_accuracy did not improve from 0.93103\n","Epoch 406/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.5039 - val_accuracy: 0.9138\n","\n","Epoch 00406: val_accuracy did not improve from 0.93103\n","Epoch 407/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5592 - val_accuracy: 0.9039\n","\n","Epoch 00407: val_accuracy did not improve from 0.93103\n","Epoch 408/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0084 - accuracy: 0.9951 - val_loss: 0.5879 - val_accuracy: 0.9089\n","\n","Epoch 00408: val_accuracy did not improve from 0.93103\n","Epoch 409/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 0.8838 - val_accuracy: 0.8719\n","\n","Epoch 00409: val_accuracy did not improve from 0.93103\n","Epoch 410/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0522 - accuracy: 0.9878 - val_loss: 0.6279 - val_accuracy: 0.8941\n","\n","Epoch 00410: val_accuracy did not improve from 0.93103\n","Epoch 411/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 0.6057 - val_accuracy: 0.8916\n","\n","Epoch 00411: val_accuracy did not improve from 0.93103\n","Epoch 412/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.7830 - val_accuracy: 0.8892\n","\n","Epoch 00412: val_accuracy did not improve from 0.93103\n","Epoch 413/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.5365 - val_accuracy: 0.8892\n","\n","Epoch 00413: val_accuracy did not improve from 0.93103\n","Epoch 414/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.7241 - val_accuracy: 0.8966\n","\n","Epoch 00414: val_accuracy did not improve from 0.93103\n","Epoch 415/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.6568 - val_accuracy: 0.8892\n","\n","Epoch 00415: val_accuracy did not improve from 0.93103\n","Epoch 416/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.7045 - val_accuracy: 0.9212\n","\n","Epoch 00416: val_accuracy did not improve from 0.93103\n","Epoch 417/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6525 - val_accuracy: 0.9113\n","\n","Epoch 00417: val_accuracy did not improve from 0.93103\n","Epoch 418/500\n","52/52 [==============================] - 17s 319ms/step - loss: 6.2282e-04 - accuracy: 1.0000 - val_loss: 0.5864 - val_accuracy: 0.9138\n","\n","Epoch 00418: val_accuracy did not improve from 0.93103\n","Epoch 419/500\n","52/52 [==============================] - 17s 323ms/step - loss: 5.4267e-04 - accuracy: 1.0000 - val_loss: 0.6654 - val_accuracy: 0.9163\n","\n","Epoch 00419: val_accuracy did not improve from 0.93103\n","Epoch 420/500\n","52/52 [==============================] - 17s 321ms/step - loss: 3.7332e-04 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.9138\n","\n","Epoch 00420: val_accuracy did not improve from 0.93103\n","Epoch 421/500\n","52/52 [==============================] - 17s 322ms/step - loss: 1.8863e-04 - accuracy: 1.0000 - val_loss: 0.5886 - val_accuracy: 0.9335\n","\n","Epoch 00421: val_accuracy improved from 0.93103 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 422/500\n","52/52 [==============================] - 17s 323ms/step - loss: 3.6981e-04 - accuracy: 1.0000 - val_loss: 0.5921 - val_accuracy: 0.9089\n","\n","Epoch 00422: val_accuracy did not improve from 0.93350\n","Epoch 423/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5500 - val_accuracy: 0.9187\n","\n","Epoch 00423: val_accuracy did not improve from 0.93350\n","Epoch 424/500\n","52/52 [==============================] - 17s 321ms/step - loss: 4.4917e-04 - accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.9113\n","\n","Epoch 00424: val_accuracy did not improve from 0.93350\n","Epoch 425/500\n","52/52 [==============================] - 17s 321ms/step - loss: 4.9033e-04 - accuracy: 1.0000 - val_loss: 0.5594 - val_accuracy: 0.9163\n","\n","Epoch 00425: val_accuracy did not improve from 0.93350\n","Epoch 426/500\n","52/52 [==============================] - 17s 322ms/step - loss: 2.9136e-04 - accuracy: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.9212\n","\n","Epoch 00426: val_accuracy did not improve from 0.93350\n","Epoch 427/500\n","52/52 [==============================] - 17s 321ms/step - loss: 5.3236e-04 - accuracy: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.9138\n","\n","Epoch 00427: val_accuracy did not improve from 0.93350\n","Epoch 428/500\n","52/52 [==============================] - 17s 322ms/step - loss: 1.9252e-04 - accuracy: 1.0000 - val_loss: 0.5724 - val_accuracy: 0.9212\n","\n","Epoch 00428: val_accuracy did not improve from 0.93350\n","Epoch 429/500\n","52/52 [==============================] - 17s 320ms/step - loss: 2.0329e-04 - accuracy: 1.0000 - val_loss: 0.5410 - val_accuracy: 0.9187\n","\n","Epoch 00429: val_accuracy did not improve from 0.93350\n","Epoch 430/500\n","52/52 [==============================] - 17s 321ms/step - loss: 1.2506e-04 - accuracy: 1.0000 - val_loss: 0.5273 - val_accuracy: 0.9261\n","\n","Epoch 00430: val_accuracy did not improve from 0.93350\n","Epoch 431/500\n","52/52 [==============================] - 17s 321ms/step - loss: 9.5243e-05 - accuracy: 1.0000 - val_loss: 0.4891 - val_accuracy: 0.9360\n","\n","Epoch 00431: val_accuracy improved from 0.93350 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5\n","Epoch 432/500\n","52/52 [==============================] - 17s 323ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.8438 - val_accuracy: 0.8867\n","\n","Epoch 00432: val_accuracy did not improve from 0.93596\n","Epoch 433/500\n","52/52 [==============================] - 17s 323ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.6538 - val_accuracy: 0.9138\n","\n","Epoch 00433: val_accuracy did not improve from 0.93596\n","Epoch 434/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.8743 - val_accuracy: 0.8719\n","\n","Epoch 00434: val_accuracy did not improve from 0.93596\n","Epoch 435/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0281 - accuracy: 0.9903 - val_loss: 1.0044 - val_accuracy: 0.8818\n","\n","Epoch 00435: val_accuracy did not improve from 0.93596\n","Epoch 436/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0140 - accuracy: 0.9970 - val_loss: 0.9587 - val_accuracy: 0.8695\n","\n","Epoch 00436: val_accuracy did not improve from 0.93596\n","Epoch 437/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0084 - accuracy: 0.9957 - val_loss: 0.7418 - val_accuracy: 0.9039\n","\n","Epoch 00437: val_accuracy did not improve from 0.93596\n","Epoch 438/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0360 - accuracy: 0.9896 - val_loss: 1.7393 - val_accuracy: 0.7562\n","\n","Epoch 00438: val_accuracy did not improve from 0.93596\n","Epoch 439/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0420 - accuracy: 0.9890 - val_loss: 0.9646 - val_accuracy: 0.8645\n","\n","Epoch 00439: val_accuracy did not improve from 0.93596\n","Epoch 440/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0115 - accuracy: 0.9951 - val_loss: 0.7146 - val_accuracy: 0.8892\n","\n","Epoch 00440: val_accuracy did not improve from 0.93596\n","Epoch 441/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.7877 - val_accuracy: 0.8818\n","\n","Epoch 00441: val_accuracy did not improve from 0.93596\n","Epoch 442/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.6642 - val_accuracy: 0.9015\n","\n","Epoch 00442: val_accuracy did not improve from 0.93596\n","Epoch 443/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.6530 - val_accuracy: 0.9212\n","\n","Epoch 00443: val_accuracy did not improve from 0.93596\n","Epoch 444/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.7746 - val_accuracy: 0.9113\n","\n","Epoch 00444: val_accuracy did not improve from 0.93596\n","Epoch 445/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.8593 - val_accuracy: 0.8818\n","\n","Epoch 00445: val_accuracy did not improve from 0.93596\n","Epoch 446/500\n","52/52 [==============================] - 17s 323ms/step - loss: 0.0086 - accuracy: 0.9957 - val_loss: 0.6686 - val_accuracy: 0.8990\n","\n","Epoch 00446: val_accuracy did not improve from 0.93596\n","Epoch 447/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.6088 - val_accuracy: 0.9039\n","\n","Epoch 00447: val_accuracy did not improve from 0.93596\n","Epoch 448/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.7246 - val_accuracy: 0.8966\n","\n","Epoch 00448: val_accuracy did not improve from 0.93596\n","Epoch 449/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.8031 - val_accuracy: 0.8941\n","\n","Epoch 00449: val_accuracy did not improve from 0.93596\n","Epoch 450/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.7038 - val_accuracy: 0.8744\n","\n","Epoch 00450: val_accuracy did not improve from 0.93596\n","Epoch 451/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0280 - accuracy: 0.9951 - val_loss: 0.6735 - val_accuracy: 0.8670\n","\n","Epoch 00451: val_accuracy did not improve from 0.93596\n","Epoch 452/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.8122 - val_accuracy: 0.8867\n","\n","Epoch 00452: val_accuracy did not improve from 0.93596\n","Epoch 453/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0218 - accuracy: 0.9945 - val_loss: 0.7522 - val_accuracy: 0.8867\n","\n","Epoch 00453: val_accuracy did not improve from 0.93596\n","Epoch 454/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.7083 - val_accuracy: 0.8867\n","\n","Epoch 00454: val_accuracy did not improve from 0.93596\n","Epoch 455/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.6329 - val_accuracy: 0.9015\n","\n","Epoch 00455: val_accuracy did not improve from 0.93596\n","Epoch 456/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.6443 - val_accuracy: 0.9064\n","\n","Epoch 00456: val_accuracy did not improve from 0.93596\n","Epoch 457/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.9138\n","\n","Epoch 00457: val_accuracy did not improve from 0.93596\n","Epoch 458/500\n","52/52 [==============================] - 18s 335ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.5961 - val_accuracy: 0.9138\n","\n","Epoch 00458: val_accuracy did not improve from 0.93596\n","Epoch 459/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5758 - val_accuracy: 0.9089\n","\n","Epoch 00459: val_accuracy did not improve from 0.93596\n","Epoch 460/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.6356 - val_accuracy: 0.9212\n","\n","Epoch 00460: val_accuracy did not improve from 0.93596\n","Epoch 461/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.7898 - val_accuracy: 0.8941\n","\n","Epoch 00461: val_accuracy did not improve from 0.93596\n","Epoch 462/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 1.0970 - val_accuracy: 0.8571\n","\n","Epoch 00462: val_accuracy did not improve from 0.93596\n","Epoch 463/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.8990 - val_accuracy: 0.8695\n","\n","Epoch 00463: val_accuracy did not improve from 0.93596\n","Epoch 464/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.8394 - val_accuracy: 0.8867\n","\n","Epoch 00464: val_accuracy did not improve from 0.93596\n","Epoch 465/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6676 - val_accuracy: 0.8990\n","\n","Epoch 00465: val_accuracy did not improve from 0.93596\n","Epoch 466/500\n","52/52 [==============================] - 17s 320ms/step - loss: 8.7253e-04 - accuracy: 1.0000 - val_loss: 0.6349 - val_accuracy: 0.9187\n","\n","Epoch 00466: val_accuracy did not improve from 0.93596\n","Epoch 467/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5756 - val_accuracy: 0.9089\n","\n","Epoch 00467: val_accuracy did not improve from 0.93596\n","Epoch 468/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.6669 - val_accuracy: 0.9089\n","\n","Epoch 00468: val_accuracy did not improve from 0.93596\n","Epoch 469/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0062 - accuracy: 0.9970 - val_loss: 0.6740 - val_accuracy: 0.8990\n","\n","Epoch 00469: val_accuracy did not improve from 0.93596\n","Epoch 470/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.8586 - val_accuracy: 0.8571\n","\n","Epoch 00470: val_accuracy did not improve from 0.93596\n","Epoch 471/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.9285 - val_accuracy: 0.8842\n","\n","Epoch 00471: val_accuracy did not improve from 0.93596\n","Epoch 472/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.9586 - val_accuracy: 0.8744\n","\n","Epoch 00472: val_accuracy did not improve from 0.93596\n","Epoch 473/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0171 - accuracy: 0.9957 - val_loss: 0.7755 - val_accuracy: 0.9015\n","\n","Epoch 00473: val_accuracy did not improve from 0.93596\n","Epoch 474/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.7372 - val_accuracy: 0.8916\n","\n","Epoch 00474: val_accuracy did not improve from 0.93596\n","Epoch 475/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.7697 - val_accuracy: 0.8793\n","\n","Epoch 00475: val_accuracy did not improve from 0.93596\n","Epoch 476/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 0.6772 - val_accuracy: 0.8916\n","\n","Epoch 00476: val_accuracy did not improve from 0.93596\n","Epoch 477/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.7781 - val_accuracy: 0.8695\n","\n","Epoch 00477: val_accuracy did not improve from 0.93596\n","Epoch 478/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.8676 - val_accuracy: 0.8793\n","\n","Epoch 00478: val_accuracy did not improve from 0.93596\n","Epoch 479/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.9604 - val_accuracy: 0.8990\n","\n","Epoch 00479: val_accuracy did not improve from 0.93596\n","Epoch 480/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0167 - accuracy: 0.9963 - val_loss: 0.7911 - val_accuracy: 0.9015\n","\n","Epoch 00480: val_accuracy did not improve from 0.93596\n","Epoch 481/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.7502 - val_accuracy: 0.9015\n","\n","Epoch 00481: val_accuracy did not improve from 0.93596\n","Epoch 482/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.7471 - val_accuracy: 0.8842\n","\n","Epoch 00482: val_accuracy did not improve from 0.93596\n","Epoch 483/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.7560 - val_accuracy: 0.8793\n","\n","Epoch 00483: val_accuracy did not improve from 0.93596\n","Epoch 484/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.7382 - val_accuracy: 0.8793\n","\n","Epoch 00484: val_accuracy did not improve from 0.93596\n","Epoch 485/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.7170 - val_accuracy: 0.8818\n","\n","Epoch 00485: val_accuracy did not improve from 0.93596\n","Epoch 486/500\n","52/52 [==============================] - 17s 319ms/step - loss: 4.4316e-04 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 0.9064\n","\n","Epoch 00486: val_accuracy did not improve from 0.93596\n","Epoch 487/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.7662 - val_accuracy: 0.8941\n","\n","Epoch 00487: val_accuracy did not improve from 0.93596\n","Epoch 488/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5616 - val_accuracy: 0.9113\n","\n","Epoch 00488: val_accuracy did not improve from 0.93596\n","Epoch 489/500\n","52/52 [==============================] - 17s 320ms/step - loss: 5.1359e-04 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.9236\n","\n","Epoch 00489: val_accuracy did not improve from 0.93596\n","Epoch 490/500\n","52/52 [==============================] - 17s 320ms/step - loss: 4.8861e-04 - accuracy: 1.0000 - val_loss: 0.5606 - val_accuracy: 0.9212\n","\n","Epoch 00490: val_accuracy did not improve from 0.93596\n","Epoch 491/500\n","52/52 [==============================] - 17s 322ms/step - loss: 3.1896e-04 - accuracy: 1.0000 - val_loss: 0.5922 - val_accuracy: 0.9138\n","\n","Epoch 00491: val_accuracy did not improve from 0.93596\n","Epoch 492/500\n","52/52 [==============================] - 17s 320ms/step - loss: 1.3524e-04 - accuracy: 1.0000 - val_loss: 0.6348 - val_accuracy: 0.9138\n","\n","Epoch 00492: val_accuracy did not improve from 0.93596\n","Epoch 493/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.5610 - val_accuracy: 0.9113\n","\n","Epoch 00493: val_accuracy did not improve from 0.93596\n","Epoch 494/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.6069 - val_accuracy: 0.9163\n","\n","Epoch 00494: val_accuracy did not improve from 0.93596\n","Epoch 495/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0191 - accuracy: 0.9951 - val_loss: 1.3527 - val_accuracy: 0.8276\n","\n","Epoch 00495: val_accuracy did not improve from 0.93596\n","Epoch 496/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0582 - accuracy: 0.9878 - val_loss: 8.5721 - val_accuracy: 0.4704\n","\n","Epoch 00496: val_accuracy did not improve from 0.93596\n","Epoch 497/500\n","52/52 [==============================] - 17s 322ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 17.9657 - val_accuracy: 0.2217\n","\n","Epoch 00497: val_accuracy did not improve from 0.93596\n","Epoch 498/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0301 - accuracy: 0.9921 - val_loss: 2.0321 - val_accuracy: 0.7389\n","\n","Epoch 00498: val_accuracy did not improve from 0.93596\n","Epoch 499/500\n","52/52 [==============================] - 17s 321ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.7199 - val_accuracy: 0.8892\n","\n","Epoch 00499: val_accuracy did not improve from 0.93596\n","Epoch 500/500\n","52/52 [==============================] - 17s 320ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.6103 - val_accuracy: 0.9015\n","\n","Epoch 00500: val_accuracy did not improve from 0.93596\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-c5dcafb79ae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mResNet101_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mResNet101_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"]}]},{"cell_type":"code","metadata":{"id":"7NJ8F7HNDGlD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628117756135,"user_tz":-540,"elapsed":11974934,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"8a0a7493-c7c2-474d-be49-98b01abf2fa6"},"source":["ResNet152_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[ResNet152_checkpoint])\n","# files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 45s 508ms/step - loss: 3.2574 - accuracy: 0.1401 - val_loss: 2406.8931 - val_accuracy: 0.0961\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09606, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/500\n","52/52 [==============================] - 23s 444ms/step - loss: 2.3038 - accuracy: 0.1839 - val_loss: 634.2455 - val_accuracy: 0.1010\n","\n","Epoch 00002: val_accuracy improved from 0.09606 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 3/500\n","52/52 [==============================] - 23s 445ms/step - loss: 2.3172 - accuracy: 0.1979 - val_loss: 34.0015 - val_accuracy: 0.1034\n","\n","Epoch 00003: val_accuracy improved from 0.10099 to 0.10345, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 4/500\n","52/52 [==============================] - 23s 445ms/step - loss: 1.9771 - accuracy: 0.3130 - val_loss: 12.5944 - val_accuracy: 0.0936\n","\n","Epoch 00004: val_accuracy did not improve from 0.10345\n","Epoch 5/500\n","52/52 [==============================] - 23s 443ms/step - loss: 1.5912 - accuracy: 0.4446 - val_loss: 15.5181 - val_accuracy: 0.0936\n","\n","Epoch 00005: val_accuracy did not improve from 0.10345\n","Epoch 6/500\n","52/52 [==============================] - 23s 443ms/step - loss: 1.3047 - accuracy: 0.5755 - val_loss: 11.2843 - val_accuracy: 0.1108\n","\n","Epoch 00006: val_accuracy improved from 0.10345 to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 7/500\n","52/52 [==============================] - 23s 444ms/step - loss: 1.2361 - accuracy: 0.6005 - val_loss: 14.5009 - val_accuracy: 0.1256\n","\n","Epoch 00007: val_accuracy improved from 0.11084 to 0.12562, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 8/500\n","52/52 [==============================] - 23s 444ms/step - loss: 1.0872 - accuracy: 0.6291 - val_loss: 11.0865 - val_accuracy: 0.1379\n","\n","Epoch 00008: val_accuracy improved from 0.12562 to 0.13793, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 9/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.9659 - accuracy: 0.6864 - val_loss: 13.7655 - val_accuracy: 0.1182\n","\n","Epoch 00009: val_accuracy did not improve from 0.13793\n","Epoch 10/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.8603 - accuracy: 0.7022 - val_loss: 2.8085 - val_accuracy: 0.3325\n","\n","Epoch 00010: val_accuracy improved from 0.13793 to 0.33251, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 11/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.7158 - accuracy: 0.7698 - val_loss: 2.2514 - val_accuracy: 0.4704\n","\n","Epoch 00011: val_accuracy improved from 0.33251 to 0.47044, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 12/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.6948 - accuracy: 0.7570 - val_loss: 1.3892 - val_accuracy: 0.6158\n","\n","Epoch 00012: val_accuracy improved from 0.47044 to 0.61576, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 13/500\n","52/52 [==============================] - 23s 451ms/step - loss: 0.6673 - accuracy: 0.7838 - val_loss: 1.1736 - val_accuracy: 0.6650\n","\n","Epoch 00013: val_accuracy improved from 0.61576 to 0.66502, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 14/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.5448 - accuracy: 0.8228 - val_loss: 1.5558 - val_accuracy: 0.6404\n","\n","Epoch 00014: val_accuracy did not improve from 0.66502\n","Epoch 15/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.5059 - accuracy: 0.8289 - val_loss: 1.2220 - val_accuracy: 0.6429\n","\n","Epoch 00015: val_accuracy did not improve from 0.66502\n","Epoch 16/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.4989 - accuracy: 0.8337 - val_loss: 1.1030 - val_accuracy: 0.6921\n","\n","Epoch 00016: val_accuracy improved from 0.66502 to 0.69212, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 17/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.4480 - accuracy: 0.8477 - val_loss: 1.2234 - val_accuracy: 0.7389\n","\n","Epoch 00017: val_accuracy improved from 0.69212 to 0.73892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 18/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.4710 - accuracy: 0.8429 - val_loss: 0.9965 - val_accuracy: 0.7414\n","\n","Epoch 00018: val_accuracy improved from 0.73892 to 0.74138, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 19/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.4998 - accuracy: 0.8307 - val_loss: 2.4634 - val_accuracy: 0.5443\n","\n","Epoch 00019: val_accuracy did not improve from 0.74138\n","Epoch 20/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.4349 - accuracy: 0.8575 - val_loss: 9.1591 - val_accuracy: 0.2463\n","\n","Epoch 00020: val_accuracy did not improve from 0.74138\n","Epoch 21/500\n","52/52 [==============================] - 23s 440ms/step - loss: 0.4096 - accuracy: 0.8611 - val_loss: 2.6850 - val_accuracy: 0.5099\n","\n","Epoch 00021: val_accuracy did not improve from 0.74138\n","Epoch 22/500\n","52/52 [==============================] - 23s 441ms/step - loss: 0.3512 - accuracy: 0.8776 - val_loss: 1.1822 - val_accuracy: 0.6946\n","\n","Epoch 00022: val_accuracy did not improve from 0.74138\n","Epoch 23/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.3315 - accuracy: 0.8837 - val_loss: 17.6498 - val_accuracy: 0.0985\n","\n","Epoch 00023: val_accuracy did not improve from 0.74138\n","Epoch 24/500\n","52/52 [==============================] - 23s 441ms/step - loss: 0.4127 - accuracy: 0.8593 - val_loss: 1.6034 - val_accuracy: 0.6700\n","\n","Epoch 00024: val_accuracy did not improve from 0.74138\n","Epoch 25/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.3238 - accuracy: 0.8776 - val_loss: 0.7512 - val_accuracy: 0.7882\n","\n","Epoch 00025: val_accuracy improved from 0.74138 to 0.78818, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 26/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.3940 - accuracy: 0.8648 - val_loss: 1.6031 - val_accuracy: 0.6773\n","\n","Epoch 00026: val_accuracy did not improve from 0.78818\n","Epoch 27/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.3614 - accuracy: 0.8825 - val_loss: 0.8676 - val_accuracy: 0.8030\n","\n","Epoch 00027: val_accuracy improved from 0.78818 to 0.80296, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 28/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.2765 - accuracy: 0.9007 - val_loss: 0.8429 - val_accuracy: 0.7759\n","\n","Epoch 00028: val_accuracy did not improve from 0.80296\n","Epoch 29/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.3828 - accuracy: 0.8636 - val_loss: 12.3604 - val_accuracy: 0.1379\n","\n","Epoch 00029: val_accuracy did not improve from 0.80296\n","Epoch 30/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.2870 - accuracy: 0.9026 - val_loss: 0.6133 - val_accuracy: 0.8202\n","\n","Epoch 00030: val_accuracy improved from 0.80296 to 0.82020, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 31/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.3072 - accuracy: 0.8971 - val_loss: 2.3797 - val_accuracy: 0.5739\n","\n","Epoch 00031: val_accuracy did not improve from 0.82020\n","Epoch 32/500\n","52/52 [==============================] - 23s 441ms/step - loss: 0.2988 - accuracy: 0.8952 - val_loss: 1.5201 - val_accuracy: 0.7365\n","\n","Epoch 00032: val_accuracy did not improve from 0.82020\n","Epoch 33/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.2790 - accuracy: 0.9013 - val_loss: 0.6271 - val_accuracy: 0.8571\n","\n","Epoch 00033: val_accuracy improved from 0.82020 to 0.85714, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 34/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.2489 - accuracy: 0.9111 - val_loss: 0.5015 - val_accuracy: 0.8645\n","\n","Epoch 00034: val_accuracy improved from 0.85714 to 0.86453, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 35/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.2661 - accuracy: 0.9093 - val_loss: 0.6907 - val_accuracy: 0.8128\n","\n","Epoch 00035: val_accuracy did not improve from 0.86453\n","Epoch 36/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.2172 - accuracy: 0.9269 - val_loss: 0.7483 - val_accuracy: 0.8325\n","\n","Epoch 00036: val_accuracy did not improve from 0.86453\n","Epoch 37/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.2370 - accuracy: 0.9239 - val_loss: 0.7081 - val_accuracy: 0.8079\n","\n","Epoch 00037: val_accuracy did not improve from 0.86453\n","Epoch 38/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.2107 - accuracy: 0.9245 - val_loss: 0.3926 - val_accuracy: 0.8744\n","\n","Epoch 00038: val_accuracy improved from 0.86453 to 0.87438, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 39/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1654 - accuracy: 0.9373 - val_loss: 0.7138 - val_accuracy: 0.8128\n","\n","Epoch 00039: val_accuracy did not improve from 0.87438\n","Epoch 40/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.2996 - accuracy: 0.8995 - val_loss: 1.1674 - val_accuracy: 0.7414\n","\n","Epoch 00040: val_accuracy did not improve from 0.87438\n","Epoch 41/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.2235 - accuracy: 0.9269 - val_loss: 4.8016 - val_accuracy: 0.4384\n","\n","Epoch 00041: val_accuracy did not improve from 0.87438\n","Epoch 42/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.2405 - accuracy: 0.9111 - val_loss: 0.6503 - val_accuracy: 0.8300\n","\n","Epoch 00042: val_accuracy did not improve from 0.87438\n","Epoch 43/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1972 - accuracy: 0.9336 - val_loss: 0.5324 - val_accuracy: 0.8473\n","\n","Epoch 00043: val_accuracy did not improve from 0.87438\n","Epoch 44/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1709 - accuracy: 0.9403 - val_loss: 1.3050 - val_accuracy: 0.7438\n","\n","Epoch 00044: val_accuracy did not improve from 0.87438\n","Epoch 45/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1693 - accuracy: 0.9434 - val_loss: 0.6665 - val_accuracy: 0.8473\n","\n","Epoch 00045: val_accuracy did not improve from 0.87438\n","Epoch 46/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1751 - accuracy: 0.9330 - val_loss: 0.7114 - val_accuracy: 0.8350\n","\n","Epoch 00046: val_accuracy did not improve from 0.87438\n","Epoch 47/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1923 - accuracy: 0.9287 - val_loss: 0.7195 - val_accuracy: 0.8005\n","\n","Epoch 00047: val_accuracy did not improve from 0.87438\n","Epoch 48/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.2800 - accuracy: 0.9068 - val_loss: 0.8739 - val_accuracy: 0.7537\n","\n","Epoch 00048: val_accuracy did not improve from 0.87438\n","Epoch 49/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1915 - accuracy: 0.9354 - val_loss: 0.8542 - val_accuracy: 0.8103\n","\n","Epoch 00049: val_accuracy did not improve from 0.87438\n","Epoch 50/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1840 - accuracy: 0.9391 - val_loss: 0.8164 - val_accuracy: 0.7931\n","\n","Epoch 00050: val_accuracy did not improve from 0.87438\n","Epoch 51/500\n","52/52 [==============================] - 23s 447ms/step - loss: 0.1736 - accuracy: 0.9397 - val_loss: 0.5910 - val_accuracy: 0.8350\n","\n","Epoch 00051: val_accuracy did not improve from 0.87438\n","Epoch 52/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1593 - accuracy: 0.9507 - val_loss: 0.8815 - val_accuracy: 0.7783\n","\n","Epoch 00052: val_accuracy did not improve from 0.87438\n","Epoch 53/500\n","52/52 [==============================] - 23s 441ms/step - loss: 0.1545 - accuracy: 0.9507 - val_loss: 0.6292 - val_accuracy: 0.8522\n","\n","Epoch 00053: val_accuracy did not improve from 0.87438\n","Epoch 54/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1415 - accuracy: 0.9464 - val_loss: 1.1417 - val_accuracy: 0.7512\n","\n","Epoch 00054: val_accuracy did not improve from 0.87438\n","Epoch 55/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1311 - accuracy: 0.9488 - val_loss: 0.7178 - val_accuracy: 0.8350\n","\n","Epoch 00055: val_accuracy did not improve from 0.87438\n","Epoch 56/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1356 - accuracy: 0.9549 - val_loss: 0.5363 - val_accuracy: 0.8621\n","\n","Epoch 00056: val_accuracy did not improve from 0.87438\n","Epoch 57/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.2159 - accuracy: 0.9312 - val_loss: 1.3752 - val_accuracy: 0.7192\n","\n","Epoch 00057: val_accuracy did not improve from 0.87438\n","Epoch 58/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.2600 - accuracy: 0.9086 - val_loss: 1.5843 - val_accuracy: 0.7192\n","\n","Epoch 00058: val_accuracy did not improve from 0.87438\n","Epoch 59/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1960 - accuracy: 0.9342 - val_loss: 0.7531 - val_accuracy: 0.8251\n","\n","Epoch 00059: val_accuracy did not improve from 0.87438\n","Epoch 60/500\n","52/52 [==============================] - 23s 441ms/step - loss: 0.1740 - accuracy: 0.9361 - val_loss: 0.6838 - val_accuracy: 0.8202\n","\n","Epoch 00060: val_accuracy did not improve from 0.87438\n","Epoch 61/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.1529 - accuracy: 0.9476 - val_loss: 0.9477 - val_accuracy: 0.8079\n","\n","Epoch 00061: val_accuracy did not improve from 0.87438\n","Epoch 62/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.1347 - accuracy: 0.9549 - val_loss: 0.8761 - val_accuracy: 0.8153\n","\n","Epoch 00062: val_accuracy did not improve from 0.87438\n","Epoch 63/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1227 - accuracy: 0.9586 - val_loss: 0.7302 - val_accuracy: 0.8424\n","\n","Epoch 00063: val_accuracy did not improve from 0.87438\n","Epoch 64/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1244 - accuracy: 0.9604 - val_loss: 0.6634 - val_accuracy: 0.8251\n","\n","Epoch 00064: val_accuracy did not improve from 0.87438\n","Epoch 65/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1918 - accuracy: 0.9409 - val_loss: 10.1026 - val_accuracy: 0.2635\n","\n","Epoch 00065: val_accuracy did not improve from 0.87438\n","Epoch 66/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.1664 - accuracy: 0.9458 - val_loss: 13.4951 - val_accuracy: 0.2069\n","\n","Epoch 00066: val_accuracy did not improve from 0.87438\n","Epoch 67/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0983 - accuracy: 0.9683 - val_loss: 0.6680 - val_accuracy: 0.8571\n","\n","Epoch 00067: val_accuracy did not improve from 0.87438\n","Epoch 68/500\n","52/52 [==============================] - 24s 455ms/step - loss: 0.2306 - accuracy: 0.9354 - val_loss: 1.1268 - val_accuracy: 0.7611\n","\n","Epoch 00068: val_accuracy did not improve from 0.87438\n","Epoch 69/500\n","52/52 [==============================] - 23s 441ms/step - loss: 0.1792 - accuracy: 0.9342 - val_loss: 0.6377 - val_accuracy: 0.8645\n","\n","Epoch 00069: val_accuracy did not improve from 0.87438\n","Epoch 70/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.1049 - accuracy: 0.9708 - val_loss: 0.7138 - val_accuracy: 0.8399\n","\n","Epoch 00070: val_accuracy did not improve from 0.87438\n","Epoch 71/500\n","52/52 [==============================] - 23s 448ms/step - loss: 0.0959 - accuracy: 0.9732 - val_loss: 0.6351 - val_accuracy: 0.8621\n","\n","Epoch 00071: val_accuracy did not improve from 0.87438\n","Epoch 72/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.1075 - accuracy: 0.9598 - val_loss: 0.5642 - val_accuracy: 0.8424\n","\n","Epoch 00072: val_accuracy did not improve from 0.87438\n","Epoch 73/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0977 - accuracy: 0.9689 - val_loss: 0.5925 - val_accuracy: 0.8719\n","\n","Epoch 00073: val_accuracy did not improve from 0.87438\n","Epoch 74/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0901 - accuracy: 0.9732 - val_loss: 0.7979 - val_accuracy: 0.8227\n","\n","Epoch 00074: val_accuracy did not improve from 0.87438\n","Epoch 75/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1095 - accuracy: 0.9610 - val_loss: 0.6711 - val_accuracy: 0.8842\n","\n","Epoch 00075: val_accuracy improved from 0.87438 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 76/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1519 - accuracy: 0.9476 - val_loss: 3.1417 - val_accuracy: 0.6232\n","\n","Epoch 00076: val_accuracy did not improve from 0.88424\n","Epoch 77/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.2011 - accuracy: 0.9361 - val_loss: 0.9853 - val_accuracy: 0.7980\n","\n","Epoch 00077: val_accuracy did not improve from 0.88424\n","Epoch 78/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0969 - accuracy: 0.9653 - val_loss: 0.8288 - val_accuracy: 0.8153\n","\n","Epoch 00078: val_accuracy did not improve from 0.88424\n","Epoch 79/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0631 - accuracy: 0.9793 - val_loss: 0.4805 - val_accuracy: 0.8793\n","\n","Epoch 00079: val_accuracy did not improve from 0.88424\n","Epoch 80/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1127 - accuracy: 0.9629 - val_loss: 0.4593 - val_accuracy: 0.8867\n","\n","Epoch 00080: val_accuracy improved from 0.88424 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 81/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.1009 - accuracy: 0.9683 - val_loss: 0.7469 - val_accuracy: 0.8177\n","\n","Epoch 00081: val_accuracy did not improve from 0.88670\n","Epoch 82/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.0957 - accuracy: 0.9677 - val_loss: 0.5554 - val_accuracy: 0.8621\n","\n","Epoch 00082: val_accuracy did not improve from 0.88670\n","Epoch 83/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1185 - accuracy: 0.9647 - val_loss: 1.1047 - val_accuracy: 0.7857\n","\n","Epoch 00083: val_accuracy did not improve from 0.88670\n","Epoch 84/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.1744 - accuracy: 0.9421 - val_loss: 2.1375 - val_accuracy: 0.7143\n","\n","Epoch 00084: val_accuracy did not improve from 0.88670\n","Epoch 85/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1146 - accuracy: 0.9616 - val_loss: 3.4772 - val_accuracy: 0.5911\n","\n","Epoch 00085: val_accuracy did not improve from 0.88670\n","Epoch 86/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.1055 - accuracy: 0.9641 - val_loss: 0.6107 - val_accuracy: 0.8670\n","\n","Epoch 00086: val_accuracy did not improve from 0.88670\n","Epoch 87/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0743 - accuracy: 0.9750 - val_loss: 0.8477 - val_accuracy: 0.8325\n","\n","Epoch 00087: val_accuracy did not improve from 0.88670\n","Epoch 88/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.0640 - accuracy: 0.9793 - val_loss: 0.6669 - val_accuracy: 0.8621\n","\n","Epoch 00088: val_accuracy did not improve from 0.88670\n","Epoch 89/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1140 - accuracy: 0.9647 - val_loss: 1.0121 - val_accuracy: 0.8227\n","\n","Epoch 00089: val_accuracy did not improve from 0.88670\n","Epoch 90/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.1028 - accuracy: 0.9653 - val_loss: 0.4635 - val_accuracy: 0.8916\n","\n","Epoch 00090: val_accuracy improved from 0.88670 to 0.89163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 91/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0968 - accuracy: 0.9647 - val_loss: 1.0936 - val_accuracy: 0.7857\n","\n","Epoch 00091: val_accuracy did not improve from 0.89163\n","Epoch 92/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.2343 - accuracy: 0.9287 - val_loss: 8.4523 - val_accuracy: 0.3177\n","\n","Epoch 00092: val_accuracy did not improve from 0.89163\n","Epoch 93/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.1034 - accuracy: 0.9647 - val_loss: 0.4386 - val_accuracy: 0.8892\n","\n","Epoch 00093: val_accuracy did not improve from 0.89163\n","Epoch 94/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0720 - accuracy: 0.9756 - val_loss: 2.0780 - val_accuracy: 0.6601\n","\n","Epoch 00094: val_accuracy did not improve from 0.89163\n","Epoch 95/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0841 - accuracy: 0.9744 - val_loss: 0.7481 - val_accuracy: 0.8571\n","\n","Epoch 00095: val_accuracy did not improve from 0.89163\n","Epoch 96/500\n","52/52 [==============================] - 23s 447ms/step - loss: 0.0793 - accuracy: 0.9732 - val_loss: 0.6562 - val_accuracy: 0.8522\n","\n","Epoch 00096: val_accuracy did not improve from 0.89163\n","Epoch 97/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0495 - accuracy: 0.9842 - val_loss: 0.7501 - val_accuracy: 0.8596\n","\n","Epoch 00097: val_accuracy did not improve from 0.89163\n","Epoch 98/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0968 - accuracy: 0.9683 - val_loss: 0.4837 - val_accuracy: 0.8990\n","\n","Epoch 00098: val_accuracy improved from 0.89163 to 0.89901, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 99/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0880 - accuracy: 0.9653 - val_loss: 0.6681 - val_accuracy: 0.8645\n","\n","Epoch 00099: val_accuracy did not improve from 0.89901\n","Epoch 100/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0932 - accuracy: 0.9671 - val_loss: 0.7901 - val_accuracy: 0.8276\n","\n","Epoch 00100: val_accuracy did not improve from 0.89901\n","Epoch 101/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0774 - accuracy: 0.9744 - val_loss: 0.9346 - val_accuracy: 0.8128\n","\n","Epoch 00101: val_accuracy did not improve from 0.89901\n","Epoch 102/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1056 - accuracy: 0.9641 - val_loss: 0.4920 - val_accuracy: 0.8695\n","\n","Epoch 00102: val_accuracy did not improve from 0.89901\n","Epoch 103/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.1426 - accuracy: 0.9519 - val_loss: 1.4984 - val_accuracy: 0.7340\n","\n","Epoch 00103: val_accuracy did not improve from 0.89901\n","Epoch 104/500\n","52/52 [==============================] - 23s 440ms/step - loss: 0.0910 - accuracy: 0.9683 - val_loss: 0.7870 - val_accuracy: 0.8079\n","\n","Epoch 00104: val_accuracy did not improve from 0.89901\n","Epoch 105/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0855 - accuracy: 0.9738 - val_loss: 0.6186 - val_accuracy: 0.8695\n","\n","Epoch 00105: val_accuracy did not improve from 0.89901\n","Epoch 106/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0621 - accuracy: 0.9781 - val_loss: 0.6320 - val_accuracy: 0.8695\n","\n","Epoch 00106: val_accuracy did not improve from 0.89901\n","Epoch 107/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0549 - accuracy: 0.9787 - val_loss: 0.4957 - val_accuracy: 0.8990\n","\n","Epoch 00107: val_accuracy did not improve from 0.89901\n","Epoch 108/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0725 - accuracy: 0.9726 - val_loss: 1.3708 - val_accuracy: 0.8030\n","\n","Epoch 00108: val_accuracy did not improve from 0.89901\n","Epoch 109/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0739 - accuracy: 0.9762 - val_loss: 0.8561 - val_accuracy: 0.8300\n","\n","Epoch 00109: val_accuracy did not improve from 0.89901\n","Epoch 110/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.1041 - accuracy: 0.9714 - val_loss: 0.5633 - val_accuracy: 0.8818\n","\n","Epoch 00110: val_accuracy did not improve from 0.89901\n","Epoch 111/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0901 - accuracy: 0.9702 - val_loss: 1.4206 - val_accuracy: 0.7586\n","\n","Epoch 00111: val_accuracy did not improve from 0.89901\n","Epoch 112/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0775 - accuracy: 0.9702 - val_loss: 0.6135 - val_accuracy: 0.8547\n","\n","Epoch 00112: val_accuracy did not improve from 0.89901\n","Epoch 113/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.1452 - accuracy: 0.9525 - val_loss: 0.9921 - val_accuracy: 0.8251\n","\n","Epoch 00113: val_accuracy did not improve from 0.89901\n","Epoch 114/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1010 - accuracy: 0.9695 - val_loss: 0.6663 - val_accuracy: 0.8424\n","\n","Epoch 00114: val_accuracy did not improve from 0.89901\n","Epoch 115/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0614 - accuracy: 0.9787 - val_loss: 0.4457 - val_accuracy: 0.8892\n","\n","Epoch 00115: val_accuracy did not improve from 0.89901\n","Epoch 116/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0459 - accuracy: 0.9823 - val_loss: 0.5801 - val_accuracy: 0.8842\n","\n","Epoch 00116: val_accuracy did not improve from 0.89901\n","Epoch 117/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0961 - accuracy: 0.9689 - val_loss: 1.7695 - val_accuracy: 0.6897\n","\n","Epoch 00117: val_accuracy did not improve from 0.89901\n","Epoch 118/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1000 - accuracy: 0.9695 - val_loss: 0.7635 - val_accuracy: 0.8596\n","\n","Epoch 00118: val_accuracy did not improve from 0.89901\n","Epoch 119/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.0650 - accuracy: 0.9781 - val_loss: 0.6775 - val_accuracy: 0.8621\n","\n","Epoch 00119: val_accuracy did not improve from 0.89901\n","Epoch 120/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.0728 - accuracy: 0.9756 - val_loss: 1.1917 - val_accuracy: 0.7956\n","\n","Epoch 00120: val_accuracy did not improve from 0.89901\n","Epoch 121/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0370 - accuracy: 0.9878 - val_loss: 0.8287 - val_accuracy: 0.8350\n","\n","Epoch 00121: val_accuracy did not improve from 0.89901\n","Epoch 122/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0452 - accuracy: 0.9848 - val_loss: 14.6350 - val_accuracy: 0.1576\n","\n","Epoch 00122: val_accuracy did not improve from 0.89901\n","Epoch 123/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.1092 - accuracy: 0.9647 - val_loss: 4.5030 - val_accuracy: 0.5197\n","\n","Epoch 00123: val_accuracy did not improve from 0.89901\n","Epoch 124/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0885 - accuracy: 0.9738 - val_loss: 0.8698 - val_accuracy: 0.8498\n","\n","Epoch 00124: val_accuracy did not improve from 0.89901\n","Epoch 125/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0949 - accuracy: 0.9708 - val_loss: 0.5077 - val_accuracy: 0.8670\n","\n","Epoch 00125: val_accuracy did not improve from 0.89901\n","Epoch 126/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0529 - accuracy: 0.9811 - val_loss: 0.5169 - val_accuracy: 0.8842\n","\n","Epoch 00126: val_accuracy did not improve from 0.89901\n","Epoch 127/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0742 - accuracy: 0.9732 - val_loss: 0.7895 - val_accuracy: 0.8399\n","\n","Epoch 00127: val_accuracy did not improve from 0.89901\n","Epoch 128/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0458 - accuracy: 0.9878 - val_loss: 0.6947 - val_accuracy: 0.8695\n","\n","Epoch 00128: val_accuracy did not improve from 0.89901\n","Epoch 129/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0315 - accuracy: 0.9878 - val_loss: 0.5247 - val_accuracy: 0.8892\n","\n","Epoch 00129: val_accuracy did not improve from 0.89901\n","Epoch 130/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0330 - accuracy: 0.9884 - val_loss: 0.6949 - val_accuracy: 0.8645\n","\n","Epoch 00130: val_accuracy did not improve from 0.89901\n","Epoch 131/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0469 - accuracy: 0.9854 - val_loss: 0.8656 - val_accuracy: 0.8399\n","\n","Epoch 00131: val_accuracy did not improve from 0.89901\n","Epoch 132/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0932 - accuracy: 0.9689 - val_loss: 8.5500 - val_accuracy: 0.3350\n","\n","Epoch 00132: val_accuracy did not improve from 0.89901\n","Epoch 133/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.0854 - accuracy: 0.9732 - val_loss: 0.7196 - val_accuracy: 0.8744\n","\n","Epoch 00133: val_accuracy did not improve from 0.89901\n","Epoch 134/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1380 - accuracy: 0.9574 - val_loss: 14.0305 - val_accuracy: 0.1921\n","\n","Epoch 00134: val_accuracy did not improve from 0.89901\n","Epoch 135/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0764 - accuracy: 0.9762 - val_loss: 2.9518 - val_accuracy: 0.6305\n","\n","Epoch 00135: val_accuracy did not improve from 0.89901\n","Epoch 136/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0416 - accuracy: 0.9860 - val_loss: 0.5157 - val_accuracy: 0.8990\n","\n","Epoch 00136: val_accuracy did not improve from 0.89901\n","Epoch 137/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0341 - accuracy: 0.9878 - val_loss: 0.7097 - val_accuracy: 0.8571\n","\n","Epoch 00137: val_accuracy did not improve from 0.89901\n","Epoch 138/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0398 - accuracy: 0.9896 - val_loss: 0.5855 - val_accuracy: 0.8719\n","\n","Epoch 00138: val_accuracy did not improve from 0.89901\n","Epoch 139/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.4273 - val_accuracy: 0.8916\n","\n","Epoch 00139: val_accuracy did not improve from 0.89901\n","Epoch 140/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0271 - accuracy: 0.9909 - val_loss: 0.4371 - val_accuracy: 0.8892\n","\n","Epoch 00140: val_accuracy did not improve from 0.89901\n","Epoch 141/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0675 - accuracy: 0.9811 - val_loss: 0.9967 - val_accuracy: 0.8128\n","\n","Epoch 00141: val_accuracy did not improve from 0.89901\n","Epoch 142/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1682 - accuracy: 0.9525 - val_loss: 0.9767 - val_accuracy: 0.8079\n","\n","Epoch 00142: val_accuracy did not improve from 0.89901\n","Epoch 143/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.0808 - accuracy: 0.9738 - val_loss: 0.7219 - val_accuracy: 0.8621\n","\n","Epoch 00143: val_accuracy did not improve from 0.89901\n","Epoch 144/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0327 - accuracy: 0.9878 - val_loss: 0.5662 - val_accuracy: 0.8793\n","\n","Epoch 00144: val_accuracy did not improve from 0.89901\n","Epoch 145/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.5035 - val_accuracy: 0.8941\n","\n","Epoch 00145: val_accuracy did not improve from 0.89901\n","Epoch 146/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.4814 - val_accuracy: 0.8966\n","\n","Epoch 00146: val_accuracy did not improve from 0.89901\n","Epoch 147/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.0225 - accuracy: 0.9915 - val_loss: 0.4561 - val_accuracy: 0.8941\n","\n","Epoch 00147: val_accuracy did not improve from 0.89901\n","Epoch 148/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0298 - accuracy: 0.9909 - val_loss: 0.5075 - val_accuracy: 0.8818\n","\n","Epoch 00148: val_accuracy did not improve from 0.89901\n","Epoch 149/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0323 - accuracy: 0.9872 - val_loss: 0.7170 - val_accuracy: 0.8645\n","\n","Epoch 00149: val_accuracy did not improve from 0.89901\n","Epoch 150/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.0588 - accuracy: 0.9823 - val_loss: 0.6986 - val_accuracy: 0.8596\n","\n","Epoch 00150: val_accuracy did not improve from 0.89901\n","Epoch 151/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.6201 - val_accuracy: 0.8941\n","\n","Epoch 00151: val_accuracy did not improve from 0.89901\n","Epoch 152/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0437 - accuracy: 0.9848 - val_loss: 1.2382 - val_accuracy: 0.7931\n","\n","Epoch 00152: val_accuracy did not improve from 0.89901\n","Epoch 153/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.1201 - accuracy: 0.9598 - val_loss: 0.8714 - val_accuracy: 0.8547\n","\n","Epoch 00153: val_accuracy did not improve from 0.89901\n","Epoch 154/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0686 - accuracy: 0.9750 - val_loss: 1.1406 - val_accuracy: 0.8227\n","\n","Epoch 00154: val_accuracy did not improve from 0.89901\n","Epoch 155/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0492 - accuracy: 0.9836 - val_loss: 1.0228 - val_accuracy: 0.8227\n","\n","Epoch 00155: val_accuracy did not improve from 0.89901\n","Epoch 156/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0362 - accuracy: 0.9860 - val_loss: 0.6287 - val_accuracy: 0.8744\n","\n","Epoch 00156: val_accuracy did not improve from 0.89901\n","Epoch 157/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0496 - accuracy: 0.9836 - val_loss: 5.7297 - val_accuracy: 0.5000\n","\n","Epoch 00157: val_accuracy did not improve from 0.89901\n","Epoch 158/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0351 - accuracy: 0.9860 - val_loss: 0.7609 - val_accuracy: 0.8695\n","\n","Epoch 00158: val_accuracy did not improve from 0.89901\n","Epoch 159/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0760 - accuracy: 0.9805 - val_loss: 1.8825 - val_accuracy: 0.6872\n","\n","Epoch 00159: val_accuracy did not improve from 0.89901\n","Epoch 160/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0844 - accuracy: 0.9683 - val_loss: 0.8976 - val_accuracy: 0.8300\n","\n","Epoch 00160: val_accuracy did not improve from 0.89901\n","Epoch 161/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0295 - accuracy: 0.9921 - val_loss: 0.4407 - val_accuracy: 0.8941\n","\n","Epoch 00161: val_accuracy did not improve from 0.89901\n","Epoch 162/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0396 - accuracy: 0.9866 - val_loss: 0.6518 - val_accuracy: 0.8695\n","\n","Epoch 00162: val_accuracy did not improve from 0.89901\n","Epoch 163/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.5542 - val_accuracy: 0.8892\n","\n","Epoch 00163: val_accuracy did not improve from 0.89901\n","Epoch 164/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0404 - accuracy: 0.9878 - val_loss: 0.8334 - val_accuracy: 0.8547\n","\n","Epoch 00164: val_accuracy did not improve from 0.89901\n","Epoch 165/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0851 - accuracy: 0.9799 - val_loss: 1.0999 - val_accuracy: 0.8202\n","\n","Epoch 00165: val_accuracy did not improve from 0.89901\n","Epoch 166/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0506 - accuracy: 0.9854 - val_loss: 0.6851 - val_accuracy: 0.8596\n","\n","Epoch 00166: val_accuracy did not improve from 0.89901\n","Epoch 167/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0317 - accuracy: 0.9921 - val_loss: 0.6102 - val_accuracy: 0.8645\n","\n","Epoch 00167: val_accuracy did not improve from 0.89901\n","Epoch 168/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.6422 - val_accuracy: 0.8892\n","\n","Epoch 00168: val_accuracy did not improve from 0.89901\n","Epoch 169/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0246 - accuracy: 0.9909 - val_loss: 0.5904 - val_accuracy: 0.8719\n","\n","Epoch 00169: val_accuracy did not improve from 0.89901\n","Epoch 170/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0166 - accuracy: 0.9939 - val_loss: 0.4863 - val_accuracy: 0.8892\n","\n","Epoch 00170: val_accuracy did not improve from 0.89901\n","Epoch 171/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 1.3767 - val_accuracy: 0.8128\n","\n","Epoch 00171: val_accuracy did not improve from 0.89901\n","Epoch 172/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1352 - accuracy: 0.9549 - val_loss: 0.8950 - val_accuracy: 0.8842\n","\n","Epoch 00172: val_accuracy did not improve from 0.89901\n","Epoch 173/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0539 - accuracy: 0.9793 - val_loss: 0.5321 - val_accuracy: 0.8966\n","\n","Epoch 00173: val_accuracy did not improve from 0.89901\n","Epoch 174/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0706 - accuracy: 0.9781 - val_loss: 1.3033 - val_accuracy: 0.8227\n","\n","Epoch 00174: val_accuracy did not improve from 0.89901\n","Epoch 175/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0564 - accuracy: 0.9817 - val_loss: 0.5804 - val_accuracy: 0.8695\n","\n","Epoch 00175: val_accuracy did not improve from 0.89901\n","Epoch 176/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0330 - accuracy: 0.9896 - val_loss: 0.9775 - val_accuracy: 0.8498\n","\n","Epoch 00176: val_accuracy did not improve from 0.89901\n","Epoch 177/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0301 - accuracy: 0.9903 - val_loss: 0.7239 - val_accuracy: 0.8621\n","\n","Epoch 00177: val_accuracy did not improve from 0.89901\n","Epoch 178/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0443 - accuracy: 0.9842 - val_loss: 0.7186 - val_accuracy: 0.8744\n","\n","Epoch 00178: val_accuracy did not improve from 0.89901\n","Epoch 179/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.5719 - val_accuracy: 0.8916\n","\n","Epoch 00179: val_accuracy did not improve from 0.89901\n","Epoch 180/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0517 - accuracy: 0.9829 - val_loss: 0.6733 - val_accuracy: 0.8842\n","\n","Epoch 00180: val_accuracy did not improve from 0.89901\n","Epoch 181/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0653 - accuracy: 0.9811 - val_loss: 0.6826 - val_accuracy: 0.8596\n","\n","Epoch 00181: val_accuracy did not improve from 0.89901\n","Epoch 182/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0518 - accuracy: 0.9842 - val_loss: 0.5625 - val_accuracy: 0.8842\n","\n","Epoch 00182: val_accuracy did not improve from 0.89901\n","Epoch 183/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.6462 - val_accuracy: 0.8818\n","\n","Epoch 00183: val_accuracy did not improve from 0.89901\n","Epoch 184/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.4815 - val_accuracy: 0.8966\n","\n","Epoch 00184: val_accuracy did not improve from 0.89901\n","Epoch 185/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 0.9253 - val_accuracy: 0.8473\n","\n","Epoch 00185: val_accuracy did not improve from 0.89901\n","Epoch 186/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.5883 - val_accuracy: 0.8719\n","\n","Epoch 00186: val_accuracy did not improve from 0.89901\n","Epoch 187/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0305 - accuracy: 0.9927 - val_loss: 0.7483 - val_accuracy: 0.8596\n","\n","Epoch 00187: val_accuracy did not improve from 0.89901\n","Epoch 188/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 1.0076 - val_accuracy: 0.8399\n","\n","Epoch 00188: val_accuracy did not improve from 0.89901\n","Epoch 189/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0378 - accuracy: 0.9872 - val_loss: 0.6483 - val_accuracy: 0.8719\n","\n","Epoch 00189: val_accuracy did not improve from 0.89901\n","Epoch 190/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.8244 - val_accuracy: 0.8448\n","\n","Epoch 00190: val_accuracy did not improve from 0.89901\n","Epoch 191/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0227 - accuracy: 0.9921 - val_loss: 0.6504 - val_accuracy: 0.8892\n","\n","Epoch 00191: val_accuracy did not improve from 0.89901\n","Epoch 192/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0215 - accuracy: 0.9915 - val_loss: 0.6499 - val_accuracy: 0.8867\n","\n","Epoch 00192: val_accuracy did not improve from 0.89901\n","Epoch 193/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.4544 - val_accuracy: 0.9212\n","\n","Epoch 00193: val_accuracy improved from 0.89901 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 194/500\n","52/52 [==============================] - 23s 447ms/step - loss: 0.0471 - accuracy: 0.9854 - val_loss: 0.9342 - val_accuracy: 0.8473\n","\n","Epoch 00194: val_accuracy did not improve from 0.92118\n","Epoch 195/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0478 - accuracy: 0.9836 - val_loss: 4.5458 - val_accuracy: 0.6158\n","\n","Epoch 00195: val_accuracy did not improve from 0.92118\n","Epoch 196/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0628 - accuracy: 0.9769 - val_loss: 5.1618 - val_accuracy: 0.5887\n","\n","Epoch 00196: val_accuracy did not improve from 0.92118\n","Epoch 197/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0600 - accuracy: 0.9793 - val_loss: 0.8929 - val_accuracy: 0.8300\n","\n","Epoch 00197: val_accuracy did not improve from 0.92118\n","Epoch 198/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1291 - accuracy: 0.9659 - val_loss: 3.0480 - val_accuracy: 0.6453\n","\n","Epoch 00198: val_accuracy did not improve from 0.92118\n","Epoch 199/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1208 - accuracy: 0.9604 - val_loss: 0.8933 - val_accuracy: 0.8621\n","\n","Epoch 00199: val_accuracy did not improve from 0.92118\n","Epoch 200/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0468 - accuracy: 0.9823 - val_loss: 0.7536 - val_accuracy: 0.8522\n","\n","Epoch 00200: val_accuracy did not improve from 0.92118\n","Epoch 201/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0584 - accuracy: 0.9811 - val_loss: 0.6306 - val_accuracy: 0.8892\n","\n","Epoch 00201: val_accuracy did not improve from 0.92118\n","Epoch 202/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0358 - accuracy: 0.9866 - val_loss: 0.5674 - val_accuracy: 0.8695\n","\n","Epoch 00202: val_accuracy did not improve from 0.92118\n","Epoch 203/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0395 - accuracy: 0.9842 - val_loss: 0.5407 - val_accuracy: 0.9039\n","\n","Epoch 00203: val_accuracy did not improve from 0.92118\n","Epoch 204/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0291 - accuracy: 0.9933 - val_loss: 0.5540 - val_accuracy: 0.8916\n","\n","Epoch 00204: val_accuracy did not improve from 0.92118\n","Epoch 205/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.4750 - val_accuracy: 0.9039\n","\n","Epoch 00205: val_accuracy did not improve from 0.92118\n","Epoch 206/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5323 - val_accuracy: 0.8892\n","\n","Epoch 00206: val_accuracy did not improve from 0.92118\n","Epoch 207/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0506 - accuracy: 0.9890 - val_loss: 0.8310 - val_accuracy: 0.8448\n","\n","Epoch 00207: val_accuracy did not improve from 0.92118\n","Epoch 208/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.6559 - val_accuracy: 0.8695\n","\n","Epoch 00208: val_accuracy did not improve from 0.92118\n","Epoch 209/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.6633 - val_accuracy: 0.8768\n","\n","Epoch 00209: val_accuracy did not improve from 0.92118\n","Epoch 210/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.6191 - val_accuracy: 0.8768\n","\n","Epoch 00210: val_accuracy did not improve from 0.92118\n","Epoch 211/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.6487 - val_accuracy: 0.8768\n","\n","Epoch 00211: val_accuracy did not improve from 0.92118\n","Epoch 212/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0078 - accuracy: 0.9963 - val_loss: 0.4226 - val_accuracy: 0.8966\n","\n","Epoch 00212: val_accuracy did not improve from 0.92118\n","Epoch 213/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.7529 - val_accuracy: 0.8621\n","\n","Epoch 00213: val_accuracy did not improve from 0.92118\n","Epoch 214/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0251 - accuracy: 0.9951 - val_loss: 0.6076 - val_accuracy: 0.8867\n","\n","Epoch 00214: val_accuracy did not improve from 0.92118\n","Epoch 215/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 0.6125 - val_accuracy: 0.8892\n","\n","Epoch 00215: val_accuracy did not improve from 0.92118\n","Epoch 216/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.5721 - val_accuracy: 0.9089\n","\n","Epoch 00216: val_accuracy did not improve from 0.92118\n","Epoch 217/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0276 - accuracy: 0.9890 - val_loss: 0.7530 - val_accuracy: 0.8744\n","\n","Epoch 00217: val_accuracy did not improve from 0.92118\n","Epoch 218/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.6313 - val_accuracy: 0.8818\n","\n","Epoch 00218: val_accuracy did not improve from 0.92118\n","Epoch 219/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.5587 - val_accuracy: 0.8768\n","\n","Epoch 00219: val_accuracy did not improve from 0.92118\n","Epoch 220/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0264 - accuracy: 0.9927 - val_loss: 0.8354 - val_accuracy: 0.8768\n","\n","Epoch 00220: val_accuracy did not improve from 0.92118\n","Epoch 221/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0333 - accuracy: 0.9909 - val_loss: 0.5720 - val_accuracy: 0.8941\n","\n","Epoch 00221: val_accuracy did not improve from 0.92118\n","Epoch 222/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0541 - accuracy: 0.9842 - val_loss: 0.7847 - val_accuracy: 0.8768\n","\n","Epoch 00222: val_accuracy did not improve from 0.92118\n","Epoch 223/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0536 - accuracy: 0.9842 - val_loss: 1.2973 - val_accuracy: 0.8128\n","\n","Epoch 00223: val_accuracy did not improve from 0.92118\n","Epoch 224/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1023 - accuracy: 0.9677 - val_loss: 1.0131 - val_accuracy: 0.7980\n","\n","Epoch 00224: val_accuracy did not improve from 0.92118\n","Epoch 225/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0540 - accuracy: 0.9769 - val_loss: 0.5901 - val_accuracy: 0.8719\n","\n","Epoch 00225: val_accuracy did not improve from 0.92118\n","Epoch 226/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0720 - accuracy: 0.9744 - val_loss: 11.5766 - val_accuracy: 0.3621\n","\n","Epoch 00226: val_accuracy did not improve from 0.92118\n","Epoch 227/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0871 - accuracy: 0.9750 - val_loss: 5.3133 - val_accuracy: 0.5690\n","\n","Epoch 00227: val_accuracy did not improve from 0.92118\n","Epoch 228/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0413 - accuracy: 0.9848 - val_loss: 0.5196 - val_accuracy: 0.8818\n","\n","Epoch 00228: val_accuracy did not improve from 0.92118\n","Epoch 229/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.5152 - val_accuracy: 0.8990\n","\n","Epoch 00229: val_accuracy did not improve from 0.92118\n","Epoch 230/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0112 - accuracy: 0.9945 - val_loss: 0.5224 - val_accuracy: 0.9039\n","\n","Epoch 00230: val_accuracy did not improve from 0.92118\n","Epoch 231/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4632 - val_accuracy: 0.8966\n","\n","Epoch 00231: val_accuracy did not improve from 0.92118\n","Epoch 232/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.5633 - val_accuracy: 0.9089\n","\n","Epoch 00232: val_accuracy did not improve from 0.92118\n","Epoch 233/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.9015\n","\n","Epoch 00233: val_accuracy did not improve from 0.92118\n","Epoch 234/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5331 - val_accuracy: 0.9015\n","\n","Epoch 00234: val_accuracy did not improve from 0.92118\n","Epoch 235/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.6659 - val_accuracy: 0.8818\n","\n","Epoch 00235: val_accuracy did not improve from 0.92118\n","Epoch 236/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4867 - val_accuracy: 0.9187\n","\n","Epoch 00236: val_accuracy did not improve from 0.92118\n","Epoch 237/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 0.6978 - val_accuracy: 0.8892\n","\n","Epoch 00237: val_accuracy did not improve from 0.92118\n","Epoch 238/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6558 - val_accuracy: 0.8768\n","\n","Epoch 00238: val_accuracy did not improve from 0.92118\n","Epoch 239/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5010 - val_accuracy: 0.9015\n","\n","Epoch 00239: val_accuracy did not improve from 0.92118\n","Epoch 240/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4739 - val_accuracy: 0.9064\n","\n","Epoch 00240: val_accuracy did not improve from 0.92118\n","Epoch 241/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5045 - val_accuracy: 0.9089\n","\n","Epoch 00241: val_accuracy did not improve from 0.92118\n","Epoch 242/500\n","52/52 [==============================] - 23s 449ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 1.0775 - val_accuracy: 0.8571\n","\n","Epoch 00242: val_accuracy did not improve from 0.92118\n","Epoch 243/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0851 - accuracy: 0.9775 - val_loss: 2.2400 - val_accuracy: 0.6946\n","\n","Epoch 00243: val_accuracy did not improve from 0.92118\n","Epoch 244/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1722 - accuracy: 0.9513 - val_loss: 7.1322 - val_accuracy: 0.4631\n","\n","Epoch 00244: val_accuracy did not improve from 0.92118\n","Epoch 245/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0786 - accuracy: 0.9787 - val_loss: 2.1391 - val_accuracy: 0.7291\n","\n","Epoch 00245: val_accuracy did not improve from 0.92118\n","Epoch 246/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0723 - accuracy: 0.9805 - val_loss: 1.4152 - val_accuracy: 0.7783\n","\n","Epoch 00246: val_accuracy did not improve from 0.92118\n","Epoch 247/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 1.1109 - val_accuracy: 0.8177\n","\n","Epoch 00247: val_accuracy did not improve from 0.92118\n","Epoch 248/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0341 - accuracy: 0.9921 - val_loss: 0.8779 - val_accuracy: 0.8645\n","\n","Epoch 00248: val_accuracy did not improve from 0.92118\n","Epoch 249/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 0.5237 - val_accuracy: 0.9089\n","\n","Epoch 00249: val_accuracy did not improve from 0.92118\n","Epoch 250/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.5777 - val_accuracy: 0.8990\n","\n","Epoch 00250: val_accuracy did not improve from 0.92118\n","Epoch 251/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.6047 - val_accuracy: 0.8916\n","\n","Epoch 00251: val_accuracy did not improve from 0.92118\n","Epoch 252/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.6603 - val_accuracy: 0.8867\n","\n","Epoch 00252: val_accuracy did not improve from 0.92118\n","Epoch 253/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.6632 - val_accuracy: 0.8744\n","\n","Epoch 00253: val_accuracy did not improve from 0.92118\n","Epoch 254/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5453 - val_accuracy: 0.8941\n","\n","Epoch 00254: val_accuracy did not improve from 0.92118\n","Epoch 255/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.6168 - val_accuracy: 0.8842\n","\n","Epoch 00255: val_accuracy did not improve from 0.92118\n","Epoch 256/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.4765 - val_accuracy: 0.9138\n","\n","Epoch 00256: val_accuracy did not improve from 0.92118\n","Epoch 257/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5483 - val_accuracy: 0.9089\n","\n","Epoch 00257: val_accuracy did not improve from 0.92118\n","Epoch 258/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 5.0810 - val_accuracy: 0.6232\n","\n","Epoch 00258: val_accuracy did not improve from 0.92118\n","Epoch 259/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.5706 - val_accuracy: 0.8867\n","\n","Epoch 00259: val_accuracy did not improve from 0.92118\n","Epoch 260/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4905 - val_accuracy: 0.9015\n","\n","Epoch 00260: val_accuracy did not improve from 0.92118\n","Epoch 261/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.9064\n","\n","Epoch 00261: val_accuracy did not improve from 0.92118\n","Epoch 262/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.5411 - val_accuracy: 0.8990\n","\n","Epoch 00262: val_accuracy did not improve from 0.92118\n","Epoch 263/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.9089\n","\n","Epoch 00263: val_accuracy did not improve from 0.92118\n","Epoch 264/500\n","52/52 [==============================] - 23s 446ms/step - loss: 5.1664e-04 - accuracy: 1.0000 - val_loss: 0.5234 - val_accuracy: 0.9113\n","\n","Epoch 00264: val_accuracy did not improve from 0.92118\n","Epoch 265/500\n","52/52 [==============================] - 23s 442ms/step - loss: 7.5185e-04 - accuracy: 1.0000 - val_loss: 0.5295 - val_accuracy: 0.9113\n","\n","Epoch 00265: val_accuracy did not improve from 0.92118\n","Epoch 266/500\n","52/52 [==============================] - 23s 444ms/step - loss: 5.7096e-04 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.8892\n","\n","Epoch 00266: val_accuracy did not improve from 0.92118\n","Epoch 267/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.7810 - val_accuracy: 0.8793\n","\n","Epoch 00267: val_accuracy did not improve from 0.92118\n","Epoch 268/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0095 - accuracy: 0.9951 - val_loss: 0.9337 - val_accuracy: 0.8645\n","\n","Epoch 00268: val_accuracy did not improve from 0.92118\n","Epoch 269/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.1272 - accuracy: 0.9622 - val_loss: 41.5582 - val_accuracy: 0.1133\n","\n","Epoch 00269: val_accuracy did not improve from 0.92118\n","Epoch 270/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0981 - accuracy: 0.9683 - val_loss: 1.7393 - val_accuracy: 0.7783\n","\n","Epoch 00270: val_accuracy did not improve from 0.92118\n","Epoch 271/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0949 - accuracy: 0.9732 - val_loss: 0.9536 - val_accuracy: 0.8374\n","\n","Epoch 00271: val_accuracy did not improve from 0.92118\n","Epoch 272/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0549 - accuracy: 0.9854 - val_loss: 0.7121 - val_accuracy: 0.8424\n","\n","Epoch 00272: val_accuracy did not improve from 0.92118\n","Epoch 273/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0761 - accuracy: 0.9775 - val_loss: 0.8507 - val_accuracy: 0.8498\n","\n","Epoch 00273: val_accuracy did not improve from 0.92118\n","Epoch 274/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.5410 - val_accuracy: 0.8867\n","\n","Epoch 00274: val_accuracy did not improve from 0.92118\n","Epoch 275/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.4544 - val_accuracy: 0.9064\n","\n","Epoch 00275: val_accuracy did not improve from 0.92118\n","Epoch 276/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.5727 - val_accuracy: 0.8818\n","\n","Epoch 00276: val_accuracy did not improve from 0.92118\n","Epoch 277/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.5333 - val_accuracy: 0.8990\n","\n","Epoch 00277: val_accuracy did not improve from 0.92118\n","Epoch 278/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.4747 - val_accuracy: 0.9015\n","\n","Epoch 00278: val_accuracy did not improve from 0.92118\n","Epoch 279/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.6081 - val_accuracy: 0.8916\n","\n","Epoch 00279: val_accuracy did not improve from 0.92118\n","Epoch 280/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5352 - val_accuracy: 0.9039\n","\n","Epoch 00280: val_accuracy did not improve from 0.92118\n","Epoch 281/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.7558 - val_accuracy: 0.8793\n","\n","Epoch 00281: val_accuracy did not improve from 0.92118\n","Epoch 282/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0088 - accuracy: 0.9957 - val_loss: 0.7418 - val_accuracy: 0.8867\n","\n","Epoch 00282: val_accuracy did not improve from 0.92118\n","Epoch 283/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.8458 - val_accuracy: 0.8547\n","\n","Epoch 00283: val_accuracy did not improve from 0.92118\n","Epoch 284/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.6708 - val_accuracy: 0.8916\n","\n","Epoch 00284: val_accuracy did not improve from 0.92118\n","Epoch 285/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0164 - accuracy: 0.9921 - val_loss: 1.0325 - val_accuracy: 0.8227\n","\n","Epoch 00285: val_accuracy did not improve from 0.92118\n","Epoch 286/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0466 - accuracy: 0.9866 - val_loss: 0.8106 - val_accuracy: 0.8768\n","\n","Epoch 00286: val_accuracy did not improve from 0.92118\n","Epoch 287/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0724 - accuracy: 0.9799 - val_loss: 0.7824 - val_accuracy: 0.8695\n","\n","Epoch 00287: val_accuracy did not improve from 0.92118\n","Epoch 288/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0343 - accuracy: 0.9915 - val_loss: 0.6082 - val_accuracy: 0.8990\n","\n","Epoch 00288: val_accuracy did not improve from 0.92118\n","Epoch 289/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0193 - accuracy: 0.9927 - val_loss: 0.7952 - val_accuracy: 0.8818\n","\n","Epoch 00289: val_accuracy did not improve from 0.92118\n","Epoch 290/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.6077 - val_accuracy: 0.8990\n","\n","Epoch 00290: val_accuracy did not improve from 0.92118\n","Epoch 291/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0182 - accuracy: 0.9921 - val_loss: 1.0975 - val_accuracy: 0.8596\n","\n","Epoch 00291: val_accuracy did not improve from 0.92118\n","Epoch 292/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 1.0379 - val_accuracy: 0.8522\n","\n","Epoch 00292: val_accuracy did not improve from 0.92118\n","Epoch 293/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0390 - accuracy: 0.9915 - val_loss: 0.8869 - val_accuracy: 0.8645\n","\n","Epoch 00293: val_accuracy did not improve from 0.92118\n","Epoch 294/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0392 - accuracy: 0.9909 - val_loss: 5.2984 - val_accuracy: 0.5887\n","\n","Epoch 00294: val_accuracy did not improve from 0.92118\n","Epoch 295/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 0.7940 - val_accuracy: 0.8793\n","\n","Epoch 00295: val_accuracy did not improve from 0.92118\n","Epoch 296/500\n","52/52 [==============================] - 23s 448ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.6031 - val_accuracy: 0.8842\n","\n","Epoch 00296: val_accuracy did not improve from 0.92118\n","Epoch 297/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.6696 - val_accuracy: 0.9039\n","\n","Epoch 00297: val_accuracy did not improve from 0.92118\n","Epoch 298/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.5102 - val_accuracy: 0.9064\n","\n","Epoch 00298: val_accuracy did not improve from 0.92118\n","Epoch 299/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.6422 - val_accuracy: 0.8916\n","\n","Epoch 00299: val_accuracy did not improve from 0.92118\n","Epoch 300/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6384 - val_accuracy: 0.8941\n","\n","Epoch 00300: val_accuracy did not improve from 0.92118\n","Epoch 301/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0158 - accuracy: 0.9939 - val_loss: 0.8598 - val_accuracy: 0.8818\n","\n","Epoch 00301: val_accuracy did not improve from 0.92118\n","Epoch 302/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0348 - accuracy: 0.9903 - val_loss: 17.8287 - val_accuracy: 0.2931\n","\n","Epoch 00302: val_accuracy did not improve from 0.92118\n","Epoch 303/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0293 - accuracy: 0.9915 - val_loss: 0.8119 - val_accuracy: 0.8793\n","\n","Epoch 00303: val_accuracy did not improve from 0.92118\n","Epoch 304/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0474 - accuracy: 0.9854 - val_loss: 0.8456 - val_accuracy: 0.8768\n","\n","Epoch 00304: val_accuracy did not improve from 0.92118\n","Epoch 305/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0347 - accuracy: 0.9939 - val_loss: 0.6587 - val_accuracy: 0.8818\n","\n","Epoch 00305: val_accuracy did not improve from 0.92118\n","Epoch 306/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0195 - accuracy: 0.9921 - val_loss: 0.6494 - val_accuracy: 0.8892\n","\n","Epoch 00306: val_accuracy did not improve from 0.92118\n","Epoch 307/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 0.6280 - val_accuracy: 0.8867\n","\n","Epoch 00307: val_accuracy did not improve from 0.92118\n","Epoch 308/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.7285 - val_accuracy: 0.8842\n","\n","Epoch 00308: val_accuracy did not improve from 0.92118\n","Epoch 309/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0195 - accuracy: 0.9963 - val_loss: 0.6101 - val_accuracy: 0.9064\n","\n","Epoch 00309: val_accuracy did not improve from 0.92118\n","Epoch 310/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.6110 - val_accuracy: 0.8916\n","\n","Epoch 00310: val_accuracy did not improve from 0.92118\n","Epoch 311/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0194 - accuracy: 0.9963 - val_loss: 0.5958 - val_accuracy: 0.9039\n","\n","Epoch 00311: val_accuracy did not improve from 0.92118\n","Epoch 312/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0113 - accuracy: 0.9951 - val_loss: 0.6894 - val_accuracy: 0.8818\n","\n","Epoch 00312: val_accuracy did not improve from 0.92118\n","Epoch 313/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 0.9381 - val_accuracy: 0.8621\n","\n","Epoch 00313: val_accuracy did not improve from 0.92118\n","Epoch 314/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0314 - accuracy: 0.9872 - val_loss: 1.2599 - val_accuracy: 0.8325\n","\n","Epoch 00314: val_accuracy did not improve from 0.92118\n","Epoch 315/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0617 - accuracy: 0.9829 - val_loss: 0.8357 - val_accuracy: 0.8522\n","\n","Epoch 00315: val_accuracy did not improve from 0.92118\n","Epoch 316/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0452 - accuracy: 0.9866 - val_loss: 1.1807 - val_accuracy: 0.8374\n","\n","Epoch 00316: val_accuracy did not improve from 0.92118\n","Epoch 317/500\n","52/52 [==============================] - 23s 447ms/step - loss: 0.0758 - accuracy: 0.9829 - val_loss: 1.0223 - val_accuracy: 0.8399\n","\n","Epoch 00317: val_accuracy did not improve from 0.92118\n","Epoch 318/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.5289 - val_accuracy: 0.8941\n","\n","Epoch 00318: val_accuracy did not improve from 0.92118\n","Epoch 319/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.9080 - val_accuracy: 0.8448\n","\n","Epoch 00319: val_accuracy did not improve from 0.92118\n","Epoch 320/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 1.0335 - val_accuracy: 0.8300\n","\n","Epoch 00320: val_accuracy did not improve from 0.92118\n","Epoch 321/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0334 - accuracy: 0.9921 - val_loss: 0.5430 - val_accuracy: 0.8892\n","\n","Epoch 00321: val_accuracy did not improve from 0.92118\n","Epoch 322/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.7465 - val_accuracy: 0.8645\n","\n","Epoch 00322: val_accuracy did not improve from 0.92118\n","Epoch 323/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.5082 - val_accuracy: 0.9113\n","\n","Epoch 00323: val_accuracy did not improve from 0.92118\n","Epoch 324/500\n","52/52 [==============================] - 23s 442ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4409 - val_accuracy: 0.9113\n","\n","Epoch 00324: val_accuracy did not improve from 0.92118\n","Epoch 325/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4723 - val_accuracy: 0.9187\n","\n","Epoch 00325: val_accuracy did not improve from 0.92118\n","Epoch 326/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.9113\n","\n","Epoch 00326: val_accuracy did not improve from 0.92118\n","Epoch 327/500\n","52/52 [==============================] - 23s 443ms/step - loss: 4.6116e-04 - accuracy: 1.0000 - val_loss: 0.4164 - val_accuracy: 0.9163\n","\n","Epoch 00327: val_accuracy did not improve from 0.92118\n","Epoch 328/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4465 - val_accuracy: 0.9138\n","\n","Epoch 00328: val_accuracy did not improve from 0.92118\n","Epoch 329/500\n","52/52 [==============================] - 23s 443ms/step - loss: 6.8920e-04 - accuracy: 1.0000 - val_loss: 0.4467 - val_accuracy: 0.9187\n","\n","Epoch 00329: val_accuracy did not improve from 0.92118\n","Epoch 330/500\n","52/52 [==============================] - 23s 445ms/step - loss: 2.6064e-04 - accuracy: 1.0000 - val_loss: 0.4586 - val_accuracy: 0.9286\n","\n","Epoch 00330: val_accuracy improved from 0.92118 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5\n","Epoch 331/500\n","52/52 [==============================] - 23s 446ms/step - loss: 2.9821e-04 - accuracy: 1.0000 - val_loss: 0.4794 - val_accuracy: 0.9113\n","\n","Epoch 00331: val_accuracy did not improve from 0.92857\n","Epoch 332/500\n","52/52 [==============================] - 23s 445ms/step - loss: 4.5867e-04 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9015\n","\n","Epoch 00332: val_accuracy did not improve from 0.92857\n","Epoch 333/500\n","52/52 [==============================] - 23s 444ms/step - loss: 3.2518e-04 - accuracy: 1.0000 - val_loss: 0.4572 - val_accuracy: 0.9138\n","\n","Epoch 00333: val_accuracy did not improve from 0.92857\n","Epoch 334/500\n","52/52 [==============================] - 23s 448ms/step - loss: 2.9657e-04 - accuracy: 1.0000 - val_loss: 0.4514 - val_accuracy: 0.9064\n","\n","Epoch 00334: val_accuracy did not improve from 0.92857\n","Epoch 335/500\n","52/52 [==============================] - 23s 445ms/step - loss: 4.7679e-04 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.9187\n","\n","Epoch 00335: val_accuracy did not improve from 0.92857\n","Epoch 336/500\n","52/52 [==============================] - 23s 445ms/step - loss: 2.7849e-04 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.9089\n","\n","Epoch 00336: val_accuracy did not improve from 0.92857\n","Epoch 337/500\n","52/52 [==============================] - 23s 445ms/step - loss: 2.7177e-04 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.9163\n","\n","Epoch 00337: val_accuracy did not improve from 0.92857\n","Epoch 338/500\n","52/52 [==============================] - 23s 446ms/step - loss: 6.1702e-04 - accuracy: 1.0000 - val_loss: 0.5224 - val_accuracy: 0.9039\n","\n","Epoch 00338: val_accuracy did not improve from 0.92857\n","Epoch 339/500\n","52/52 [==============================] - 23s 445ms/step - loss: 7.0236e-04 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.9113\n","\n","Epoch 00339: val_accuracy did not improve from 0.92857\n","Epoch 340/500\n","52/52 [==============================] - 23s 444ms/step - loss: 8.8268e-04 - accuracy: 0.9994 - val_loss: 0.4764 - val_accuracy: 0.9187\n","\n","Epoch 00340: val_accuracy did not improve from 0.92857\n","Epoch 341/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0469 - accuracy: 0.9872 - val_loss: 29.0089 - val_accuracy: 0.1133\n","\n","Epoch 00341: val_accuracy did not improve from 0.92857\n","Epoch 342/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.1494 - accuracy: 0.9555 - val_loss: 1.6522 - val_accuracy: 0.7759\n","\n","Epoch 00342: val_accuracy did not improve from 0.92857\n","Epoch 343/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0742 - accuracy: 0.9781 - val_loss: 0.8007 - val_accuracy: 0.8744\n","\n","Epoch 00343: val_accuracy did not improve from 0.92857\n","Epoch 344/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 1.1379 - val_accuracy: 0.8325\n","\n","Epoch 00344: val_accuracy did not improve from 0.92857\n","Epoch 345/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0202 - accuracy: 0.9903 - val_loss: 0.6016 - val_accuracy: 0.9064\n","\n","Epoch 00345: val_accuracy did not improve from 0.92857\n","Epoch 346/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.9222 - val_accuracy: 0.8399\n","\n","Epoch 00346: val_accuracy did not improve from 0.92857\n","Epoch 347/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0137 - accuracy: 0.9939 - val_loss: 0.4627 - val_accuracy: 0.8941\n","\n","Epoch 00347: val_accuracy did not improve from 0.92857\n","Epoch 348/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.5369 - val_accuracy: 0.8892\n","\n","Epoch 00348: val_accuracy did not improve from 0.92857\n","Epoch 349/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5267 - val_accuracy: 0.9089\n","\n","Epoch 00349: val_accuracy did not improve from 0.92857\n","Epoch 350/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.6117 - val_accuracy: 0.8941\n","\n","Epoch 00350: val_accuracy did not improve from 0.92857\n","Epoch 351/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.6064 - val_accuracy: 0.9064\n","\n","Epoch 00351: val_accuracy did not improve from 0.92857\n","Epoch 352/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0403 - accuracy: 0.9884 - val_loss: 1.1604 - val_accuracy: 0.8350\n","\n","Epoch 00352: val_accuracy did not improve from 0.92857\n","Epoch 353/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0416 - accuracy: 0.9890 - val_loss: 1.0343 - val_accuracy: 0.8399\n","\n","Epoch 00353: val_accuracy did not improve from 0.92857\n","Epoch 354/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0254 - accuracy: 0.9896 - val_loss: 2.3987 - val_accuracy: 0.6946\n","\n","Epoch 00354: val_accuracy did not improve from 0.92857\n","Epoch 355/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0468 - accuracy: 0.9909 - val_loss: 1.0830 - val_accuracy: 0.8473\n","\n","Epoch 00355: val_accuracy did not improve from 0.92857\n","Epoch 356/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0374 - accuracy: 0.9872 - val_loss: 0.8348 - val_accuracy: 0.8498\n","\n","Epoch 00356: val_accuracy did not improve from 0.92857\n","Epoch 357/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.6090 - val_accuracy: 0.8842\n","\n","Epoch 00357: val_accuracy did not improve from 0.92857\n","Epoch 358/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0152 - accuracy: 0.9970 - val_loss: 0.7854 - val_accuracy: 0.8621\n","\n","Epoch 00358: val_accuracy did not improve from 0.92857\n","Epoch 359/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0233 - accuracy: 0.9896 - val_loss: 1.2615 - val_accuracy: 0.8079\n","\n","Epoch 00359: val_accuracy did not improve from 0.92857\n","Epoch 360/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.6588 - val_accuracy: 0.8867\n","\n","Epoch 00360: val_accuracy did not improve from 0.92857\n","Epoch 361/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.5194 - val_accuracy: 0.9064\n","\n","Epoch 00361: val_accuracy did not improve from 0.92857\n","Epoch 362/500\n","52/52 [==============================] - 23s 452ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.7441 - val_accuracy: 0.8990\n","\n","Epoch 00362: val_accuracy did not improve from 0.92857\n","Epoch 363/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0308 - accuracy: 0.9872 - val_loss: 0.9859 - val_accuracy: 0.8399\n","\n","Epoch 00363: val_accuracy did not improve from 0.92857\n","Epoch 364/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0578 - accuracy: 0.9848 - val_loss: 0.8243 - val_accuracy: 0.8596\n","\n","Epoch 00364: val_accuracy did not improve from 0.92857\n","Epoch 365/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.5590 - val_accuracy: 0.9015\n","\n","Epoch 00365: val_accuracy did not improve from 0.92857\n","Epoch 366/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5543 - val_accuracy: 0.9089\n","\n","Epoch 00366: val_accuracy did not improve from 0.92857\n","Epoch 367/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.6080 - val_accuracy: 0.9113\n","\n","Epoch 00367: val_accuracy did not improve from 0.92857\n","Epoch 368/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0218 - accuracy: 0.9945 - val_loss: 0.6049 - val_accuracy: 0.8916\n","\n","Epoch 00368: val_accuracy did not improve from 0.92857\n","Epoch 369/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.4189 - val_accuracy: 0.9236\n","\n","Epoch 00369: val_accuracy did not improve from 0.92857\n","Epoch 370/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.8169 - val_accuracy: 0.8621\n","\n","Epoch 00370: val_accuracy did not improve from 0.92857\n","Epoch 371/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0360 - accuracy: 0.9872 - val_loss: 0.9435 - val_accuracy: 0.8670\n","\n","Epoch 00371: val_accuracy did not improve from 0.92857\n","Epoch 372/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.7196 - val_accuracy: 0.8695\n","\n","Epoch 00372: val_accuracy did not improve from 0.92857\n","Epoch 373/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.5962 - val_accuracy: 0.8990\n","\n","Epoch 00373: val_accuracy did not improve from 0.92857\n","Epoch 374/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.5548 - val_accuracy: 0.8867\n","\n","Epoch 00374: val_accuracy did not improve from 0.92857\n","Epoch 375/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.7379 - val_accuracy: 0.8892\n","\n","Epoch 00375: val_accuracy did not improve from 0.92857\n","Epoch 376/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.6881 - val_accuracy: 0.8990\n","\n","Epoch 00376: val_accuracy did not improve from 0.92857\n","Epoch 377/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5394 - val_accuracy: 0.9015\n","\n","Epoch 00377: val_accuracy did not improve from 0.92857\n","Epoch 378/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5426 - val_accuracy: 0.8966\n","\n","Epoch 00378: val_accuracy did not improve from 0.92857\n","Epoch 379/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0078 - accuracy: 0.9963 - val_loss: 0.5710 - val_accuracy: 0.9015\n","\n","Epoch 00379: val_accuracy did not improve from 0.92857\n","Epoch 380/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.5615 - val_accuracy: 0.9064\n","\n","Epoch 00380: val_accuracy did not improve from 0.92857\n","Epoch 381/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.5555 - val_accuracy: 0.8966\n","\n","Epoch 00381: val_accuracy did not improve from 0.92857\n","Epoch 382/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.5834 - val_accuracy: 0.8892\n","\n","Epoch 00382: val_accuracy did not improve from 0.92857\n","Epoch 383/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5827 - val_accuracy: 0.9015\n","\n","Epoch 00383: val_accuracy did not improve from 0.92857\n","Epoch 384/500\n","52/52 [==============================] - 23s 448ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4984 - val_accuracy: 0.9064\n","\n","Epoch 00384: val_accuracy did not improve from 0.92857\n","Epoch 385/500\n","52/52 [==============================] - 23s 445ms/step - loss: 9.4319e-04 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.9039\n","\n","Epoch 00385: val_accuracy did not improve from 0.92857\n","Epoch 386/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.6991 - val_accuracy: 0.8867\n","\n","Epoch 00386: val_accuracy did not improve from 0.92857\n","Epoch 387/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0312 - accuracy: 0.9921 - val_loss: 0.6966 - val_accuracy: 0.8719\n","\n","Epoch 00387: val_accuracy did not improve from 0.92857\n","Epoch 388/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.7054 - val_accuracy: 0.8867\n","\n","Epoch 00388: val_accuracy did not improve from 0.92857\n","Epoch 389/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.5814 - val_accuracy: 0.8966\n","\n","Epoch 00389: val_accuracy did not improve from 0.92857\n","Epoch 390/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.7162 - val_accuracy: 0.8916\n","\n","Epoch 00390: val_accuracy did not improve from 0.92857\n","Epoch 391/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.8978 - val_accuracy: 0.8744\n","\n","Epoch 00391: val_accuracy did not improve from 0.92857\n","Epoch 392/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.6605 - val_accuracy: 0.8793\n","\n","Epoch 00392: val_accuracy did not improve from 0.92857\n","Epoch 393/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.6343 - val_accuracy: 0.8941\n","\n","Epoch 00393: val_accuracy did not improve from 0.92857\n","Epoch 394/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.7798 - val_accuracy: 0.8966\n","\n","Epoch 00394: val_accuracy did not improve from 0.92857\n","Epoch 395/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.5843 - val_accuracy: 0.9089\n","\n","Epoch 00395: val_accuracy did not improve from 0.92857\n","Epoch 396/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.5432 - val_accuracy: 0.9138\n","\n","Epoch 00396: val_accuracy did not improve from 0.92857\n","Epoch 397/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.9553 - val_accuracy: 0.8842\n","\n","Epoch 00397: val_accuracy did not improve from 0.92857\n","Epoch 398/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.9275 - val_accuracy: 0.8448\n","\n","Epoch 00398: val_accuracy did not improve from 0.92857\n","Epoch 399/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.7212 - val_accuracy: 0.8744\n","\n","Epoch 00399: val_accuracy did not improve from 0.92857\n","Epoch 400/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0445 - accuracy: 0.9866 - val_loss: 1.0679 - val_accuracy: 0.8645\n","\n","Epoch 00400: val_accuracy did not improve from 0.92857\n","Epoch 401/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0398 - accuracy: 0.9909 - val_loss: 0.8262 - val_accuracy: 0.8695\n","\n","Epoch 00401: val_accuracy did not improve from 0.92857\n","Epoch 402/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0237 - accuracy: 0.9896 - val_loss: 0.7991 - val_accuracy: 0.8867\n","\n","Epoch 00402: val_accuracy did not improve from 0.92857\n","Epoch 403/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0394 - accuracy: 0.9884 - val_loss: 1.3097 - val_accuracy: 0.8227\n","\n","Epoch 00403: val_accuracy did not improve from 0.92857\n","Epoch 404/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.7169 - val_accuracy: 0.8768\n","\n","Epoch 00404: val_accuracy did not improve from 0.92857\n","Epoch 405/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.6967 - val_accuracy: 0.8867\n","\n","Epoch 00405: val_accuracy did not improve from 0.92857\n","Epoch 406/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.6364 - val_accuracy: 0.8867\n","\n","Epoch 00406: val_accuracy did not improve from 0.92857\n","Epoch 407/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.8793\n","\n","Epoch 00407: val_accuracy did not improve from 0.92857\n","Epoch 408/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.6453 - val_accuracy: 0.9015\n","\n","Epoch 00408: val_accuracy did not improve from 0.92857\n","Epoch 409/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5419 - val_accuracy: 0.8966\n","\n","Epoch 00409: val_accuracy did not improve from 0.92857\n","Epoch 410/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5301 - val_accuracy: 0.9039\n","\n","Epoch 00410: val_accuracy did not improve from 0.92857\n","Epoch 411/500\n","52/52 [==============================] - 23s 443ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7227 - val_accuracy: 0.8842\n","\n","Epoch 00411: val_accuracy did not improve from 0.92857\n","Epoch 412/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.6642 - val_accuracy: 0.8941\n","\n","Epoch 00412: val_accuracy did not improve from 0.92857\n","Epoch 413/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.6063 - val_accuracy: 0.9064\n","\n","Epoch 00413: val_accuracy did not improve from 0.92857\n","Epoch 414/500\n","52/52 [==============================] - 23s 446ms/step - loss: 8.8314e-04 - accuracy: 1.0000 - val_loss: 0.6602 - val_accuracy: 0.8990\n","\n","Epoch 00414: val_accuracy did not improve from 0.92857\n","Epoch 415/500\n","52/52 [==============================] - 23s 447ms/step - loss: 7.5349e-04 - accuracy: 0.9994 - val_loss: 0.6187 - val_accuracy: 0.8941\n","\n","Epoch 00415: val_accuracy did not improve from 0.92857\n","Epoch 416/500\n","52/52 [==============================] - 23s 446ms/step - loss: 7.6655e-04 - accuracy: 1.0000 - val_loss: 0.5504 - val_accuracy: 0.9089\n","\n","Epoch 00416: val_accuracy did not improve from 0.92857\n","Epoch 417/500\n","52/52 [==============================] - 23s 443ms/step - loss: 3.8539e-04 - accuracy: 1.0000 - val_loss: 0.5840 - val_accuracy: 0.9089\n","\n","Epoch 00417: val_accuracy did not improve from 0.92857\n","Epoch 418/500\n","52/52 [==============================] - 23s 446ms/step - loss: 9.6176e-04 - accuracy: 1.0000 - val_loss: 0.6961 - val_accuracy: 0.8916\n","\n","Epoch 00418: val_accuracy did not improve from 0.92857\n","Epoch 419/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.6887 - val_accuracy: 0.8867\n","\n","Epoch 00419: val_accuracy did not improve from 0.92857\n","Epoch 420/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0797 - accuracy: 0.9769 - val_loss: 1.3201 - val_accuracy: 0.8153\n","\n","Epoch 00420: val_accuracy did not improve from 0.92857\n","Epoch 421/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0524 - accuracy: 0.9829 - val_loss: 3.9923 - val_accuracy: 0.6502\n","\n","Epoch 00421: val_accuracy did not improve from 0.92857\n","Epoch 422/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.5819 - val_accuracy: 0.9039\n","\n","Epoch 00422: val_accuracy did not improve from 0.92857\n","Epoch 423/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.7994 - val_accuracy: 0.8719\n","\n","Epoch 00423: val_accuracy did not improve from 0.92857\n","Epoch 424/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.5336 - val_accuracy: 0.8966\n","\n","Epoch 00424: val_accuracy did not improve from 0.92857\n","Epoch 425/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.5703 - val_accuracy: 0.9138\n","\n","Epoch 00425: val_accuracy did not improve from 0.92857\n","Epoch 426/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5805 - val_accuracy: 0.8990\n","\n","Epoch 00426: val_accuracy did not improve from 0.92857\n","Epoch 427/500\n","52/52 [==============================] - 23s 447ms/step - loss: 4.2379e-04 - accuracy: 1.0000 - val_loss: 0.6377 - val_accuracy: 0.8941\n","\n","Epoch 00427: val_accuracy did not improve from 0.92857\n","Epoch 428/500\n","52/52 [==============================] - 23s 445ms/step - loss: 6.5677e-04 - accuracy: 1.0000 - val_loss: 0.6030 - val_accuracy: 0.8941\n","\n","Epoch 00428: val_accuracy did not improve from 0.92857\n","Epoch 429/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.9161 - val_accuracy: 0.8744\n","\n","Epoch 00429: val_accuracy did not improve from 0.92857\n","Epoch 430/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.9069 - val_accuracy: 0.8621\n","\n","Epoch 00430: val_accuracy did not improve from 0.92857\n","Epoch 431/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.7746 - val_accuracy: 0.8867\n","\n","Epoch 00431: val_accuracy did not improve from 0.92857\n","Epoch 432/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 0.7297 - val_accuracy: 0.8842\n","\n","Epoch 00432: val_accuracy did not improve from 0.92857\n","Epoch 433/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.6705 - val_accuracy: 0.8818\n","\n","Epoch 00433: val_accuracy did not improve from 0.92857\n","Epoch 434/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0207 - accuracy: 0.9957 - val_loss: 0.7511 - val_accuracy: 0.8867\n","\n","Epoch 00434: val_accuracy did not improve from 0.92857\n","Epoch 435/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.5911 - val_accuracy: 0.8842\n","\n","Epoch 00435: val_accuracy did not improve from 0.92857\n","Epoch 436/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.5411 - val_accuracy: 0.9015\n","\n","Epoch 00436: val_accuracy did not improve from 0.92857\n","Epoch 437/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.6030 - val_accuracy: 0.8966\n","\n","Epoch 00437: val_accuracy did not improve from 0.92857\n","Epoch 438/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.5506 - val_accuracy: 0.9187\n","\n","Epoch 00438: val_accuracy did not improve from 0.92857\n","Epoch 439/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.6599 - val_accuracy: 0.8793\n","\n","Epoch 00439: val_accuracy did not improve from 0.92857\n","Epoch 440/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.8243 - val_accuracy: 0.8695\n","\n","Epoch 00440: val_accuracy did not improve from 0.92857\n","Epoch 441/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5253 - val_accuracy: 0.9138\n","\n","Epoch 00441: val_accuracy did not improve from 0.92857\n","Epoch 442/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.7288 - val_accuracy: 0.8916\n","\n","Epoch 00442: val_accuracy did not improve from 0.92857\n","Epoch 443/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.6549 - val_accuracy: 0.8966\n","\n","Epoch 00443: val_accuracy did not improve from 0.92857\n","Epoch 444/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.7202 - val_accuracy: 0.8892\n","\n","Epoch 00444: val_accuracy did not improve from 0.92857\n","Epoch 445/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.8966\n","\n","Epoch 00445: val_accuracy did not improve from 0.92857\n","Epoch 446/500\n","52/52 [==============================] - 23s 445ms/step - loss: 4.7816e-04 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.9187\n","\n","Epoch 00446: val_accuracy did not improve from 0.92857\n","Epoch 447/500\n","52/52 [==============================] - 23s 446ms/step - loss: 6.5164e-04 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.9261\n","\n","Epoch 00447: val_accuracy did not improve from 0.92857\n","Epoch 448/500\n","52/52 [==============================] - 23s 447ms/step - loss: 5.7978e-04 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.9187\n","\n","Epoch 00448: val_accuracy did not improve from 0.92857\n","Epoch 449/500\n","52/52 [==============================] - 23s 444ms/step - loss: 7.6280e-04 - accuracy: 1.0000 - val_loss: 0.5856 - val_accuracy: 0.8892\n","\n","Epoch 00449: val_accuracy did not improve from 0.92857\n","Epoch 450/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4813 - val_accuracy: 0.8941\n","\n","Epoch 00450: val_accuracy did not improve from 0.92857\n","Epoch 451/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.5900 - val_accuracy: 0.8966\n","\n","Epoch 00451: val_accuracy did not improve from 0.92857\n","Epoch 452/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.8867\n","\n","Epoch 00452: val_accuracy did not improve from 0.92857\n","Epoch 453/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4875 - val_accuracy: 0.9089\n","\n","Epoch 00453: val_accuracy did not improve from 0.92857\n","Epoch 454/500\n","52/52 [==============================] - 23s 450ms/step - loss: 4.4114e-04 - accuracy: 1.0000 - val_loss: 0.5732 - val_accuracy: 0.8892\n","\n","Epoch 00454: val_accuracy did not improve from 0.92857\n","Epoch 455/500\n","52/52 [==============================] - 23s 445ms/step - loss: 1.4962e-04 - accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.9015\n","\n","Epoch 00455: val_accuracy did not improve from 0.92857\n","Epoch 456/500\n","52/52 [==============================] - 23s 446ms/step - loss: 1.3846e-04 - accuracy: 1.0000 - val_loss: 0.5221 - val_accuracy: 0.9039\n","\n","Epoch 00456: val_accuracy did not improve from 0.92857\n","Epoch 457/500\n","52/52 [==============================] - 23s 445ms/step - loss: 2.4335e-04 - accuracy: 1.0000 - val_loss: 0.4771 - val_accuracy: 0.9015\n","\n","Epoch 00457: val_accuracy did not improve from 0.92857\n","Epoch 458/500\n","52/52 [==============================] - 23s 445ms/step - loss: 1.1958e-04 - accuracy: 1.0000 - val_loss: 0.5342 - val_accuracy: 0.9015\n","\n","Epoch 00458: val_accuracy did not improve from 0.92857\n","Epoch 459/500\n","52/52 [==============================] - 23s 445ms/step - loss: 1.1936e-04 - accuracy: 1.0000 - val_loss: 0.4609 - val_accuracy: 0.9039\n","\n","Epoch 00459: val_accuracy did not improve from 0.92857\n","Epoch 460/500\n","52/52 [==============================] - 23s 445ms/step - loss: 1.0668e-04 - accuracy: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.9187\n","\n","Epoch 00460: val_accuracy did not improve from 0.92857\n","Epoch 461/500\n","52/52 [==============================] - 23s 445ms/step - loss: 5.7412e-05 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.9064\n","\n","Epoch 00461: val_accuracy did not improve from 0.92857\n","Epoch 462/500\n","52/52 [==============================] - 23s 444ms/step - loss: 1.1129e-04 - accuracy: 1.0000 - val_loss: 0.5654 - val_accuracy: 0.9089\n","\n","Epoch 00462: val_accuracy did not improve from 0.92857\n","Epoch 463/500\n","52/52 [==============================] - 23s 446ms/step - loss: 5.3855e-05 - accuracy: 1.0000 - val_loss: 0.4787 - val_accuracy: 0.9064\n","\n","Epoch 00463: val_accuracy did not improve from 0.92857\n","Epoch 464/500\n","52/52 [==============================] - 23s 444ms/step - loss: 4.8349e-05 - accuracy: 1.0000 - val_loss: 0.6091 - val_accuracy: 0.8966\n","\n","Epoch 00464: val_accuracy did not improve from 0.92857\n","Epoch 465/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 1.5593 - val_accuracy: 0.8054\n","\n","Epoch 00465: val_accuracy did not improve from 0.92857\n","Epoch 466/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.1053 - accuracy: 0.9769 - val_loss: 1.9673 - val_accuracy: 0.7882\n","\n","Epoch 00466: val_accuracy did not improve from 0.92857\n","Epoch 467/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.1018 - accuracy: 0.9689 - val_loss: 20.6967 - val_accuracy: 0.2389\n","\n","Epoch 00467: val_accuracy did not improve from 0.92857\n","Epoch 468/500\n","52/52 [==============================] - 23s 449ms/step - loss: 0.1281 - accuracy: 0.9641 - val_loss: 2.6210 - val_accuracy: 0.6847\n","\n","Epoch 00468: val_accuracy did not improve from 0.92857\n","Epoch 469/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0278 - accuracy: 0.9903 - val_loss: 0.5685 - val_accuracy: 0.8768\n","\n","Epoch 00469: val_accuracy did not improve from 0.92857\n","Epoch 470/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.6189 - val_accuracy: 0.8842\n","\n","Epoch 00470: val_accuracy did not improve from 0.92857\n","Epoch 471/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.6015 - val_accuracy: 0.8670\n","\n","Epoch 00471: val_accuracy did not improve from 0.92857\n","Epoch 472/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4734 - val_accuracy: 0.8892\n","\n","Epoch 00472: val_accuracy did not improve from 0.92857\n","Epoch 473/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.5453 - val_accuracy: 0.9089\n","\n","Epoch 00473: val_accuracy did not improve from 0.92857\n","Epoch 474/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5748 - val_accuracy: 0.8818\n","\n","Epoch 00474: val_accuracy did not improve from 0.92857\n","Epoch 475/500\n","52/52 [==============================] - 23s 446ms/step - loss: 8.8126e-04 - accuracy: 1.0000 - val_loss: 0.5366 - val_accuracy: 0.8966\n","\n","Epoch 00475: val_accuracy did not improve from 0.92857\n","Epoch 476/500\n","52/52 [==============================] - 23s 444ms/step - loss: 9.8892e-04 - accuracy: 1.0000 - val_loss: 0.4955 - val_accuracy: 0.9113\n","\n","Epoch 00476: val_accuracy did not improve from 0.92857\n","Epoch 477/500\n","52/52 [==============================] - 23s 445ms/step - loss: 6.2472e-04 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 0.9089\n","\n","Epoch 00477: val_accuracy did not improve from 0.92857\n","Epoch 478/500\n","52/52 [==============================] - 23s 446ms/step - loss: 5.7736e-04 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.8867\n","\n","Epoch 00478: val_accuracy did not improve from 0.92857\n","Epoch 479/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.5580 - val_accuracy: 0.8892\n","\n","Epoch 00479: val_accuracy did not improve from 0.92857\n","Epoch 480/500\n","52/52 [==============================] - 23s 445ms/step - loss: 7.2531e-04 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.9015\n","\n","Epoch 00480: val_accuracy did not improve from 0.92857\n","Epoch 481/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5843 - val_accuracy: 0.8966\n","\n","Epoch 00481: val_accuracy did not improve from 0.92857\n","Epoch 482/500\n","52/52 [==============================] - 23s 445ms/step - loss: 2.4607e-04 - accuracy: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.8941\n","\n","Epoch 00482: val_accuracy did not improve from 0.92857\n","Epoch 483/500\n","52/52 [==============================] - 23s 446ms/step - loss: 9.2662e-04 - accuracy: 1.0000 - val_loss: 0.5406 - val_accuracy: 0.8916\n","\n","Epoch 00483: val_accuracy did not improve from 0.92857\n","Epoch 484/500\n","52/52 [==============================] - 23s 445ms/step - loss: 4.5063e-04 - accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 0.8842\n","\n","Epoch 00484: val_accuracy did not improve from 0.92857\n","Epoch 485/500\n","52/52 [==============================] - 23s 449ms/step - loss: 2.4370e-04 - accuracy: 1.0000 - val_loss: 0.5976 - val_accuracy: 0.8990\n","\n","Epoch 00485: val_accuracy did not improve from 0.92857\n","Epoch 486/500\n","52/52 [==============================] - 23s 446ms/step - loss: 3.1129e-04 - accuracy: 1.0000 - val_loss: 0.6380 - val_accuracy: 0.8990\n","\n","Epoch 00486: val_accuracy did not improve from 0.92857\n","Epoch 487/500\n","52/52 [==============================] - 23s 444ms/step - loss: 2.5177e-04 - accuracy: 1.0000 - val_loss: 0.6304 - val_accuracy: 0.8818\n","\n","Epoch 00487: val_accuracy did not improve from 0.92857\n","Epoch 488/500\n","52/52 [==============================] - 23s 446ms/step - loss: 3.3787e-04 - accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.8966\n","\n","Epoch 00488: val_accuracy did not improve from 0.92857\n","Epoch 489/500\n","52/52 [==============================] - 23s 447ms/step - loss: 6.5476e-04 - accuracy: 1.0000 - val_loss: 0.5948 - val_accuracy: 0.8966\n","\n","Epoch 00489: val_accuracy did not improve from 0.92857\n","Epoch 490/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5664 - val_accuracy: 0.8990\n","\n","Epoch 00490: val_accuracy did not improve from 0.92857\n","Epoch 491/500\n","52/52 [==============================] - 23s 446ms/step - loss: 5.5410e-04 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.8916\n","\n","Epoch 00491: val_accuracy did not improve from 0.92857\n","Epoch 492/500\n","52/52 [==============================] - 23s 445ms/step - loss: 3.5069e-04 - accuracy: 1.0000 - val_loss: 0.5559 - val_accuracy: 0.8990\n","\n","Epoch 00492: val_accuracy did not improve from 0.92857\n","Epoch 493/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.6305 - val_accuracy: 0.8793\n","\n","Epoch 00493: val_accuracy did not improve from 0.92857\n","Epoch 494/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.9284 - val_accuracy: 0.8645\n","\n","Epoch 00494: val_accuracy did not improve from 0.92857\n","Epoch 495/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0661 - accuracy: 0.9836 - val_loss: 1.0625 - val_accuracy: 0.8424\n","\n","Epoch 00495: val_accuracy did not improve from 0.92857\n","Epoch 496/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0499 - accuracy: 0.9817 - val_loss: 0.8780 - val_accuracy: 0.8695\n","\n","Epoch 00496: val_accuracy did not improve from 0.92857\n","Epoch 497/500\n","52/52 [==============================] - 23s 445ms/step - loss: 0.0313 - accuracy: 0.9878 - val_loss: 1.4629 - val_accuracy: 0.8103\n","\n","Epoch 00497: val_accuracy did not improve from 0.92857\n","Epoch 498/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 1.1032 - val_accuracy: 0.8498\n","\n","Epoch 00498: val_accuracy did not improve from 0.92857\n","Epoch 499/500\n","52/52 [==============================] - 23s 444ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.7137 - val_accuracy: 0.8818\n","\n","Epoch 00499: val_accuracy did not improve from 0.92857\n","Epoch 500/500\n","52/52 [==============================] - 23s 446ms/step - loss: 0.0443 - accuracy: 0.9896 - val_loss: 4.3951 - val_accuracy: 0.5567\n","\n","Epoch 00500: val_accuracy did not improve from 0.92857\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f86fdebffd0>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"TDQDcGhdDHnI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628122819188,"user_tz":-540,"elapsed":5063090,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"982f83c5-03f2-44a6-a00e-f5d94fbdcd13"},"source":["ResNet50V2_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[ResNet50V2_checkpoint])\n","# files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["52/52 [==============================] - 18s 218ms/step - loss: 2.1483 - accuracy: 0.2826 - val_loss: 5.7136 - val_accuracy: 0.0911\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09113, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/500\n","52/52 [==============================] - 10s 192ms/step - loss: 1.3847 - accuracy: 0.5104 - val_loss: 18.4140 - val_accuracy: 0.1084\n","\n","Epoch 00002: val_accuracy improved from 0.09113 to 0.10837, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 3/500\n","52/52 [==============================] - 10s 193ms/step - loss: 1.1148 - accuracy: 0.6285 - val_loss: 20.1397 - val_accuracy: 0.0936\n","\n","Epoch 00003: val_accuracy did not improve from 0.10837\n","Epoch 4/500\n","52/52 [==============================] - 10s 193ms/step - loss: 0.9281 - accuracy: 0.6827 - val_loss: 8.2296 - val_accuracy: 0.1158\n","\n","Epoch 00004: val_accuracy improved from 0.10837 to 0.11576, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 5/500\n","52/52 [==============================] - 10s 193ms/step - loss: 0.8119 - accuracy: 0.7278 - val_loss: 8.6699 - val_accuracy: 0.1133\n","\n","Epoch 00005: val_accuracy did not improve from 0.11576\n","Epoch 6/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.7560 - accuracy: 0.7436 - val_loss: 7.1816 - val_accuracy: 0.1502\n","\n","Epoch 00006: val_accuracy improved from 0.11576 to 0.15025, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 7/500\n","52/52 [==============================] - 10s 193ms/step - loss: 0.7538 - accuracy: 0.7497 - val_loss: 4.8448 - val_accuracy: 0.3177\n","\n","Epoch 00007: val_accuracy improved from 0.15025 to 0.31773, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 8/500\n","52/52 [==============================] - 10s 196ms/step - loss: 0.6106 - accuracy: 0.7795 - val_loss: 4.5872 - val_accuracy: 0.2635\n","\n","Epoch 00008: val_accuracy did not improve from 0.31773\n","Epoch 9/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.6230 - accuracy: 0.7777 - val_loss: 2.5535 - val_accuracy: 0.5074\n","\n","Epoch 00009: val_accuracy improved from 0.31773 to 0.50739, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 10/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.5745 - accuracy: 0.8112 - val_loss: 1.3665 - val_accuracy: 0.6232\n","\n","Epoch 00010: val_accuracy improved from 0.50739 to 0.62315, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 11/500\n","52/52 [==============================] - 10s 194ms/step - loss: 0.5165 - accuracy: 0.8283 - val_loss: 1.0983 - val_accuracy: 0.6921\n","\n","Epoch 00011: val_accuracy improved from 0.62315 to 0.69212, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 12/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.4136 - accuracy: 0.8569 - val_loss: 2.4446 - val_accuracy: 0.5197\n","\n","Epoch 00012: val_accuracy did not improve from 0.69212\n","Epoch 13/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.4855 - accuracy: 0.8252 - val_loss: 1.9888 - val_accuracy: 0.6010\n","\n","Epoch 00013: val_accuracy did not improve from 0.69212\n","Epoch 14/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.4530 - accuracy: 0.8551 - val_loss: 18.3001 - val_accuracy: 0.1281\n","\n","Epoch 00014: val_accuracy did not improve from 0.69212\n","Epoch 15/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.3914 - accuracy: 0.8648 - val_loss: 11.3746 - val_accuracy: 0.1847\n","\n","Epoch 00015: val_accuracy did not improve from 0.69212\n","Epoch 16/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.3891 - accuracy: 0.8648 - val_loss: 4.1923 - val_accuracy: 0.4163\n","\n","Epoch 00016: val_accuracy did not improve from 0.69212\n","Epoch 17/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.3460 - accuracy: 0.8819 - val_loss: 7.3994 - val_accuracy: 0.2537\n","\n","Epoch 00017: val_accuracy did not improve from 0.69212\n","Epoch 18/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.3697 - accuracy: 0.8806 - val_loss: 1.7654 - val_accuracy: 0.5246\n","\n","Epoch 00018: val_accuracy did not improve from 0.69212\n","Epoch 19/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.3689 - accuracy: 0.8745 - val_loss: 14.1810 - val_accuracy: 0.1601\n","\n","Epoch 00019: val_accuracy did not improve from 0.69212\n","Epoch 20/500\n","52/52 [==============================] - 10s 187ms/step - loss: 0.3139 - accuracy: 0.8812 - val_loss: 3.4807 - val_accuracy: 0.5468\n","\n","Epoch 00020: val_accuracy did not improve from 0.69212\n","Epoch 21/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.3311 - accuracy: 0.8825 - val_loss: 3.1304 - val_accuracy: 0.4631\n","\n","Epoch 00021: val_accuracy did not improve from 0.69212\n","Epoch 22/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.3169 - accuracy: 0.8910 - val_loss: 7.2343 - val_accuracy: 0.3325\n","\n","Epoch 00022: val_accuracy did not improve from 0.69212\n","Epoch 23/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.2471 - accuracy: 0.9220 - val_loss: 0.9912 - val_accuracy: 0.7488\n","\n","Epoch 00023: val_accuracy improved from 0.69212 to 0.74877, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 24/500\n","52/52 [==============================] - 10s 193ms/step - loss: 0.2883 - accuracy: 0.9062 - val_loss: 1.9427 - val_accuracy: 0.6355\n","\n","Epoch 00024: val_accuracy did not improve from 0.74877\n","Epoch 25/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.2405 - accuracy: 0.9190 - val_loss: 1.3557 - val_accuracy: 0.6700\n","\n","Epoch 00025: val_accuracy did not improve from 0.74877\n","Epoch 26/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.3479 - accuracy: 0.8831 - val_loss: 2.1814 - val_accuracy: 0.6404\n","\n","Epoch 00026: val_accuracy did not improve from 0.74877\n","Epoch 27/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.2614 - accuracy: 0.9019 - val_loss: 0.7807 - val_accuracy: 0.7980\n","\n","Epoch 00027: val_accuracy improved from 0.74877 to 0.79803, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 28/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.2471 - accuracy: 0.9184 - val_loss: 13.1717 - val_accuracy: 0.1478\n","\n","Epoch 00028: val_accuracy did not improve from 0.79803\n","Epoch 29/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.2220 - accuracy: 0.9251 - val_loss: 1.3725 - val_accuracy: 0.6897\n","\n","Epoch 00029: val_accuracy did not improve from 0.79803\n","Epoch 30/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.2118 - accuracy: 0.9239 - val_loss: 3.3483 - val_accuracy: 0.5837\n","\n","Epoch 00030: val_accuracy did not improve from 0.79803\n","Epoch 31/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.2157 - accuracy: 0.9281 - val_loss: 4.1783 - val_accuracy: 0.4483\n","\n","Epoch 00031: val_accuracy did not improve from 0.79803\n","Epoch 32/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.2043 - accuracy: 0.9300 - val_loss: 0.6443 - val_accuracy: 0.8300\n","\n","Epoch 00032: val_accuracy improved from 0.79803 to 0.83005, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 33/500\n","52/52 [==============================] - 10s 194ms/step - loss: 0.2245 - accuracy: 0.9178 - val_loss: 2.3934 - val_accuracy: 0.6404\n","\n","Epoch 00033: val_accuracy did not improve from 0.83005\n","Epoch 34/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.2092 - accuracy: 0.9300 - val_loss: 1.5997 - val_accuracy: 0.7241\n","\n","Epoch 00034: val_accuracy did not improve from 0.83005\n","Epoch 35/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.1650 - accuracy: 0.9440 - val_loss: 5.1192 - val_accuracy: 0.4187\n","\n","Epoch 00035: val_accuracy did not improve from 0.83005\n","Epoch 36/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.1502 - accuracy: 0.9476 - val_loss: 0.6215 - val_accuracy: 0.8374\n","\n","Epoch 00036: val_accuracy improved from 0.83005 to 0.83744, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 37/500\n","52/52 [==============================] - 10s 193ms/step - loss: 0.2301 - accuracy: 0.9251 - val_loss: 1.3202 - val_accuracy: 0.7611\n","\n","Epoch 00037: val_accuracy did not improve from 0.83744\n","Epoch 38/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.1537 - accuracy: 0.9434 - val_loss: 0.6016 - val_accuracy: 0.8276\n","\n","Epoch 00038: val_accuracy did not improve from 0.83744\n","Epoch 39/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.1177 - accuracy: 0.9580 - val_loss: 0.5096 - val_accuracy: 0.8448\n","\n","Epoch 00039: val_accuracy improved from 0.83744 to 0.84483, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 40/500\n","52/52 [==============================] - 10s 193ms/step - loss: 0.1606 - accuracy: 0.9513 - val_loss: 4.9900 - val_accuracy: 0.4754\n","\n","Epoch 00040: val_accuracy did not improve from 0.84483\n","Epoch 41/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.1825 - accuracy: 0.9361 - val_loss: 0.6180 - val_accuracy: 0.8374\n","\n","Epoch 00041: val_accuracy did not improve from 0.84483\n","Epoch 42/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.2051 - accuracy: 0.9312 - val_loss: 0.9166 - val_accuracy: 0.7660\n","\n","Epoch 00042: val_accuracy did not improve from 0.84483\n","Epoch 43/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1729 - accuracy: 0.9428 - val_loss: 0.7890 - val_accuracy: 0.7956\n","\n","Epoch 00043: val_accuracy did not improve from 0.84483\n","Epoch 44/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1184 - accuracy: 0.9592 - val_loss: 12.7578 - val_accuracy: 0.2118\n","\n","Epoch 00044: val_accuracy did not improve from 0.84483\n","Epoch 45/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.1554 - accuracy: 0.9464 - val_loss: 5.4887 - val_accuracy: 0.4680\n","\n","Epoch 00045: val_accuracy did not improve from 0.84483\n","Epoch 46/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1478 - accuracy: 0.9501 - val_loss: 0.7221 - val_accuracy: 0.8374\n","\n","Epoch 00046: val_accuracy did not improve from 0.84483\n","Epoch 47/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.1553 - accuracy: 0.9470 - val_loss: 5.3258 - val_accuracy: 0.4557\n","\n","Epoch 00047: val_accuracy did not improve from 0.84483\n","Epoch 48/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1610 - accuracy: 0.9488 - val_loss: 1.4865 - val_accuracy: 0.7438\n","\n","Epoch 00048: val_accuracy did not improve from 0.84483\n","Epoch 49/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.1381 - accuracy: 0.9495 - val_loss: 0.7475 - val_accuracy: 0.8399\n","\n","Epoch 00049: val_accuracy did not improve from 0.84483\n","Epoch 50/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1023 - accuracy: 0.9629 - val_loss: 0.5797 - val_accuracy: 0.8645\n","\n","Epoch 00050: val_accuracy improved from 0.84483 to 0.86453, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 51/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.1321 - accuracy: 0.9513 - val_loss: 0.9314 - val_accuracy: 0.8202\n","\n","Epoch 00051: val_accuracy did not improve from 0.86453\n","Epoch 52/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.1426 - accuracy: 0.9537 - val_loss: 14.5225 - val_accuracy: 0.2660\n","\n","Epoch 00052: val_accuracy did not improve from 0.86453\n","Epoch 53/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1025 - accuracy: 0.9616 - val_loss: 1.1565 - val_accuracy: 0.7956\n","\n","Epoch 00053: val_accuracy did not improve from 0.86453\n","Epoch 54/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1421 - accuracy: 0.9537 - val_loss: 0.7567 - val_accuracy: 0.8300\n","\n","Epoch 00054: val_accuracy did not improve from 0.86453\n","Epoch 55/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0823 - accuracy: 0.9738 - val_loss: 0.8382 - val_accuracy: 0.8030\n","\n","Epoch 00055: val_accuracy did not improve from 0.86453\n","Epoch 56/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.1093 - accuracy: 0.9671 - val_loss: 14.9577 - val_accuracy: 0.2291\n","\n","Epoch 00056: val_accuracy did not improve from 0.86453\n","Epoch 57/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.2126 - accuracy: 0.9269 - val_loss: 21.7160 - val_accuracy: 0.1773\n","\n","Epoch 00057: val_accuracy did not improve from 0.86453\n","Epoch 58/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1221 - accuracy: 0.9549 - val_loss: 1.0621 - val_accuracy: 0.7833\n","\n","Epoch 00058: val_accuracy did not improve from 0.86453\n","Epoch 59/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1183 - accuracy: 0.9629 - val_loss: 0.7614 - val_accuracy: 0.8276\n","\n","Epoch 00059: val_accuracy did not improve from 0.86453\n","Epoch 60/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1235 - accuracy: 0.9555 - val_loss: 0.6565 - val_accuracy: 0.8522\n","\n","Epoch 00060: val_accuracy did not improve from 0.86453\n","Epoch 61/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.1322 - accuracy: 0.9604 - val_loss: 0.5175 - val_accuracy: 0.8645\n","\n","Epoch 00061: val_accuracy did not improve from 0.86453\n","Epoch 62/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0862 - accuracy: 0.9671 - val_loss: 1.0061 - val_accuracy: 0.7611\n","\n","Epoch 00062: val_accuracy did not improve from 0.86453\n","Epoch 63/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0518 - accuracy: 0.9829 - val_loss: 0.5382 - val_accuracy: 0.8867\n","\n","Epoch 00063: val_accuracy improved from 0.86453 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 64/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.0565 - accuracy: 0.9811 - val_loss: 0.5501 - val_accuracy: 0.8744\n","\n","Epoch 00064: val_accuracy did not improve from 0.88670\n","Epoch 65/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0679 - accuracy: 0.9756 - val_loss: 0.8588 - val_accuracy: 0.8325\n","\n","Epoch 00065: val_accuracy did not improve from 0.88670\n","Epoch 66/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.1109 - accuracy: 0.9629 - val_loss: 0.9491 - val_accuracy: 0.8054\n","\n","Epoch 00066: val_accuracy did not improve from 0.88670\n","Epoch 67/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1071 - accuracy: 0.9610 - val_loss: 0.7620 - val_accuracy: 0.8498\n","\n","Epoch 00067: val_accuracy did not improve from 0.88670\n","Epoch 68/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.1010 - accuracy: 0.9665 - val_loss: 17.4102 - val_accuracy: 0.2118\n","\n","Epoch 00068: val_accuracy did not improve from 0.88670\n","Epoch 69/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.1838 - accuracy: 0.9434 - val_loss: 0.9433 - val_accuracy: 0.8325\n","\n","Epoch 00069: val_accuracy did not improve from 0.88670\n","Epoch 70/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0897 - accuracy: 0.9744 - val_loss: 0.6132 - val_accuracy: 0.8645\n","\n","Epoch 00070: val_accuracy did not improve from 0.88670\n","Epoch 71/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0521 - accuracy: 0.9829 - val_loss: 0.4943 - val_accuracy: 0.8719\n","\n","Epoch 00071: val_accuracy did not improve from 0.88670\n","Epoch 72/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0559 - accuracy: 0.9829 - val_loss: 0.5937 - val_accuracy: 0.8547\n","\n","Epoch 00072: val_accuracy did not improve from 0.88670\n","Epoch 73/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0981 - accuracy: 0.9665 - val_loss: 0.5840 - val_accuracy: 0.8424\n","\n","Epoch 00073: val_accuracy did not improve from 0.88670\n","Epoch 74/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1366 - accuracy: 0.9482 - val_loss: 7.5790 - val_accuracy: 0.4212\n","\n","Epoch 00074: val_accuracy did not improve from 0.88670\n","Epoch 75/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.1051 - accuracy: 0.9683 - val_loss: 0.8514 - val_accuracy: 0.8399\n","\n","Epoch 00075: val_accuracy did not improve from 0.88670\n","Epoch 76/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1635 - accuracy: 0.9501 - val_loss: 0.5401 - val_accuracy: 0.8621\n","\n","Epoch 00076: val_accuracy did not improve from 0.88670\n","Epoch 77/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0743 - accuracy: 0.9781 - val_loss: 18.7430 - val_accuracy: 0.1379\n","\n","Epoch 00077: val_accuracy did not improve from 0.88670\n","Epoch 78/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0798 - accuracy: 0.9665 - val_loss: 12.9602 - val_accuracy: 0.2906\n","\n","Epoch 00078: val_accuracy did not improve from 0.88670\n","Epoch 79/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0781 - accuracy: 0.9744 - val_loss: 0.4410 - val_accuracy: 0.8867\n","\n","Epoch 00079: val_accuracy did not improve from 0.88670\n","Epoch 80/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1144 - accuracy: 0.9659 - val_loss: 1.0629 - val_accuracy: 0.8079\n","\n","Epoch 00080: val_accuracy did not improve from 0.88670\n","Epoch 81/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1287 - accuracy: 0.9580 - val_loss: 0.7260 - val_accuracy: 0.8547\n","\n","Epoch 00081: val_accuracy did not improve from 0.88670\n","Epoch 82/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0740 - accuracy: 0.9769 - val_loss: 0.6687 - val_accuracy: 0.8695\n","\n","Epoch 00082: val_accuracy did not improve from 0.88670\n","Epoch 83/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0750 - accuracy: 0.9756 - val_loss: 1.2897 - val_accuracy: 0.7685\n","\n","Epoch 00083: val_accuracy did not improve from 0.88670\n","Epoch 84/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0703 - accuracy: 0.9762 - val_loss: 0.5633 - val_accuracy: 0.8621\n","\n","Epoch 00084: val_accuracy did not improve from 0.88670\n","Epoch 85/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0403 - accuracy: 0.9829 - val_loss: 1.9345 - val_accuracy: 0.7266\n","\n","Epoch 00085: val_accuracy did not improve from 0.88670\n","Epoch 86/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0552 - accuracy: 0.9793 - val_loss: 0.5270 - val_accuracy: 0.8645\n","\n","Epoch 00086: val_accuracy did not improve from 0.88670\n","Epoch 87/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1111 - accuracy: 0.9622 - val_loss: 0.6514 - val_accuracy: 0.8473\n","\n","Epoch 00087: val_accuracy did not improve from 0.88670\n","Epoch 88/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0647 - accuracy: 0.9714 - val_loss: 0.4826 - val_accuracy: 0.8793\n","\n","Epoch 00088: val_accuracy did not improve from 0.88670\n","Epoch 89/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0664 - accuracy: 0.9756 - val_loss: 4.1244 - val_accuracy: 0.5074\n","\n","Epoch 00089: val_accuracy did not improve from 0.88670\n","Epoch 90/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0545 - accuracy: 0.9775 - val_loss: 0.6579 - val_accuracy: 0.8670\n","\n","Epoch 00090: val_accuracy did not improve from 0.88670\n","Epoch 91/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1706 - accuracy: 0.9495 - val_loss: 18.5146 - val_accuracy: 0.1749\n","\n","Epoch 00091: val_accuracy did not improve from 0.88670\n","Epoch 92/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1207 - accuracy: 0.9555 - val_loss: 1.2096 - val_accuracy: 0.8103\n","\n","Epoch 00092: val_accuracy did not improve from 0.88670\n","Epoch 93/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0680 - accuracy: 0.9750 - val_loss: 0.6805 - val_accuracy: 0.8522\n","\n","Epoch 00093: val_accuracy did not improve from 0.88670\n","Epoch 94/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0567 - accuracy: 0.9811 - val_loss: 0.5371 - val_accuracy: 0.8768\n","\n","Epoch 00094: val_accuracy did not improve from 0.88670\n","Epoch 95/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0602 - accuracy: 0.9805 - val_loss: 0.4963 - val_accuracy: 0.8867\n","\n","Epoch 00095: val_accuracy did not improve from 0.88670\n","Epoch 96/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 0.3873 - val_accuracy: 0.8892\n","\n","Epoch 00096: val_accuracy improved from 0.88670 to 0.88916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 97/500\n","52/52 [==============================] - 10s 194ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 2.7583 - val_accuracy: 0.6281\n","\n","Epoch 00097: val_accuracy did not improve from 0.88916\n","Epoch 98/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.0324 - accuracy: 0.9903 - val_loss: 0.9780 - val_accuracy: 0.8153\n","\n","Epoch 00098: val_accuracy did not improve from 0.88916\n","Epoch 99/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0563 - accuracy: 0.9805 - val_loss: 1.0396 - val_accuracy: 0.8128\n","\n","Epoch 00099: val_accuracy did not improve from 0.88916\n","Epoch 100/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0581 - accuracy: 0.9756 - val_loss: 0.5632 - val_accuracy: 0.8547\n","\n","Epoch 00100: val_accuracy did not improve from 0.88916\n","Epoch 101/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0521 - accuracy: 0.9817 - val_loss: 0.4971 - val_accuracy: 0.8892\n","\n","Epoch 00101: val_accuracy did not improve from 0.88916\n","Epoch 102/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 0.6064 - val_accuracy: 0.8571\n","\n","Epoch 00102: val_accuracy did not improve from 0.88916\n","Epoch 103/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0420 - accuracy: 0.9854 - val_loss: 0.6729 - val_accuracy: 0.8793\n","\n","Epoch 00103: val_accuracy did not improve from 0.88916\n","Epoch 104/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1103 - accuracy: 0.9695 - val_loss: 21.1656 - val_accuracy: 0.1823\n","\n","Epoch 00104: val_accuracy did not improve from 0.88916\n","Epoch 105/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0809 - accuracy: 0.9775 - val_loss: 8.8828 - val_accuracy: 0.4039\n","\n","Epoch 00105: val_accuracy did not improve from 0.88916\n","Epoch 106/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0600 - accuracy: 0.9799 - val_loss: 0.8450 - val_accuracy: 0.8670\n","\n","Epoch 00106: val_accuracy did not improve from 0.88916\n","Epoch 107/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0720 - accuracy: 0.9769 - val_loss: 0.5811 - val_accuracy: 0.8670\n","\n","Epoch 00107: val_accuracy did not improve from 0.88916\n","Epoch 108/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0688 - accuracy: 0.9762 - val_loss: 0.5341 - val_accuracy: 0.8719\n","\n","Epoch 00108: val_accuracy did not improve from 0.88916\n","Epoch 109/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0462 - accuracy: 0.9860 - val_loss: 0.6798 - val_accuracy: 0.8719\n","\n","Epoch 00109: val_accuracy did not improve from 0.88916\n","Epoch 110/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0689 - accuracy: 0.9769 - val_loss: 1.4615 - val_accuracy: 0.7635\n","\n","Epoch 00110: val_accuracy did not improve from 0.88916\n","Epoch 111/500\n","52/52 [==============================] - 10s 187ms/step - loss: 0.0694 - accuracy: 0.9781 - val_loss: 0.7665 - val_accuracy: 0.8276\n","\n","Epoch 00111: val_accuracy did not improve from 0.88916\n","Epoch 112/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0445 - accuracy: 0.9836 - val_loss: 1.5108 - val_accuracy: 0.7562\n","\n","Epoch 00112: val_accuracy did not improve from 0.88916\n","Epoch 113/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0364 - accuracy: 0.9860 - val_loss: 0.6424 - val_accuracy: 0.8867\n","\n","Epoch 00113: val_accuracy did not improve from 0.88916\n","Epoch 114/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0482 - accuracy: 0.9842 - val_loss: 0.5035 - val_accuracy: 0.8842\n","\n","Epoch 00114: val_accuracy did not improve from 0.88916\n","Epoch 115/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0523 - accuracy: 0.9787 - val_loss: 0.6162 - val_accuracy: 0.8744\n","\n","Epoch 00115: val_accuracy did not improve from 0.88916\n","Epoch 116/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0719 - accuracy: 0.9750 - val_loss: 1.0862 - val_accuracy: 0.8177\n","\n","Epoch 00116: val_accuracy did not improve from 0.88916\n","Epoch 117/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0889 - accuracy: 0.9744 - val_loss: 0.9031 - val_accuracy: 0.8202\n","\n","Epoch 00117: val_accuracy did not improve from 0.88916\n","Epoch 118/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0697 - accuracy: 0.9817 - val_loss: 0.7522 - val_accuracy: 0.8596\n","\n","Epoch 00118: val_accuracy did not improve from 0.88916\n","Epoch 119/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0535 - accuracy: 0.9805 - val_loss: 0.4656 - val_accuracy: 0.9064\n","\n","Epoch 00119: val_accuracy improved from 0.88916 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 120/500\n","52/52 [==============================] - 10s 193ms/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 0.5811 - val_accuracy: 0.8768\n","\n","Epoch 00120: val_accuracy did not improve from 0.90640\n","Epoch 121/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0750 - accuracy: 0.9775 - val_loss: 1.0155 - val_accuracy: 0.8399\n","\n","Epoch 00121: val_accuracy did not improve from 0.90640\n","Epoch 122/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1134 - accuracy: 0.9635 - val_loss: 0.8868 - val_accuracy: 0.8276\n","\n","Epoch 00122: val_accuracy did not improve from 0.90640\n","Epoch 123/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0680 - accuracy: 0.9811 - val_loss: 0.6989 - val_accuracy: 0.8695\n","\n","Epoch 00123: val_accuracy did not improve from 0.90640\n","Epoch 124/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0377 - accuracy: 0.9836 - val_loss: 0.7438 - val_accuracy: 0.8645\n","\n","Epoch 00124: val_accuracy did not improve from 0.90640\n","Epoch 125/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0344 - accuracy: 0.9903 - val_loss: 0.4917 - val_accuracy: 0.8842\n","\n","Epoch 00125: val_accuracy did not improve from 0.90640\n","Epoch 126/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.6347 - val_accuracy: 0.8818\n","\n","Epoch 00126: val_accuracy did not improve from 0.90640\n","Epoch 127/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0945 - accuracy: 0.9677 - val_loss: 0.9888 - val_accuracy: 0.8350\n","\n","Epoch 00127: val_accuracy did not improve from 0.90640\n","Epoch 128/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 2.1941 - val_accuracy: 0.7709\n","\n","Epoch 00128: val_accuracy did not improve from 0.90640\n","Epoch 129/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0425 - accuracy: 0.9848 - val_loss: 0.6476 - val_accuracy: 0.8670\n","\n","Epoch 00129: val_accuracy did not improve from 0.90640\n","Epoch 130/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0437 - accuracy: 0.9866 - val_loss: 0.6500 - val_accuracy: 0.8596\n","\n","Epoch 00130: val_accuracy did not improve from 0.90640\n","Epoch 131/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.6124 - val_accuracy: 0.8719\n","\n","Epoch 00131: val_accuracy did not improve from 0.90640\n","Epoch 132/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.6257 - val_accuracy: 0.8695\n","\n","Epoch 00132: val_accuracy did not improve from 0.90640\n","Epoch 133/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.5087 - val_accuracy: 0.8941\n","\n","Epoch 00133: val_accuracy did not improve from 0.90640\n","Epoch 134/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0399 - accuracy: 0.9872 - val_loss: 1.0655 - val_accuracy: 0.8473\n","\n","Epoch 00134: val_accuracy did not improve from 0.90640\n","Epoch 135/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0616 - accuracy: 0.9781 - val_loss: 25.0877 - val_accuracy: 0.1232\n","\n","Epoch 00135: val_accuracy did not improve from 0.90640\n","Epoch 136/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0533 - accuracy: 0.9842 - val_loss: 21.3275 - val_accuracy: 0.1970\n","\n","Epoch 00136: val_accuracy did not improve from 0.90640\n","Epoch 137/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 3.0790 - val_accuracy: 0.6207\n","\n","Epoch 00137: val_accuracy did not improve from 0.90640\n","Epoch 138/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0213 - accuracy: 0.9963 - val_loss: 16.1583 - val_accuracy: 0.2340\n","\n","Epoch 00138: val_accuracy did not improve from 0.90640\n","Epoch 139/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0915 - accuracy: 0.9708 - val_loss: 1.0313 - val_accuracy: 0.8374\n","\n","Epoch 00139: val_accuracy did not improve from 0.90640\n","Epoch 140/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0956 - accuracy: 0.9781 - val_loss: 0.8260 - val_accuracy: 0.8522\n","\n","Epoch 00140: val_accuracy did not improve from 0.90640\n","Epoch 141/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1309 - accuracy: 0.9580 - val_loss: 0.8268 - val_accuracy: 0.8547\n","\n","Epoch 00141: val_accuracy did not improve from 0.90640\n","Epoch 142/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1018 - accuracy: 0.9659 - val_loss: 1.6600 - val_accuracy: 0.7365\n","\n","Epoch 00142: val_accuracy did not improve from 0.90640\n","Epoch 143/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0797 - accuracy: 0.9689 - val_loss: 1.1201 - val_accuracy: 0.7906\n","\n","Epoch 00143: val_accuracy did not improve from 0.90640\n","Epoch 144/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0589 - accuracy: 0.9836 - val_loss: 0.6902 - val_accuracy: 0.8547\n","\n","Epoch 00144: val_accuracy did not improve from 0.90640\n","Epoch 145/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0341 - accuracy: 0.9921 - val_loss: 0.8830 - val_accuracy: 0.8300\n","\n","Epoch 00145: val_accuracy did not improve from 0.90640\n","Epoch 146/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0632 - accuracy: 0.9793 - val_loss: 27.5500 - val_accuracy: 0.0985\n","\n","Epoch 00146: val_accuracy did not improve from 0.90640\n","Epoch 147/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0284 - accuracy: 0.9921 - val_loss: 0.5375 - val_accuracy: 0.9015\n","\n","Epoch 00147: val_accuracy did not improve from 0.90640\n","Epoch 148/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.4989 - val_accuracy: 0.9113\n","\n","Epoch 00148: val_accuracy improved from 0.90640 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 149/500\n","52/52 [==============================] - 10s 193ms/step - loss: 0.0237 - accuracy: 0.9909 - val_loss: 0.5480 - val_accuracy: 0.9113\n","\n","Epoch 00149: val_accuracy did not improve from 0.91133\n","Epoch 150/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.5406 - val_accuracy: 0.9113\n","\n","Epoch 00150: val_accuracy did not improve from 0.91133\n","Epoch 151/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.4860 - val_accuracy: 0.9089\n","\n","Epoch 00151: val_accuracy did not improve from 0.91133\n","Epoch 152/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4044 - val_accuracy: 0.9113\n","\n","Epoch 00152: val_accuracy did not improve from 0.91133\n","Epoch 153/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4304 - val_accuracy: 0.9212\n","\n","Epoch 00153: val_accuracy improved from 0.91133 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 154/500\n","52/52 [==============================] - 10s 194ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5507 - val_accuracy: 0.9039\n","\n","Epoch 00154: val_accuracy did not improve from 0.92118\n","Epoch 155/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0062 - accuracy: 0.9970 - val_loss: 0.6241 - val_accuracy: 0.8719\n","\n","Epoch 00155: val_accuracy did not improve from 0.92118\n","Epoch 156/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0200 - accuracy: 0.9945 - val_loss: 0.4647 - val_accuracy: 0.9163\n","\n","Epoch 00156: val_accuracy did not improve from 0.92118\n","Epoch 157/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.6156 - val_accuracy: 0.8892\n","\n","Epoch 00157: val_accuracy did not improve from 0.92118\n","Epoch 158/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0167 - accuracy: 0.9927 - val_loss: 0.7925 - val_accuracy: 0.8522\n","\n","Epoch 00158: val_accuracy did not improve from 0.92118\n","Epoch 159/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0468 - accuracy: 0.9829 - val_loss: 0.5825 - val_accuracy: 0.8842\n","\n","Epoch 00159: val_accuracy did not improve from 0.92118\n","Epoch 160/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0591 - accuracy: 0.9756 - val_loss: 1.4081 - val_accuracy: 0.7980\n","\n","Epoch 00160: val_accuracy did not improve from 0.92118\n","Epoch 161/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1052 - accuracy: 0.9683 - val_loss: 5.5767 - val_accuracy: 0.5148\n","\n","Epoch 00161: val_accuracy did not improve from 0.92118\n","Epoch 162/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0560 - accuracy: 0.9805 - val_loss: 0.9738 - val_accuracy: 0.8424\n","\n","Epoch 00162: val_accuracy did not improve from 0.92118\n","Epoch 163/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0309 - accuracy: 0.9890 - val_loss: 0.6004 - val_accuracy: 0.8892\n","\n","Epoch 00163: val_accuracy did not improve from 0.92118\n","Epoch 164/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0593 - accuracy: 0.9787 - val_loss: 4.0592 - val_accuracy: 0.6429\n","\n","Epoch 00164: val_accuracy did not improve from 0.92118\n","Epoch 165/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0372 - accuracy: 0.9866 - val_loss: 0.6338 - val_accuracy: 0.8867\n","\n","Epoch 00165: val_accuracy did not improve from 0.92118\n","Epoch 166/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.7176 - val_accuracy: 0.8695\n","\n","Epoch 00166: val_accuracy did not improve from 0.92118\n","Epoch 167/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.5551 - val_accuracy: 0.8941\n","\n","Epoch 00167: val_accuracy did not improve from 0.92118\n","Epoch 168/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.4973 - val_accuracy: 0.9113\n","\n","Epoch 00168: val_accuracy did not improve from 0.92118\n","Epoch 169/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.5255 - val_accuracy: 0.8966\n","\n","Epoch 00169: val_accuracy did not improve from 0.92118\n","Epoch 170/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.5534 - val_accuracy: 0.8990\n","\n","Epoch 00170: val_accuracy did not improve from 0.92118\n","Epoch 171/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.5271 - val_accuracy: 0.9089\n","\n","Epoch 00171: val_accuracy did not improve from 0.92118\n","Epoch 172/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.8031 - val_accuracy: 0.8793\n","\n","Epoch 00172: val_accuracy did not improve from 0.92118\n","Epoch 173/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.5879 - val_accuracy: 0.8990\n","\n","Epoch 00173: val_accuracy did not improve from 0.92118\n","Epoch 174/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5775 - val_accuracy: 0.9089\n","\n","Epoch 00174: val_accuracy did not improve from 0.92118\n","Epoch 175/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4631 - val_accuracy: 0.9335\n","\n","Epoch 00175: val_accuracy improved from 0.92118 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5\n","Epoch 176/500\n","52/52 [==============================] - 10s 193ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4652 - val_accuracy: 0.9212\n","\n","Epoch 00176: val_accuracy did not improve from 0.93350\n","Epoch 177/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.9113\n","\n","Epoch 00177: val_accuracy did not improve from 0.93350\n","Epoch 178/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.6372 - val_accuracy: 0.8990\n","\n","Epoch 00178: val_accuracy did not improve from 0.93350\n","Epoch 179/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0934 - accuracy: 0.9714 - val_loss: 1.6043 - val_accuracy: 0.7833\n","\n","Epoch 00179: val_accuracy did not improve from 0.93350\n","Epoch 180/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1160 - accuracy: 0.9610 - val_loss: 1.2186 - val_accuracy: 0.8153\n","\n","Epoch 00180: val_accuracy did not improve from 0.93350\n","Epoch 181/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1138 - accuracy: 0.9641 - val_loss: 7.6175 - val_accuracy: 0.4631\n","\n","Epoch 00181: val_accuracy did not improve from 0.93350\n","Epoch 182/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0892 - accuracy: 0.9659 - val_loss: 0.7974 - val_accuracy: 0.8547\n","\n","Epoch 00182: val_accuracy did not improve from 0.93350\n","Epoch 183/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0270 - accuracy: 0.9909 - val_loss: 0.5949 - val_accuracy: 0.8768\n","\n","Epoch 00183: val_accuracy did not improve from 0.93350\n","Epoch 184/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0236 - accuracy: 0.9903 - val_loss: 0.6332 - val_accuracy: 0.8941\n","\n","Epoch 00184: val_accuracy did not improve from 0.93350\n","Epoch 185/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.6420 - val_accuracy: 0.8818\n","\n","Epoch 00185: val_accuracy did not improve from 0.93350\n","Epoch 186/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0221 - accuracy: 0.9915 - val_loss: 0.7395 - val_accuracy: 0.8621\n","\n","Epoch 00186: val_accuracy did not improve from 0.93350\n","Epoch 187/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0325 - accuracy: 0.9890 - val_loss: 0.5345 - val_accuracy: 0.8990\n","\n","Epoch 00187: val_accuracy did not improve from 0.93350\n","Epoch 188/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.5879 - val_accuracy: 0.8966\n","\n","Epoch 00188: val_accuracy did not improve from 0.93350\n","Epoch 189/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.6293 - val_accuracy: 0.8916\n","\n","Epoch 00189: val_accuracy did not improve from 0.93350\n","Epoch 190/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.5003 - val_accuracy: 0.9163\n","\n","Epoch 00190: val_accuracy did not improve from 0.93350\n","Epoch 191/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0123 - accuracy: 0.9939 - val_loss: 0.6534 - val_accuracy: 0.8744\n","\n","Epoch 00191: val_accuracy did not improve from 0.93350\n","Epoch 192/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 12.1299 - val_accuracy: 0.3670\n","\n","Epoch 00192: val_accuracy did not improve from 0.93350\n","Epoch 193/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.6608 - val_accuracy: 0.8818\n","\n","Epoch 00193: val_accuracy did not improve from 0.93350\n","Epoch 194/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0089 - accuracy: 0.9988 - val_loss: 0.4807 - val_accuracy: 0.8941\n","\n","Epoch 00194: val_accuracy did not improve from 0.93350\n","Epoch 195/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.5328 - val_accuracy: 0.8990\n","\n","Epoch 00195: val_accuracy did not improve from 0.93350\n","Epoch 196/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0328 - accuracy: 0.9890 - val_loss: 0.6769 - val_accuracy: 0.8695\n","\n","Epoch 00196: val_accuracy did not improve from 0.93350\n","Epoch 197/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0697 - accuracy: 0.9756 - val_loss: 13.6407 - val_accuracy: 0.3079\n","\n","Epoch 00197: val_accuracy did not improve from 0.93350\n","Epoch 198/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0609 - accuracy: 0.9787 - val_loss: 0.9279 - val_accuracy: 0.8571\n","\n","Epoch 00198: val_accuracy did not improve from 0.93350\n","Epoch 199/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0470 - accuracy: 0.9842 - val_loss: 1.2337 - val_accuracy: 0.8128\n","\n","Epoch 00199: val_accuracy did not improve from 0.93350\n","Epoch 200/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0549 - accuracy: 0.9836 - val_loss: 0.6848 - val_accuracy: 0.8768\n","\n","Epoch 00200: val_accuracy did not improve from 0.93350\n","Epoch 201/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0217 - accuracy: 0.9951 - val_loss: 0.7203 - val_accuracy: 0.8744\n","\n","Epoch 00201: val_accuracy did not improve from 0.93350\n","Epoch 202/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0290 - accuracy: 0.9909 - val_loss: 13.9495 - val_accuracy: 0.2488\n","\n","Epoch 00202: val_accuracy did not improve from 0.93350\n","Epoch 203/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0162 - accuracy: 0.9933 - val_loss: 1.2401 - val_accuracy: 0.8251\n","\n","Epoch 00203: val_accuracy did not improve from 0.93350\n","Epoch 204/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 9.6429 - val_accuracy: 0.4852\n","\n","Epoch 00204: val_accuracy did not improve from 0.93350\n","Epoch 205/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0398 - accuracy: 0.9909 - val_loss: 0.7081 - val_accuracy: 0.8892\n","\n","Epoch 00205: val_accuracy did not improve from 0.93350\n","Epoch 206/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0277 - accuracy: 0.9933 - val_loss: 0.7118 - val_accuracy: 0.8744\n","\n","Epoch 00206: val_accuracy did not improve from 0.93350\n","Epoch 207/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0896 - accuracy: 0.9732 - val_loss: 5.2259 - val_accuracy: 0.5493\n","\n","Epoch 00207: val_accuracy did not improve from 0.93350\n","Epoch 208/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0263 - accuracy: 0.9927 - val_loss: 0.6792 - val_accuracy: 0.8744\n","\n","Epoch 00208: val_accuracy did not improve from 0.93350\n","Epoch 209/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 1.1182 - val_accuracy: 0.8300\n","\n","Epoch 00209: val_accuracy did not improve from 0.93350\n","Epoch 210/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.7286 - val_accuracy: 0.8670\n","\n","Epoch 00210: val_accuracy did not improve from 0.93350\n","Epoch 211/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.5742 - val_accuracy: 0.8966\n","\n","Epoch 00211: val_accuracy did not improve from 0.93350\n","Epoch 212/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0341 - accuracy: 0.9878 - val_loss: 1.1968 - val_accuracy: 0.8399\n","\n","Epoch 00212: val_accuracy did not improve from 0.93350\n","Epoch 213/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0331 - accuracy: 0.9915 - val_loss: 0.4779 - val_accuracy: 0.9212\n","\n","Epoch 00213: val_accuracy did not improve from 0.93350\n","Epoch 214/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0225 - accuracy: 0.9909 - val_loss: 0.7343 - val_accuracy: 0.8768\n","\n","Epoch 00214: val_accuracy did not improve from 0.93350\n","Epoch 215/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 0.6167 - val_accuracy: 0.8892\n","\n","Epoch 00215: val_accuracy did not improve from 0.93350\n","Epoch 216/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0167 - accuracy: 0.9927 - val_loss: 0.6457 - val_accuracy: 0.8916\n","\n","Epoch 00216: val_accuracy did not improve from 0.93350\n","Epoch 217/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0680 - accuracy: 0.9823 - val_loss: 1.0525 - val_accuracy: 0.8399\n","\n","Epoch 00217: val_accuracy did not improve from 0.93350\n","Epoch 218/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0469 - accuracy: 0.9836 - val_loss: 0.6246 - val_accuracy: 0.8793\n","\n","Epoch 00218: val_accuracy did not improve from 0.93350\n","Epoch 219/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0477 - accuracy: 0.9866 - val_loss: 1.2391 - val_accuracy: 0.8030\n","\n","Epoch 00219: val_accuracy did not improve from 0.93350\n","Epoch 220/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 5.9673 - val_accuracy: 0.5714\n","\n","Epoch 00220: val_accuracy did not improve from 0.93350\n","Epoch 221/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0375 - accuracy: 0.9878 - val_loss: 0.9464 - val_accuracy: 0.8424\n","\n","Epoch 00221: val_accuracy did not improve from 0.93350\n","Epoch 222/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0213 - accuracy: 0.9921 - val_loss: 0.6007 - val_accuracy: 0.8867\n","\n","Epoch 00222: val_accuracy did not improve from 0.93350\n","Epoch 223/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0182 - accuracy: 0.9933 - val_loss: 0.5966 - val_accuracy: 0.8990\n","\n","Epoch 00223: val_accuracy did not improve from 0.93350\n","Epoch 224/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 5.7059 - val_accuracy: 0.5296\n","\n","Epoch 00224: val_accuracy did not improve from 0.93350\n","Epoch 225/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0534 - accuracy: 0.9823 - val_loss: 0.6591 - val_accuracy: 0.8571\n","\n","Epoch 00225: val_accuracy did not improve from 0.93350\n","Epoch 226/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0340 - accuracy: 0.9903 - val_loss: 0.8141 - val_accuracy: 0.8522\n","\n","Epoch 00226: val_accuracy did not improve from 0.93350\n","Epoch 227/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.5884 - val_accuracy: 0.8916\n","\n","Epoch 00227: val_accuracy did not improve from 0.93350\n","Epoch 228/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.5850 - val_accuracy: 0.8793\n","\n","Epoch 00228: val_accuracy did not improve from 0.93350\n","Epoch 229/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.5748 - val_accuracy: 0.8966\n","\n","Epoch 00229: val_accuracy did not improve from 0.93350\n","Epoch 230/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5256 - val_accuracy: 0.8867\n","\n","Epoch 00230: val_accuracy did not improve from 0.93350\n","Epoch 231/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.5900 - val_accuracy: 0.8966\n","\n","Epoch 00231: val_accuracy did not improve from 0.93350\n","Epoch 232/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.5134 - val_accuracy: 0.8941\n","\n","Epoch 00232: val_accuracy did not improve from 0.93350\n","Epoch 233/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 0.6689 - val_accuracy: 0.8768\n","\n","Epoch 00233: val_accuracy did not improve from 0.93350\n","Epoch 234/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0271 - accuracy: 0.9909 - val_loss: 0.8131 - val_accuracy: 0.8596\n","\n","Epoch 00234: val_accuracy did not improve from 0.93350\n","Epoch 235/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0293 - accuracy: 0.9909 - val_loss: 0.7327 - val_accuracy: 0.8695\n","\n","Epoch 00235: val_accuracy did not improve from 0.93350\n","Epoch 236/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0204 - accuracy: 0.9909 - val_loss: 0.6707 - val_accuracy: 0.8768\n","\n","Epoch 00236: val_accuracy did not improve from 0.93350\n","Epoch 237/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.8615 - val_accuracy: 0.8522\n","\n","Epoch 00237: val_accuracy did not improve from 0.93350\n","Epoch 238/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0565 - accuracy: 0.9829 - val_loss: 1.2527 - val_accuracy: 0.8424\n","\n","Epoch 00238: val_accuracy did not improve from 0.93350\n","Epoch 239/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0710 - accuracy: 0.9823 - val_loss: 3.4696 - val_accuracy: 0.6576\n","\n","Epoch 00239: val_accuracy did not improve from 0.93350\n","Epoch 240/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0475 - accuracy: 0.9860 - val_loss: 1.7786 - val_accuracy: 0.7512\n","\n","Epoch 00240: val_accuracy did not improve from 0.93350\n","Epoch 241/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0325 - accuracy: 0.9866 - val_loss: 0.4831 - val_accuracy: 0.9015\n","\n","Epoch 00241: val_accuracy did not improve from 0.93350\n","Epoch 242/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.6829 - val_accuracy: 0.8867\n","\n","Epoch 00242: val_accuracy did not improve from 0.93350\n","Epoch 243/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.5159 - val_accuracy: 0.9039\n","\n","Epoch 00243: val_accuracy did not improve from 0.93350\n","Epoch 244/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.5704 - val_accuracy: 0.9089\n","\n","Epoch 00244: val_accuracy did not improve from 0.93350\n","Epoch 245/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.4971 - val_accuracy: 0.8867\n","\n","Epoch 00245: val_accuracy did not improve from 0.93350\n","Epoch 246/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.5459 - val_accuracy: 0.9039\n","\n","Epoch 00246: val_accuracy did not improve from 0.93350\n","Epoch 247/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.6345 - val_accuracy: 0.8941\n","\n","Epoch 00247: val_accuracy did not improve from 0.93350\n","Epoch 248/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.4946 - val_accuracy: 0.9187\n","\n","Epoch 00248: val_accuracy did not improve from 0.93350\n","Epoch 249/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.6021 - val_accuracy: 0.8842\n","\n","Epoch 00249: val_accuracy did not improve from 0.93350\n","Epoch 250/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.6382 - val_accuracy: 0.9015\n","\n","Epoch 00250: val_accuracy did not improve from 0.93350\n","Epoch 251/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5132 - val_accuracy: 0.8867\n","\n","Epoch 00251: val_accuracy did not improve from 0.93350\n","Epoch 252/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.9089\n","\n","Epoch 00252: val_accuracy did not improve from 0.93350\n","Epoch 253/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4096 - val_accuracy: 0.9236\n","\n","Epoch 00253: val_accuracy did not improve from 0.93350\n","Epoch 254/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.7189 - val_accuracy: 0.8670\n","\n","Epoch 00254: val_accuracy did not improve from 0.93350\n","Epoch 255/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0459 - accuracy: 0.9903 - val_loss: 1.1619 - val_accuracy: 0.8251\n","\n","Epoch 00255: val_accuracy did not improve from 0.93350\n","Epoch 256/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 0.4957 - val_accuracy: 0.9064\n","\n","Epoch 00256: val_accuracy did not improve from 0.93350\n","Epoch 257/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.9394 - val_accuracy: 0.8424\n","\n","Epoch 00257: val_accuracy did not improve from 0.93350\n","Epoch 258/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.5732 - val_accuracy: 0.8793\n","\n","Epoch 00258: val_accuracy did not improve from 0.93350\n","Epoch 259/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.5843 - val_accuracy: 0.8966\n","\n","Epoch 00259: val_accuracy did not improve from 0.93350\n","Epoch 260/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 0.4712 - val_accuracy: 0.9064\n","\n","Epoch 00260: val_accuracy did not improve from 0.93350\n","Epoch 261/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0265 - accuracy: 0.9890 - val_loss: 0.6975 - val_accuracy: 0.8768\n","\n","Epoch 00261: val_accuracy did not improve from 0.93350\n","Epoch 262/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0680 - accuracy: 0.9811 - val_loss: 10.7469 - val_accuracy: 0.3374\n","\n","Epoch 00262: val_accuracy did not improve from 0.93350\n","Epoch 263/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0469 - accuracy: 0.9854 - val_loss: 0.8986 - val_accuracy: 0.8719\n","\n","Epoch 00263: val_accuracy did not improve from 0.93350\n","Epoch 264/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 0.5873 - val_accuracy: 0.8990\n","\n","Epoch 00264: val_accuracy did not improve from 0.93350\n","Epoch 265/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.9136 - val_accuracy: 0.8719\n","\n","Epoch 00265: val_accuracy did not improve from 0.93350\n","Epoch 266/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.5079 - val_accuracy: 0.8990\n","\n","Epoch 00266: val_accuracy did not improve from 0.93350\n","Epoch 267/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 0.6185 - val_accuracy: 0.8793\n","\n","Epoch 00267: val_accuracy did not improve from 0.93350\n","Epoch 268/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.4061 - val_accuracy: 0.9089\n","\n","Epoch 00268: val_accuracy did not improve from 0.93350\n","Epoch 269/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.4938 - val_accuracy: 0.9039\n","\n","Epoch 00269: val_accuracy did not improve from 0.93350\n","Epoch 270/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0405 - accuracy: 0.9872 - val_loss: 1.1044 - val_accuracy: 0.8448\n","\n","Epoch 00270: val_accuracy did not improve from 0.93350\n","Epoch 271/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0380 - accuracy: 0.9872 - val_loss: 9.5763 - val_accuracy: 0.3818\n","\n","Epoch 00271: val_accuracy did not improve from 0.93350\n","Epoch 272/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0262 - accuracy: 0.9927 - val_loss: 0.7149 - val_accuracy: 0.8621\n","\n","Epoch 00272: val_accuracy did not improve from 0.93350\n","Epoch 273/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.5832 - val_accuracy: 0.8892\n","\n","Epoch 00273: val_accuracy did not improve from 0.93350\n","Epoch 274/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.5886 - val_accuracy: 0.8867\n","\n","Epoch 00274: val_accuracy did not improve from 0.93350\n","Epoch 275/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4356 - val_accuracy: 0.9015\n","\n","Epoch 00275: val_accuracy did not improve from 0.93350\n","Epoch 276/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.8990\n","\n","Epoch 00276: val_accuracy did not improve from 0.93350\n","Epoch 277/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.5630 - val_accuracy: 0.8966\n","\n","Epoch 00277: val_accuracy did not improve from 0.93350\n","Epoch 278/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.5043 - val_accuracy: 0.8941\n","\n","Epoch 00278: val_accuracy did not improve from 0.93350\n","Epoch 279/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5245 - val_accuracy: 0.8941\n","\n","Epoch 00279: val_accuracy did not improve from 0.93350\n","Epoch 280/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.6887 - val_accuracy: 0.8768\n","\n","Epoch 00280: val_accuracy did not improve from 0.93350\n","Epoch 281/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.6486 - val_accuracy: 0.8842\n","\n","Epoch 00281: val_accuracy did not improve from 0.93350\n","Epoch 282/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.6468 - val_accuracy: 0.8916\n","\n","Epoch 00282: val_accuracy did not improve from 0.93350\n","Epoch 283/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.6359 - val_accuracy: 0.8941\n","\n","Epoch 00283: val_accuracy did not improve from 0.93350\n","Epoch 284/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.3932 - val_accuracy: 0.9261\n","\n","Epoch 00284: val_accuracy did not improve from 0.93350\n","Epoch 285/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4469 - val_accuracy: 0.9187\n","\n","Epoch 00285: val_accuracy did not improve from 0.93350\n","Epoch 286/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4496 - val_accuracy: 0.9039\n","\n","Epoch 00286: val_accuracy did not improve from 0.93350\n","Epoch 287/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.5092 - val_accuracy: 0.9113\n","\n","Epoch 00287: val_accuracy did not improve from 0.93350\n","Epoch 288/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0204 - accuracy: 0.9915 - val_loss: 1.2149 - val_accuracy: 0.8276\n","\n","Epoch 00288: val_accuracy did not improve from 0.93350\n","Epoch 289/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0813 - accuracy: 0.9756 - val_loss: 0.9714 - val_accuracy: 0.8498\n","\n","Epoch 00289: val_accuracy did not improve from 0.93350\n","Epoch 290/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.6981 - val_accuracy: 0.8818\n","\n","Epoch 00290: val_accuracy did not improve from 0.93350\n","Epoch 291/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0203 - accuracy: 0.9921 - val_loss: 0.8282 - val_accuracy: 0.8892\n","\n","Epoch 00291: val_accuracy did not improve from 0.93350\n","Epoch 292/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.6280 - val_accuracy: 0.8916\n","\n","Epoch 00292: val_accuracy did not improve from 0.93350\n","Epoch 293/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0544 - accuracy: 0.9842 - val_loss: 1.6429 - val_accuracy: 0.7734\n","\n","Epoch 00293: val_accuracy did not improve from 0.93350\n","Epoch 294/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0726 - accuracy: 0.9781 - val_loss: 1.6737 - val_accuracy: 0.8079\n","\n","Epoch 00294: val_accuracy did not improve from 0.93350\n","Epoch 295/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0512 - accuracy: 0.9829 - val_loss: 0.7351 - val_accuracy: 0.8793\n","\n","Epoch 00295: val_accuracy did not improve from 0.93350\n","Epoch 296/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0277 - accuracy: 0.9909 - val_loss: 0.4789 - val_accuracy: 0.8916\n","\n","Epoch 00296: val_accuracy did not improve from 0.93350\n","Epoch 297/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.5331 - val_accuracy: 0.8941\n","\n","Epoch 00297: val_accuracy did not improve from 0.93350\n","Epoch 298/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.6772 - val_accuracy: 0.8645\n","\n","Epoch 00298: val_accuracy did not improve from 0.93350\n","Epoch 299/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.4919 - val_accuracy: 0.9015\n","\n","Epoch 00299: val_accuracy did not improve from 0.93350\n","Epoch 300/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0110 - accuracy: 0.9945 - val_loss: 0.4899 - val_accuracy: 0.9064\n","\n","Epoch 00300: val_accuracy did not improve from 0.93350\n","Epoch 301/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.4211 - val_accuracy: 0.9113\n","\n","Epoch 00301: val_accuracy did not improve from 0.93350\n","Epoch 302/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4500 - val_accuracy: 0.9015\n","\n","Epoch 00302: val_accuracy did not improve from 0.93350\n","Epoch 303/500\n","52/52 [==============================] - 10s 189ms/step - loss: 8.5801e-04 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.8966\n","\n","Epoch 00303: val_accuracy did not improve from 0.93350\n","Epoch 304/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5252 - val_accuracy: 0.8990\n","\n","Epoch 00304: val_accuracy did not improve from 0.93350\n","Epoch 305/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.6293 - val_accuracy: 0.9039\n","\n","Epoch 00305: val_accuracy did not improve from 0.93350\n","Epoch 306/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.6018 - val_accuracy: 0.8892\n","\n","Epoch 00306: val_accuracy did not improve from 0.93350\n","Epoch 307/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5758 - val_accuracy: 0.8916\n","\n","Epoch 00307: val_accuracy did not improve from 0.93350\n","Epoch 308/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4530 - val_accuracy: 0.9064\n","\n","Epoch 00308: val_accuracy did not improve from 0.93350\n","Epoch 309/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 14.4794 - val_accuracy: 0.3670\n","\n","Epoch 00309: val_accuracy did not improve from 0.93350\n","Epoch 310/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 17.4494 - val_accuracy: 0.2956\n","\n","Epoch 00310: val_accuracy did not improve from 0.93350\n","Epoch 311/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0060 - accuracy: 0.9970 - val_loss: 0.5638 - val_accuracy: 0.9015\n","\n","Epoch 00311: val_accuracy did not improve from 0.93350\n","Epoch 312/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5770 - val_accuracy: 0.8793\n","\n","Epoch 00312: val_accuracy did not improve from 0.93350\n","Epoch 313/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5453 - val_accuracy: 0.8818\n","\n","Epoch 00313: val_accuracy did not improve from 0.93350\n","Epoch 314/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 16.9236 - val_accuracy: 0.2833\n","\n","Epoch 00314: val_accuracy did not improve from 0.93350\n","Epoch 315/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0181 - accuracy: 0.9963 - val_loss: 1.9413 - val_accuracy: 0.7709\n","\n","Epoch 00315: val_accuracy did not improve from 0.93350\n","Epoch 316/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0177 - accuracy: 0.9927 - val_loss: 0.6369 - val_accuracy: 0.8793\n","\n","Epoch 00316: val_accuracy did not improve from 0.93350\n","Epoch 317/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.9183 - val_accuracy: 0.8448\n","\n","Epoch 00317: val_accuracy did not improve from 0.93350\n","Epoch 318/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.5607 - val_accuracy: 0.8990\n","\n","Epoch 00318: val_accuracy did not improve from 0.93350\n","Epoch 319/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0153 - accuracy: 0.9933 - val_loss: 0.8048 - val_accuracy: 0.8744\n","\n","Epoch 00319: val_accuracy did not improve from 0.93350\n","Epoch 320/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0566 - accuracy: 0.9829 - val_loss: 1.0422 - val_accuracy: 0.8547\n","\n","Epoch 00320: val_accuracy did not improve from 0.93350\n","Epoch 321/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0623 - accuracy: 0.9823 - val_loss: 0.7338 - val_accuracy: 0.8793\n","\n","Epoch 00321: val_accuracy did not improve from 0.93350\n","Epoch 322/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0526 - accuracy: 0.9836 - val_loss: 0.8487 - val_accuracy: 0.8473\n","\n","Epoch 00322: val_accuracy did not improve from 0.93350\n","Epoch 323/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.6219 - val_accuracy: 0.8842\n","\n","Epoch 00323: val_accuracy did not improve from 0.93350\n","Epoch 324/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.5961 - val_accuracy: 0.8744\n","\n","Epoch 00324: val_accuracy did not improve from 0.93350\n","Epoch 325/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.7914 - val_accuracy: 0.8867\n","\n","Epoch 00325: val_accuracy did not improve from 0.93350\n","Epoch 326/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 0.7148 - val_accuracy: 0.8842\n","\n","Epoch 00326: val_accuracy did not improve from 0.93350\n","Epoch 327/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0331 - accuracy: 0.9872 - val_loss: 0.7118 - val_accuracy: 0.8867\n","\n","Epoch 00327: val_accuracy did not improve from 0.93350\n","Epoch 328/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0217 - accuracy: 0.9939 - val_loss: 0.8196 - val_accuracy: 0.8941\n","\n","Epoch 00328: val_accuracy did not improve from 0.93350\n","Epoch 329/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.6801 - val_accuracy: 0.8768\n","\n","Epoch 00329: val_accuracy did not improve from 0.93350\n","Epoch 330/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0225 - accuracy: 0.9939 - val_loss: 0.8784 - val_accuracy: 0.8793\n","\n","Epoch 00330: val_accuracy did not improve from 0.93350\n","Epoch 331/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0416 - accuracy: 0.9915 - val_loss: 0.7983 - val_accuracy: 0.8719\n","\n","Epoch 00331: val_accuracy did not improve from 0.93350\n","Epoch 332/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0219 - accuracy: 0.9915 - val_loss: 0.5557 - val_accuracy: 0.8916\n","\n","Epoch 00332: val_accuracy did not improve from 0.93350\n","Epoch 333/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.4982 - val_accuracy: 0.9089\n","\n","Epoch 00333: val_accuracy did not improve from 0.93350\n","Epoch 334/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.5430 - val_accuracy: 0.9039\n","\n","Epoch 00334: val_accuracy did not improve from 0.93350\n","Epoch 335/500\n","52/52 [==============================] - 10s 191ms/step - loss: 9.2786e-04 - accuracy: 1.0000 - val_loss: 0.5733 - val_accuracy: 0.8941\n","\n","Epoch 00335: val_accuracy did not improve from 0.93350\n","Epoch 336/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5963 - val_accuracy: 0.9039\n","\n","Epoch 00336: val_accuracy did not improve from 0.93350\n","Epoch 337/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.5216 - val_accuracy: 0.9113\n","\n","Epoch 00337: val_accuracy did not improve from 0.93350\n","Epoch 338/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.5475 - val_accuracy: 0.8966\n","\n","Epoch 00338: val_accuracy did not improve from 0.93350\n","Epoch 339/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.6173 - val_accuracy: 0.8916\n","\n","Epoch 00339: val_accuracy did not improve from 0.93350\n","Epoch 340/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4144 - val_accuracy: 0.9113\n","\n","Epoch 00340: val_accuracy did not improve from 0.93350\n","Epoch 341/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5384 - val_accuracy: 0.8867\n","\n","Epoch 00341: val_accuracy did not improve from 0.93350\n","Epoch 342/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.6156 - val_accuracy: 0.8990\n","\n","Epoch 00342: val_accuracy did not improve from 0.93350\n","Epoch 343/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.6421 - val_accuracy: 0.8916\n","\n","Epoch 00343: val_accuracy did not improve from 0.93350\n","Epoch 344/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.7098 - val_accuracy: 0.8744\n","\n","Epoch 00344: val_accuracy did not improve from 0.93350\n","Epoch 345/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5911 - val_accuracy: 0.8892\n","\n","Epoch 00345: val_accuracy did not improve from 0.93350\n","Epoch 346/500\n","52/52 [==============================] - 10s 189ms/step - loss: 8.2969e-04 - accuracy: 1.0000 - val_loss: 0.5740 - val_accuracy: 0.8941\n","\n","Epoch 00346: val_accuracy did not improve from 0.93350\n","Epoch 347/500\n","52/52 [==============================] - 10s 190ms/step - loss: 7.2457e-04 - accuracy: 1.0000 - val_loss: 0.5211 - val_accuracy: 0.9236\n","\n","Epoch 00347: val_accuracy did not improve from 0.93350\n","Epoch 348/500\n","52/52 [==============================] - 10s 190ms/step - loss: 5.6972e-04 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.9187\n","\n","Epoch 00348: val_accuracy did not improve from 0.93350\n","Epoch 349/500\n","52/52 [==============================] - 10s 189ms/step - loss: 4.2004e-04 - accuracy: 1.0000 - val_loss: 0.5860 - val_accuracy: 0.9163\n","\n","Epoch 00349: val_accuracy did not improve from 0.93350\n","Epoch 350/500\n","52/52 [==============================] - 10s 189ms/step - loss: 3.5580e-04 - accuracy: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.9138\n","\n","Epoch 00350: val_accuracy did not improve from 0.93350\n","Epoch 351/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.5346 - val_accuracy: 0.9089\n","\n","Epoch 00351: val_accuracy did not improve from 0.93350\n","Epoch 352/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.7844 - val_accuracy: 0.8793\n","\n","Epoch 00352: val_accuracy did not improve from 0.93350\n","Epoch 353/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.7523 - val_accuracy: 0.8892\n","\n","Epoch 00353: val_accuracy did not improve from 0.93350\n","Epoch 354/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0354 - accuracy: 0.9896 - val_loss: 0.9534 - val_accuracy: 0.8670\n","\n","Epoch 00354: val_accuracy did not improve from 0.93350\n","Epoch 355/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0352 - accuracy: 0.9866 - val_loss: 0.8859 - val_accuracy: 0.8719\n","\n","Epoch 00355: val_accuracy did not improve from 0.93350\n","Epoch 356/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 0.6736 - val_accuracy: 0.8719\n","\n","Epoch 00356: val_accuracy did not improve from 0.93350\n","Epoch 357/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0499 - accuracy: 0.9866 - val_loss: 0.8241 - val_accuracy: 0.8719\n","\n","Epoch 00357: val_accuracy did not improve from 0.93350\n","Epoch 358/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0650 - accuracy: 0.9781 - val_loss: 19.9515 - val_accuracy: 0.2537\n","\n","Epoch 00358: val_accuracy did not improve from 0.93350\n","Epoch 359/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0442 - accuracy: 0.9842 - val_loss: 0.8058 - val_accuracy: 0.8744\n","\n","Epoch 00359: val_accuracy did not improve from 0.93350\n","Epoch 360/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.7164 - val_accuracy: 0.8892\n","\n","Epoch 00360: val_accuracy did not improve from 0.93350\n","Epoch 361/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.6921 - val_accuracy: 0.8768\n","\n","Epoch 00361: val_accuracy did not improve from 0.93350\n","Epoch 362/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.6420 - val_accuracy: 0.8966\n","\n","Epoch 00362: val_accuracy did not improve from 0.93350\n","Epoch 363/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5948 - val_accuracy: 0.8941\n","\n","Epoch 00363: val_accuracy did not improve from 0.93350\n","Epoch 364/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0414 - accuracy: 0.9933 - val_loss: 12.6052 - val_accuracy: 0.3571\n","\n","Epoch 00364: val_accuracy did not improve from 0.93350\n","Epoch 365/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0366 - accuracy: 0.9872 - val_loss: 0.6424 - val_accuracy: 0.8818\n","\n","Epoch 00365: val_accuracy did not improve from 0.93350\n","Epoch 366/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0152 - accuracy: 0.9945 - val_loss: 0.6437 - val_accuracy: 0.8744\n","\n","Epoch 00366: val_accuracy did not improve from 0.93350\n","Epoch 367/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0199 - accuracy: 0.9957 - val_loss: 10.0487 - val_accuracy: 0.4163\n","\n","Epoch 00367: val_accuracy did not improve from 0.93350\n","Epoch 368/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.9089\n","\n","Epoch 00368: val_accuracy did not improve from 0.93350\n","Epoch 369/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.9187\n","\n","Epoch 00369: val_accuracy did not improve from 0.93350\n","Epoch 370/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.4554 - val_accuracy: 0.9187\n","\n","Epoch 00370: val_accuracy did not improve from 0.93350\n","Epoch 371/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4389 - val_accuracy: 0.9064\n","\n","Epoch 00371: val_accuracy did not improve from 0.93350\n","Epoch 372/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4598 - val_accuracy: 0.9163\n","\n","Epoch 00372: val_accuracy did not improve from 0.93350\n","Epoch 373/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 1.0284 - val_accuracy: 0.8473\n","\n","Epoch 00373: val_accuracy did not improve from 0.93350\n","Epoch 374/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.5568 - val_accuracy: 0.8990\n","\n","Epoch 00374: val_accuracy did not improve from 0.93350\n","Epoch 375/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.5032 - val_accuracy: 0.8990\n","\n","Epoch 00375: val_accuracy did not improve from 0.93350\n","Epoch 376/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.6293 - val_accuracy: 0.8990\n","\n","Epoch 00376: val_accuracy did not improve from 0.93350\n","Epoch 377/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.6585 - val_accuracy: 0.8670\n","\n","Epoch 00377: val_accuracy did not improve from 0.93350\n","Epoch 378/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.6592 - val_accuracy: 0.8842\n","\n","Epoch 00378: val_accuracy did not improve from 0.93350\n","Epoch 379/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.6312 - val_accuracy: 0.8793\n","\n","Epoch 00379: val_accuracy did not improve from 0.93350\n","Epoch 380/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.8603 - val_accuracy: 0.8768\n","\n","Epoch 00380: val_accuracy did not improve from 0.93350\n","Epoch 381/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.7805 - val_accuracy: 0.8793\n","\n","Epoch 00381: val_accuracy did not improve from 0.93350\n","Epoch 382/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.7020 - val_accuracy: 0.8990\n","\n","Epoch 00382: val_accuracy did not improve from 0.93350\n","Epoch 383/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0157 - accuracy: 0.9933 - val_loss: 0.7168 - val_accuracy: 0.8695\n","\n","Epoch 00383: val_accuracy did not improve from 0.93350\n","Epoch 384/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0406 - accuracy: 0.9878 - val_loss: 0.9347 - val_accuracy: 0.8596\n","\n","Epoch 00384: val_accuracy did not improve from 0.93350\n","Epoch 385/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.6365 - val_accuracy: 0.8867\n","\n","Epoch 00385: val_accuracy did not improve from 0.93350\n","Epoch 386/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.5360 - val_accuracy: 0.9089\n","\n","Epoch 00386: val_accuracy did not improve from 0.93350\n","Epoch 387/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.6093 - val_accuracy: 0.8941\n","\n","Epoch 00387: val_accuracy did not improve from 0.93350\n","Epoch 388/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.9236\n","\n","Epoch 00388: val_accuracy did not improve from 0.93350\n","Epoch 389/500\n","52/52 [==============================] - 10s 191ms/step - loss: 3.7283e-04 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.9039\n","\n","Epoch 00389: val_accuracy did not improve from 0.93350\n","Epoch 390/500\n","52/52 [==============================] - 10s 190ms/step - loss: 4.5049e-04 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9212\n","\n","Epoch 00390: val_accuracy did not improve from 0.93350\n","Epoch 391/500\n","52/52 [==============================] - 10s 190ms/step - loss: 3.1735e-04 - accuracy: 1.0000 - val_loss: 0.5349 - val_accuracy: 0.8990\n","\n","Epoch 00391: val_accuracy did not improve from 0.93350\n","Epoch 392/500\n","52/52 [==============================] - 10s 190ms/step - loss: 6.8999e-04 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.9236\n","\n","Epoch 00392: val_accuracy did not improve from 0.93350\n","Epoch 393/500\n","52/52 [==============================] - 10s 190ms/step - loss: 8.8027e-04 - accuracy: 1.0000 - val_loss: 0.4819 - val_accuracy: 0.9212\n","\n","Epoch 00393: val_accuracy did not improve from 0.93350\n","Epoch 394/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5835 - val_accuracy: 0.9039\n","\n","Epoch 00394: val_accuracy did not improve from 0.93350\n","Epoch 395/500\n","52/52 [==============================] - 10s 190ms/step - loss: 5.1084e-04 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.9113\n","\n","Epoch 00395: val_accuracy did not improve from 0.93350\n","Epoch 396/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5214 - val_accuracy: 0.9187\n","\n","Epoch 00396: val_accuracy did not improve from 0.93350\n","Epoch 397/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0643 - accuracy: 0.9817 - val_loss: 1.8828 - val_accuracy: 0.7586\n","\n","Epoch 00397: val_accuracy did not improve from 0.93350\n","Epoch 398/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.1001 - accuracy: 0.9695 - val_loss: 2.2137 - val_accuracy: 0.7783\n","\n","Epoch 00398: val_accuracy did not improve from 0.93350\n","Epoch 399/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0374 - accuracy: 0.9872 - val_loss: 12.6875 - val_accuracy: 0.3793\n","\n","Epoch 00399: val_accuracy did not improve from 0.93350\n","Epoch 400/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0871 - accuracy: 0.9823 - val_loss: 1.2697 - val_accuracy: 0.7980\n","\n","Epoch 00400: val_accuracy did not improve from 0.93350\n","Epoch 401/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0606 - accuracy: 0.9787 - val_loss: 0.9293 - val_accuracy: 0.8596\n","\n","Epoch 00401: val_accuracy did not improve from 0.93350\n","Epoch 402/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.7200 - val_accuracy: 0.8892\n","\n","Epoch 00402: val_accuracy did not improve from 0.93350\n","Epoch 403/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.5343 - val_accuracy: 0.8867\n","\n","Epoch 00403: val_accuracy did not improve from 0.93350\n","Epoch 404/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4974 - val_accuracy: 0.8892\n","\n","Epoch 00404: val_accuracy did not improve from 0.93350\n","Epoch 405/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5910 - val_accuracy: 0.8867\n","\n","Epoch 00405: val_accuracy did not improve from 0.93350\n","Epoch 406/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5725 - val_accuracy: 0.8966\n","\n","Epoch 00406: val_accuracy did not improve from 0.93350\n","Epoch 407/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5990 - val_accuracy: 0.8892\n","\n","Epoch 00407: val_accuracy did not improve from 0.93350\n","Epoch 408/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.5640 - val_accuracy: 0.8941\n","\n","Epoch 00408: val_accuracy did not improve from 0.93350\n","Epoch 409/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.5565 - val_accuracy: 0.8966\n","\n","Epoch 00409: val_accuracy did not improve from 0.93350\n","Epoch 410/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.9064\n","\n","Epoch 00410: val_accuracy did not improve from 0.93350\n","Epoch 411/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4806 - val_accuracy: 0.9113\n","\n","Epoch 00411: val_accuracy did not improve from 0.93350\n","Epoch 412/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5548 - val_accuracy: 0.9015\n","\n","Epoch 00412: val_accuracy did not improve from 0.93350\n","Epoch 413/500\n","52/52 [==============================] - 10s 189ms/step - loss: 7.9421e-04 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.8990\n","\n","Epoch 00413: val_accuracy did not improve from 0.93350\n","Epoch 414/500\n","52/52 [==============================] - 10s 189ms/step - loss: 4.5068e-04 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.9187\n","\n","Epoch 00414: val_accuracy did not improve from 0.93350\n","Epoch 415/500\n","52/52 [==============================] - 10s 189ms/step - loss: 8.0709e-04 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.9187\n","\n","Epoch 00415: val_accuracy did not improve from 0.93350\n","Epoch 416/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.5940 - val_accuracy: 0.9015\n","\n","Epoch 00416: val_accuracy did not improve from 0.93350\n","Epoch 417/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 0.7842 - val_accuracy: 0.8645\n","\n","Epoch 00417: val_accuracy did not improve from 0.93350\n","Epoch 418/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.9217 - val_accuracy: 0.8547\n","\n","Epoch 00418: val_accuracy did not improve from 0.93350\n","Epoch 419/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.5833 - val_accuracy: 0.8892\n","\n","Epoch 00419: val_accuracy did not improve from 0.93350\n","Epoch 420/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.6958 - val_accuracy: 0.8744\n","\n","Epoch 00420: val_accuracy did not improve from 0.93350\n","Epoch 421/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.9301 - val_accuracy: 0.8670\n","\n","Epoch 00421: val_accuracy did not improve from 0.93350\n","Epoch 422/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.5640 - val_accuracy: 0.8966\n","\n","Epoch 00422: val_accuracy did not improve from 0.93350\n","Epoch 423/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.6420 - val_accuracy: 0.8867\n","\n","Epoch 00423: val_accuracy did not improve from 0.93350\n","Epoch 424/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5658 - val_accuracy: 0.9064\n","\n","Epoch 00424: val_accuracy did not improve from 0.93350\n","Epoch 425/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5162 - val_accuracy: 0.9015\n","\n","Epoch 00425: val_accuracy did not improve from 0.93350\n","Epoch 426/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0054 - accuracy: 0.9970 - val_loss: 0.5814 - val_accuracy: 0.8916\n","\n","Epoch 00426: val_accuracy did not improve from 0.93350\n","Epoch 427/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.5782 - val_accuracy: 0.9039\n","\n","Epoch 00427: val_accuracy did not improve from 0.93350\n","Epoch 428/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4568 - val_accuracy: 0.9163\n","\n","Epoch 00428: val_accuracy did not improve from 0.93350\n","Epoch 429/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.6033 - val_accuracy: 0.9064\n","\n","Epoch 00429: val_accuracy did not improve from 0.93350\n","Epoch 430/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.5901 - val_accuracy: 0.9064\n","\n","Epoch 00430: val_accuracy did not improve from 0.93350\n","Epoch 431/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.6489 - val_accuracy: 0.8867\n","\n","Epoch 00431: val_accuracy did not improve from 0.93350\n","Epoch 432/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.7679 - val_accuracy: 0.8867\n","\n","Epoch 00432: val_accuracy did not improve from 0.93350\n","Epoch 433/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.5516 - val_accuracy: 0.9015\n","\n","Epoch 00433: val_accuracy did not improve from 0.93350\n","Epoch 434/500\n","52/52 [==============================] - 10s 190ms/step - loss: 6.0024e-04 - accuracy: 1.0000 - val_loss: 0.5342 - val_accuracy: 0.9039\n","\n","Epoch 00434: val_accuracy did not improve from 0.93350\n","Epoch 435/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.6243 - val_accuracy: 0.8916\n","\n","Epoch 00435: val_accuracy did not improve from 0.93350\n","Epoch 436/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5232 - val_accuracy: 0.9089\n","\n","Epoch 00436: val_accuracy did not improve from 0.93350\n","Epoch 437/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5524 - val_accuracy: 0.9138\n","\n","Epoch 00437: val_accuracy did not improve from 0.93350\n","Epoch 438/500\n","52/52 [==============================] - 10s 191ms/step - loss: 6.6257e-04 - accuracy: 1.0000 - val_loss: 0.5496 - val_accuracy: 0.9064\n","\n","Epoch 00438: val_accuracy did not improve from 0.93350\n","Epoch 439/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5229 - val_accuracy: 0.8990\n","\n","Epoch 00439: val_accuracy did not improve from 0.93350\n","Epoch 440/500\n","52/52 [==============================] - 10s 190ms/step - loss: 4.1499e-04 - accuracy: 1.0000 - val_loss: 0.5124 - val_accuracy: 0.9261\n","\n","Epoch 00440: val_accuracy did not improve from 0.93350\n","Epoch 441/500\n","52/52 [==============================] - 10s 191ms/step - loss: 3.5330e-04 - accuracy: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.9138\n","\n","Epoch 00441: val_accuracy did not improve from 0.93350\n","Epoch 442/500\n","52/52 [==============================] - 10s 192ms/step - loss: 6.5795e-04 - accuracy: 1.0000 - val_loss: 0.5487 - val_accuracy: 0.9138\n","\n","Epoch 00442: val_accuracy did not improve from 0.93350\n","Epoch 443/500\n","52/52 [==============================] - 10s 191ms/step - loss: 1.6724e-04 - accuracy: 1.0000 - val_loss: 0.5437 - val_accuracy: 0.9138\n","\n","Epoch 00443: val_accuracy did not improve from 0.93350\n","Epoch 444/500\n","52/52 [==============================] - 10s 190ms/step - loss: 3.0237e-04 - accuracy: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.9187\n","\n","Epoch 00444: val_accuracy did not improve from 0.93350\n","Epoch 445/500\n","52/52 [==============================] - 10s 190ms/step - loss: 1.9354e-04 - accuracy: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.9064\n","\n","Epoch 00445: val_accuracy did not improve from 0.93350\n","Epoch 446/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5399 - val_accuracy: 0.9089\n","\n","Epoch 00446: val_accuracy did not improve from 0.93350\n","Epoch 447/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.8098 - val_accuracy: 0.8695\n","\n","Epoch 00447: val_accuracy did not improve from 0.93350\n","Epoch 448/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5462 - val_accuracy: 0.9089\n","\n","Epoch 00448: val_accuracy did not improve from 0.93350\n","Epoch 449/500\n","52/52 [==============================] - 10s 190ms/step - loss: 5.3529e-04 - accuracy: 1.0000 - val_loss: 0.5334 - val_accuracy: 0.9261\n","\n","Epoch 00449: val_accuracy did not improve from 0.93350\n","Epoch 450/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.7000 - val_accuracy: 0.8966\n","\n","Epoch 00450: val_accuracy did not improve from 0.93350\n","Epoch 451/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.9471 - val_accuracy: 0.8645\n","\n","Epoch 00451: val_accuracy did not improve from 0.93350\n","Epoch 452/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.7025 - val_accuracy: 0.8793\n","\n","Epoch 00452: val_accuracy did not improve from 0.93350\n","Epoch 453/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0306 - accuracy: 0.9909 - val_loss: 1.0142 - val_accuracy: 0.8793\n","\n","Epoch 00453: val_accuracy did not improve from 0.93350\n","Epoch 454/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0347 - accuracy: 0.9884 - val_loss: 0.8702 - val_accuracy: 0.8818\n","\n","Epoch 00454: val_accuracy did not improve from 0.93350\n","Epoch 455/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.1075 - accuracy: 0.9720 - val_loss: 1.5786 - val_accuracy: 0.7882\n","\n","Epoch 00455: val_accuracy did not improve from 0.93350\n","Epoch 456/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0931 - accuracy: 0.9732 - val_loss: 1.1158 - val_accuracy: 0.8350\n","\n","Epoch 00456: val_accuracy did not improve from 0.93350\n","Epoch 457/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0284 - accuracy: 0.9878 - val_loss: 0.5781 - val_accuracy: 0.8941\n","\n","Epoch 00457: val_accuracy did not improve from 0.93350\n","Epoch 458/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0238 - accuracy: 0.9945 - val_loss: 3.4881 - val_accuracy: 0.6626\n","\n","Epoch 00458: val_accuracy did not improve from 0.93350\n","Epoch 459/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.5353 - val_accuracy: 0.8966\n","\n","Epoch 00459: val_accuracy did not improve from 0.93350\n","Epoch 460/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.8941\n","\n","Epoch 00460: val_accuracy did not improve from 0.93350\n","Epoch 461/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5430 - val_accuracy: 0.9138\n","\n","Epoch 00461: val_accuracy did not improve from 0.93350\n","Epoch 462/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4981 - val_accuracy: 0.9064\n","\n","Epoch 00462: val_accuracy did not improve from 0.93350\n","Epoch 463/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.9015\n","\n","Epoch 00463: val_accuracy did not improve from 0.93350\n","Epoch 464/500\n","52/52 [==============================] - 10s 192ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5807 - val_accuracy: 0.8916\n","\n","Epoch 00464: val_accuracy did not improve from 0.93350\n","Epoch 465/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.5157 - val_accuracy: 0.9089\n","\n","Epoch 00465: val_accuracy did not improve from 0.93350\n","Epoch 466/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5174 - val_accuracy: 0.8990\n","\n","Epoch 00466: val_accuracy did not improve from 0.93350\n","Epoch 467/500\n","52/52 [==============================] - 10s 190ms/step - loss: 6.9550e-04 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.9163\n","\n","Epoch 00467: val_accuracy did not improve from 0.93350\n","Epoch 468/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5624 - val_accuracy: 0.8990\n","\n","Epoch 00468: val_accuracy did not improve from 0.93350\n","Epoch 469/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.5560 - val_accuracy: 0.8941\n","\n","Epoch 00469: val_accuracy did not improve from 0.93350\n","Epoch 470/500\n","52/52 [==============================] - 10s 191ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5209 - val_accuracy: 0.8941\n","\n","Epoch 00470: val_accuracy did not improve from 0.93350\n","Epoch 471/500\n","52/52 [==============================] - 10s 191ms/step - loss: 9.2318e-04 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.9015\n","\n","Epoch 00471: val_accuracy did not improve from 0.93350\n","Epoch 472/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.6969 - val_accuracy: 0.8867\n","\n","Epoch 00472: val_accuracy did not improve from 0.93350\n","Epoch 473/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.5067 - val_accuracy: 0.9064\n","\n","Epoch 00473: val_accuracy did not improve from 0.93350\n","Epoch 474/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.7018 - val_accuracy: 0.8744\n","\n","Epoch 00474: val_accuracy did not improve from 0.93350\n","Epoch 475/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.7341 - val_accuracy: 0.8842\n","\n","Epoch 00475: val_accuracy did not improve from 0.93350\n","Epoch 476/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.4899 - val_accuracy: 0.8966\n","\n","Epoch 00476: val_accuracy did not improve from 0.93350\n","Epoch 477/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5117 - val_accuracy: 0.9187\n","\n","Epoch 00477: val_accuracy did not improve from 0.93350\n","Epoch 478/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5122 - val_accuracy: 0.9163\n","\n","Epoch 00478: val_accuracy did not improve from 0.93350\n","Epoch 479/500\n","52/52 [==============================] - 10s 190ms/step - loss: 5.6464e-04 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.9089\n","\n","Epoch 00479: val_accuracy did not improve from 0.93350\n","Epoch 480/500\n","52/52 [==============================] - 10s 191ms/step - loss: 4.1084e-04 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9113\n","\n","Epoch 00480: val_accuracy did not improve from 0.93350\n","Epoch 481/500\n","52/52 [==============================] - 10s 189ms/step - loss: 4.2964e-04 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9064\n","\n","Epoch 00481: val_accuracy did not improve from 0.93350\n","Epoch 482/500\n","52/52 [==============================] - 10s 190ms/step - loss: 4.0452e-04 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9212\n","\n","Epoch 00482: val_accuracy did not improve from 0.93350\n","Epoch 483/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.5304 - val_accuracy: 0.9064\n","\n","Epoch 00483: val_accuracy did not improve from 0.93350\n","Epoch 484/500\n","52/52 [==============================] - 10s 190ms/step - loss: 7.7693e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9236\n","\n","Epoch 00484: val_accuracy did not improve from 0.93350\n","Epoch 485/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5558 - val_accuracy: 0.9039\n","\n","Epoch 00485: val_accuracy did not improve from 0.93350\n","Epoch 486/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.4978 - val_accuracy: 0.9187\n","\n","Epoch 00486: val_accuracy did not improve from 0.93350\n","Epoch 487/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.5528 - val_accuracy: 0.9064\n","\n","Epoch 00487: val_accuracy did not improve from 0.93350\n","Epoch 488/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.5545 - val_accuracy: 0.9113\n","\n","Epoch 00488: val_accuracy did not improve from 0.93350\n","Epoch 489/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.6874 - val_accuracy: 0.8867\n","\n","Epoch 00489: val_accuracy did not improve from 0.93350\n","Epoch 490/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 0.5641 - val_accuracy: 0.8842\n","\n","Epoch 00490: val_accuracy did not improve from 0.93350\n","Epoch 491/500\n","52/52 [==============================] - 10s 188ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.8053 - val_accuracy: 0.8621\n","\n","Epoch 00491: val_accuracy did not improve from 0.93350\n","Epoch 492/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.8144 - val_accuracy: 0.8744\n","\n","Epoch 00492: val_accuracy did not improve from 0.93350\n","Epoch 493/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.7098 - val_accuracy: 0.8793\n","\n","Epoch 00493: val_accuracy did not improve from 0.93350\n","Epoch 494/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.6098 - val_accuracy: 0.8941\n","\n","Epoch 00494: val_accuracy did not improve from 0.93350\n","Epoch 495/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.6514 - val_accuracy: 0.8867\n","\n","Epoch 00495: val_accuracy did not improve from 0.93350\n","Epoch 496/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.8158 - val_accuracy: 0.8793\n","\n","Epoch 00496: val_accuracy did not improve from 0.93350\n","Epoch 497/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0138 - accuracy: 0.9970 - val_loss: 1.1065 - val_accuracy: 0.8571\n","\n","Epoch 00497: val_accuracy did not improve from 0.93350\n","Epoch 498/500\n","52/52 [==============================] - 10s 190ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.7135 - val_accuracy: 0.8719\n","\n","Epoch 00498: val_accuracy did not improve from 0.93350\n","Epoch 499/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.9571 - val_accuracy: 0.8621\n","\n","Epoch 00499: val_accuracy did not improve from 0.93350\n","Epoch 500/500\n","52/52 [==============================] - 10s 189ms/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 0.7422 - val_accuracy: 0.8793\n","\n","Epoch 00500: val_accuracy did not improve from 0.93350\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f821b384c50>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"OfeQPdbJDI9h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628130919544,"user_tz":-540,"elapsed":8100389,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"5dbcc238-fe34-49e3-af5a-43052bc0ed65"},"source":["ResNet101V2_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[ResNet101V2_checkpoint])\n","# files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["52/52 [==============================] - 29s 342ms/step - loss: 2.4447 - accuracy: 0.1504 - val_loss: 94.9972 - val_accuracy: 0.0936\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09360, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/500\n","52/52 [==============================] - 16s 307ms/step - loss: 2.0183 - accuracy: 0.2473 - val_loss: 10.3339 - val_accuracy: 0.0985\n","\n","Epoch 00002: val_accuracy improved from 0.09360 to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 3/500\n","52/52 [==============================] - 16s 306ms/step - loss: 1.6137 - accuracy: 0.4086 - val_loss: 11.0606 - val_accuracy: 0.1010\n","\n","Epoch 00003: val_accuracy improved from 0.09852 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 4/500\n","52/52 [==============================] - 16s 305ms/step - loss: 1.2825 - accuracy: 0.5408 - val_loss: 7.6738 - val_accuracy: 0.1010\n","\n","Epoch 00004: val_accuracy did not improve from 0.10099\n","Epoch 5/500\n","52/52 [==============================] - 16s 302ms/step - loss: 1.0624 - accuracy: 0.6480 - val_loss: 4.9941 - val_accuracy: 0.1650\n","\n","Epoch 00005: val_accuracy improved from 0.10099 to 0.16502, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 6/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.9426 - accuracy: 0.6784 - val_loss: 5.1414 - val_accuracy: 0.2611\n","\n","Epoch 00006: val_accuracy improved from 0.16502 to 0.26108, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 7/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.8513 - accuracy: 0.7119 - val_loss: 3.4849 - val_accuracy: 0.3719\n","\n","Epoch 00007: val_accuracy improved from 0.26108 to 0.37192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 8/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.6926 - accuracy: 0.7655 - val_loss: 2.1415 - val_accuracy: 0.5468\n","\n","Epoch 00008: val_accuracy improved from 0.37192 to 0.54680, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 9/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.6753 - accuracy: 0.7741 - val_loss: 1.5087 - val_accuracy: 0.6305\n","\n","Epoch 00009: val_accuracy improved from 0.54680 to 0.63054, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 10/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.6279 - accuracy: 0.7942 - val_loss: 8.6691 - val_accuracy: 0.2488\n","\n","Epoch 00010: val_accuracy did not improve from 0.63054\n","Epoch 11/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.5698 - accuracy: 0.8094 - val_loss: 3.1090 - val_accuracy: 0.4483\n","\n","Epoch 00011: val_accuracy did not improve from 0.63054\n","Epoch 12/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.6055 - accuracy: 0.8051 - val_loss: 61.0885 - val_accuracy: 0.1158\n","\n","Epoch 00012: val_accuracy did not improve from 0.63054\n","Epoch 13/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.6025 - accuracy: 0.8094 - val_loss: 17.6555 - val_accuracy: 0.1330\n","\n","Epoch 00013: val_accuracy did not improve from 0.63054\n","Epoch 14/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.4673 - accuracy: 0.8423 - val_loss: 17.2691 - val_accuracy: 0.1108\n","\n","Epoch 00014: val_accuracy did not improve from 0.63054\n","Epoch 15/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.5006 - accuracy: 0.8350 - val_loss: 20.7485 - val_accuracy: 0.1133\n","\n","Epoch 00015: val_accuracy did not improve from 0.63054\n","Epoch 16/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.5645 - accuracy: 0.8136 - val_loss: 30.6353 - val_accuracy: 0.1059\n","\n","Epoch 00016: val_accuracy did not improve from 0.63054\n","Epoch 17/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.4118 - accuracy: 0.8484 - val_loss: 3.2488 - val_accuracy: 0.4729\n","\n","Epoch 00017: val_accuracy did not improve from 0.63054\n","Epoch 18/500\n","52/52 [==============================] - 16s 301ms/step - loss: 0.4161 - accuracy: 0.8605 - val_loss: 0.9594 - val_accuracy: 0.7562\n","\n","Epoch 00018: val_accuracy improved from 0.63054 to 0.75616, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 19/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.4187 - accuracy: 0.8563 - val_loss: 2.0859 - val_accuracy: 0.5813\n","\n","Epoch 00019: val_accuracy did not improve from 0.75616\n","Epoch 20/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.3787 - accuracy: 0.8745 - val_loss: 0.8401 - val_accuracy: 0.7931\n","\n","Epoch 00020: val_accuracy improved from 0.75616 to 0.79310, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 21/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.2955 - accuracy: 0.8934 - val_loss: 1.1304 - val_accuracy: 0.7315\n","\n","Epoch 00021: val_accuracy did not improve from 0.79310\n","Epoch 22/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.3175 - accuracy: 0.8904 - val_loss: 1.8826 - val_accuracy: 0.6478\n","\n","Epoch 00022: val_accuracy did not improve from 0.79310\n","Epoch 23/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.2982 - accuracy: 0.9032 - val_loss: 0.8553 - val_accuracy: 0.8005\n","\n","Epoch 00023: val_accuracy improved from 0.79310 to 0.80049, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 24/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.2787 - accuracy: 0.9050 - val_loss: 0.8440 - val_accuracy: 0.7586\n","\n","Epoch 00024: val_accuracy did not improve from 0.80049\n","Epoch 25/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.2714 - accuracy: 0.9007 - val_loss: 2.6437 - val_accuracy: 0.5246\n","\n","Epoch 00025: val_accuracy did not improve from 0.80049\n","Epoch 26/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.2499 - accuracy: 0.9178 - val_loss: 0.8211 - val_accuracy: 0.7833\n","\n","Epoch 00026: val_accuracy did not improve from 0.80049\n","Epoch 27/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.3089 - accuracy: 0.8873 - val_loss: 1.0026 - val_accuracy: 0.7192\n","\n","Epoch 00027: val_accuracy did not improve from 0.80049\n","Epoch 28/500\n","52/52 [==============================] - 16s 301ms/step - loss: 0.2893 - accuracy: 0.8977 - val_loss: 1.8502 - val_accuracy: 0.6970\n","\n","Epoch 00028: val_accuracy did not improve from 0.80049\n","Epoch 29/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.3829 - accuracy: 0.8764 - val_loss: 0.5485 - val_accuracy: 0.8276\n","\n","Epoch 00029: val_accuracy improved from 0.80049 to 0.82759, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 30/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.2876 - accuracy: 0.9019 - val_loss: 1.1185 - val_accuracy: 0.7660\n","\n","Epoch 00030: val_accuracy did not improve from 0.82759\n","Epoch 31/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.2579 - accuracy: 0.9153 - val_loss: 1.1136 - val_accuracy: 0.7365\n","\n","Epoch 00031: val_accuracy did not improve from 0.82759\n","Epoch 32/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.2553 - accuracy: 0.9117 - val_loss: 6.9644 - val_accuracy: 0.2980\n","\n","Epoch 00032: val_accuracy did not improve from 0.82759\n","Epoch 33/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.1982 - accuracy: 0.9294 - val_loss: 1.1640 - val_accuracy: 0.7389\n","\n","Epoch 00033: val_accuracy did not improve from 0.82759\n","Epoch 34/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1853 - accuracy: 0.9342 - val_loss: 0.8120 - val_accuracy: 0.7685\n","\n","Epoch 00034: val_accuracy did not improve from 0.82759\n","Epoch 35/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.3046 - accuracy: 0.8934 - val_loss: 4.1394 - val_accuracy: 0.4409\n","\n","Epoch 00035: val_accuracy did not improve from 0.82759\n","Epoch 36/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.2133 - accuracy: 0.9227 - val_loss: 0.9859 - val_accuracy: 0.7980\n","\n","Epoch 00036: val_accuracy did not improve from 0.82759\n","Epoch 37/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1822 - accuracy: 0.9367 - val_loss: 0.5680 - val_accuracy: 0.8374\n","\n","Epoch 00037: val_accuracy improved from 0.82759 to 0.83744, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 38/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.1694 - accuracy: 0.9385 - val_loss: 0.6685 - val_accuracy: 0.8399\n","\n","Epoch 00038: val_accuracy improved from 0.83744 to 0.83990, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 39/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.1315 - accuracy: 0.9610 - val_loss: 0.6458 - val_accuracy: 0.8424\n","\n","Epoch 00039: val_accuracy improved from 0.83990 to 0.84236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 40/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.1914 - accuracy: 0.9324 - val_loss: 0.5944 - val_accuracy: 0.8424\n","\n","Epoch 00040: val_accuracy did not improve from 0.84236\n","Epoch 41/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.1751 - accuracy: 0.9397 - val_loss: 0.4333 - val_accuracy: 0.8695\n","\n","Epoch 00041: val_accuracy improved from 0.84236 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 42/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1974 - accuracy: 0.9294 - val_loss: 13.2399 - val_accuracy: 0.1897\n","\n","Epoch 00042: val_accuracy did not improve from 0.86946\n","Epoch 43/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1501 - accuracy: 0.9482 - val_loss: 3.0463 - val_accuracy: 0.5123\n","\n","Epoch 00043: val_accuracy did not improve from 0.86946\n","Epoch 44/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.1387 - accuracy: 0.9488 - val_loss: 0.5394 - val_accuracy: 0.8448\n","\n","Epoch 00044: val_accuracy did not improve from 0.86946\n","Epoch 45/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1665 - accuracy: 0.9488 - val_loss: 0.7171 - val_accuracy: 0.8276\n","\n","Epoch 00045: val_accuracy did not improve from 0.86946\n","Epoch 46/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.2249 - accuracy: 0.9220 - val_loss: 5.3088 - val_accuracy: 0.4310\n","\n","Epoch 00046: val_accuracy did not improve from 0.86946\n","Epoch 47/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1680 - accuracy: 0.9379 - val_loss: 14.9326 - val_accuracy: 0.1970\n","\n","Epoch 00047: val_accuracy did not improve from 0.86946\n","Epoch 48/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1664 - accuracy: 0.9385 - val_loss: 0.9883 - val_accuracy: 0.8030\n","\n","Epoch 00048: val_accuracy did not improve from 0.86946\n","Epoch 49/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.2139 - accuracy: 0.9269 - val_loss: 1.1100 - val_accuracy: 0.7586\n","\n","Epoch 00049: val_accuracy did not improve from 0.86946\n","Epoch 50/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.1628 - accuracy: 0.9488 - val_loss: 0.5986 - val_accuracy: 0.8350\n","\n","Epoch 00050: val_accuracy did not improve from 0.86946\n","Epoch 51/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1221 - accuracy: 0.9568 - val_loss: 1.1635 - val_accuracy: 0.7660\n","\n","Epoch 00051: val_accuracy did not improve from 0.86946\n","Epoch 52/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1428 - accuracy: 0.9513 - val_loss: 0.5815 - val_accuracy: 0.8645\n","\n","Epoch 00052: val_accuracy did not improve from 0.86946\n","Epoch 53/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1127 - accuracy: 0.9610 - val_loss: 0.5525 - val_accuracy: 0.8424\n","\n","Epoch 00053: val_accuracy did not improve from 0.86946\n","Epoch 54/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0996 - accuracy: 0.9653 - val_loss: 0.5889 - val_accuracy: 0.8621\n","\n","Epoch 00054: val_accuracy did not improve from 0.86946\n","Epoch 55/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.1324 - accuracy: 0.9525 - val_loss: 0.7535 - val_accuracy: 0.8054\n","\n","Epoch 00055: val_accuracy did not improve from 0.86946\n","Epoch 56/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0972 - accuracy: 0.9702 - val_loss: 0.7159 - val_accuracy: 0.8547\n","\n","Epoch 00056: val_accuracy did not improve from 0.86946\n","Epoch 57/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1304 - accuracy: 0.9555 - val_loss: 1.4311 - val_accuracy: 0.7315\n","\n","Epoch 00057: val_accuracy did not improve from 0.86946\n","Epoch 58/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1663 - accuracy: 0.9428 - val_loss: 2.0519 - val_accuracy: 0.6872\n","\n","Epoch 00058: val_accuracy did not improve from 0.86946\n","Epoch 59/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.1770 - accuracy: 0.9434 - val_loss: 0.6768 - val_accuracy: 0.8522\n","\n","Epoch 00059: val_accuracy did not improve from 0.86946\n","Epoch 60/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1872 - accuracy: 0.9361 - val_loss: 0.8574 - val_accuracy: 0.7906\n","\n","Epoch 00060: val_accuracy did not improve from 0.86946\n","Epoch 61/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1163 - accuracy: 0.9616 - val_loss: 0.8650 - val_accuracy: 0.8005\n","\n","Epoch 00061: val_accuracy did not improve from 0.86946\n","Epoch 62/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.1253 - accuracy: 0.9562 - val_loss: 1.1478 - val_accuracy: 0.7833\n","\n","Epoch 00062: val_accuracy did not improve from 0.86946\n","Epoch 63/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1708 - accuracy: 0.9397 - val_loss: 1.1535 - val_accuracy: 0.7882\n","\n","Epoch 00063: val_accuracy did not improve from 0.86946\n","Epoch 64/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1633 - accuracy: 0.9434 - val_loss: 0.8580 - val_accuracy: 0.8300\n","\n","Epoch 00064: val_accuracy did not improve from 0.86946\n","Epoch 65/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0993 - accuracy: 0.9653 - val_loss: 0.5176 - val_accuracy: 0.8596\n","\n","Epoch 00065: val_accuracy did not improve from 0.86946\n","Epoch 66/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1289 - accuracy: 0.9555 - val_loss: 0.6832 - val_accuracy: 0.8276\n","\n","Epoch 00066: val_accuracy did not improve from 0.86946\n","Epoch 67/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1317 - accuracy: 0.9525 - val_loss: 14.4005 - val_accuracy: 0.2537\n","\n","Epoch 00067: val_accuracy did not improve from 0.86946\n","Epoch 68/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1038 - accuracy: 0.9677 - val_loss: 7.2879 - val_accuracy: 0.3892\n","\n","Epoch 00068: val_accuracy did not improve from 0.86946\n","Epoch 69/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.1131 - accuracy: 0.9604 - val_loss: 0.6435 - val_accuracy: 0.8498\n","\n","Epoch 00069: val_accuracy did not improve from 0.86946\n","Epoch 70/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.1099 - accuracy: 0.9592 - val_loss: 0.7420 - val_accuracy: 0.8325\n","\n","Epoch 00070: val_accuracy did not improve from 0.86946\n","Epoch 71/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0895 - accuracy: 0.9683 - val_loss: 0.5087 - val_accuracy: 0.8842\n","\n","Epoch 00071: val_accuracy improved from 0.86946 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 72/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0773 - accuracy: 0.9720 - val_loss: 0.7515 - val_accuracy: 0.8522\n","\n","Epoch 00072: val_accuracy did not improve from 0.88424\n","Epoch 73/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0852 - accuracy: 0.9708 - val_loss: 7.3038 - val_accuracy: 0.4113\n","\n","Epoch 00073: val_accuracy did not improve from 0.88424\n","Epoch 74/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0945 - accuracy: 0.9695 - val_loss: 1.8166 - val_accuracy: 0.6626\n","\n","Epoch 00074: val_accuracy did not improve from 0.88424\n","Epoch 75/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0653 - accuracy: 0.9799 - val_loss: 0.6341 - val_accuracy: 0.8596\n","\n","Epoch 00075: val_accuracy did not improve from 0.88424\n","Epoch 76/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.1064 - accuracy: 0.9653 - val_loss: 0.7306 - val_accuracy: 0.8325\n","\n","Epoch 00076: val_accuracy did not improve from 0.88424\n","Epoch 77/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0900 - accuracy: 0.9708 - val_loss: 0.6272 - val_accuracy: 0.8424\n","\n","Epoch 00077: val_accuracy did not improve from 0.88424\n","Epoch 78/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0679 - accuracy: 0.9775 - val_loss: 5.5672 - val_accuracy: 0.4557\n","\n","Epoch 00078: val_accuracy did not improve from 0.88424\n","Epoch 79/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0954 - accuracy: 0.9659 - val_loss: 1.0035 - val_accuracy: 0.8128\n","\n","Epoch 00079: val_accuracy did not improve from 0.88424\n","Epoch 80/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0787 - accuracy: 0.9738 - val_loss: 1.2543 - val_accuracy: 0.8177\n","\n","Epoch 00080: val_accuracy did not improve from 0.88424\n","Epoch 81/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0649 - accuracy: 0.9775 - val_loss: 0.8015 - val_accuracy: 0.8522\n","\n","Epoch 00081: val_accuracy did not improve from 0.88424\n","Epoch 82/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1005 - accuracy: 0.9665 - val_loss: 1.3410 - val_accuracy: 0.7833\n","\n","Epoch 00082: val_accuracy did not improve from 0.88424\n","Epoch 83/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1323 - accuracy: 0.9574 - val_loss: 1.0828 - val_accuracy: 0.8103\n","\n","Epoch 00083: val_accuracy did not improve from 0.88424\n","Epoch 84/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0945 - accuracy: 0.9665 - val_loss: 8.8748 - val_accuracy: 0.2931\n","\n","Epoch 00084: val_accuracy did not improve from 0.88424\n","Epoch 85/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1183 - accuracy: 0.9610 - val_loss: 19.7501 - val_accuracy: 0.1478\n","\n","Epoch 00085: val_accuracy did not improve from 0.88424\n","Epoch 86/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.1291 - accuracy: 0.9543 - val_loss: 0.9127 - val_accuracy: 0.8350\n","\n","Epoch 00086: val_accuracy did not improve from 0.88424\n","Epoch 87/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0890 - accuracy: 0.9677 - val_loss: 1.3622 - val_accuracy: 0.7463\n","\n","Epoch 00087: val_accuracy did not improve from 0.88424\n","Epoch 88/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1138 - accuracy: 0.9592 - val_loss: 0.7560 - val_accuracy: 0.8522\n","\n","Epoch 00088: val_accuracy did not improve from 0.88424\n","Epoch 89/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1255 - accuracy: 0.9574 - val_loss: 0.6312 - val_accuracy: 0.8768\n","\n","Epoch 00089: val_accuracy did not improve from 0.88424\n","Epoch 90/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1073 - accuracy: 0.9610 - val_loss: 0.9226 - val_accuracy: 0.8177\n","\n","Epoch 00090: val_accuracy did not improve from 0.88424\n","Epoch 91/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1350 - accuracy: 0.9537 - val_loss: 8.6529 - val_accuracy: 0.3424\n","\n","Epoch 00091: val_accuracy did not improve from 0.88424\n","Epoch 92/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0940 - accuracy: 0.9671 - val_loss: 2.2549 - val_accuracy: 0.6970\n","\n","Epoch 00092: val_accuracy did not improve from 0.88424\n","Epoch 93/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0565 - accuracy: 0.9823 - val_loss: 0.5519 - val_accuracy: 0.8818\n","\n","Epoch 00093: val_accuracy did not improve from 0.88424\n","Epoch 94/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0524 - accuracy: 0.9823 - val_loss: 0.4517 - val_accuracy: 0.9138\n","\n","Epoch 00094: val_accuracy improved from 0.88424 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 95/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0312 - accuracy: 0.9890 - val_loss: 0.4560 - val_accuracy: 0.8818\n","\n","Epoch 00095: val_accuracy did not improve from 0.91379\n","Epoch 96/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0676 - accuracy: 0.9769 - val_loss: 0.8799 - val_accuracy: 0.8325\n","\n","Epoch 00096: val_accuracy did not improve from 0.91379\n","Epoch 97/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0527 - accuracy: 0.9793 - val_loss: 0.6115 - val_accuracy: 0.8621\n","\n","Epoch 00097: val_accuracy did not improve from 0.91379\n","Epoch 98/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0519 - accuracy: 0.9823 - val_loss: 0.7226 - val_accuracy: 0.8374\n","\n","Epoch 00098: val_accuracy did not improve from 0.91379\n","Epoch 99/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0649 - accuracy: 0.9750 - val_loss: 4.6714 - val_accuracy: 0.5123\n","\n","Epoch 00099: val_accuracy did not improve from 0.91379\n","Epoch 100/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1234 - accuracy: 0.9592 - val_loss: 9.9277 - val_accuracy: 0.3177\n","\n","Epoch 00100: val_accuracy did not improve from 0.91379\n","Epoch 101/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0980 - accuracy: 0.9653 - val_loss: 14.5673 - val_accuracy: 0.2537\n","\n","Epoch 00101: val_accuracy did not improve from 0.91379\n","Epoch 102/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0544 - accuracy: 0.9811 - val_loss: 13.3271 - val_accuracy: 0.2512\n","\n","Epoch 00102: val_accuracy did not improve from 0.91379\n","Epoch 103/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0916 - accuracy: 0.9738 - val_loss: 0.5730 - val_accuracy: 0.8818\n","\n","Epoch 00103: val_accuracy did not improve from 0.91379\n","Epoch 104/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0721 - accuracy: 0.9769 - val_loss: 0.6109 - val_accuracy: 0.8768\n","\n","Epoch 00104: val_accuracy did not improve from 0.91379\n","Epoch 105/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0712 - accuracy: 0.9762 - val_loss: 0.9491 - val_accuracy: 0.8227\n","\n","Epoch 00105: val_accuracy did not improve from 0.91379\n","Epoch 106/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0735 - accuracy: 0.9756 - val_loss: 0.9469 - val_accuracy: 0.8399\n","\n","Epoch 00106: val_accuracy did not improve from 0.91379\n","Epoch 107/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0463 - accuracy: 0.9854 - val_loss: 0.5753 - val_accuracy: 0.8818\n","\n","Epoch 00107: val_accuracy did not improve from 0.91379\n","Epoch 108/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0803 - accuracy: 0.9702 - val_loss: 3.5688 - val_accuracy: 0.6108\n","\n","Epoch 00108: val_accuracy did not improve from 0.91379\n","Epoch 109/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.1669 - accuracy: 0.9428 - val_loss: 1.2668 - val_accuracy: 0.7709\n","\n","Epoch 00109: val_accuracy did not improve from 0.91379\n","Epoch 110/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0953 - accuracy: 0.9641 - val_loss: 0.6515 - val_accuracy: 0.8744\n","\n","Epoch 00110: val_accuracy did not improve from 0.91379\n","Epoch 111/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0450 - accuracy: 0.9854 - val_loss: 0.5716 - val_accuracy: 0.8793\n","\n","Epoch 00111: val_accuracy did not improve from 0.91379\n","Epoch 112/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0347 - accuracy: 0.9896 - val_loss: 5.2013 - val_accuracy: 0.5099\n","\n","Epoch 00112: val_accuracy did not improve from 0.91379\n","Epoch 113/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0573 - accuracy: 0.9799 - val_loss: 1.3263 - val_accuracy: 0.7980\n","\n","Epoch 00113: val_accuracy did not improve from 0.91379\n","Epoch 114/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0439 - accuracy: 0.9860 - val_loss: 0.6339 - val_accuracy: 0.8645\n","\n","Epoch 00114: val_accuracy did not improve from 0.91379\n","Epoch 115/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 0.6470 - val_accuracy: 0.8768\n","\n","Epoch 00115: val_accuracy did not improve from 0.91379\n","Epoch 116/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0445 - accuracy: 0.9854 - val_loss: 0.7412 - val_accuracy: 0.8621\n","\n","Epoch 00116: val_accuracy did not improve from 0.91379\n","Epoch 117/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0422 - accuracy: 0.9854 - val_loss: 0.7677 - val_accuracy: 0.8670\n","\n","Epoch 00117: val_accuracy did not improve from 0.91379\n","Epoch 118/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 0.5729 - val_accuracy: 0.8842\n","\n","Epoch 00118: val_accuracy did not improve from 0.91379\n","Epoch 119/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0295 - accuracy: 0.9884 - val_loss: 0.7586 - val_accuracy: 0.8571\n","\n","Epoch 00119: val_accuracy did not improve from 0.91379\n","Epoch 120/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0431 - accuracy: 0.9848 - val_loss: 0.9608 - val_accuracy: 0.8498\n","\n","Epoch 00120: val_accuracy did not improve from 0.91379\n","Epoch 121/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0344 - accuracy: 0.9909 - val_loss: 0.6471 - val_accuracy: 0.8621\n","\n","Epoch 00121: val_accuracy did not improve from 0.91379\n","Epoch 122/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0633 - accuracy: 0.9787 - val_loss: 0.7025 - val_accuracy: 0.8374\n","\n","Epoch 00122: val_accuracy did not improve from 0.91379\n","Epoch 123/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0762 - accuracy: 0.9726 - val_loss: 0.8529 - val_accuracy: 0.8473\n","\n","Epoch 00123: val_accuracy did not improve from 0.91379\n","Epoch 124/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0372 - accuracy: 0.9878 - val_loss: 0.6974 - val_accuracy: 0.8768\n","\n","Epoch 00124: val_accuracy did not improve from 0.91379\n","Epoch 125/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0409 - accuracy: 0.9842 - val_loss: 0.6929 - val_accuracy: 0.8670\n","\n","Epoch 00125: val_accuracy did not improve from 0.91379\n","Epoch 126/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0382 - accuracy: 0.9872 - val_loss: 0.6455 - val_accuracy: 0.8768\n","\n","Epoch 00126: val_accuracy did not improve from 0.91379\n","Epoch 127/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.7730 - val_accuracy: 0.8670\n","\n","Epoch 00127: val_accuracy did not improve from 0.91379\n","Epoch 128/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0449 - accuracy: 0.9842 - val_loss: 0.6421 - val_accuracy: 0.8744\n","\n","Epoch 00128: val_accuracy did not improve from 0.91379\n","Epoch 129/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0216 - accuracy: 0.9945 - val_loss: 0.6718 - val_accuracy: 0.8744\n","\n","Epoch 00129: val_accuracy did not improve from 0.91379\n","Epoch 130/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0306 - accuracy: 0.9878 - val_loss: 0.7398 - val_accuracy: 0.8621\n","\n","Epoch 00130: val_accuracy did not improve from 0.91379\n","Epoch 131/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0419 - accuracy: 0.9866 - val_loss: 0.8145 - val_accuracy: 0.8300\n","\n","Epoch 00131: val_accuracy did not improve from 0.91379\n","Epoch 132/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 0.7464 - val_accuracy: 0.8768\n","\n","Epoch 00132: val_accuracy did not improve from 0.91379\n","Epoch 133/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.6394 - val_accuracy: 0.8793\n","\n","Epoch 00133: val_accuracy did not improve from 0.91379\n","Epoch 134/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0425 - accuracy: 0.9848 - val_loss: 3.3222 - val_accuracy: 0.6281\n","\n","Epoch 00134: val_accuracy did not improve from 0.91379\n","Epoch 135/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0398 - accuracy: 0.9903 - val_loss: 13.3912 - val_accuracy: 0.3522\n","\n","Epoch 00135: val_accuracy did not improve from 0.91379\n","Epoch 136/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0357 - accuracy: 0.9866 - val_loss: 0.5858 - val_accuracy: 0.8744\n","\n","Epoch 00136: val_accuracy did not improve from 0.91379\n","Epoch 137/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 0.8191 - val_accuracy: 0.8498\n","\n","Epoch 00137: val_accuracy did not improve from 0.91379\n","Epoch 138/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0334 - accuracy: 0.9915 - val_loss: 0.9682 - val_accuracy: 0.8596\n","\n","Epoch 00138: val_accuracy did not improve from 0.91379\n","Epoch 139/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1263 - accuracy: 0.9574 - val_loss: 1.4263 - val_accuracy: 0.7931\n","\n","Epoch 00139: val_accuracy did not improve from 0.91379\n","Epoch 140/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1555 - accuracy: 0.9543 - val_loss: 1.7749 - val_accuracy: 0.7315\n","\n","Epoch 00140: val_accuracy did not improve from 0.91379\n","Epoch 141/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0596 - accuracy: 0.9799 - val_loss: 0.8327 - val_accuracy: 0.8719\n","\n","Epoch 00141: val_accuracy did not improve from 0.91379\n","Epoch 142/500\n","52/52 [==============================] - 16s 301ms/step - loss: 0.0836 - accuracy: 0.9750 - val_loss: 1.1401 - val_accuracy: 0.8448\n","\n","Epoch 00142: val_accuracy did not improve from 0.91379\n","Epoch 143/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0560 - accuracy: 0.9769 - val_loss: 0.5803 - val_accuracy: 0.8793\n","\n","Epoch 00143: val_accuracy did not improve from 0.91379\n","Epoch 144/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0502 - accuracy: 0.9842 - val_loss: 0.6754 - val_accuracy: 0.8670\n","\n","Epoch 00144: val_accuracy did not improve from 0.91379\n","Epoch 145/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0362 - accuracy: 0.9866 - val_loss: 0.5617 - val_accuracy: 0.8966\n","\n","Epoch 00145: val_accuracy did not improve from 0.91379\n","Epoch 146/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0411 - accuracy: 0.9842 - val_loss: 16.4016 - val_accuracy: 0.2192\n","\n","Epoch 00146: val_accuracy did not improve from 0.91379\n","Epoch 147/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0464 - accuracy: 0.9829 - val_loss: 1.0314 - val_accuracy: 0.8227\n","\n","Epoch 00147: val_accuracy did not improve from 0.91379\n","Epoch 148/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.7638 - val_accuracy: 0.8424\n","\n","Epoch 00148: val_accuracy did not improve from 0.91379\n","Epoch 149/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0211 - accuracy: 0.9951 - val_loss: 0.7398 - val_accuracy: 0.8842\n","\n","Epoch 00149: val_accuracy did not improve from 0.91379\n","Epoch 150/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0282 - accuracy: 0.9909 - val_loss: 0.6768 - val_accuracy: 0.8842\n","\n","Epoch 00150: val_accuracy did not improve from 0.91379\n","Epoch 151/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.6492 - val_accuracy: 0.8744\n","\n","Epoch 00151: val_accuracy did not improve from 0.91379\n","Epoch 152/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0264 - accuracy: 0.9884 - val_loss: 0.7701 - val_accuracy: 0.8645\n","\n","Epoch 00152: val_accuracy did not improve from 0.91379\n","Epoch 153/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0535 - accuracy: 0.9793 - val_loss: 0.8633 - val_accuracy: 0.8670\n","\n","Epoch 00153: val_accuracy did not improve from 0.91379\n","Epoch 154/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0851 - accuracy: 0.9744 - val_loss: 0.7925 - val_accuracy: 0.8571\n","\n","Epoch 00154: val_accuracy did not improve from 0.91379\n","Epoch 155/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0942 - accuracy: 0.9775 - val_loss: 31.4947 - val_accuracy: 0.1207\n","\n","Epoch 00155: val_accuracy did not improve from 0.91379\n","Epoch 156/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.1143 - accuracy: 0.9702 - val_loss: 1.9285 - val_accuracy: 0.7365\n","\n","Epoch 00156: val_accuracy did not improve from 0.91379\n","Epoch 157/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0476 - accuracy: 0.9836 - val_loss: 0.6892 - val_accuracy: 0.8892\n","\n","Epoch 00157: val_accuracy did not improve from 0.91379\n","Epoch 158/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0374 - accuracy: 0.9842 - val_loss: 0.8790 - val_accuracy: 0.8645\n","\n","Epoch 00158: val_accuracy did not improve from 0.91379\n","Epoch 159/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 0.5843 - val_accuracy: 0.8768\n","\n","Epoch 00159: val_accuracy did not improve from 0.91379\n","Epoch 160/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0209 - accuracy: 0.9909 - val_loss: 0.6907 - val_accuracy: 0.8695\n","\n","Epoch 00160: val_accuracy did not improve from 0.91379\n","Epoch 161/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0292 - accuracy: 0.9933 - val_loss: 0.6502 - val_accuracy: 0.8719\n","\n","Epoch 00161: val_accuracy did not improve from 0.91379\n","Epoch 162/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 0.5512 - val_accuracy: 0.8916\n","\n","Epoch 00162: val_accuracy did not improve from 0.91379\n","Epoch 163/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.5063 - val_accuracy: 0.8818\n","\n","Epoch 00163: val_accuracy did not improve from 0.91379\n","Epoch 164/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.4856 - val_accuracy: 0.8867\n","\n","Epoch 00164: val_accuracy did not improve from 0.91379\n","Epoch 165/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5650 - val_accuracy: 0.8916\n","\n","Epoch 00165: val_accuracy did not improve from 0.91379\n","Epoch 166/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.4130 - val_accuracy: 0.9039\n","\n","Epoch 00166: val_accuracy did not improve from 0.91379\n","Epoch 167/500\n","52/52 [==============================] - 16s 301ms/step - loss: 0.0355 - accuracy: 0.9878 - val_loss: 0.8721 - val_accuracy: 0.8522\n","\n","Epoch 00167: val_accuracy did not improve from 0.91379\n","Epoch 168/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.7362 - val_accuracy: 0.8621\n","\n","Epoch 00168: val_accuracy did not improve from 0.91379\n","Epoch 169/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.7627 - val_accuracy: 0.8571\n","\n","Epoch 00169: val_accuracy did not improve from 0.91379\n","Epoch 170/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.2017 - accuracy: 0.9501 - val_loss: 31.9597 - val_accuracy: 0.1823\n","\n","Epoch 00170: val_accuracy did not improve from 0.91379\n","Epoch 171/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1628 - accuracy: 0.9440 - val_loss: 2.6413 - val_accuracy: 0.7020\n","\n","Epoch 00171: val_accuracy did not improve from 0.91379\n","Epoch 172/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0691 - accuracy: 0.9781 - val_loss: 1.4404 - val_accuracy: 0.7833\n","\n","Epoch 00172: val_accuracy did not improve from 0.91379\n","Epoch 173/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0482 - accuracy: 0.9799 - val_loss: 0.7206 - val_accuracy: 0.8621\n","\n","Epoch 00173: val_accuracy did not improve from 0.91379\n","Epoch 174/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0299 - accuracy: 0.9890 - val_loss: 0.6370 - val_accuracy: 0.8596\n","\n","Epoch 00174: val_accuracy did not improve from 0.91379\n","Epoch 175/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.3673 - val_accuracy: 0.9187\n","\n","Epoch 00175: val_accuracy improved from 0.91379 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 176/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.4456 - val_accuracy: 0.9187\n","\n","Epoch 00176: val_accuracy did not improve from 0.91872\n","Epoch 177/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0295 - accuracy: 0.9927 - val_loss: 0.6154 - val_accuracy: 0.8596\n","\n","Epoch 00177: val_accuracy did not improve from 0.91872\n","Epoch 178/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0493 - accuracy: 0.9829 - val_loss: 9.6928 - val_accuracy: 0.3448\n","\n","Epoch 00178: val_accuracy did not improve from 0.91872\n","Epoch 179/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.6441 - val_accuracy: 0.8818\n","\n","Epoch 00179: val_accuracy did not improve from 0.91872\n","Epoch 180/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.5961 - val_accuracy: 0.8842\n","\n","Epoch 00180: val_accuracy did not improve from 0.91872\n","Epoch 181/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.8522 - val_accuracy: 0.8300\n","\n","Epoch 00181: val_accuracy did not improve from 0.91872\n","Epoch 182/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0206 - accuracy: 0.9921 - val_loss: 0.7561 - val_accuracy: 0.8719\n","\n","Epoch 00182: val_accuracy did not improve from 0.91872\n","Epoch 183/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.7857 - val_accuracy: 0.8842\n","\n","Epoch 00183: val_accuracy did not improve from 0.91872\n","Epoch 184/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1814 - accuracy: 0.9434 - val_loss: 1.6441 - val_accuracy: 0.7931\n","\n","Epoch 00184: val_accuracy did not improve from 0.91872\n","Epoch 185/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0558 - accuracy: 0.9787 - val_loss: 0.5802 - val_accuracy: 0.8744\n","\n","Epoch 00185: val_accuracy did not improve from 0.91872\n","Epoch 186/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0537 - accuracy: 0.9836 - val_loss: 0.5902 - val_accuracy: 0.8621\n","\n","Epoch 00186: val_accuracy did not improve from 0.91872\n","Epoch 187/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0358 - accuracy: 0.9872 - val_loss: 0.5640 - val_accuracy: 0.8744\n","\n","Epoch 00187: val_accuracy did not improve from 0.91872\n","Epoch 188/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0329 - accuracy: 0.9909 - val_loss: 0.4906 - val_accuracy: 0.9015\n","\n","Epoch 00188: val_accuracy did not improve from 0.91872\n","Epoch 189/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0243 - accuracy: 0.9939 - val_loss: 0.6826 - val_accuracy: 0.8744\n","\n","Epoch 00189: val_accuracy did not improve from 0.91872\n","Epoch 190/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0459 - accuracy: 0.9872 - val_loss: 0.5790 - val_accuracy: 0.8793\n","\n","Epoch 00190: val_accuracy did not improve from 0.91872\n","Epoch 191/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0476 - accuracy: 0.9848 - val_loss: 1.4083 - val_accuracy: 0.7611\n","\n","Epoch 00191: val_accuracy did not improve from 0.91872\n","Epoch 192/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.6726 - val_accuracy: 0.8867\n","\n","Epoch 00192: val_accuracy did not improve from 0.91872\n","Epoch 193/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.5293 - val_accuracy: 0.8818\n","\n","Epoch 00193: val_accuracy did not improve from 0.91872\n","Epoch 194/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.5613 - val_accuracy: 0.8966\n","\n","Epoch 00194: val_accuracy did not improve from 0.91872\n","Epoch 195/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.5423 - val_accuracy: 0.8941\n","\n","Epoch 00195: val_accuracy did not improve from 0.91872\n","Epoch 196/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0508 - accuracy: 0.9866 - val_loss: 16.1571 - val_accuracy: 0.3054\n","\n","Epoch 00196: val_accuracy did not improve from 0.91872\n","Epoch 197/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0291 - accuracy: 0.9890 - val_loss: 0.6546 - val_accuracy: 0.8941\n","\n","Epoch 00197: val_accuracy did not improve from 0.91872\n","Epoch 198/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.7288 - val_accuracy: 0.8645\n","\n","Epoch 00198: val_accuracy did not improve from 0.91872\n","Epoch 199/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.5535 - val_accuracy: 0.8941\n","\n","Epoch 00199: val_accuracy did not improve from 0.91872\n","Epoch 200/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0152 - accuracy: 0.9939 - val_loss: 0.5077 - val_accuracy: 0.9113\n","\n","Epoch 00200: val_accuracy did not improve from 0.91872\n","Epoch 201/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0470 - accuracy: 0.9854 - val_loss: 0.6273 - val_accuracy: 0.8744\n","\n","Epoch 00201: val_accuracy did not improve from 0.91872\n","Epoch 202/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0537 - accuracy: 0.9848 - val_loss: 1.0147 - val_accuracy: 0.8448\n","\n","Epoch 00202: val_accuracy did not improve from 0.91872\n","Epoch 203/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0339 - accuracy: 0.9884 - val_loss: 4.2895 - val_accuracy: 0.5887\n","\n","Epoch 00203: val_accuracy did not improve from 0.91872\n","Epoch 204/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 9.4084 - val_accuracy: 0.3670\n","\n","Epoch 00204: val_accuracy did not improve from 0.91872\n","Epoch 205/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.6956 - val_accuracy: 0.8768\n","\n","Epoch 00205: val_accuracy did not improve from 0.91872\n","Epoch 206/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 2.0379 - val_accuracy: 0.7094\n","\n","Epoch 00206: val_accuracy did not improve from 0.91872\n","Epoch 207/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.5720 - val_accuracy: 0.8941\n","\n","Epoch 00207: val_accuracy did not improve from 0.91872\n","Epoch 208/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4748 - val_accuracy: 0.9163\n","\n","Epoch 00208: val_accuracy did not improve from 0.91872\n","Epoch 209/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.7593 - val_accuracy: 0.8793\n","\n","Epoch 00209: val_accuracy did not improve from 0.91872\n","Epoch 210/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0470 - accuracy: 0.9836 - val_loss: 3.4398 - val_accuracy: 0.6379\n","\n","Epoch 00210: val_accuracy did not improve from 0.91872\n","Epoch 211/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0381 - accuracy: 0.9903 - val_loss: 0.6549 - val_accuracy: 0.8670\n","\n","Epoch 00211: val_accuracy did not improve from 0.91872\n","Epoch 212/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0466 - accuracy: 0.9842 - val_loss: 0.5947 - val_accuracy: 0.9039\n","\n","Epoch 00212: val_accuracy did not improve from 0.91872\n","Epoch 213/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0310 - accuracy: 0.9884 - val_loss: 0.6195 - val_accuracy: 0.8892\n","\n","Epoch 00213: val_accuracy did not improve from 0.91872\n","Epoch 214/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.9975 - val_accuracy: 0.8473\n","\n","Epoch 00214: val_accuracy did not improve from 0.91872\n","Epoch 215/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0279 - accuracy: 0.9890 - val_loss: 1.0474 - val_accuracy: 0.8473\n","\n","Epoch 00215: val_accuracy did not improve from 0.91872\n","Epoch 216/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 3.4891 - val_accuracy: 0.6232\n","\n","Epoch 00216: val_accuracy did not improve from 0.91872\n","Epoch 217/500\n","52/52 [==============================] - 16s 309ms/step - loss: 0.0704 - accuracy: 0.9793 - val_loss: 0.8006 - val_accuracy: 0.8670\n","\n","Epoch 00217: val_accuracy did not improve from 0.91872\n","Epoch 218/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0339 - accuracy: 0.9878 - val_loss: 1.8513 - val_accuracy: 0.7611\n","\n","Epoch 00218: val_accuracy did not improve from 0.91872\n","Epoch 219/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0277 - accuracy: 0.9939 - val_loss: 0.6203 - val_accuracy: 0.8818\n","\n","Epoch 00219: val_accuracy did not improve from 0.91872\n","Epoch 220/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.5806 - val_accuracy: 0.8990\n","\n","Epoch 00220: val_accuracy did not improve from 0.91872\n","Epoch 221/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0277 - accuracy: 0.9927 - val_loss: 0.8347 - val_accuracy: 0.8645\n","\n","Epoch 00221: val_accuracy did not improve from 0.91872\n","Epoch 222/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.5395 - val_accuracy: 0.8966\n","\n","Epoch 00222: val_accuracy did not improve from 0.91872\n","Epoch 223/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 0.7125 - val_accuracy: 0.8768\n","\n","Epoch 00223: val_accuracy did not improve from 0.91872\n","Epoch 224/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 1.0129 - val_accuracy: 0.8547\n","\n","Epoch 00224: val_accuracy did not improve from 0.91872\n","Epoch 225/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 15.7327 - val_accuracy: 0.2882\n","\n","Epoch 00225: val_accuracy did not improve from 0.91872\n","Epoch 226/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0297 - accuracy: 0.9896 - val_loss: 0.7882 - val_accuracy: 0.8670\n","\n","Epoch 00226: val_accuracy did not improve from 0.91872\n","Epoch 227/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0348 - accuracy: 0.9903 - val_loss: 0.8064 - val_accuracy: 0.8695\n","\n","Epoch 00227: val_accuracy did not improve from 0.91872\n","Epoch 228/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.9904 - val_accuracy: 0.8424\n","\n","Epoch 00228: val_accuracy did not improve from 0.91872\n","Epoch 229/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0831 - accuracy: 0.9805 - val_loss: 0.9686 - val_accuracy: 0.8621\n","\n","Epoch 00229: val_accuracy did not improve from 0.91872\n","Epoch 230/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0314 - accuracy: 0.9890 - val_loss: 0.7444 - val_accuracy: 0.8596\n","\n","Epoch 00230: val_accuracy did not improve from 0.91872\n","Epoch 231/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0259 - accuracy: 0.9896 - val_loss: 0.6033 - val_accuracy: 0.8941\n","\n","Epoch 00231: val_accuracy did not improve from 0.91872\n","Epoch 232/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.5665 - val_accuracy: 0.8867\n","\n","Epoch 00232: val_accuracy did not improve from 0.91872\n","Epoch 233/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0319 - accuracy: 0.9884 - val_loss: 0.5782 - val_accuracy: 0.8941\n","\n","Epoch 00233: val_accuracy did not improve from 0.91872\n","Epoch 234/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.5620 - val_accuracy: 0.9089\n","\n","Epoch 00234: val_accuracy did not improve from 0.91872\n","Epoch 235/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.6321 - val_accuracy: 0.8941\n","\n","Epoch 00235: val_accuracy did not improve from 0.91872\n","Epoch 236/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0125 - accuracy: 0.9945 - val_loss: 1.0662 - val_accuracy: 0.8547\n","\n","Epoch 00236: val_accuracy did not improve from 0.91872\n","Epoch 237/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0268 - accuracy: 0.9890 - val_loss: 1.3729 - val_accuracy: 0.7783\n","\n","Epoch 00237: val_accuracy did not improve from 0.91872\n","Epoch 238/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.6350 - val_accuracy: 0.8916\n","\n","Epoch 00238: val_accuracy did not improve from 0.91872\n","Epoch 239/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0520 - accuracy: 0.9860 - val_loss: 0.7154 - val_accuracy: 0.8719\n","\n","Epoch 00239: val_accuracy did not improve from 0.91872\n","Epoch 240/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0315 - accuracy: 0.9878 - val_loss: 0.6333 - val_accuracy: 0.8867\n","\n","Epoch 00240: val_accuracy did not improve from 0.91872\n","Epoch 241/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0342 - accuracy: 0.9909 - val_loss: 0.6929 - val_accuracy: 0.8941\n","\n","Epoch 00241: val_accuracy did not improve from 0.91872\n","Epoch 242/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0367 - accuracy: 0.9878 - val_loss: 0.6646 - val_accuracy: 0.8842\n","\n","Epoch 00242: val_accuracy did not improve from 0.91872\n","Epoch 243/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0178 - accuracy: 0.9933 - val_loss: 0.6460 - val_accuracy: 0.8768\n","\n","Epoch 00243: val_accuracy did not improve from 0.91872\n","Epoch 244/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.7605 - val_accuracy: 0.8645\n","\n","Epoch 00244: val_accuracy did not improve from 0.91872\n","Epoch 245/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.6427 - val_accuracy: 0.8744\n","\n","Epoch 00245: val_accuracy did not improve from 0.91872\n","Epoch 246/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.6003 - val_accuracy: 0.8990\n","\n","Epoch 00246: val_accuracy did not improve from 0.91872\n","Epoch 247/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.7148 - val_accuracy: 0.8818\n","\n","Epoch 00247: val_accuracy did not improve from 0.91872\n","Epoch 248/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0163 - accuracy: 0.9970 - val_loss: 0.6976 - val_accuracy: 0.8670\n","\n","Epoch 00248: val_accuracy did not improve from 0.91872\n","Epoch 249/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.7556 - val_accuracy: 0.8645\n","\n","Epoch 00249: val_accuracy did not improve from 0.91872\n","Epoch 250/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 1.0605 - val_accuracy: 0.8399\n","\n","Epoch 00250: val_accuracy did not improve from 0.91872\n","Epoch 251/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.7766 - val_accuracy: 0.8645\n","\n","Epoch 00251: val_accuracy did not improve from 0.91872\n","Epoch 252/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.6461 - val_accuracy: 0.8793\n","\n","Epoch 00252: val_accuracy did not improve from 0.91872\n","Epoch 253/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.9031 - val_accuracy: 0.8645\n","\n","Epoch 00253: val_accuracy did not improve from 0.91872\n","Epoch 254/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.6695 - val_accuracy: 0.8966\n","\n","Epoch 00254: val_accuracy did not improve from 0.91872\n","Epoch 255/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.7106 - val_accuracy: 0.8892\n","\n","Epoch 00255: val_accuracy did not improve from 0.91872\n","Epoch 256/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6666 - val_accuracy: 0.8966\n","\n","Epoch 00256: val_accuracy did not improve from 0.91872\n","Epoch 257/500\n","52/52 [==============================] - 17s 319ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5294 - val_accuracy: 0.9039\n","\n","Epoch 00257: val_accuracy did not improve from 0.91872\n","Epoch 258/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5814 - val_accuracy: 0.9138\n","\n","Epoch 00258: val_accuracy did not improve from 0.91872\n","Epoch 259/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6142 - val_accuracy: 0.9015\n","\n","Epoch 00259: val_accuracy did not improve from 0.91872\n","Epoch 260/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0202 - accuracy: 0.9909 - val_loss: 0.9699 - val_accuracy: 0.8768\n","\n","Epoch 00260: val_accuracy did not improve from 0.91872\n","Epoch 261/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.9518 - val_accuracy: 0.8399\n","\n","Epoch 00261: val_accuracy did not improve from 0.91872\n","Epoch 262/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0544 - accuracy: 0.9829 - val_loss: 1.0616 - val_accuracy: 0.8596\n","\n","Epoch 00262: val_accuracy did not improve from 0.91872\n","Epoch 263/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.7760 - val_accuracy: 0.8744\n","\n","Epoch 00263: val_accuracy did not improve from 0.91872\n","Epoch 264/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.8063 - val_accuracy: 0.8621\n","\n","Epoch 00264: val_accuracy did not improve from 0.91872\n","Epoch 265/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 1.1426 - val_accuracy: 0.8227\n","\n","Epoch 00265: val_accuracy did not improve from 0.91872\n","Epoch 266/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.8053 - val_accuracy: 0.8842\n","\n","Epoch 00266: val_accuracy did not improve from 0.91872\n","Epoch 267/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0331 - accuracy: 0.9878 - val_loss: 0.9933 - val_accuracy: 0.8547\n","\n","Epoch 00267: val_accuracy did not improve from 0.91872\n","Epoch 268/500\n","52/52 [==============================] - 16s 309ms/step - loss: 0.0533 - accuracy: 0.9775 - val_loss: 1.0027 - val_accuracy: 0.8473\n","\n","Epoch 00268: val_accuracy did not improve from 0.91872\n","Epoch 269/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0473 - accuracy: 0.9817 - val_loss: 1.2825 - val_accuracy: 0.8300\n","\n","Epoch 00269: val_accuracy did not improve from 0.91872\n","Epoch 270/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0257 - accuracy: 0.9909 - val_loss: 0.6653 - val_accuracy: 0.8645\n","\n","Epoch 00270: val_accuracy did not improve from 0.91872\n","Epoch 271/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.7505 - val_accuracy: 0.8768\n","\n","Epoch 00271: val_accuracy did not improve from 0.91872\n","Epoch 272/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0287 - accuracy: 0.9896 - val_loss: 0.9691 - val_accuracy: 0.8300\n","\n","Epoch 00272: val_accuracy did not improve from 0.91872\n","Epoch 273/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.7658 - val_accuracy: 0.8768\n","\n","Epoch 00273: val_accuracy did not improve from 0.91872\n","Epoch 274/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 1.9521 - val_accuracy: 0.7438\n","\n","Epoch 00274: val_accuracy did not improve from 0.91872\n","Epoch 275/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 0.7151 - val_accuracy: 0.8695\n","\n","Epoch 00275: val_accuracy did not improve from 0.91872\n","Epoch 276/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 1.4954 - val_accuracy: 0.7980\n","\n","Epoch 00276: val_accuracy did not improve from 0.91872\n","Epoch 277/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.8404 - val_accuracy: 0.8547\n","\n","Epoch 00277: val_accuracy did not improve from 0.91872\n","Epoch 278/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.8563 - val_accuracy: 0.8522\n","\n","Epoch 00278: val_accuracy did not improve from 0.91872\n","Epoch 279/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0298 - accuracy: 0.9927 - val_loss: 0.8096 - val_accuracy: 0.8621\n","\n","Epoch 00279: val_accuracy did not improve from 0.91872\n","Epoch 280/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.7505 - val_accuracy: 0.8645\n","\n","Epoch 00280: val_accuracy did not improve from 0.91872\n","Epoch 281/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 0.5129 - val_accuracy: 0.8990\n","\n","Epoch 00281: val_accuracy did not improve from 0.91872\n","Epoch 282/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.5483 - val_accuracy: 0.9064\n","\n","Epoch 00282: val_accuracy did not improve from 0.91872\n","Epoch 283/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0104 - accuracy: 0.9951 - val_loss: 0.5842 - val_accuracy: 0.8990\n","\n","Epoch 00283: val_accuracy did not improve from 0.91872\n","Epoch 284/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.5493 - val_accuracy: 0.8892\n","\n","Epoch 00284: val_accuracy did not improve from 0.91872\n","Epoch 285/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.9175 - val_accuracy: 0.8645\n","\n","Epoch 00285: val_accuracy did not improve from 0.91872\n","Epoch 286/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.7480 - val_accuracy: 0.8892\n","\n","Epoch 00286: val_accuracy did not improve from 0.91872\n","Epoch 287/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.7390 - val_accuracy: 0.8842\n","\n","Epoch 00287: val_accuracy did not improve from 0.91872\n","Epoch 288/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 1.0048 - val_accuracy: 0.8498\n","\n","Epoch 00288: val_accuracy did not improve from 0.91872\n","Epoch 289/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.6589 - val_accuracy: 0.8990\n","\n","Epoch 00289: val_accuracy did not improve from 0.91872\n","Epoch 290/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 14.5976 - val_accuracy: 0.2783\n","\n","Epoch 00290: val_accuracy did not improve from 0.91872\n","Epoch 291/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 8.1188 - val_accuracy: 0.4557\n","\n","Epoch 00291: val_accuracy did not improve from 0.91872\n","Epoch 292/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0509 - accuracy: 0.9884 - val_loss: 1.1044 - val_accuracy: 0.8695\n","\n","Epoch 00292: val_accuracy did not improve from 0.91872\n","Epoch 293/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0788 - accuracy: 0.9793 - val_loss: 2.0381 - val_accuracy: 0.7808\n","\n","Epoch 00293: val_accuracy did not improve from 0.91872\n","Epoch 294/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0614 - accuracy: 0.9823 - val_loss: 0.7450 - val_accuracy: 0.8571\n","\n","Epoch 00294: val_accuracy did not improve from 0.91872\n","Epoch 295/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.7370 - val_accuracy: 0.8818\n","\n","Epoch 00295: val_accuracy did not improve from 0.91872\n","Epoch 296/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.5843 - val_accuracy: 0.8842\n","\n","Epoch 00296: val_accuracy did not improve from 0.91872\n","Epoch 297/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.5983 - val_accuracy: 0.8842\n","\n","Epoch 00297: val_accuracy did not improve from 0.91872\n","Epoch 298/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0134 - accuracy: 0.9939 - val_loss: 0.6054 - val_accuracy: 0.8941\n","\n","Epoch 00298: val_accuracy did not improve from 0.91872\n","Epoch 299/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0114 - accuracy: 0.9982 - val_loss: 0.7302 - val_accuracy: 0.8793\n","\n","Epoch 00299: val_accuracy did not improve from 0.91872\n","Epoch 300/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.8916\n","\n","Epoch 00300: val_accuracy did not improve from 0.91872\n","Epoch 301/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0202 - accuracy: 0.9951 - val_loss: 0.7125 - val_accuracy: 0.8818\n","\n","Epoch 00301: val_accuracy did not improve from 0.91872\n","Epoch 302/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.7405 - val_accuracy: 0.8547\n","\n","Epoch 00302: val_accuracy did not improve from 0.91872\n","Epoch 303/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.6127 - val_accuracy: 0.9015\n","\n","Epoch 00303: val_accuracy did not improve from 0.91872\n","Epoch 304/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0104 - accuracy: 0.9951 - val_loss: 0.6141 - val_accuracy: 0.8867\n","\n","Epoch 00304: val_accuracy did not improve from 0.91872\n","Epoch 305/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0059 - accuracy: 0.9970 - val_loss: 0.7150 - val_accuracy: 0.8966\n","\n","Epoch 00305: val_accuracy did not improve from 0.91872\n","Epoch 306/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.6515 - val_accuracy: 0.8966\n","\n","Epoch 00306: val_accuracy did not improve from 0.91872\n","Epoch 307/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0300 - accuracy: 0.9915 - val_loss: 0.8136 - val_accuracy: 0.8695\n","\n","Epoch 00307: val_accuracy did not improve from 0.91872\n","Epoch 308/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.5399 - val_accuracy: 0.9089\n","\n","Epoch 00308: val_accuracy did not improve from 0.91872\n","Epoch 309/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.8129 - val_accuracy: 0.8645\n","\n","Epoch 00309: val_accuracy did not improve from 0.91872\n","Epoch 310/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.5816 - val_accuracy: 0.8966\n","\n","Epoch 00310: val_accuracy did not improve from 0.91872\n","Epoch 311/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.6716 - val_accuracy: 0.8793\n","\n","Epoch 00311: val_accuracy did not improve from 0.91872\n","Epoch 312/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0531 - accuracy: 0.9878 - val_loss: 1.5237 - val_accuracy: 0.7833\n","\n","Epoch 00312: val_accuracy did not improve from 0.91872\n","Epoch 313/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.1085 - accuracy: 0.9702 - val_loss: 2.7285 - val_accuracy: 0.6798\n","\n","Epoch 00313: val_accuracy did not improve from 0.91872\n","Epoch 314/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0337 - accuracy: 0.9866 - val_loss: 0.7894 - val_accuracy: 0.8842\n","\n","Epoch 00314: val_accuracy did not improve from 0.91872\n","Epoch 315/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.7189 - val_accuracy: 0.8867\n","\n","Epoch 00315: val_accuracy did not improve from 0.91872\n","Epoch 316/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.6643 - val_accuracy: 0.8842\n","\n","Epoch 00316: val_accuracy did not improve from 0.91872\n","Epoch 317/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0100 - accuracy: 0.9957 - val_loss: 0.4800 - val_accuracy: 0.9015\n","\n","Epoch 00317: val_accuracy did not improve from 0.91872\n","Epoch 318/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.6460 - val_accuracy: 0.8966\n","\n","Epoch 00318: val_accuracy did not improve from 0.91872\n","Epoch 319/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.6203 - val_accuracy: 0.8966\n","\n","Epoch 00319: val_accuracy did not improve from 0.91872\n","Epoch 320/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.5512 - val_accuracy: 0.9015\n","\n","Epoch 00320: val_accuracy did not improve from 0.91872\n","Epoch 321/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.7339 - val_accuracy: 0.8571\n","\n","Epoch 00321: val_accuracy did not improve from 0.91872\n","Epoch 322/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.7247 - val_accuracy: 0.8941\n","\n","Epoch 00322: val_accuracy did not improve from 0.91872\n","Epoch 323/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5428 - val_accuracy: 0.9089\n","\n","Epoch 00323: val_accuracy did not improve from 0.91872\n","Epoch 324/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.7228 - val_accuracy: 0.8645\n","\n","Epoch 00324: val_accuracy did not improve from 0.91872\n","Epoch 325/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 0.7848 - val_accuracy: 0.8744\n","\n","Epoch 00325: val_accuracy did not improve from 0.91872\n","Epoch 326/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0517 - accuracy: 0.9854 - val_loss: 0.9654 - val_accuracy: 0.8621\n","\n","Epoch 00326: val_accuracy did not improve from 0.91872\n","Epoch 327/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0429 - accuracy: 0.9854 - val_loss: 0.9437 - val_accuracy: 0.8522\n","\n","Epoch 00327: val_accuracy did not improve from 0.91872\n","Epoch 328/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.7162 - val_accuracy: 0.8916\n","\n","Epoch 00328: val_accuracy did not improve from 0.91872\n","Epoch 329/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 6.5302 - val_accuracy: 0.5148\n","\n","Epoch 00329: val_accuracy did not improve from 0.91872\n","Epoch 330/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.5847 - val_accuracy: 0.9015\n","\n","Epoch 00330: val_accuracy did not improve from 0.91872\n","Epoch 331/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.6313 - val_accuracy: 0.8990\n","\n","Epoch 00331: val_accuracy did not improve from 0.91872\n","Epoch 332/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4805 - val_accuracy: 0.8990\n","\n","Epoch 00332: val_accuracy did not improve from 0.91872\n","Epoch 333/500\n","52/52 [==============================] - 16s 305ms/step - loss: 9.1873e-04 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.9064\n","\n","Epoch 00333: val_accuracy did not improve from 0.91872\n","Epoch 334/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.6073 - val_accuracy: 0.9039\n","\n","Epoch 00334: val_accuracy did not improve from 0.91872\n","Epoch 335/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.6465 - val_accuracy: 0.9039\n","\n","Epoch 00335: val_accuracy did not improve from 0.91872\n","Epoch 336/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.6946 - val_accuracy: 0.8990\n","\n","Epoch 00336: val_accuracy did not improve from 0.91872\n","Epoch 337/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.4980 - val_accuracy: 0.9163\n","\n","Epoch 00337: val_accuracy did not improve from 0.91872\n","Epoch 338/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4542 - val_accuracy: 0.9113\n","\n","Epoch 00338: val_accuracy did not improve from 0.91872\n","Epoch 339/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.6254 - val_accuracy: 0.8892\n","\n","Epoch 00339: val_accuracy did not improve from 0.91872\n","Epoch 340/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.8324 - val_accuracy: 0.8522\n","\n","Epoch 00340: val_accuracy did not improve from 0.91872\n","Epoch 341/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5237 - val_accuracy: 0.9163\n","\n","Epoch 00341: val_accuracy did not improve from 0.91872\n","Epoch 342/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5623 - val_accuracy: 0.9163\n","\n","Epoch 00342: val_accuracy did not improve from 0.91872\n","Epoch 343/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4775 - val_accuracy: 0.9064\n","\n","Epoch 00343: val_accuracy did not improve from 0.91872\n","Epoch 344/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5316 - val_accuracy: 0.9138\n","\n","Epoch 00344: val_accuracy did not improve from 0.91872\n","Epoch 345/500\n","52/52 [==============================] - 16s 305ms/step - loss: 9.5652e-04 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 0.9064\n","\n","Epoch 00345: val_accuracy did not improve from 0.91872\n","Epoch 346/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.9138\n","\n","Epoch 00346: val_accuracy did not improve from 0.91872\n","Epoch 347/500\n","52/52 [==============================] - 16s 304ms/step - loss: 6.3842e-04 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9187\n","\n","Epoch 00347: val_accuracy did not improve from 0.91872\n","Epoch 348/500\n","52/52 [==============================] - 16s 306ms/step - loss: 7.4324e-04 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.9113\n","\n","Epoch 00348: val_accuracy did not improve from 0.91872\n","Epoch 349/500\n","52/52 [==============================] - 16s 305ms/step - loss: 5.9051e-04 - accuracy: 1.0000 - val_loss: 0.6421 - val_accuracy: 0.8768\n","\n","Epoch 00349: val_accuracy did not improve from 0.91872\n","Epoch 350/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 0.8727 - val_accuracy: 0.8571\n","\n","Epoch 00350: val_accuracy did not improve from 0.91872\n","Epoch 351/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0566 - accuracy: 0.9848 - val_loss: 1.0758 - val_accuracy: 0.8596\n","\n","Epoch 00351: val_accuracy did not improve from 0.91872\n","Epoch 352/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0543 - accuracy: 0.9805 - val_loss: 0.8240 - val_accuracy: 0.8695\n","\n","Epoch 00352: val_accuracy did not improve from 0.91872\n","Epoch 353/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0340 - accuracy: 0.9909 - val_loss: 0.9145 - val_accuracy: 0.8547\n","\n","Epoch 00353: val_accuracy did not improve from 0.91872\n","Epoch 354/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0408 - accuracy: 0.9884 - val_loss: 0.9995 - val_accuracy: 0.8498\n","\n","Epoch 00354: val_accuracy did not improve from 0.91872\n","Epoch 355/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 1.2840 - val_accuracy: 0.8103\n","\n","Epoch 00355: val_accuracy did not improve from 0.91872\n","Epoch 356/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0578 - accuracy: 0.9787 - val_loss: 1.0816 - val_accuracy: 0.8448\n","\n","Epoch 00356: val_accuracy did not improve from 0.91872\n","Epoch 357/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.7287 - val_accuracy: 0.8966\n","\n","Epoch 00357: val_accuracy did not improve from 0.91872\n","Epoch 358/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.5766 - val_accuracy: 0.8966\n","\n","Epoch 00358: val_accuracy did not improve from 0.91872\n","Epoch 359/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.9662 - val_accuracy: 0.8990\n","\n","Epoch 00359: val_accuracy did not improve from 0.91872\n","Epoch 360/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0289 - accuracy: 0.9896 - val_loss: 0.8087 - val_accuracy: 0.8547\n","\n","Epoch 00360: val_accuracy did not improve from 0.91872\n","Epoch 361/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0135 - accuracy: 0.9945 - val_loss: 0.7580 - val_accuracy: 0.8867\n","\n","Epoch 00361: val_accuracy did not improve from 0.91872\n","Epoch 362/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.5840 - val_accuracy: 0.8990\n","\n","Epoch 00362: val_accuracy did not improve from 0.91872\n","Epoch 363/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5914 - val_accuracy: 0.8867\n","\n","Epoch 00363: val_accuracy did not improve from 0.91872\n","Epoch 364/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.5058 - val_accuracy: 0.8966\n","\n","Epoch 00364: val_accuracy did not improve from 0.91872\n","Epoch 365/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0257 - accuracy: 0.9951 - val_loss: 0.6854 - val_accuracy: 0.9015\n","\n","Epoch 00365: val_accuracy did not improve from 0.91872\n","Epoch 366/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.5641 - val_accuracy: 0.9039\n","\n","Epoch 00366: val_accuracy did not improve from 0.91872\n","Epoch 367/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5834 - val_accuracy: 0.8966\n","\n","Epoch 00367: val_accuracy did not improve from 0.91872\n","Epoch 368/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.7820 - val_accuracy: 0.8695\n","\n","Epoch 00368: val_accuracy did not improve from 0.91872\n","Epoch 369/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.7211 - val_accuracy: 0.8695\n","\n","Epoch 00369: val_accuracy did not improve from 0.91872\n","Epoch 370/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.5987 - val_accuracy: 0.9015\n","\n","Epoch 00370: val_accuracy did not improve from 0.91872\n","Epoch 371/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.8366 - val_accuracy: 0.8818\n","\n","Epoch 00371: val_accuracy did not improve from 0.91872\n","Epoch 372/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5552 - val_accuracy: 0.8990\n","\n","Epoch 00372: val_accuracy did not improve from 0.91872\n","Epoch 373/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0180 - accuracy: 0.9957 - val_loss: 0.6958 - val_accuracy: 0.9064\n","\n","Epoch 00373: val_accuracy did not improve from 0.91872\n","Epoch 374/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0103 - accuracy: 0.9951 - val_loss: 0.6988 - val_accuracy: 0.8966\n","\n","Epoch 00374: val_accuracy did not improve from 0.91872\n","Epoch 375/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.9732 - val_accuracy: 0.8719\n","\n","Epoch 00375: val_accuracy did not improve from 0.91872\n","Epoch 376/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.7898 - val_accuracy: 0.8867\n","\n","Epoch 00376: val_accuracy did not improve from 0.91872\n","Epoch 377/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.7201 - val_accuracy: 0.8818\n","\n","Epoch 00377: val_accuracy did not improve from 0.91872\n","Epoch 378/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0100 - accuracy: 0.9945 - val_loss: 0.8089 - val_accuracy: 0.8744\n","\n","Epoch 00378: val_accuracy did not improve from 0.91872\n","Epoch 379/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.8991 - val_accuracy: 0.8547\n","\n","Epoch 00379: val_accuracy did not improve from 0.91872\n","Epoch 380/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.6551 - val_accuracy: 0.8941\n","\n","Epoch 00380: val_accuracy did not improve from 0.91872\n","Epoch 381/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.6502 - val_accuracy: 0.9113\n","\n","Epoch 00381: val_accuracy did not improve from 0.91872\n","Epoch 382/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.6681 - val_accuracy: 0.8990\n","\n","Epoch 00382: val_accuracy did not improve from 0.91872\n","Epoch 383/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.8478 - val_accuracy: 0.8867\n","\n","Epoch 00383: val_accuracy did not improve from 0.91872\n","Epoch 384/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.7950 - val_accuracy: 0.8867\n","\n","Epoch 00384: val_accuracy did not improve from 0.91872\n","Epoch 385/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0375 - accuracy: 0.9860 - val_loss: 1.2905 - val_accuracy: 0.8424\n","\n","Epoch 00385: val_accuracy did not improve from 0.91872\n","Epoch 386/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0446 - accuracy: 0.9890 - val_loss: 1.3745 - val_accuracy: 0.8374\n","\n","Epoch 00386: val_accuracy did not improve from 0.91872\n","Epoch 387/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0445 - accuracy: 0.9848 - val_loss: 0.8153 - val_accuracy: 0.8842\n","\n","Epoch 00387: val_accuracy did not improve from 0.91872\n","Epoch 388/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0299 - accuracy: 0.9921 - val_loss: 0.8776 - val_accuracy: 0.8941\n","\n","Epoch 00388: val_accuracy did not improve from 0.91872\n","Epoch 389/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.7843 - val_accuracy: 0.8695\n","\n","Epoch 00389: val_accuracy did not improve from 0.91872\n","Epoch 390/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.7053 - val_accuracy: 0.8793\n","\n","Epoch 00390: val_accuracy did not improve from 0.91872\n","Epoch 391/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.7194 - val_accuracy: 0.8719\n","\n","Epoch 00391: val_accuracy did not improve from 0.91872\n","Epoch 392/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.8088 - val_accuracy: 0.8768\n","\n","Epoch 00392: val_accuracy did not improve from 0.91872\n","Epoch 393/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0044 - accuracy: 0.9976 - val_loss: 0.6620 - val_accuracy: 0.8990\n","\n","Epoch 00393: val_accuracy did not improve from 0.91872\n","Epoch 394/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5643 - val_accuracy: 0.9015\n","\n","Epoch 00394: val_accuracy did not improve from 0.91872\n","Epoch 395/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.6266 - val_accuracy: 0.8941\n","\n","Epoch 00395: val_accuracy did not improve from 0.91872\n","Epoch 396/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.5787 - val_accuracy: 0.9113\n","\n","Epoch 00396: val_accuracy did not improve from 0.91872\n","Epoch 397/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.7794 - val_accuracy: 0.8892\n","\n","Epoch 00397: val_accuracy did not improve from 0.91872\n","Epoch 398/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6805 - val_accuracy: 0.8793\n","\n","Epoch 00398: val_accuracy did not improve from 0.91872\n","Epoch 399/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.8436 - val_accuracy: 0.8768\n","\n","Epoch 00399: val_accuracy did not improve from 0.91872\n","Epoch 400/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0148 - accuracy: 0.9939 - val_loss: 0.6390 - val_accuracy: 0.8916\n","\n","Epoch 00400: val_accuracy did not improve from 0.91872\n","Epoch 401/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0198 - accuracy: 0.9915 - val_loss: 0.6849 - val_accuracy: 0.8768\n","\n","Epoch 00401: val_accuracy did not improve from 0.91872\n","Epoch 402/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.5783 - val_accuracy: 0.9064\n","\n","Epoch 00402: val_accuracy did not improve from 0.91872\n","Epoch 403/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6199 - val_accuracy: 0.8966\n","\n","Epoch 00403: val_accuracy did not improve from 0.91872\n","Epoch 404/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5541 - val_accuracy: 0.9015\n","\n","Epoch 00404: val_accuracy did not improve from 0.91872\n","Epoch 405/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0036 - accuracy: 0.9976 - val_loss: 0.5909 - val_accuracy: 0.8990\n","\n","Epoch 00405: val_accuracy did not improve from 0.91872\n","Epoch 406/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.5567 - val_accuracy: 0.9015\n","\n","Epoch 00406: val_accuracy did not improve from 0.91872\n","Epoch 407/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.6122 - val_accuracy: 0.8990\n","\n","Epoch 00407: val_accuracy did not improve from 0.91872\n","Epoch 408/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.8990\n","\n","Epoch 00408: val_accuracy did not improve from 0.91872\n","Epoch 409/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.9297 - val_accuracy: 0.8719\n","\n","Epoch 00409: val_accuracy did not improve from 0.91872\n","Epoch 410/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0259 - accuracy: 0.9903 - val_loss: 9.7378 - val_accuracy: 0.4261\n","\n","Epoch 00410: val_accuracy did not improve from 0.91872\n","Epoch 411/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0223 - accuracy: 0.9915 - val_loss: 1.3893 - val_accuracy: 0.8227\n","\n","Epoch 00411: val_accuracy did not improve from 0.91872\n","Epoch 412/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 1.0018 - val_accuracy: 0.8596\n","\n","Epoch 00412: val_accuracy did not improve from 0.91872\n","Epoch 413/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 0.9867 - val_accuracy: 0.8670\n","\n","Epoch 00413: val_accuracy did not improve from 0.91872\n","Epoch 414/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0298 - accuracy: 0.9927 - val_loss: 0.8708 - val_accuracy: 0.8571\n","\n","Epoch 00414: val_accuracy did not improve from 0.91872\n","Epoch 415/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0252 - accuracy: 0.9909 - val_loss: 1.0801 - val_accuracy: 0.8571\n","\n","Epoch 00415: val_accuracy did not improve from 0.91872\n","Epoch 416/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 1.7825 - val_accuracy: 0.7931\n","\n","Epoch 00416: val_accuracy did not improve from 0.91872\n","Epoch 417/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.9217 - val_accuracy: 0.8695\n","\n","Epoch 00417: val_accuracy did not improve from 0.91872\n","Epoch 418/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.7116 - val_accuracy: 0.8966\n","\n","Epoch 00418: val_accuracy did not improve from 0.91872\n","Epoch 419/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.6288 - val_accuracy: 0.8941\n","\n","Epoch 00419: val_accuracy did not improve from 0.91872\n","Epoch 420/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.6404 - val_accuracy: 0.9039\n","\n","Epoch 00420: val_accuracy did not improve from 0.91872\n","Epoch 421/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.6891 - val_accuracy: 0.8842\n","\n","Epoch 00421: val_accuracy did not improve from 0.91872\n","Epoch 422/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 0.9064\n","\n","Epoch 00422: val_accuracy did not improve from 0.91872\n","Epoch 423/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6871 - val_accuracy: 0.8990\n","\n","Epoch 00423: val_accuracy did not improve from 0.91872\n","Epoch 424/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0293 - accuracy: 0.9903 - val_loss: 1.2707 - val_accuracy: 0.8498\n","\n","Epoch 00424: val_accuracy did not improve from 0.91872\n","Epoch 425/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0286 - accuracy: 0.9927 - val_loss: 1.0419 - val_accuracy: 0.8571\n","\n","Epoch 00425: val_accuracy did not improve from 0.91872\n","Epoch 426/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0414 - accuracy: 0.9896 - val_loss: 1.1676 - val_accuracy: 0.8448\n","\n","Epoch 00426: val_accuracy did not improve from 0.91872\n","Epoch 427/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0224 - accuracy: 0.9915 - val_loss: 0.7725 - val_accuracy: 0.8744\n","\n","Epoch 00427: val_accuracy did not improve from 0.91872\n","Epoch 428/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0149 - accuracy: 0.9976 - val_loss: 0.7489 - val_accuracy: 0.8818\n","\n","Epoch 00428: val_accuracy did not improve from 0.91872\n","Epoch 429/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.5822 - val_accuracy: 0.8867\n","\n","Epoch 00429: val_accuracy did not improve from 0.91872\n","Epoch 430/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0079 - accuracy: 0.9963 - val_loss: 0.8713 - val_accuracy: 0.8522\n","\n","Epoch 00430: val_accuracy did not improve from 0.91872\n","Epoch 431/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.6719 - val_accuracy: 0.9015\n","\n","Epoch 00431: val_accuracy did not improve from 0.91872\n","Epoch 432/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.8470 - val_accuracy: 0.8818\n","\n","Epoch 00432: val_accuracy did not improve from 0.91872\n","Epoch 433/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0600 - accuracy: 0.9848 - val_loss: 1.0473 - val_accuracy: 0.8325\n","\n","Epoch 00433: val_accuracy did not improve from 0.91872\n","Epoch 434/500\n","52/52 [==============================] - 16s 309ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.5935 - val_accuracy: 0.8719\n","\n","Epoch 00434: val_accuracy did not improve from 0.91872\n","Epoch 435/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.6578 - val_accuracy: 0.8744\n","\n","Epoch 00435: val_accuracy did not improve from 0.91872\n","Epoch 436/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.5361 - val_accuracy: 0.9015\n","\n","Epoch 00436: val_accuracy did not improve from 0.91872\n","Epoch 437/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.9352 - val_accuracy: 0.8670\n","\n","Epoch 00437: val_accuracy did not improve from 0.91872\n","Epoch 438/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5270 - val_accuracy: 0.8941\n","\n","Epoch 00438: val_accuracy did not improve from 0.91872\n","Epoch 439/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.4721 - val_accuracy: 0.9064\n","\n","Epoch 00439: val_accuracy did not improve from 0.91872\n","Epoch 440/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.4992 - val_accuracy: 0.8990\n","\n","Epoch 00440: val_accuracy did not improve from 0.91872\n","Epoch 441/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4336 - val_accuracy: 0.9138\n","\n","Epoch 00441: val_accuracy did not improve from 0.91872\n","Epoch 442/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.7021 - val_accuracy: 0.8916\n","\n","Epoch 00442: val_accuracy did not improve from 0.91872\n","Epoch 443/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.6240 - val_accuracy: 0.8842\n","\n","Epoch 00443: val_accuracy did not improve from 0.91872\n","Epoch 444/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0042 - accuracy: 0.9976 - val_loss: 0.7699 - val_accuracy: 0.8695\n","\n","Epoch 00444: val_accuracy did not improve from 0.91872\n","Epoch 445/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5907 - val_accuracy: 0.8892\n","\n","Epoch 00445: val_accuracy did not improve from 0.91872\n","Epoch 446/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5888 - val_accuracy: 0.9113\n","\n","Epoch 00446: val_accuracy did not improve from 0.91872\n","Epoch 447/500\n","52/52 [==============================] - 16s 305ms/step - loss: 5.3357e-04 - accuracy: 1.0000 - val_loss: 0.5344 - val_accuracy: 0.9089\n","\n","Epoch 00447: val_accuracy did not improve from 0.91872\n","Epoch 448/500\n","52/52 [==============================] - 16s 304ms/step - loss: 2.5337e-04 - accuracy: 1.0000 - val_loss: 0.4879 - val_accuracy: 0.9113\n","\n","Epoch 00448: val_accuracy did not improve from 0.91872\n","Epoch 449/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5507 - val_accuracy: 0.9113\n","\n","Epoch 00449: val_accuracy did not improve from 0.91872\n","Epoch 450/500\n","52/52 [==============================] - 16s 304ms/step - loss: 8.7833e-04 - accuracy: 1.0000 - val_loss: 0.5286 - val_accuracy: 0.9089\n","\n","Epoch 00450: val_accuracy did not improve from 0.91872\n","Epoch 451/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5910 - val_accuracy: 0.9089\n","\n","Epoch 00451: val_accuracy did not improve from 0.91872\n","Epoch 452/500\n","52/52 [==============================] - 16s 305ms/step - loss: 4.3180e-04 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.9138\n","\n","Epoch 00452: val_accuracy did not improve from 0.91872\n","Epoch 453/500\n","52/52 [==============================] - 16s 306ms/step - loss: 5.5979e-04 - accuracy: 1.0000 - val_loss: 0.6193 - val_accuracy: 0.9039\n","\n","Epoch 00453: val_accuracy did not improve from 0.91872\n","Epoch 454/500\n","52/52 [==============================] - 16s 305ms/step - loss: 3.1014e-04 - accuracy: 1.0000 - val_loss: 0.5527 - val_accuracy: 0.9138\n","\n","Epoch 00454: val_accuracy did not improve from 0.91872\n","Epoch 455/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4379 - val_accuracy: 0.9187\n","\n","Epoch 00455: val_accuracy did not improve from 0.91872\n","Epoch 456/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5851 - val_accuracy: 0.9015\n","\n","Epoch 00456: val_accuracy did not improve from 0.91872\n","Epoch 457/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.8465 - val_accuracy: 0.8621\n","\n","Epoch 00457: val_accuracy did not improve from 0.91872\n","Epoch 458/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0131 - accuracy: 0.9939 - val_loss: 0.8247 - val_accuracy: 0.8793\n","\n","Epoch 00458: val_accuracy did not improve from 0.91872\n","Epoch 459/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 3.4211 - val_accuracy: 0.6527\n","\n","Epoch 00459: val_accuracy did not improve from 0.91872\n","Epoch 460/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0641 - accuracy: 0.9829 - val_loss: 9.1024 - val_accuracy: 0.4680\n","\n","Epoch 00460: val_accuracy did not improve from 0.91872\n","Epoch 461/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0698 - accuracy: 0.9775 - val_loss: 1.1368 - val_accuracy: 0.8227\n","\n","Epoch 00461: val_accuracy did not improve from 0.91872\n","Epoch 462/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0745 - accuracy: 0.9823 - val_loss: 1.4420 - val_accuracy: 0.8005\n","\n","Epoch 00462: val_accuracy did not improve from 0.91872\n","Epoch 463/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0380 - accuracy: 0.9903 - val_loss: 0.7140 - val_accuracy: 0.8892\n","\n","Epoch 00463: val_accuracy did not improve from 0.91872\n","Epoch 464/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.6437 - val_accuracy: 0.8966\n","\n","Epoch 00464: val_accuracy did not improve from 0.91872\n","Epoch 465/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.5689 - val_accuracy: 0.8916\n","\n","Epoch 00465: val_accuracy did not improve from 0.91872\n","Epoch 466/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5617 - val_accuracy: 0.8941\n","\n","Epoch 00466: val_accuracy did not improve from 0.91872\n","Epoch 467/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4679 - val_accuracy: 0.9163\n","\n","Epoch 00467: val_accuracy did not improve from 0.91872\n","Epoch 468/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0030 - accuracy: 0.9982 - val_loss: 0.4428 - val_accuracy: 0.9089\n","\n","Epoch 00468: val_accuracy did not improve from 0.91872\n","Epoch 469/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.6686 - val_accuracy: 0.8916\n","\n","Epoch 00469: val_accuracy did not improve from 0.91872\n","Epoch 470/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6504 - val_accuracy: 0.8916\n","\n","Epoch 00470: val_accuracy did not improve from 0.91872\n","Epoch 471/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5121 - val_accuracy: 0.8990\n","\n","Epoch 00471: val_accuracy did not improve from 0.91872\n","Epoch 472/500\n","52/52 [==============================] - 16s 305ms/step - loss: 7.7694e-04 - accuracy: 1.0000 - val_loss: 0.5693 - val_accuracy: 0.9015\n","\n","Epoch 00472: val_accuracy did not improve from 0.91872\n","Epoch 473/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9187\n","\n","Epoch 00473: val_accuracy did not improve from 0.91872\n","Epoch 474/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 6.7301 - val_accuracy: 0.5222\n","\n","Epoch 00474: val_accuracy did not improve from 0.91872\n","Epoch 475/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0193 - accuracy: 0.9927 - val_loss: 0.7477 - val_accuracy: 0.8916\n","\n","Epoch 00475: val_accuracy did not improve from 0.91872\n","Epoch 476/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.6751 - val_accuracy: 0.8744\n","\n","Epoch 00476: val_accuracy did not improve from 0.91872\n","Epoch 477/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.6847 - val_accuracy: 0.9064\n","\n","Epoch 00477: val_accuracy did not improve from 0.91872\n","Epoch 478/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.6013 - val_accuracy: 0.9089\n","\n","Epoch 00478: val_accuracy did not improve from 0.91872\n","Epoch 479/500\n","52/52 [==============================] - 16s 305ms/step - loss: 9.4562e-04 - accuracy: 1.0000 - val_loss: 0.6222 - val_accuracy: 0.9015\n","\n","Epoch 00479: val_accuracy did not improve from 0.91872\n","Epoch 480/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.6927 - val_accuracy: 0.8768\n","\n","Epoch 00480: val_accuracy did not improve from 0.91872\n","Epoch 481/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.7433 - val_accuracy: 0.8892\n","\n","Epoch 00481: val_accuracy did not improve from 0.91872\n","Epoch 482/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.7538 - val_accuracy: 0.8719\n","\n","Epoch 00482: val_accuracy did not improve from 0.91872\n","Epoch 483/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.6358 - val_accuracy: 0.9039\n","\n","Epoch 00483: val_accuracy did not improve from 0.91872\n","Epoch 484/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.6866 - val_accuracy: 0.8842\n","\n","Epoch 00484: val_accuracy did not improve from 0.91872\n","Epoch 485/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4926 - val_accuracy: 0.9138\n","\n","Epoch 00485: val_accuracy did not improve from 0.91872\n","Epoch 486/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5649 - val_accuracy: 0.9015\n","\n","Epoch 00486: val_accuracy did not improve from 0.91872\n","Epoch 487/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4770 - val_accuracy: 0.9138\n","\n","Epoch 00487: val_accuracy did not improve from 0.91872\n","Epoch 488/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.5940 - val_accuracy: 0.8966\n","\n","Epoch 00488: val_accuracy did not improve from 0.91872\n","Epoch 489/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.7467 - val_accuracy: 0.8966\n","\n","Epoch 00489: val_accuracy did not improve from 0.91872\n","Epoch 490/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.6082 - val_accuracy: 0.8941\n","\n","Epoch 00490: val_accuracy did not improve from 0.91872\n","Epoch 491/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0406 - accuracy: 0.9860 - val_loss: 1.3553 - val_accuracy: 0.8079\n","\n","Epoch 00491: val_accuracy did not improve from 0.91872\n","Epoch 492/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0321 - accuracy: 0.9896 - val_loss: 0.6532 - val_accuracy: 0.8793\n","\n","Epoch 00492: val_accuracy did not improve from 0.91872\n","Epoch 493/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 0.8234 - val_accuracy: 0.8670\n","\n","Epoch 00493: val_accuracy did not improve from 0.91872\n","Epoch 494/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.5275 - val_accuracy: 0.9212\n","\n","Epoch 00494: val_accuracy improved from 0.91872 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5\n","Epoch 495/500\n","52/52 [==============================] - 16s 309ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.9138\n","\n","Epoch 00495: val_accuracy did not improve from 0.92118\n","Epoch 496/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5990 - val_accuracy: 0.9064\n","\n","Epoch 00496: val_accuracy did not improve from 0.92118\n","Epoch 497/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.5327 - val_accuracy: 0.9089\n","\n","Epoch 00497: val_accuracy did not improve from 0.92118\n","Epoch 498/500\n","52/52 [==============================] - 16s 306ms/step - loss: 9.5125e-04 - accuracy: 1.0000 - val_loss: 0.5915 - val_accuracy: 0.9064\n","\n","Epoch 00498: val_accuracy did not improve from 0.92118\n","Epoch 499/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5899 - val_accuracy: 0.9015\n","\n","Epoch 00499: val_accuracy did not improve from 0.92118\n","Epoch 500/500\n","52/52 [==============================] - 16s 305ms/step - loss: 8.2521e-04 - accuracy: 0.9994 - val_loss: 0.5970 - val_accuracy: 0.9089\n","\n","Epoch 00500: val_accuracy did not improve from 0.92118\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f853e55d190>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"zSmniqeJDKe2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628142457002,"user_tz":-540,"elapsed":11537496,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"7901b723-71eb-4417-cf24-bebcf7985612"},"source":["ResNet152V2_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[ResNet152V2_checkpoint])\n","# files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 43s 484ms/step - loss: 2.3625 - accuracy: 0.1766 - val_loss: 12.2605 - val_accuracy: 0.0985\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/500\n","52/52 [==============================] - 22s 428ms/step - loss: 1.7803 - accuracy: 0.3800 - val_loss: 20.6379 - val_accuracy: 0.0961\n","\n","Epoch 00002: val_accuracy did not improve from 0.09852\n","Epoch 3/500\n","52/52 [==============================] - 22s 425ms/step - loss: 1.3703 - accuracy: 0.5128 - val_loss: 9.1149 - val_accuracy: 0.1010\n","\n","Epoch 00003: val_accuracy improved from 0.09852 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 4/500\n","52/52 [==============================] - 22s 427ms/step - loss: 1.0974 - accuracy: 0.6224 - val_loss: 8.8091 - val_accuracy: 0.1084\n","\n","Epoch 00004: val_accuracy improved from 0.10099 to 0.10837, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 5/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.9201 - accuracy: 0.6918 - val_loss: 7.2591 - val_accuracy: 0.1847\n","\n","Epoch 00005: val_accuracy improved from 0.10837 to 0.18473, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 6/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.8026 - accuracy: 0.7387 - val_loss: 4.0166 - val_accuracy: 0.2241\n","\n","Epoch 00006: val_accuracy improved from 0.18473 to 0.22414, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 7/500\n","52/52 [==============================] - 22s 429ms/step - loss: 0.6767 - accuracy: 0.7832 - val_loss: 4.0469 - val_accuracy: 0.1995\n","\n","Epoch 00007: val_accuracy did not improve from 0.22414\n","Epoch 8/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.7216 - accuracy: 0.7594 - val_loss: 3.0790 - val_accuracy: 0.4113\n","\n","Epoch 00008: val_accuracy improved from 0.22414 to 0.41133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 9/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.6271 - accuracy: 0.7911 - val_loss: 3.0041 - val_accuracy: 0.3621\n","\n","Epoch 00009: val_accuracy did not improve from 0.41133\n","Epoch 10/500\n","52/52 [==============================] - 22s 423ms/step - loss: 0.6043 - accuracy: 0.7996 - val_loss: 2.7357 - val_accuracy: 0.5394\n","\n","Epoch 00010: val_accuracy improved from 0.41133 to 0.53941, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 11/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.5850 - accuracy: 0.8021 - val_loss: 1.3844 - val_accuracy: 0.6601\n","\n","Epoch 00011: val_accuracy improved from 0.53941 to 0.66010, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 12/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.5150 - accuracy: 0.8289 - val_loss: 6.6539 - val_accuracy: 0.3054\n","\n","Epoch 00012: val_accuracy did not improve from 0.66010\n","Epoch 13/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.5083 - accuracy: 0.8240 - val_loss: 15.0271 - val_accuracy: 0.1207\n","\n","Epoch 00013: val_accuracy did not improve from 0.66010\n","Epoch 14/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.5213 - accuracy: 0.8276 - val_loss: 14.9736 - val_accuracy: 0.1330\n","\n","Epoch 00014: val_accuracy did not improve from 0.66010\n","Epoch 15/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.4301 - accuracy: 0.8508 - val_loss: 5.1311 - val_accuracy: 0.3719\n","\n","Epoch 00015: val_accuracy did not improve from 0.66010\n","Epoch 16/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.4160 - accuracy: 0.8618 - val_loss: 7.1276 - val_accuracy: 0.2709\n","\n","Epoch 00016: val_accuracy did not improve from 0.66010\n","Epoch 17/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.4568 - accuracy: 0.8471 - val_loss: 11.8637 - val_accuracy: 0.1847\n","\n","Epoch 00017: val_accuracy did not improve from 0.66010\n","Epoch 18/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.3934 - accuracy: 0.8733 - val_loss: 2.5949 - val_accuracy: 0.5197\n","\n","Epoch 00018: val_accuracy did not improve from 0.66010\n","Epoch 19/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.3706 - accuracy: 0.8685 - val_loss: 1.6443 - val_accuracy: 0.5961\n","\n","Epoch 00019: val_accuracy did not improve from 0.66010\n","Epoch 20/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.4290 - accuracy: 0.8593 - val_loss: 9.3738 - val_accuracy: 0.2241\n","\n","Epoch 00020: val_accuracy did not improve from 0.66010\n","Epoch 21/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.2904 - accuracy: 0.9068 - val_loss: 5.4007 - val_accuracy: 0.3966\n","\n","Epoch 00021: val_accuracy did not improve from 0.66010\n","Epoch 22/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.2748 - accuracy: 0.9001 - val_loss: 2.6076 - val_accuracy: 0.5837\n","\n","Epoch 00022: val_accuracy did not improve from 0.66010\n","Epoch 23/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.3048 - accuracy: 0.8934 - val_loss: 0.7387 - val_accuracy: 0.8153\n","\n","Epoch 00023: val_accuracy improved from 0.66010 to 0.81527, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 24/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.2808 - accuracy: 0.9062 - val_loss: 15.0321 - val_accuracy: 0.1552\n","\n","Epoch 00024: val_accuracy did not improve from 0.81527\n","Epoch 25/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.2378 - accuracy: 0.9220 - val_loss: 1.6344 - val_accuracy: 0.6995\n","\n","Epoch 00025: val_accuracy did not improve from 0.81527\n","Epoch 26/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.2857 - accuracy: 0.8977 - val_loss: 0.9404 - val_accuracy: 0.7315\n","\n","Epoch 00026: val_accuracy did not improve from 0.81527\n","Epoch 27/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.2836 - accuracy: 0.8952 - val_loss: 0.7900 - val_accuracy: 0.8079\n","\n","Epoch 00027: val_accuracy did not improve from 0.81527\n","Epoch 28/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.2330 - accuracy: 0.9196 - val_loss: 1.6852 - val_accuracy: 0.6601\n","\n","Epoch 00028: val_accuracy did not improve from 0.81527\n","Epoch 29/500\n","52/52 [==============================] - 22s 422ms/step - loss: 0.2247 - accuracy: 0.9178 - val_loss: 0.5843 - val_accuracy: 0.8374\n","\n","Epoch 00029: val_accuracy improved from 0.81527 to 0.83744, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 30/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.2567 - accuracy: 0.9111 - val_loss: 4.9830 - val_accuracy: 0.4163\n","\n","Epoch 00030: val_accuracy did not improve from 0.83744\n","Epoch 31/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.2483 - accuracy: 0.9123 - val_loss: 1.3891 - val_accuracy: 0.7020\n","\n","Epoch 00031: val_accuracy did not improve from 0.83744\n","Epoch 32/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.2278 - accuracy: 0.9220 - val_loss: 0.9085 - val_accuracy: 0.7635\n","\n","Epoch 00032: val_accuracy did not improve from 0.83744\n","Epoch 33/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.2120 - accuracy: 0.9281 - val_loss: 5.4050 - val_accuracy: 0.4335\n","\n","Epoch 00033: val_accuracy did not improve from 0.83744\n","Epoch 34/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.2009 - accuracy: 0.9336 - val_loss: 1.1918 - val_accuracy: 0.7094\n","\n","Epoch 00034: val_accuracy did not improve from 0.83744\n","Epoch 35/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.2285 - accuracy: 0.9202 - val_loss: 2.3883 - val_accuracy: 0.6232\n","\n","Epoch 00035: val_accuracy did not improve from 0.83744\n","Epoch 36/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.3292 - accuracy: 0.8916 - val_loss: 1.1982 - val_accuracy: 0.7192\n","\n","Epoch 00036: val_accuracy did not improve from 0.83744\n","Epoch 37/500\n","52/52 [==============================] - 22s 423ms/step - loss: 0.2691 - accuracy: 0.9117 - val_loss: 2.9189 - val_accuracy: 0.6158\n","\n","Epoch 00037: val_accuracy did not improve from 0.83744\n","Epoch 38/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1892 - accuracy: 0.9287 - val_loss: 4.2088 - val_accuracy: 0.4310\n","\n","Epoch 00038: val_accuracy did not improve from 0.83744\n","Epoch 39/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.2210 - accuracy: 0.9117 - val_loss: 1.4873 - val_accuracy: 0.6995\n","\n","Epoch 00039: val_accuracy did not improve from 0.83744\n","Epoch 40/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1533 - accuracy: 0.9452 - val_loss: 0.4080 - val_accuracy: 0.8547\n","\n","Epoch 00040: val_accuracy improved from 0.83744 to 0.85468, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 41/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.1486 - accuracy: 0.9476 - val_loss: 3.3665 - val_accuracy: 0.4360\n","\n","Epoch 00041: val_accuracy did not improve from 0.85468\n","Epoch 42/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.2566 - accuracy: 0.9214 - val_loss: 1.4511 - val_accuracy: 0.7020\n","\n","Epoch 00042: val_accuracy did not improve from 0.85468\n","Epoch 43/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.2068 - accuracy: 0.9287 - val_loss: 14.1165 - val_accuracy: 0.1626\n","\n","Epoch 00043: val_accuracy did not improve from 0.85468\n","Epoch 44/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1816 - accuracy: 0.9336 - val_loss: 1.3771 - val_accuracy: 0.7118\n","\n","Epoch 00044: val_accuracy did not improve from 0.85468\n","Epoch 45/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.2043 - accuracy: 0.9336 - val_loss: 2.4229 - val_accuracy: 0.5961\n","\n","Epoch 00045: val_accuracy did not improve from 0.85468\n","Epoch 46/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.1185 - accuracy: 0.9616 - val_loss: 0.5416 - val_accuracy: 0.8448\n","\n","Epoch 00046: val_accuracy did not improve from 0.85468\n","Epoch 47/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1939 - accuracy: 0.9373 - val_loss: 0.7375 - val_accuracy: 0.8325\n","\n","Epoch 00047: val_accuracy did not improve from 0.85468\n","Epoch 48/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.1544 - accuracy: 0.9434 - val_loss: 0.5781 - val_accuracy: 0.8571\n","\n","Epoch 00048: val_accuracy improved from 0.85468 to 0.85714, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 49/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.1185 - accuracy: 0.9610 - val_loss: 0.5055 - val_accuracy: 0.8719\n","\n","Epoch 00049: val_accuracy improved from 0.85714 to 0.87192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 50/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.1208 - accuracy: 0.9574 - val_loss: 0.8548 - val_accuracy: 0.7956\n","\n","Epoch 00050: val_accuracy did not improve from 0.87192\n","Epoch 51/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1239 - accuracy: 0.9531 - val_loss: 24.5157 - val_accuracy: 0.0985\n","\n","Epoch 00051: val_accuracy did not improve from 0.87192\n","Epoch 52/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.1152 - accuracy: 0.9568 - val_loss: 6.2675 - val_accuracy: 0.4039\n","\n","Epoch 00052: val_accuracy did not improve from 0.87192\n","Epoch 53/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.1329 - accuracy: 0.9543 - val_loss: 9.6598 - val_accuracy: 0.2291\n","\n","Epoch 00053: val_accuracy did not improve from 0.87192\n","Epoch 54/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.1336 - accuracy: 0.9501 - val_loss: 1.4612 - val_accuracy: 0.7365\n","\n","Epoch 00054: val_accuracy did not improve from 0.87192\n","Epoch 55/500\n","52/52 [==============================] - 22s 423ms/step - loss: 0.1403 - accuracy: 0.9519 - val_loss: 0.8332 - val_accuracy: 0.8005\n","\n","Epoch 00055: val_accuracy did not improve from 0.87192\n","Epoch 56/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1154 - accuracy: 0.9586 - val_loss: 0.7760 - val_accuracy: 0.8325\n","\n","Epoch 00056: val_accuracy did not improve from 0.87192\n","Epoch 57/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.1119 - accuracy: 0.9616 - val_loss: 16.5067 - val_accuracy: 0.1700\n","\n","Epoch 00057: val_accuracy did not improve from 0.87192\n","Epoch 58/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.1528 - accuracy: 0.9428 - val_loss: 1.0542 - val_accuracy: 0.8128\n","\n","Epoch 00058: val_accuracy did not improve from 0.87192\n","Epoch 59/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1048 - accuracy: 0.9653 - val_loss: 0.5143 - val_accuracy: 0.8842\n","\n","Epoch 00059: val_accuracy improved from 0.87192 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 60/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.1022 - accuracy: 0.9641 - val_loss: 7.3069 - val_accuracy: 0.3251\n","\n","Epoch 00060: val_accuracy did not improve from 0.88424\n","Epoch 61/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.1437 - accuracy: 0.9543 - val_loss: 3.9010 - val_accuracy: 0.4951\n","\n","Epoch 00061: val_accuracy did not improve from 0.88424\n","Epoch 62/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1174 - accuracy: 0.9629 - val_loss: 0.6577 - val_accuracy: 0.8522\n","\n","Epoch 00062: val_accuracy did not improve from 0.88424\n","Epoch 63/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.2016 - accuracy: 0.9330 - val_loss: 9.2166 - val_accuracy: 0.2660\n","\n","Epoch 00063: val_accuracy did not improve from 0.88424\n","Epoch 64/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1235 - accuracy: 0.9604 - val_loss: 0.6490 - val_accuracy: 0.8498\n","\n","Epoch 00064: val_accuracy did not improve from 0.88424\n","Epoch 65/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0988 - accuracy: 0.9665 - val_loss: 8.8966 - val_accuracy: 0.3054\n","\n","Epoch 00065: val_accuracy did not improve from 0.88424\n","Epoch 66/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0968 - accuracy: 0.9653 - val_loss: 4.9702 - val_accuracy: 0.3547\n","\n","Epoch 00066: val_accuracy did not improve from 0.88424\n","Epoch 67/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0890 - accuracy: 0.9714 - val_loss: 0.7994 - val_accuracy: 0.8448\n","\n","Epoch 00067: val_accuracy did not improve from 0.88424\n","Epoch 68/500\n","52/52 [==============================] - 22s 423ms/step - loss: 0.1172 - accuracy: 0.9586 - val_loss: 1.2439 - val_accuracy: 0.7709\n","\n","Epoch 00068: val_accuracy did not improve from 0.88424\n","Epoch 69/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0929 - accuracy: 0.9677 - val_loss: 2.8612 - val_accuracy: 0.5887\n","\n","Epoch 00069: val_accuracy did not improve from 0.88424\n","Epoch 70/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1043 - accuracy: 0.9598 - val_loss: 0.8638 - val_accuracy: 0.7906\n","\n","Epoch 00070: val_accuracy did not improve from 0.88424\n","Epoch 71/500\n","52/52 [==============================] - 22s 423ms/step - loss: 0.1252 - accuracy: 0.9580 - val_loss: 0.6936 - val_accuracy: 0.8448\n","\n","Epoch 00071: val_accuracy did not improve from 0.88424\n","Epoch 72/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1086 - accuracy: 0.9647 - val_loss: 1.1392 - val_accuracy: 0.7906\n","\n","Epoch 00072: val_accuracy did not improve from 0.88424\n","Epoch 73/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0823 - accuracy: 0.9689 - val_loss: 0.5596 - val_accuracy: 0.8473\n","\n","Epoch 00073: val_accuracy did not improve from 0.88424\n","Epoch 74/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0548 - accuracy: 0.9805 - val_loss: 2.2896 - val_accuracy: 0.6182\n","\n","Epoch 00074: val_accuracy did not improve from 0.88424\n","Epoch 75/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0552 - accuracy: 0.9811 - val_loss: 4.7682 - val_accuracy: 0.5172\n","\n","Epoch 00075: val_accuracy did not improve from 0.88424\n","Epoch 76/500\n","52/52 [==============================] - 22s 423ms/step - loss: 0.0752 - accuracy: 0.9750 - val_loss: 0.9273 - val_accuracy: 0.7931\n","\n","Epoch 00076: val_accuracy did not improve from 0.88424\n","Epoch 77/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.1289 - accuracy: 0.9616 - val_loss: 2.4807 - val_accuracy: 0.6355\n","\n","Epoch 00077: val_accuracy did not improve from 0.88424\n","Epoch 78/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.1118 - accuracy: 0.9641 - val_loss: 0.6148 - val_accuracy: 0.8473\n","\n","Epoch 00078: val_accuracy did not improve from 0.88424\n","Epoch 79/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0688 - accuracy: 0.9738 - val_loss: 0.7757 - val_accuracy: 0.8350\n","\n","Epoch 00079: val_accuracy did not improve from 0.88424\n","Epoch 80/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0957 - accuracy: 0.9683 - val_loss: 0.6733 - val_accuracy: 0.8695\n","\n","Epoch 00080: val_accuracy did not improve from 0.88424\n","Epoch 81/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.1523 - accuracy: 0.9464 - val_loss: 1.2014 - val_accuracy: 0.7759\n","\n","Epoch 00081: val_accuracy did not improve from 0.88424\n","Epoch 82/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.1837 - accuracy: 0.9391 - val_loss: 18.6313 - val_accuracy: 0.1404\n","\n","Epoch 00082: val_accuracy did not improve from 0.88424\n","Epoch 83/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.1936 - accuracy: 0.9379 - val_loss: 1.6807 - val_accuracy: 0.7167\n","\n","Epoch 00083: val_accuracy did not improve from 0.88424\n","Epoch 84/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0795 - accuracy: 0.9726 - val_loss: 0.5117 - val_accuracy: 0.8892\n","\n","Epoch 00084: val_accuracy improved from 0.88424 to 0.88916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 85/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0627 - accuracy: 0.9762 - val_loss: 0.5878 - val_accuracy: 0.8719\n","\n","Epoch 00085: val_accuracy did not improve from 0.88916\n","Epoch 86/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0509 - accuracy: 0.9854 - val_loss: 0.5231 - val_accuracy: 0.8818\n","\n","Epoch 00086: val_accuracy did not improve from 0.88916\n","Epoch 87/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0578 - accuracy: 0.9823 - val_loss: 0.5584 - val_accuracy: 0.8621\n","\n","Epoch 00087: val_accuracy did not improve from 0.88916\n","Epoch 88/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0466 - accuracy: 0.9854 - val_loss: 0.6049 - val_accuracy: 0.8670\n","\n","Epoch 00088: val_accuracy did not improve from 0.88916\n","Epoch 89/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0520 - accuracy: 0.9848 - val_loss: 0.5538 - val_accuracy: 0.8793\n","\n","Epoch 00089: val_accuracy did not improve from 0.88916\n","Epoch 90/500\n","52/52 [==============================] - 22s 423ms/step - loss: 0.0805 - accuracy: 0.9732 - val_loss: 0.6252 - val_accuracy: 0.8473\n","\n","Epoch 00090: val_accuracy did not improve from 0.88916\n","Epoch 91/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0680 - accuracy: 0.9756 - val_loss: 0.5118 - val_accuracy: 0.8941\n","\n","Epoch 00091: val_accuracy improved from 0.88916 to 0.89409, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 92/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0616 - accuracy: 0.9799 - val_loss: 0.5986 - val_accuracy: 0.8645\n","\n","Epoch 00092: val_accuracy did not improve from 0.89409\n","Epoch 93/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0662 - accuracy: 0.9756 - val_loss: 0.7502 - val_accuracy: 0.8424\n","\n","Epoch 00093: val_accuracy did not improve from 0.89409\n","Epoch 94/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0961 - accuracy: 0.9677 - val_loss: 0.9200 - val_accuracy: 0.8227\n","\n","Epoch 00094: val_accuracy did not improve from 0.89409\n","Epoch 95/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0812 - accuracy: 0.9756 - val_loss: 0.7723 - val_accuracy: 0.8399\n","\n","Epoch 00095: val_accuracy did not improve from 0.89409\n","Epoch 96/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.1040 - accuracy: 0.9641 - val_loss: 0.9324 - val_accuracy: 0.8251\n","\n","Epoch 00096: val_accuracy did not improve from 0.89409\n","Epoch 97/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0958 - accuracy: 0.9695 - val_loss: 1.1241 - val_accuracy: 0.7734\n","\n","Epoch 00097: val_accuracy did not improve from 0.89409\n","Epoch 98/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0877 - accuracy: 0.9659 - val_loss: 0.6687 - val_accuracy: 0.8571\n","\n","Epoch 00098: val_accuracy did not improve from 0.89409\n","Epoch 99/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0913 - accuracy: 0.9756 - val_loss: 1.3727 - val_accuracy: 0.7660\n","\n","Epoch 00099: val_accuracy did not improve from 0.89409\n","Epoch 100/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1140 - accuracy: 0.9598 - val_loss: 3.9339 - val_accuracy: 0.5394\n","\n","Epoch 00100: val_accuracy did not improve from 0.89409\n","Epoch 101/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1332 - accuracy: 0.9653 - val_loss: 8.4325 - val_accuracy: 0.3793\n","\n","Epoch 00101: val_accuracy did not improve from 0.89409\n","Epoch 102/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.1148 - accuracy: 0.9665 - val_loss: 0.5901 - val_accuracy: 0.8571\n","\n","Epoch 00102: val_accuracy did not improve from 0.89409\n","Epoch 103/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0843 - accuracy: 0.9720 - val_loss: 0.8715 - val_accuracy: 0.8596\n","\n","Epoch 00103: val_accuracy did not improve from 0.89409\n","Epoch 104/500\n","52/52 [==============================] - 22s 429ms/step - loss: 0.0976 - accuracy: 0.9677 - val_loss: 0.6008 - val_accuracy: 0.8522\n","\n","Epoch 00104: val_accuracy did not improve from 0.89409\n","Epoch 105/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0550 - accuracy: 0.9811 - val_loss: 0.5145 - val_accuracy: 0.8867\n","\n","Epoch 00105: val_accuracy did not improve from 0.89409\n","Epoch 106/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0347 - accuracy: 0.9890 - val_loss: 0.5714 - val_accuracy: 0.8670\n","\n","Epoch 00106: val_accuracy did not improve from 0.89409\n","Epoch 107/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0543 - accuracy: 0.9817 - val_loss: 0.9437 - val_accuracy: 0.8448\n","\n","Epoch 00107: val_accuracy did not improve from 0.89409\n","Epoch 108/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0578 - accuracy: 0.9762 - val_loss: 1.0857 - val_accuracy: 0.8030\n","\n","Epoch 00108: val_accuracy did not improve from 0.89409\n","Epoch 109/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0799 - accuracy: 0.9720 - val_loss: 0.6495 - val_accuracy: 0.8498\n","\n","Epoch 00109: val_accuracy did not improve from 0.89409\n","Epoch 110/500\n","52/52 [==============================] - 22s 423ms/step - loss: 0.0543 - accuracy: 0.9823 - val_loss: 0.9001 - val_accuracy: 0.8128\n","\n","Epoch 00110: val_accuracy did not improve from 0.89409\n","Epoch 111/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0544 - accuracy: 0.9762 - val_loss: 0.6227 - val_accuracy: 0.8768\n","\n","Epoch 00111: val_accuracy did not improve from 0.89409\n","Epoch 112/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0885 - accuracy: 0.9683 - val_loss: 0.6696 - val_accuracy: 0.8571\n","\n","Epoch 00112: val_accuracy did not improve from 0.89409\n","Epoch 113/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0747 - accuracy: 0.9738 - val_loss: 1.4697 - val_accuracy: 0.7709\n","\n","Epoch 00113: val_accuracy did not improve from 0.89409\n","Epoch 114/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0475 - accuracy: 0.9848 - val_loss: 3.6305 - val_accuracy: 0.5887\n","\n","Epoch 00114: val_accuracy did not improve from 0.89409\n","Epoch 115/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 11.7945 - val_accuracy: 0.2365\n","\n","Epoch 00115: val_accuracy did not improve from 0.89409\n","Epoch 116/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0391 - accuracy: 0.9866 - val_loss: 0.6427 - val_accuracy: 0.8867\n","\n","Epoch 00116: val_accuracy did not improve from 0.89409\n","Epoch 117/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0497 - accuracy: 0.9836 - val_loss: 0.5761 - val_accuracy: 0.8818\n","\n","Epoch 00117: val_accuracy did not improve from 0.89409\n","Epoch 118/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0446 - accuracy: 0.9811 - val_loss: 0.5594 - val_accuracy: 0.8842\n","\n","Epoch 00118: val_accuracy did not improve from 0.89409\n","Epoch 119/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0396 - accuracy: 0.9860 - val_loss: 0.5804 - val_accuracy: 0.8695\n","\n","Epoch 00119: val_accuracy did not improve from 0.89409\n","Epoch 120/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.1186 - accuracy: 0.9622 - val_loss: 0.7180 - val_accuracy: 0.8768\n","\n","Epoch 00120: val_accuracy did not improve from 0.89409\n","Epoch 121/500\n","52/52 [==============================] - 22s 423ms/step - loss: 0.0632 - accuracy: 0.9793 - val_loss: 0.5910 - val_accuracy: 0.8621\n","\n","Epoch 00121: val_accuracy did not improve from 0.89409\n","Epoch 122/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0587 - accuracy: 0.9829 - val_loss: 0.7394 - val_accuracy: 0.8645\n","\n","Epoch 00122: val_accuracy did not improve from 0.89409\n","Epoch 123/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0678 - accuracy: 0.9775 - val_loss: 0.5929 - val_accuracy: 0.8768\n","\n","Epoch 00123: val_accuracy did not improve from 0.89409\n","Epoch 124/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0644 - accuracy: 0.9829 - val_loss: 0.8670 - val_accuracy: 0.8473\n","\n","Epoch 00124: val_accuracy did not improve from 0.89409\n","Epoch 125/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0415 - accuracy: 0.9866 - val_loss: 1.2385 - val_accuracy: 0.7882\n","\n","Epoch 00125: val_accuracy did not improve from 0.89409\n","Epoch 126/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0363 - accuracy: 0.9878 - val_loss: 0.4657 - val_accuracy: 0.9039\n","\n","Epoch 00126: val_accuracy improved from 0.89409 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 127/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0887 - accuracy: 0.9720 - val_loss: 1.3682 - val_accuracy: 0.7414\n","\n","Epoch 00127: val_accuracy did not improve from 0.90394\n","Epoch 128/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.1010 - accuracy: 0.9635 - val_loss: 1.1704 - val_accuracy: 0.7931\n","\n","Epoch 00128: val_accuracy did not improve from 0.90394\n","Epoch 129/500\n","52/52 [==============================] - 22s 423ms/step - loss: 0.0438 - accuracy: 0.9854 - val_loss: 0.6015 - val_accuracy: 0.9039\n","\n","Epoch 00129: val_accuracy did not improve from 0.90394\n","Epoch 130/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0425 - accuracy: 0.9842 - val_loss: 0.9165 - val_accuracy: 0.8374\n","\n","Epoch 00130: val_accuracy did not improve from 0.90394\n","Epoch 131/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0408 - accuracy: 0.9860 - val_loss: 0.5234 - val_accuracy: 0.8768\n","\n","Epoch 00131: val_accuracy did not improve from 0.90394\n","Epoch 132/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0735 - accuracy: 0.9756 - val_loss: 0.6463 - val_accuracy: 0.8768\n","\n","Epoch 00132: val_accuracy did not improve from 0.90394\n","Epoch 133/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0306 - accuracy: 0.9909 - val_loss: 0.4565 - val_accuracy: 0.8916\n","\n","Epoch 00133: val_accuracy did not improve from 0.90394\n","Epoch 134/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0436 - accuracy: 0.9848 - val_loss: 0.4676 - val_accuracy: 0.8966\n","\n","Epoch 00134: val_accuracy did not improve from 0.90394\n","Epoch 135/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0430 - accuracy: 0.9866 - val_loss: 0.6463 - val_accuracy: 0.8547\n","\n","Epoch 00135: val_accuracy did not improve from 0.90394\n","Epoch 136/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0490 - accuracy: 0.9866 - val_loss: 0.5030 - val_accuracy: 0.8842\n","\n","Epoch 00136: val_accuracy did not improve from 0.90394\n","Epoch 137/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.4943 - val_accuracy: 0.9089\n","\n","Epoch 00137: val_accuracy improved from 0.90394 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 138/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.5598 - val_accuracy: 0.8892\n","\n","Epoch 00138: val_accuracy did not improve from 0.90887\n","Epoch 139/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0556 - accuracy: 0.9787 - val_loss: 0.6518 - val_accuracy: 0.8473\n","\n","Epoch 00139: val_accuracy did not improve from 0.90887\n","Epoch 140/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.2048 - accuracy: 0.9385 - val_loss: 13.4472 - val_accuracy: 0.3424\n","\n","Epoch 00140: val_accuracy did not improve from 0.90887\n","Epoch 141/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0899 - accuracy: 0.9714 - val_loss: 1.1311 - val_accuracy: 0.8227\n","\n","Epoch 00141: val_accuracy did not improve from 0.90887\n","Epoch 142/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0281 - accuracy: 0.9878 - val_loss: 0.9113 - val_accuracy: 0.8473\n","\n","Epoch 00142: val_accuracy did not improve from 0.90887\n","Epoch 143/500\n","52/52 [==============================] - 23s 438ms/step - loss: 0.0513 - accuracy: 0.9829 - val_loss: 0.4792 - val_accuracy: 0.8768\n","\n","Epoch 00143: val_accuracy did not improve from 0.90887\n","Epoch 144/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0501 - accuracy: 0.9848 - val_loss: 0.6269 - val_accuracy: 0.8793\n","\n","Epoch 00144: val_accuracy did not improve from 0.90887\n","Epoch 145/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0422 - accuracy: 0.9848 - val_loss: 0.7918 - val_accuracy: 0.8670\n","\n","Epoch 00145: val_accuracy did not improve from 0.90887\n","Epoch 146/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.5483 - val_accuracy: 0.8941\n","\n","Epoch 00146: val_accuracy did not improve from 0.90887\n","Epoch 147/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0370 - accuracy: 0.9872 - val_loss: 0.6326 - val_accuracy: 0.8645\n","\n","Epoch 00147: val_accuracy did not improve from 0.90887\n","Epoch 148/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.6795 - val_accuracy: 0.8522\n","\n","Epoch 00148: val_accuracy did not improve from 0.90887\n","Epoch 149/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0230 - accuracy: 0.9915 - val_loss: 0.4647 - val_accuracy: 0.8966\n","\n","Epoch 00149: val_accuracy did not improve from 0.90887\n","Epoch 150/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0277 - accuracy: 0.9903 - val_loss: 0.6604 - val_accuracy: 0.8842\n","\n","Epoch 00150: val_accuracy did not improve from 0.90887\n","Epoch 151/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.5247 - val_accuracy: 0.9064\n","\n","Epoch 00151: val_accuracy did not improve from 0.90887\n","Epoch 152/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0203 - accuracy: 0.9951 - val_loss: 0.5701 - val_accuracy: 0.8793\n","\n","Epoch 00152: val_accuracy did not improve from 0.90887\n","Epoch 153/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0550 - accuracy: 0.9805 - val_loss: 1.8001 - val_accuracy: 0.7340\n","\n","Epoch 00153: val_accuracy did not improve from 0.90887\n","Epoch 154/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1043 - accuracy: 0.9695 - val_loss: 1.6954 - val_accuracy: 0.7882\n","\n","Epoch 00154: val_accuracy did not improve from 0.90887\n","Epoch 155/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0485 - accuracy: 0.9842 - val_loss: 0.9876 - val_accuracy: 0.8473\n","\n","Epoch 00155: val_accuracy did not improve from 0.90887\n","Epoch 156/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0541 - accuracy: 0.9848 - val_loss: 0.7597 - val_accuracy: 0.8621\n","\n","Epoch 00156: val_accuracy did not improve from 0.90887\n","Epoch 157/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0599 - accuracy: 0.9836 - val_loss: 0.4642 - val_accuracy: 0.8842\n","\n","Epoch 00157: val_accuracy did not improve from 0.90887\n","Epoch 158/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0708 - accuracy: 0.9756 - val_loss: 0.9384 - val_accuracy: 0.8374\n","\n","Epoch 00158: val_accuracy did not improve from 0.90887\n","Epoch 159/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0648 - accuracy: 0.9811 - val_loss: 0.7974 - val_accuracy: 0.8867\n","\n","Epoch 00159: val_accuracy did not improve from 0.90887\n","Epoch 160/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0415 - accuracy: 0.9848 - val_loss: 0.8290 - val_accuracy: 0.8621\n","\n","Epoch 00160: val_accuracy did not improve from 0.90887\n","Epoch 161/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0283 - accuracy: 0.9921 - val_loss: 0.6221 - val_accuracy: 0.9015\n","\n","Epoch 00161: val_accuracy did not improve from 0.90887\n","Epoch 162/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0171 - accuracy: 0.9933 - val_loss: 0.5730 - val_accuracy: 0.8818\n","\n","Epoch 00162: val_accuracy did not improve from 0.90887\n","Epoch 163/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.4633 - val_accuracy: 0.8990\n","\n","Epoch 00163: val_accuracy did not improve from 0.90887\n","Epoch 164/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.4614 - val_accuracy: 0.8990\n","\n","Epoch 00164: val_accuracy did not improve from 0.90887\n","Epoch 165/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.5135 - val_accuracy: 0.9064\n","\n","Epoch 00165: val_accuracy did not improve from 0.90887\n","Epoch 166/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.4531 - val_accuracy: 0.9064\n","\n","Epoch 00166: val_accuracy did not improve from 0.90887\n","Epoch 167/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0148 - accuracy: 0.9939 - val_loss: 0.4454 - val_accuracy: 0.8990\n","\n","Epoch 00167: val_accuracy did not improve from 0.90887\n","Epoch 168/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.4652 - val_accuracy: 0.9089\n","\n","Epoch 00168: val_accuracy did not improve from 0.90887\n","Epoch 169/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.8381 - val_accuracy: 0.8596\n","\n","Epoch 00169: val_accuracy did not improve from 0.90887\n","Epoch 170/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.1476 - accuracy: 0.9604 - val_loss: 8.1114 - val_accuracy: 0.4064\n","\n","Epoch 00170: val_accuracy did not improve from 0.90887\n","Epoch 171/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1137 - accuracy: 0.9683 - val_loss: 0.5857 - val_accuracy: 0.8448\n","\n","Epoch 00171: val_accuracy did not improve from 0.90887\n","Epoch 172/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0704 - accuracy: 0.9793 - val_loss: 1.5772 - val_accuracy: 0.7906\n","\n","Epoch 00172: val_accuracy did not improve from 0.90887\n","Epoch 173/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0456 - accuracy: 0.9890 - val_loss: 0.5535 - val_accuracy: 0.8867\n","\n","Epoch 00173: val_accuracy did not improve from 0.90887\n","Epoch 174/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.5078 - val_accuracy: 0.8990\n","\n","Epoch 00174: val_accuracy did not improve from 0.90887\n","Epoch 175/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0191 - accuracy: 0.9921 - val_loss: 0.4554 - val_accuracy: 0.8842\n","\n","Epoch 00175: val_accuracy did not improve from 0.90887\n","Epoch 176/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0433 - accuracy: 0.9848 - val_loss: 0.5977 - val_accuracy: 0.8768\n","\n","Epoch 00176: val_accuracy did not improve from 0.90887\n","Epoch 177/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0630 - accuracy: 0.9793 - val_loss: 0.8072 - val_accuracy: 0.8498\n","\n","Epoch 00177: val_accuracy did not improve from 0.90887\n","Epoch 178/500\n","52/52 [==============================] - 22s 424ms/step - loss: 0.1234 - accuracy: 0.9647 - val_loss: 1.5718 - val_accuracy: 0.7365\n","\n","Epoch 00178: val_accuracy did not improve from 0.90887\n","Epoch 179/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1045 - accuracy: 0.9659 - val_loss: 0.6001 - val_accuracy: 0.8768\n","\n","Epoch 00179: val_accuracy did not improve from 0.90887\n","Epoch 180/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0433 - accuracy: 0.9848 - val_loss: 0.5567 - val_accuracy: 0.8744\n","\n","Epoch 00180: val_accuracy did not improve from 0.90887\n","Epoch 181/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0273 - accuracy: 0.9927 - val_loss: 0.5343 - val_accuracy: 0.8695\n","\n","Epoch 00181: val_accuracy did not improve from 0.90887\n","Epoch 182/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.3837 - val_accuracy: 0.9113\n","\n","Epoch 00182: val_accuracy improved from 0.90887 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 183/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.4482 - val_accuracy: 0.9039\n","\n","Epoch 00183: val_accuracy did not improve from 0.91133\n","Epoch 184/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.4200 - val_accuracy: 0.9138\n","\n","Epoch 00184: val_accuracy improved from 0.91133 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 185/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5157 - val_accuracy: 0.8990\n","\n","Epoch 00185: val_accuracy did not improve from 0.91379\n","Epoch 186/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0414 - accuracy: 0.9890 - val_loss: 0.5275 - val_accuracy: 0.8842\n","\n","Epoch 00186: val_accuracy did not improve from 0.91379\n","Epoch 187/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0525 - accuracy: 0.9817 - val_loss: 14.1545 - val_accuracy: 0.2685\n","\n","Epoch 00187: val_accuracy did not improve from 0.91379\n","Epoch 188/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0636 - accuracy: 0.9799 - val_loss: 1.7250 - val_accuracy: 0.7438\n","\n","Epoch 00188: val_accuracy did not improve from 0.91379\n","Epoch 189/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0828 - accuracy: 0.9683 - val_loss: 1.2530 - val_accuracy: 0.8079\n","\n","Epoch 00189: val_accuracy did not improve from 0.91379\n","Epoch 190/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0838 - accuracy: 0.9738 - val_loss: 0.7145 - val_accuracy: 0.8547\n","\n","Epoch 00190: val_accuracy did not improve from 0.91379\n","Epoch 191/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0369 - accuracy: 0.9872 - val_loss: 0.7613 - val_accuracy: 0.8670\n","\n","Epoch 00191: val_accuracy did not improve from 0.91379\n","Epoch 192/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0380 - accuracy: 0.9854 - val_loss: 0.5421 - val_accuracy: 0.8818\n","\n","Epoch 00192: val_accuracy did not improve from 0.91379\n","Epoch 193/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0230 - accuracy: 0.9909 - val_loss: 0.5791 - val_accuracy: 0.8645\n","\n","Epoch 00193: val_accuracy did not improve from 0.91379\n","Epoch 194/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0340 - accuracy: 0.9884 - val_loss: 0.5144 - val_accuracy: 0.8990\n","\n","Epoch 00194: val_accuracy did not improve from 0.91379\n","Epoch 195/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0169 - accuracy: 0.9927 - val_loss: 0.5124 - val_accuracy: 0.8867\n","\n","Epoch 00195: val_accuracy did not improve from 0.91379\n","Epoch 196/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.5827 - val_accuracy: 0.8892\n","\n","Epoch 00196: val_accuracy did not improve from 0.91379\n","Epoch 197/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.6960 - val_accuracy: 0.8768\n","\n","Epoch 00197: val_accuracy did not improve from 0.91379\n","Epoch 198/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0370 - accuracy: 0.9903 - val_loss: 1.1186 - val_accuracy: 0.8276\n","\n","Epoch 00198: val_accuracy did not improve from 0.91379\n","Epoch 199/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0474 - accuracy: 0.9842 - val_loss: 0.7825 - val_accuracy: 0.8621\n","\n","Epoch 00199: val_accuracy did not improve from 0.91379\n","Epoch 200/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0402 - accuracy: 0.9854 - val_loss: 0.6834 - val_accuracy: 0.8916\n","\n","Epoch 00200: val_accuracy did not improve from 0.91379\n","Epoch 201/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.6913 - val_accuracy: 0.8768\n","\n","Epoch 00201: val_accuracy did not improve from 0.91379\n","Epoch 202/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0223 - accuracy: 0.9909 - val_loss: 0.5284 - val_accuracy: 0.9089\n","\n","Epoch 00202: val_accuracy did not improve from 0.91379\n","Epoch 203/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.7292 - val_accuracy: 0.8768\n","\n","Epoch 00203: val_accuracy did not improve from 0.91379\n","Epoch 204/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.4889 - val_accuracy: 0.9039\n","\n","Epoch 00204: val_accuracy did not improve from 0.91379\n","Epoch 205/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.4400 - val_accuracy: 0.8842\n","\n","Epoch 00205: val_accuracy did not improve from 0.91379\n","Epoch 206/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0377 - accuracy: 0.9866 - val_loss: 0.5751 - val_accuracy: 0.8966\n","\n","Epoch 00206: val_accuracy did not improve from 0.91379\n","Epoch 207/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0359 - accuracy: 0.9903 - val_loss: 0.6222 - val_accuracy: 0.8842\n","\n","Epoch 00207: val_accuracy did not improve from 0.91379\n","Epoch 208/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.5731 - val_accuracy: 0.9163\n","\n","Epoch 00208: val_accuracy improved from 0.91379 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 209/500\n","52/52 [==============================] - 22s 429ms/step - loss: 0.0198 - accuracy: 0.9921 - val_loss: 0.5758 - val_accuracy: 0.8916\n","\n","Epoch 00209: val_accuracy did not improve from 0.91626\n","Epoch 210/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.5369 - val_accuracy: 0.8990\n","\n","Epoch 00210: val_accuracy did not improve from 0.91626\n","Epoch 211/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.7330 - val_accuracy: 0.8768\n","\n","Epoch 00211: val_accuracy did not improve from 0.91626\n","Epoch 212/500\n","52/52 [==============================] - 22s 429ms/step - loss: 0.0265 - accuracy: 0.9903 - val_loss: 0.7850 - val_accuracy: 0.8645\n","\n","Epoch 00212: val_accuracy did not improve from 0.91626\n","Epoch 213/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0535 - accuracy: 0.9866 - val_loss: 14.9317 - val_accuracy: 0.2340\n","\n","Epoch 00213: val_accuracy did not improve from 0.91626\n","Epoch 214/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0330 - accuracy: 0.9909 - val_loss: 0.7616 - val_accuracy: 0.8719\n","\n","Epoch 00214: val_accuracy did not improve from 0.91626\n","Epoch 215/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0452 - accuracy: 0.9890 - val_loss: 0.7564 - val_accuracy: 0.8621\n","\n","Epoch 00215: val_accuracy did not improve from 0.91626\n","Epoch 216/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.7220 - val_accuracy: 0.8916\n","\n","Epoch 00216: val_accuracy did not improve from 0.91626\n","Epoch 217/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.5884 - val_accuracy: 0.8818\n","\n","Epoch 00217: val_accuracy did not improve from 0.91626\n","Epoch 218/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0204 - accuracy: 0.9915 - val_loss: 0.4610 - val_accuracy: 0.9089\n","\n","Epoch 00218: val_accuracy did not improve from 0.91626\n","Epoch 219/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.4734 - val_accuracy: 0.9113\n","\n","Epoch 00219: val_accuracy did not improve from 0.91626\n","Epoch 220/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.5359 - val_accuracy: 0.9089\n","\n","Epoch 00220: val_accuracy did not improve from 0.91626\n","Epoch 221/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.6124 - val_accuracy: 0.9039\n","\n","Epoch 00221: val_accuracy did not improve from 0.91626\n","Epoch 222/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0759 - accuracy: 0.9805 - val_loss: 1.0329 - val_accuracy: 0.8473\n","\n","Epoch 00222: val_accuracy did not improve from 0.91626\n","Epoch 223/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0410 - accuracy: 0.9872 - val_loss: 1.4016 - val_accuracy: 0.7906\n","\n","Epoch 00223: val_accuracy did not improve from 0.91626\n","Epoch 224/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0424 - accuracy: 0.9842 - val_loss: 0.6344 - val_accuracy: 0.8990\n","\n","Epoch 00224: val_accuracy did not improve from 0.91626\n","Epoch 225/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.5158 - val_accuracy: 0.9064\n","\n","Epoch 00225: val_accuracy did not improve from 0.91626\n","Epoch 226/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.4302 - val_accuracy: 0.9113\n","\n","Epoch 00226: val_accuracy did not improve from 0.91626\n","Epoch 227/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.6227 - val_accuracy: 0.8793\n","\n","Epoch 00227: val_accuracy did not improve from 0.91626\n","Epoch 228/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0143 - accuracy: 0.9933 - val_loss: 0.6958 - val_accuracy: 0.8744\n","\n","Epoch 00228: val_accuracy did not improve from 0.91626\n","Epoch 229/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.4890 - val_accuracy: 0.9138\n","\n","Epoch 00229: val_accuracy did not improve from 0.91626\n","Epoch 230/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0401 - accuracy: 0.9842 - val_loss: 1.2060 - val_accuracy: 0.7956\n","\n","Epoch 00230: val_accuracy did not improve from 0.91626\n","Epoch 231/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0881 - accuracy: 0.9720 - val_loss: 2.8125 - val_accuracy: 0.6823\n","\n","Epoch 00231: val_accuracy did not improve from 0.91626\n","Epoch 232/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0764 - accuracy: 0.9775 - val_loss: 24.5790 - val_accuracy: 0.1207\n","\n","Epoch 00232: val_accuracy did not improve from 0.91626\n","Epoch 233/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0383 - accuracy: 0.9878 - val_loss: 0.7266 - val_accuracy: 0.8842\n","\n","Epoch 00233: val_accuracy did not improve from 0.91626\n","Epoch 234/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.4721 - val_accuracy: 0.8990\n","\n","Epoch 00234: val_accuracy did not improve from 0.91626\n","Epoch 235/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.4950 - val_accuracy: 0.9015\n","\n","Epoch 00235: val_accuracy did not improve from 0.91626\n","Epoch 236/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.4587 - val_accuracy: 0.8990\n","\n","Epoch 00236: val_accuracy did not improve from 0.91626\n","Epoch 237/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.4237 - val_accuracy: 0.9064\n","\n","Epoch 00237: val_accuracy did not improve from 0.91626\n","Epoch 238/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0136 - accuracy: 0.9945 - val_loss: 0.5676 - val_accuracy: 0.8966\n","\n","Epoch 00238: val_accuracy did not improve from 0.91626\n","Epoch 239/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.4620 - val_accuracy: 0.9064\n","\n","Epoch 00239: val_accuracy did not improve from 0.91626\n","Epoch 240/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 0.4756 - val_accuracy: 0.9089\n","\n","Epoch 00240: val_accuracy did not improve from 0.91626\n","Epoch 241/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0210 - accuracy: 0.9915 - val_loss: 0.7346 - val_accuracy: 0.8670\n","\n","Epoch 00241: val_accuracy did not improve from 0.91626\n","Epoch 242/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.4369 - val_accuracy: 0.9089\n","\n","Epoch 00242: val_accuracy did not improve from 0.91626\n","Epoch 243/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.4861 - val_accuracy: 0.8941\n","\n","Epoch 00243: val_accuracy did not improve from 0.91626\n","Epoch 244/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.8430 - val_accuracy: 0.8670\n","\n","Epoch 00244: val_accuracy did not improve from 0.91626\n","Epoch 245/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0252 - accuracy: 0.9945 - val_loss: 0.6005 - val_accuracy: 0.8916\n","\n","Epoch 00245: val_accuracy did not improve from 0.91626\n","Epoch 246/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0395 - accuracy: 0.9903 - val_loss: 0.7647 - val_accuracy: 0.8818\n","\n","Epoch 00246: val_accuracy did not improve from 0.91626\n","Epoch 247/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0554 - accuracy: 0.9866 - val_loss: 0.5262 - val_accuracy: 0.8941\n","\n","Epoch 00247: val_accuracy did not improve from 0.91626\n","Epoch 248/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0409 - accuracy: 0.9866 - val_loss: 0.5960 - val_accuracy: 0.8892\n","\n","Epoch 00248: val_accuracy did not improve from 0.91626\n","Epoch 249/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.6311 - val_accuracy: 0.8966\n","\n","Epoch 00249: val_accuracy did not improve from 0.91626\n","Epoch 250/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.6416 - val_accuracy: 0.8818\n","\n","Epoch 00250: val_accuracy did not improve from 0.91626\n","Epoch 251/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.4693 - val_accuracy: 0.9212\n","\n","Epoch 00251: val_accuracy improved from 0.91626 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 252/500\n","52/52 [==============================] - 22s 429ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.5033 - val_accuracy: 0.8990\n","\n","Epoch 00252: val_accuracy did not improve from 0.92118\n","Epoch 253/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.9138\n","\n","Epoch 00253: val_accuracy did not improve from 0.92118\n","Epoch 254/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0215 - accuracy: 0.9951 - val_loss: 0.7402 - val_accuracy: 0.8793\n","\n","Epoch 00254: val_accuracy did not improve from 0.92118\n","Epoch 255/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.6592 - val_accuracy: 0.8941\n","\n","Epoch 00255: val_accuracy did not improve from 0.92118\n","Epoch 256/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.5907 - val_accuracy: 0.8867\n","\n","Epoch 00256: val_accuracy did not improve from 0.92118\n","Epoch 257/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.5115 - val_accuracy: 0.8966\n","\n","Epoch 00257: val_accuracy did not improve from 0.92118\n","Epoch 258/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.4940 - val_accuracy: 0.8941\n","\n","Epoch 00258: val_accuracy did not improve from 0.92118\n","Epoch 259/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.4732 - val_accuracy: 0.9163\n","\n","Epoch 00259: val_accuracy did not improve from 0.92118\n","Epoch 260/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.6859 - val_accuracy: 0.8719\n","\n","Epoch 00260: val_accuracy did not improve from 0.92118\n","Epoch 261/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0368 - accuracy: 0.9878 - val_loss: 0.9160 - val_accuracy: 0.8547\n","\n","Epoch 00261: val_accuracy did not improve from 0.92118\n","Epoch 262/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0915 - accuracy: 0.9769 - val_loss: 0.8093 - val_accuracy: 0.8793\n","\n","Epoch 00262: val_accuracy did not improve from 0.92118\n","Epoch 263/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0863 - accuracy: 0.9762 - val_loss: 1.1303 - val_accuracy: 0.8251\n","\n","Epoch 00263: val_accuracy did not improve from 0.92118\n","Epoch 264/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0379 - accuracy: 0.9854 - val_loss: 0.5924 - val_accuracy: 0.8916\n","\n","Epoch 00264: val_accuracy did not improve from 0.92118\n","Epoch 265/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 1.0420 - val_accuracy: 0.8498\n","\n","Epoch 00265: val_accuracy did not improve from 0.92118\n","Epoch 266/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0128 - accuracy: 0.9939 - val_loss: 0.6594 - val_accuracy: 0.8842\n","\n","Epoch 00266: val_accuracy did not improve from 0.92118\n","Epoch 267/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.5596 - val_accuracy: 0.8966\n","\n","Epoch 00267: val_accuracy did not improve from 0.92118\n","Epoch 268/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.3807 - val_accuracy: 0.9187\n","\n","Epoch 00268: val_accuracy did not improve from 0.92118\n","Epoch 269/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.4789 - val_accuracy: 0.9212\n","\n","Epoch 00269: val_accuracy did not improve from 0.92118\n","Epoch 270/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.4814 - val_accuracy: 0.9064\n","\n","Epoch 00270: val_accuracy did not improve from 0.92118\n","Epoch 271/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.5333 - val_accuracy: 0.8966\n","\n","Epoch 00271: val_accuracy did not improve from 0.92118\n","Epoch 272/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.5285 - val_accuracy: 0.9039\n","\n","Epoch 00272: val_accuracy did not improve from 0.92118\n","Epoch 273/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9138\n","\n","Epoch 00273: val_accuracy did not improve from 0.92118\n","Epoch 274/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.5325 - val_accuracy: 0.8941\n","\n","Epoch 00274: val_accuracy did not improve from 0.92118\n","Epoch 275/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.4249 - val_accuracy: 0.9212\n","\n","Epoch 00275: val_accuracy did not improve from 0.92118\n","Epoch 276/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.5048 - val_accuracy: 0.8990\n","\n","Epoch 00276: val_accuracy did not improve from 0.92118\n","Epoch 277/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.4981 - val_accuracy: 0.9212\n","\n","Epoch 00277: val_accuracy did not improve from 0.92118\n","Epoch 278/500\n","52/52 [==============================] - 22s 429ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.4541 - val_accuracy: 0.9163\n","\n","Epoch 00278: val_accuracy did not improve from 0.92118\n","Epoch 279/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.6439 - val_accuracy: 0.8768\n","\n","Epoch 00279: val_accuracy did not improve from 0.92118\n","Epoch 280/500\n","52/52 [==============================] - 22s 430ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.6057 - val_accuracy: 0.8966\n","\n","Epoch 00280: val_accuracy did not improve from 0.92118\n","Epoch 281/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5412 - val_accuracy: 0.8966\n","\n","Epoch 00281: val_accuracy did not improve from 0.92118\n","Epoch 282/500\n","52/52 [==============================] - 22s 428ms/step - loss: 8.5806e-04 - accuracy: 1.0000 - val_loss: 0.5152 - val_accuracy: 0.9064\n","\n","Epoch 00282: val_accuracy did not improve from 0.92118\n","Epoch 283/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5615 - val_accuracy: 0.9089\n","\n","Epoch 00283: val_accuracy did not improve from 0.92118\n","Epoch 284/500\n","52/52 [==============================] - 22s 426ms/step - loss: 8.1201e-04 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.9064\n","\n","Epoch 00284: val_accuracy did not improve from 0.92118\n","Epoch 285/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5693 - val_accuracy: 0.9187\n","\n","Epoch 00285: val_accuracy did not improve from 0.92118\n","Epoch 286/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.5257 - val_accuracy: 0.9113\n","\n","Epoch 00286: val_accuracy did not improve from 0.92118\n","Epoch 287/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5483 - val_accuracy: 0.9089\n","\n","Epoch 00287: val_accuracy did not improve from 0.92118\n","Epoch 288/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.7273 - val_accuracy: 0.8842\n","\n","Epoch 00288: val_accuracy did not improve from 0.92118\n","Epoch 289/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.1592 - accuracy: 0.9586 - val_loss: 2.8799 - val_accuracy: 0.7586\n","\n","Epoch 00289: val_accuracy did not improve from 0.92118\n","Epoch 290/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.1367 - accuracy: 0.9555 - val_loss: 8.7491 - val_accuracy: 0.3719\n","\n","Epoch 00290: val_accuracy did not improve from 0.92118\n","Epoch 291/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.1365 - accuracy: 0.9604 - val_loss: 1.2398 - val_accuracy: 0.8202\n","\n","Epoch 00291: val_accuracy did not improve from 0.92118\n","Epoch 292/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0458 - accuracy: 0.9836 - val_loss: 1.0040 - val_accuracy: 0.8227\n","\n","Epoch 00292: val_accuracy did not improve from 0.92118\n","Epoch 293/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0358 - accuracy: 0.9896 - val_loss: 0.5131 - val_accuracy: 0.8941\n","\n","Epoch 00293: val_accuracy did not improve from 0.92118\n","Epoch 294/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.5311 - val_accuracy: 0.9064\n","\n","Epoch 00294: val_accuracy did not improve from 0.92118\n","Epoch 295/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.4776 - val_accuracy: 0.9089\n","\n","Epoch 00295: val_accuracy did not improve from 0.92118\n","Epoch 296/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.5116 - val_accuracy: 0.8916\n","\n","Epoch 00296: val_accuracy did not improve from 0.92118\n","Epoch 297/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.5156 - val_accuracy: 0.9064\n","\n","Epoch 00297: val_accuracy did not improve from 0.92118\n","Epoch 298/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.4797 - val_accuracy: 0.9039\n","\n","Epoch 00298: val_accuracy did not improve from 0.92118\n","Epoch 299/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4355 - val_accuracy: 0.9236\n","\n","Epoch 00299: val_accuracy improved from 0.92118 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 300/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.4651 - val_accuracy: 0.9212\n","\n","Epoch 00300: val_accuracy did not improve from 0.92365\n","Epoch 301/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.5945 - val_accuracy: 0.8990\n","\n","Epoch 00301: val_accuracy did not improve from 0.92365\n","Epoch 302/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.5363 - val_accuracy: 0.9187\n","\n","Epoch 00302: val_accuracy did not improve from 0.92365\n","Epoch 303/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.4894 - val_accuracy: 0.8941\n","\n","Epoch 00303: val_accuracy did not improve from 0.92365\n","Epoch 304/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4811 - val_accuracy: 0.9089\n","\n","Epoch 00304: val_accuracy did not improve from 0.92365\n","Epoch 305/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 3.2930 - val_accuracy: 0.6478\n","\n","Epoch 00305: val_accuracy did not improve from 0.92365\n","Epoch 306/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5643 - val_accuracy: 0.9039\n","\n","Epoch 00306: val_accuracy did not improve from 0.92365\n","Epoch 307/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5211 - val_accuracy: 0.9138\n","\n","Epoch 00307: val_accuracy did not improve from 0.92365\n","Epoch 308/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5452 - val_accuracy: 0.8916\n","\n","Epoch 00308: val_accuracy did not improve from 0.92365\n","Epoch 309/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.5691 - val_accuracy: 0.8990\n","\n","Epoch 00309: val_accuracy did not improve from 0.92365\n","Epoch 310/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.5536 - val_accuracy: 0.9039\n","\n","Epoch 00310: val_accuracy did not improve from 0.92365\n","Epoch 311/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.5245 - val_accuracy: 0.9015\n","\n","Epoch 00311: val_accuracy did not improve from 0.92365\n","Epoch 312/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.5445 - val_accuracy: 0.8990\n","\n","Epoch 00312: val_accuracy did not improve from 0.92365\n","Epoch 313/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0491 - accuracy: 0.9860 - val_loss: 0.7922 - val_accuracy: 0.8596\n","\n","Epoch 00313: val_accuracy did not improve from 0.92365\n","Epoch 314/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0485 - accuracy: 0.9817 - val_loss: 4.9059 - val_accuracy: 0.5911\n","\n","Epoch 00314: val_accuracy did not improve from 0.92365\n","Epoch 315/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0948 - accuracy: 0.9750 - val_loss: 5.4726 - val_accuracy: 0.5394\n","\n","Epoch 00315: val_accuracy did not improve from 0.92365\n","Epoch 316/500\n","52/52 [==============================] - 22s 429ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 0.6894 - val_accuracy: 0.8842\n","\n","Epoch 00316: val_accuracy did not improve from 0.92365\n","Epoch 317/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0238 - accuracy: 0.9909 - val_loss: 0.6059 - val_accuracy: 0.8793\n","\n","Epoch 00317: val_accuracy did not improve from 0.92365\n","Epoch 318/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.6113 - val_accuracy: 0.8941\n","\n","Epoch 00318: val_accuracy did not improve from 0.92365\n","Epoch 319/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.5726 - val_accuracy: 0.8990\n","\n","Epoch 00319: val_accuracy did not improve from 0.92365\n","Epoch 320/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.5405 - val_accuracy: 0.8842\n","\n","Epoch 00320: val_accuracy did not improve from 0.92365\n","Epoch 321/500\n","52/52 [==============================] - 22s 429ms/step - loss: 0.0165 - accuracy: 0.9963 - val_loss: 0.6808 - val_accuracy: 0.8793\n","\n","Epoch 00321: val_accuracy did not improve from 0.92365\n","Epoch 322/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.5251 - val_accuracy: 0.9138\n","\n","Epoch 00322: val_accuracy did not improve from 0.92365\n","Epoch 323/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.4404 - val_accuracy: 0.9064\n","\n","Epoch 00323: val_accuracy did not improve from 0.92365\n","Epoch 324/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4299 - val_accuracy: 0.9236\n","\n","Epoch 00324: val_accuracy did not improve from 0.92365\n","Epoch 325/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.4456 - val_accuracy: 0.9163\n","\n","Epoch 00325: val_accuracy did not improve from 0.92365\n","Epoch 326/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4467 - val_accuracy: 0.9187\n","\n","Epoch 00326: val_accuracy did not improve from 0.92365\n","Epoch 327/500\n","52/52 [==============================] - 22s 427ms/step - loss: 7.7733e-04 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9286\n","\n","Epoch 00327: val_accuracy improved from 0.92365 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 328/500\n","52/52 [==============================] - 22s 428ms/step - loss: 8.3488e-04 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.9261\n","\n","Epoch 00328: val_accuracy did not improve from 0.92857\n","Epoch 329/500\n","52/52 [==============================] - 22s 426ms/step - loss: 5.1892e-04 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9360\n","\n","Epoch 00329: val_accuracy improved from 0.92857 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5\n","Epoch 330/500\n","52/52 [==============================] - 22s 427ms/step - loss: 7.3827e-04 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.9236\n","\n","Epoch 00330: val_accuracy did not improve from 0.93596\n","Epoch 331/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4658 - val_accuracy: 0.9138\n","\n","Epoch 00331: val_accuracy did not improve from 0.93596\n","Epoch 332/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4719 - val_accuracy: 0.9187\n","\n","Epoch 00332: val_accuracy did not improve from 0.93596\n","Epoch 333/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4328 - val_accuracy: 0.9236\n","\n","Epoch 00333: val_accuracy did not improve from 0.93596\n","Epoch 334/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5385 - val_accuracy: 0.9163\n","\n","Epoch 00334: val_accuracy did not improve from 0.93596\n","Epoch 335/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.5271 - val_accuracy: 0.9187\n","\n","Epoch 00335: val_accuracy did not improve from 0.93596\n","Epoch 336/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.4082 - val_accuracy: 0.9187\n","\n","Epoch 00336: val_accuracy did not improve from 0.93596\n","Epoch 337/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.5295 - val_accuracy: 0.8990\n","\n","Epoch 00337: val_accuracy did not improve from 0.93596\n","Epoch 338/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5641 - val_accuracy: 0.9015\n","\n","Epoch 00338: val_accuracy did not improve from 0.93596\n","Epoch 339/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.6798 - val_accuracy: 0.9039\n","\n","Epoch 00339: val_accuracy did not improve from 0.93596\n","Epoch 340/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.7017 - val_accuracy: 0.8892\n","\n","Epoch 00340: val_accuracy did not improve from 0.93596\n","Epoch 341/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0295 - accuracy: 0.9884 - val_loss: 0.7623 - val_accuracy: 0.8695\n","\n","Epoch 00341: val_accuracy did not improve from 0.93596\n","Epoch 342/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0404 - accuracy: 0.9854 - val_loss: 0.7964 - val_accuracy: 0.8842\n","\n","Epoch 00342: val_accuracy did not improve from 0.93596\n","Epoch 343/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0399 - accuracy: 0.9884 - val_loss: 34.5521 - val_accuracy: 0.0936\n","\n","Epoch 00343: val_accuracy did not improve from 0.93596\n","Epoch 344/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.7034 - val_accuracy: 0.8448\n","\n","Epoch 00344: val_accuracy did not improve from 0.93596\n","Epoch 345/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0308 - accuracy: 0.9866 - val_loss: 0.7407 - val_accuracy: 0.8867\n","\n","Epoch 00345: val_accuracy did not improve from 0.93596\n","Epoch 346/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.8989 - val_accuracy: 0.8645\n","\n","Epoch 00346: val_accuracy did not improve from 0.93596\n","Epoch 347/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0149 - accuracy: 0.9939 - val_loss: 0.9393 - val_accuracy: 0.8621\n","\n","Epoch 00347: val_accuracy did not improve from 0.93596\n","Epoch 348/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 0.6357 - val_accuracy: 0.8892\n","\n","Epoch 00348: val_accuracy did not improve from 0.93596\n","Epoch 349/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.5642 - val_accuracy: 0.9113\n","\n","Epoch 00349: val_accuracy did not improve from 0.93596\n","Epoch 350/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.4455 - val_accuracy: 0.9089\n","\n","Epoch 00350: val_accuracy did not improve from 0.93596\n","Epoch 351/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.4898 - val_accuracy: 0.9138\n","\n","Epoch 00351: val_accuracy did not improve from 0.93596\n","Epoch 352/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.5624 - val_accuracy: 0.9064\n","\n","Epoch 00352: val_accuracy did not improve from 0.93596\n","Epoch 353/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.4841 - val_accuracy: 0.9212\n","\n","Epoch 00353: val_accuracy did not improve from 0.93596\n","Epoch 354/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.6139 - val_accuracy: 0.9039\n","\n","Epoch 00354: val_accuracy did not improve from 0.93596\n","Epoch 355/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.9064\n","\n","Epoch 00355: val_accuracy did not improve from 0.93596\n","Epoch 356/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.9163\n","\n","Epoch 00356: val_accuracy did not improve from 0.93596\n","Epoch 357/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0346 - accuracy: 0.9909 - val_loss: 0.9534 - val_accuracy: 0.8596\n","\n","Epoch 00357: val_accuracy did not improve from 0.93596\n","Epoch 358/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0323 - accuracy: 0.9872 - val_loss: 1.7969 - val_accuracy: 0.7956\n","\n","Epoch 00358: val_accuracy did not improve from 0.93596\n","Epoch 359/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0516 - accuracy: 0.9866 - val_loss: 0.9879 - val_accuracy: 0.8571\n","\n","Epoch 00359: val_accuracy did not improve from 0.93596\n","Epoch 360/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 11.4338 - val_accuracy: 0.3571\n","\n","Epoch 00360: val_accuracy did not improve from 0.93596\n","Epoch 361/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 3.3661 - val_accuracy: 0.6502\n","\n","Epoch 00361: val_accuracy did not improve from 0.93596\n","Epoch 362/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0062 - accuracy: 0.9970 - val_loss: 0.6286 - val_accuracy: 0.8990\n","\n","Epoch 00362: val_accuracy did not improve from 0.93596\n","Epoch 363/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5252 - val_accuracy: 0.9064\n","\n","Epoch 00363: val_accuracy did not improve from 0.93596\n","Epoch 364/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.6475 - val_accuracy: 0.8966\n","\n","Epoch 00364: val_accuracy did not improve from 0.93596\n","Epoch 365/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.6651 - val_accuracy: 0.8966\n","\n","Epoch 00365: val_accuracy did not improve from 0.93596\n","Epoch 366/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0364 - accuracy: 0.9896 - val_loss: 0.6618 - val_accuracy: 0.8818\n","\n","Epoch 00366: val_accuracy did not improve from 0.93596\n","Epoch 367/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0364 - accuracy: 0.9903 - val_loss: 0.7727 - val_accuracy: 0.8645\n","\n","Epoch 00367: val_accuracy did not improve from 0.93596\n","Epoch 368/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.5460 - val_accuracy: 0.9015\n","\n","Epoch 00368: val_accuracy did not improve from 0.93596\n","Epoch 369/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 2.2501 - val_accuracy: 0.7635\n","\n","Epoch 00369: val_accuracy did not improve from 0.93596\n","Epoch 370/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.4570 - val_accuracy: 0.9310\n","\n","Epoch 00370: val_accuracy did not improve from 0.93596\n","Epoch 371/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4572 - val_accuracy: 0.9212\n","\n","Epoch 00371: val_accuracy did not improve from 0.93596\n","Epoch 372/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5386 - val_accuracy: 0.9089\n","\n","Epoch 00372: val_accuracy did not improve from 0.93596\n","Epoch 373/500\n","52/52 [==============================] - 22s 426ms/step - loss: 9.1180e-04 - accuracy: 1.0000 - val_loss: 0.5219 - val_accuracy: 0.9039\n","\n","Epoch 00373: val_accuracy did not improve from 0.93596\n","Epoch 374/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5650 - val_accuracy: 0.8916\n","\n","Epoch 00374: val_accuracy did not improve from 0.93596\n","Epoch 375/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 2.2798 - val_accuracy: 0.7291\n","\n","Epoch 00375: val_accuracy did not improve from 0.93596\n","Epoch 376/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.5119 - val_accuracy: 0.9089\n","\n","Epoch 00376: val_accuracy did not improve from 0.93596\n","Epoch 377/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0293 - accuracy: 0.9921 - val_loss: 0.6855 - val_accuracy: 0.8768\n","\n","Epoch 00377: val_accuracy did not improve from 0.93596\n","Epoch 378/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.5778 - val_accuracy: 0.9064\n","\n","Epoch 00378: val_accuracy did not improve from 0.93596\n","Epoch 379/500\n","52/52 [==============================] - 22s 429ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.6195 - val_accuracy: 0.9089\n","\n","Epoch 00379: val_accuracy did not improve from 0.93596\n","Epoch 380/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0200 - accuracy: 0.9957 - val_loss: 1.1500 - val_accuracy: 0.8153\n","\n","Epoch 00380: val_accuracy did not improve from 0.93596\n","Epoch 381/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0624 - accuracy: 0.9805 - val_loss: 30.9485 - val_accuracy: 0.1084\n","\n","Epoch 00381: val_accuracy did not improve from 0.93596\n","Epoch 382/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0281 - accuracy: 0.9884 - val_loss: 0.7350 - val_accuracy: 0.8768\n","\n","Epoch 00382: val_accuracy did not improve from 0.93596\n","Epoch 383/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0214 - accuracy: 0.9921 - val_loss: 0.6142 - val_accuracy: 0.9064\n","\n","Epoch 00383: val_accuracy did not improve from 0.93596\n","Epoch 384/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0362 - accuracy: 0.9909 - val_loss: 7.7729 - val_accuracy: 0.4557\n","\n","Epoch 00384: val_accuracy did not improve from 0.93596\n","Epoch 385/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.5312 - val_accuracy: 0.8966\n","\n","Epoch 00385: val_accuracy did not improve from 0.93596\n","Epoch 386/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5074 - val_accuracy: 0.9212\n","\n","Epoch 00386: val_accuracy did not improve from 0.93596\n","Epoch 387/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0275 - accuracy: 0.9903 - val_loss: 0.6740 - val_accuracy: 0.8990\n","\n","Epoch 00387: val_accuracy did not improve from 0.93596\n","Epoch 388/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 0.6813 - val_accuracy: 0.8842\n","\n","Epoch 00388: val_accuracy did not improve from 0.93596\n","Epoch 389/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.6855 - val_accuracy: 0.8719\n","\n","Epoch 00389: val_accuracy did not improve from 0.93596\n","Epoch 390/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6642 - val_accuracy: 0.8916\n","\n","Epoch 00390: val_accuracy did not improve from 0.93596\n","Epoch 391/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5338 - val_accuracy: 0.9064\n","\n","Epoch 00391: val_accuracy did not improve from 0.93596\n","Epoch 392/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4861 - val_accuracy: 0.9015\n","\n","Epoch 00392: val_accuracy did not improve from 0.93596\n","Epoch 393/500\n","52/52 [==============================] - 22s 426ms/step - loss: 7.3907e-04 - accuracy: 1.0000 - val_loss: 0.5745 - val_accuracy: 0.9015\n","\n","Epoch 00393: val_accuracy did not improve from 0.93596\n","Epoch 394/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5589 - val_accuracy: 0.9138\n","\n","Epoch 00394: val_accuracy did not improve from 0.93596\n","Epoch 395/500\n","52/52 [==============================] - 22s 428ms/step - loss: 8.7504e-04 - accuracy: 1.0000 - val_loss: 0.5762 - val_accuracy: 0.9089\n","\n","Epoch 00395: val_accuracy did not improve from 0.93596\n","Epoch 396/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5285 - val_accuracy: 0.9187\n","\n","Epoch 00396: val_accuracy did not improve from 0.93596\n","Epoch 397/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5908 - val_accuracy: 0.9039\n","\n","Epoch 00397: val_accuracy did not improve from 0.93596\n","Epoch 398/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.7280 - val_accuracy: 0.8892\n","\n","Epoch 00398: val_accuracy did not improve from 0.93596\n","Epoch 399/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4939 - val_accuracy: 0.9187\n","\n","Epoch 00399: val_accuracy did not improve from 0.93596\n","Epoch 400/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.9212\n","\n","Epoch 00400: val_accuracy did not improve from 0.93596\n","Epoch 401/500\n","52/52 [==============================] - 22s 428ms/step - loss: 8.7462e-04 - accuracy: 1.0000 - val_loss: 0.6069 - val_accuracy: 0.9163\n","\n","Epoch 00401: val_accuracy did not improve from 0.93596\n","Epoch 402/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9310\n","\n","Epoch 00402: val_accuracy did not improve from 0.93596\n","Epoch 403/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.9187\n","\n","Epoch 00403: val_accuracy did not improve from 0.93596\n","Epoch 404/500\n","52/52 [==============================] - 22s 426ms/step - loss: 4.6634e-04 - accuracy: 1.0000 - val_loss: 0.5067 - val_accuracy: 0.9089\n","\n","Epoch 00404: val_accuracy did not improve from 0.93596\n","Epoch 405/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.6187 - val_accuracy: 0.9163\n","\n","Epoch 00405: val_accuracy did not improve from 0.93596\n","Epoch 406/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5618 - val_accuracy: 0.9039\n","\n","Epoch 00406: val_accuracy did not improve from 0.93596\n","Epoch 407/500\n","52/52 [==============================] - 22s 428ms/step - loss: 9.5007e-04 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.9212\n","\n","Epoch 00407: val_accuracy did not improve from 0.93596\n","Epoch 408/500\n","52/52 [==============================] - 22s 428ms/step - loss: 4.5892e-04 - accuracy: 1.0000 - val_loss: 0.5242 - val_accuracy: 0.9187\n","\n","Epoch 00408: val_accuracy did not improve from 0.93596\n","Epoch 409/500\n","52/52 [==============================] - 22s 427ms/step - loss: 3.3108e-04 - accuracy: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.9335\n","\n","Epoch 00409: val_accuracy did not improve from 0.93596\n","Epoch 410/500\n","52/52 [==============================] - 22s 427ms/step - loss: 3.7145e-04 - accuracy: 1.0000 - val_loss: 0.5649 - val_accuracy: 0.9212\n","\n","Epoch 00410: val_accuracy did not improve from 0.93596\n","Epoch 411/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 1.0589 - val_accuracy: 0.8695\n","\n","Epoch 00411: val_accuracy did not improve from 0.93596\n","Epoch 412/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0891 - accuracy: 0.9744 - val_loss: 0.6267 - val_accuracy: 0.9138\n","\n","Epoch 00412: val_accuracy did not improve from 0.93596\n","Epoch 413/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0923 - accuracy: 0.9744 - val_loss: 22.0374 - val_accuracy: 0.1724\n","\n","Epoch 00413: val_accuracy did not improve from 0.93596\n","Epoch 414/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0599 - accuracy: 0.9829 - val_loss: 1.0892 - val_accuracy: 0.8374\n","\n","Epoch 00414: val_accuracy did not improve from 0.93596\n","Epoch 415/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0375 - accuracy: 0.9848 - val_loss: 1.3178 - val_accuracy: 0.8374\n","\n","Epoch 00415: val_accuracy did not improve from 0.93596\n","Epoch 416/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.5044 - val_accuracy: 0.9113\n","\n","Epoch 00416: val_accuracy did not improve from 0.93596\n","Epoch 417/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4511 - val_accuracy: 0.9015\n","\n","Epoch 00417: val_accuracy did not improve from 0.93596\n","Epoch 418/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.5252 - val_accuracy: 0.9015\n","\n","Epoch 00418: val_accuracy did not improve from 0.93596\n","Epoch 419/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5041 - val_accuracy: 0.9089\n","\n","Epoch 00419: val_accuracy did not improve from 0.93596\n","Epoch 420/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.4938 - val_accuracy: 0.9089\n","\n","Epoch 00420: val_accuracy did not improve from 0.93596\n","Epoch 421/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.5788 - val_accuracy: 0.8966\n","\n","Epoch 00421: val_accuracy did not improve from 0.93596\n","Epoch 422/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0064 - accuracy: 0.9970 - val_loss: 0.5327 - val_accuracy: 0.9064\n","\n","Epoch 00422: val_accuracy did not improve from 0.93596\n","Epoch 423/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.6658 - val_accuracy: 0.8744\n","\n","Epoch 00423: val_accuracy did not improve from 0.93596\n","Epoch 424/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.4684 - val_accuracy: 0.9089\n","\n","Epoch 00424: val_accuracy did not improve from 0.93596\n","Epoch 425/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.6172 - val_accuracy: 0.9039\n","\n","Epoch 00425: val_accuracy did not improve from 0.93596\n","Epoch 426/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.5176 - val_accuracy: 0.9286\n","\n","Epoch 00426: val_accuracy did not improve from 0.93596\n","Epoch 427/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5208 - val_accuracy: 0.9039\n","\n","Epoch 00427: val_accuracy did not improve from 0.93596\n","Epoch 428/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5960 - val_accuracy: 0.9064\n","\n","Epoch 00428: val_accuracy did not improve from 0.93596\n","Epoch 429/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4769 - val_accuracy: 0.9261\n","\n","Epoch 00429: val_accuracy did not improve from 0.93596\n","Epoch 430/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.5837 - val_accuracy: 0.9089\n","\n","Epoch 00430: val_accuracy did not improve from 0.93596\n","Epoch 431/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.7682 - val_accuracy: 0.8670\n","\n","Epoch 00431: val_accuracy did not improve from 0.93596\n","Epoch 432/500\n","52/52 [==============================] - 22s 429ms/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 0.7449 - val_accuracy: 0.8818\n","\n","Epoch 00432: val_accuracy did not improve from 0.93596\n","Epoch 433/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.6378 - val_accuracy: 0.8941\n","\n","Epoch 00433: val_accuracy did not improve from 0.93596\n","Epoch 434/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5220 - val_accuracy: 0.9113\n","\n","Epoch 00434: val_accuracy did not improve from 0.93596\n","Epoch 435/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.5751 - val_accuracy: 0.9015\n","\n","Epoch 00435: val_accuracy did not improve from 0.93596\n","Epoch 436/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.5090 - val_accuracy: 0.9138\n","\n","Epoch 00436: val_accuracy did not improve from 0.93596\n","Epoch 437/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5486 - val_accuracy: 0.8916\n","\n","Epoch 00437: val_accuracy did not improve from 0.93596\n","Epoch 438/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.9089\n","\n","Epoch 00438: val_accuracy did not improve from 0.93596\n","Epoch 439/500\n","52/52 [==============================] - 22s 428ms/step - loss: 9.9623e-04 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.9163\n","\n","Epoch 00439: val_accuracy did not improve from 0.93596\n","Epoch 440/500\n","52/52 [==============================] - 22s 428ms/step - loss: 6.6019e-04 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.9113\n","\n","Epoch 00440: val_accuracy did not improve from 0.93596\n","Epoch 441/500\n","52/52 [==============================] - 22s 429ms/step - loss: 7.0198e-04 - accuracy: 1.0000 - val_loss: 0.4530 - val_accuracy: 0.9187\n","\n","Epoch 00441: val_accuracy did not improve from 0.93596\n","Epoch 442/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0027 - accuracy: 0.9982 - val_loss: 0.5313 - val_accuracy: 0.9138\n","\n","Epoch 00442: val_accuracy did not improve from 0.93596\n","Epoch 443/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.6048 - val_accuracy: 0.8941\n","\n","Epoch 00443: val_accuracy did not improve from 0.93596\n","Epoch 444/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5512 - val_accuracy: 0.9089\n","\n","Epoch 00444: val_accuracy did not improve from 0.93596\n","Epoch 445/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.6386 - val_accuracy: 0.9113\n","\n","Epoch 00445: val_accuracy did not improve from 0.93596\n","Epoch 446/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5806 - val_accuracy: 0.9064\n","\n","Epoch 00446: val_accuracy did not improve from 0.93596\n","Epoch 447/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5894 - val_accuracy: 0.9039\n","\n","Epoch 00447: val_accuracy did not improve from 0.93596\n","Epoch 448/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0221 - accuracy: 0.9945 - val_loss: 4.4266 - val_accuracy: 0.6281\n","\n","Epoch 00448: val_accuracy did not improve from 0.93596\n","Epoch 449/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0434 - accuracy: 0.9860 - val_loss: 1.0432 - val_accuracy: 0.8227\n","\n","Epoch 00449: val_accuracy did not improve from 0.93596\n","Epoch 450/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0592 - accuracy: 0.9787 - val_loss: 12.2727 - val_accuracy: 0.3990\n","\n","Epoch 00450: val_accuracy did not improve from 0.93596\n","Epoch 451/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.1010 - accuracy: 0.9732 - val_loss: 0.8437 - val_accuracy: 0.8670\n","\n","Epoch 00451: val_accuracy did not improve from 0.93596\n","Epoch 452/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0269 - accuracy: 0.9903 - val_loss: 0.5981 - val_accuracy: 0.9089\n","\n","Epoch 00452: val_accuracy did not improve from 0.93596\n","Epoch 453/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0203 - accuracy: 0.9951 - val_loss: 0.9055 - val_accuracy: 0.8399\n","\n","Epoch 00453: val_accuracy did not improve from 0.93596\n","Epoch 454/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0139 - accuracy: 0.9933 - val_loss: 0.5465 - val_accuracy: 0.8892\n","\n","Epoch 00454: val_accuracy did not improve from 0.93596\n","Epoch 455/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.5227 - val_accuracy: 0.8966\n","\n","Epoch 00455: val_accuracy did not improve from 0.93596\n","Epoch 456/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5043 - val_accuracy: 0.8941\n","\n","Epoch 00456: val_accuracy did not improve from 0.93596\n","Epoch 457/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.5661 - val_accuracy: 0.9015\n","\n","Epoch 00457: val_accuracy did not improve from 0.93596\n","Epoch 458/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5546 - val_accuracy: 0.9039\n","\n","Epoch 00458: val_accuracy did not improve from 0.93596\n","Epoch 459/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 0.6455 - val_accuracy: 0.8818\n","\n","Epoch 00459: val_accuracy did not improve from 0.93596\n","Epoch 460/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0072 - accuracy: 0.9963 - val_loss: 0.5932 - val_accuracy: 0.9039\n","\n","Epoch 00460: val_accuracy did not improve from 0.93596\n","Epoch 461/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0080 - accuracy: 0.9963 - val_loss: 1.2516 - val_accuracy: 0.8103\n","\n","Epoch 00461: val_accuracy did not improve from 0.93596\n","Epoch 462/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.5674 - val_accuracy: 0.9163\n","\n","Epoch 00462: val_accuracy did not improve from 0.93596\n","Epoch 463/500\n","52/52 [==============================] - 22s 425ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5567 - val_accuracy: 0.9212\n","\n","Epoch 00463: val_accuracy did not improve from 0.93596\n","Epoch 464/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5016 - val_accuracy: 0.9089\n","\n","Epoch 00464: val_accuracy did not improve from 0.93596\n","Epoch 465/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.6519 - val_accuracy: 0.8966\n","\n","Epoch 00465: val_accuracy did not improve from 0.93596\n","Epoch 466/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.6873 - val_accuracy: 0.9015\n","\n","Epoch 00466: val_accuracy did not improve from 0.93596\n","Epoch 467/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.7581 - val_accuracy: 0.9039\n","\n","Epoch 00467: val_accuracy did not improve from 0.93596\n","Epoch 468/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.5631 - val_accuracy: 0.9163\n","\n","Epoch 00468: val_accuracy did not improve from 0.93596\n","Epoch 469/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.7702 - val_accuracy: 0.8744\n","\n","Epoch 00469: val_accuracy did not improve from 0.93596\n","Epoch 470/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0093 - accuracy: 0.9957 - val_loss: 0.6179 - val_accuracy: 0.9089\n","\n","Epoch 00470: val_accuracy did not improve from 0.93596\n","Epoch 471/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.6911 - val_accuracy: 0.8941\n","\n","Epoch 00471: val_accuracy did not improve from 0.93596\n","Epoch 472/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.6702 - val_accuracy: 0.8966\n","\n","Epoch 00472: val_accuracy did not improve from 0.93596\n","Epoch 473/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.4973 - val_accuracy: 0.9236\n","\n","Epoch 00473: val_accuracy did not improve from 0.93596\n","Epoch 474/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.9286\n","\n","Epoch 00474: val_accuracy did not improve from 0.93596\n","Epoch 475/500\n","52/52 [==============================] - 22s 428ms/step - loss: 5.7144e-04 - accuracy: 1.0000 - val_loss: 0.5655 - val_accuracy: 0.9261\n","\n","Epoch 00475: val_accuracy did not improve from 0.93596\n","Epoch 476/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5054 - val_accuracy: 0.9261\n","\n","Epoch 00476: val_accuracy did not improve from 0.93596\n","Epoch 477/500\n","52/52 [==============================] - 22s 428ms/step - loss: 5.8414e-04 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.9236\n","\n","Epoch 00477: val_accuracy did not improve from 0.93596\n","Epoch 478/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5628 - val_accuracy: 0.9286\n","\n","Epoch 00478: val_accuracy did not improve from 0.93596\n","Epoch 479/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.5586 - val_accuracy: 0.9064\n","\n","Epoch 00479: val_accuracy did not improve from 0.93596\n","Epoch 480/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5018 - val_accuracy: 0.8941\n","\n","Epoch 00480: val_accuracy did not improve from 0.93596\n","Epoch 481/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.5555 - val_accuracy: 0.9138\n","\n","Epoch 00481: val_accuracy did not improve from 0.93596\n","Epoch 482/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.6132 - val_accuracy: 0.9163\n","\n","Epoch 00482: val_accuracy did not improve from 0.93596\n","Epoch 483/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5003 - val_accuracy: 0.9187\n","\n","Epoch 00483: val_accuracy did not improve from 0.93596\n","Epoch 484/500\n","52/52 [==============================] - 22s 429ms/step - loss: 6.7272e-04 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 0.9212\n","\n","Epoch 00484: val_accuracy did not improve from 0.93596\n","Epoch 485/500\n","52/52 [==============================] - 22s 427ms/step - loss: 5.7817e-04 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9310\n","\n","Epoch 00485: val_accuracy did not improve from 0.93596\n","Epoch 486/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4603 - val_accuracy: 0.9286\n","\n","Epoch 00486: val_accuracy did not improve from 0.93596\n","Epoch 487/500\n","52/52 [==============================] - 22s 426ms/step - loss: 7.7785e-04 - accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9261\n","\n","Epoch 00487: val_accuracy did not improve from 0.93596\n","Epoch 488/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5673 - val_accuracy: 0.9236\n","\n","Epoch 00488: val_accuracy did not improve from 0.93596\n","Epoch 489/500\n","52/52 [==============================] - 22s 425ms/step - loss: 7.9009e-04 - accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.9138\n","\n","Epoch 00489: val_accuracy did not improve from 0.93596\n","Epoch 490/500\n","52/52 [==============================] - 22s 426ms/step - loss: 2.0018e-04 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 0.9187\n","\n","Epoch 00490: val_accuracy did not improve from 0.93596\n","Epoch 491/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.6112 - val_accuracy: 0.9138\n","\n","Epoch 00491: val_accuracy did not improve from 0.93596\n","Epoch 492/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.9465 - val_accuracy: 0.8818\n","\n","Epoch 00492: val_accuracy did not improve from 0.93596\n","Epoch 493/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.9170 - val_accuracy: 0.8793\n","\n","Epoch 00493: val_accuracy did not improve from 0.93596\n","Epoch 494/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.6792 - val_accuracy: 0.9039\n","\n","Epoch 00494: val_accuracy did not improve from 0.93596\n","Epoch 495/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.7600 - val_accuracy: 0.8966\n","\n","Epoch 00495: val_accuracy did not improve from 0.93596\n","Epoch 496/500\n","52/52 [==============================] - 22s 428ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 1.4092 - val_accuracy: 0.7611\n","\n","Epoch 00496: val_accuracy did not improve from 0.93596\n","Epoch 497/500\n","52/52 [==============================] - 22s 427ms/step - loss: 0.0144 - accuracy: 0.9945 - val_loss: 0.7097 - val_accuracy: 0.8842\n","\n","Epoch 00497: val_accuracy did not improve from 0.93596\n","Epoch 498/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.5647 - val_accuracy: 0.9187\n","\n","Epoch 00498: val_accuracy did not improve from 0.93596\n","Epoch 499/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0289 - accuracy: 0.9933 - val_loss: 1.0638 - val_accuracy: 0.8670\n","\n","Epoch 00499: val_accuracy did not improve from 0.93596\n","Epoch 500/500\n","52/52 [==============================] - 22s 426ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.7122 - val_accuracy: 0.8867\n","\n","Epoch 00500: val_accuracy did not improve from 0.93596\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f821adceb90>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"0yzpywaoDN_n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628149004934,"user_tz":-540,"elapsed":6547968,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"936f3277-b67c-402a-87dc-84834adc503a"},"source":["VGG16_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[VGG16_checkpoint])\n","# files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_VGG16.h5')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Epoch 1/500"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["\n","52/52 [==============================] - 22s 326ms/step - loss: 2.9299 - accuracy: 0.1035 - val_loss: 2.3009 - val_accuracy: 0.1133\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.11330, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_VGG16.h5\n","Epoch 2/500\n","52/52 [==============================] - 13s 252ms/step - loss: 2.3019 - accuracy: 0.1139 - val_loss: 2.3003 - val_accuracy: 0.1133\n","\n","Epoch 00002: val_accuracy did not improve from 0.11330\n","Epoch 3/500\n","52/52 [==============================] - 13s 252ms/step - loss: 2.3015 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00003: val_accuracy did not improve from 0.11330\n","Epoch 4/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3016 - accuracy: 0.1139 - val_loss: 2.3002 - val_accuracy: 0.1133\n","\n","Epoch 00004: val_accuracy did not improve from 0.11330\n","Epoch 5/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3020 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00005: val_accuracy did not improve from 0.11330\n","Epoch 6/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3020 - accuracy: 0.1139 - val_loss: 2.3003 - val_accuracy: 0.1133\n","\n","Epoch 00006: val_accuracy did not improve from 0.11330\n","Epoch 7/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3011 - accuracy: 0.1096 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00007: val_accuracy did not improve from 0.11330\n","Epoch 8/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3013 - accuracy: 0.1139 - val_loss: 2.3002 - val_accuracy: 0.1133\n","\n","Epoch 00008: val_accuracy did not improve from 0.11330\n","Epoch 9/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3013 - accuracy: 0.1139 - val_loss: 2.3002 - val_accuracy: 0.1133\n","\n","Epoch 00009: val_accuracy did not improve from 0.11330\n","Epoch 10/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n","\n","Epoch 00010: val_accuracy did not improve from 0.11330\n","Epoch 11/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n","\n","Epoch 00011: val_accuracy did not improve from 0.11330\n","Epoch 12/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3011 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00012: val_accuracy did not improve from 0.11330\n","Epoch 13/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3002 - val_accuracy: 0.1133\n","\n","Epoch 00013: val_accuracy did not improve from 0.11330\n","Epoch 14/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3002 - val_accuracy: 0.1133\n","\n","Epoch 00014: val_accuracy did not improve from 0.11330\n","Epoch 15/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00015: val_accuracy did not improve from 0.11330\n","Epoch 16/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00016: val_accuracy did not improve from 0.11330\n","Epoch 17/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n","\n","Epoch 00017: val_accuracy did not improve from 0.11330\n","Epoch 18/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00018: val_accuracy did not improve from 0.11330\n","Epoch 19/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3010 - accuracy: 0.1029 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00019: val_accuracy did not improve from 0.11330\n","Epoch 20/500\n","52/52 [==============================] - 13s 246ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n","\n","Epoch 00020: val_accuracy did not improve from 0.11330\n","Epoch 21/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00021: val_accuracy did not improve from 0.11330\n","Epoch 22/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00022: val_accuracy did not improve from 0.11330\n","Epoch 23/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00023: val_accuracy did not improve from 0.11330\n","Epoch 24/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n","\n","Epoch 00024: val_accuracy did not improve from 0.11330\n","Epoch 25/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00025: val_accuracy did not improve from 0.11330\n","Epoch 26/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00026: val_accuracy did not improve from 0.11330\n","Epoch 27/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00027: val_accuracy did not improve from 0.11330\n","Epoch 28/500\n","52/52 [==============================] - 13s 246ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n","\n","Epoch 00028: val_accuracy did not improve from 0.11330\n","Epoch 29/500\n","52/52 [==============================] - 13s 246ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00029: val_accuracy did not improve from 0.11330\n","Epoch 30/500\n","52/52 [==============================] - 13s 246ms/step - loss: 2.3011 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00030: val_accuracy did not improve from 0.11330\n","Epoch 31/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00031: val_accuracy did not improve from 0.11330\n","Epoch 32/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00032: val_accuracy did not improve from 0.11330\n","Epoch 33/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00033: val_accuracy did not improve from 0.11330\n","Epoch 34/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00034: val_accuracy did not improve from 0.11330\n","Epoch 35/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00035: val_accuracy did not improve from 0.11330\n","Epoch 36/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00036: val_accuracy did not improve from 0.11330\n","Epoch 37/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00037: val_accuracy did not improve from 0.11330\n","Epoch 38/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00038: val_accuracy did not improve from 0.11330\n","Epoch 39/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00039: val_accuracy did not improve from 0.11330\n","Epoch 40/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00040: val_accuracy did not improve from 0.11330\n","Epoch 41/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00041: val_accuracy did not improve from 0.11330\n","Epoch 42/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00042: val_accuracy did not improve from 0.11330\n","Epoch 43/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00043: val_accuracy did not improve from 0.11330\n","Epoch 44/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00044: val_accuracy did not improve from 0.11330\n","Epoch 45/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00045: val_accuracy did not improve from 0.11330\n","Epoch 46/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00046: val_accuracy did not improve from 0.11330\n","Epoch 47/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00047: val_accuracy did not improve from 0.11330\n","Epoch 48/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00048: val_accuracy did not improve from 0.11330\n","Epoch 49/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00049: val_accuracy did not improve from 0.11330\n","Epoch 50/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00050: val_accuracy did not improve from 0.11330\n","Epoch 51/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00051: val_accuracy did not improve from 0.11330\n","Epoch 52/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00052: val_accuracy did not improve from 0.11330\n","Epoch 53/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00053: val_accuracy did not improve from 0.11330\n","Epoch 54/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00054: val_accuracy did not improve from 0.11330\n","Epoch 55/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00055: val_accuracy did not improve from 0.11330\n","Epoch 56/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00056: val_accuracy did not improve from 0.11330\n","Epoch 57/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00057: val_accuracy did not improve from 0.11330\n","Epoch 58/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00058: val_accuracy did not improve from 0.11330\n","Epoch 59/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00059: val_accuracy did not improve from 0.11330\n","Epoch 60/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00060: val_accuracy did not improve from 0.11330\n","Epoch 61/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00061: val_accuracy did not improve from 0.11330\n","Epoch 62/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00062: val_accuracy did not improve from 0.11330\n","Epoch 63/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00063: val_accuracy did not improve from 0.11330\n","Epoch 64/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00064: val_accuracy did not improve from 0.11330\n","Epoch 65/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00065: val_accuracy did not improve from 0.11330\n","Epoch 66/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00066: val_accuracy did not improve from 0.11330\n","Epoch 67/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00067: val_accuracy did not improve from 0.11330\n","Epoch 68/500\n","52/52 [==============================] - 13s 246ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00068: val_accuracy did not improve from 0.11330\n","Epoch 69/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00069: val_accuracy did not improve from 0.11330\n","Epoch 70/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00070: val_accuracy did not improve from 0.11330\n","Epoch 71/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00071: val_accuracy did not improve from 0.11330\n","Epoch 72/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00072: val_accuracy did not improve from 0.11330\n","Epoch 73/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00073: val_accuracy did not improve from 0.11330\n","Epoch 74/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00074: val_accuracy did not improve from 0.11330\n","Epoch 75/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00075: val_accuracy did not improve from 0.11330\n","Epoch 76/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00076: val_accuracy did not improve from 0.11330\n","Epoch 77/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00077: val_accuracy did not improve from 0.11330\n","Epoch 78/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00078: val_accuracy did not improve from 0.11330\n","Epoch 79/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00079: val_accuracy did not improve from 0.11330\n","Epoch 80/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00080: val_accuracy did not improve from 0.11330\n","Epoch 81/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00081: val_accuracy did not improve from 0.11330\n","Epoch 82/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00082: val_accuracy did not improve from 0.11330\n","Epoch 83/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00083: val_accuracy did not improve from 0.11330\n","Epoch 84/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00084: val_accuracy did not improve from 0.11330\n","Epoch 85/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00085: val_accuracy did not improve from 0.11330\n","Epoch 86/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00086: val_accuracy did not improve from 0.11330\n","Epoch 87/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00087: val_accuracy did not improve from 0.11330\n","Epoch 88/500\n","52/52 [==============================] - 13s 251ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00088: val_accuracy did not improve from 0.11330\n","Epoch 89/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00089: val_accuracy did not improve from 0.11330\n","Epoch 90/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00090: val_accuracy did not improve from 0.11330\n","Epoch 91/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00091: val_accuracy did not improve from 0.11330\n","Epoch 92/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00092: val_accuracy did not improve from 0.11330\n","Epoch 93/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00093: val_accuracy did not improve from 0.11330\n","Epoch 94/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00094: val_accuracy did not improve from 0.11330\n","Epoch 95/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00095: val_accuracy did not improve from 0.11330\n","Epoch 96/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00096: val_accuracy did not improve from 0.11330\n","Epoch 97/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00097: val_accuracy did not improve from 0.11330\n","Epoch 98/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00098: val_accuracy did not improve from 0.11330\n","Epoch 99/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00099: val_accuracy did not improve from 0.11330\n","Epoch 100/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00100: val_accuracy did not improve from 0.11330\n","Epoch 101/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00101: val_accuracy did not improve from 0.11330\n","Epoch 102/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00102: val_accuracy did not improve from 0.11330\n","Epoch 103/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00103: val_accuracy did not improve from 0.11330\n","Epoch 104/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00104: val_accuracy did not improve from 0.11330\n","Epoch 105/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00105: val_accuracy did not improve from 0.11330\n","Epoch 106/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00106: val_accuracy did not improve from 0.11330\n","Epoch 107/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00107: val_accuracy did not improve from 0.11330\n","Epoch 108/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00108: val_accuracy did not improve from 0.11330\n","Epoch 109/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00109: val_accuracy did not improve from 0.11330\n","Epoch 110/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00110: val_accuracy did not improve from 0.11330\n","Epoch 111/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00111: val_accuracy did not improve from 0.11330\n","Epoch 112/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00112: val_accuracy did not improve from 0.11330\n","Epoch 113/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00113: val_accuracy did not improve from 0.11330\n","Epoch 114/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00114: val_accuracy did not improve from 0.11330\n","Epoch 115/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00115: val_accuracy did not improve from 0.11330\n","Epoch 116/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00116: val_accuracy did not improve from 0.11330\n","Epoch 117/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00117: val_accuracy did not improve from 0.11330\n","Epoch 118/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00118: val_accuracy did not improve from 0.11330\n","Epoch 119/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00119: val_accuracy did not improve from 0.11330\n","Epoch 120/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00120: val_accuracy did not improve from 0.11330\n","Epoch 121/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00121: val_accuracy did not improve from 0.11330\n","Epoch 122/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00122: val_accuracy did not improve from 0.11330\n","Epoch 123/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00123: val_accuracy did not improve from 0.11330\n","Epoch 124/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00124: val_accuracy did not improve from 0.11330\n","Epoch 125/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00125: val_accuracy did not improve from 0.11330\n","Epoch 126/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00126: val_accuracy did not improve from 0.11330\n","Epoch 127/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00127: val_accuracy did not improve from 0.11330\n","Epoch 128/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00128: val_accuracy did not improve from 0.11330\n","Epoch 129/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00129: val_accuracy did not improve from 0.11330\n","Epoch 130/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00130: val_accuracy did not improve from 0.11330\n","Epoch 131/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00131: val_accuracy did not improve from 0.11330\n","Epoch 132/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00132: val_accuracy did not improve from 0.11330\n","Epoch 133/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00133: val_accuracy did not improve from 0.11330\n","Epoch 134/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00134: val_accuracy did not improve from 0.11330\n","Epoch 135/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00135: val_accuracy did not improve from 0.11330\n","Epoch 136/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00136: val_accuracy did not improve from 0.11330\n","Epoch 137/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00137: val_accuracy did not improve from 0.11330\n","Epoch 138/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00138: val_accuracy did not improve from 0.11330\n","Epoch 139/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00139: val_accuracy did not improve from 0.11330\n","Epoch 140/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00140: val_accuracy did not improve from 0.11330\n","Epoch 141/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00141: val_accuracy did not improve from 0.11330\n","Epoch 142/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00142: val_accuracy did not improve from 0.11330\n","Epoch 143/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00143: val_accuracy did not improve from 0.11330\n","Epoch 144/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00144: val_accuracy did not improve from 0.11330\n","Epoch 145/500\n","52/52 [==============================] - 13s 252ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00145: val_accuracy did not improve from 0.11330\n","Epoch 146/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00146: val_accuracy did not improve from 0.11330\n","Epoch 147/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00147: val_accuracy did not improve from 0.11330\n","Epoch 148/500\n","52/52 [==============================] - 13s 251ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00148: val_accuracy did not improve from 0.11330\n","Epoch 149/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00149: val_accuracy did not improve from 0.11330\n","Epoch 150/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00150: val_accuracy did not improve from 0.11330\n","Epoch 151/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00151: val_accuracy did not improve from 0.11330\n","Epoch 152/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00152: val_accuracy did not improve from 0.11330\n","Epoch 153/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00153: val_accuracy did not improve from 0.11330\n","Epoch 154/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00154: val_accuracy did not improve from 0.11330\n","Epoch 155/500\n","52/52 [==============================] - 13s 251ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00155: val_accuracy did not improve from 0.11330\n","Epoch 156/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00156: val_accuracy did not improve from 0.11330\n","Epoch 157/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00157: val_accuracy did not improve from 0.11330\n","Epoch 158/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00158: val_accuracy did not improve from 0.11330\n","Epoch 159/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00159: val_accuracy did not improve from 0.11330\n","Epoch 160/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00160: val_accuracy did not improve from 0.11330\n","Epoch 161/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00161: val_accuracy did not improve from 0.11330\n","Epoch 162/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00162: val_accuracy did not improve from 0.11330\n","Epoch 163/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00163: val_accuracy did not improve from 0.11330\n","Epoch 164/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00164: val_accuracy did not improve from 0.11330\n","Epoch 165/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00165: val_accuracy did not improve from 0.11330\n","Epoch 166/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00166: val_accuracy did not improve from 0.11330\n","Epoch 167/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00167: val_accuracy did not improve from 0.11330\n","Epoch 168/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00168: val_accuracy did not improve from 0.11330\n","Epoch 169/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00169: val_accuracy did not improve from 0.11330\n","Epoch 170/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00170: val_accuracy did not improve from 0.11330\n","Epoch 171/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00171: val_accuracy did not improve from 0.11330\n","Epoch 172/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00172: val_accuracy did not improve from 0.11330\n","Epoch 173/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00173: val_accuracy did not improve from 0.11330\n","Epoch 174/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00174: val_accuracy did not improve from 0.11330\n","Epoch 175/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00175: val_accuracy did not improve from 0.11330\n","Epoch 176/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00176: val_accuracy did not improve from 0.11330\n","Epoch 177/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00177: val_accuracy did not improve from 0.11330\n","Epoch 178/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00178: val_accuracy did not improve from 0.11330\n","Epoch 179/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00179: val_accuracy did not improve from 0.11330\n","Epoch 180/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00180: val_accuracy did not improve from 0.11330\n","Epoch 181/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00181: val_accuracy did not improve from 0.11330\n","Epoch 182/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00182: val_accuracy did not improve from 0.11330\n","Epoch 183/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00183: val_accuracy did not improve from 0.11330\n","Epoch 184/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00184: val_accuracy did not improve from 0.11330\n","Epoch 185/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00185: val_accuracy did not improve from 0.11330\n","Epoch 186/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00186: val_accuracy did not improve from 0.11330\n","Epoch 187/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00187: val_accuracy did not improve from 0.11330\n","Epoch 188/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00188: val_accuracy did not improve from 0.11330\n","Epoch 189/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00189: val_accuracy did not improve from 0.11330\n","Epoch 190/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00190: val_accuracy did not improve from 0.11330\n","Epoch 191/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00191: val_accuracy did not improve from 0.11330\n","Epoch 192/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00192: val_accuracy did not improve from 0.11330\n","Epoch 193/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00193: val_accuracy did not improve from 0.11330\n","Epoch 194/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00194: val_accuracy did not improve from 0.11330\n","Epoch 195/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00195: val_accuracy did not improve from 0.11330\n","Epoch 196/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00196: val_accuracy did not improve from 0.11330\n","Epoch 197/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00197: val_accuracy did not improve from 0.11330\n","Epoch 198/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00198: val_accuracy did not improve from 0.11330\n","Epoch 199/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00199: val_accuracy did not improve from 0.11330\n","Epoch 200/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00200: val_accuracy did not improve from 0.11330\n","Epoch 201/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00201: val_accuracy did not improve from 0.11330\n","Epoch 202/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00202: val_accuracy did not improve from 0.11330\n","Epoch 203/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00203: val_accuracy did not improve from 0.11330\n","Epoch 204/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00204: val_accuracy did not improve from 0.11330\n","Epoch 205/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00205: val_accuracy did not improve from 0.11330\n","Epoch 206/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00206: val_accuracy did not improve from 0.11330\n","Epoch 207/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00207: val_accuracy did not improve from 0.11330\n","Epoch 208/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00208: val_accuracy did not improve from 0.11330\n","Epoch 209/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00209: val_accuracy did not improve from 0.11330\n","Epoch 210/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00210: val_accuracy did not improve from 0.11330\n","Epoch 211/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00211: val_accuracy did not improve from 0.11330\n","Epoch 212/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00212: val_accuracy did not improve from 0.11330\n","Epoch 213/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00213: val_accuracy did not improve from 0.11330\n","Epoch 214/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00214: val_accuracy did not improve from 0.11330\n","Epoch 215/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00215: val_accuracy did not improve from 0.11330\n","Epoch 216/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00216: val_accuracy did not improve from 0.11330\n","Epoch 217/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00217: val_accuracy did not improve from 0.11330\n","Epoch 218/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00218: val_accuracy did not improve from 0.11330\n","Epoch 219/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00219: val_accuracy did not improve from 0.11330\n","Epoch 220/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00220: val_accuracy did not improve from 0.11330\n","Epoch 221/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00221: val_accuracy did not improve from 0.11330\n","Epoch 222/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00222: val_accuracy did not improve from 0.11330\n","Epoch 223/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00223: val_accuracy did not improve from 0.11330\n","Epoch 224/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00224: val_accuracy did not improve from 0.11330\n","Epoch 225/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00225: val_accuracy did not improve from 0.11330\n","Epoch 226/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00226: val_accuracy did not improve from 0.11330\n","Epoch 227/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00227: val_accuracy did not improve from 0.11330\n","Epoch 228/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00228: val_accuracy did not improve from 0.11330\n","Epoch 229/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00229: val_accuracy did not improve from 0.11330\n","Epoch 230/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00230: val_accuracy did not improve from 0.11330\n","Epoch 231/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00231: val_accuracy did not improve from 0.11330\n","Epoch 232/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00232: val_accuracy did not improve from 0.11330\n","Epoch 233/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00233: val_accuracy did not improve from 0.11330\n","Epoch 234/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00234: val_accuracy did not improve from 0.11330\n","Epoch 235/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00235: val_accuracy did not improve from 0.11330\n","Epoch 236/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00236: val_accuracy did not improve from 0.11330\n","Epoch 237/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00237: val_accuracy did not improve from 0.11330\n","Epoch 238/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00238: val_accuracy did not improve from 0.11330\n","Epoch 239/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00239: val_accuracy did not improve from 0.11330\n","Epoch 240/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00240: val_accuracy did not improve from 0.11330\n","Epoch 241/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00241: val_accuracy did not improve from 0.11330\n","Epoch 242/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00242: val_accuracy did not improve from 0.11330\n","Epoch 243/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00243: val_accuracy did not improve from 0.11330\n","Epoch 244/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00244: val_accuracy did not improve from 0.11330\n","Epoch 245/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00245: val_accuracy did not improve from 0.11330\n","Epoch 246/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00246: val_accuracy did not improve from 0.11330\n","Epoch 247/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00247: val_accuracy did not improve from 0.11330\n","Epoch 248/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00248: val_accuracy did not improve from 0.11330\n","Epoch 249/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00249: val_accuracy did not improve from 0.11330\n","Epoch 250/500\n","52/52 [==============================] - 13s 252ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00250: val_accuracy did not improve from 0.11330\n","Epoch 251/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00251: val_accuracy did not improve from 0.11330\n","Epoch 252/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00252: val_accuracy did not improve from 0.11330\n","Epoch 253/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00253: val_accuracy did not improve from 0.11330\n","Epoch 254/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00254: val_accuracy did not improve from 0.11330\n","Epoch 255/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00255: val_accuracy did not improve from 0.11330\n","Epoch 256/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00256: val_accuracy did not improve from 0.11330\n","Epoch 257/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00257: val_accuracy did not improve from 0.11330\n","Epoch 258/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00258: val_accuracy did not improve from 0.11330\n","Epoch 259/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00259: val_accuracy did not improve from 0.11330\n","Epoch 260/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00260: val_accuracy did not improve from 0.11330\n","Epoch 261/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00261: val_accuracy did not improve from 0.11330\n","Epoch 262/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00262: val_accuracy did not improve from 0.11330\n","Epoch 263/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00263: val_accuracy did not improve from 0.11330\n","Epoch 264/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00264: val_accuracy did not improve from 0.11330\n","Epoch 265/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00265: val_accuracy did not improve from 0.11330\n","Epoch 266/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00266: val_accuracy did not improve from 0.11330\n","Epoch 267/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00267: val_accuracy did not improve from 0.11330\n","Epoch 268/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00268: val_accuracy did not improve from 0.11330\n","Epoch 269/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00269: val_accuracy did not improve from 0.11330\n","Epoch 270/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00270: val_accuracy did not improve from 0.11330\n","Epoch 271/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00271: val_accuracy did not improve from 0.11330\n","Epoch 272/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00272: val_accuracy did not improve from 0.11330\n","Epoch 273/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00273: val_accuracy did not improve from 0.11330\n","Epoch 274/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00274: val_accuracy did not improve from 0.11330\n","Epoch 275/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00275: val_accuracy did not improve from 0.11330\n","Epoch 276/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00276: val_accuracy did not improve from 0.11330\n","Epoch 277/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00277: val_accuracy did not improve from 0.11330\n","Epoch 278/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00278: val_accuracy did not improve from 0.11330\n","Epoch 279/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00279: val_accuracy did not improve from 0.11330\n","Epoch 280/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00280: val_accuracy did not improve from 0.11330\n","Epoch 281/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00281: val_accuracy did not improve from 0.11330\n","Epoch 282/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00282: val_accuracy did not improve from 0.11330\n","Epoch 283/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00283: val_accuracy did not improve from 0.11330\n","Epoch 284/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00284: val_accuracy did not improve from 0.11330\n","Epoch 285/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00285: val_accuracy did not improve from 0.11330\n","Epoch 286/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00286: val_accuracy did not improve from 0.11330\n","Epoch 287/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00287: val_accuracy did not improve from 0.11330\n","Epoch 288/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00288: val_accuracy did not improve from 0.11330\n","Epoch 289/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00289: val_accuracy did not improve from 0.11330\n","Epoch 290/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00290: val_accuracy did not improve from 0.11330\n","Epoch 291/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00291: val_accuracy did not improve from 0.11330\n","Epoch 292/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00292: val_accuracy did not improve from 0.11330\n","Epoch 293/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00293: val_accuracy did not improve from 0.11330\n","Epoch 294/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00294: val_accuracy did not improve from 0.11330\n","Epoch 295/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00295: val_accuracy did not improve from 0.11330\n","Epoch 296/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00296: val_accuracy did not improve from 0.11330\n","Epoch 297/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00297: val_accuracy did not improve from 0.11330\n","Epoch 298/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00298: val_accuracy did not improve from 0.11330\n","Epoch 299/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00299: val_accuracy did not improve from 0.11330\n","Epoch 300/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00300: val_accuracy did not improve from 0.11330\n","Epoch 301/500\n","52/52 [==============================] - 13s 251ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00301: val_accuracy did not improve from 0.11330\n","Epoch 302/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00302: val_accuracy did not improve from 0.11330\n","Epoch 303/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00303: val_accuracy did not improve from 0.11330\n","Epoch 304/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00304: val_accuracy did not improve from 0.11330\n","Epoch 305/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00305: val_accuracy did not improve from 0.11330\n","Epoch 306/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00306: val_accuracy did not improve from 0.11330\n","Epoch 307/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00307: val_accuracy did not improve from 0.11330\n","Epoch 308/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00308: val_accuracy did not improve from 0.11330\n","Epoch 309/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00309: val_accuracy did not improve from 0.11330\n","Epoch 310/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00310: val_accuracy did not improve from 0.11330\n","Epoch 311/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00311: val_accuracy did not improve from 0.11330\n","Epoch 312/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00312: val_accuracy did not improve from 0.11330\n","Epoch 313/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00313: val_accuracy did not improve from 0.11330\n","Epoch 314/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00314: val_accuracy did not improve from 0.11330\n","Epoch 315/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00315: val_accuracy did not improve from 0.11330\n","Epoch 316/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00316: val_accuracy did not improve from 0.11330\n","Epoch 317/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00317: val_accuracy did not improve from 0.11330\n","Epoch 318/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00318: val_accuracy did not improve from 0.11330\n","Epoch 319/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00319: val_accuracy did not improve from 0.11330\n","Epoch 320/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00320: val_accuracy did not improve from 0.11330\n","Epoch 321/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00321: val_accuracy did not improve from 0.11330\n","Epoch 322/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00322: val_accuracy did not improve from 0.11330\n","Epoch 323/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00323: val_accuracy did not improve from 0.11330\n","Epoch 324/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00324: val_accuracy did not improve from 0.11330\n","Epoch 325/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00325: val_accuracy did not improve from 0.11330\n","Epoch 326/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00326: val_accuracy did not improve from 0.11330\n","Epoch 327/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00327: val_accuracy did not improve from 0.11330\n","Epoch 328/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00328: val_accuracy did not improve from 0.11330\n","Epoch 329/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00329: val_accuracy did not improve from 0.11330\n","Epoch 330/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00330: val_accuracy did not improve from 0.11330\n","Epoch 331/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00331: val_accuracy did not improve from 0.11330\n","Epoch 332/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00332: val_accuracy did not improve from 0.11330\n","Epoch 333/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00333: val_accuracy did not improve from 0.11330\n","Epoch 334/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00334: val_accuracy did not improve from 0.11330\n","Epoch 335/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00335: val_accuracy did not improve from 0.11330\n","Epoch 336/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00336: val_accuracy did not improve from 0.11330\n","Epoch 337/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00337: val_accuracy did not improve from 0.11330\n","Epoch 338/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00338: val_accuracy did not improve from 0.11330\n","Epoch 339/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00339: val_accuracy did not improve from 0.11330\n","Epoch 340/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00340: val_accuracy did not improve from 0.11330\n","Epoch 341/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00341: val_accuracy did not improve from 0.11330\n","Epoch 342/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00342: val_accuracy did not improve from 0.11330\n","Epoch 343/500\n","52/52 [==============================] - 13s 252ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00343: val_accuracy did not improve from 0.11330\n","Epoch 344/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00344: val_accuracy did not improve from 0.11330\n","Epoch 345/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00345: val_accuracy did not improve from 0.11330\n","Epoch 346/500\n","52/52 [==============================] - 13s 246ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00346: val_accuracy did not improve from 0.11330\n","Epoch 347/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00347: val_accuracy did not improve from 0.11330\n","Epoch 348/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00348: val_accuracy did not improve from 0.11330\n","Epoch 349/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00349: val_accuracy did not improve from 0.11330\n","Epoch 350/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00350: val_accuracy did not improve from 0.11330\n","Epoch 351/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00351: val_accuracy did not improve from 0.11330\n","Epoch 352/500\n","52/52 [==============================] - 13s 252ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00352: val_accuracy did not improve from 0.11330\n","Epoch 353/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00353: val_accuracy did not improve from 0.11330\n","Epoch 354/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00354: val_accuracy did not improve from 0.11330\n","Epoch 355/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00355: val_accuracy did not improve from 0.11330\n","Epoch 356/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00356: val_accuracy did not improve from 0.11330\n","Epoch 357/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00357: val_accuracy did not improve from 0.11330\n","Epoch 358/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00358: val_accuracy did not improve from 0.11330\n","Epoch 359/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00359: val_accuracy did not improve from 0.11330\n","Epoch 360/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00360: val_accuracy did not improve from 0.11330\n","Epoch 361/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00361: val_accuracy did not improve from 0.11330\n","Epoch 362/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00362: val_accuracy did not improve from 0.11330\n","Epoch 363/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00363: val_accuracy did not improve from 0.11330\n","Epoch 364/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00364: val_accuracy did not improve from 0.11330\n","Epoch 365/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00365: val_accuracy did not improve from 0.11330\n","Epoch 366/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00366: val_accuracy did not improve from 0.11330\n","Epoch 367/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00367: val_accuracy did not improve from 0.11330\n","Epoch 368/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00368: val_accuracy did not improve from 0.11330\n","Epoch 369/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00369: val_accuracy did not improve from 0.11330\n","Epoch 370/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00370: val_accuracy did not improve from 0.11330\n","Epoch 371/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00371: val_accuracy did not improve from 0.11330\n","Epoch 372/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00372: val_accuracy did not improve from 0.11330\n","Epoch 373/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00373: val_accuracy did not improve from 0.11330\n","Epoch 374/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00374: val_accuracy did not improve from 0.11330\n","Epoch 375/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00375: val_accuracy did not improve from 0.11330\n","Epoch 376/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00376: val_accuracy did not improve from 0.11330\n","Epoch 377/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00377: val_accuracy did not improve from 0.11330\n","Epoch 378/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00378: val_accuracy did not improve from 0.11330\n","Epoch 379/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00379: val_accuracy did not improve from 0.11330\n","Epoch 380/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00380: val_accuracy did not improve from 0.11330\n","Epoch 381/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00381: val_accuracy did not improve from 0.11330\n","Epoch 382/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00382: val_accuracy did not improve from 0.11330\n","Epoch 383/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00383: val_accuracy did not improve from 0.11330\n","Epoch 384/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00384: val_accuracy did not improve from 0.11330\n","Epoch 385/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00385: val_accuracy did not improve from 0.11330\n","Epoch 386/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00386: val_accuracy did not improve from 0.11330\n","Epoch 387/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00387: val_accuracy did not improve from 0.11330\n","Epoch 388/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00388: val_accuracy did not improve from 0.11330\n","Epoch 389/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00389: val_accuracy did not improve from 0.11330\n","Epoch 390/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00390: val_accuracy did not improve from 0.11330\n","Epoch 391/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00391: val_accuracy did not improve from 0.11330\n","Epoch 392/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00392: val_accuracy did not improve from 0.11330\n","Epoch 393/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00393: val_accuracy did not improve from 0.11330\n","Epoch 394/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00394: val_accuracy did not improve from 0.11330\n","Epoch 395/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00395: val_accuracy did not improve from 0.11330\n","Epoch 396/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00396: val_accuracy did not improve from 0.11330\n","Epoch 397/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00397: val_accuracy did not improve from 0.11330\n","Epoch 398/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00398: val_accuracy did not improve from 0.11330\n","Epoch 399/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00399: val_accuracy did not improve from 0.11330\n","Epoch 400/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00400: val_accuracy did not improve from 0.11330\n","Epoch 401/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00401: val_accuracy did not improve from 0.11330\n","Epoch 402/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00402: val_accuracy did not improve from 0.11330\n","Epoch 403/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00403: val_accuracy did not improve from 0.11330\n","Epoch 404/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00404: val_accuracy did not improve from 0.11330\n","Epoch 405/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00405: val_accuracy did not improve from 0.11330\n","Epoch 406/500\n","52/52 [==============================] - 13s 251ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00406: val_accuracy did not improve from 0.11330\n","Epoch 407/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00407: val_accuracy did not improve from 0.11330\n","Epoch 408/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00408: val_accuracy did not improve from 0.11330\n","Epoch 409/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00409: val_accuracy did not improve from 0.11330\n","Epoch 410/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00410: val_accuracy did not improve from 0.11330\n","Epoch 411/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00411: val_accuracy did not improve from 0.11330\n","Epoch 412/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00412: val_accuracy did not improve from 0.11330\n","Epoch 413/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00413: val_accuracy did not improve from 0.11330\n","Epoch 414/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00414: val_accuracy did not improve from 0.11330\n","Epoch 415/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00415: val_accuracy did not improve from 0.11330\n","Epoch 416/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00416: val_accuracy did not improve from 0.11330\n","Epoch 417/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00417: val_accuracy did not improve from 0.11330\n","Epoch 418/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00418: val_accuracy did not improve from 0.11330\n","Epoch 419/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00419: val_accuracy did not improve from 0.11330\n","Epoch 420/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00420: val_accuracy did not improve from 0.11330\n","Epoch 421/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00421: val_accuracy did not improve from 0.11330\n","Epoch 422/500\n","52/52 [==============================] - 13s 246ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00422: val_accuracy did not improve from 0.11330\n","Epoch 423/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00423: val_accuracy did not improve from 0.11330\n","Epoch 424/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00424: val_accuracy did not improve from 0.11330\n","Epoch 425/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00425: val_accuracy did not improve from 0.11330\n","Epoch 426/500\n","52/52 [==============================] - 13s 251ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00426: val_accuracy did not improve from 0.11330\n","Epoch 427/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00427: val_accuracy did not improve from 0.11330\n","Epoch 428/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00428: val_accuracy did not improve from 0.11330\n","Epoch 429/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00429: val_accuracy did not improve from 0.11330\n","Epoch 430/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00430: val_accuracy did not improve from 0.11330\n","Epoch 431/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00431: val_accuracy did not improve from 0.11330\n","Epoch 432/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00432: val_accuracy did not improve from 0.11330\n","Epoch 433/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00433: val_accuracy did not improve from 0.11330\n","Epoch 434/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00434: val_accuracy did not improve from 0.11330\n","Epoch 435/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00435: val_accuracy did not improve from 0.11330\n","Epoch 436/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00436: val_accuracy did not improve from 0.11330\n","Epoch 437/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00437: val_accuracy did not improve from 0.11330\n","Epoch 438/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00438: val_accuracy did not improve from 0.11330\n","Epoch 439/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00439: val_accuracy did not improve from 0.11330\n","Epoch 440/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00440: val_accuracy did not improve from 0.11330\n","Epoch 441/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00441: val_accuracy did not improve from 0.11330\n","Epoch 442/500\n","52/52 [==============================] - 13s 246ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00442: val_accuracy did not improve from 0.11330\n","Epoch 443/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00443: val_accuracy did not improve from 0.11330\n","Epoch 444/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00444: val_accuracy did not improve from 0.11330\n","Epoch 445/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00445: val_accuracy did not improve from 0.11330\n","Epoch 446/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00446: val_accuracy did not improve from 0.11330\n","Epoch 447/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00447: val_accuracy did not improve from 0.11330\n","Epoch 448/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00448: val_accuracy did not improve from 0.11330\n","Epoch 449/500\n","52/52 [==============================] - 13s 251ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00449: val_accuracy did not improve from 0.11330\n","Epoch 450/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00450: val_accuracy did not improve from 0.11330\n","Epoch 451/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00451: val_accuracy did not improve from 0.11330\n","Epoch 452/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00452: val_accuracy did not improve from 0.11330\n","Epoch 453/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00453: val_accuracy did not improve from 0.11330\n","Epoch 454/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00454: val_accuracy did not improve from 0.11330\n","Epoch 455/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00455: val_accuracy did not improve from 0.11330\n","Epoch 456/500\n","52/52 [==============================] - 13s 251ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00456: val_accuracy did not improve from 0.11330\n","Epoch 457/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00457: val_accuracy did not improve from 0.11330\n","Epoch 458/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00458: val_accuracy did not improve from 0.11330\n","Epoch 459/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00459: val_accuracy did not improve from 0.11330\n","Epoch 460/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00460: val_accuracy did not improve from 0.11330\n","Epoch 461/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00461: val_accuracy did not improve from 0.11330\n","Epoch 462/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00462: val_accuracy did not improve from 0.11330\n","Epoch 463/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00463: val_accuracy did not improve from 0.11330\n","Epoch 464/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00464: val_accuracy did not improve from 0.11330\n","Epoch 465/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00465: val_accuracy did not improve from 0.11330\n","Epoch 466/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00466: val_accuracy did not improve from 0.11330\n","Epoch 467/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00467: val_accuracy did not improve from 0.11330\n","Epoch 468/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00468: val_accuracy did not improve from 0.11330\n","Epoch 469/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00469: val_accuracy did not improve from 0.11330\n","Epoch 470/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00470: val_accuracy did not improve from 0.11330\n","Epoch 471/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00471: val_accuracy did not improve from 0.11330\n","Epoch 472/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00472: val_accuracy did not improve from 0.11330\n","Epoch 473/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00473: val_accuracy did not improve from 0.11330\n","Epoch 474/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00474: val_accuracy did not improve from 0.11330\n","Epoch 475/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00475: val_accuracy did not improve from 0.11330\n","Epoch 476/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00476: val_accuracy did not improve from 0.11330\n","Epoch 477/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00477: val_accuracy did not improve from 0.11330\n","Epoch 478/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00478: val_accuracy did not improve from 0.11330\n","Epoch 479/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00479: val_accuracy did not improve from 0.11330\n","Epoch 480/500\n","52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00480: val_accuracy did not improve from 0.11330\n","Epoch 481/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00481: val_accuracy did not improve from 0.11330\n","Epoch 482/500\n","52/52 [==============================] - 13s 246ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00482: val_accuracy did not improve from 0.11330\n","Epoch 483/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00483: val_accuracy did not improve from 0.11330\n","Epoch 484/500\n","52/52 [==============================] - 13s 252ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00484: val_accuracy did not improve from 0.11330\n","Epoch 485/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00485: val_accuracy did not improve from 0.11330\n","Epoch 486/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00486: val_accuracy did not improve from 0.11330\n","Epoch 487/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00487: val_accuracy did not improve from 0.11330\n","Epoch 488/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00488: val_accuracy did not improve from 0.11330\n","Epoch 489/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00489: val_accuracy did not improve from 0.11330\n","Epoch 490/500\n","52/52 [==============================] - 13s 250ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00490: val_accuracy did not improve from 0.11330\n","Epoch 491/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00491: val_accuracy did not improve from 0.11330\n","Epoch 492/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00492: val_accuracy did not improve from 0.11330\n","Epoch 493/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00493: val_accuracy did not improve from 0.11330\n","Epoch 494/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00494: val_accuracy did not improve from 0.11330\n","Epoch 495/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00495: val_accuracy did not improve from 0.11330\n","Epoch 496/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00496: val_accuracy did not improve from 0.11330\n","Epoch 497/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00497: val_accuracy did not improve from 0.11330\n","Epoch 498/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00498: val_accuracy did not improve from 0.11330\n","Epoch 499/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00499: val_accuracy did not improve from 0.11330\n","Epoch 500/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00500: val_accuracy did not improve from 0.11330\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f8211961610>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"obGf3yw0DPH6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"100d6d8d-17fb-474a-c76f-5ea87ce63c32"},"source":["VGG19_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[VGG19_checkpoint])\n","# files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_VGG19.h5')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["52/52 [==============================] - 16s 292ms/step - loss: 4.5639 - accuracy: 0.1084 - val_loss: 2.3011 - val_accuracy: 0.1108\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_VGG19.h5\n","Epoch 2/500\n","52/52 [==============================] - 15s 289ms/step - loss: 2.3029 - accuracy: 0.1151 - val_loss: 2.3005 - val_accuracy: 0.1133\n","\n","Epoch 00002: val_accuracy improved from 0.11084 to 0.11330, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_VGG19.h5\n","Epoch 3/500\n","52/52 [==============================] - 15s 289ms/step - loss: 2.3016 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n","\n","Epoch 00003: val_accuracy did not improve from 0.11330\n","Epoch 4/500\n","52/52 [==============================] - 15s 287ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n","\n","Epoch 00004: val_accuracy did not improve from 0.11330\n","Epoch 5/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3015 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00005: val_accuracy did not improve from 0.11330\n","Epoch 6/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3011 - accuracy: 0.1072 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00006: val_accuracy did not improve from 0.11330\n","Epoch 7/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3011 - accuracy: 0.1102 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00007: val_accuracy did not improve from 0.11330\n","Epoch 8/500\n","52/52 [==============================] - 15s 288ms/step - loss: 2.3011 - accuracy: 0.1139 - val_loss: 2.3003 - val_accuracy: 0.1133\n","\n","Epoch 00008: val_accuracy did not improve from 0.11330\n","Epoch 9/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00009: val_accuracy did not improve from 0.11330\n","Epoch 10/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00010: val_accuracy did not improve from 0.11330\n","Epoch 11/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3012 - accuracy: 0.1084 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00011: val_accuracy did not improve from 0.11330\n","Epoch 12/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00012: val_accuracy did not improve from 0.11330\n","Epoch 13/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n","\n","Epoch 00013: val_accuracy did not improve from 0.11330\n","Epoch 14/500\n","52/52 [==============================] - 15s 286ms/step - loss: 2.3013 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00014: val_accuracy did not improve from 0.11330\n","Epoch 15/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3002 - val_accuracy: 0.1133\n","\n","Epoch 00015: val_accuracy did not improve from 0.11330\n","Epoch 16/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3011 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n","\n","Epoch 00016: val_accuracy did not improve from 0.11330\n","Epoch 17/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3013 - accuracy: 0.1139 - val_loss: 2.3002 - val_accuracy: 0.1133\n","\n","Epoch 00017: val_accuracy did not improve from 0.11330\n","Epoch 18/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00018: val_accuracy did not improve from 0.11330\n","Epoch 19/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3013 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n","\n","Epoch 00019: val_accuracy did not improve from 0.11330\n","Epoch 20/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00020: val_accuracy did not improve from 0.11330\n","Epoch 21/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00021: val_accuracy did not improve from 0.11330\n","Epoch 22/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00022: val_accuracy did not improve from 0.11330\n","Epoch 23/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00023: val_accuracy did not improve from 0.11330\n","Epoch 24/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00024: val_accuracy did not improve from 0.11330\n","Epoch 25/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00025: val_accuracy did not improve from 0.11330\n","Epoch 26/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00026: val_accuracy did not improve from 0.11330\n","Epoch 27/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00027: val_accuracy did not improve from 0.11330\n","Epoch 28/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00028: val_accuracy did not improve from 0.11330\n","Epoch 29/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00029: val_accuracy did not improve from 0.11330\n","Epoch 30/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00030: val_accuracy did not improve from 0.11330\n","Epoch 31/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00031: val_accuracy did not improve from 0.11330\n","Epoch 32/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00032: val_accuracy did not improve from 0.11330\n","Epoch 33/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00033: val_accuracy did not improve from 0.11330\n","Epoch 34/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00034: val_accuracy did not improve from 0.11330\n","Epoch 35/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00035: val_accuracy did not improve from 0.11330\n","Epoch 36/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00036: val_accuracy did not improve from 0.11330\n","Epoch 37/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00037: val_accuracy did not improve from 0.11330\n","Epoch 38/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00038: val_accuracy did not improve from 0.11330\n","Epoch 39/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00039: val_accuracy did not improve from 0.11330\n","Epoch 40/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00040: val_accuracy did not improve from 0.11330\n","Epoch 41/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00041: val_accuracy did not improve from 0.11330\n","Epoch 42/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00042: val_accuracy did not improve from 0.11330\n","Epoch 43/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00043: val_accuracy did not improve from 0.11330\n","Epoch 44/500\n","52/52 [==============================] - 15s 286ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00044: val_accuracy did not improve from 0.11330\n","Epoch 45/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00045: val_accuracy did not improve from 0.11330\n","Epoch 46/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00046: val_accuracy did not improve from 0.11330\n","Epoch 47/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00047: val_accuracy did not improve from 0.11330\n","Epoch 48/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00048: val_accuracy did not improve from 0.11330\n","Epoch 49/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00049: val_accuracy did not improve from 0.11330\n","Epoch 50/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00050: val_accuracy did not improve from 0.11330\n","Epoch 51/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00051: val_accuracy did not improve from 0.11330\n","Epoch 52/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00052: val_accuracy did not improve from 0.11330\n","Epoch 53/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00053: val_accuracy did not improve from 0.11330\n","Epoch 54/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00054: val_accuracy did not improve from 0.11330\n","Epoch 55/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00055: val_accuracy did not improve from 0.11330\n","Epoch 56/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00056: val_accuracy did not improve from 0.11330\n","Epoch 57/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00057: val_accuracy did not improve from 0.11330\n","Epoch 58/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00058: val_accuracy did not improve from 0.11330\n","Epoch 59/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00059: val_accuracy did not improve from 0.11330\n","Epoch 60/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00060: val_accuracy did not improve from 0.11330\n","Epoch 61/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00061: val_accuracy did not improve from 0.11330\n","Epoch 62/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00062: val_accuracy did not improve from 0.11330\n","Epoch 63/500\n","52/52 [==============================] - 15s 286ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00063: val_accuracy did not improve from 0.11330\n","Epoch 64/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00064: val_accuracy did not improve from 0.11330\n","Epoch 65/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00065: val_accuracy did not improve from 0.11330\n","Epoch 66/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n","\n","Epoch 00066: val_accuracy did not improve from 0.11330\n","Epoch 67/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n","\n","Epoch 00067: val_accuracy did not improve from 0.11330\n","Epoch 68/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00068: val_accuracy did not improve from 0.11330\n","Epoch 69/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00069: val_accuracy did not improve from 0.11330\n","Epoch 70/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00070: val_accuracy did not improve from 0.11330\n","Epoch 71/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00071: val_accuracy did not improve from 0.11330\n","Epoch 72/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00072: val_accuracy did not improve from 0.11330\n","Epoch 73/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00073: val_accuracy did not improve from 0.11330\n","Epoch 74/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00074: val_accuracy did not improve from 0.11330\n","Epoch 75/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00075: val_accuracy did not improve from 0.11330\n","Epoch 76/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00076: val_accuracy did not improve from 0.11330\n","Epoch 77/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00077: val_accuracy did not improve from 0.11330\n","Epoch 78/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00078: val_accuracy did not improve from 0.11330\n","Epoch 79/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00079: val_accuracy did not improve from 0.11330\n","Epoch 80/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00080: val_accuracy did not improve from 0.11330\n","Epoch 81/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00081: val_accuracy did not improve from 0.11330\n","Epoch 82/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00082: val_accuracy did not improve from 0.11330\n","Epoch 83/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00083: val_accuracy did not improve from 0.11330\n","Epoch 84/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00084: val_accuracy did not improve from 0.11330\n","Epoch 85/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00085: val_accuracy did not improve from 0.11330\n","Epoch 86/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00086: val_accuracy did not improve from 0.11330\n","Epoch 87/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00087: val_accuracy did not improve from 0.11330\n","Epoch 88/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00088: val_accuracy did not improve from 0.11330\n","Epoch 89/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00089: val_accuracy did not improve from 0.11330\n","Epoch 90/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00090: val_accuracy did not improve from 0.11330\n","Epoch 91/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00091: val_accuracy did not improve from 0.11330\n","Epoch 92/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00092: val_accuracy did not improve from 0.11330\n","Epoch 93/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00093: val_accuracy did not improve from 0.11330\n","Epoch 94/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00094: val_accuracy did not improve from 0.11330\n","Epoch 95/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00095: val_accuracy did not improve from 0.11330\n","Epoch 96/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00096: val_accuracy did not improve from 0.11330\n","Epoch 97/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00097: val_accuracy did not improve from 0.11330\n","Epoch 98/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00098: val_accuracy did not improve from 0.11330\n","Epoch 99/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00099: val_accuracy did not improve from 0.11330\n","Epoch 100/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00100: val_accuracy did not improve from 0.11330\n","Epoch 101/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00101: val_accuracy did not improve from 0.11330\n","Epoch 102/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00102: val_accuracy did not improve from 0.11330\n","Epoch 103/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00103: val_accuracy did not improve from 0.11330\n","Epoch 104/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00104: val_accuracy did not improve from 0.11330\n","Epoch 105/500\n","52/52 [==============================] - 15s 283ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00105: val_accuracy did not improve from 0.11330\n","Epoch 106/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00106: val_accuracy did not improve from 0.11330\n","Epoch 107/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00107: val_accuracy did not improve from 0.11330\n","Epoch 108/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00108: val_accuracy did not improve from 0.11330\n","Epoch 109/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00109: val_accuracy did not improve from 0.11330\n","Epoch 110/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00110: val_accuracy did not improve from 0.11330\n","Epoch 111/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00111: val_accuracy did not improve from 0.11330\n","Epoch 112/500\n","52/52 [==============================] - 15s 285ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00112: val_accuracy did not improve from 0.11330\n","Epoch 113/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00113: val_accuracy did not improve from 0.11330\n","Epoch 114/500\n","52/52 [==============================] - 15s 286ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n","\n","Epoch 00114: val_accuracy did not improve from 0.11330\n","Epoch 115/500\n","52/52 [==============================] - 15s 284ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n","\n","Epoch 00115: val_accuracy did not improve from 0.11330\n","Epoch 116/500\n","30/52 [================>.............] - ETA: 5s - loss: 2.3028 - accuracy: 0.0991"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JAeDavrKDQTO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628160732339,"user_tz":-540,"elapsed":4479005,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"51e9e65c-4174-46ca-9208-0199a664a737"},"source":["InceptionV3_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[InceptionV3_checkpoint])\n","# files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 32s 208ms/step - loss: 2.6270 - accuracy: 0.1419 - val_loss: 14.3781 - val_accuracy: 0.0936\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09360, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 2/500\n","52/52 [==============================] - 9s 167ms/step - loss: 2.0403 - accuracy: 0.2960 - val_loss: 26.6248 - val_accuracy: 0.0936\n","\n","Epoch 00002: val_accuracy did not improve from 0.09360\n","Epoch 3/500\n","52/52 [==============================] - 9s 166ms/step - loss: 1.5505 - accuracy: 0.4653 - val_loss: 5.6435 - val_accuracy: 0.0985\n","\n","Epoch 00003: val_accuracy improved from 0.09360 to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 4/500\n","52/52 [==============================] - 9s 165ms/step - loss: 1.1842 - accuracy: 0.6114 - val_loss: 6.0461 - val_accuracy: 0.0936\n","\n","Epoch 00004: val_accuracy did not improve from 0.09852\n","Epoch 5/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.9204 - accuracy: 0.7052 - val_loss: 10.7899 - val_accuracy: 0.0985\n","\n","Epoch 00005: val_accuracy did not improve from 0.09852\n","Epoch 6/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.8079 - accuracy: 0.7375 - val_loss: 8.5648 - val_accuracy: 0.0961\n","\n","Epoch 00006: val_accuracy did not improve from 0.09852\n","Epoch 7/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.6640 - accuracy: 0.7868 - val_loss: 6.4538 - val_accuracy: 0.0985\n","\n","Epoch 00007: val_accuracy did not improve from 0.09852\n","Epoch 8/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.6118 - accuracy: 0.8021 - val_loss: 13.0411 - val_accuracy: 0.1010\n","\n","Epoch 00008: val_accuracy improved from 0.09852 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 9/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.5868 - accuracy: 0.8149 - val_loss: 3.8071 - val_accuracy: 0.2783\n","\n","Epoch 00009: val_accuracy improved from 0.10099 to 0.27833, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 10/500\n","52/52 [==============================] - 9s 171ms/step - loss: 0.4764 - accuracy: 0.8392 - val_loss: 2.5675 - val_accuracy: 0.3350\n","\n","Epoch 00010: val_accuracy improved from 0.27833 to 0.33498, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 11/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.4757 - accuracy: 0.8441 - val_loss: 4.8270 - val_accuracy: 0.2783\n","\n","Epoch 00011: val_accuracy did not improve from 0.33498\n","Epoch 12/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.3909 - accuracy: 0.8721 - val_loss: 2.1594 - val_accuracy: 0.5099\n","\n","Epoch 00012: val_accuracy improved from 0.33498 to 0.50985, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 13/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.4616 - accuracy: 0.8453 - val_loss: 1.1743 - val_accuracy: 0.6502\n","\n","Epoch 00013: val_accuracy improved from 0.50985 to 0.65025, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 14/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.3958 - accuracy: 0.8703 - val_loss: 1.1742 - val_accuracy: 0.6872\n","\n","Epoch 00014: val_accuracy improved from 0.65025 to 0.68719, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 15/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.3829 - accuracy: 0.8752 - val_loss: 1.4953 - val_accuracy: 0.6773\n","\n","Epoch 00015: val_accuracy did not improve from 0.68719\n","Epoch 16/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.3080 - accuracy: 0.8952 - val_loss: 2.8808 - val_accuracy: 0.5369\n","\n","Epoch 00016: val_accuracy did not improve from 0.68719\n","Epoch 17/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.2826 - accuracy: 0.9062 - val_loss: 0.4876 - val_accuracy: 0.8325\n","\n","Epoch 00017: val_accuracy improved from 0.68719 to 0.83251, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 18/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.2528 - accuracy: 0.9166 - val_loss: 0.5877 - val_accuracy: 0.8350\n","\n","Epoch 00018: val_accuracy improved from 0.83251 to 0.83498, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 19/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.3323 - accuracy: 0.8855 - val_loss: 1.1917 - val_accuracy: 0.7291\n","\n","Epoch 00019: val_accuracy did not improve from 0.83498\n","Epoch 20/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.2668 - accuracy: 0.9153 - val_loss: 0.5428 - val_accuracy: 0.8498\n","\n","Epoch 00020: val_accuracy improved from 0.83498 to 0.84975, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 21/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.2270 - accuracy: 0.9245 - val_loss: 0.6171 - val_accuracy: 0.8300\n","\n","Epoch 00021: val_accuracy did not improve from 0.84975\n","Epoch 22/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.2278 - accuracy: 0.9220 - val_loss: 0.9925 - val_accuracy: 0.7783\n","\n","Epoch 00022: val_accuracy did not improve from 0.84975\n","Epoch 23/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.1876 - accuracy: 0.9403 - val_loss: 0.4254 - val_accuracy: 0.8793\n","\n","Epoch 00023: val_accuracy improved from 0.84975 to 0.87931, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 24/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.2325 - accuracy: 0.9281 - val_loss: 1.7918 - val_accuracy: 0.5985\n","\n","Epoch 00024: val_accuracy did not improve from 0.87931\n","Epoch 25/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.2872 - accuracy: 0.9062 - val_loss: 1.4583 - val_accuracy: 0.7143\n","\n","Epoch 00025: val_accuracy did not improve from 0.87931\n","Epoch 26/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.2275 - accuracy: 0.9269 - val_loss: 5.4301 - val_accuracy: 0.3177\n","\n","Epoch 00026: val_accuracy did not improve from 0.87931\n","Epoch 27/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.2133 - accuracy: 0.9263 - val_loss: 0.6239 - val_accuracy: 0.8547\n","\n","Epoch 00027: val_accuracy did not improve from 0.87931\n","Epoch 28/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.1627 - accuracy: 0.9476 - val_loss: 1.7868 - val_accuracy: 0.6429\n","\n","Epoch 00028: val_accuracy did not improve from 0.87931\n","Epoch 29/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1652 - accuracy: 0.9385 - val_loss: 1.0345 - val_accuracy: 0.7980\n","\n","Epoch 00029: val_accuracy did not improve from 0.87931\n","Epoch 30/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.2203 - accuracy: 0.9251 - val_loss: 1.0366 - val_accuracy: 0.7734\n","\n","Epoch 00030: val_accuracy did not improve from 0.87931\n","Epoch 31/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.1134 - accuracy: 0.9598 - val_loss: 0.6207 - val_accuracy: 0.8202\n","\n","Epoch 00031: val_accuracy did not improve from 0.87931\n","Epoch 32/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.2123 - accuracy: 0.9251 - val_loss: 47.4798 - val_accuracy: 0.1330\n","\n","Epoch 00032: val_accuracy did not improve from 0.87931\n","Epoch 33/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.2785 - accuracy: 0.9032 - val_loss: 4.1842 - val_accuracy: 0.5887\n","\n","Epoch 00033: val_accuracy did not improve from 0.87931\n","Epoch 34/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1676 - accuracy: 0.9403 - val_loss: 0.8817 - val_accuracy: 0.8079\n","\n","Epoch 00034: val_accuracy did not improve from 0.87931\n","Epoch 35/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.1864 - accuracy: 0.9397 - val_loss: 0.4798 - val_accuracy: 0.8768\n","\n","Epoch 00035: val_accuracy did not improve from 0.87931\n","Epoch 36/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1223 - accuracy: 0.9598 - val_loss: 0.3692 - val_accuracy: 0.8941\n","\n","Epoch 00036: val_accuracy improved from 0.87931 to 0.89409, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 37/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1324 - accuracy: 0.9507 - val_loss: 0.6882 - val_accuracy: 0.8473\n","\n","Epoch 00037: val_accuracy did not improve from 0.89409\n","Epoch 38/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.1247 - accuracy: 0.9592 - val_loss: 0.8329 - val_accuracy: 0.8153\n","\n","Epoch 00038: val_accuracy did not improve from 0.89409\n","Epoch 39/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.1723 - accuracy: 0.9440 - val_loss: 0.9095 - val_accuracy: 0.7882\n","\n","Epoch 00039: val_accuracy did not improve from 0.89409\n","Epoch 40/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.1379 - accuracy: 0.9568 - val_loss: 1.8336 - val_accuracy: 0.7069\n","\n","Epoch 00040: val_accuracy did not improve from 0.89409\n","Epoch 41/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0798 - accuracy: 0.9732 - val_loss: 0.6410 - val_accuracy: 0.8424\n","\n","Epoch 00041: val_accuracy did not improve from 0.89409\n","Epoch 42/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0917 - accuracy: 0.9708 - val_loss: 0.5431 - val_accuracy: 0.8695\n","\n","Epoch 00042: val_accuracy did not improve from 0.89409\n","Epoch 43/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1971 - accuracy: 0.9354 - val_loss: 3.1234 - val_accuracy: 0.6773\n","\n","Epoch 00043: val_accuracy did not improve from 0.89409\n","Epoch 44/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1712 - accuracy: 0.9452 - val_loss: 13.6867 - val_accuracy: 0.3128\n","\n","Epoch 00044: val_accuracy did not improve from 0.89409\n","Epoch 45/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.1083 - accuracy: 0.9598 - val_loss: 0.4800 - val_accuracy: 0.8670\n","\n","Epoch 00045: val_accuracy did not improve from 0.89409\n","Epoch 46/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.1113 - accuracy: 0.9629 - val_loss: 0.4935 - val_accuracy: 0.8621\n","\n","Epoch 00046: val_accuracy did not improve from 0.89409\n","Epoch 47/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0970 - accuracy: 0.9695 - val_loss: 0.4278 - val_accuracy: 0.8818\n","\n","Epoch 00047: val_accuracy did not improve from 0.89409\n","Epoch 48/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0702 - accuracy: 0.9762 - val_loss: 0.6154 - val_accuracy: 0.8448\n","\n","Epoch 00048: val_accuracy did not improve from 0.89409\n","Epoch 49/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0852 - accuracy: 0.9683 - val_loss: 0.5450 - val_accuracy: 0.8670\n","\n","Epoch 00049: val_accuracy did not improve from 0.89409\n","Epoch 50/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.1194 - accuracy: 0.9568 - val_loss: 0.5574 - val_accuracy: 0.8596\n","\n","Epoch 00050: val_accuracy did not improve from 0.89409\n","Epoch 51/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0632 - accuracy: 0.9787 - val_loss: 0.5431 - val_accuracy: 0.8596\n","\n","Epoch 00051: val_accuracy did not improve from 0.89409\n","Epoch 52/500\n","52/52 [==============================] - 9s 164ms/step - loss: 0.0906 - accuracy: 0.9720 - val_loss: 0.6593 - val_accuracy: 0.8498\n","\n","Epoch 00052: val_accuracy did not improve from 0.89409\n","Epoch 53/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0935 - accuracy: 0.9665 - val_loss: 0.6523 - val_accuracy: 0.8325\n","\n","Epoch 00053: val_accuracy did not improve from 0.89409\n","Epoch 54/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.1110 - accuracy: 0.9635 - val_loss: 0.6108 - val_accuracy: 0.8596\n","\n","Epoch 00054: val_accuracy did not improve from 0.89409\n","Epoch 55/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0939 - accuracy: 0.9714 - val_loss: 3.3269 - val_accuracy: 0.5591\n","\n","Epoch 00055: val_accuracy did not improve from 0.89409\n","Epoch 56/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0653 - accuracy: 0.9775 - val_loss: 0.4195 - val_accuracy: 0.8818\n","\n","Epoch 00056: val_accuracy did not improve from 0.89409\n","Epoch 57/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0538 - accuracy: 0.9805 - val_loss: 0.3771 - val_accuracy: 0.9039\n","\n","Epoch 00057: val_accuracy improved from 0.89409 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 58/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0456 - accuracy: 0.9811 - val_loss: 0.5089 - val_accuracy: 0.8793\n","\n","Epoch 00058: val_accuracy did not improve from 0.90394\n","Epoch 59/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.1029 - accuracy: 0.9683 - val_loss: 1.0587 - val_accuracy: 0.7882\n","\n","Epoch 00059: val_accuracy did not improve from 0.90394\n","Epoch 60/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.1297 - accuracy: 0.9592 - val_loss: 0.5447 - val_accuracy: 0.8571\n","\n","Epoch 00060: val_accuracy did not improve from 0.90394\n","Epoch 61/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0928 - accuracy: 0.9653 - val_loss: 0.5727 - val_accuracy: 0.8695\n","\n","Epoch 00061: val_accuracy did not improve from 0.90394\n","Epoch 62/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1010 - accuracy: 0.9635 - val_loss: 0.7203 - val_accuracy: 0.8695\n","\n","Epoch 00062: val_accuracy did not improve from 0.90394\n","Epoch 63/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0851 - accuracy: 0.9726 - val_loss: 0.9870 - val_accuracy: 0.7833\n","\n","Epoch 00063: val_accuracy did not improve from 0.90394\n","Epoch 64/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0808 - accuracy: 0.9714 - val_loss: 0.7584 - val_accuracy: 0.8227\n","\n","Epoch 00064: val_accuracy did not improve from 0.90394\n","Epoch 65/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0922 - accuracy: 0.9671 - val_loss: 0.6053 - val_accuracy: 0.8473\n","\n","Epoch 00065: val_accuracy did not improve from 0.90394\n","Epoch 66/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.1126 - accuracy: 0.9622 - val_loss: 1.5298 - val_accuracy: 0.7069\n","\n","Epoch 00066: val_accuracy did not improve from 0.90394\n","Epoch 67/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0877 - accuracy: 0.9702 - val_loss: 1.9667 - val_accuracy: 0.7094\n","\n","Epoch 00067: val_accuracy did not improve from 0.90394\n","Epoch 68/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0651 - accuracy: 0.9799 - val_loss: 0.6310 - val_accuracy: 0.8892\n","\n","Epoch 00068: val_accuracy did not improve from 0.90394\n","Epoch 69/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0742 - accuracy: 0.9762 - val_loss: 0.4680 - val_accuracy: 0.8941\n","\n","Epoch 00069: val_accuracy did not improve from 0.90394\n","Epoch 70/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0867 - accuracy: 0.9732 - val_loss: 0.4906 - val_accuracy: 0.8571\n","\n","Epoch 00070: val_accuracy did not improve from 0.90394\n","Epoch 71/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0743 - accuracy: 0.9769 - val_loss: 1.5006 - val_accuracy: 0.8005\n","\n","Epoch 00071: val_accuracy did not improve from 0.90394\n","Epoch 72/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0480 - accuracy: 0.9848 - val_loss: 0.3915 - val_accuracy: 0.8867\n","\n","Epoch 00072: val_accuracy did not improve from 0.90394\n","Epoch 73/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0888 - accuracy: 0.9689 - val_loss: 0.6810 - val_accuracy: 0.8498\n","\n","Epoch 00073: val_accuracy did not improve from 0.90394\n","Epoch 74/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1273 - accuracy: 0.9647 - val_loss: 1.6484 - val_accuracy: 0.7488\n","\n","Epoch 00074: val_accuracy did not improve from 0.90394\n","Epoch 75/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0867 - accuracy: 0.9677 - val_loss: 0.4300 - val_accuracy: 0.8966\n","\n","Epoch 00075: val_accuracy did not improve from 0.90394\n","Epoch 76/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0480 - accuracy: 0.9836 - val_loss: 0.5224 - val_accuracy: 0.8596\n","\n","Epoch 00076: val_accuracy did not improve from 0.90394\n","Epoch 77/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.3891 - val_accuracy: 0.9163\n","\n","Epoch 00077: val_accuracy improved from 0.90394 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 78/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.3750 - val_accuracy: 0.9039\n","\n","Epoch 00078: val_accuracy did not improve from 0.91626\n","Epoch 79/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0666 - accuracy: 0.9756 - val_loss: 0.5888 - val_accuracy: 0.8571\n","\n","Epoch 00079: val_accuracy did not improve from 0.91626\n","Epoch 80/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0472 - accuracy: 0.9842 - val_loss: 0.6771 - val_accuracy: 0.8522\n","\n","Epoch 00080: val_accuracy did not improve from 0.91626\n","Epoch 81/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 0.4988 - val_accuracy: 0.8966\n","\n","Epoch 00081: val_accuracy did not improve from 0.91626\n","Epoch 82/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0351 - accuracy: 0.9878 - val_loss: 0.5007 - val_accuracy: 0.8793\n","\n","Epoch 00082: val_accuracy did not improve from 0.91626\n","Epoch 83/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0775 - accuracy: 0.9750 - val_loss: 2.9850 - val_accuracy: 0.6872\n","\n","Epoch 00083: val_accuracy did not improve from 0.91626\n","Epoch 84/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0862 - accuracy: 0.9695 - val_loss: 1.0283 - val_accuracy: 0.8030\n","\n","Epoch 00084: val_accuracy did not improve from 0.91626\n","Epoch 85/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1447 - accuracy: 0.9555 - val_loss: 0.4870 - val_accuracy: 0.8966\n","\n","Epoch 00085: val_accuracy did not improve from 0.91626\n","Epoch 86/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0927 - accuracy: 0.9738 - val_loss: 0.8201 - val_accuracy: 0.8128\n","\n","Epoch 00086: val_accuracy did not improve from 0.91626\n","Epoch 87/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0378 - accuracy: 0.9915 - val_loss: 0.5274 - val_accuracy: 0.8916\n","\n","Epoch 00087: val_accuracy did not improve from 0.91626\n","Epoch 88/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0446 - accuracy: 0.9842 - val_loss: 0.8459 - val_accuracy: 0.8350\n","\n","Epoch 00088: val_accuracy did not improve from 0.91626\n","Epoch 89/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1372 - accuracy: 0.9586 - val_loss: 0.9395 - val_accuracy: 0.7931\n","\n","Epoch 00089: val_accuracy did not improve from 0.91626\n","Epoch 90/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0916 - accuracy: 0.9677 - val_loss: 0.5532 - val_accuracy: 0.8867\n","\n","Epoch 00090: val_accuracy did not improve from 0.91626\n","Epoch 91/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0705 - accuracy: 0.9799 - val_loss: 0.6499 - val_accuracy: 0.8670\n","\n","Epoch 00091: val_accuracy did not improve from 0.91626\n","Epoch 92/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0406 - accuracy: 0.9896 - val_loss: 0.6382 - val_accuracy: 0.8892\n","\n","Epoch 00092: val_accuracy did not improve from 0.91626\n","Epoch 93/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0465 - accuracy: 0.9884 - val_loss: 0.5451 - val_accuracy: 0.8768\n","\n","Epoch 00093: val_accuracy did not improve from 0.91626\n","Epoch 94/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0514 - accuracy: 0.9811 - val_loss: 0.4882 - val_accuracy: 0.8966\n","\n","Epoch 00094: val_accuracy did not improve from 0.91626\n","Epoch 95/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0627 - accuracy: 0.9805 - val_loss: 0.8833 - val_accuracy: 0.8300\n","\n","Epoch 00095: val_accuracy did not improve from 0.91626\n","Epoch 96/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.1409 - accuracy: 0.9537 - val_loss: 12.9506 - val_accuracy: 0.3966\n","\n","Epoch 00096: val_accuracy did not improve from 0.91626\n","Epoch 97/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0900 - accuracy: 0.9671 - val_loss: 0.6757 - val_accuracy: 0.8571\n","\n","Epoch 00097: val_accuracy did not improve from 0.91626\n","Epoch 98/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.1076 - accuracy: 0.9629 - val_loss: 0.8893 - val_accuracy: 0.8424\n","\n","Epoch 00098: val_accuracy did not improve from 0.91626\n","Epoch 99/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0733 - accuracy: 0.9762 - val_loss: 0.6069 - val_accuracy: 0.8498\n","\n","Epoch 00099: val_accuracy did not improve from 0.91626\n","Epoch 100/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0545 - accuracy: 0.9769 - val_loss: 0.4302 - val_accuracy: 0.8966\n","\n","Epoch 00100: val_accuracy did not improve from 0.91626\n","Epoch 101/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0368 - accuracy: 0.9872 - val_loss: 0.4836 - val_accuracy: 0.8892\n","\n","Epoch 00101: val_accuracy did not improve from 0.91626\n","Epoch 102/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0185 - accuracy: 0.9957 - val_loss: 0.4199 - val_accuracy: 0.8966\n","\n","Epoch 00102: val_accuracy did not improve from 0.91626\n","Epoch 103/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.4474 - val_accuracy: 0.9064\n","\n","Epoch 00103: val_accuracy did not improve from 0.91626\n","Epoch 104/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0135 - accuracy: 0.9939 - val_loss: 0.5216 - val_accuracy: 0.8818\n","\n","Epoch 00104: val_accuracy did not improve from 0.91626\n","Epoch 105/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 1.2198 - val_accuracy: 0.7956\n","\n","Epoch 00105: val_accuracy did not improve from 0.91626\n","Epoch 106/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0404 - accuracy: 0.9884 - val_loss: 0.5342 - val_accuracy: 0.8842\n","\n","Epoch 00106: val_accuracy did not improve from 0.91626\n","Epoch 107/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0592 - accuracy: 0.9769 - val_loss: 1.9091 - val_accuracy: 0.6970\n","\n","Epoch 00107: val_accuracy did not improve from 0.91626\n","Epoch 108/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0743 - accuracy: 0.9769 - val_loss: 0.5573 - val_accuracy: 0.8892\n","\n","Epoch 00108: val_accuracy did not improve from 0.91626\n","Epoch 109/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1055 - accuracy: 0.9708 - val_loss: 1.6675 - val_accuracy: 0.7488\n","\n","Epoch 00109: val_accuracy did not improve from 0.91626\n","Epoch 110/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0647 - accuracy: 0.9787 - val_loss: 0.7790 - val_accuracy: 0.8251\n","\n","Epoch 00110: val_accuracy did not improve from 0.91626\n","Epoch 111/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0480 - accuracy: 0.9842 - val_loss: 0.5649 - val_accuracy: 0.8793\n","\n","Epoch 00111: val_accuracy did not improve from 0.91626\n","Epoch 112/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 0.5265 - val_accuracy: 0.8768\n","\n","Epoch 00112: val_accuracy did not improve from 0.91626\n","Epoch 113/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0373 - accuracy: 0.9915 - val_loss: 0.6335 - val_accuracy: 0.8719\n","\n","Epoch 00113: val_accuracy did not improve from 0.91626\n","Epoch 114/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0152 - accuracy: 0.9939 - val_loss: 0.3862 - val_accuracy: 0.8941\n","\n","Epoch 00114: val_accuracy did not improve from 0.91626\n","Epoch 115/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.4923 - val_accuracy: 0.8990\n","\n","Epoch 00115: val_accuracy did not improve from 0.91626\n","Epoch 116/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0447 - accuracy: 0.9872 - val_loss: 0.8938 - val_accuracy: 0.8227\n","\n","Epoch 00116: val_accuracy did not improve from 0.91626\n","Epoch 117/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.1533 - accuracy: 0.9513 - val_loss: 3.4735 - val_accuracy: 0.7020\n","\n","Epoch 00117: val_accuracy did not improve from 0.91626\n","Epoch 118/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0994 - accuracy: 0.9671 - val_loss: 0.7598 - val_accuracy: 0.8719\n","\n","Epoch 00118: val_accuracy did not improve from 0.91626\n","Epoch 119/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0535 - accuracy: 0.9823 - val_loss: 0.6343 - val_accuracy: 0.8596\n","\n","Epoch 00119: val_accuracy did not improve from 0.91626\n","Epoch 120/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0511 - accuracy: 0.9823 - val_loss: 0.4577 - val_accuracy: 0.8793\n","\n","Epoch 00120: val_accuracy did not improve from 0.91626\n","Epoch 121/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0319 - accuracy: 0.9909 - val_loss: 0.4511 - val_accuracy: 0.9015\n","\n","Epoch 00121: val_accuracy did not improve from 0.91626\n","Epoch 122/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.3565 - val_accuracy: 0.9187\n","\n","Epoch 00122: val_accuracy improved from 0.91626 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 123/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0170 - accuracy: 0.9933 - val_loss: 0.4902 - val_accuracy: 0.8818\n","\n","Epoch 00123: val_accuracy did not improve from 0.91872\n","Epoch 124/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.4155 - val_accuracy: 0.9015\n","\n","Epoch 00124: val_accuracy did not improve from 0.91872\n","Epoch 125/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.4125 - val_accuracy: 0.9064\n","\n","Epoch 00125: val_accuracy did not improve from 0.91872\n","Epoch 126/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.6863 - val_accuracy: 0.8448\n","\n","Epoch 00126: val_accuracy did not improve from 0.91872\n","Epoch 127/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1072 - accuracy: 0.9720 - val_loss: 0.8693 - val_accuracy: 0.8227\n","\n","Epoch 00127: val_accuracy did not improve from 0.91872\n","Epoch 128/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1208 - accuracy: 0.9635 - val_loss: 0.5674 - val_accuracy: 0.8744\n","\n","Epoch 00128: val_accuracy did not improve from 0.91872\n","Epoch 129/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0376 - accuracy: 0.9878 - val_loss: 0.4519 - val_accuracy: 0.9064\n","\n","Epoch 00129: val_accuracy did not improve from 0.91872\n","Epoch 130/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0346 - accuracy: 0.9860 - val_loss: 0.3332 - val_accuracy: 0.9212\n","\n","Epoch 00130: val_accuracy improved from 0.91872 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 131/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0281 - accuracy: 0.9927 - val_loss: 0.3177 - val_accuracy: 0.9286\n","\n","Epoch 00131: val_accuracy improved from 0.92118 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 132/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.3078 - val_accuracy: 0.9187\n","\n","Epoch 00132: val_accuracy did not improve from 0.92857\n","Epoch 133/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 0.5235 - val_accuracy: 0.8892\n","\n","Epoch 00133: val_accuracy did not improve from 0.92857\n","Epoch 134/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.6454 - val_accuracy: 0.8670\n","\n","Epoch 00134: val_accuracy did not improve from 0.92857\n","Epoch 135/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0271 - accuracy: 0.9890 - val_loss: 0.4548 - val_accuracy: 0.9064\n","\n","Epoch 00135: val_accuracy did not improve from 0.92857\n","Epoch 136/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.5324 - val_accuracy: 0.8867\n","\n","Epoch 00136: val_accuracy did not improve from 0.92857\n","Epoch 137/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.5104 - val_accuracy: 0.8966\n","\n","Epoch 00137: val_accuracy did not improve from 0.92857\n","Epoch 138/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.1203 - accuracy: 0.9665 - val_loss: 0.7871 - val_accuracy: 0.8374\n","\n","Epoch 00138: val_accuracy did not improve from 0.92857\n","Epoch 139/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0861 - accuracy: 0.9720 - val_loss: 0.5180 - val_accuracy: 0.8645\n","\n","Epoch 00139: val_accuracy did not improve from 0.92857\n","Epoch 140/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0314 - accuracy: 0.9903 - val_loss: 0.5189 - val_accuracy: 0.8867\n","\n","Epoch 00140: val_accuracy did not improve from 0.92857\n","Epoch 141/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0315 - accuracy: 0.9866 - val_loss: 0.3895 - val_accuracy: 0.9212\n","\n","Epoch 00141: val_accuracy did not improve from 0.92857\n","Epoch 142/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.3361 - val_accuracy: 0.8966\n","\n","Epoch 00142: val_accuracy did not improve from 0.92857\n","Epoch 143/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.5426 - val_accuracy: 0.8744\n","\n","Epoch 00143: val_accuracy did not improve from 0.92857\n","Epoch 144/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0300 - accuracy: 0.9884 - val_loss: 0.5219 - val_accuracy: 0.8768\n","\n","Epoch 00144: val_accuracy did not improve from 0.92857\n","Epoch 145/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 0.4839 - val_accuracy: 0.8941\n","\n","Epoch 00145: val_accuracy did not improve from 0.92857\n","Epoch 146/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0435 - accuracy: 0.9860 - val_loss: 0.9844 - val_accuracy: 0.8325\n","\n","Epoch 00146: val_accuracy did not improve from 0.92857\n","Epoch 147/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0377 - accuracy: 0.9896 - val_loss: 0.7342 - val_accuracy: 0.8744\n","\n","Epoch 00147: val_accuracy did not improve from 0.92857\n","Epoch 148/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0167 - accuracy: 0.9963 - val_loss: 0.5396 - val_accuracy: 0.8916\n","\n","Epoch 00148: val_accuracy did not improve from 0.92857\n","Epoch 149/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 0.4948 - val_accuracy: 0.8941\n","\n","Epoch 00149: val_accuracy did not improve from 0.92857\n","Epoch 150/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0409 - accuracy: 0.9848 - val_loss: 0.3291 - val_accuracy: 0.9212\n","\n","Epoch 00150: val_accuracy did not improve from 0.92857\n","Epoch 151/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0414 - accuracy: 0.9872 - val_loss: 0.6978 - val_accuracy: 0.8498\n","\n","Epoch 00151: val_accuracy did not improve from 0.92857\n","Epoch 152/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0930 - accuracy: 0.9732 - val_loss: 0.5579 - val_accuracy: 0.9015\n","\n","Epoch 00152: val_accuracy did not improve from 0.92857\n","Epoch 153/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0333 - accuracy: 0.9890 - val_loss: 0.6308 - val_accuracy: 0.8424\n","\n","Epoch 00153: val_accuracy did not improve from 0.92857\n","Epoch 154/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0864 - accuracy: 0.9756 - val_loss: 1.2656 - val_accuracy: 0.7685\n","\n","Epoch 00154: val_accuracy did not improve from 0.92857\n","Epoch 155/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0578 - accuracy: 0.9811 - val_loss: 0.8729 - val_accuracy: 0.8522\n","\n","Epoch 00155: val_accuracy did not improve from 0.92857\n","Epoch 156/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0289 - accuracy: 0.9927 - val_loss: 0.4513 - val_accuracy: 0.9039\n","\n","Epoch 00156: val_accuracy did not improve from 0.92857\n","Epoch 157/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0347 - accuracy: 0.9872 - val_loss: 0.5365 - val_accuracy: 0.8990\n","\n","Epoch 00157: val_accuracy did not improve from 0.92857\n","Epoch 158/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.4689 - val_accuracy: 0.9015\n","\n","Epoch 00158: val_accuracy did not improve from 0.92857\n","Epoch 159/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.4082 - val_accuracy: 0.9015\n","\n","Epoch 00159: val_accuracy did not improve from 0.92857\n","Epoch 160/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0104 - accuracy: 0.9957 - val_loss: 0.4147 - val_accuracy: 0.9089\n","\n","Epoch 00160: val_accuracy did not improve from 0.92857\n","Epoch 161/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0268 - accuracy: 0.9903 - val_loss: 0.7654 - val_accuracy: 0.8473\n","\n","Epoch 00161: val_accuracy did not improve from 0.92857\n","Epoch 162/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0652 - accuracy: 0.9799 - val_loss: 3.8532 - val_accuracy: 0.6650\n","\n","Epoch 00162: val_accuracy did not improve from 0.92857\n","Epoch 163/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0682 - accuracy: 0.9781 - val_loss: 0.5781 - val_accuracy: 0.8793\n","\n","Epoch 00163: val_accuracy did not improve from 0.92857\n","Epoch 164/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.6033 - val_accuracy: 0.8941\n","\n","Epoch 00164: val_accuracy did not improve from 0.92857\n","Epoch 165/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.4993 - val_accuracy: 0.8744\n","\n","Epoch 00165: val_accuracy did not improve from 0.92857\n","Epoch 166/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.5135 - val_accuracy: 0.8867\n","\n","Epoch 00166: val_accuracy did not improve from 0.92857\n","Epoch 167/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0226 - accuracy: 0.9945 - val_loss: 0.5143 - val_accuracy: 0.8867\n","\n","Epoch 00167: val_accuracy did not improve from 0.92857\n","Epoch 168/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.5563 - val_accuracy: 0.9039\n","\n","Epoch 00168: val_accuracy did not improve from 0.92857\n","Epoch 169/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.5382 - val_accuracy: 0.8941\n","\n","Epoch 00169: val_accuracy did not improve from 0.92857\n","Epoch 170/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.4726 - val_accuracy: 0.8916\n","\n","Epoch 00170: val_accuracy did not improve from 0.92857\n","Epoch 171/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 0.5995 - val_accuracy: 0.8867\n","\n","Epoch 00171: val_accuracy did not improve from 0.92857\n","Epoch 172/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0549 - accuracy: 0.9836 - val_loss: 0.8267 - val_accuracy: 0.8448\n","\n","Epoch 00172: val_accuracy did not improve from 0.92857\n","Epoch 173/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0440 - accuracy: 0.9836 - val_loss: 0.4867 - val_accuracy: 0.9039\n","\n","Epoch 00173: val_accuracy did not improve from 0.92857\n","Epoch 174/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0441 - accuracy: 0.9848 - val_loss: 0.7331 - val_accuracy: 0.8473\n","\n","Epoch 00174: val_accuracy did not improve from 0.92857\n","Epoch 175/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0598 - accuracy: 0.9781 - val_loss: 0.9074 - val_accuracy: 0.8645\n","\n","Epoch 00175: val_accuracy did not improve from 0.92857\n","Epoch 176/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.6302 - val_accuracy: 0.8818\n","\n","Epoch 00176: val_accuracy did not improve from 0.92857\n","Epoch 177/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0262 - accuracy: 0.9933 - val_loss: 0.5581 - val_accuracy: 0.8990\n","\n","Epoch 00177: val_accuracy did not improve from 0.92857\n","Epoch 178/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0214 - accuracy: 0.9921 - val_loss: 0.5132 - val_accuracy: 0.9015\n","\n","Epoch 00178: val_accuracy did not improve from 0.92857\n","Epoch 179/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.4923 - val_accuracy: 0.8990\n","\n","Epoch 00179: val_accuracy did not improve from 0.92857\n","Epoch 180/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.4301 - val_accuracy: 0.9187\n","\n","Epoch 00180: val_accuracy did not improve from 0.92857\n","Epoch 181/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.8374 - val_accuracy: 0.8695\n","\n","Epoch 00181: val_accuracy did not improve from 0.92857\n","Epoch 182/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.4216 - val_accuracy: 0.9089\n","\n","Epoch 00182: val_accuracy did not improve from 0.92857\n","Epoch 183/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0276 - accuracy: 0.9921 - val_loss: 0.5976 - val_accuracy: 0.8916\n","\n","Epoch 00183: val_accuracy did not improve from 0.92857\n","Epoch 184/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0825 - accuracy: 0.9708 - val_loss: 1.1851 - val_accuracy: 0.8350\n","\n","Epoch 00184: val_accuracy did not improve from 0.92857\n","Epoch 185/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0648 - accuracy: 0.9793 - val_loss: 0.8550 - val_accuracy: 0.8300\n","\n","Epoch 00185: val_accuracy did not improve from 0.92857\n","Epoch 186/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0462 - accuracy: 0.9842 - val_loss: 0.5922 - val_accuracy: 0.8818\n","\n","Epoch 00186: val_accuracy did not improve from 0.92857\n","Epoch 187/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 0.6761 - val_accuracy: 0.8670\n","\n","Epoch 00187: val_accuracy did not improve from 0.92857\n","Epoch 188/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.4920 - val_accuracy: 0.9113\n","\n","Epoch 00188: val_accuracy did not improve from 0.92857\n","Epoch 189/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.5401 - val_accuracy: 0.8916\n","\n","Epoch 00189: val_accuracy did not improve from 0.92857\n","Epoch 190/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4977 - val_accuracy: 0.8941\n","\n","Epoch 00190: val_accuracy did not improve from 0.92857\n","Epoch 191/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.4903 - val_accuracy: 0.8966\n","\n","Epoch 00191: val_accuracy did not improve from 0.92857\n","Epoch 192/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.4404 - val_accuracy: 0.9089\n","\n","Epoch 00192: val_accuracy did not improve from 0.92857\n","Epoch 193/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.5310 - val_accuracy: 0.8916\n","\n","Epoch 00193: val_accuracy did not improve from 0.92857\n","Epoch 194/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.5483 - val_accuracy: 0.8793\n","\n","Epoch 00194: val_accuracy did not improve from 0.92857\n","Epoch 195/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.5192 - val_accuracy: 0.8867\n","\n","Epoch 00195: val_accuracy did not improve from 0.92857\n","Epoch 196/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.8586 - val_accuracy: 0.8522\n","\n","Epoch 00196: val_accuracy did not improve from 0.92857\n","Epoch 197/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0373 - accuracy: 0.9915 - val_loss: 0.5378 - val_accuracy: 0.8842\n","\n","Epoch 00197: val_accuracy did not improve from 0.92857\n","Epoch 198/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0424 - accuracy: 0.9872 - val_loss: 0.6300 - val_accuracy: 0.8744\n","\n","Epoch 00198: val_accuracy did not improve from 0.92857\n","Epoch 199/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0161 - accuracy: 0.9933 - val_loss: 0.5606 - val_accuracy: 0.8966\n","\n","Epoch 00199: val_accuracy did not improve from 0.92857\n","Epoch 200/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.7581 - val_accuracy: 0.8399\n","\n","Epoch 00200: val_accuracy did not improve from 0.92857\n","Epoch 201/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0628 - accuracy: 0.9799 - val_loss: 0.8551 - val_accuracy: 0.8276\n","\n","Epoch 00201: val_accuracy did not improve from 0.92857\n","Epoch 202/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 1.0766 - val_accuracy: 0.8128\n","\n","Epoch 00202: val_accuracy did not improve from 0.92857\n","Epoch 203/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0242 - accuracy: 0.9939 - val_loss: 0.6582 - val_accuracy: 0.8818\n","\n","Epoch 00203: val_accuracy did not improve from 0.92857\n","Epoch 204/500\n","52/52 [==============================] - 9s 164ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 0.6246 - val_accuracy: 0.8867\n","\n","Epoch 00204: val_accuracy did not improve from 0.92857\n","Epoch 205/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0820 - accuracy: 0.9744 - val_loss: 0.9830 - val_accuracy: 0.8251\n","\n","Epoch 00205: val_accuracy did not improve from 0.92857\n","Epoch 206/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.7614 - val_accuracy: 0.8621\n","\n","Epoch 00206: val_accuracy did not improve from 0.92857\n","Epoch 207/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.5221 - val_accuracy: 0.8768\n","\n","Epoch 00207: val_accuracy did not improve from 0.92857\n","Epoch 208/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.4661 - val_accuracy: 0.8966\n","\n","Epoch 00208: val_accuracy did not improve from 0.92857\n","Epoch 209/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0179 - accuracy: 0.9933 - val_loss: 0.4807 - val_accuracy: 0.8966\n","\n","Epoch 00209: val_accuracy did not improve from 0.92857\n","Epoch 210/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.6394 - val_accuracy: 0.8842\n","\n","Epoch 00210: val_accuracy did not improve from 0.92857\n","Epoch 211/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0320 - accuracy: 0.9921 - val_loss: 0.6809 - val_accuracy: 0.8670\n","\n","Epoch 00211: val_accuracy did not improve from 0.92857\n","Epoch 212/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0287 - accuracy: 0.9909 - val_loss: 0.6334 - val_accuracy: 0.8867\n","\n","Epoch 00212: val_accuracy did not improve from 0.92857\n","Epoch 213/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 0.9199 - val_accuracy: 0.8596\n","\n","Epoch 00213: val_accuracy did not improve from 0.92857\n","Epoch 214/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0200 - accuracy: 0.9921 - val_loss: 0.7990 - val_accuracy: 0.8571\n","\n","Epoch 00214: val_accuracy did not improve from 0.92857\n","Epoch 215/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.6335 - val_accuracy: 0.8818\n","\n","Epoch 00215: val_accuracy did not improve from 0.92857\n","Epoch 216/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.4349 - val_accuracy: 0.9113\n","\n","Epoch 00216: val_accuracy did not improve from 0.92857\n","Epoch 217/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.5116 - val_accuracy: 0.8941\n","\n","Epoch 00217: val_accuracy did not improve from 0.92857\n","Epoch 218/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0109 - accuracy: 0.9951 - val_loss: 0.5638 - val_accuracy: 0.8842\n","\n","Epoch 00218: val_accuracy did not improve from 0.92857\n","Epoch 219/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0190 - accuracy: 0.9927 - val_loss: 0.7960 - val_accuracy: 0.8596\n","\n","Epoch 00219: val_accuracy did not improve from 0.92857\n","Epoch 220/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0359 - accuracy: 0.9890 - val_loss: 1.1484 - val_accuracy: 0.7906\n","\n","Epoch 00220: val_accuracy did not improve from 0.92857\n","Epoch 221/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0417 - accuracy: 0.9909 - val_loss: 0.8590 - val_accuracy: 0.8596\n","\n","Epoch 00221: val_accuracy did not improve from 0.92857\n","Epoch 222/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 1.0408 - val_accuracy: 0.8153\n","\n","Epoch 00222: val_accuracy did not improve from 0.92857\n","Epoch 223/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0357 - accuracy: 0.9909 - val_loss: 0.6698 - val_accuracy: 0.8719\n","\n","Epoch 00223: val_accuracy did not improve from 0.92857\n","Epoch 224/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0285 - accuracy: 0.9915 - val_loss: 0.5061 - val_accuracy: 0.8818\n","\n","Epoch 00224: val_accuracy did not improve from 0.92857\n","Epoch 225/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0158 - accuracy: 0.9970 - val_loss: 0.4509 - val_accuracy: 0.9064\n","\n","Epoch 00225: val_accuracy did not improve from 0.92857\n","Epoch 226/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.4812 - val_accuracy: 0.9039\n","\n","Epoch 00226: val_accuracy did not improve from 0.92857\n","Epoch 227/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.4460 - val_accuracy: 0.9064\n","\n","Epoch 00227: val_accuracy did not improve from 0.92857\n","Epoch 228/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.9163\n","\n","Epoch 00228: val_accuracy did not improve from 0.92857\n","Epoch 229/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0208 - accuracy: 0.9951 - val_loss: 0.8932 - val_accuracy: 0.8522\n","\n","Epoch 00229: val_accuracy did not improve from 0.92857\n","Epoch 230/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.7318 - val_accuracy: 0.8596\n","\n","Epoch 00230: val_accuracy did not improve from 0.92857\n","Epoch 231/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0211 - accuracy: 0.9927 - val_loss: 0.7224 - val_accuracy: 0.8522\n","\n","Epoch 00231: val_accuracy did not improve from 0.92857\n","Epoch 232/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0103 - accuracy: 0.9957 - val_loss: 0.3891 - val_accuracy: 0.9064\n","\n","Epoch 00232: val_accuracy did not improve from 0.92857\n","Epoch 233/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5259 - val_accuracy: 0.8966\n","\n","Epoch 00233: val_accuracy did not improve from 0.92857\n","Epoch 234/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.5764 - val_accuracy: 0.8793\n","\n","Epoch 00234: val_accuracy did not improve from 0.92857\n","Epoch 235/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.7853 - val_accuracy: 0.8399\n","\n","Epoch 00235: val_accuracy did not improve from 0.92857\n","Epoch 236/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0296 - accuracy: 0.9939 - val_loss: 0.9034 - val_accuracy: 0.8350\n","\n","Epoch 00236: val_accuracy did not improve from 0.92857\n","Epoch 237/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0271 - accuracy: 0.9939 - val_loss: 0.6913 - val_accuracy: 0.8621\n","\n","Epoch 00237: val_accuracy did not improve from 0.92857\n","Epoch 238/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0271 - accuracy: 0.9890 - val_loss: 0.5980 - val_accuracy: 0.8892\n","\n","Epoch 00238: val_accuracy did not improve from 0.92857\n","Epoch 239/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.3933 - val_accuracy: 0.9163\n","\n","Epoch 00239: val_accuracy did not improve from 0.92857\n","Epoch 240/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0130 - accuracy: 0.9982 - val_loss: 0.4886 - val_accuracy: 0.9015\n","\n","Epoch 00240: val_accuracy did not improve from 0.92857\n","Epoch 241/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.9089\n","\n","Epoch 00241: val_accuracy did not improve from 0.92857\n","Epoch 242/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9113\n","\n","Epoch 00242: val_accuracy did not improve from 0.92857\n","Epoch 243/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.7259 - val_accuracy: 0.8719\n","\n","Epoch 00243: val_accuracy did not improve from 0.92857\n","Epoch 244/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.5183 - val_accuracy: 0.8892\n","\n","Epoch 00244: val_accuracy did not improve from 0.92857\n","Epoch 245/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4835 - val_accuracy: 0.9039\n","\n","Epoch 00245: val_accuracy did not improve from 0.92857\n","Epoch 246/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.4877 - val_accuracy: 0.9064\n","\n","Epoch 00246: val_accuracy did not improve from 0.92857\n","Epoch 247/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.6218 - val_accuracy: 0.8916\n","\n","Epoch 00247: val_accuracy did not improve from 0.92857\n","Epoch 248/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0153 - accuracy: 0.9939 - val_loss: 0.6817 - val_accuracy: 0.8793\n","\n","Epoch 00248: val_accuracy did not improve from 0.92857\n","Epoch 249/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0432 - accuracy: 0.9890 - val_loss: 0.6413 - val_accuracy: 0.8966\n","\n","Epoch 00249: val_accuracy did not improve from 0.92857\n","Epoch 250/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0370 - accuracy: 0.9866 - val_loss: 0.8512 - val_accuracy: 0.8498\n","\n","Epoch 00250: val_accuracy did not improve from 0.92857\n","Epoch 251/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0480 - accuracy: 0.9872 - val_loss: 0.7300 - val_accuracy: 0.8892\n","\n","Epoch 00251: val_accuracy did not improve from 0.92857\n","Epoch 252/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.8698 - val_accuracy: 0.8374\n","\n","Epoch 00252: val_accuracy did not improve from 0.92857\n","Epoch 253/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0264 - accuracy: 0.9903 - val_loss: 1.6664 - val_accuracy: 0.7488\n","\n","Epoch 00253: val_accuracy did not improve from 0.92857\n","Epoch 254/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.4249 - val_accuracy: 0.9187\n","\n","Epoch 00254: val_accuracy did not improve from 0.92857\n","Epoch 255/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5544 - val_accuracy: 0.9064\n","\n","Epoch 00255: val_accuracy did not improve from 0.92857\n","Epoch 256/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.6218 - val_accuracy: 0.8941\n","\n","Epoch 00256: val_accuracy did not improve from 0.92857\n","Epoch 257/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.3337 - val_accuracy: 0.9212\n","\n","Epoch 00257: val_accuracy did not improve from 0.92857\n","Epoch 258/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.5516 - val_accuracy: 0.8966\n","\n","Epoch 00258: val_accuracy did not improve from 0.92857\n","Epoch 259/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.7656 - val_accuracy: 0.8670\n","\n","Epoch 00259: val_accuracy did not improve from 0.92857\n","Epoch 260/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0582 - accuracy: 0.9829 - val_loss: 0.7575 - val_accuracy: 0.8670\n","\n","Epoch 00260: val_accuracy did not improve from 0.92857\n","Epoch 261/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0346 - accuracy: 0.9872 - val_loss: 0.5235 - val_accuracy: 0.8941\n","\n","Epoch 00261: val_accuracy did not improve from 0.92857\n","Epoch 262/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 0.6000 - val_accuracy: 0.8966\n","\n","Epoch 00262: val_accuracy did not improve from 0.92857\n","Epoch 263/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0396 - accuracy: 0.9903 - val_loss: 0.6841 - val_accuracy: 0.8966\n","\n","Epoch 00263: val_accuracy did not improve from 0.92857\n","Epoch 264/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0192 - accuracy: 0.9957 - val_loss: 0.5529 - val_accuracy: 0.9113\n","\n","Epoch 00264: val_accuracy did not improve from 0.92857\n","Epoch 265/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5131 - val_accuracy: 0.9089\n","\n","Epoch 00265: val_accuracy did not improve from 0.92857\n","Epoch 266/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0060 - accuracy: 0.9970 - val_loss: 0.4199 - val_accuracy: 0.9113\n","\n","Epoch 00266: val_accuracy did not improve from 0.92857\n","Epoch 267/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.3623 - val_accuracy: 0.9212\n","\n","Epoch 00267: val_accuracy did not improve from 0.92857\n","Epoch 268/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.5473 - val_accuracy: 0.9089\n","\n","Epoch 00268: val_accuracy did not improve from 0.92857\n","Epoch 269/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0421 - accuracy: 0.9884 - val_loss: 0.6958 - val_accuracy: 0.9089\n","\n","Epoch 00269: val_accuracy did not improve from 0.92857\n","Epoch 270/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0277 - accuracy: 0.9909 - val_loss: 0.6750 - val_accuracy: 0.8744\n","\n","Epoch 00270: val_accuracy did not improve from 0.92857\n","Epoch 271/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.5110 - val_accuracy: 0.9064\n","\n","Epoch 00271: val_accuracy did not improve from 0.92857\n","Epoch 272/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.6313 - val_accuracy: 0.8818\n","\n","Epoch 00272: val_accuracy did not improve from 0.92857\n","Epoch 273/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.5222 - val_accuracy: 0.8966\n","\n","Epoch 00273: val_accuracy did not improve from 0.92857\n","Epoch 274/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.0525 - accuracy: 0.9866 - val_loss: 0.7944 - val_accuracy: 0.8571\n","\n","Epoch 00274: val_accuracy did not improve from 0.92857\n","Epoch 275/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0256 - accuracy: 0.9903 - val_loss: 0.6043 - val_accuracy: 0.8793\n","\n","Epoch 00275: val_accuracy did not improve from 0.92857\n","Epoch 276/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.5797 - val_accuracy: 0.8793\n","\n","Epoch 00276: val_accuracy did not improve from 0.92857\n","Epoch 277/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.3599 - val_accuracy: 0.9039\n","\n","Epoch 00277: val_accuracy did not improve from 0.92857\n","Epoch 278/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.3838 - val_accuracy: 0.9163\n","\n","Epoch 00278: val_accuracy did not improve from 0.92857\n","Epoch 279/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.3700 - val_accuracy: 0.9212\n","\n","Epoch 00279: val_accuracy did not improve from 0.92857\n","Epoch 280/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5864 - val_accuracy: 0.8990\n","\n","Epoch 00280: val_accuracy did not improve from 0.92857\n","Epoch 281/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0617 - accuracy: 0.9848 - val_loss: 0.6496 - val_accuracy: 0.8768\n","\n","Epoch 00281: val_accuracy did not improve from 0.92857\n","Epoch 282/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 0.6454 - val_accuracy: 0.8867\n","\n","Epoch 00282: val_accuracy did not improve from 0.92857\n","Epoch 283/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.4067 - val_accuracy: 0.9187\n","\n","Epoch 00283: val_accuracy did not improve from 0.92857\n","Epoch 284/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.5617 - val_accuracy: 0.8842\n","\n","Epoch 00284: val_accuracy did not improve from 0.92857\n","Epoch 285/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0515 - accuracy: 0.9854 - val_loss: 0.8365 - val_accuracy: 0.8670\n","\n","Epoch 00285: val_accuracy did not improve from 0.92857\n","Epoch 286/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 0.4826 - val_accuracy: 0.8818\n","\n","Epoch 00286: val_accuracy did not improve from 0.92857\n","Epoch 287/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0187 - accuracy: 0.9927 - val_loss: 0.6377 - val_accuracy: 0.8916\n","\n","Epoch 00287: val_accuracy did not improve from 0.92857\n","Epoch 288/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.4556 - val_accuracy: 0.9236\n","\n","Epoch 00288: val_accuracy did not improve from 0.92857\n","Epoch 289/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.5791 - val_accuracy: 0.8916\n","\n","Epoch 00289: val_accuracy did not improve from 0.92857\n","Epoch 290/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.5243 - val_accuracy: 0.8990\n","\n","Epoch 00290: val_accuracy did not improve from 0.92857\n","Epoch 291/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.4791 - val_accuracy: 0.9089\n","\n","Epoch 00291: val_accuracy did not improve from 0.92857\n","Epoch 292/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0105 - accuracy: 0.9988 - val_loss: 0.4604 - val_accuracy: 0.9236\n","\n","Epoch 00292: val_accuracy did not improve from 0.92857\n","Epoch 293/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3885 - val_accuracy: 0.9236\n","\n","Epoch 00293: val_accuracy did not improve from 0.92857\n","Epoch 294/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.4144 - val_accuracy: 0.9163\n","\n","Epoch 00294: val_accuracy did not improve from 0.92857\n","Epoch 295/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4841 - val_accuracy: 0.9089\n","\n","Epoch 00295: val_accuracy did not improve from 0.92857\n","Epoch 296/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.9113\n","\n","Epoch 00296: val_accuracy did not improve from 0.92857\n","Epoch 297/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4371 - val_accuracy: 0.9286\n","\n","Epoch 00297: val_accuracy did not improve from 0.92857\n","Epoch 298/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.5986 - val_accuracy: 0.8867\n","\n","Epoch 00298: val_accuracy did not improve from 0.92857\n","Epoch 299/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0235 - accuracy: 0.9939 - val_loss: 0.6231 - val_accuracy: 0.9089\n","\n","Epoch 00299: val_accuracy did not improve from 0.92857\n","Epoch 300/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.6566 - val_accuracy: 0.8990\n","\n","Epoch 00300: val_accuracy did not improve from 0.92857\n","Epoch 301/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0336 - accuracy: 0.9933 - val_loss: 0.7349 - val_accuracy: 0.8818\n","\n","Epoch 00301: val_accuracy did not improve from 0.92857\n","Epoch 302/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0328 - accuracy: 0.9927 - val_loss: 0.5080 - val_accuracy: 0.9039\n","\n","Epoch 00302: val_accuracy did not improve from 0.92857\n","Epoch 303/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.5957 - val_accuracy: 0.8818\n","\n","Epoch 00303: val_accuracy did not improve from 0.92857\n","Epoch 304/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.5424 - val_accuracy: 0.8892\n","\n","Epoch 00304: val_accuracy did not improve from 0.92857\n","Epoch 305/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.4515 - val_accuracy: 0.8966\n","\n","Epoch 00305: val_accuracy did not improve from 0.92857\n","Epoch 306/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0062 - accuracy: 0.9970 - val_loss: 0.4467 - val_accuracy: 0.9212\n","\n","Epoch 00306: val_accuracy did not improve from 0.92857\n","Epoch 307/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.4512 - val_accuracy: 0.9187\n","\n","Epoch 00307: val_accuracy did not improve from 0.92857\n","Epoch 308/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9261\n","\n","Epoch 00308: val_accuracy did not improve from 0.92857\n","Epoch 309/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0093 - accuracy: 0.9957 - val_loss: 0.4944 - val_accuracy: 0.9064\n","\n","Epoch 00309: val_accuracy did not improve from 0.92857\n","Epoch 310/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5332 - val_accuracy: 0.9015\n","\n","Epoch 00310: val_accuracy did not improve from 0.92857\n","Epoch 311/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.7988 - val_accuracy: 0.8842\n","\n","Epoch 00311: val_accuracy did not improve from 0.92857\n","Epoch 312/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.7587 - val_accuracy: 0.8966\n","\n","Epoch 00312: val_accuracy did not improve from 0.92857\n","Epoch 313/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 0.5874 - val_accuracy: 0.8966\n","\n","Epoch 00313: val_accuracy did not improve from 0.92857\n","Epoch 314/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.4996 - val_accuracy: 0.9089\n","\n","Epoch 00314: val_accuracy did not improve from 0.92857\n","Epoch 315/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.6158 - val_accuracy: 0.9039\n","\n","Epoch 00315: val_accuracy did not improve from 0.92857\n","Epoch 316/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0234 - accuracy: 0.9945 - val_loss: 0.6042 - val_accuracy: 0.9039\n","\n","Epoch 00316: val_accuracy did not improve from 0.92857\n","Epoch 317/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.8215 - val_accuracy: 0.8916\n","\n","Epoch 00317: val_accuracy did not improve from 0.92857\n","Epoch 318/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.5079 - val_accuracy: 0.8966\n","\n","Epoch 00318: val_accuracy did not improve from 0.92857\n","Epoch 319/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0236 - accuracy: 0.9945 - val_loss: 0.5442 - val_accuracy: 0.8990\n","\n","Epoch 00319: val_accuracy did not improve from 0.92857\n","Epoch 320/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.4696 - val_accuracy: 0.8941\n","\n","Epoch 00320: val_accuracy did not improve from 0.92857\n","Epoch 321/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4442 - val_accuracy: 0.9064\n","\n","Epoch 00321: val_accuracy did not improve from 0.92857\n","Epoch 322/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0122 - accuracy: 0.9945 - val_loss: 0.4783 - val_accuracy: 0.9113\n","\n","Epoch 00322: val_accuracy did not improve from 0.92857\n","Epoch 323/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4117 - val_accuracy: 0.9163\n","\n","Epoch 00323: val_accuracy did not improve from 0.92857\n","Epoch 324/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.6671 - val_accuracy: 0.8941\n","\n","Epoch 00324: val_accuracy did not improve from 0.92857\n","Epoch 325/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.6677 - val_accuracy: 0.8695\n","\n","Epoch 00325: val_accuracy did not improve from 0.92857\n","Epoch 326/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.7105 - val_accuracy: 0.8818\n","\n","Epoch 00326: val_accuracy did not improve from 0.92857\n","Epoch 327/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.9125 - val_accuracy: 0.8719\n","\n","Epoch 00327: val_accuracy did not improve from 0.92857\n","Epoch 328/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0262 - accuracy: 0.9927 - val_loss: 0.5496 - val_accuracy: 0.8966\n","\n","Epoch 00328: val_accuracy did not improve from 0.92857\n","Epoch 329/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.9821 - val_accuracy: 0.8842\n","\n","Epoch 00329: val_accuracy did not improve from 0.92857\n","Epoch 330/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.8015 - val_accuracy: 0.8744\n","\n","Epoch 00330: val_accuracy did not improve from 0.92857\n","Epoch 331/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.7666 - val_accuracy: 0.8744\n","\n","Epoch 00331: val_accuracy did not improve from 0.92857\n","Epoch 332/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 0.7451 - val_accuracy: 0.8966\n","\n","Epoch 00332: val_accuracy did not improve from 0.92857\n","Epoch 333/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.4658 - val_accuracy: 0.9212\n","\n","Epoch 00333: val_accuracy did not improve from 0.92857\n","Epoch 334/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0217 - accuracy: 0.9921 - val_loss: 0.4475 - val_accuracy: 0.9138\n","\n","Epoch 00334: val_accuracy did not improve from 0.92857\n","Epoch 335/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.5728 - val_accuracy: 0.8990\n","\n","Epoch 00335: val_accuracy did not improve from 0.92857\n","Epoch 336/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.5586 - val_accuracy: 0.9138\n","\n","Epoch 00336: val_accuracy did not improve from 0.92857\n","Epoch 337/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0114 - accuracy: 0.9945 - val_loss: 0.5614 - val_accuracy: 0.9236\n","\n","Epoch 00337: val_accuracy did not improve from 0.92857\n","Epoch 338/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 0.8118 - val_accuracy: 0.8744\n","\n","Epoch 00338: val_accuracy did not improve from 0.92857\n","Epoch 339/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 0.6659 - val_accuracy: 0.8768\n","\n","Epoch 00339: val_accuracy did not improve from 0.92857\n","Epoch 340/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.5981 - val_accuracy: 0.9039\n","\n","Epoch 00340: val_accuracy did not improve from 0.92857\n","Epoch 341/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.5390 - val_accuracy: 0.9039\n","\n","Epoch 00341: val_accuracy did not improve from 0.92857\n","Epoch 342/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0396 - accuracy: 0.9860 - val_loss: 0.6000 - val_accuracy: 0.8842\n","\n","Epoch 00342: val_accuracy did not improve from 0.92857\n","Epoch 343/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.4814 - val_accuracy: 0.9039\n","\n","Epoch 00343: val_accuracy did not improve from 0.92857\n","Epoch 344/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.5003 - val_accuracy: 0.9064\n","\n","Epoch 00344: val_accuracy did not improve from 0.92857\n","Epoch 345/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.9064\n","\n","Epoch 00345: val_accuracy did not improve from 0.92857\n","Epoch 346/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.9212\n","\n","Epoch 00346: val_accuracy did not improve from 0.92857\n","Epoch 347/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3554 - val_accuracy: 0.9187\n","\n","Epoch 00347: val_accuracy did not improve from 0.92857\n","Epoch 348/500\n","52/52 [==============================] - 9s 169ms/step - loss: 4.2141e-04 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.9360\n","\n","Epoch 00348: val_accuracy improved from 0.92857 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 349/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9187\n","\n","Epoch 00349: val_accuracy did not improve from 0.93596\n","Epoch 350/500\n","52/52 [==============================] - 9s 171ms/step - loss: 2.7289e-04 - accuracy: 1.0000 - val_loss: 0.3846 - val_accuracy: 0.9335\n","\n","Epoch 00350: val_accuracy did not improve from 0.93596\n","Epoch 351/500\n","52/52 [==============================] - 9s 168ms/step - loss: 2.1186e-04 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.9286\n","\n","Epoch 00351: val_accuracy did not improve from 0.93596\n","Epoch 352/500\n","52/52 [==============================] - 9s 168ms/step - loss: 3.0948e-04 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.9433\n","\n","Epoch 00352: val_accuracy improved from 0.93596 to 0.94335, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 353/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4193 - val_accuracy: 0.9286\n","\n","Epoch 00353: val_accuracy did not improve from 0.94335\n","Epoch 354/500\n","52/52 [==============================] - 9s 167ms/step - loss: 3.6019e-04 - accuracy: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.9310\n","\n","Epoch 00354: val_accuracy did not improve from 0.94335\n","Epoch 355/500\n","52/52 [==============================] - 9s 168ms/step - loss: 3.3643e-04 - accuracy: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.9286\n","\n","Epoch 00355: val_accuracy did not improve from 0.94335\n","Epoch 356/500\n","52/52 [==============================] - 9s 168ms/step - loss: 2.0800e-04 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9433\n","\n","Epoch 00356: val_accuracy did not improve from 0.94335\n","Epoch 357/500\n","52/52 [==============================] - 9s 168ms/step - loss: 1.3272e-04 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9236\n","\n","Epoch 00357: val_accuracy did not improve from 0.94335\n","Epoch 358/500\n","52/52 [==============================] - 9s 166ms/step - loss: 3.4750e-04 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9335\n","\n","Epoch 00358: val_accuracy did not improve from 0.94335\n","Epoch 359/500\n","52/52 [==============================] - 9s 169ms/step - loss: 1.5021e-04 - accuracy: 1.0000 - val_loss: 0.3809 - val_accuracy: 0.9286\n","\n","Epoch 00359: val_accuracy did not improve from 0.94335\n","Epoch 360/500\n","52/52 [==============================] - 9s 166ms/step - loss: 1.0962e-04 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9360\n","\n","Epoch 00360: val_accuracy did not improve from 0.94335\n","Epoch 361/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 1.0306 - val_accuracy: 0.8374\n","\n","Epoch 00361: val_accuracy did not improve from 0.94335\n","Epoch 362/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0452 - accuracy: 0.9872 - val_loss: 0.7891 - val_accuracy: 0.8768\n","\n","Epoch 00362: val_accuracy did not improve from 0.94335\n","Epoch 363/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.6453 - val_accuracy: 0.8966\n","\n","Epoch 00363: val_accuracy did not improve from 0.94335\n","Epoch 364/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.0672 - accuracy: 0.9793 - val_loss: 0.8221 - val_accuracy: 0.8818\n","\n","Epoch 00364: val_accuracy did not improve from 0.94335\n","Epoch 365/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0566 - accuracy: 0.9848 - val_loss: 0.5469 - val_accuracy: 0.9163\n","\n","Epoch 00365: val_accuracy did not improve from 0.94335\n","Epoch 366/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0447 - accuracy: 0.9878 - val_loss: 0.7758 - val_accuracy: 0.8793\n","\n","Epoch 00366: val_accuracy did not improve from 0.94335\n","Epoch 367/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.0174 - accuracy: 0.9957 - val_loss: 0.5995 - val_accuracy: 0.9039\n","\n","Epoch 00367: val_accuracy did not improve from 0.94335\n","Epoch 368/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.6324 - val_accuracy: 0.8916\n","\n","Epoch 00368: val_accuracy did not improve from 0.94335\n","Epoch 369/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5656 - val_accuracy: 0.8966\n","\n","Epoch 00369: val_accuracy did not improve from 0.94335\n","Epoch 370/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.4737 - val_accuracy: 0.9187\n","\n","Epoch 00370: val_accuracy did not improve from 0.94335\n","Epoch 371/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5206 - val_accuracy: 0.9261\n","\n","Epoch 00371: val_accuracy did not improve from 0.94335\n","Epoch 372/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.8450 - val_accuracy: 0.8867\n","\n","Epoch 00372: val_accuracy did not improve from 0.94335\n","Epoch 373/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.6151 - val_accuracy: 0.9039\n","\n","Epoch 00373: val_accuracy did not improve from 0.94335\n","Epoch 374/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.7359 - val_accuracy: 0.8916\n","\n","Epoch 00374: val_accuracy did not improve from 0.94335\n","Epoch 375/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.5559 - val_accuracy: 0.9039\n","\n","Epoch 00375: val_accuracy did not improve from 0.94335\n","Epoch 376/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.8303 - val_accuracy: 0.8596\n","\n","Epoch 00376: val_accuracy did not improve from 0.94335\n","Epoch 377/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.4991 - val_accuracy: 0.9064\n","\n","Epoch 00377: val_accuracy did not improve from 0.94335\n","Epoch 378/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.5326 - val_accuracy: 0.9015\n","\n","Epoch 00378: val_accuracy did not improve from 0.94335\n","Epoch 379/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.5647 - val_accuracy: 0.8867\n","\n","Epoch 00379: val_accuracy did not improve from 0.94335\n","Epoch 380/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.5740 - val_accuracy: 0.9039\n","\n","Epoch 00380: val_accuracy did not improve from 0.94335\n","Epoch 381/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5381 - val_accuracy: 0.9015\n","\n","Epoch 00381: val_accuracy did not improve from 0.94335\n","Epoch 382/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5172 - val_accuracy: 0.8966\n","\n","Epoch 00382: val_accuracy did not improve from 0.94335\n","Epoch 383/500\n","52/52 [==============================] - 9s 168ms/step - loss: 9.7255e-04 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.9261\n","\n","Epoch 00383: val_accuracy did not improve from 0.94335\n","Epoch 384/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.6353 - val_accuracy: 0.9113\n","\n","Epoch 00384: val_accuracy did not improve from 0.94335\n","Epoch 385/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0131 - accuracy: 0.9945 - val_loss: 0.5935 - val_accuracy: 0.8892\n","\n","Epoch 00385: val_accuracy did not improve from 0.94335\n","Epoch 386/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.4713 - val_accuracy: 0.8990\n","\n","Epoch 00386: val_accuracy did not improve from 0.94335\n","Epoch 387/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.6214 - val_accuracy: 0.8892\n","\n","Epoch 00387: val_accuracy did not improve from 0.94335\n","Epoch 388/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.8094 - val_accuracy: 0.8793\n","\n","Epoch 00388: val_accuracy did not improve from 0.94335\n","Epoch 389/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.5938 - val_accuracy: 0.8941\n","\n","Epoch 00389: val_accuracy did not improve from 0.94335\n","Epoch 390/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.6320 - val_accuracy: 0.8842\n","\n","Epoch 00390: val_accuracy did not improve from 0.94335\n","Epoch 391/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.5918 - val_accuracy: 0.9064\n","\n","Epoch 00391: val_accuracy did not improve from 0.94335\n","Epoch 392/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.6544 - val_accuracy: 0.9015\n","\n","Epoch 00392: val_accuracy did not improve from 0.94335\n","Epoch 393/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.7455 - val_accuracy: 0.8990\n","\n","Epoch 00393: val_accuracy did not improve from 0.94335\n","Epoch 394/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.7780 - val_accuracy: 0.8793\n","\n","Epoch 00394: val_accuracy did not improve from 0.94335\n","Epoch 395/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.6243 - val_accuracy: 0.8867\n","\n","Epoch 00395: val_accuracy did not improve from 0.94335\n","Epoch 396/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.7323 - val_accuracy: 0.8768\n","\n","Epoch 00396: val_accuracy did not improve from 0.94335\n","Epoch 397/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 0.7614 - val_accuracy: 0.8670\n","\n","Epoch 00397: val_accuracy did not improve from 0.94335\n","Epoch 398/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.6824 - val_accuracy: 0.8768\n","\n","Epoch 00398: val_accuracy did not improve from 0.94335\n","Epoch 399/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.5572 - val_accuracy: 0.9015\n","\n","Epoch 00399: val_accuracy did not improve from 0.94335\n","Epoch 400/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.4775 - val_accuracy: 0.9064\n","\n","Epoch 00400: val_accuracy did not improve from 0.94335\n","Epoch 401/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.4813 - val_accuracy: 0.9163\n","\n","Epoch 00401: val_accuracy did not improve from 0.94335\n","Epoch 402/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.4985 - val_accuracy: 0.9039\n","\n","Epoch 00402: val_accuracy did not improve from 0.94335\n","Epoch 403/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.5851 - val_accuracy: 0.8793\n","\n","Epoch 00403: val_accuracy did not improve from 0.94335\n","Epoch 404/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0143 - accuracy: 0.9933 - val_loss: 0.6153 - val_accuracy: 0.8990\n","\n","Epoch 00404: val_accuracy did not improve from 0.94335\n","Epoch 405/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.0097 - accuracy: 0.9957 - val_loss: 0.4983 - val_accuracy: 0.9089\n","\n","Epoch 00405: val_accuracy did not improve from 0.94335\n","Epoch 406/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0215 - accuracy: 0.9963 - val_loss: 0.5849 - val_accuracy: 0.8990\n","\n","Epoch 00406: val_accuracy did not improve from 0.94335\n","Epoch 407/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0096 - accuracy: 0.9957 - val_loss: 0.5363 - val_accuracy: 0.9113\n","\n","Epoch 00407: val_accuracy did not improve from 0.94335\n","Epoch 408/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.4607 - val_accuracy: 0.9039\n","\n","Epoch 00408: val_accuracy did not improve from 0.94335\n","Epoch 409/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.5368 - val_accuracy: 0.8966\n","\n","Epoch 00409: val_accuracy did not improve from 0.94335\n","Epoch 410/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.6364 - val_accuracy: 0.8990\n","\n","Epoch 00410: val_accuracy did not improve from 0.94335\n","Epoch 411/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.4957 - val_accuracy: 0.9089\n","\n","Epoch 00411: val_accuracy did not improve from 0.94335\n","Epoch 412/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.3472 - val_accuracy: 0.9286\n","\n","Epoch 00412: val_accuracy did not improve from 0.94335\n","Epoch 413/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.4622 - val_accuracy: 0.9236\n","\n","Epoch 00413: val_accuracy did not improve from 0.94335\n","Epoch 414/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.4988 - val_accuracy: 0.9015\n","\n","Epoch 00414: val_accuracy did not improve from 0.94335\n","Epoch 415/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.6374 - val_accuracy: 0.8892\n","\n","Epoch 00415: val_accuracy did not improve from 0.94335\n","Epoch 416/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.4881 - val_accuracy: 0.9212\n","\n","Epoch 00416: val_accuracy did not improve from 0.94335\n","Epoch 417/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.5048 - val_accuracy: 0.8990\n","\n","Epoch 00417: val_accuracy did not improve from 0.94335\n","Epoch 418/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0046 - accuracy: 0.9976 - val_loss: 0.5403 - val_accuracy: 0.8990\n","\n","Epoch 00418: val_accuracy did not improve from 0.94335\n","Epoch 419/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.8990\n","\n","Epoch 00419: val_accuracy did not improve from 0.94335\n","Epoch 420/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.5954 - val_accuracy: 0.9039\n","\n","Epoch 00420: val_accuracy did not improve from 0.94335\n","Epoch 421/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.9064\n","\n","Epoch 00421: val_accuracy did not improve from 0.94335\n","Epoch 422/500\n","52/52 [==============================] - 9s 168ms/step - loss: 4.1301e-04 - accuracy: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.9138\n","\n","Epoch 00422: val_accuracy did not improve from 0.94335\n","Epoch 423/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5497 - val_accuracy: 0.9064\n","\n","Epoch 00423: val_accuracy did not improve from 0.94335\n","Epoch 424/500\n","52/52 [==============================] - 9s 168ms/step - loss: 7.5212e-04 - accuracy: 1.0000 - val_loss: 0.4916 - val_accuracy: 0.9089\n","\n","Epoch 00424: val_accuracy did not improve from 0.94335\n","Epoch 425/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4830 - val_accuracy: 0.9039\n","\n","Epoch 00425: val_accuracy did not improve from 0.94335\n","Epoch 426/500\n","52/52 [==============================] - 9s 166ms/step - loss: 9.9204e-04 - accuracy: 0.9994 - val_loss: 0.4318 - val_accuracy: 0.9261\n","\n","Epoch 00426: val_accuracy did not improve from 0.94335\n","Epoch 427/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.4211 - val_accuracy: 0.9261\n","\n","Epoch 00427: val_accuracy did not improve from 0.94335\n","Epoch 428/500\n","52/52 [==============================] - 9s 166ms/step - loss: 1.9527e-04 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9286\n","\n","Epoch 00428: val_accuracy did not improve from 0.94335\n","Epoch 429/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4813 - val_accuracy: 0.9261\n","\n","Epoch 00429: val_accuracy did not improve from 0.94335\n","Epoch 430/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.6360 - val_accuracy: 0.8966\n","\n","Epoch 00430: val_accuracy did not improve from 0.94335\n","Epoch 431/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9310\n","\n","Epoch 00431: val_accuracy did not improve from 0.94335\n","Epoch 432/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4895 - val_accuracy: 0.9163\n","\n","Epoch 00432: val_accuracy did not improve from 0.94335\n","Epoch 433/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.5193 - val_accuracy: 0.8966\n","\n","Epoch 00433: val_accuracy did not improve from 0.94335\n","Epoch 434/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5868 - val_accuracy: 0.8990\n","\n","Epoch 00434: val_accuracy did not improve from 0.94335\n","Epoch 435/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.9064\n","\n","Epoch 00435: val_accuracy did not improve from 0.94335\n","Epoch 436/500\n","52/52 [==============================] - 9s 167ms/step - loss: 9.0873e-04 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9089\n","\n","Epoch 00436: val_accuracy did not improve from 0.94335\n","Epoch 437/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5010 - val_accuracy: 0.9039\n","\n","Epoch 00437: val_accuracy did not improve from 0.94335\n","Epoch 438/500\n","52/52 [==============================] - 9s 169ms/step - loss: 3.9301e-04 - accuracy: 1.0000 - val_loss: 0.3845 - val_accuracy: 0.9310\n","\n","Epoch 00438: val_accuracy did not improve from 0.94335\n","Epoch 439/500\n","52/52 [==============================] - 9s 169ms/step - loss: 5.1419e-04 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.9187\n","\n","Epoch 00439: val_accuracy did not improve from 0.94335\n","Epoch 440/500\n","52/52 [==============================] - 9s 166ms/step - loss: 2.4552e-04 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.9163\n","\n","Epoch 00440: val_accuracy did not improve from 0.94335\n","Epoch 441/500\n","52/52 [==============================] - 9s 168ms/step - loss: 7.8640e-04 - accuracy: 1.0000 - val_loss: 0.3707 - val_accuracy: 0.9360\n","\n","Epoch 00441: val_accuracy did not improve from 0.94335\n","Epoch 442/500\n","52/52 [==============================] - 9s 166ms/step - loss: 1.6599e-04 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9409\n","\n","Epoch 00442: val_accuracy did not improve from 0.94335\n","Epoch 443/500\n","52/52 [==============================] - 9s 165ms/step - loss: 1.5811e-04 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.9187\n","\n","Epoch 00443: val_accuracy did not improve from 0.94335\n","Epoch 444/500\n","52/52 [==============================] - 9s 166ms/step - loss: 2.6281e-04 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.9409\n","\n","Epoch 00444: val_accuracy did not improve from 0.94335\n","Epoch 445/500\n","52/52 [==============================] - 9s 168ms/step - loss: 3.0595e-04 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.9138\n","\n","Epoch 00445: val_accuracy did not improve from 0.94335\n","Epoch 446/500\n","52/52 [==============================] - 9s 168ms/step - loss: 8.1379e-05 - accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.9163\n","\n","Epoch 00446: val_accuracy did not improve from 0.94335\n","Epoch 447/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.6267 - val_accuracy: 0.9064\n","\n","Epoch 00447: val_accuracy did not improve from 0.94335\n","Epoch 448/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0917 - accuracy: 0.9793 - val_loss: 3.2971 - val_accuracy: 0.7857\n","\n","Epoch 00448: val_accuracy did not improve from 0.94335\n","Epoch 449/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0674 - accuracy: 0.9817 - val_loss: 2.7587 - val_accuracy: 0.6897\n","\n","Epoch 00449: val_accuracy did not improve from 0.94335\n","Epoch 450/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0391 - accuracy: 0.9884 - val_loss: 0.7388 - val_accuracy: 0.8695\n","\n","Epoch 00450: val_accuracy did not improve from 0.94335\n","Epoch 451/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0269 - accuracy: 0.9903 - val_loss: 0.7024 - val_accuracy: 0.8645\n","\n","Epoch 00451: val_accuracy did not improve from 0.94335\n","Epoch 452/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.4754 - val_accuracy: 0.9236\n","\n","Epoch 00452: val_accuracy did not improve from 0.94335\n","Epoch 453/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.0124 - accuracy: 0.9945 - val_loss: 0.4865 - val_accuracy: 0.9064\n","\n","Epoch 00453: val_accuracy did not improve from 0.94335\n","Epoch 454/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 0.5175 - val_accuracy: 0.9163\n","\n","Epoch 00454: val_accuracy did not improve from 0.94335\n","Epoch 455/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.4394 - val_accuracy: 0.9163\n","\n","Epoch 00455: val_accuracy did not improve from 0.94335\n","Epoch 456/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9236\n","\n","Epoch 00456: val_accuracy did not improve from 0.94335\n","Epoch 457/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.9335\n","\n","Epoch 00457: val_accuracy did not improve from 0.94335\n","Epoch 458/500\n","52/52 [==============================] - 9s 169ms/step - loss: 7.9685e-04 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9212\n","\n","Epoch 00458: val_accuracy did not improve from 0.94335\n","Epoch 459/500\n","52/52 [==============================] - 9s 166ms/step - loss: 2.2493e-04 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.9335\n","\n","Epoch 00459: val_accuracy did not improve from 0.94335\n","Epoch 460/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0036 - accuracy: 0.9976 - val_loss: 0.4285 - val_accuracy: 0.9261\n","\n","Epoch 00460: val_accuracy did not improve from 0.94335\n","Epoch 461/500\n","52/52 [==============================] - 9s 165ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3805 - val_accuracy: 0.9261\n","\n","Epoch 00461: val_accuracy did not improve from 0.94335\n","Epoch 462/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.9261\n","\n","Epoch 00462: val_accuracy did not improve from 0.94335\n","Epoch 463/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.6511 - val_accuracy: 0.8966\n","\n","Epoch 00463: val_accuracy did not improve from 0.94335\n","Epoch 464/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0415 - accuracy: 0.9884 - val_loss: 0.8796 - val_accuracy: 0.8695\n","\n","Epoch 00464: val_accuracy did not improve from 0.94335\n","Epoch 465/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.5991 - val_accuracy: 0.9212\n","\n","Epoch 00465: val_accuracy did not improve from 0.94335\n","Epoch 466/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0238 - accuracy: 0.9939 - val_loss: 0.5666 - val_accuracy: 0.9138\n","\n","Epoch 00466: val_accuracy did not improve from 0.94335\n","Epoch 467/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5107 - val_accuracy: 0.9187\n","\n","Epoch 00467: val_accuracy did not improve from 0.94335\n","Epoch 468/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.5293 - val_accuracy: 0.9113\n","\n","Epoch 00468: val_accuracy did not improve from 0.94335\n","Epoch 469/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.5222 - val_accuracy: 0.9187\n","\n","Epoch 00469: val_accuracy did not improve from 0.94335\n","Epoch 470/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.4885 - val_accuracy: 0.9212\n","\n","Epoch 00470: val_accuracy did not improve from 0.94335\n","Epoch 471/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 0.4426 - val_accuracy: 0.9064\n","\n","Epoch 00471: val_accuracy did not improve from 0.94335\n","Epoch 472/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.4647 - val_accuracy: 0.9138\n","\n","Epoch 00472: val_accuracy did not improve from 0.94335\n","Epoch 473/500\n","52/52 [==============================] - 9s 170ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.9138\n","\n","Epoch 00473: val_accuracy did not improve from 0.94335\n","Epoch 474/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.5180 - val_accuracy: 0.9039\n","\n","Epoch 00474: val_accuracy did not improve from 0.94335\n","Epoch 475/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.5353 - val_accuracy: 0.9039\n","\n","Epoch 00475: val_accuracy did not improve from 0.94335\n","Epoch 476/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0040 - accuracy: 0.9976 - val_loss: 0.4358 - val_accuracy: 0.9236\n","\n","Epoch 00476: val_accuracy did not improve from 0.94335\n","Epoch 477/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5656 - val_accuracy: 0.9187\n","\n","Epoch 00477: val_accuracy did not improve from 0.94335\n","Epoch 478/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4082 - val_accuracy: 0.9286\n","\n","Epoch 00478: val_accuracy did not improve from 0.94335\n","Epoch 479/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4949 - val_accuracy: 0.9261\n","\n","Epoch 00479: val_accuracy did not improve from 0.94335\n","Epoch 480/500\n","52/52 [==============================] - 9s 169ms/step - loss: 3.3062e-04 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9163\n","\n","Epoch 00480: val_accuracy did not improve from 0.94335\n","Epoch 481/500\n","52/52 [==============================] - 9s 168ms/step - loss: 5.1684e-04 - accuracy: 1.0000 - val_loss: 0.3846 - val_accuracy: 0.9212\n","\n","Epoch 00481: val_accuracy did not improve from 0.94335\n","Epoch 482/500\n","52/52 [==============================] - 9s 166ms/step - loss: 9.6341e-04 - accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.9286\n","\n","Epoch 00482: val_accuracy did not improve from 0.94335\n","Epoch 483/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4793 - val_accuracy: 0.9163\n","\n","Epoch 00483: val_accuracy did not improve from 0.94335\n","Epoch 484/500\n","52/52 [==============================] - 9s 166ms/step - loss: 7.4457e-04 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.9212\n","\n","Epoch 00484: val_accuracy did not improve from 0.94335\n","Epoch 485/500\n","52/52 [==============================] - 9s 165ms/step - loss: 5.4397e-04 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9236\n","\n","Epoch 00485: val_accuracy did not improve from 0.94335\n","Epoch 486/500\n","52/52 [==============================] - 9s 168ms/step - loss: 3.7712e-04 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.9310\n","\n","Epoch 00486: val_accuracy did not improve from 0.94335\n","Epoch 487/500\n","52/52 [==============================] - 9s 168ms/step - loss: 1.1324e-04 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.9236\n","\n","Epoch 00487: val_accuracy did not improve from 0.94335\n","Epoch 488/500\n","52/52 [==============================] - 9s 169ms/step - loss: 4.3583e-04 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.9458\n","\n","Epoch 00488: val_accuracy improved from 0.94335 to 0.94581, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5\n","Epoch 489/500\n","52/52 [==============================] - 9s 171ms/step - loss: 9.6843e-04 - accuracy: 0.9994 - val_loss: 0.5021 - val_accuracy: 0.9261\n","\n","Epoch 00489: val_accuracy did not improve from 0.94581\n","Epoch 490/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0078 - accuracy: 0.9994 - val_loss: 0.5185 - val_accuracy: 0.9310\n","\n","Epoch 00490: val_accuracy did not improve from 0.94581\n","Epoch 491/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.9065 - val_accuracy: 0.8670\n","\n","Epoch 00491: val_accuracy did not improve from 0.94581\n","Epoch 492/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0821 - accuracy: 0.9781 - val_loss: 1.4716 - val_accuracy: 0.8350\n","\n","Epoch 00492: val_accuracy did not improve from 0.94581\n","Epoch 493/500\n","52/52 [==============================] - 9s 169ms/step - loss: 0.0620 - accuracy: 0.9866 - val_loss: 0.9209 - val_accuracy: 0.8793\n","\n","Epoch 00493: val_accuracy did not improve from 0.94581\n","Epoch 494/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.7061 - val_accuracy: 0.8916\n","\n","Epoch 00494: val_accuracy did not improve from 0.94581\n","Epoch 495/500\n","52/52 [==============================] - 9s 166ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.4030 - val_accuracy: 0.9113\n","\n","Epoch 00495: val_accuracy did not improve from 0.94581\n","Epoch 496/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.4897 - val_accuracy: 0.9163\n","\n","Epoch 00496: val_accuracy did not improve from 0.94581\n","Epoch 497/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.3821 - val_accuracy: 0.9113\n","\n","Epoch 00497: val_accuracy did not improve from 0.94581\n","Epoch 498/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9261\n","\n","Epoch 00498: val_accuracy did not improve from 0.94581\n","Epoch 499/500\n","52/52 [==============================] - 9s 168ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9212\n","\n","Epoch 00499: val_accuracy did not improve from 0.94581\n","Epoch 500/500\n","52/52 [==============================] - 9s 167ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4106 - val_accuracy: 0.9212\n","\n","Epoch 00500: val_accuracy did not improve from 0.94581\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff5510fcad0>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"b6o5FeM3DRNl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628170006083,"user_tz":-540,"elapsed":9273774,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"eec521ae-d251-4f39-acb3-2ce0d4c4c1f1"},"source":["InceptionResNetV2_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[InceptionResNetV2_checkpoint])\n","# files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["52/52 [==============================] - 37s 422ms/step - loss: 2.1317 - accuracy: 0.2753 - val_loss: 3.1749 - val_accuracy: 0.0985\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 2/500\n","52/52 [==============================] - 18s 350ms/step - loss: 1.2407 - accuracy: 0.5639 - val_loss: 4.2747 - val_accuracy: 0.1010\n","\n","Epoch 00002: val_accuracy improved from 0.09852 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 3/500\n","52/52 [==============================] - 18s 346ms/step - loss: 0.9498 - accuracy: 0.6790 - val_loss: 3.4941 - val_accuracy: 0.0961\n","\n","Epoch 00003: val_accuracy did not improve from 0.10099\n","Epoch 4/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.8133 - accuracy: 0.7272 - val_loss: 3.4950 - val_accuracy: 0.0985\n","\n","Epoch 00004: val_accuracy did not improve from 0.10099\n","Epoch 5/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.7014 - accuracy: 0.7667 - val_loss: 2.8845 - val_accuracy: 0.0837\n","\n","Epoch 00005: val_accuracy did not improve from 0.10099\n","Epoch 6/500\n","52/52 [==============================] - 18s 346ms/step - loss: 0.6128 - accuracy: 0.7862 - val_loss: 4.9559 - val_accuracy: 0.0985\n","\n","Epoch 00006: val_accuracy did not improve from 0.10099\n","Epoch 7/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.5550 - accuracy: 0.8039 - val_loss: 5.6352 - val_accuracy: 0.0985\n","\n","Epoch 00007: val_accuracy did not improve from 0.10099\n","Epoch 8/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.4571 - accuracy: 0.8441 - val_loss: 3.2021 - val_accuracy: 0.3153\n","\n","Epoch 00008: val_accuracy improved from 0.10099 to 0.31527, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 9/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.4325 - accuracy: 0.8526 - val_loss: 3.7263 - val_accuracy: 0.3005\n","\n","Epoch 00009: val_accuracy did not improve from 0.31527\n","Epoch 10/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.4028 - accuracy: 0.8630 - val_loss: 5.6936 - val_accuracy: 0.1059\n","\n","Epoch 00010: val_accuracy did not improve from 0.31527\n","Epoch 11/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.3539 - accuracy: 0.8752 - val_loss: 3.5349 - val_accuracy: 0.3128\n","\n","Epoch 00011: val_accuracy did not improve from 0.31527\n","Epoch 12/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.3383 - accuracy: 0.8861 - val_loss: 6.2494 - val_accuracy: 0.2660\n","\n","Epoch 00012: val_accuracy did not improve from 0.31527\n","Epoch 13/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.3552 - accuracy: 0.8861 - val_loss: 1.5053 - val_accuracy: 0.6601\n","\n","Epoch 00013: val_accuracy improved from 0.31527 to 0.66010, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 14/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.2647 - accuracy: 0.9172 - val_loss: 0.4814 - val_accuracy: 0.8448\n","\n","Epoch 00014: val_accuracy improved from 0.66010 to 0.84483, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 15/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.2597 - accuracy: 0.9233 - val_loss: 1.0133 - val_accuracy: 0.7488\n","\n","Epoch 00015: val_accuracy did not improve from 0.84483\n","Epoch 16/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.2362 - accuracy: 0.9184 - val_loss: 0.7100 - val_accuracy: 0.7882\n","\n","Epoch 00016: val_accuracy did not improve from 0.84483\n","Epoch 17/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.2409 - accuracy: 0.9190 - val_loss: 1.3327 - val_accuracy: 0.6798\n","\n","Epoch 00017: val_accuracy did not improve from 0.84483\n","Epoch 18/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.2526 - accuracy: 0.9129 - val_loss: 2.8144 - val_accuracy: 0.5000\n","\n","Epoch 00018: val_accuracy did not improve from 0.84483\n","Epoch 19/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.2085 - accuracy: 0.9294 - val_loss: 1.3013 - val_accuracy: 0.6946\n","\n","Epoch 00019: val_accuracy did not improve from 0.84483\n","Epoch 20/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.2587 - accuracy: 0.9208 - val_loss: 1.1126 - val_accuracy: 0.7488\n","\n","Epoch 00020: val_accuracy did not improve from 0.84483\n","Epoch 21/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.1734 - accuracy: 0.9446 - val_loss: 0.8290 - val_accuracy: 0.8079\n","\n","Epoch 00021: val_accuracy did not improve from 0.84483\n","Epoch 22/500\n","52/52 [==============================] - 18s 344ms/step - loss: 0.1612 - accuracy: 0.9470 - val_loss: 1.0321 - val_accuracy: 0.7783\n","\n","Epoch 00022: val_accuracy did not improve from 0.84483\n","Epoch 23/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.1993 - accuracy: 0.9281 - val_loss: 0.9066 - val_accuracy: 0.7956\n","\n","Epoch 00023: val_accuracy did not improve from 0.84483\n","Epoch 24/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.1944 - accuracy: 0.9330 - val_loss: 0.7792 - val_accuracy: 0.8128\n","\n","Epoch 00024: val_accuracy did not improve from 0.84483\n","Epoch 25/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.1534 - accuracy: 0.9482 - val_loss: 0.7764 - val_accuracy: 0.7931\n","\n","Epoch 00025: val_accuracy did not improve from 0.84483\n","Epoch 26/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.1547 - accuracy: 0.9440 - val_loss: 0.5299 - val_accuracy: 0.8695\n","\n","Epoch 00026: val_accuracy improved from 0.84483 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 27/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.1741 - accuracy: 0.9409 - val_loss: 0.7878 - val_accuracy: 0.8276\n","\n","Epoch 00027: val_accuracy did not improve from 0.86946\n","Epoch 28/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.1386 - accuracy: 0.9464 - val_loss: 1.0623 - val_accuracy: 0.7635\n","\n","Epoch 00028: val_accuracy did not improve from 0.86946\n","Epoch 29/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.1459 - accuracy: 0.9488 - val_loss: 0.9376 - val_accuracy: 0.7660\n","\n","Epoch 00029: val_accuracy did not improve from 0.86946\n","Epoch 30/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.1026 - accuracy: 0.9635 - val_loss: 2.7782 - val_accuracy: 0.3251\n","\n","Epoch 00030: val_accuracy did not improve from 0.86946\n","Epoch 31/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.1380 - accuracy: 0.9519 - val_loss: 2.9272 - val_accuracy: 0.5862\n","\n","Epoch 00031: val_accuracy did not improve from 0.86946\n","Epoch 32/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.1463 - accuracy: 0.9531 - val_loss: 1.4901 - val_accuracy: 0.7463\n","\n","Epoch 00032: val_accuracy did not improve from 0.86946\n","Epoch 33/500\n","52/52 [==============================] - 18s 345ms/step - loss: 0.1706 - accuracy: 0.9452 - val_loss: 0.6631 - val_accuracy: 0.8596\n","\n","Epoch 00033: val_accuracy did not improve from 0.86946\n","Epoch 34/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.1199 - accuracy: 0.9592 - val_loss: 0.6640 - val_accuracy: 0.8498\n","\n","Epoch 00034: val_accuracy did not improve from 0.86946\n","Epoch 35/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.1200 - accuracy: 0.9616 - val_loss: 0.5718 - val_accuracy: 0.8547\n","\n","Epoch 00035: val_accuracy did not improve from 0.86946\n","Epoch 36/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.1434 - accuracy: 0.9549 - val_loss: 1.2686 - val_accuracy: 0.7340\n","\n","Epoch 00036: val_accuracy did not improve from 0.86946\n","Epoch 37/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0706 - accuracy: 0.9799 - val_loss: 2.1704 - val_accuracy: 0.6207\n","\n","Epoch 00037: val_accuracy did not improve from 0.86946\n","Epoch 38/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0897 - accuracy: 0.9720 - val_loss: 0.5034 - val_accuracy: 0.8719\n","\n","Epoch 00038: val_accuracy improved from 0.86946 to 0.87192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 39/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0921 - accuracy: 0.9689 - val_loss: 0.5941 - val_accuracy: 0.8670\n","\n","Epoch 00039: val_accuracy did not improve from 0.87192\n","Epoch 40/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0862 - accuracy: 0.9726 - val_loss: 0.5697 - val_accuracy: 0.8670\n","\n","Epoch 00040: val_accuracy did not improve from 0.87192\n","Epoch 41/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0595 - accuracy: 0.9817 - val_loss: 0.5521 - val_accuracy: 0.8793\n","\n","Epoch 00041: val_accuracy improved from 0.87192 to 0.87931, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 42/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0556 - accuracy: 0.9842 - val_loss: 0.5915 - val_accuracy: 0.8645\n","\n","Epoch 00042: val_accuracy did not improve from 0.87931\n","Epoch 43/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0640 - accuracy: 0.9799 - val_loss: 0.9476 - val_accuracy: 0.8103\n","\n","Epoch 00043: val_accuracy did not improve from 0.87931\n","Epoch 44/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.1537 - accuracy: 0.9562 - val_loss: 4.0420 - val_accuracy: 0.5172\n","\n","Epoch 00044: val_accuracy did not improve from 0.87931\n","Epoch 45/500\n","52/52 [==============================] - 18s 353ms/step - loss: 0.1547 - accuracy: 0.9434 - val_loss: 1.6751 - val_accuracy: 0.6601\n","\n","Epoch 00045: val_accuracy did not improve from 0.87931\n","Epoch 46/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0668 - accuracy: 0.9775 - val_loss: 0.5121 - val_accuracy: 0.8719\n","\n","Epoch 00046: val_accuracy did not improve from 0.87931\n","Epoch 47/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0809 - accuracy: 0.9689 - val_loss: 1.0367 - val_accuracy: 0.8399\n","\n","Epoch 00047: val_accuracy did not improve from 0.87931\n","Epoch 48/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.1101 - accuracy: 0.9665 - val_loss: 1.4488 - val_accuracy: 0.7783\n","\n","Epoch 00048: val_accuracy did not improve from 0.87931\n","Epoch 49/500\n","52/52 [==============================] - 18s 346ms/step - loss: 0.1951 - accuracy: 0.9434 - val_loss: 2.1910 - val_accuracy: 0.6798\n","\n","Epoch 00049: val_accuracy did not improve from 0.87931\n","Epoch 50/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0885 - accuracy: 0.9641 - val_loss: 1.1517 - val_accuracy: 0.7882\n","\n","Epoch 00050: val_accuracy did not improve from 0.87931\n","Epoch 51/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0643 - accuracy: 0.9811 - val_loss: 0.6242 - val_accuracy: 0.8719\n","\n","Epoch 00051: val_accuracy did not improve from 0.87931\n","Epoch 52/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0718 - accuracy: 0.9769 - val_loss: 0.8931 - val_accuracy: 0.8153\n","\n","Epoch 00052: val_accuracy did not improve from 0.87931\n","Epoch 53/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0593 - accuracy: 0.9823 - val_loss: 0.8016 - val_accuracy: 0.8424\n","\n","Epoch 00053: val_accuracy did not improve from 0.87931\n","Epoch 54/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0405 - accuracy: 0.9848 - val_loss: 0.6088 - val_accuracy: 0.8596\n","\n","Epoch 00054: val_accuracy did not improve from 0.87931\n","Epoch 55/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0546 - accuracy: 0.9829 - val_loss: 0.5737 - val_accuracy: 0.8645\n","\n","Epoch 00055: val_accuracy did not improve from 0.87931\n","Epoch 56/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 0.6120 - val_accuracy: 0.8719\n","\n","Epoch 00056: val_accuracy did not improve from 0.87931\n","Epoch 57/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0393 - accuracy: 0.9860 - val_loss: 0.7385 - val_accuracy: 0.8547\n","\n","Epoch 00057: val_accuracy did not improve from 0.87931\n","Epoch 58/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0754 - accuracy: 0.9744 - val_loss: 1.2047 - val_accuracy: 0.8251\n","\n","Epoch 00058: val_accuracy did not improve from 0.87931\n","Epoch 59/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0627 - accuracy: 0.9805 - val_loss: 0.5065 - val_accuracy: 0.8892\n","\n","Epoch 00059: val_accuracy improved from 0.87931 to 0.88916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 60/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0506 - accuracy: 0.9823 - val_loss: 0.4701 - val_accuracy: 0.8867\n","\n","Epoch 00060: val_accuracy did not improve from 0.88916\n","Epoch 61/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0345 - accuracy: 0.9878 - val_loss: 0.5401 - val_accuracy: 0.8892\n","\n","Epoch 00061: val_accuracy did not improve from 0.88916\n","Epoch 62/500\n","52/52 [==============================] - 18s 346ms/step - loss: 0.0515 - accuracy: 0.9848 - val_loss: 1.1395 - val_accuracy: 0.7906\n","\n","Epoch 00062: val_accuracy did not improve from 0.88916\n","Epoch 63/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0746 - accuracy: 0.9787 - val_loss: 1.9791 - val_accuracy: 0.7167\n","\n","Epoch 00063: val_accuracy did not improve from 0.88916\n","Epoch 64/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0398 - accuracy: 0.9860 - val_loss: 0.6850 - val_accuracy: 0.8596\n","\n","Epoch 00064: val_accuracy did not improve from 0.88916\n","Epoch 65/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0532 - accuracy: 0.9842 - val_loss: 0.6271 - val_accuracy: 0.8547\n","\n","Epoch 00065: val_accuracy did not improve from 0.88916\n","Epoch 66/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0422 - accuracy: 0.9829 - val_loss: 0.6153 - val_accuracy: 0.8818\n","\n","Epoch 00066: val_accuracy did not improve from 0.88916\n","Epoch 67/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.6534 - val_accuracy: 0.8744\n","\n","Epoch 00067: val_accuracy did not improve from 0.88916\n","Epoch 68/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0958 - accuracy: 0.9641 - val_loss: 1.3111 - val_accuracy: 0.7808\n","\n","Epoch 00068: val_accuracy did not improve from 0.88916\n","Epoch 69/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.1466 - accuracy: 0.9574 - val_loss: 0.8869 - val_accuracy: 0.8448\n","\n","Epoch 00069: val_accuracy did not improve from 0.88916\n","Epoch 70/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0913 - accuracy: 0.9726 - val_loss: 0.5637 - val_accuracy: 0.8719\n","\n","Epoch 00070: val_accuracy did not improve from 0.88916\n","Epoch 71/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0406 - accuracy: 0.9866 - val_loss: 0.5667 - val_accuracy: 0.8818\n","\n","Epoch 00071: val_accuracy did not improve from 0.88916\n","Epoch 72/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0503 - accuracy: 0.9866 - val_loss: 0.7208 - val_accuracy: 0.8325\n","\n","Epoch 00072: val_accuracy did not improve from 0.88916\n","Epoch 73/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0383 - accuracy: 0.9896 - val_loss: 0.5445 - val_accuracy: 0.8867\n","\n","Epoch 00073: val_accuracy did not improve from 0.88916\n","Epoch 74/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.8224 - val_accuracy: 0.8325\n","\n","Epoch 00074: val_accuracy did not improve from 0.88916\n","Epoch 75/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0704 - accuracy: 0.9781 - val_loss: 0.7837 - val_accuracy: 0.8547\n","\n","Epoch 00075: val_accuracy did not improve from 0.88916\n","Epoch 76/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0703 - accuracy: 0.9750 - val_loss: 0.9553 - val_accuracy: 0.8202\n","\n","Epoch 00076: val_accuracy did not improve from 0.88916\n","Epoch 77/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0675 - accuracy: 0.9775 - val_loss: 1.2195 - val_accuracy: 0.8054\n","\n","Epoch 00077: val_accuracy did not improve from 0.88916\n","Epoch 78/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0724 - accuracy: 0.9762 - val_loss: 1.0841 - val_accuracy: 0.7882\n","\n","Epoch 00078: val_accuracy did not improve from 0.88916\n","Epoch 79/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0613 - accuracy: 0.9793 - val_loss: 0.8679 - val_accuracy: 0.8473\n","\n","Epoch 00079: val_accuracy did not improve from 0.88916\n","Epoch 80/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 0.5190 - val_accuracy: 0.8990\n","\n","Epoch 00080: val_accuracy improved from 0.88916 to 0.89901, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 81/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0398 - accuracy: 0.9866 - val_loss: 0.9036 - val_accuracy: 0.8350\n","\n","Epoch 00081: val_accuracy did not improve from 0.89901\n","Epoch 82/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0289 - accuracy: 0.9866 - val_loss: 0.6384 - val_accuracy: 0.8768\n","\n","Epoch 00082: val_accuracy did not improve from 0.89901\n","Epoch 83/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0689 - accuracy: 0.9823 - val_loss: 0.9962 - val_accuracy: 0.8227\n","\n","Epoch 00083: val_accuracy did not improve from 0.89901\n","Epoch 84/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.1060 - accuracy: 0.9695 - val_loss: 1.0659 - val_accuracy: 0.8103\n","\n","Epoch 00084: val_accuracy did not improve from 0.89901\n","Epoch 85/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.1094 - accuracy: 0.9695 - val_loss: 1.2792 - val_accuracy: 0.7833\n","\n","Epoch 00085: val_accuracy did not improve from 0.89901\n","Epoch 86/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0912 - accuracy: 0.9744 - val_loss: 0.8889 - val_accuracy: 0.8424\n","\n","Epoch 00086: val_accuracy did not improve from 0.89901\n","Epoch 87/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0744 - accuracy: 0.9708 - val_loss: 0.8743 - val_accuracy: 0.8374\n","\n","Epoch 00087: val_accuracy did not improve from 0.89901\n","Epoch 88/500\n","52/52 [==============================] - 18s 345ms/step - loss: 0.0497 - accuracy: 0.9829 - val_loss: 0.8942 - val_accuracy: 0.8645\n","\n","Epoch 00088: val_accuracy did not improve from 0.89901\n","Epoch 89/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0518 - accuracy: 0.9848 - val_loss: 0.7587 - val_accuracy: 0.8547\n","\n","Epoch 00089: val_accuracy did not improve from 0.89901\n","Epoch 90/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 0.5281 - val_accuracy: 0.8842\n","\n","Epoch 00090: val_accuracy did not improve from 0.89901\n","Epoch 91/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.6050 - val_accuracy: 0.8768\n","\n","Epoch 00091: val_accuracy did not improve from 0.89901\n","Epoch 92/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0081 - accuracy: 0.9988 - val_loss: 0.4771 - val_accuracy: 0.9064\n","\n","Epoch 00092: val_accuracy improved from 0.89901 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 93/500\n","52/52 [==============================] - 18s 353ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.5756 - val_accuracy: 0.8990\n","\n","Epoch 00093: val_accuracy did not improve from 0.90640\n","Epoch 94/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.5611 - val_accuracy: 0.9113\n","\n","Epoch 00094: val_accuracy improved from 0.90640 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 95/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.7137 - val_accuracy: 0.8793\n","\n","Epoch 00095: val_accuracy did not improve from 0.91133\n","Epoch 96/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0361 - accuracy: 0.9896 - val_loss: 0.6461 - val_accuracy: 0.8966\n","\n","Epoch 00096: val_accuracy did not improve from 0.91133\n","Epoch 97/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0406 - accuracy: 0.9878 - val_loss: 1.1592 - val_accuracy: 0.8177\n","\n","Epoch 00097: val_accuracy did not improve from 0.91133\n","Epoch 98/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0520 - accuracy: 0.9805 - val_loss: 1.4475 - val_accuracy: 0.7734\n","\n","Epoch 00098: val_accuracy did not improve from 0.91133\n","Epoch 99/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.1386 - accuracy: 0.9659 - val_loss: 1.1064 - val_accuracy: 0.8350\n","\n","Epoch 00099: val_accuracy did not improve from 0.91133\n","Epoch 100/500\n","52/52 [==============================] - 18s 346ms/step - loss: 0.1136 - accuracy: 0.9702 - val_loss: 7.9548 - val_accuracy: 0.3030\n","\n","Epoch 00100: val_accuracy did not improve from 0.91133\n","Epoch 101/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.1131 - accuracy: 0.9653 - val_loss: 1.0591 - val_accuracy: 0.8374\n","\n","Epoch 00101: val_accuracy did not improve from 0.91133\n","Epoch 102/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0432 - accuracy: 0.9842 - val_loss: 0.5839 - val_accuracy: 0.8744\n","\n","Epoch 00102: val_accuracy did not improve from 0.91133\n","Epoch 103/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0565 - accuracy: 0.9817 - val_loss: 0.9711 - val_accuracy: 0.8719\n","\n","Epoch 00103: val_accuracy did not improve from 0.91133\n","Epoch 104/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0247 - accuracy: 0.9903 - val_loss: 0.5301 - val_accuracy: 0.8966\n","\n","Epoch 00104: val_accuracy did not improve from 0.91133\n","Epoch 105/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0969 - accuracy: 0.9714 - val_loss: 1.7113 - val_accuracy: 0.7414\n","\n","Epoch 00105: val_accuracy did not improve from 0.91133\n","Epoch 106/500\n","52/52 [==============================] - 18s 345ms/step - loss: 0.0756 - accuracy: 0.9756 - val_loss: 0.9617 - val_accuracy: 0.8498\n","\n","Epoch 00106: val_accuracy did not improve from 0.91133\n","Epoch 107/500\n","52/52 [==============================] - 18s 345ms/step - loss: 0.0227 - accuracy: 0.9921 - val_loss: 0.7838 - val_accuracy: 0.8793\n","\n","Epoch 00107: val_accuracy did not improve from 0.91133\n","Epoch 108/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.5845 - val_accuracy: 0.8966\n","\n","Epoch 00108: val_accuracy did not improve from 0.91133\n","Epoch 109/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.7562 - val_accuracy: 0.8842\n","\n","Epoch 00109: val_accuracy did not improve from 0.91133\n","Epoch 110/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.6402 - val_accuracy: 0.8941\n","\n","Epoch 00110: val_accuracy did not improve from 0.91133\n","Epoch 111/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.5540 - val_accuracy: 0.9039\n","\n","Epoch 00111: val_accuracy did not improve from 0.91133\n","Epoch 112/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0581 - accuracy: 0.9842 - val_loss: 0.6430 - val_accuracy: 0.8941\n","\n","Epoch 00112: val_accuracy did not improve from 0.91133\n","Epoch 113/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0873 - accuracy: 0.9714 - val_loss: 3.8856 - val_accuracy: 0.5394\n","\n","Epoch 00113: val_accuracy did not improve from 0.91133\n","Epoch 114/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.1032 - accuracy: 0.9659 - val_loss: 1.6903 - val_accuracy: 0.7660\n","\n","Epoch 00114: val_accuracy did not improve from 0.91133\n","Epoch 115/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0633 - accuracy: 0.9817 - val_loss: 0.8175 - val_accuracy: 0.8473\n","\n","Epoch 00115: val_accuracy did not improve from 0.91133\n","Epoch 116/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0396 - accuracy: 0.9860 - val_loss: 0.7471 - val_accuracy: 0.8571\n","\n","Epoch 00116: val_accuracy did not improve from 0.91133\n","Epoch 117/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.7061 - val_accuracy: 0.8571\n","\n","Epoch 00117: val_accuracy did not improve from 0.91133\n","Epoch 118/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0152 - accuracy: 0.9939 - val_loss: 0.9899 - val_accuracy: 0.8473\n","\n","Epoch 00118: val_accuracy did not improve from 0.91133\n","Epoch 119/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0273 - accuracy: 0.9909 - val_loss: 0.5557 - val_accuracy: 0.9064\n","\n","Epoch 00119: val_accuracy did not improve from 0.91133\n","Epoch 120/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0424 - accuracy: 0.9909 - val_loss: 0.5190 - val_accuracy: 0.8892\n","\n","Epoch 00120: val_accuracy did not improve from 0.91133\n","Epoch 121/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0251 - accuracy: 0.9903 - val_loss: 0.8065 - val_accuracy: 0.8645\n","\n","Epoch 00121: val_accuracy did not improve from 0.91133\n","Epoch 122/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.5926 - val_accuracy: 0.8966\n","\n","Epoch 00122: val_accuracy did not improve from 0.91133\n","Epoch 123/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.4599 - val_accuracy: 0.9163\n","\n","Epoch 00123: val_accuracy improved from 0.91133 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 124/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.5129 - val_accuracy: 0.9261\n","\n","Epoch 00124: val_accuracy improved from 0.91626 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 125/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.7125 - val_accuracy: 0.8621\n","\n","Epoch 00125: val_accuracy did not improve from 0.92611\n","Epoch 126/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0397 - accuracy: 0.9878 - val_loss: 0.6819 - val_accuracy: 0.8842\n","\n","Epoch 00126: val_accuracy did not improve from 0.92611\n","Epoch 127/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0568 - accuracy: 0.9817 - val_loss: 0.8230 - val_accuracy: 0.8768\n","\n","Epoch 00127: val_accuracy did not improve from 0.92611\n","Epoch 128/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0697 - accuracy: 0.9799 - val_loss: 0.6895 - val_accuracy: 0.8719\n","\n","Epoch 00128: val_accuracy did not improve from 0.92611\n","Epoch 129/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0628 - accuracy: 0.9817 - val_loss: 0.6605 - val_accuracy: 0.8867\n","\n","Epoch 00129: val_accuracy did not improve from 0.92611\n","Epoch 130/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0541 - accuracy: 0.9829 - val_loss: 4.8258 - val_accuracy: 0.5246\n","\n","Epoch 00130: val_accuracy did not improve from 0.92611\n","Epoch 131/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0459 - accuracy: 0.9836 - val_loss: 0.9425 - val_accuracy: 0.8719\n","\n","Epoch 00131: val_accuracy did not improve from 0.92611\n","Epoch 132/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0896 - accuracy: 0.9732 - val_loss: 0.7965 - val_accuracy: 0.8621\n","\n","Epoch 00132: val_accuracy did not improve from 0.92611\n","Epoch 133/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0611 - accuracy: 0.9829 - val_loss: 1.2077 - val_accuracy: 0.8300\n","\n","Epoch 00133: val_accuracy did not improve from 0.92611\n","Epoch 134/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0615 - accuracy: 0.9787 - val_loss: 0.6528 - val_accuracy: 0.8744\n","\n","Epoch 00134: val_accuracy did not improve from 0.92611\n","Epoch 135/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.6506 - val_accuracy: 0.8867\n","\n","Epoch 00135: val_accuracy did not improve from 0.92611\n","Epoch 136/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.5610 - val_accuracy: 0.8867\n","\n","Epoch 00136: val_accuracy did not improve from 0.92611\n","Epoch 137/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.5215 - val_accuracy: 0.9113\n","\n","Epoch 00137: val_accuracy did not improve from 0.92611\n","Epoch 138/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.5242 - val_accuracy: 0.9113\n","\n","Epoch 00138: val_accuracy did not improve from 0.92611\n","Epoch 139/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4310 - val_accuracy: 0.8990\n","\n","Epoch 00139: val_accuracy did not improve from 0.92611\n","Epoch 140/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.6080 - val_accuracy: 0.8941\n","\n","Epoch 00140: val_accuracy did not improve from 0.92611\n","Epoch 141/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0052 - accuracy: 0.9970 - val_loss: 0.5028 - val_accuracy: 0.8966\n","\n","Epoch 00141: val_accuracy did not improve from 0.92611\n","Epoch 142/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.4171 - val_accuracy: 0.9236\n","\n","Epoch 00142: val_accuracy did not improve from 0.92611\n","Epoch 143/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.4375 - val_accuracy: 0.9236\n","\n","Epoch 00143: val_accuracy did not improve from 0.92611\n","Epoch 144/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.3970 - val_accuracy: 0.9236\n","\n","Epoch 00144: val_accuracy did not improve from 0.92611\n","Epoch 145/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.5313 - val_accuracy: 0.8941\n","\n","Epoch 00145: val_accuracy did not improve from 0.92611\n","Epoch 146/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.5841 - val_accuracy: 0.8990\n","\n","Epoch 00146: val_accuracy did not improve from 0.92611\n","Epoch 147/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.7228 - val_accuracy: 0.8818\n","\n","Epoch 00147: val_accuracy did not improve from 0.92611\n","Epoch 148/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0683 - accuracy: 0.9781 - val_loss: 3.4504 - val_accuracy: 0.6897\n","\n","Epoch 00148: val_accuracy did not improve from 0.92611\n","Epoch 149/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.1102 - accuracy: 0.9635 - val_loss: 2.2114 - val_accuracy: 0.7734\n","\n","Epoch 00149: val_accuracy did not improve from 0.92611\n","Epoch 150/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0740 - accuracy: 0.9805 - val_loss: 0.8268 - val_accuracy: 0.8498\n","\n","Epoch 00150: val_accuracy did not improve from 0.92611\n","Epoch 151/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0370 - accuracy: 0.9884 - val_loss: 0.7866 - val_accuracy: 0.8547\n","\n","Epoch 00151: val_accuracy did not improve from 0.92611\n","Epoch 152/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0533 - accuracy: 0.9829 - val_loss: 0.9516 - val_accuracy: 0.8571\n","\n","Epoch 00152: val_accuracy did not improve from 0.92611\n","Epoch 153/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0766 - accuracy: 0.9787 - val_loss: 1.1618 - val_accuracy: 0.8473\n","\n","Epoch 00153: val_accuracy did not improve from 0.92611\n","Epoch 154/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0345 - accuracy: 0.9909 - val_loss: 0.6181 - val_accuracy: 0.8916\n","\n","Epoch 00154: val_accuracy did not improve from 0.92611\n","Epoch 155/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.6224 - val_accuracy: 0.9089\n","\n","Epoch 00155: val_accuracy did not improve from 0.92611\n","Epoch 156/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0752 - accuracy: 0.9787 - val_loss: 0.9677 - val_accuracy: 0.8448\n","\n","Epoch 00156: val_accuracy did not improve from 0.92611\n","Epoch 157/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0724 - accuracy: 0.9811 - val_loss: 1.0567 - val_accuracy: 0.8374\n","\n","Epoch 00157: val_accuracy did not improve from 0.92611\n","Epoch 158/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0432 - accuracy: 0.9909 - val_loss: 0.9795 - val_accuracy: 0.8645\n","\n","Epoch 00158: val_accuracy did not improve from 0.92611\n","Epoch 159/500\n","52/52 [==============================] - 18s 345ms/step - loss: 0.0329 - accuracy: 0.9903 - val_loss: 0.4998 - val_accuracy: 0.9089\n","\n","Epoch 00159: val_accuracy did not improve from 0.92611\n","Epoch 160/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.4676 - val_accuracy: 0.9039\n","\n","Epoch 00160: val_accuracy did not improve from 0.92611\n","Epoch 161/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.5967 - val_accuracy: 0.8818\n","\n","Epoch 00161: val_accuracy did not improve from 0.92611\n","Epoch 162/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.5768 - val_accuracy: 0.9015\n","\n","Epoch 00162: val_accuracy did not improve from 0.92611\n","Epoch 163/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0204 - accuracy: 0.9945 - val_loss: 0.7255 - val_accuracy: 0.8793\n","\n","Epoch 00163: val_accuracy did not improve from 0.92611\n","Epoch 164/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0180 - accuracy: 0.9957 - val_loss: 0.7307 - val_accuracy: 0.8818\n","\n","Epoch 00164: val_accuracy did not improve from 0.92611\n","Epoch 165/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.5483 - val_accuracy: 0.8990\n","\n","Epoch 00165: val_accuracy did not improve from 0.92611\n","Epoch 166/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0156 - accuracy: 0.9970 - val_loss: 0.5749 - val_accuracy: 0.8867\n","\n","Epoch 00166: val_accuracy did not improve from 0.92611\n","Epoch 167/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.5818 - val_accuracy: 0.8793\n","\n","Epoch 00167: val_accuracy did not improve from 0.92611\n","Epoch 168/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0096 - accuracy: 0.9945 - val_loss: 0.3874 - val_accuracy: 0.9089\n","\n","Epoch 00168: val_accuracy did not improve from 0.92611\n","Epoch 169/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.4794 - val_accuracy: 0.8941\n","\n","Epoch 00169: val_accuracy did not improve from 0.92611\n","Epoch 170/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0346 - accuracy: 0.9915 - val_loss: 0.7534 - val_accuracy: 0.8941\n","\n","Epoch 00170: val_accuracy did not improve from 0.92611\n","Epoch 171/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0484 - accuracy: 0.9866 - val_loss: 0.6375 - val_accuracy: 0.8867\n","\n","Epoch 00171: val_accuracy did not improve from 0.92611\n","Epoch 172/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.7935 - val_accuracy: 0.9015\n","\n","Epoch 00172: val_accuracy did not improve from 0.92611\n","Epoch 173/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0224 - accuracy: 0.9909 - val_loss: 1.1060 - val_accuracy: 0.8399\n","\n","Epoch 00173: val_accuracy did not improve from 0.92611\n","Epoch 174/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.7327 - val_accuracy: 0.8744\n","\n","Epoch 00174: val_accuracy did not improve from 0.92611\n","Epoch 175/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.6531 - val_accuracy: 0.8966\n","\n","Epoch 00175: val_accuracy did not improve from 0.92611\n","Epoch 176/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0188 - accuracy: 0.9927 - val_loss: 0.5241 - val_accuracy: 0.9163\n","\n","Epoch 00176: val_accuracy did not improve from 0.92611\n","Epoch 177/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.5288 - val_accuracy: 0.9163\n","\n","Epoch 00177: val_accuracy did not improve from 0.92611\n","Epoch 178/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.6493 - val_accuracy: 0.8744\n","\n","Epoch 00178: val_accuracy did not improve from 0.92611\n","Epoch 179/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.7124 - val_accuracy: 0.8990\n","\n","Epoch 00179: val_accuracy did not improve from 0.92611\n","Epoch 180/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.6299 - val_accuracy: 0.9212\n","\n","Epoch 00180: val_accuracy did not improve from 0.92611\n","Epoch 181/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.8141 - val_accuracy: 0.8424\n","\n","Epoch 00181: val_accuracy did not improve from 0.92611\n","Epoch 182/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0630 - accuracy: 0.9860 - val_loss: 0.7495 - val_accuracy: 0.8990\n","\n","Epoch 00182: val_accuracy did not improve from 0.92611\n","Epoch 183/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0979 - accuracy: 0.9714 - val_loss: 0.9045 - val_accuracy: 0.8424\n","\n","Epoch 00183: val_accuracy did not improve from 0.92611\n","Epoch 184/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0432 - accuracy: 0.9872 - val_loss: 0.9366 - val_accuracy: 0.8621\n","\n","Epoch 00184: val_accuracy did not improve from 0.92611\n","Epoch 185/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0244 - accuracy: 0.9909 - val_loss: 0.7788 - val_accuracy: 0.8916\n","\n","Epoch 00185: val_accuracy did not improve from 0.92611\n","Epoch 186/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0263 - accuracy: 0.9878 - val_loss: 0.9369 - val_accuracy: 0.8719\n","\n","Epoch 00186: val_accuracy did not improve from 0.92611\n","Epoch 187/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.7014 - val_accuracy: 0.8867\n","\n","Epoch 00187: val_accuracy did not improve from 0.92611\n","Epoch 188/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.5025 - val_accuracy: 0.8867\n","\n","Epoch 00188: val_accuracy did not improve from 0.92611\n","Epoch 189/500\n","52/52 [==============================] - 18s 354ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.8294 - val_accuracy: 0.8719\n","\n","Epoch 00189: val_accuracy did not improve from 0.92611\n","Epoch 190/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.8420 - val_accuracy: 0.8867\n","\n","Epoch 00190: val_accuracy did not improve from 0.92611\n","Epoch 191/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.9207 - val_accuracy: 0.8818\n","\n","Epoch 00191: val_accuracy did not improve from 0.92611\n","Epoch 192/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0447 - accuracy: 0.9884 - val_loss: 0.7621 - val_accuracy: 0.8350\n","\n","Epoch 00192: val_accuracy did not improve from 0.92611\n","Epoch 193/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0533 - accuracy: 0.9829 - val_loss: 0.8687 - val_accuracy: 0.8842\n","\n","Epoch 00193: val_accuracy did not improve from 0.92611\n","Epoch 194/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0201 - accuracy: 0.9921 - val_loss: 0.8097 - val_accuracy: 0.8670\n","\n","Epoch 00194: val_accuracy did not improve from 0.92611\n","Epoch 195/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.7775 - val_accuracy: 0.8670\n","\n","Epoch 00195: val_accuracy did not improve from 0.92611\n","Epoch 196/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 1.1073 - val_accuracy: 0.8621\n","\n","Epoch 00196: val_accuracy did not improve from 0.92611\n","Epoch 197/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0293 - accuracy: 0.9909 - val_loss: 1.1438 - val_accuracy: 0.8596\n","\n","Epoch 00197: val_accuracy did not improve from 0.92611\n","Epoch 198/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0418 - accuracy: 0.9890 - val_loss: 1.0889 - val_accuracy: 0.8276\n","\n","Epoch 00198: val_accuracy did not improve from 0.92611\n","Epoch 199/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.7886 - val_accuracy: 0.8768\n","\n","Epoch 00199: val_accuracy did not improve from 0.92611\n","Epoch 200/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0161 - accuracy: 0.9927 - val_loss: 0.6459 - val_accuracy: 0.8941\n","\n","Epoch 00200: val_accuracy did not improve from 0.92611\n","Epoch 201/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0343 - accuracy: 0.9945 - val_loss: 0.6713 - val_accuracy: 0.8892\n","\n","Epoch 00201: val_accuracy did not improve from 0.92611\n","Epoch 202/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0349 - accuracy: 0.9909 - val_loss: 0.5959 - val_accuracy: 0.9089\n","\n","Epoch 00202: val_accuracy did not improve from 0.92611\n","Epoch 203/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.6681 - val_accuracy: 0.8941\n","\n","Epoch 00203: val_accuracy did not improve from 0.92611\n","Epoch 204/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0308 - accuracy: 0.9927 - val_loss: 0.7638 - val_accuracy: 0.8793\n","\n","Epoch 00204: val_accuracy did not improve from 0.92611\n","Epoch 205/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.6348 - val_accuracy: 0.9015\n","\n","Epoch 00205: val_accuracy did not improve from 0.92611\n","Epoch 206/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.5820 - val_accuracy: 0.8990\n","\n","Epoch 00206: val_accuracy did not improve from 0.92611\n","Epoch 207/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.6259 - val_accuracy: 0.8842\n","\n","Epoch 00207: val_accuracy did not improve from 0.92611\n","Epoch 208/500\n","52/52 [==============================] - 18s 346ms/step - loss: 0.0783 - accuracy: 0.9811 - val_loss: 1.0838 - val_accuracy: 0.8571\n","\n","Epoch 00208: val_accuracy did not improve from 0.92611\n","Epoch 209/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0735 - accuracy: 0.9762 - val_loss: 1.7811 - val_accuracy: 0.7980\n","\n","Epoch 00209: val_accuracy did not improve from 0.92611\n","Epoch 210/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.8982 - val_accuracy: 0.8744\n","\n","Epoch 00210: val_accuracy did not improve from 0.92611\n","Epoch 211/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 1.0681 - val_accuracy: 0.8350\n","\n","Epoch 00211: val_accuracy did not improve from 0.92611\n","Epoch 212/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 0.6857 - val_accuracy: 0.8892\n","\n","Epoch 00212: val_accuracy did not improve from 0.92611\n","Epoch 213/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6896 - val_accuracy: 0.8842\n","\n","Epoch 00213: val_accuracy did not improve from 0.92611\n","Epoch 214/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5953 - val_accuracy: 0.9064\n","\n","Epoch 00214: val_accuracy did not improve from 0.92611\n","Epoch 215/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.9236\n","\n","Epoch 00215: val_accuracy did not improve from 0.92611\n","Epoch 216/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.6682 - val_accuracy: 0.9064\n","\n","Epoch 00216: val_accuracy did not improve from 0.92611\n","Epoch 217/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.7641 - val_accuracy: 0.8670\n","\n","Epoch 00217: val_accuracy did not improve from 0.92611\n","Epoch 218/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.9609 - val_accuracy: 0.8695\n","\n","Epoch 00218: val_accuracy did not improve from 0.92611\n","Epoch 219/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0590 - accuracy: 0.9878 - val_loss: 0.6896 - val_accuracy: 0.8842\n","\n","Epoch 00219: val_accuracy did not improve from 0.92611\n","Epoch 220/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.8912 - val_accuracy: 0.8818\n","\n","Epoch 00220: val_accuracy did not improve from 0.92611\n","Epoch 221/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0314 - accuracy: 0.9915 - val_loss: 1.3939 - val_accuracy: 0.7956\n","\n","Epoch 00221: val_accuracy did not improve from 0.92611\n","Epoch 222/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.7162 - val_accuracy: 0.8744\n","\n","Epoch 00222: val_accuracy did not improve from 0.92611\n","Epoch 223/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.6733 - val_accuracy: 0.8990\n","\n","Epoch 00223: val_accuracy did not improve from 0.92611\n","Epoch 224/500\n","52/52 [==============================] - 18s 346ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4897 - val_accuracy: 0.9187\n","\n","Epoch 00224: val_accuracy did not improve from 0.92611\n","Epoch 225/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5580 - val_accuracy: 0.9113\n","\n","Epoch 00225: val_accuracy did not improve from 0.92611\n","Epoch 226/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.6512 - val_accuracy: 0.8990\n","\n","Epoch 00226: val_accuracy did not improve from 0.92611\n","Epoch 227/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.5657 - val_accuracy: 0.8990\n","\n","Epoch 00227: val_accuracy did not improve from 0.92611\n","Epoch 228/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.6003 - val_accuracy: 0.8892\n","\n","Epoch 00228: val_accuracy did not improve from 0.92611\n","Epoch 229/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5611 - val_accuracy: 0.9089\n","\n","Epoch 00229: val_accuracy did not improve from 0.92611\n","Epoch 230/500\n","52/52 [==============================] - 18s 350ms/step - loss: 8.7936e-04 - accuracy: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.9138\n","\n","Epoch 00230: val_accuracy did not improve from 0.92611\n","Epoch 231/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.7704 - val_accuracy: 0.8867\n","\n","Epoch 00231: val_accuracy did not improve from 0.92611\n","Epoch 232/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.7445 - val_accuracy: 0.8892\n","\n","Epoch 00232: val_accuracy did not improve from 0.92611\n","Epoch 233/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.8532 - val_accuracy: 0.8941\n","\n","Epoch 00233: val_accuracy did not improve from 0.92611\n","Epoch 234/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0154 - accuracy: 0.9939 - val_loss: 0.9066 - val_accuracy: 0.8621\n","\n","Epoch 00234: val_accuracy did not improve from 0.92611\n","Epoch 235/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.6686 - val_accuracy: 0.8966\n","\n","Epoch 00235: val_accuracy did not improve from 0.92611\n","Epoch 236/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.9296 - val_accuracy: 0.8892\n","\n","Epoch 00236: val_accuracy did not improve from 0.92611\n","Epoch 237/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.7913 - val_accuracy: 0.8941\n","\n","Epoch 00237: val_accuracy did not improve from 0.92611\n","Epoch 238/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.8405 - val_accuracy: 0.8990\n","\n","Epoch 00238: val_accuracy did not improve from 0.92611\n","Epoch 239/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.6398 - val_accuracy: 0.9113\n","\n","Epoch 00239: val_accuracy did not improve from 0.92611\n","Epoch 240/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.7208 - val_accuracy: 0.9039\n","\n","Epoch 00240: val_accuracy did not improve from 0.92611\n","Epoch 241/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0225 - accuracy: 0.9945 - val_loss: 0.8242 - val_accuracy: 0.8424\n","\n","Epoch 00241: val_accuracy did not improve from 0.92611\n","Epoch 242/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0125 - accuracy: 0.9939 - val_loss: 0.7793 - val_accuracy: 0.8793\n","\n","Epoch 00242: val_accuracy did not improve from 0.92611\n","Epoch 243/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.5931 - val_accuracy: 0.8842\n","\n","Epoch 00243: val_accuracy did not improve from 0.92611\n","Epoch 244/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.7791 - val_accuracy: 0.8818\n","\n","Epoch 00244: val_accuracy did not improve from 0.92611\n","Epoch 245/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 1.0492 - val_accuracy: 0.8695\n","\n","Epoch 00245: val_accuracy did not improve from 0.92611\n","Epoch 246/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0421 - accuracy: 0.9866 - val_loss: 1.1789 - val_accuracy: 0.8670\n","\n","Epoch 00246: val_accuracy did not improve from 0.92611\n","Epoch 247/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6620 - val_accuracy: 0.9039\n","\n","Epoch 00247: val_accuracy did not improve from 0.92611\n","Epoch 248/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0233 - accuracy: 0.9951 - val_loss: 0.7473 - val_accuracy: 0.8842\n","\n","Epoch 00248: val_accuracy did not improve from 0.92611\n","Epoch 249/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.5970 - val_accuracy: 0.8941\n","\n","Epoch 00249: val_accuracy did not improve from 0.92611\n","Epoch 250/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.6808 - val_accuracy: 0.8793\n","\n","Epoch 00250: val_accuracy did not improve from 0.92611\n","Epoch 251/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0095 - accuracy: 0.9957 - val_loss: 0.7018 - val_accuracy: 0.8916\n","\n","Epoch 00251: val_accuracy did not improve from 0.92611\n","Epoch 252/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.8125 - val_accuracy: 0.8793\n","\n","Epoch 00252: val_accuracy did not improve from 0.92611\n","Epoch 253/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.6951 - val_accuracy: 0.8916\n","\n","Epoch 00253: val_accuracy did not improve from 0.92611\n","Epoch 254/500\n","52/52 [==============================] - 18s 346ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.6444 - val_accuracy: 0.9015\n","\n","Epoch 00254: val_accuracy did not improve from 0.92611\n","Epoch 255/500\n","52/52 [==============================] - 18s 344ms/step - loss: 0.0302 - accuracy: 0.9927 - val_loss: 2.9626 - val_accuracy: 0.6429\n","\n","Epoch 00255: val_accuracy did not improve from 0.92611\n","Epoch 256/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0595 - accuracy: 0.9866 - val_loss: 1.0356 - val_accuracy: 0.8547\n","\n","Epoch 00256: val_accuracy did not improve from 0.92611\n","Epoch 257/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0863 - accuracy: 0.9793 - val_loss: 1.4996 - val_accuracy: 0.8005\n","\n","Epoch 00257: val_accuracy did not improve from 0.92611\n","Epoch 258/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0520 - accuracy: 0.9848 - val_loss: 1.0664 - val_accuracy: 0.8596\n","\n","Epoch 00258: val_accuracy did not improve from 0.92611\n","Epoch 259/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.7639 - val_accuracy: 0.8867\n","\n","Epoch 00259: val_accuracy did not improve from 0.92611\n","Epoch 260/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.8420 - val_accuracy: 0.8719\n","\n","Epoch 00260: val_accuracy did not improve from 0.92611\n","Epoch 261/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.5834 - val_accuracy: 0.8892\n","\n","Epoch 00261: val_accuracy did not improve from 0.92611\n","Epoch 262/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0052 - accuracy: 0.9970 - val_loss: 0.6838 - val_accuracy: 0.8793\n","\n","Epoch 00262: val_accuracy did not improve from 0.92611\n","Epoch 263/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.6047 - val_accuracy: 0.9015\n","\n","Epoch 00263: val_accuracy did not improve from 0.92611\n","Epoch 264/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.6404 - val_accuracy: 0.8941\n","\n","Epoch 00264: val_accuracy did not improve from 0.92611\n","Epoch 265/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5698 - val_accuracy: 0.9113\n","\n","Epoch 00265: val_accuracy did not improve from 0.92611\n","Epoch 266/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5328 - val_accuracy: 0.8966\n","\n","Epoch 00266: val_accuracy did not improve from 0.92611\n","Epoch 267/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5917 - val_accuracy: 0.9163\n","\n","Epoch 00267: val_accuracy did not improve from 0.92611\n","Epoch 268/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.6819 - val_accuracy: 0.8892\n","\n","Epoch 00268: val_accuracy did not improve from 0.92611\n","Epoch 269/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5186 - val_accuracy: 0.9163\n","\n","Epoch 00269: val_accuracy did not improve from 0.92611\n","Epoch 270/500\n","52/52 [==============================] - 18s 348ms/step - loss: 5.9089e-04 - accuracy: 1.0000 - val_loss: 0.4896 - val_accuracy: 0.9212\n","\n","Epoch 00270: val_accuracy did not improve from 0.92611\n","Epoch 271/500\n","52/52 [==============================] - 18s 349ms/step - loss: 2.1446e-04 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.9187\n","\n","Epoch 00271: val_accuracy did not improve from 0.92611\n","Epoch 272/500\n","52/52 [==============================] - 18s 350ms/step - loss: 4.3881e-04 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.9187\n","\n","Epoch 00272: val_accuracy did not improve from 0.92611\n","Epoch 273/500\n","52/52 [==============================] - 18s 351ms/step - loss: 3.1914e-04 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9187\n","\n","Epoch 00273: val_accuracy did not improve from 0.92611\n","Epoch 274/500\n","52/52 [==============================] - 18s 351ms/step - loss: 2.9042e-04 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.9138\n","\n","Epoch 00274: val_accuracy did not improve from 0.92611\n","Epoch 275/500\n","52/52 [==============================] - 18s 352ms/step - loss: 2.2908e-04 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.9163\n","\n","Epoch 00275: val_accuracy did not improve from 0.92611\n","Epoch 276/500\n","52/52 [==============================] - 18s 350ms/step - loss: 5.3446e-04 - accuracy: 1.0000 - val_loss: 0.5520 - val_accuracy: 0.9039\n","\n","Epoch 00276: val_accuracy did not improve from 0.92611\n","Epoch 277/500\n","52/52 [==============================] - 18s 348ms/step - loss: 9.8951e-05 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.9187\n","\n","Epoch 00277: val_accuracy did not improve from 0.92611\n","Epoch 278/500\n","52/52 [==============================] - 18s 352ms/step - loss: 2.4119e-04 - accuracy: 1.0000 - val_loss: 0.5350 - val_accuracy: 0.9113\n","\n","Epoch 00278: val_accuracy did not improve from 0.92611\n","Epoch 279/500\n","52/52 [==============================] - 18s 350ms/step - loss: 2.9606e-04 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.9163\n","\n","Epoch 00279: val_accuracy did not improve from 0.92611\n","Epoch 280/500\n","52/52 [==============================] - 18s 348ms/step - loss: 5.5507e-04 - accuracy: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.9138\n","\n","Epoch 00280: val_accuracy did not improve from 0.92611\n","Epoch 281/500\n","52/52 [==============================] - 18s 349ms/step - loss: 2.3622e-04 - accuracy: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.9212\n","\n","Epoch 00281: val_accuracy did not improve from 0.92611\n","Epoch 282/500\n","52/52 [==============================] - 18s 351ms/step - loss: 7.6047e-05 - accuracy: 1.0000 - val_loss: 0.5158 - val_accuracy: 0.9261\n","\n","Epoch 00282: val_accuracy did not improve from 0.92611\n","Epoch 283/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.7404 - val_accuracy: 0.8966\n","\n","Epoch 00283: val_accuracy did not improve from 0.92611\n","Epoch 284/500\n","52/52 [==============================] - 18s 345ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 1.2873 - val_accuracy: 0.8448\n","\n","Epoch 00284: val_accuracy did not improve from 0.92611\n","Epoch 285/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0772 - accuracy: 0.9848 - val_loss: 4.5981 - val_accuracy: 0.6256\n","\n","Epoch 00285: val_accuracy did not improve from 0.92611\n","Epoch 286/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.1055 - accuracy: 0.9720 - val_loss: 2.1893 - val_accuracy: 0.7931\n","\n","Epoch 00286: val_accuracy did not improve from 0.92611\n","Epoch 287/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0586 - accuracy: 0.9811 - val_loss: 3.7305 - val_accuracy: 0.7266\n","\n","Epoch 00287: val_accuracy did not improve from 0.92611\n","Epoch 288/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0680 - accuracy: 0.9781 - val_loss: 1.0768 - val_accuracy: 0.8473\n","\n","Epoch 00288: val_accuracy did not improve from 0.92611\n","Epoch 289/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0389 - accuracy: 0.9884 - val_loss: 0.7961 - val_accuracy: 0.8621\n","\n","Epoch 00289: val_accuracy did not improve from 0.92611\n","Epoch 290/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0682 - accuracy: 0.9823 - val_loss: 1.2164 - val_accuracy: 0.7980\n","\n","Epoch 00290: val_accuracy did not improve from 0.92611\n","Epoch 291/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0741 - accuracy: 0.9848 - val_loss: 1.3153 - val_accuracy: 0.8276\n","\n","Epoch 00291: val_accuracy did not improve from 0.92611\n","Epoch 292/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 0.9538 - val_accuracy: 0.8719\n","\n","Epoch 00292: val_accuracy did not improve from 0.92611\n","Epoch 293/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0331 - accuracy: 0.9878 - val_loss: 1.0296 - val_accuracy: 0.8571\n","\n","Epoch 00293: val_accuracy did not improve from 0.92611\n","Epoch 294/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0669 - accuracy: 0.9848 - val_loss: 1.0578 - val_accuracy: 0.8473\n","\n","Epoch 00294: val_accuracy did not improve from 0.92611\n","Epoch 295/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.6384 - val_accuracy: 0.8892\n","\n","Epoch 00295: val_accuracy did not improve from 0.92611\n","Epoch 296/500\n","52/52 [==============================] - 18s 346ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.8139 - val_accuracy: 0.8793\n","\n","Epoch 00296: val_accuracy did not improve from 0.92611\n","Epoch 297/500\n","52/52 [==============================] - 18s 346ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.6727 - val_accuracy: 0.9015\n","\n","Epoch 00297: val_accuracy did not improve from 0.92611\n","Epoch 298/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.5765 - val_accuracy: 0.9089\n","\n","Epoch 00298: val_accuracy did not improve from 0.92611\n","Epoch 299/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.6061 - val_accuracy: 0.9015\n","\n","Epoch 00299: val_accuracy did not improve from 0.92611\n","Epoch 300/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0042 - accuracy: 0.9970 - val_loss: 0.5460 - val_accuracy: 0.9089\n","\n","Epoch 00300: val_accuracy did not improve from 0.92611\n","Epoch 301/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.6413 - val_accuracy: 0.8916\n","\n","Epoch 00301: val_accuracy did not improve from 0.92611\n","Epoch 302/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5725 - val_accuracy: 0.9064\n","\n","Epoch 00302: val_accuracy did not improve from 0.92611\n","Epoch 303/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.6718 - val_accuracy: 0.8941\n","\n","Epoch 00303: val_accuracy did not improve from 0.92611\n","Epoch 304/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0414 - accuracy: 0.9890 - val_loss: 1.0336 - val_accuracy: 0.8695\n","\n","Epoch 00304: val_accuracy did not improve from 0.92611\n","Epoch 305/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.6208 - val_accuracy: 0.9089\n","\n","Epoch 00305: val_accuracy did not improve from 0.92611\n","Epoch 306/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.6632 - val_accuracy: 0.9064\n","\n","Epoch 00306: val_accuracy did not improve from 0.92611\n","Epoch 307/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.7026 - val_accuracy: 0.8768\n","\n","Epoch 00307: val_accuracy did not improve from 0.92611\n","Epoch 308/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.7291 - val_accuracy: 0.8793\n","\n","Epoch 00308: val_accuracy did not improve from 0.92611\n","Epoch 309/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.6039 - val_accuracy: 0.9015\n","\n","Epoch 00309: val_accuracy did not improve from 0.92611\n","Epoch 310/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.7308 - val_accuracy: 0.9064\n","\n","Epoch 00310: val_accuracy did not improve from 0.92611\n","Epoch 311/500\n","52/52 [==============================] - 18s 351ms/step - loss: 7.7986e-04 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.9064\n","\n","Epoch 00311: val_accuracy did not improve from 0.92611\n","Epoch 312/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.6313 - val_accuracy: 0.9138\n","\n","Epoch 00312: val_accuracy did not improve from 0.92611\n","Epoch 313/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.7764 - val_accuracy: 0.8941\n","\n","Epoch 00313: val_accuracy did not improve from 0.92611\n","Epoch 314/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.7394 - val_accuracy: 0.8966\n","\n","Epoch 00314: val_accuracy did not improve from 0.92611\n","Epoch 315/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5688 - val_accuracy: 0.9113\n","\n","Epoch 00315: val_accuracy did not improve from 0.92611\n","Epoch 316/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5482 - val_accuracy: 0.9089\n","\n","Epoch 00316: val_accuracy did not improve from 0.92611\n","Epoch 317/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.6075 - val_accuracy: 0.9187\n","\n","Epoch 00317: val_accuracy did not improve from 0.92611\n","Epoch 318/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.7167 - val_accuracy: 0.8842\n","\n","Epoch 00318: val_accuracy did not improve from 0.92611\n","Epoch 319/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.8072 - val_accuracy: 0.8892\n","\n","Epoch 00319: val_accuracy did not improve from 0.92611\n","Epoch 320/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.6843 - val_accuracy: 0.9064\n","\n","Epoch 00320: val_accuracy did not improve from 0.92611\n","Epoch 321/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.9238 - val_accuracy: 0.8818\n","\n","Epoch 00321: val_accuracy did not improve from 0.92611\n","Epoch 322/500\n","52/52 [==============================] - 18s 353ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.6053 - val_accuracy: 0.9187\n","\n","Epoch 00322: val_accuracy did not improve from 0.92611\n","Epoch 323/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6527 - val_accuracy: 0.8990\n","\n","Epoch 00323: val_accuracy did not improve from 0.92611\n","Epoch 324/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.7517 - val_accuracy: 0.9163\n","\n","Epoch 00324: val_accuracy did not improve from 0.92611\n","Epoch 325/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0470 - accuracy: 0.9890 - val_loss: 0.8278 - val_accuracy: 0.8916\n","\n","Epoch 00325: val_accuracy did not improve from 0.92611\n","Epoch 326/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0486 - accuracy: 0.9842 - val_loss: 1.7144 - val_accuracy: 0.7956\n","\n","Epoch 00326: val_accuracy did not improve from 0.92611\n","Epoch 327/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 0.8842 - val_accuracy: 0.8695\n","\n","Epoch 00327: val_accuracy did not improve from 0.92611\n","Epoch 328/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.7229 - val_accuracy: 0.8966\n","\n","Epoch 00328: val_accuracy did not improve from 0.92611\n","Epoch 329/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.6320 - val_accuracy: 0.9212\n","\n","Epoch 00329: val_accuracy did not improve from 0.92611\n","Epoch 330/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 1.1216 - val_accuracy: 0.8645\n","\n","Epoch 00330: val_accuracy did not improve from 0.92611\n","Epoch 331/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0050 - accuracy: 0.9970 - val_loss: 0.7826 - val_accuracy: 0.8990\n","\n","Epoch 00331: val_accuracy did not improve from 0.92611\n","Epoch 332/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5763 - val_accuracy: 0.9138\n","\n","Epoch 00332: val_accuracy did not improve from 0.92611\n","Epoch 333/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.6970 - val_accuracy: 0.8966\n","\n","Epoch 00333: val_accuracy did not improve from 0.92611\n","Epoch 334/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 0.7082 - val_accuracy: 0.8867\n","\n","Epoch 00334: val_accuracy did not improve from 0.92611\n","Epoch 335/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.9619 - val_accuracy: 0.8744\n","\n","Epoch 00335: val_accuracy did not improve from 0.92611\n","Epoch 336/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0194 - accuracy: 0.9957 - val_loss: 0.5873 - val_accuracy: 0.8941\n","\n","Epoch 00336: val_accuracy did not improve from 0.92611\n","Epoch 337/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.7003 - val_accuracy: 0.8941\n","\n","Epoch 00337: val_accuracy did not improve from 0.92611\n","Epoch 338/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.8821 - val_accuracy: 0.8842\n","\n","Epoch 00338: val_accuracy did not improve from 0.92611\n","Epoch 339/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.8467 - val_accuracy: 0.8892\n","\n","Epoch 00339: val_accuracy did not improve from 0.92611\n","Epoch 340/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.6263 - val_accuracy: 0.9163\n","\n","Epoch 00340: val_accuracy did not improve from 0.92611\n","Epoch 341/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6295 - val_accuracy: 0.9113\n","\n","Epoch 00341: val_accuracy did not improve from 0.92611\n","Epoch 342/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.6229 - val_accuracy: 0.9212\n","\n","Epoch 00342: val_accuracy did not improve from 0.92611\n","Epoch 343/500\n","52/52 [==============================] - 18s 349ms/step - loss: 9.9279e-04 - accuracy: 1.0000 - val_loss: 0.6116 - val_accuracy: 0.9138\n","\n","Epoch 00343: val_accuracy did not improve from 0.92611\n","Epoch 344/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0138 - accuracy: 0.9982 - val_loss: 0.8000 - val_accuracy: 0.8941\n","\n","Epoch 00344: val_accuracy did not improve from 0.92611\n","Epoch 345/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.7327 - val_accuracy: 0.8990\n","\n","Epoch 00345: val_accuracy did not improve from 0.92611\n","Epoch 346/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.5893 - val_accuracy: 0.9039\n","\n","Epoch 00346: val_accuracy did not improve from 0.92611\n","Epoch 347/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0128 - accuracy: 0.9982 - val_loss: 0.7012 - val_accuracy: 0.9138\n","\n","Epoch 00347: val_accuracy did not improve from 0.92611\n","Epoch 348/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.8266 - val_accuracy: 0.9064\n","\n","Epoch 00348: val_accuracy did not improve from 0.92611\n","Epoch 349/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.9033 - val_accuracy: 0.8793\n","\n","Epoch 00349: val_accuracy did not improve from 0.92611\n","Epoch 350/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.9236 - val_accuracy: 0.8719\n","\n","Epoch 00350: val_accuracy did not improve from 0.92611\n","Epoch 351/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 1.1434 - val_accuracy: 0.8621\n","\n","Epoch 00351: val_accuracy did not improve from 0.92611\n","Epoch 352/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0195 - accuracy: 0.9921 - val_loss: 0.9514 - val_accuracy: 0.8645\n","\n","Epoch 00352: val_accuracy did not improve from 0.92611\n","Epoch 353/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 0.9448 - val_accuracy: 0.8719\n","\n","Epoch 00353: val_accuracy did not improve from 0.92611\n","Epoch 354/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.7718 - val_accuracy: 0.8842\n","\n","Epoch 00354: val_accuracy did not improve from 0.92611\n","Epoch 355/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.7942 - val_accuracy: 0.8867\n","\n","Epoch 00355: val_accuracy did not improve from 0.92611\n","Epoch 356/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.7971 - val_accuracy: 0.8892\n","\n","Epoch 00356: val_accuracy did not improve from 0.92611\n","Epoch 357/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 1.4083 - val_accuracy: 0.8522\n","\n","Epoch 00357: val_accuracy did not improve from 0.92611\n","Epoch 358/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.6585 - val_accuracy: 0.8990\n","\n","Epoch 00358: val_accuracy did not improve from 0.92611\n","Epoch 359/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.9047 - val_accuracy: 0.9015\n","\n","Epoch 00359: val_accuracy did not improve from 0.92611\n","Epoch 360/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.7604 - val_accuracy: 0.9064\n","\n","Epoch 00360: val_accuracy did not improve from 0.92611\n","Epoch 361/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5750 - val_accuracy: 0.9236\n","\n","Epoch 00361: val_accuracy did not improve from 0.92611\n","Epoch 362/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.6647 - val_accuracy: 0.9212\n","\n","Epoch 00362: val_accuracy did not improve from 0.92611\n","Epoch 363/500\n","52/52 [==============================] - 18s 349ms/step - loss: 4.9355e-04 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 0.9039\n","\n","Epoch 00363: val_accuracy did not improve from 0.92611\n","Epoch 364/500\n","52/52 [==============================] - 18s 348ms/step - loss: 3.3553e-04 - accuracy: 1.0000 - val_loss: 0.6024 - val_accuracy: 0.9212\n","\n","Epoch 00364: val_accuracy did not improve from 0.92611\n","Epoch 365/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.6091 - val_accuracy: 0.9138\n","\n","Epoch 00365: val_accuracy did not improve from 0.92611\n","Epoch 366/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.9163\n","\n","Epoch 00366: val_accuracy did not improve from 0.92611\n","Epoch 367/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.8408 - val_accuracy: 0.9089\n","\n","Epoch 00367: val_accuracy did not improve from 0.92611\n","Epoch 368/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 1.0605 - val_accuracy: 0.8867\n","\n","Epoch 00368: val_accuracy did not improve from 0.92611\n","Epoch 369/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.6321 - val_accuracy: 0.9039\n","\n","Epoch 00369: val_accuracy did not improve from 0.92611\n","Epoch 370/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.9073 - val_accuracy: 0.8670\n","\n","Epoch 00370: val_accuracy did not improve from 0.92611\n","Epoch 371/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0337 - accuracy: 0.9909 - val_loss: 1.4133 - val_accuracy: 0.8103\n","\n","Epoch 00371: val_accuracy did not improve from 0.92611\n","Epoch 372/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 1.1212 - val_accuracy: 0.8547\n","\n","Epoch 00372: val_accuracy did not improve from 0.92611\n","Epoch 373/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.7248 - val_accuracy: 0.8867\n","\n","Epoch 00373: val_accuracy did not improve from 0.92611\n","Epoch 374/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0102 - accuracy: 0.9951 - val_loss: 0.8468 - val_accuracy: 0.8621\n","\n","Epoch 00374: val_accuracy did not improve from 0.92611\n","Epoch 375/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 1.0539 - val_accuracy: 0.8596\n","\n","Epoch 00375: val_accuracy did not improve from 0.92611\n","Epoch 376/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.9798 - val_accuracy: 0.8867\n","\n","Epoch 00376: val_accuracy did not improve from 0.92611\n","Epoch 377/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 1.5700 - val_accuracy: 0.8276\n","\n","Epoch 00377: val_accuracy did not improve from 0.92611\n","Epoch 378/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0233 - accuracy: 0.9939 - val_loss: 0.8929 - val_accuracy: 0.8916\n","\n","Epoch 00378: val_accuracy did not improve from 0.92611\n","Epoch 379/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.8480 - val_accuracy: 0.8867\n","\n","Epoch 00379: val_accuracy did not improve from 0.92611\n","Epoch 380/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 1.0420 - val_accuracy: 0.8892\n","\n","Epoch 00380: val_accuracy did not improve from 0.92611\n","Epoch 381/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.7146 - val_accuracy: 0.8990\n","\n","Epoch 00381: val_accuracy did not improve from 0.92611\n","Epoch 382/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 1.0272 - val_accuracy: 0.8719\n","\n","Epoch 00382: val_accuracy did not improve from 0.92611\n","Epoch 383/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 1.1124 - val_accuracy: 0.8744\n","\n","Epoch 00383: val_accuracy did not improve from 0.92611\n","Epoch 384/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.8185 - val_accuracy: 0.8966\n","\n","Epoch 00384: val_accuracy did not improve from 0.92611\n","Epoch 385/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0285 - accuracy: 0.9951 - val_loss: 0.6355 - val_accuracy: 0.9113\n","\n","Epoch 00385: val_accuracy did not improve from 0.92611\n","Epoch 386/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.6595 - val_accuracy: 0.9039\n","\n","Epoch 00386: val_accuracy did not improve from 0.92611\n","Epoch 387/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 1.1124 - val_accuracy: 0.8522\n","\n","Epoch 00387: val_accuracy did not improve from 0.92611\n","Epoch 388/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.8609 - val_accuracy: 0.8941\n","\n","Epoch 00388: val_accuracy did not improve from 0.92611\n","Epoch 389/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6409 - val_accuracy: 0.8990\n","\n","Epoch 00389: val_accuracy did not improve from 0.92611\n","Epoch 390/500\n","52/52 [==============================] - 18s 350ms/step - loss: 9.8113e-04 - accuracy: 1.0000 - val_loss: 0.6708 - val_accuracy: 0.9089\n","\n","Epoch 00390: val_accuracy did not improve from 0.92611\n","Epoch 391/500\n","52/52 [==============================] - 18s 351ms/step - loss: 4.5422e-04 - accuracy: 1.0000 - val_loss: 0.5982 - val_accuracy: 0.9236\n","\n","Epoch 00391: val_accuracy did not improve from 0.92611\n","Epoch 392/500\n","52/52 [==============================] - 18s 350ms/step - loss: 3.8980e-04 - accuracy: 1.0000 - val_loss: 0.5981 - val_accuracy: 0.9187\n","\n","Epoch 00392: val_accuracy did not improve from 0.92611\n","Epoch 393/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.9046 - val_accuracy: 0.8818\n","\n","Epoch 00393: val_accuracy did not improve from 0.92611\n","Epoch 394/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.5939 - val_accuracy: 0.9212\n","\n","Epoch 00394: val_accuracy did not improve from 0.92611\n","Epoch 395/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.7245 - val_accuracy: 0.8941\n","\n","Epoch 00395: val_accuracy did not improve from 0.92611\n","Epoch 396/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0325 - accuracy: 0.9939 - val_loss: 1.0927 - val_accuracy: 0.8768\n","\n","Epoch 00396: val_accuracy did not improve from 0.92611\n","Epoch 397/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0806 - accuracy: 0.9848 - val_loss: 0.7076 - val_accuracy: 0.8695\n","\n","Epoch 00397: val_accuracy did not improve from 0.92611\n","Epoch 398/500\n","52/52 [==============================] - 18s 353ms/step - loss: 0.0272 - accuracy: 0.9939 - val_loss: 1.0167 - val_accuracy: 0.8571\n","\n","Epoch 00398: val_accuracy did not improve from 0.92611\n","Epoch 399/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0677 - accuracy: 0.9854 - val_loss: 1.7445 - val_accuracy: 0.8227\n","\n","Epoch 00399: val_accuracy did not improve from 0.92611\n","Epoch 400/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 1.8373 - val_accuracy: 0.8202\n","\n","Epoch 00400: val_accuracy did not improve from 0.92611\n","Epoch 401/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.8804 - val_accuracy: 0.8547\n","\n","Epoch 00401: val_accuracy did not improve from 0.92611\n","Epoch 402/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.7481 - val_accuracy: 0.8842\n","\n","Epoch 00402: val_accuracy did not improve from 0.92611\n","Epoch 403/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.7412 - val_accuracy: 0.8990\n","\n","Epoch 00403: val_accuracy did not improve from 0.92611\n","Epoch 404/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.7084 - val_accuracy: 0.9015\n","\n","Epoch 00404: val_accuracy did not improve from 0.92611\n","Epoch 405/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.7162 - val_accuracy: 0.8990\n","\n","Epoch 00405: val_accuracy did not improve from 0.92611\n","Epoch 406/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.7207 - val_accuracy: 0.8941\n","\n","Epoch 00406: val_accuracy did not improve from 0.92611\n","Epoch 407/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.5823 - val_accuracy: 0.9015\n","\n","Epoch 00407: val_accuracy did not improve from 0.92611\n","Epoch 408/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5909 - val_accuracy: 0.8990\n","\n","Epoch 00408: val_accuracy did not improve from 0.92611\n","Epoch 409/500\n","52/52 [==============================] - 18s 348ms/step - loss: 7.4598e-04 - accuracy: 1.0000 - val_loss: 0.6543 - val_accuracy: 0.9039\n","\n","Epoch 00409: val_accuracy did not improve from 0.92611\n","Epoch 410/500\n","52/52 [==============================] - 18s 352ms/step - loss: 4.8689e-04 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.8990\n","\n","Epoch 00410: val_accuracy did not improve from 0.92611\n","Epoch 411/500\n","52/52 [==============================] - 18s 348ms/step - loss: 5.8003e-04 - accuracy: 1.0000 - val_loss: 0.5418 - val_accuracy: 0.9163\n","\n","Epoch 00411: val_accuracy did not improve from 0.92611\n","Epoch 412/500\n","52/52 [==============================] - 18s 348ms/step - loss: 4.2392e-04 - accuracy: 1.0000 - val_loss: 0.5968 - val_accuracy: 0.9163\n","\n","Epoch 00412: val_accuracy did not improve from 0.92611\n","Epoch 413/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.7080 - val_accuracy: 0.9064\n","\n","Epoch 00413: val_accuracy did not improve from 0.92611\n","Epoch 414/500\n","52/52 [==============================] - 18s 349ms/step - loss: 6.1795e-04 - accuracy: 1.0000 - val_loss: 0.6023 - val_accuracy: 0.9064\n","\n","Epoch 00414: val_accuracy did not improve from 0.92611\n","Epoch 415/500\n","52/52 [==============================] - 18s 348ms/step - loss: 2.2900e-04 - accuracy: 1.0000 - val_loss: 0.5990 - val_accuracy: 0.9187\n","\n","Epoch 00415: val_accuracy did not improve from 0.92611\n","Epoch 416/500\n","52/52 [==============================] - 18s 347ms/step - loss: 2.2817e-04 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 0.9015\n","\n","Epoch 00416: val_accuracy did not improve from 0.92611\n","Epoch 417/500\n","52/52 [==============================] - 18s 351ms/step - loss: 1.0343e-04 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.9089\n","\n","Epoch 00417: val_accuracy did not improve from 0.92611\n","Epoch 418/500\n","52/52 [==============================] - 18s 349ms/step - loss: 1.5743e-04 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.9212\n","\n","Epoch 00418: val_accuracy did not improve from 0.92611\n","Epoch 419/500\n","52/52 [==============================] - 18s 350ms/step - loss: 2.7806e-04 - accuracy: 1.0000 - val_loss: 0.6299 - val_accuracy: 0.9064\n","\n","Epoch 00419: val_accuracy did not improve from 0.92611\n","Epoch 420/500\n","52/52 [==============================] - 18s 349ms/step - loss: 1.6809e-04 - accuracy: 1.0000 - val_loss: 0.5462 - val_accuracy: 0.9310\n","\n","Epoch 00420: val_accuracy improved from 0.92611 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5\n","Epoch 421/500\n","52/52 [==============================] - 18s 350ms/step - loss: 2.0343e-04 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.9261\n","\n","Epoch 00421: val_accuracy did not improve from 0.93103\n","Epoch 422/500\n","52/52 [==============================] - 18s 350ms/step - loss: 1.8340e-04 - accuracy: 1.0000 - val_loss: 0.5738 - val_accuracy: 0.9089\n","\n","Epoch 00422: val_accuracy did not improve from 0.93103\n","Epoch 423/500\n","52/52 [==============================] - 18s 349ms/step - loss: 6.3738e-05 - accuracy: 1.0000 - val_loss: 0.5336 - val_accuracy: 0.9261\n","\n","Epoch 00423: val_accuracy did not improve from 0.93103\n","Epoch 424/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.6243 - val_accuracy: 0.9187\n","\n","Epoch 00424: val_accuracy did not improve from 0.93103\n","Epoch 425/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 0.6591 - val_accuracy: 0.8966\n","\n","Epoch 00425: val_accuracy did not improve from 0.93103\n","Epoch 426/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0250 - accuracy: 0.9939 - val_loss: 0.8057 - val_accuracy: 0.8695\n","\n","Epoch 00426: val_accuracy did not improve from 0.93103\n","Epoch 427/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.8247 - val_accuracy: 0.8842\n","\n","Epoch 00427: val_accuracy did not improve from 0.93103\n","Epoch 428/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.7263 - val_accuracy: 0.8966\n","\n","Epoch 00428: val_accuracy did not improve from 0.93103\n","Epoch 429/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.7674 - val_accuracy: 0.8941\n","\n","Epoch 00429: val_accuracy did not improve from 0.93103\n","Epoch 430/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.5462 - val_accuracy: 0.9138\n","\n","Epoch 00430: val_accuracy did not improve from 0.93103\n","Epoch 431/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.6268 - val_accuracy: 0.9039\n","\n","Epoch 00431: val_accuracy did not improve from 0.93103\n","Epoch 432/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.9580 - val_accuracy: 0.8768\n","\n","Epoch 00432: val_accuracy did not improve from 0.93103\n","Epoch 433/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0492 - accuracy: 0.9854 - val_loss: 1.0796 - val_accuracy: 0.8621\n","\n","Epoch 00433: val_accuracy did not improve from 0.93103\n","Epoch 434/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0544 - accuracy: 0.9884 - val_loss: 2.6518 - val_accuracy: 0.7808\n","\n","Epoch 00434: val_accuracy did not improve from 0.93103\n","Epoch 435/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0464 - accuracy: 0.9903 - val_loss: 2.2435 - val_accuracy: 0.7931\n","\n","Epoch 00435: val_accuracy did not improve from 0.93103\n","Epoch 436/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0218 - accuracy: 0.9921 - val_loss: 1.2777 - val_accuracy: 0.8448\n","\n","Epoch 00436: val_accuracy did not improve from 0.93103\n","Epoch 437/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.9785 - val_accuracy: 0.8892\n","\n","Epoch 00437: val_accuracy did not improve from 0.93103\n","Epoch 438/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.6936 - val_accuracy: 0.9015\n","\n","Epoch 00438: val_accuracy did not improve from 0.93103\n","Epoch 439/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.6549 - val_accuracy: 0.9212\n","\n","Epoch 00439: val_accuracy did not improve from 0.93103\n","Epoch 440/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.8572 - val_accuracy: 0.8793\n","\n","Epoch 00440: val_accuracy did not improve from 0.93103\n","Epoch 441/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.6366 - val_accuracy: 0.9163\n","\n","Epoch 00441: val_accuracy did not improve from 0.93103\n","Epoch 442/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5702 - val_accuracy: 0.9138\n","\n","Epoch 00442: val_accuracy did not improve from 0.93103\n","Epoch 443/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5722 - val_accuracy: 0.9212\n","\n","Epoch 00443: val_accuracy did not improve from 0.93103\n","Epoch 444/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.7399 - val_accuracy: 0.9113\n","\n","Epoch 00444: val_accuracy did not improve from 0.93103\n","Epoch 445/500\n","52/52 [==============================] - 18s 350ms/step - loss: 9.6755e-04 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.9236\n","\n","Epoch 00445: val_accuracy did not improve from 0.93103\n","Epoch 446/500\n","52/52 [==============================] - 18s 351ms/step - loss: 1.7711e-04 - accuracy: 1.0000 - val_loss: 0.7399 - val_accuracy: 0.9113\n","\n","Epoch 00446: val_accuracy did not improve from 0.93103\n","Epoch 447/500\n","52/52 [==============================] - 18s 348ms/step - loss: 4.6223e-04 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.9187\n","\n","Epoch 00447: val_accuracy did not improve from 0.93103\n","Epoch 448/500\n","52/52 [==============================] - 18s 349ms/step - loss: 1.4245e-04 - accuracy: 1.0000 - val_loss: 0.6007 - val_accuracy: 0.9212\n","\n","Epoch 00448: val_accuracy did not improve from 0.93103\n","Epoch 449/500\n","52/52 [==============================] - 18s 352ms/step - loss: 4.0586e-04 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 0.9113\n","\n","Epoch 00449: val_accuracy did not improve from 0.93103\n","Epoch 450/500\n","52/52 [==============================] - 18s 350ms/step - loss: 2.3740e-04 - accuracy: 1.0000 - val_loss: 0.6910 - val_accuracy: 0.9212\n","\n","Epoch 00450: val_accuracy did not improve from 0.93103\n","Epoch 451/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7414 - val_accuracy: 0.9212\n","\n","Epoch 00451: val_accuracy did not improve from 0.93103\n","Epoch 452/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.6442 - val_accuracy: 0.9163\n","\n","Epoch 00452: val_accuracy did not improve from 0.93103\n","Epoch 453/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0157 - accuracy: 0.9970 - val_loss: 0.6574 - val_accuracy: 0.9064\n","\n","Epoch 00453: val_accuracy did not improve from 0.93103\n","Epoch 454/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.7721 - val_accuracy: 0.9138\n","\n","Epoch 00454: val_accuracy did not improve from 0.93103\n","Epoch 455/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 0.6301 - val_accuracy: 0.9163\n","\n","Epoch 00455: val_accuracy did not improve from 0.93103\n","Epoch 456/500\n","52/52 [==============================] - 18s 349ms/step - loss: 6.8817e-04 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.9015\n","\n","Epoch 00456: val_accuracy did not improve from 0.93103\n","Epoch 457/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.7605 - val_accuracy: 0.9089\n","\n","Epoch 00457: val_accuracy did not improve from 0.93103\n","Epoch 458/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0212 - accuracy: 0.9957 - val_loss: 0.9243 - val_accuracy: 0.8768\n","\n","Epoch 00458: val_accuracy did not improve from 0.93103\n","Epoch 459/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0075 - accuracy: 0.9970 - val_loss: 0.6874 - val_accuracy: 0.9015\n","\n","Epoch 00459: val_accuracy did not improve from 0.93103\n","Epoch 460/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0293 - accuracy: 0.9945 - val_loss: 1.2399 - val_accuracy: 0.8621\n","\n","Epoch 00460: val_accuracy did not improve from 0.93103\n","Epoch 461/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 1.4381 - val_accuracy: 0.8448\n","\n","Epoch 00461: val_accuracy did not improve from 0.93103\n","Epoch 462/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0385 - accuracy: 0.9939 - val_loss: 1.0533 - val_accuracy: 0.8867\n","\n","Epoch 00462: val_accuracy did not improve from 0.93103\n","Epoch 463/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0237 - accuracy: 0.9951 - val_loss: 0.7875 - val_accuracy: 0.8867\n","\n","Epoch 00463: val_accuracy did not improve from 0.93103\n","Epoch 464/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0152 - accuracy: 0.9976 - val_loss: 0.5168 - val_accuracy: 0.9089\n","\n","Epoch 00464: val_accuracy did not improve from 0.93103\n","Epoch 465/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.7057 - val_accuracy: 0.9138\n","\n","Epoch 00465: val_accuracy did not improve from 0.93103\n","Epoch 466/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.5649 - val_accuracy: 0.9138\n","\n","Epoch 00466: val_accuracy did not improve from 0.93103\n","Epoch 467/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.5662 - val_accuracy: 0.9113\n","\n","Epoch 00467: val_accuracy did not improve from 0.93103\n","Epoch 468/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.6791 - val_accuracy: 0.8916\n","\n","Epoch 00468: val_accuracy did not improve from 0.93103\n","Epoch 469/500\n","52/52 [==============================] - 18s 351ms/step - loss: 4.2555e-04 - accuracy: 1.0000 - val_loss: 0.5498 - val_accuracy: 0.9064\n","\n","Epoch 00469: val_accuracy did not improve from 0.93103\n","Epoch 470/500\n","52/52 [==============================] - 18s 350ms/step - loss: 4.3804e-04 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.9187\n","\n","Epoch 00470: val_accuracy did not improve from 0.93103\n","Epoch 471/500\n","52/52 [==============================] - 18s 353ms/step - loss: 3.9332e-04 - accuracy: 1.0000 - val_loss: 0.6363 - val_accuracy: 0.9113\n","\n","Epoch 00471: val_accuracy did not improve from 0.93103\n","Epoch 472/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4883 - val_accuracy: 0.9187\n","\n","Epoch 00472: val_accuracy did not improve from 0.93103\n","Epoch 473/500\n","52/52 [==============================] - 18s 348ms/step - loss: 4.3556e-04 - accuracy: 1.0000 - val_loss: 0.5263 - val_accuracy: 0.9113\n","\n","Epoch 00473: val_accuracy did not improve from 0.93103\n","Epoch 474/500\n","52/52 [==============================] - 18s 351ms/step - loss: 2.8371e-04 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.9310\n","\n","Epoch 00474: val_accuracy did not improve from 0.93103\n","Epoch 475/500\n","52/52 [==============================] - 18s 349ms/step - loss: 9.6419e-04 - accuracy: 0.9994 - val_loss: 0.5846 - val_accuracy: 0.9187\n","\n","Epoch 00475: val_accuracy did not improve from 0.93103\n","Epoch 476/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.6378 - val_accuracy: 0.9064\n","\n","Epoch 00476: val_accuracy did not improve from 0.93103\n","Epoch 477/500\n","52/52 [==============================] - 18s 351ms/step - loss: 9.5845e-04 - accuracy: 1.0000 - val_loss: 0.6963 - val_accuracy: 0.9163\n","\n","Epoch 00477: val_accuracy did not improve from 0.93103\n","Epoch 478/500\n","52/52 [==============================] - 18s 351ms/step - loss: 2.5048e-04 - accuracy: 1.0000 - val_loss: 0.6437 - val_accuracy: 0.9187\n","\n","Epoch 00478: val_accuracy did not improve from 0.93103\n","Epoch 479/500\n","52/52 [==============================] - 18s 351ms/step - loss: 1.7481e-04 - accuracy: 1.0000 - val_loss: 0.6325 - val_accuracy: 0.9236\n","\n","Epoch 00479: val_accuracy did not improve from 0.93103\n","Epoch 480/500\n","52/52 [==============================] - 18s 349ms/step - loss: 9.7611e-04 - accuracy: 0.9994 - val_loss: 0.7254 - val_accuracy: 0.9187\n","\n","Epoch 00480: val_accuracy did not improve from 0.93103\n","Epoch 481/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.8871 - val_accuracy: 0.8867\n","\n","Epoch 00481: val_accuracy did not improve from 0.93103\n","Epoch 482/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0201 - accuracy: 0.9963 - val_loss: 1.4437 - val_accuracy: 0.8498\n","\n","Epoch 00482: val_accuracy did not improve from 0.93103\n","Epoch 483/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 1.0146 - val_accuracy: 0.8695\n","\n","Epoch 00483: val_accuracy did not improve from 0.93103\n","Epoch 484/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 1.1165 - val_accuracy: 0.8670\n","\n","Epoch 00484: val_accuracy did not improve from 0.93103\n","Epoch 485/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0247 - accuracy: 0.9896 - val_loss: 1.0368 - val_accuracy: 0.8818\n","\n","Epoch 00485: val_accuracy did not improve from 0.93103\n","Epoch 486/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 1.2035 - val_accuracy: 0.8695\n","\n","Epoch 00486: val_accuracy did not improve from 0.93103\n","Epoch 487/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 1.1862 - val_accuracy: 0.8842\n","\n","Epoch 00487: val_accuracy did not improve from 0.93103\n","Epoch 488/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0248 - accuracy: 0.9951 - val_loss: 0.9018 - val_accuracy: 0.8892\n","\n","Epoch 00488: val_accuracy did not improve from 0.93103\n","Epoch 489/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0070 - accuracy: 0.9963 - val_loss: 0.8028 - val_accuracy: 0.8867\n","\n","Epoch 00489: val_accuracy did not improve from 0.93103\n","Epoch 490/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.7711 - val_accuracy: 0.9064\n","\n","Epoch 00490: val_accuracy did not improve from 0.93103\n","Epoch 491/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.5891 - val_accuracy: 0.9212\n","\n","Epoch 00491: val_accuracy did not improve from 0.93103\n","Epoch 492/500\n","52/52 [==============================] - 18s 347ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.7358 - val_accuracy: 0.8892\n","\n","Epoch 00492: val_accuracy did not improve from 0.93103\n","Epoch 493/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.7560 - val_accuracy: 0.9039\n","\n","Epoch 00493: val_accuracy did not improve from 0.93103\n","Epoch 494/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.8752 - val_accuracy: 0.9015\n","\n","Epoch 00494: val_accuracy did not improve from 0.93103\n","Epoch 495/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.8619 - val_accuracy: 0.9015\n","\n","Epoch 00495: val_accuracy did not improve from 0.93103\n","Epoch 496/500\n","52/52 [==============================] - 18s 351ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.8016 - val_accuracy: 0.8892\n","\n","Epoch 00496: val_accuracy did not improve from 0.93103\n","Epoch 497/500\n","52/52 [==============================] - 18s 350ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.5869 - val_accuracy: 0.9015\n","\n","Epoch 00497: val_accuracy did not improve from 0.93103\n","Epoch 498/500\n","52/52 [==============================] - 18s 352ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.8636 - val_accuracy: 0.8916\n","\n","Epoch 00498: val_accuracy did not improve from 0.93103\n","Epoch 499/500\n","52/52 [==============================] - 18s 349ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.8416 - val_accuracy: 0.8842\n","\n","Epoch 00499: val_accuracy did not improve from 0.93103\n","Epoch 500/500\n","52/52 [==============================] - 18s 348ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.8240 - val_accuracy: 0.8793\n","\n","Epoch 00500: val_accuracy did not improve from 0.93103\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff550f0f190>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"U46jOdS6DSbn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628175512627,"user_tz":-540,"elapsed":5506576,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"22c316bf-a0fe-4ef1-b156-8129980d744b"},"source":["DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[DenseNet121_checkpoint])\n","# files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["52/52 [==============================] - 24s 261ms/step - loss: 1.9163 - accuracy: 0.3173 - val_loss: 6.7082 - val_accuracy: 0.1010\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 2/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.2636 - accuracy: 0.5725 - val_loss: 8.3082 - val_accuracy: 0.0936\n","\n","Epoch 00002: val_accuracy did not improve from 0.10099\n","Epoch 3/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.9608 - accuracy: 0.6851 - val_loss: 20.9299 - val_accuracy: 0.1010\n","\n","Epoch 00003: val_accuracy did not improve from 0.10099\n","Epoch 4/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.8642 - accuracy: 0.7113 - val_loss: 8.5774 - val_accuracy: 0.1010\n","\n","Epoch 00004: val_accuracy did not improve from 0.10099\n","Epoch 5/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.7024 - accuracy: 0.7698 - val_loss: 10.4198 - val_accuracy: 0.1478\n","\n","Epoch 00005: val_accuracy improved from 0.10099 to 0.14778, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 6/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.6115 - accuracy: 0.7978 - val_loss: 7.3188 - val_accuracy: 0.1404\n","\n","Epoch 00006: val_accuracy did not improve from 0.14778\n","Epoch 7/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.5482 - accuracy: 0.8197 - val_loss: 5.8088 - val_accuracy: 0.2291\n","\n","Epoch 00007: val_accuracy improved from 0.14778 to 0.22906, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 8/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.5727 - accuracy: 0.8082 - val_loss: 3.4725 - val_accuracy: 0.3448\n","\n","Epoch 00008: val_accuracy improved from 0.22906 to 0.34483, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 9/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.5062 - accuracy: 0.8350 - val_loss: 2.5724 - val_accuracy: 0.4310\n","\n","Epoch 00009: val_accuracy improved from 0.34483 to 0.43103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 10/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.4612 - accuracy: 0.8471 - val_loss: 2.8447 - val_accuracy: 0.4507\n","\n","Epoch 00010: val_accuracy improved from 0.43103 to 0.45074, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 11/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.4344 - accuracy: 0.8404 - val_loss: 1.5536 - val_accuracy: 0.6502\n","\n","Epoch 00011: val_accuracy improved from 0.45074 to 0.65025, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 12/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.5768 - accuracy: 0.8197 - val_loss: 3.9985 - val_accuracy: 0.3571\n","\n","Epoch 00012: val_accuracy did not improve from 0.65025\n","Epoch 13/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.4259 - accuracy: 0.8648 - val_loss: 0.8142 - val_accuracy: 0.7537\n","\n","Epoch 00013: val_accuracy improved from 0.65025 to 0.75369, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 14/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.3991 - accuracy: 0.8624 - val_loss: 0.7349 - val_accuracy: 0.7931\n","\n","Epoch 00014: val_accuracy improved from 0.75369 to 0.79310, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 15/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.3739 - accuracy: 0.8770 - val_loss: 1.0368 - val_accuracy: 0.6798\n","\n","Epoch 00015: val_accuracy did not improve from 0.79310\n","Epoch 16/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.4080 - accuracy: 0.8618 - val_loss: 0.7233 - val_accuracy: 0.8128\n","\n","Epoch 00016: val_accuracy improved from 0.79310 to 0.81281, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 17/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.3311 - accuracy: 0.8928 - val_loss: 0.6242 - val_accuracy: 0.7956\n","\n","Epoch 00017: val_accuracy did not improve from 0.81281\n","Epoch 18/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.2858 - accuracy: 0.9019 - val_loss: 0.5176 - val_accuracy: 0.8473\n","\n","Epoch 00018: val_accuracy improved from 0.81281 to 0.84729, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 19/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.2881 - accuracy: 0.9062 - val_loss: 0.7374 - val_accuracy: 0.7660\n","\n","Epoch 00019: val_accuracy did not improve from 0.84729\n","Epoch 20/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.2894 - accuracy: 0.9050 - val_loss: 0.5719 - val_accuracy: 0.8350\n","\n","Epoch 00020: val_accuracy did not improve from 0.84729\n","Epoch 21/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.2993 - accuracy: 0.9056 - val_loss: 0.5817 - val_accuracy: 0.8251\n","\n","Epoch 00021: val_accuracy did not improve from 0.84729\n","Epoch 22/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.2518 - accuracy: 0.9184 - val_loss: 0.5382 - val_accuracy: 0.8399\n","\n","Epoch 00022: val_accuracy did not improve from 0.84729\n","Epoch 23/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.2389 - accuracy: 0.9239 - val_loss: 0.8147 - val_accuracy: 0.7734\n","\n","Epoch 00023: val_accuracy did not improve from 0.84729\n","Epoch 24/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.2177 - accuracy: 0.9263 - val_loss: 0.5005 - val_accuracy: 0.8522\n","\n","Epoch 00024: val_accuracy improved from 0.84729 to 0.85222, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 25/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.2237 - accuracy: 0.9135 - val_loss: 0.6581 - val_accuracy: 0.8054\n","\n","Epoch 00025: val_accuracy did not improve from 0.85222\n","Epoch 26/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1703 - accuracy: 0.9391 - val_loss: 0.4712 - val_accuracy: 0.8818\n","\n","Epoch 00026: val_accuracy improved from 0.85222 to 0.88177, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 27/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1948 - accuracy: 0.9318 - val_loss: 0.4650 - val_accuracy: 0.8670\n","\n","Epoch 00027: val_accuracy did not improve from 0.88177\n","Epoch 28/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.1853 - accuracy: 0.9421 - val_loss: 0.5443 - val_accuracy: 0.8350\n","\n","Epoch 00028: val_accuracy did not improve from 0.88177\n","Epoch 29/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.1832 - accuracy: 0.9342 - val_loss: 0.6475 - val_accuracy: 0.8103\n","\n","Epoch 00029: val_accuracy did not improve from 0.88177\n","Epoch 30/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1566 - accuracy: 0.9476 - val_loss: 1.3347 - val_accuracy: 0.6897\n","\n","Epoch 00030: val_accuracy did not improve from 0.88177\n","Epoch 31/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1983 - accuracy: 0.9287 - val_loss: 1.5943 - val_accuracy: 0.6502\n","\n","Epoch 00031: val_accuracy did not improve from 0.88177\n","Epoch 32/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1722 - accuracy: 0.9409 - val_loss: 0.5897 - val_accuracy: 0.8128\n","\n","Epoch 00032: val_accuracy did not improve from 0.88177\n","Epoch 33/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1349 - accuracy: 0.9555 - val_loss: 0.7339 - val_accuracy: 0.8128\n","\n","Epoch 00033: val_accuracy did not improve from 0.88177\n","Epoch 34/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.1247 - accuracy: 0.9549 - val_loss: 0.7791 - val_accuracy: 0.8103\n","\n","Epoch 00034: val_accuracy did not improve from 0.88177\n","Epoch 35/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1625 - accuracy: 0.9470 - val_loss: 0.5996 - val_accuracy: 0.8374\n","\n","Epoch 00035: val_accuracy did not improve from 0.88177\n","Epoch 36/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.1778 - accuracy: 0.9361 - val_loss: 0.7649 - val_accuracy: 0.8325\n","\n","Epoch 00036: val_accuracy did not improve from 0.88177\n","Epoch 37/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.1803 - accuracy: 0.9385 - val_loss: 0.9317 - val_accuracy: 0.8054\n","\n","Epoch 00037: val_accuracy did not improve from 0.88177\n","Epoch 38/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1676 - accuracy: 0.9476 - val_loss: 0.7561 - val_accuracy: 0.8128\n","\n","Epoch 00038: val_accuracy did not improve from 0.88177\n","Epoch 39/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.1226 - accuracy: 0.9586 - val_loss: 0.7132 - val_accuracy: 0.8399\n","\n","Epoch 00039: val_accuracy did not improve from 0.88177\n","Epoch 40/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1022 - accuracy: 0.9677 - val_loss: 0.5273 - val_accuracy: 0.8547\n","\n","Epoch 00040: val_accuracy did not improve from 0.88177\n","Epoch 41/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0889 - accuracy: 0.9714 - val_loss: 0.5703 - val_accuracy: 0.8424\n","\n","Epoch 00041: val_accuracy did not improve from 0.88177\n","Epoch 42/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.1094 - accuracy: 0.9647 - val_loss: 0.9767 - val_accuracy: 0.7488\n","\n","Epoch 00042: val_accuracy did not improve from 0.88177\n","Epoch 43/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1081 - accuracy: 0.9604 - val_loss: 0.4927 - val_accuracy: 0.8596\n","\n","Epoch 00043: val_accuracy did not improve from 0.88177\n","Epoch 44/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.1213 - accuracy: 0.9598 - val_loss: 0.6767 - val_accuracy: 0.8103\n","\n","Epoch 00044: val_accuracy did not improve from 0.88177\n","Epoch 45/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0747 - accuracy: 0.9732 - val_loss: 0.7056 - val_accuracy: 0.8177\n","\n","Epoch 00045: val_accuracy did not improve from 0.88177\n","Epoch 46/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.1156 - accuracy: 0.9592 - val_loss: 0.5056 - val_accuracy: 0.8670\n","\n","Epoch 00046: val_accuracy did not improve from 0.88177\n","Epoch 47/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0872 - accuracy: 0.9714 - val_loss: 0.5987 - val_accuracy: 0.8374\n","\n","Epoch 00047: val_accuracy did not improve from 0.88177\n","Epoch 48/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0797 - accuracy: 0.9744 - val_loss: 0.6616 - val_accuracy: 0.8251\n","\n","Epoch 00048: val_accuracy did not improve from 0.88177\n","Epoch 49/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0897 - accuracy: 0.9702 - val_loss: 0.4927 - val_accuracy: 0.8695\n","\n","Epoch 00049: val_accuracy did not improve from 0.88177\n","Epoch 50/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.1437 - accuracy: 0.9482 - val_loss: 0.7372 - val_accuracy: 0.8424\n","\n","Epoch 00050: val_accuracy did not improve from 0.88177\n","Epoch 51/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0711 - accuracy: 0.9769 - val_loss: 0.4714 - val_accuracy: 0.8768\n","\n","Epoch 00051: val_accuracy did not improve from 0.88177\n","Epoch 52/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0793 - accuracy: 0.9702 - val_loss: 0.6090 - val_accuracy: 0.8522\n","\n","Epoch 00052: val_accuracy did not improve from 0.88177\n","Epoch 53/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0792 - accuracy: 0.9702 - val_loss: 0.5800 - val_accuracy: 0.8596\n","\n","Epoch 00053: val_accuracy did not improve from 0.88177\n","Epoch 54/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0821 - accuracy: 0.9695 - val_loss: 0.4814 - val_accuracy: 0.8596\n","\n","Epoch 00054: val_accuracy did not improve from 0.88177\n","Epoch 55/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0653 - accuracy: 0.9811 - val_loss: 0.8740 - val_accuracy: 0.8054\n","\n","Epoch 00055: val_accuracy did not improve from 0.88177\n","Epoch 56/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0893 - accuracy: 0.9689 - val_loss: 0.9805 - val_accuracy: 0.7857\n","\n","Epoch 00056: val_accuracy did not improve from 0.88177\n","Epoch 57/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0791 - accuracy: 0.9726 - val_loss: 0.5302 - val_accuracy: 0.8744\n","\n","Epoch 00057: val_accuracy did not improve from 0.88177\n","Epoch 58/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0419 - accuracy: 0.9872 - val_loss: 0.5986 - val_accuracy: 0.8793\n","\n","Epoch 00058: val_accuracy did not improve from 0.88177\n","Epoch 59/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0518 - accuracy: 0.9842 - val_loss: 0.5308 - val_accuracy: 0.8596\n","\n","Epoch 00059: val_accuracy did not improve from 0.88177\n","Epoch 60/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0773 - accuracy: 0.9762 - val_loss: 0.8589 - val_accuracy: 0.8103\n","\n","Epoch 00060: val_accuracy did not improve from 0.88177\n","Epoch 61/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0735 - accuracy: 0.9738 - val_loss: 0.7703 - val_accuracy: 0.8227\n","\n","Epoch 00061: val_accuracy did not improve from 0.88177\n","Epoch 62/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0551 - accuracy: 0.9829 - val_loss: 0.4390 - val_accuracy: 0.8867\n","\n","Epoch 00062: val_accuracy improved from 0.88177 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 63/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0685 - accuracy: 0.9762 - val_loss: 0.8323 - val_accuracy: 0.7833\n","\n","Epoch 00063: val_accuracy did not improve from 0.88670\n","Epoch 64/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0687 - accuracy: 0.9762 - val_loss: 0.6876 - val_accuracy: 0.8571\n","\n","Epoch 00064: val_accuracy did not improve from 0.88670\n","Epoch 65/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0869 - accuracy: 0.9720 - val_loss: 0.7428 - val_accuracy: 0.8596\n","\n","Epoch 00065: val_accuracy did not improve from 0.88670\n","Epoch 66/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0920 - accuracy: 0.9695 - val_loss: 1.3776 - val_accuracy: 0.6552\n","\n","Epoch 00066: val_accuracy did not improve from 0.88670\n","Epoch 67/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0753 - accuracy: 0.9762 - val_loss: 0.8424 - val_accuracy: 0.8103\n","\n","Epoch 00067: val_accuracy did not improve from 0.88670\n","Epoch 68/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0482 - accuracy: 0.9811 - val_loss: 0.4979 - val_accuracy: 0.8892\n","\n","Epoch 00068: val_accuracy improved from 0.88670 to 0.88916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 69/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0610 - accuracy: 0.9811 - val_loss: 2.9305 - val_accuracy: 0.5887\n","\n","Epoch 00069: val_accuracy did not improve from 0.88916\n","Epoch 70/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0736 - accuracy: 0.9720 - val_loss: 0.6267 - val_accuracy: 0.8596\n","\n","Epoch 00070: val_accuracy did not improve from 0.88916\n","Epoch 71/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0380 - accuracy: 0.9890 - val_loss: 0.7043 - val_accuracy: 0.8596\n","\n","Epoch 00071: val_accuracy did not improve from 0.88916\n","Epoch 72/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0695 - accuracy: 0.9769 - val_loss: 0.5612 - val_accuracy: 0.8547\n","\n","Epoch 00072: val_accuracy did not improve from 0.88916\n","Epoch 73/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0806 - accuracy: 0.9744 - val_loss: 0.5511 - val_accuracy: 0.8498\n","\n","Epoch 00073: val_accuracy did not improve from 0.88916\n","Epoch 74/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0560 - accuracy: 0.9762 - val_loss: 0.6983 - val_accuracy: 0.8177\n","\n","Epoch 00074: val_accuracy did not improve from 0.88916\n","Epoch 75/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0306 - accuracy: 0.9909 - val_loss: 0.4193 - val_accuracy: 0.8892\n","\n","Epoch 00075: val_accuracy did not improve from 0.88916\n","Epoch 76/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0386 - accuracy: 0.9860 - val_loss: 0.6614 - val_accuracy: 0.8645\n","\n","Epoch 00076: val_accuracy did not improve from 0.88916\n","Epoch 77/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0569 - accuracy: 0.9878 - val_loss: 1.0804 - val_accuracy: 0.7685\n","\n","Epoch 00077: val_accuracy did not improve from 0.88916\n","Epoch 78/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0618 - accuracy: 0.9811 - val_loss: 0.6490 - val_accuracy: 0.8670\n","\n","Epoch 00078: val_accuracy did not improve from 0.88916\n","Epoch 79/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0564 - accuracy: 0.9793 - val_loss: 0.5130 - val_accuracy: 0.8719\n","\n","Epoch 00079: val_accuracy did not improve from 0.88916\n","Epoch 80/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0822 - accuracy: 0.9702 - val_loss: 0.6241 - val_accuracy: 0.8621\n","\n","Epoch 00080: val_accuracy did not improve from 0.88916\n","Epoch 81/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0730 - accuracy: 0.9708 - val_loss: 0.9348 - val_accuracy: 0.8079\n","\n","Epoch 00081: val_accuracy did not improve from 0.88916\n","Epoch 82/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0480 - accuracy: 0.9823 - val_loss: 0.6676 - val_accuracy: 0.8473\n","\n","Epoch 00082: val_accuracy did not improve from 0.88916\n","Epoch 83/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0251 - accuracy: 0.9927 - val_loss: 0.4113 - val_accuracy: 0.8966\n","\n","Epoch 00083: val_accuracy improved from 0.88916 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 84/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0378 - accuracy: 0.9866 - val_loss: 0.6784 - val_accuracy: 0.8374\n","\n","Epoch 00084: val_accuracy did not improve from 0.89655\n","Epoch 85/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0280 - accuracy: 0.9896 - val_loss: 0.4043 - val_accuracy: 0.8842\n","\n","Epoch 00085: val_accuracy did not improve from 0.89655\n","Epoch 86/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0308 - accuracy: 0.9903 - val_loss: 0.6601 - val_accuracy: 0.8744\n","\n","Epoch 00086: val_accuracy did not improve from 0.89655\n","Epoch 87/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0548 - accuracy: 0.9817 - val_loss: 0.6263 - val_accuracy: 0.8571\n","\n","Epoch 00087: val_accuracy did not improve from 0.89655\n","Epoch 88/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1023 - accuracy: 0.9732 - val_loss: 0.7292 - val_accuracy: 0.8596\n","\n","Epoch 00088: val_accuracy did not improve from 0.89655\n","Epoch 89/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0538 - accuracy: 0.9799 - val_loss: 0.5941 - val_accuracy: 0.8818\n","\n","Epoch 00089: val_accuracy did not improve from 0.89655\n","Epoch 90/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0615 - accuracy: 0.9762 - val_loss: 1.3227 - val_accuracy: 0.7734\n","\n","Epoch 00090: val_accuracy did not improve from 0.89655\n","Epoch 91/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.1048 - accuracy: 0.9635 - val_loss: 0.8591 - val_accuracy: 0.8005\n","\n","Epoch 00091: val_accuracy did not improve from 0.89655\n","Epoch 92/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.1408 - accuracy: 0.9580 - val_loss: 2.2314 - val_accuracy: 0.6552\n","\n","Epoch 00092: val_accuracy did not improve from 0.89655\n","Epoch 93/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0693 - accuracy: 0.9738 - val_loss: 0.5711 - val_accuracy: 0.8793\n","\n","Epoch 00093: val_accuracy did not improve from 0.89655\n","Epoch 94/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0565 - accuracy: 0.9799 - val_loss: 0.4849 - val_accuracy: 0.8867\n","\n","Epoch 00094: val_accuracy did not improve from 0.89655\n","Epoch 95/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0458 - accuracy: 0.9854 - val_loss: 0.3798 - val_accuracy: 0.8990\n","\n","Epoch 00095: val_accuracy improved from 0.89655 to 0.89901, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 96/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.5154 - val_accuracy: 0.8966\n","\n","Epoch 00096: val_accuracy did not improve from 0.89901\n","Epoch 97/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.4472 - val_accuracy: 0.8818\n","\n","Epoch 00097: val_accuracy did not improve from 0.89901\n","Epoch 98/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 0.5583 - val_accuracy: 0.8842\n","\n","Epoch 00098: val_accuracy did not improve from 0.89901\n","Epoch 99/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 0.5032 - val_accuracy: 0.8793\n","\n","Epoch 00099: val_accuracy did not improve from 0.89901\n","Epoch 100/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0522 - accuracy: 0.9836 - val_loss: 0.6083 - val_accuracy: 0.8719\n","\n","Epoch 00100: val_accuracy did not improve from 0.89901\n","Epoch 101/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 0.7518 - val_accuracy: 0.8621\n","\n","Epoch 00101: val_accuracy did not improve from 0.89901\n","Epoch 102/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.4846 - val_accuracy: 0.8966\n","\n","Epoch 00102: val_accuracy did not improve from 0.89901\n","Epoch 103/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.3176 - val_accuracy: 0.9113\n","\n","Epoch 00103: val_accuracy improved from 0.89901 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 104/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0249 - accuracy: 0.9909 - val_loss: 0.3725 - val_accuracy: 0.9064\n","\n","Epoch 00104: val_accuracy did not improve from 0.91133\n","Epoch 105/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0098 - accuracy: 0.9951 - val_loss: 0.4275 - val_accuracy: 0.9089\n","\n","Epoch 00105: val_accuracy did not improve from 0.91133\n","Epoch 106/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.3577 - val_accuracy: 0.9212\n","\n","Epoch 00106: val_accuracy improved from 0.91133 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 107/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.4674 - val_accuracy: 0.9089\n","\n","Epoch 00107: val_accuracy did not improve from 0.92118\n","Epoch 108/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.4424 - val_accuracy: 0.8892\n","\n","Epoch 00108: val_accuracy did not improve from 0.92118\n","Epoch 109/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 0.4777 - val_accuracy: 0.8966\n","\n","Epoch 00109: val_accuracy did not improve from 0.92118\n","Epoch 110/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0334 - accuracy: 0.9903 - val_loss: 0.6044 - val_accuracy: 0.8645\n","\n","Epoch 00110: val_accuracy did not improve from 0.92118\n","Epoch 111/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0454 - accuracy: 0.9854 - val_loss: 0.7929 - val_accuracy: 0.8424\n","\n","Epoch 00111: val_accuracy did not improve from 0.92118\n","Epoch 112/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0362 - accuracy: 0.9872 - val_loss: 0.5956 - val_accuracy: 0.8892\n","\n","Epoch 00112: val_accuracy did not improve from 0.92118\n","Epoch 113/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0303 - accuracy: 0.9884 - val_loss: 0.4064 - val_accuracy: 0.9064\n","\n","Epoch 00113: val_accuracy did not improve from 0.92118\n","Epoch 114/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0293 - accuracy: 0.9884 - val_loss: 0.6560 - val_accuracy: 0.8621\n","\n","Epoch 00114: val_accuracy did not improve from 0.92118\n","Epoch 115/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.4838 - val_accuracy: 0.8793\n","\n","Epoch 00115: val_accuracy did not improve from 0.92118\n","Epoch 116/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0632 - accuracy: 0.9823 - val_loss: 0.8671 - val_accuracy: 0.8177\n","\n","Epoch 00116: val_accuracy did not improve from 0.92118\n","Epoch 117/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0548 - accuracy: 0.9799 - val_loss: 0.5894 - val_accuracy: 0.8744\n","\n","Epoch 00117: val_accuracy did not improve from 0.92118\n","Epoch 118/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0517 - accuracy: 0.9829 - val_loss: 0.6690 - val_accuracy: 0.8621\n","\n","Epoch 00118: val_accuracy did not improve from 0.92118\n","Epoch 119/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0417 - accuracy: 0.9854 - val_loss: 1.2814 - val_accuracy: 0.7660\n","\n","Epoch 00119: val_accuracy did not improve from 0.92118\n","Epoch 120/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0699 - accuracy: 0.9781 - val_loss: 1.0190 - val_accuracy: 0.8030\n","\n","Epoch 00120: val_accuracy did not improve from 0.92118\n","Epoch 121/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0612 - accuracy: 0.9805 - val_loss: 0.7112 - val_accuracy: 0.8547\n","\n","Epoch 00121: val_accuracy did not improve from 0.92118\n","Epoch 122/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0383 - accuracy: 0.9909 - val_loss: 0.7057 - val_accuracy: 0.8350\n","\n","Epoch 00122: val_accuracy did not improve from 0.92118\n","Epoch 123/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0571 - accuracy: 0.9787 - val_loss: 1.1520 - val_accuracy: 0.7857\n","\n","Epoch 00123: val_accuracy did not improve from 0.92118\n","Epoch 124/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0423 - accuracy: 0.9866 - val_loss: 0.5383 - val_accuracy: 0.8695\n","\n","Epoch 00124: val_accuracy did not improve from 0.92118\n","Epoch 125/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0247 - accuracy: 0.9939 - val_loss: 0.4631 - val_accuracy: 0.9015\n","\n","Epoch 00125: val_accuracy did not improve from 0.92118\n","Epoch 126/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.4479 - val_accuracy: 0.8966\n","\n","Epoch 00126: val_accuracy did not improve from 0.92118\n","Epoch 127/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0221 - accuracy: 0.9957 - val_loss: 0.5746 - val_accuracy: 0.8842\n","\n","Epoch 00127: val_accuracy did not improve from 0.92118\n","Epoch 128/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.4915 - val_accuracy: 0.8842\n","\n","Epoch 00128: val_accuracy did not improve from 0.92118\n","Epoch 129/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0274 - accuracy: 0.9927 - val_loss: 0.7169 - val_accuracy: 0.8719\n","\n","Epoch 00129: val_accuracy did not improve from 0.92118\n","Epoch 130/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0750 - accuracy: 0.9775 - val_loss: 0.8135 - val_accuracy: 0.8547\n","\n","Epoch 00130: val_accuracy did not improve from 0.92118\n","Epoch 131/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0547 - accuracy: 0.9848 - val_loss: 0.4759 - val_accuracy: 0.9039\n","\n","Epoch 00131: val_accuracy did not improve from 0.92118\n","Epoch 132/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0283 - accuracy: 0.9909 - val_loss: 0.5597 - val_accuracy: 0.8768\n","\n","Epoch 00132: val_accuracy did not improve from 0.92118\n","Epoch 133/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0257 - accuracy: 0.9909 - val_loss: 0.5679 - val_accuracy: 0.8522\n","\n","Epoch 00133: val_accuracy did not improve from 0.92118\n","Epoch 134/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.4863 - val_accuracy: 0.8818\n","\n","Epoch 00134: val_accuracy did not improve from 0.92118\n","Epoch 135/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.4239 - val_accuracy: 0.9039\n","\n","Epoch 00135: val_accuracy did not improve from 0.92118\n","Epoch 136/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.3713 - val_accuracy: 0.9187\n","\n","Epoch 00136: val_accuracy did not improve from 0.92118\n","Epoch 137/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.3501 - val_accuracy: 0.9212\n","\n","Epoch 00137: val_accuracy did not improve from 0.92118\n","Epoch 138/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0087 - accuracy: 0.9957 - val_loss: 0.4566 - val_accuracy: 0.9064\n","\n","Epoch 00138: val_accuracy did not improve from 0.92118\n","Epoch 139/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4474 - val_accuracy: 0.9113\n","\n","Epoch 00139: val_accuracy did not improve from 0.92118\n","Epoch 140/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.9163\n","\n","Epoch 00140: val_accuracy did not improve from 0.92118\n","Epoch 141/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5426 - val_accuracy: 0.9089\n","\n","Epoch 00141: val_accuracy did not improve from 0.92118\n","Epoch 142/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.4056 - val_accuracy: 0.9113\n","\n","Epoch 00142: val_accuracy did not improve from 0.92118\n","Epoch 143/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9138\n","\n","Epoch 00143: val_accuracy did not improve from 0.92118\n","Epoch 144/500\n","52/52 [==============================] - 11s 204ms/step - loss: 8.9891e-04 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.9138\n","\n","Epoch 00144: val_accuracy did not improve from 0.92118\n","Epoch 145/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4479 - val_accuracy: 0.9138\n","\n","Epoch 00145: val_accuracy did not improve from 0.92118\n","Epoch 146/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.4523 - val_accuracy: 0.9039\n","\n","Epoch 00146: val_accuracy did not improve from 0.92118\n","Epoch 147/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0671 - accuracy: 0.9793 - val_loss: 1.9399 - val_accuracy: 0.7044\n","\n","Epoch 00147: val_accuracy did not improve from 0.92118\n","Epoch 148/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1215 - accuracy: 0.9586 - val_loss: 2.6212 - val_accuracy: 0.6897\n","\n","Epoch 00148: val_accuracy did not improve from 0.92118\n","Epoch 149/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0639 - accuracy: 0.9750 - val_loss: 1.3512 - val_accuracy: 0.7463\n","\n","Epoch 00149: val_accuracy did not improve from 0.92118\n","Epoch 150/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0547 - accuracy: 0.9836 - val_loss: 0.7670 - val_accuracy: 0.8399\n","\n","Epoch 00150: val_accuracy did not improve from 0.92118\n","Epoch 151/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0438 - accuracy: 0.9842 - val_loss: 0.6698 - val_accuracy: 0.8768\n","\n","Epoch 00151: val_accuracy did not improve from 0.92118\n","Epoch 152/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0460 - accuracy: 0.9890 - val_loss: 0.5946 - val_accuracy: 0.8793\n","\n","Epoch 00152: val_accuracy did not improve from 0.92118\n","Epoch 153/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.5384 - val_accuracy: 0.8842\n","\n","Epoch 00153: val_accuracy did not improve from 0.92118\n","Epoch 154/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0223 - accuracy: 0.9909 - val_loss: 0.5486 - val_accuracy: 0.8892\n","\n","Epoch 00154: val_accuracy did not improve from 0.92118\n","Epoch 155/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.6421 - val_accuracy: 0.8719\n","\n","Epoch 00155: val_accuracy did not improve from 0.92118\n","Epoch 156/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0173 - accuracy: 0.9927 - val_loss: 0.7818 - val_accuracy: 0.8424\n","\n","Epoch 00156: val_accuracy did not improve from 0.92118\n","Epoch 157/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1016 - accuracy: 0.9683 - val_loss: 1.0183 - val_accuracy: 0.8276\n","\n","Epoch 00157: val_accuracy did not improve from 0.92118\n","Epoch 158/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0314 - accuracy: 0.9921 - val_loss: 0.4962 - val_accuracy: 0.8966\n","\n","Epoch 00158: val_accuracy did not improve from 0.92118\n","Epoch 159/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0571 - accuracy: 0.9817 - val_loss: 0.8712 - val_accuracy: 0.8399\n","\n","Epoch 00159: val_accuracy did not improve from 0.92118\n","Epoch 160/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.5255 - val_accuracy: 0.8966\n","\n","Epoch 00160: val_accuracy did not improve from 0.92118\n","Epoch 161/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0223 - accuracy: 0.9909 - val_loss: 0.5571 - val_accuracy: 0.8966\n","\n","Epoch 00161: val_accuracy did not improve from 0.92118\n","Epoch 162/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.5931 - val_accuracy: 0.8818\n","\n","Epoch 00162: val_accuracy did not improve from 0.92118\n","Epoch 163/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.6027 - val_accuracy: 0.8818\n","\n","Epoch 00163: val_accuracy did not improve from 0.92118\n","Epoch 164/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.5336 - val_accuracy: 0.8916\n","\n","Epoch 00164: val_accuracy did not improve from 0.92118\n","Epoch 165/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.5137 - val_accuracy: 0.9039\n","\n","Epoch 00165: val_accuracy did not improve from 0.92118\n","Epoch 166/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4974 - val_accuracy: 0.9163\n","\n","Epoch 00166: val_accuracy did not improve from 0.92118\n","Epoch 167/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.4555 - val_accuracy: 0.9015\n","\n","Epoch 00167: val_accuracy did not improve from 0.92118\n","Epoch 168/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0321 - accuracy: 0.9896 - val_loss: 0.5742 - val_accuracy: 0.8768\n","\n","Epoch 00168: val_accuracy did not improve from 0.92118\n","Epoch 169/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.7510 - val_accuracy: 0.8547\n","\n","Epoch 00169: val_accuracy did not improve from 0.92118\n","Epoch 170/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.4216 - val_accuracy: 0.9039\n","\n","Epoch 00170: val_accuracy did not improve from 0.92118\n","Epoch 171/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.7686 - val_accuracy: 0.8744\n","\n","Epoch 00171: val_accuracy did not improve from 0.92118\n","Epoch 172/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.6199 - val_accuracy: 0.8695\n","\n","Epoch 00172: val_accuracy did not improve from 0.92118\n","Epoch 173/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0403 - accuracy: 0.9860 - val_loss: 0.5217 - val_accuracy: 0.8867\n","\n","Epoch 00173: val_accuracy did not improve from 0.92118\n","Epoch 174/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.4183 - val_accuracy: 0.9187\n","\n","Epoch 00174: val_accuracy did not improve from 0.92118\n","Epoch 175/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.4508 - val_accuracy: 0.9113\n","\n","Epoch 00175: val_accuracy did not improve from 0.92118\n","Epoch 176/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.6321 - val_accuracy: 0.8966\n","\n","Epoch 00176: val_accuracy did not improve from 0.92118\n","Epoch 177/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.5328 - val_accuracy: 0.8719\n","\n","Epoch 00177: val_accuracy did not improve from 0.92118\n","Epoch 178/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.7848 - val_accuracy: 0.8744\n","\n","Epoch 00178: val_accuracy did not improve from 0.92118\n","Epoch 179/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0750 - accuracy: 0.9829 - val_loss: 0.7316 - val_accuracy: 0.8645\n","\n","Epoch 00179: val_accuracy did not improve from 0.92118\n","Epoch 180/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0292 - accuracy: 0.9884 - val_loss: 0.9115 - val_accuracy: 0.8522\n","\n","Epoch 00180: val_accuracy did not improve from 0.92118\n","Epoch 181/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.7082 - val_accuracy: 0.8867\n","\n","Epoch 00181: val_accuracy did not improve from 0.92118\n","Epoch 182/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0718 - accuracy: 0.9762 - val_loss: 1.1017 - val_accuracy: 0.8030\n","\n","Epoch 00182: val_accuracy did not improve from 0.92118\n","Epoch 183/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0366 - accuracy: 0.9903 - val_loss: 0.5919 - val_accuracy: 0.8892\n","\n","Epoch 00183: val_accuracy did not improve from 0.92118\n","Epoch 184/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0155 - accuracy: 0.9939 - val_loss: 0.5906 - val_accuracy: 0.8818\n","\n","Epoch 00184: val_accuracy did not improve from 0.92118\n","Epoch 185/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.4718 - val_accuracy: 0.8916\n","\n","Epoch 00185: val_accuracy did not improve from 0.92118\n","Epoch 186/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4123 - val_accuracy: 0.9187\n","\n","Epoch 00186: val_accuracy did not improve from 0.92118\n","Epoch 187/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.4147 - val_accuracy: 0.9064\n","\n","Epoch 00187: val_accuracy did not improve from 0.92118\n","Epoch 188/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.4636 - val_accuracy: 0.8916\n","\n","Epoch 00188: val_accuracy did not improve from 0.92118\n","Epoch 189/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.8589 - val_accuracy: 0.8473\n","\n","Epoch 00189: val_accuracy did not improve from 0.92118\n","Epoch 190/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0235 - accuracy: 0.9909 - val_loss: 0.7341 - val_accuracy: 0.8571\n","\n","Epoch 00190: val_accuracy did not improve from 0.92118\n","Epoch 191/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0248 - accuracy: 0.9945 - val_loss: 0.6862 - val_accuracy: 0.8744\n","\n","Epoch 00191: val_accuracy did not improve from 0.92118\n","Epoch 192/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0323 - accuracy: 0.9884 - val_loss: 0.5897 - val_accuracy: 0.8547\n","\n","Epoch 00192: val_accuracy did not improve from 0.92118\n","Epoch 193/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.5301 - val_accuracy: 0.9015\n","\n","Epoch 00193: val_accuracy did not improve from 0.92118\n","Epoch 194/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0327 - accuracy: 0.9903 - val_loss: 0.8660 - val_accuracy: 0.8522\n","\n","Epoch 00194: val_accuracy did not improve from 0.92118\n","Epoch 195/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0444 - accuracy: 0.9878 - val_loss: 0.5442 - val_accuracy: 0.8695\n","\n","Epoch 00195: val_accuracy did not improve from 0.92118\n","Epoch 196/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.5680 - val_accuracy: 0.8768\n","\n","Epoch 00196: val_accuracy did not improve from 0.92118\n","Epoch 197/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0171 - accuracy: 0.9933 - val_loss: 0.6846 - val_accuracy: 0.8842\n","\n","Epoch 00197: val_accuracy did not improve from 0.92118\n","Epoch 198/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.8589 - val_accuracy: 0.8842\n","\n","Epoch 00198: val_accuracy did not improve from 0.92118\n","Epoch 199/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.4305 - val_accuracy: 0.9039\n","\n","Epoch 00199: val_accuracy did not improve from 0.92118\n","Epoch 200/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5127 - val_accuracy: 0.8916\n","\n","Epoch 00200: val_accuracy did not improve from 0.92118\n","Epoch 201/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.5403 - val_accuracy: 0.8941\n","\n","Epoch 00201: val_accuracy did not improve from 0.92118\n","Epoch 202/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.4284 - val_accuracy: 0.9236\n","\n","Epoch 00202: val_accuracy improved from 0.92118 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 203/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0414 - accuracy: 0.9878 - val_loss: 0.8270 - val_accuracy: 0.8399\n","\n","Epoch 00203: val_accuracy did not improve from 0.92365\n","Epoch 204/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0362 - accuracy: 0.9866 - val_loss: 0.9648 - val_accuracy: 0.8399\n","\n","Epoch 00204: val_accuracy did not improve from 0.92365\n","Epoch 205/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0322 - accuracy: 0.9903 - val_loss: 0.5601 - val_accuracy: 0.8867\n","\n","Epoch 00205: val_accuracy did not improve from 0.92365\n","Epoch 206/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0526 - accuracy: 0.9836 - val_loss: 0.6571 - val_accuracy: 0.8867\n","\n","Epoch 00206: val_accuracy did not improve from 0.92365\n","Epoch 207/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0330 - accuracy: 0.9896 - val_loss: 0.5734 - val_accuracy: 0.8916\n","\n","Epoch 00207: val_accuracy did not improve from 0.92365\n","Epoch 208/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.5241 - val_accuracy: 0.8966\n","\n","Epoch 00208: val_accuracy did not improve from 0.92365\n","Epoch 209/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.4856 - val_accuracy: 0.9015\n","\n","Epoch 00209: val_accuracy did not improve from 0.92365\n","Epoch 210/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.4617 - val_accuracy: 0.9064\n","\n","Epoch 00210: val_accuracy did not improve from 0.92365\n","Epoch 211/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.9138\n","\n","Epoch 00211: val_accuracy did not improve from 0.92365\n","Epoch 212/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.9064\n","\n","Epoch 00212: val_accuracy did not improve from 0.92365\n","Epoch 213/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3760 - val_accuracy: 0.9286\n","\n","Epoch 00213: val_accuracy improved from 0.92365 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 214/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.9212\n","\n","Epoch 00214: val_accuracy did not improve from 0.92857\n","Epoch 215/500\n","52/52 [==============================] - 11s 207ms/step - loss: 6.4089e-04 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.9138\n","\n","Epoch 00215: val_accuracy did not improve from 0.92857\n","Epoch 216/500\n","52/52 [==============================] - 11s 207ms/step - loss: 7.2993e-04 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9261\n","\n","Epoch 00216: val_accuracy did not improve from 0.92857\n","Epoch 217/500\n","52/52 [==============================] - 11s 204ms/step - loss: 4.0173e-04 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.9286\n","\n","Epoch 00217: val_accuracy did not improve from 0.92857\n","Epoch 218/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.9131e-04 - accuracy: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.9360\n","\n","Epoch 00218: val_accuracy improved from 0.92857 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 219/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.7159e-04 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9138\n","\n","Epoch 00219: val_accuracy did not improve from 0.93596\n","Epoch 220/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.6336 - val_accuracy: 0.8744\n","\n","Epoch 00220: val_accuracy did not improve from 0.93596\n","Epoch 221/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0138 - accuracy: 0.9933 - val_loss: 0.6850 - val_accuracy: 0.8670\n","\n","Epoch 00221: val_accuracy did not improve from 0.93596\n","Epoch 222/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.6003 - val_accuracy: 0.8670\n","\n","Epoch 00222: val_accuracy did not improve from 0.93596\n","Epoch 223/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0469 - accuracy: 0.9890 - val_loss: 1.6031 - val_accuracy: 0.8153\n","\n","Epoch 00223: val_accuracy did not improve from 0.93596\n","Epoch 224/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0551 - accuracy: 0.9823 - val_loss: 0.8713 - val_accuracy: 0.8744\n","\n","Epoch 00224: val_accuracy did not improve from 0.93596\n","Epoch 225/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0626 - accuracy: 0.9866 - val_loss: 0.5904 - val_accuracy: 0.8768\n","\n","Epoch 00225: val_accuracy did not improve from 0.93596\n","Epoch 226/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.4819 - val_accuracy: 0.9039\n","\n","Epoch 00226: val_accuracy did not improve from 0.93596\n","Epoch 227/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.4825 - val_accuracy: 0.9138\n","\n","Epoch 00227: val_accuracy did not improve from 0.93596\n","Epoch 228/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.3623 - val_accuracy: 0.9236\n","\n","Epoch 00228: val_accuracy did not improve from 0.93596\n","Epoch 229/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.4301 - val_accuracy: 0.9163\n","\n","Epoch 00229: val_accuracy did not improve from 0.93596\n","Epoch 230/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.3637 - val_accuracy: 0.9187\n","\n","Epoch 00230: val_accuracy did not improve from 0.93596\n","Epoch 231/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.3464 - val_accuracy: 0.9187\n","\n","Epoch 00231: val_accuracy did not improve from 0.93596\n","Epoch 232/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0802 - accuracy: 0.9762 - val_loss: 2.8244 - val_accuracy: 0.6946\n","\n","Epoch 00232: val_accuracy did not improve from 0.93596\n","Epoch 233/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0445 - accuracy: 0.9854 - val_loss: 0.5678 - val_accuracy: 0.8892\n","\n","Epoch 00233: val_accuracy did not improve from 0.93596\n","Epoch 234/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.4935 - val_accuracy: 0.8744\n","\n","Epoch 00234: val_accuracy did not improve from 0.93596\n","Epoch 235/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.5877 - val_accuracy: 0.8842\n","\n","Epoch 00235: val_accuracy did not improve from 0.93596\n","Epoch 236/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5125 - val_accuracy: 0.8990\n","\n","Epoch 00236: val_accuracy did not improve from 0.93596\n","Epoch 237/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.8990\n","\n","Epoch 00237: val_accuracy did not improve from 0.93596\n","Epoch 238/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.4527 - val_accuracy: 0.9064\n","\n","Epoch 00238: val_accuracy did not improve from 0.93596\n","Epoch 239/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.4879 - val_accuracy: 0.9064\n","\n","Epoch 00239: val_accuracy did not improve from 0.93596\n","Epoch 240/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.7230 - val_accuracy: 0.8744\n","\n","Epoch 00240: val_accuracy did not improve from 0.93596\n","Epoch 241/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.6073 - val_accuracy: 0.8916\n","\n","Epoch 00241: val_accuracy did not improve from 0.93596\n","Epoch 242/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.5957 - val_accuracy: 0.8892\n","\n","Epoch 00242: val_accuracy did not improve from 0.93596\n","Epoch 243/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4270 - val_accuracy: 0.9163\n","\n","Epoch 00243: val_accuracy did not improve from 0.93596\n","Epoch 244/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 0.6601 - val_accuracy: 0.8941\n","\n","Epoch 00244: val_accuracy did not improve from 0.93596\n","Epoch 245/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0167 - accuracy: 0.9933 - val_loss: 0.7198 - val_accuracy: 0.8768\n","\n","Epoch 00245: val_accuracy did not improve from 0.93596\n","Epoch 246/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0323 - accuracy: 0.9878 - val_loss: 0.6025 - val_accuracy: 0.8818\n","\n","Epoch 00246: val_accuracy did not improve from 0.93596\n","Epoch 247/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0161 - accuracy: 0.9933 - val_loss: 0.6394 - val_accuracy: 0.8966\n","\n","Epoch 00247: val_accuracy did not improve from 0.93596\n","Epoch 248/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 0.6092 - val_accuracy: 0.8966\n","\n","Epoch 00248: val_accuracy did not improve from 0.93596\n","Epoch 249/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5555 - val_accuracy: 0.8941\n","\n","Epoch 00249: val_accuracy did not improve from 0.93596\n","Epoch 250/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4431 - val_accuracy: 0.9163\n","\n","Epoch 00250: val_accuracy did not improve from 0.93596\n","Epoch 251/500\n","52/52 [==============================] - 11s 205ms/step - loss: 8.3708e-04 - accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.9064\n","\n","Epoch 00251: val_accuracy did not improve from 0.93596\n","Epoch 252/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 1.0063 - val_accuracy: 0.8522\n","\n","Epoch 00252: val_accuracy did not improve from 0.93596\n","Epoch 253/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0525 - accuracy: 0.9823 - val_loss: 0.6212 - val_accuracy: 0.8621\n","\n","Epoch 00253: val_accuracy did not improve from 0.93596\n","Epoch 254/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.8466 - val_accuracy: 0.8325\n","\n","Epoch 00254: val_accuracy did not improve from 0.93596\n","Epoch 255/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0637 - accuracy: 0.9817 - val_loss: 1.0372 - val_accuracy: 0.8103\n","\n","Epoch 00255: val_accuracy did not improve from 0.93596\n","Epoch 256/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0339 - accuracy: 0.9915 - val_loss: 0.5920 - val_accuracy: 0.8916\n","\n","Epoch 00256: val_accuracy did not improve from 0.93596\n","Epoch 257/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0308 - accuracy: 0.9903 - val_loss: 0.5118 - val_accuracy: 0.8916\n","\n","Epoch 00257: val_accuracy did not improve from 0.93596\n","Epoch 258/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0210 - accuracy: 0.9909 - val_loss: 0.3797 - val_accuracy: 0.9089\n","\n","Epoch 00258: val_accuracy did not improve from 0.93596\n","Epoch 259/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0175 - accuracy: 0.9915 - val_loss: 0.5196 - val_accuracy: 0.8892\n","\n","Epoch 00259: val_accuracy did not improve from 0.93596\n","Epoch 260/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.4740 - val_accuracy: 0.8990\n","\n","Epoch 00260: val_accuracy did not improve from 0.93596\n","Epoch 261/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.9187\n","\n","Epoch 00261: val_accuracy did not improve from 0.93596\n","Epoch 262/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.3788 - val_accuracy: 0.9360\n","\n","Epoch 00262: val_accuracy did not improve from 0.93596\n","Epoch 263/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4201 - val_accuracy: 0.9163\n","\n","Epoch 00263: val_accuracy did not improve from 0.93596\n","Epoch 264/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.4938 - val_accuracy: 0.8990\n","\n","Epoch 00264: val_accuracy did not improve from 0.93596\n","Epoch 265/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5206 - val_accuracy: 0.9089\n","\n","Epoch 00265: val_accuracy did not improve from 0.93596\n","Epoch 266/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4798 - val_accuracy: 0.9064\n","\n","Epoch 00266: val_accuracy did not improve from 0.93596\n","Epoch 267/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 0.6774 - val_accuracy: 0.8916\n","\n","Epoch 00267: val_accuracy did not improve from 0.93596\n","Epoch 268/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0268 - accuracy: 0.9896 - val_loss: 0.8509 - val_accuracy: 0.8571\n","\n","Epoch 00268: val_accuracy did not improve from 0.93596\n","Epoch 269/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0269 - accuracy: 0.9890 - val_loss: 0.7063 - val_accuracy: 0.8719\n","\n","Epoch 00269: val_accuracy did not improve from 0.93596\n","Epoch 270/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.4681 - val_accuracy: 0.9163\n","\n","Epoch 00270: val_accuracy did not improve from 0.93596\n","Epoch 271/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4229 - val_accuracy: 0.8966\n","\n","Epoch 00271: val_accuracy did not improve from 0.93596\n","Epoch 272/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0140 - accuracy: 0.9970 - val_loss: 0.5455 - val_accuracy: 0.8793\n","\n","Epoch 00272: val_accuracy did not improve from 0.93596\n","Epoch 273/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.4803 - val_accuracy: 0.9089\n","\n","Epoch 00273: val_accuracy did not improve from 0.93596\n","Epoch 274/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4221 - val_accuracy: 0.9212\n","\n","Epoch 00274: val_accuracy did not improve from 0.93596\n","Epoch 275/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.5076 - val_accuracy: 0.9039\n","\n","Epoch 00275: val_accuracy did not improve from 0.93596\n","Epoch 276/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0188 - accuracy: 0.9921 - val_loss: 0.5737 - val_accuracy: 0.9163\n","\n","Epoch 00276: val_accuracy did not improve from 0.93596\n","Epoch 277/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0660 - accuracy: 0.9848 - val_loss: 0.8225 - val_accuracy: 0.8424\n","\n","Epoch 00277: val_accuracy did not improve from 0.93596\n","Epoch 278/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0244 - accuracy: 0.9896 - val_loss: 0.7634 - val_accuracy: 0.8596\n","\n","Epoch 00278: val_accuracy did not improve from 0.93596\n","Epoch 279/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.4604 - val_accuracy: 0.9236\n","\n","Epoch 00279: val_accuracy did not improve from 0.93596\n","Epoch 280/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4478 - val_accuracy: 0.9163\n","\n","Epoch 00280: val_accuracy did not improve from 0.93596\n","Epoch 281/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.9138\n","\n","Epoch 00281: val_accuracy did not improve from 0.93596\n","Epoch 282/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.5318 - val_accuracy: 0.9212\n","\n","Epoch 00282: val_accuracy did not improve from 0.93596\n","Epoch 283/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.5501 - val_accuracy: 0.9064\n","\n","Epoch 00283: val_accuracy did not improve from 0.93596\n","Epoch 284/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.4086 - val_accuracy: 0.9261\n","\n","Epoch 00284: val_accuracy did not improve from 0.93596\n","Epoch 285/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5519 - val_accuracy: 0.9113\n","\n","Epoch 00285: val_accuracy did not improve from 0.93596\n","Epoch 286/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4505 - val_accuracy: 0.9212\n","\n","Epoch 00286: val_accuracy did not improve from 0.93596\n","Epoch 287/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0075 - accuracy: 0.9970 - val_loss: 0.5128 - val_accuracy: 0.8966\n","\n","Epoch 00287: val_accuracy did not improve from 0.93596\n","Epoch 288/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4481 - val_accuracy: 0.9163\n","\n","Epoch 00288: val_accuracy did not improve from 0.93596\n","Epoch 289/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4722 - val_accuracy: 0.9163\n","\n","Epoch 00289: val_accuracy did not improve from 0.93596\n","Epoch 290/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5532 - val_accuracy: 0.9113\n","\n","Epoch 00290: val_accuracy did not improve from 0.93596\n","Epoch 291/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5308 - val_accuracy: 0.8966\n","\n","Epoch 00291: val_accuracy did not improve from 0.93596\n","Epoch 292/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5202 - val_accuracy: 0.9138\n","\n","Epoch 00292: val_accuracy did not improve from 0.93596\n","Epoch 293/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 1.1519 - val_accuracy: 0.8350\n","\n","Epoch 00293: val_accuracy did not improve from 0.93596\n","Epoch 294/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0425 - accuracy: 0.9872 - val_loss: 0.6811 - val_accuracy: 0.8818\n","\n","Epoch 00294: val_accuracy did not improve from 0.93596\n","Epoch 295/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.1080 - accuracy: 0.9671 - val_loss: 1.3457 - val_accuracy: 0.7463\n","\n","Epoch 00295: val_accuracy did not improve from 0.93596\n","Epoch 296/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0360 - accuracy: 0.9909 - val_loss: 0.5723 - val_accuracy: 0.8941\n","\n","Epoch 00296: val_accuracy did not improve from 0.93596\n","Epoch 297/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0180 - accuracy: 0.9921 - val_loss: 0.6247 - val_accuracy: 0.8916\n","\n","Epoch 00297: val_accuracy did not improve from 0.93596\n","Epoch 298/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.6597 - val_accuracy: 0.8621\n","\n","Epoch 00298: val_accuracy did not improve from 0.93596\n","Epoch 299/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5948 - val_accuracy: 0.8768\n","\n","Epoch 00299: val_accuracy did not improve from 0.93596\n","Epoch 300/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.5233 - val_accuracy: 0.8768\n","\n","Epoch 00300: val_accuracy did not improve from 0.93596\n","Epoch 301/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.5933 - val_accuracy: 0.8941\n","\n","Epoch 00301: val_accuracy did not improve from 0.93596\n","Epoch 302/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.6425 - val_accuracy: 0.8867\n","\n","Epoch 00302: val_accuracy did not improve from 0.93596\n","Epoch 303/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5861 - val_accuracy: 0.8990\n","\n","Epoch 00303: val_accuracy did not improve from 0.93596\n","Epoch 304/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0050 - accuracy: 0.9970 - val_loss: 0.5674 - val_accuracy: 0.9064\n","\n","Epoch 00304: val_accuracy did not improve from 0.93596\n","Epoch 305/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.6401 - val_accuracy: 0.8892\n","\n","Epoch 00305: val_accuracy did not improve from 0.93596\n","Epoch 306/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.6534 - val_accuracy: 0.8867\n","\n","Epoch 00306: val_accuracy did not improve from 0.93596\n","Epoch 307/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.6766 - val_accuracy: 0.8990\n","\n","Epoch 00307: val_accuracy did not improve from 0.93596\n","Epoch 308/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0540 - accuracy: 0.9817 - val_loss: 0.9846 - val_accuracy: 0.8768\n","\n","Epoch 00308: val_accuracy did not improve from 0.93596\n","Epoch 309/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.7597 - val_accuracy: 0.8966\n","\n","Epoch 00309: val_accuracy did not improve from 0.93596\n","Epoch 310/500\n","52/52 [==============================] - 11s 210ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.6170 - val_accuracy: 0.9064\n","\n","Epoch 00310: val_accuracy did not improve from 0.93596\n","Epoch 311/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5814 - val_accuracy: 0.8916\n","\n","Epoch 00311: val_accuracy did not improve from 0.93596\n","Epoch 312/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.5797 - val_accuracy: 0.8941\n","\n","Epoch 00312: val_accuracy did not improve from 0.93596\n","Epoch 313/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.7760 - val_accuracy: 0.8842\n","\n","Epoch 00313: val_accuracy did not improve from 0.93596\n","Epoch 314/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6396 - val_accuracy: 0.8990\n","\n","Epoch 00314: val_accuracy did not improve from 0.93596\n","Epoch 315/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.8966\n","\n","Epoch 00315: val_accuracy did not improve from 0.93596\n","Epoch 316/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5813 - val_accuracy: 0.8892\n","\n","Epoch 00316: val_accuracy did not improve from 0.93596\n","Epoch 317/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 0.5176 - val_accuracy: 0.9064\n","\n","Epoch 00317: val_accuracy did not improve from 0.93596\n","Epoch 318/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0123 - accuracy: 0.9994 - val_loss: 0.6902 - val_accuracy: 0.8966\n","\n","Epoch 00318: val_accuracy did not improve from 0.93596\n","Epoch 319/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.6419 - val_accuracy: 0.8966\n","\n","Epoch 00319: val_accuracy did not improve from 0.93596\n","Epoch 320/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0090 - accuracy: 0.9957 - val_loss: 0.5919 - val_accuracy: 0.8966\n","\n","Epoch 00320: val_accuracy did not improve from 0.93596\n","Epoch 321/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.5826 - val_accuracy: 0.8842\n","\n","Epoch 00321: val_accuracy did not improve from 0.93596\n","Epoch 322/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.5971 - val_accuracy: 0.8892\n","\n","Epoch 00322: val_accuracy did not improve from 0.93596\n","Epoch 323/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0232 - accuracy: 0.9939 - val_loss: 0.6223 - val_accuracy: 0.8916\n","\n","Epoch 00323: val_accuracy did not improve from 0.93596\n","Epoch 324/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0280 - accuracy: 0.9927 - val_loss: 0.8250 - val_accuracy: 0.8892\n","\n","Epoch 00324: val_accuracy did not improve from 0.93596\n","Epoch 325/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.7588 - val_accuracy: 0.8892\n","\n","Epoch 00325: val_accuracy did not improve from 0.93596\n","Epoch 326/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.5973 - val_accuracy: 0.8892\n","\n","Epoch 00326: val_accuracy did not improve from 0.93596\n","Epoch 327/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0467 - accuracy: 0.9896 - val_loss: 0.8578 - val_accuracy: 0.8744\n","\n","Epoch 00327: val_accuracy did not improve from 0.93596\n","Epoch 328/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.4894 - val_accuracy: 0.8941\n","\n","Epoch 00328: val_accuracy did not improve from 0.93596\n","Epoch 329/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 0.5386 - val_accuracy: 0.8966\n","\n","Epoch 00329: val_accuracy did not improve from 0.93596\n","Epoch 330/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.4860 - val_accuracy: 0.9039\n","\n","Epoch 00330: val_accuracy did not improve from 0.93596\n","Epoch 331/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.4849 - val_accuracy: 0.9113\n","\n","Epoch 00331: val_accuracy did not improve from 0.93596\n","Epoch 332/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.4854 - val_accuracy: 0.8966\n","\n","Epoch 00332: val_accuracy did not improve from 0.93596\n","Epoch 333/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 1.2934 - val_accuracy: 0.7882\n","\n","Epoch 00333: val_accuracy did not improve from 0.93596\n","Epoch 334/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0169 - accuracy: 0.9927 - val_loss: 0.5497 - val_accuracy: 0.8867\n","\n","Epoch 00334: val_accuracy did not improve from 0.93596\n","Epoch 335/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.5411 - val_accuracy: 0.9089\n","\n","Epoch 00335: val_accuracy did not improve from 0.93596\n","Epoch 336/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5401 - val_accuracy: 0.8990\n","\n","Epoch 00336: val_accuracy did not improve from 0.93596\n","Epoch 337/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.4545 - val_accuracy: 0.9064\n","\n","Epoch 00337: val_accuracy did not improve from 0.93596\n","Epoch 338/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.4932 - val_accuracy: 0.9039\n","\n","Epoch 00338: val_accuracy did not improve from 0.93596\n","Epoch 339/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9187\n","\n","Epoch 00339: val_accuracy did not improve from 0.93596\n","Epoch 340/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.7080e-04 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.9089\n","\n","Epoch 00340: val_accuracy did not improve from 0.93596\n","Epoch 341/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.4280e-04 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.9089\n","\n","Epoch 00341: val_accuracy did not improve from 0.93596\n","Epoch 342/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.9138\n","\n","Epoch 00342: val_accuracy did not improve from 0.93596\n","Epoch 343/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.6874e-04 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.9039\n","\n","Epoch 00343: val_accuracy did not improve from 0.93596\n","Epoch 344/500\n","52/52 [==============================] - 11s 208ms/step - loss: 8.2116e-04 - accuracy: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.9261\n","\n","Epoch 00344: val_accuracy did not improve from 0.93596\n","Epoch 345/500\n","52/52 [==============================] - 11s 204ms/step - loss: 2.1382e-04 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9310\n","\n","Epoch 00345: val_accuracy did not improve from 0.93596\n","Epoch 346/500\n","52/52 [==============================] - 11s 208ms/step - loss: 4.4800e-04 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.9261\n","\n","Epoch 00346: val_accuracy did not improve from 0.93596\n","Epoch 347/500\n","52/52 [==============================] - 11s 204ms/step - loss: 6.8834e-04 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.9384\n","\n","Epoch 00347: val_accuracy improved from 0.93596 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5\n","Epoch 348/500\n","52/52 [==============================] - 11s 207ms/step - loss: 2.4316e-04 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9236\n","\n","Epoch 00348: val_accuracy did not improve from 0.93842\n","Epoch 349/500\n","52/52 [==============================] - 11s 208ms/step - loss: 3.9134e-04 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.9187\n","\n","Epoch 00349: val_accuracy did not improve from 0.93842\n","Epoch 350/500\n","52/52 [==============================] - 11s 207ms/step - loss: 1.0485e-04 - accuracy: 1.0000 - val_loss: 0.4199 - val_accuracy: 0.9335\n","\n","Epoch 00350: val_accuracy did not improve from 0.93842\n","Epoch 351/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 0.4318 - val_accuracy: 0.9261\n","\n","Epoch 00351: val_accuracy did not improve from 0.93842\n","Epoch 352/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.5190 - val_accuracy: 0.9113\n","\n","Epoch 00352: val_accuracy did not improve from 0.93842\n","Epoch 353/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.5168 - val_accuracy: 0.8966\n","\n","Epoch 00353: val_accuracy did not improve from 0.93842\n","Epoch 354/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5487 - val_accuracy: 0.8990\n","\n","Epoch 00354: val_accuracy did not improve from 0.93842\n","Epoch 355/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 1.0748 - val_accuracy: 0.8571\n","\n","Epoch 00355: val_accuracy did not improve from 0.93842\n","Epoch 356/500\n","52/52 [==============================] - 11s 210ms/step - loss: 0.0334 - accuracy: 0.9903 - val_loss: 0.6531 - val_accuracy: 0.8966\n","\n","Epoch 00356: val_accuracy did not improve from 0.93842\n","Epoch 357/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0341 - accuracy: 0.9854 - val_loss: 0.8061 - val_accuracy: 0.8522\n","\n","Epoch 00357: val_accuracy did not improve from 0.93842\n","Epoch 358/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0480 - accuracy: 0.9854 - val_loss: 1.0640 - val_accuracy: 0.8276\n","\n","Epoch 00358: val_accuracy did not improve from 0.93842\n","Epoch 359/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.6932 - val_accuracy: 0.8645\n","\n","Epoch 00359: val_accuracy did not improve from 0.93842\n","Epoch 360/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0204 - accuracy: 0.9921 - val_loss: 0.8095 - val_accuracy: 0.8251\n","\n","Epoch 00360: val_accuracy did not improve from 0.93842\n","Epoch 361/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.6031 - val_accuracy: 0.8695\n","\n","Epoch 00361: val_accuracy did not improve from 0.93842\n","Epoch 362/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0129 - accuracy: 0.9945 - val_loss: 0.6163 - val_accuracy: 0.8916\n","\n","Epoch 00362: val_accuracy did not improve from 0.93842\n","Epoch 363/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.9617 - val_accuracy: 0.7906\n","\n","Epoch 00363: val_accuracy did not improve from 0.93842\n","Epoch 364/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0260 - accuracy: 0.9933 - val_loss: 0.8303 - val_accuracy: 0.8645\n","\n","Epoch 00364: val_accuracy did not improve from 0.93842\n","Epoch 365/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.6625 - val_accuracy: 0.8892\n","\n","Epoch 00365: val_accuracy did not improve from 0.93842\n","Epoch 366/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.5511 - val_accuracy: 0.8892\n","\n","Epoch 00366: val_accuracy did not improve from 0.93842\n","Epoch 367/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0227 - accuracy: 0.9951 - val_loss: 0.6658 - val_accuracy: 0.8867\n","\n","Epoch 00367: val_accuracy did not improve from 0.93842\n","Epoch 368/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.6378 - val_accuracy: 0.8842\n","\n","Epoch 00368: val_accuracy did not improve from 0.93842\n","Epoch 369/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5412 - val_accuracy: 0.9015\n","\n","Epoch 00369: val_accuracy did not improve from 0.93842\n","Epoch 370/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4323 - val_accuracy: 0.9187\n","\n","Epoch 00370: val_accuracy did not improve from 0.93842\n","Epoch 371/500\n","52/52 [==============================] - 11s 208ms/step - loss: 7.2007e-04 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.9163\n","\n","Epoch 00371: val_accuracy did not improve from 0.93842\n","Epoch 372/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.9236\n","\n","Epoch 00372: val_accuracy did not improve from 0.93842\n","Epoch 373/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.3733e-04 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9261\n","\n","Epoch 00373: val_accuracy did not improve from 0.93842\n","Epoch 374/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.8843e-04 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9187\n","\n","Epoch 00374: val_accuracy did not improve from 0.93842\n","Epoch 375/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.8802e-04 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9286\n","\n","Epoch 00375: val_accuracy did not improve from 0.93842\n","Epoch 376/500\n","52/52 [==============================] - 11s 207ms/step - loss: 4.5683e-04 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.9360\n","\n","Epoch 00376: val_accuracy did not improve from 0.93842\n","Epoch 377/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.4130 - val_accuracy: 0.9261\n","\n","Epoch 00377: val_accuracy did not improve from 0.93842\n","Epoch 378/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4851 - val_accuracy: 0.9039\n","\n","Epoch 00378: val_accuracy did not improve from 0.93842\n","Epoch 379/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.5197 - val_accuracy: 0.8966\n","\n","Epoch 00379: val_accuracy did not improve from 0.93842\n","Epoch 380/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.9286\n","\n","Epoch 00380: val_accuracy did not improve from 0.93842\n","Epoch 381/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.5263e-04 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9089\n","\n","Epoch 00381: val_accuracy did not improve from 0.93842\n","Epoch 382/500\n","52/52 [==============================] - 11s 209ms/step - loss: 7.9141e-04 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.9310\n","\n","Epoch 00382: val_accuracy did not improve from 0.93842\n","Epoch 383/500\n","52/52 [==============================] - 11s 208ms/step - loss: 3.8591e-04 - accuracy: 1.0000 - val_loss: 0.4050 - val_accuracy: 0.9286\n","\n","Epoch 00383: val_accuracy did not improve from 0.93842\n","Epoch 384/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.5237 - val_accuracy: 0.8867\n","\n","Epoch 00384: val_accuracy did not improve from 0.93842\n","Epoch 385/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.4976 - val_accuracy: 0.9089\n","\n","Epoch 00385: val_accuracy did not improve from 0.93842\n","Epoch 386/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.5824 - val_accuracy: 0.9015\n","\n","Epoch 00386: val_accuracy did not improve from 0.93842\n","Epoch 387/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.7816 - val_accuracy: 0.8621\n","\n","Epoch 00387: val_accuracy did not improve from 0.93842\n","Epoch 388/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.7580 - val_accuracy: 0.8990\n","\n","Epoch 00388: val_accuracy did not improve from 0.93842\n","Epoch 389/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.6109 - val_accuracy: 0.8793\n","\n","Epoch 00389: val_accuracy did not improve from 0.93842\n","Epoch 390/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0214 - accuracy: 0.9921 - val_loss: 0.7209 - val_accuracy: 0.8621\n","\n","Epoch 00390: val_accuracy did not improve from 0.93842\n","Epoch 391/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0555 - accuracy: 0.9836 - val_loss: 1.2234 - val_accuracy: 0.7980\n","\n","Epoch 00391: val_accuracy did not improve from 0.93842\n","Epoch 392/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0356 - accuracy: 0.9909 - val_loss: 0.6362 - val_accuracy: 0.9039\n","\n","Epoch 00392: val_accuracy did not improve from 0.93842\n","Epoch 393/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.5852 - val_accuracy: 0.8916\n","\n","Epoch 00393: val_accuracy did not improve from 0.93842\n","Epoch 394/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0194 - accuracy: 0.9921 - val_loss: 0.6002 - val_accuracy: 0.9015\n","\n","Epoch 00394: val_accuracy did not improve from 0.93842\n","Epoch 395/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.5680 - val_accuracy: 0.8892\n","\n","Epoch 00395: val_accuracy did not improve from 0.93842\n","Epoch 396/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4865 - val_accuracy: 0.9064\n","\n","Epoch 00396: val_accuracy did not improve from 0.93842\n","Epoch 397/500\n","52/52 [==============================] - 11s 207ms/step - loss: 9.2244e-04 - accuracy: 1.0000 - val_loss: 0.3952 - val_accuracy: 0.9335\n","\n","Epoch 00397: val_accuracy did not improve from 0.93842\n","Epoch 398/500\n","52/52 [==============================] - 11s 208ms/step - loss: 6.5158e-04 - accuracy: 1.0000 - val_loss: 0.4388 - val_accuracy: 0.9236\n","\n","Epoch 00398: val_accuracy did not improve from 0.93842\n","Epoch 399/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4952 - val_accuracy: 0.9187\n","\n","Epoch 00399: val_accuracy did not improve from 0.93842\n","Epoch 400/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.4046 - val_accuracy: 0.9261\n","\n","Epoch 00400: val_accuracy did not improve from 0.93842\n","Epoch 401/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.9138\n","\n","Epoch 00401: val_accuracy did not improve from 0.93842\n","Epoch 402/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.0392e-04 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9286\n","\n","Epoch 00402: val_accuracy did not improve from 0.93842\n","Epoch 403/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.5690 - val_accuracy: 0.9039\n","\n","Epoch 00403: val_accuracy did not improve from 0.93842\n","Epoch 404/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.5145 - val_accuracy: 0.8966\n","\n","Epoch 00404: val_accuracy did not improve from 0.93842\n","Epoch 405/500\n","52/52 [==============================] - 11s 207ms/step - loss: 9.9385e-04 - accuracy: 1.0000 - val_loss: 0.5505 - val_accuracy: 0.8867\n","\n","Epoch 00405: val_accuracy did not improve from 0.93842\n","Epoch 406/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4649 - val_accuracy: 0.9039\n","\n","Epoch 00406: val_accuracy did not improve from 0.93842\n","Epoch 407/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4784 - val_accuracy: 0.9113\n","\n","Epoch 00407: val_accuracy did not improve from 0.93842\n","Epoch 408/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4026 - val_accuracy: 0.9187\n","\n","Epoch 00408: val_accuracy did not improve from 0.93842\n","Epoch 409/500\n","52/52 [==============================] - 11s 209ms/step - loss: 5.6142e-04 - accuracy: 1.0000 - val_loss: 0.4789 - val_accuracy: 0.9163\n","\n","Epoch 00409: val_accuracy did not improve from 0.93842\n","Epoch 410/500\n","52/52 [==============================] - 11s 208ms/step - loss: 5.2481e-04 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9384\n","\n","Epoch 00410: val_accuracy did not improve from 0.93842\n","Epoch 411/500\n","52/52 [==============================] - 11s 207ms/step - loss: 7.0425e-04 - accuracy: 1.0000 - val_loss: 0.4509 - val_accuracy: 0.9236\n","\n","Epoch 00411: val_accuracy did not improve from 0.93842\n","Epoch 412/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.8180e-04 - accuracy: 1.0000 - val_loss: 0.3825 - val_accuracy: 0.9236\n","\n","Epoch 00412: val_accuracy did not improve from 0.93842\n","Epoch 413/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.1951e-04 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.9261\n","\n","Epoch 00413: val_accuracy did not improve from 0.93842\n","Epoch 414/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.7212e-04 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.9187\n","\n","Epoch 00414: val_accuracy did not improve from 0.93842\n","Epoch 415/500\n","52/52 [==============================] - 11s 207ms/step - loss: 2.9462e-04 - accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 0.9236\n","\n","Epoch 00415: val_accuracy did not improve from 0.93842\n","Epoch 416/500\n","52/52 [==============================] - 11s 209ms/step - loss: 1.0444e-04 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.9261\n","\n","Epoch 00416: val_accuracy did not improve from 0.93842\n","Epoch 417/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.9335e-04 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 0.9236\n","\n","Epoch 00417: val_accuracy did not improve from 0.93842\n","Epoch 418/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.8718e-04 - accuracy: 1.0000 - val_loss: 0.4787 - val_accuracy: 0.9113\n","\n","Epoch 00418: val_accuracy did not improve from 0.93842\n","Epoch 419/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.1787e-04 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.9113\n","\n","Epoch 00419: val_accuracy did not improve from 0.93842\n","Epoch 420/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.9082e-04 - accuracy: 1.0000 - val_loss: 0.3759 - val_accuracy: 0.9187\n","\n","Epoch 00420: val_accuracy did not improve from 0.93842\n","Epoch 421/500\n","52/52 [==============================] - 11s 208ms/step - loss: 2.9047e-04 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.9064\n","\n","Epoch 00421: val_accuracy did not improve from 0.93842\n","Epoch 422/500\n","52/52 [==============================] - 11s 208ms/step - loss: 1.8718e-04 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9163\n","\n","Epoch 00422: val_accuracy did not improve from 0.93842\n","Epoch 423/500\n","52/52 [==============================] - 11s 210ms/step - loss: 8.8149e-05 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.9261\n","\n","Epoch 00423: val_accuracy did not improve from 0.93842\n","Epoch 424/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.3097e-04 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.9236\n","\n","Epoch 00424: val_accuracy did not improve from 0.93842\n","Epoch 425/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.9259e-05 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9286\n","\n","Epoch 00425: val_accuracy did not improve from 0.93842\n","Epoch 426/500\n","52/52 [==============================] - 11s 207ms/step - loss: 1.0263e-04 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.9261\n","\n","Epoch 00426: val_accuracy did not improve from 0.93842\n","Epoch 427/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.9113\n","\n","Epoch 00427: val_accuracy did not improve from 0.93842\n","Epoch 428/500\n","52/52 [==============================] - 11s 209ms/step - loss: 3.0749e-04 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9335\n","\n","Epoch 00428: val_accuracy did not improve from 0.93842\n","Epoch 429/500\n","52/52 [==============================] - 11s 209ms/step - loss: 9.9712e-05 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9163\n","\n","Epoch 00429: val_accuracy did not improve from 0.93842\n","Epoch 430/500\n","52/52 [==============================] - 11s 208ms/step - loss: 2.2760e-04 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9236\n","\n","Epoch 00430: val_accuracy did not improve from 0.93842\n","Epoch 431/500\n","52/52 [==============================] - 11s 208ms/step - loss: 2.0710e-04 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.9384\n","\n","Epoch 00431: val_accuracy did not improve from 0.93842\n","Epoch 432/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.7275e-04 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9187\n","\n","Epoch 00432: val_accuracy did not improve from 0.93842\n","Epoch 433/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.5681e-05 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.9212\n","\n","Epoch 00433: val_accuracy did not improve from 0.93842\n","Epoch 434/500\n","52/52 [==============================] - 11s 205ms/step - loss: 9.0252e-05 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.9163\n","\n","Epoch 00434: val_accuracy did not improve from 0.93842\n","Epoch 435/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1022 - accuracy: 0.9689 - val_loss: 2.7433 - val_accuracy: 0.7463\n","\n","Epoch 00435: val_accuracy did not improve from 0.93842\n","Epoch 436/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.1125 - accuracy: 0.9677 - val_loss: 1.1961 - val_accuracy: 0.8350\n","\n","Epoch 00436: val_accuracy did not improve from 0.93842\n","Epoch 437/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0462 - accuracy: 0.9854 - val_loss: 0.9080 - val_accuracy: 0.8571\n","\n","Epoch 00437: val_accuracy did not improve from 0.93842\n","Epoch 438/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 0.5751 - val_accuracy: 0.8941\n","\n","Epoch 00438: val_accuracy did not improve from 0.93842\n","Epoch 439/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.5259 - val_accuracy: 0.8842\n","\n","Epoch 00439: val_accuracy did not improve from 0.93842\n","Epoch 440/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.4368 - val_accuracy: 0.9064\n","\n","Epoch 00440: val_accuracy did not improve from 0.93842\n","Epoch 441/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4871 - val_accuracy: 0.8966\n","\n","Epoch 00441: val_accuracy did not improve from 0.93842\n","Epoch 442/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9286\n","\n","Epoch 00442: val_accuracy did not improve from 0.93842\n","Epoch 443/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9187\n","\n","Epoch 00443: val_accuracy did not improve from 0.93842\n","Epoch 444/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4610 - val_accuracy: 0.9236\n","\n","Epoch 00444: val_accuracy did not improve from 0.93842\n","Epoch 445/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.4647 - val_accuracy: 0.9064\n","\n","Epoch 00445: val_accuracy did not improve from 0.93842\n","Epoch 446/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.5033 - val_accuracy: 0.8990\n","\n","Epoch 00446: val_accuracy did not improve from 0.93842\n","Epoch 447/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.4830e-04 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.9089\n","\n","Epoch 00447: val_accuracy did not improve from 0.93842\n","Epoch 448/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5804 - val_accuracy: 0.8916\n","\n","Epoch 00448: val_accuracy did not improve from 0.93842\n","Epoch 449/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.5158 - val_accuracy: 0.9163\n","\n","Epoch 00449: val_accuracy did not improve from 0.93842\n","Epoch 450/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.9064\n","\n","Epoch 00450: val_accuracy did not improve from 0.93842\n","Epoch 451/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.9187\n","\n","Epoch 00451: val_accuracy did not improve from 0.93842\n","Epoch 452/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.5642 - val_accuracy: 0.8941\n","\n","Epoch 00452: val_accuracy did not improve from 0.93842\n","Epoch 453/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0037 - accuracy: 0.9976 - val_loss: 0.4531 - val_accuracy: 0.9335\n","\n","Epoch 00453: val_accuracy did not improve from 0.93842\n","Epoch 454/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.5703 - val_accuracy: 0.8990\n","\n","Epoch 00454: val_accuracy did not improve from 0.93842\n","Epoch 455/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4483 - val_accuracy: 0.9039\n","\n","Epoch 00455: val_accuracy did not improve from 0.93842\n","Epoch 456/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.5687 - val_accuracy: 0.8966\n","\n","Epoch 00456: val_accuracy did not improve from 0.93842\n","Epoch 457/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.5460 - val_accuracy: 0.8966\n","\n","Epoch 00457: val_accuracy did not improve from 0.93842\n","Epoch 458/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5493 - val_accuracy: 0.9039\n","\n","Epoch 00458: val_accuracy did not improve from 0.93842\n","Epoch 459/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 0.7091 - val_accuracy: 0.8867\n","\n","Epoch 00459: val_accuracy did not improve from 0.93842\n","Epoch 460/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.7113 - val_accuracy: 0.8547\n","\n","Epoch 00460: val_accuracy did not improve from 0.93842\n","Epoch 461/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.5956 - val_accuracy: 0.8916\n","\n","Epoch 00461: val_accuracy did not improve from 0.93842\n","Epoch 462/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4591 - val_accuracy: 0.9163\n","\n","Epoch 00462: val_accuracy did not improve from 0.93842\n","Epoch 463/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.7667 - val_accuracy: 0.8818\n","\n","Epoch 00463: val_accuracy did not improve from 0.93842\n","Epoch 464/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 0.5080 - val_accuracy: 0.8966\n","\n","Epoch 00464: val_accuracy did not improve from 0.93842\n","Epoch 465/500\n","52/52 [==============================] - 11s 205ms/step - loss: 8.2991e-04 - accuracy: 1.0000 - val_loss: 0.5061 - val_accuracy: 0.9089\n","\n","Epoch 00465: val_accuracy did not improve from 0.93842\n","Epoch 466/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.5447 - val_accuracy: 0.8892\n","\n","Epoch 00466: val_accuracy did not improve from 0.93842\n","Epoch 467/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5782 - val_accuracy: 0.9064\n","\n","Epoch 00467: val_accuracy did not improve from 0.93842\n","Epoch 468/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4335 - val_accuracy: 0.9039\n","\n","Epoch 00468: val_accuracy did not improve from 0.93842\n","Epoch 469/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.9089\n","\n","Epoch 00469: val_accuracy did not improve from 0.93842\n","Epoch 470/500\n","52/52 [==============================] - 11s 210ms/step - loss: 5.2666e-04 - accuracy: 1.0000 - val_loss: 0.4781 - val_accuracy: 0.9113\n","\n","Epoch 00470: val_accuracy did not improve from 0.93842\n","Epoch 471/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4174 - val_accuracy: 0.9064\n","\n","Epoch 00471: val_accuracy did not improve from 0.93842\n","Epoch 472/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.9212\n","\n","Epoch 00472: val_accuracy did not improve from 0.93842\n","Epoch 473/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.4870 - val_accuracy: 0.9138\n","\n","Epoch 00473: val_accuracy did not improve from 0.93842\n","Epoch 474/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.4960 - val_accuracy: 0.8892\n","\n","Epoch 00474: val_accuracy did not improve from 0.93842\n","Epoch 475/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6314 - val_accuracy: 0.8990\n","\n","Epoch 00475: val_accuracy did not improve from 0.93842\n","Epoch 476/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.6446 - val_accuracy: 0.8990\n","\n","Epoch 00476: val_accuracy did not improve from 0.93842\n","Epoch 477/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5398 - val_accuracy: 0.9039\n","\n","Epoch 00477: val_accuracy did not improve from 0.93842\n","Epoch 478/500\n","52/52 [==============================] - 11s 203ms/step - loss: 5.8663e-04 - accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.9064\n","\n","Epoch 00478: val_accuracy did not improve from 0.93842\n","Epoch 479/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.6766 - val_accuracy: 0.9015\n","\n","Epoch 00479: val_accuracy did not improve from 0.93842\n","Epoch 480/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.5345 - val_accuracy: 0.9015\n","\n","Epoch 00480: val_accuracy did not improve from 0.93842\n","Epoch 481/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0121 - accuracy: 0.9945 - val_loss: 0.9162 - val_accuracy: 0.8399\n","\n","Epoch 00481: val_accuracy did not improve from 0.93842\n","Epoch 482/500\n","52/52 [==============================] - 11s 210ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 0.6684 - val_accuracy: 0.8621\n","\n","Epoch 00482: val_accuracy did not improve from 0.93842\n","Epoch 483/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.6081 - val_accuracy: 0.8818\n","\n","Epoch 00483: val_accuracy did not improve from 0.93842\n","Epoch 484/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.7114 - val_accuracy: 0.8768\n","\n","Epoch 00484: val_accuracy did not improve from 0.93842\n","Epoch 485/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.6518 - val_accuracy: 0.9064\n","\n","Epoch 00485: val_accuracy did not improve from 0.93842\n","Epoch 486/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0068 - accuracy: 0.9963 - val_loss: 0.7395 - val_accuracy: 0.8768\n","\n","Epoch 00486: val_accuracy did not improve from 0.93842\n","Epoch 487/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.5708 - val_accuracy: 0.8867\n","\n","Epoch 00487: val_accuracy did not improve from 0.93842\n","Epoch 488/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 1.1399 - val_accuracy: 0.8079\n","\n","Epoch 00488: val_accuracy did not improve from 0.93842\n","Epoch 489/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.6662 - val_accuracy: 0.8892\n","\n","Epoch 00489: val_accuracy did not improve from 0.93842\n","Epoch 490/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5750 - val_accuracy: 0.9039\n","\n","Epoch 00490: val_accuracy did not improve from 0.93842\n","Epoch 491/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.5410 - val_accuracy: 0.9138\n","\n","Epoch 00491: val_accuracy did not improve from 0.93842\n","Epoch 492/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.7212 - val_accuracy: 0.8793\n","\n","Epoch 00492: val_accuracy did not improve from 0.93842\n","Epoch 493/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5698 - val_accuracy: 0.8941\n","\n","Epoch 00493: val_accuracy did not improve from 0.93842\n","Epoch 494/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.7232 - val_accuracy: 0.8621\n","\n","Epoch 00494: val_accuracy did not improve from 0.93842\n","Epoch 495/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4589 - val_accuracy: 0.9212\n","\n","Epoch 00495: val_accuracy did not improve from 0.93842\n","Epoch 496/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4663 - val_accuracy: 0.9212\n","\n","Epoch 00496: val_accuracy did not improve from 0.93842\n","Epoch 497/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.4722 - val_accuracy: 0.9212\n","\n","Epoch 00497: val_accuracy did not improve from 0.93842\n","Epoch 498/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.9310\n","\n","Epoch 00498: val_accuracy did not improve from 0.93842\n","Epoch 499/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5355 - val_accuracy: 0.9089\n","\n","Epoch 00499: val_accuracy did not improve from 0.93842\n","Epoch 500/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.5227 - val_accuracy: 0.9015\n","\n","Epoch 00500: val_accuracy did not improve from 0.93842\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff227d7e410>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"xyijRlNCDTaO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628182108066,"user_tz":-540,"elapsed":6595485,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0b8e4483-da9e-412a-b885-68f17363e9a5"},"source":["DenseNet169_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[DenseNet169_checkpoint])\n","# files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["52/52 [==============================] - 28s 302ms/step - loss: 1.8002 - accuracy: 0.3873 - val_loss: 19.2859 - val_accuracy: 0.1059\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.10591, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 2/500\n","52/52 [==============================] - 13s 247ms/step - loss: 1.0994 - accuracy: 0.6285 - val_loss: 13.6163 - val_accuracy: 0.0764\n","\n","Epoch 00002: val_accuracy did not improve from 0.10591\n","Epoch 3/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.9359 - accuracy: 0.6888 - val_loss: 5.6528 - val_accuracy: 0.0961\n","\n","Epoch 00003: val_accuracy did not improve from 0.10591\n","Epoch 4/500\n","52/52 [==============================] - 13s 244ms/step - loss: 0.7140 - accuracy: 0.7570 - val_loss: 13.6177 - val_accuracy: 0.1034\n","\n","Epoch 00004: val_accuracy did not improve from 0.10591\n","Epoch 5/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.7071 - accuracy: 0.7637 - val_loss: 20.4447 - val_accuracy: 0.0985\n","\n","Epoch 00005: val_accuracy did not improve from 0.10591\n","Epoch 6/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.6329 - accuracy: 0.7905 - val_loss: 5.0312 - val_accuracy: 0.2192\n","\n","Epoch 00006: val_accuracy improved from 0.10591 to 0.21921, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 7/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.5701 - accuracy: 0.8112 - val_loss: 14.3781 - val_accuracy: 0.1601\n","\n","Epoch 00007: val_accuracy did not improve from 0.21921\n","Epoch 8/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.4823 - accuracy: 0.8234 - val_loss: 4.7712 - val_accuracy: 0.2882\n","\n","Epoch 00008: val_accuracy improved from 0.21921 to 0.28818, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 9/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.5031 - accuracy: 0.8362 - val_loss: 2.8856 - val_accuracy: 0.4631\n","\n","Epoch 00009: val_accuracy improved from 0.28818 to 0.46305, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 10/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.4204 - accuracy: 0.8636 - val_loss: 1.9873 - val_accuracy: 0.5862\n","\n","Epoch 00010: val_accuracy improved from 0.46305 to 0.58621, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 11/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.4392 - accuracy: 0.8459 - val_loss: 1.2167 - val_accuracy: 0.7217\n","\n","Epoch 00011: val_accuracy improved from 0.58621 to 0.72167, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 12/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.4738 - accuracy: 0.8404 - val_loss: 3.3427 - val_accuracy: 0.4384\n","\n","Epoch 00012: val_accuracy did not improve from 0.72167\n","Epoch 13/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.3615 - accuracy: 0.8788 - val_loss: 0.6991 - val_accuracy: 0.8005\n","\n","Epoch 00013: val_accuracy improved from 0.72167 to 0.80049, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 14/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.3122 - accuracy: 0.8971 - val_loss: 0.6591 - val_accuracy: 0.8128\n","\n","Epoch 00014: val_accuracy improved from 0.80049 to 0.81281, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 15/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.3161 - accuracy: 0.8873 - val_loss: 0.7480 - val_accuracy: 0.7857\n","\n","Epoch 00015: val_accuracy did not improve from 0.81281\n","Epoch 16/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.3013 - accuracy: 0.9001 - val_loss: 1.1561 - val_accuracy: 0.6970\n","\n","Epoch 00016: val_accuracy did not improve from 0.81281\n","Epoch 17/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.3166 - accuracy: 0.8812 - val_loss: 0.6419 - val_accuracy: 0.8374\n","\n","Epoch 00017: val_accuracy improved from 0.81281 to 0.83744, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 18/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.2970 - accuracy: 0.9007 - val_loss: 0.8023 - val_accuracy: 0.7980\n","\n","Epoch 00018: val_accuracy did not improve from 0.83744\n","Epoch 19/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.3031 - accuracy: 0.8965 - val_loss: 1.2133 - val_accuracy: 0.6970\n","\n","Epoch 00019: val_accuracy did not improve from 0.83744\n","Epoch 20/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.2283 - accuracy: 0.9227 - val_loss: 0.5394 - val_accuracy: 0.8300\n","\n","Epoch 00020: val_accuracy did not improve from 0.83744\n","Epoch 21/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.1958 - accuracy: 0.9348 - val_loss: 1.1199 - val_accuracy: 0.7241\n","\n","Epoch 00021: val_accuracy did not improve from 0.83744\n","Epoch 22/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.2536 - accuracy: 0.9117 - val_loss: 1.0242 - val_accuracy: 0.7414\n","\n","Epoch 00022: val_accuracy did not improve from 0.83744\n","Epoch 23/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.2706 - accuracy: 0.9056 - val_loss: 0.6190 - val_accuracy: 0.8300\n","\n","Epoch 00023: val_accuracy did not improve from 0.83744\n","Epoch 24/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.2047 - accuracy: 0.9239 - val_loss: 0.8460 - val_accuracy: 0.7906\n","\n","Epoch 00024: val_accuracy did not improve from 0.83744\n","Epoch 25/500\n","52/52 [==============================] - 13s 244ms/step - loss: 0.2306 - accuracy: 0.9214 - val_loss: 1.0922 - val_accuracy: 0.7882\n","\n","Epoch 00025: val_accuracy did not improve from 0.83744\n","Epoch 26/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.2010 - accuracy: 0.9348 - val_loss: 1.2159 - val_accuracy: 0.7266\n","\n","Epoch 00026: val_accuracy did not improve from 0.83744\n","Epoch 27/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.1897 - accuracy: 0.9361 - val_loss: 0.7883 - val_accuracy: 0.8128\n","\n","Epoch 00027: val_accuracy did not improve from 0.83744\n","Epoch 28/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.1495 - accuracy: 0.9458 - val_loss: 0.6307 - val_accuracy: 0.8473\n","\n","Epoch 00028: val_accuracy improved from 0.83744 to 0.84729, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 29/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.1666 - accuracy: 0.9440 - val_loss: 2.3233 - val_accuracy: 0.6158\n","\n","Epoch 00029: val_accuracy did not improve from 0.84729\n","Epoch 30/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.1906 - accuracy: 0.9324 - val_loss: 1.3471 - val_accuracy: 0.7118\n","\n","Epoch 00030: val_accuracy did not improve from 0.84729\n","Epoch 31/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.2616 - accuracy: 0.9129 - val_loss: 1.3272 - val_accuracy: 0.7488\n","\n","Epoch 00031: val_accuracy did not improve from 0.84729\n","Epoch 32/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.2039 - accuracy: 0.9348 - val_loss: 1.5854 - val_accuracy: 0.7414\n","\n","Epoch 00032: val_accuracy did not improve from 0.84729\n","Epoch 33/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.1774 - accuracy: 0.9373 - val_loss: 0.8689 - val_accuracy: 0.8202\n","\n","Epoch 00033: val_accuracy did not improve from 0.84729\n","Epoch 34/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.1238 - accuracy: 0.9586 - val_loss: 0.5219 - val_accuracy: 0.8473\n","\n","Epoch 00034: val_accuracy did not improve from 0.84729\n","Epoch 35/500\n","52/52 [==============================] - 13s 244ms/step - loss: 0.1415 - accuracy: 0.9464 - val_loss: 0.7712 - val_accuracy: 0.8325\n","\n","Epoch 00035: val_accuracy did not improve from 0.84729\n","Epoch 36/500\n","52/52 [==============================] - 13s 244ms/step - loss: 0.1088 - accuracy: 0.9604 - val_loss: 0.4660 - val_accuracy: 0.8645\n","\n","Epoch 00036: val_accuracy improved from 0.84729 to 0.86453, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 37/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0966 - accuracy: 0.9665 - val_loss: 0.5580 - val_accuracy: 0.8473\n","\n","Epoch 00037: val_accuracy did not improve from 0.86453\n","Epoch 38/500\n","52/52 [==============================] - 13s 251ms/step - loss: 0.1026 - accuracy: 0.9659 - val_loss: 0.4620 - val_accuracy: 0.8744\n","\n","Epoch 00038: val_accuracy improved from 0.86453 to 0.87438, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 39/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.1060 - accuracy: 0.9641 - val_loss: 0.7935 - val_accuracy: 0.8276\n","\n","Epoch 00039: val_accuracy did not improve from 0.87438\n","Epoch 40/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.1793 - accuracy: 0.9403 - val_loss: 0.6206 - val_accuracy: 0.8325\n","\n","Epoch 00040: val_accuracy did not improve from 0.87438\n","Epoch 41/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.2059 - accuracy: 0.9257 - val_loss: 0.8952 - val_accuracy: 0.7980\n","\n","Epoch 00041: val_accuracy did not improve from 0.87438\n","Epoch 42/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.1047 - accuracy: 0.9629 - val_loss: 0.8108 - val_accuracy: 0.8153\n","\n","Epoch 00042: val_accuracy did not improve from 0.87438\n","Epoch 43/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.1805 - accuracy: 0.9421 - val_loss: 0.6513 - val_accuracy: 0.8596\n","\n","Epoch 00043: val_accuracy did not improve from 0.87438\n","Epoch 44/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.1533 - accuracy: 0.9446 - val_loss: 6.9610 - val_accuracy: 0.3571\n","\n","Epoch 00044: val_accuracy did not improve from 0.87438\n","Epoch 45/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.1341 - accuracy: 0.9531 - val_loss: 1.4188 - val_accuracy: 0.7315\n","\n","Epoch 00045: val_accuracy did not improve from 0.87438\n","Epoch 46/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.1203 - accuracy: 0.9592 - val_loss: 0.5233 - val_accuracy: 0.8892\n","\n","Epoch 00046: val_accuracy improved from 0.87438 to 0.88916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 47/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.1105 - accuracy: 0.9665 - val_loss: 0.5176 - val_accuracy: 0.8645\n","\n","Epoch 00047: val_accuracy did not improve from 0.88916\n","Epoch 48/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.1121 - accuracy: 0.9622 - val_loss: 0.6170 - val_accuracy: 0.8621\n","\n","Epoch 00048: val_accuracy did not improve from 0.88916\n","Epoch 49/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0673 - accuracy: 0.9726 - val_loss: 0.5141 - val_accuracy: 0.8670\n","\n","Epoch 00049: val_accuracy did not improve from 0.88916\n","Epoch 50/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0454 - accuracy: 0.9836 - val_loss: 0.4879 - val_accuracy: 0.8473\n","\n","Epoch 00050: val_accuracy did not improve from 0.88916\n","Epoch 51/500\n","52/52 [==============================] - 13s 244ms/step - loss: 0.0367 - accuracy: 0.9896 - val_loss: 0.4125 - val_accuracy: 0.8867\n","\n","Epoch 00051: val_accuracy did not improve from 0.88916\n","Epoch 52/500\n","52/52 [==============================] - 13s 244ms/step - loss: 0.0662 - accuracy: 0.9744 - val_loss: 0.5771 - val_accuracy: 0.8695\n","\n","Epoch 00052: val_accuracy did not improve from 0.88916\n","Epoch 53/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0692 - accuracy: 0.9750 - val_loss: 0.6909 - val_accuracy: 0.8448\n","\n","Epoch 00053: val_accuracy did not improve from 0.88916\n","Epoch 54/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0807 - accuracy: 0.9702 - val_loss: 0.3925 - val_accuracy: 0.9039\n","\n","Epoch 00054: val_accuracy improved from 0.88916 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 55/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0669 - accuracy: 0.9793 - val_loss: 0.5596 - val_accuracy: 0.8621\n","\n","Epoch 00055: val_accuracy did not improve from 0.90394\n","Epoch 56/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0817 - accuracy: 0.9708 - val_loss: 0.7725 - val_accuracy: 0.8350\n","\n","Epoch 00056: val_accuracy did not improve from 0.90394\n","Epoch 57/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.1319 - accuracy: 0.9586 - val_loss: 1.0517 - val_accuracy: 0.7857\n","\n","Epoch 00057: val_accuracy did not improve from 0.90394\n","Epoch 58/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.1092 - accuracy: 0.9653 - val_loss: 0.5761 - val_accuracy: 0.8571\n","\n","Epoch 00058: val_accuracy did not improve from 0.90394\n","Epoch 59/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0614 - accuracy: 0.9775 - val_loss: 0.5976 - val_accuracy: 0.8670\n","\n","Epoch 00059: val_accuracy did not improve from 0.90394\n","Epoch 60/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0411 - accuracy: 0.9854 - val_loss: 0.5787 - val_accuracy: 0.8621\n","\n","Epoch 00060: val_accuracy did not improve from 0.90394\n","Epoch 61/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0958 - accuracy: 0.9659 - val_loss: 0.7958 - val_accuracy: 0.8374\n","\n","Epoch 00061: val_accuracy did not improve from 0.90394\n","Epoch 62/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0824 - accuracy: 0.9714 - val_loss: 0.5830 - val_accuracy: 0.8670\n","\n","Epoch 00062: val_accuracy did not improve from 0.90394\n","Epoch 63/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0976 - accuracy: 0.9659 - val_loss: 0.8533 - val_accuracy: 0.8251\n","\n","Epoch 00063: val_accuracy did not improve from 0.90394\n","Epoch 64/500\n","52/52 [==============================] - 13s 244ms/step - loss: 0.0804 - accuracy: 0.9714 - val_loss: 0.4893 - val_accuracy: 0.8793\n","\n","Epoch 00064: val_accuracy did not improve from 0.90394\n","Epoch 65/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0488 - accuracy: 0.9823 - val_loss: 0.4779 - val_accuracy: 0.8916\n","\n","Epoch 00065: val_accuracy did not improve from 0.90394\n","Epoch 66/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0317 - accuracy: 0.9909 - val_loss: 0.4098 - val_accuracy: 0.8916\n","\n","Epoch 00066: val_accuracy did not improve from 0.90394\n","Epoch 67/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.4345 - val_accuracy: 0.8966\n","\n","Epoch 00067: val_accuracy did not improve from 0.90394\n","Epoch 68/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.3956 - val_accuracy: 0.8966\n","\n","Epoch 00068: val_accuracy did not improve from 0.90394\n","Epoch 69/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.3910 - val_accuracy: 0.9138\n","\n","Epoch 00069: val_accuracy improved from 0.90394 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 70/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0199 - accuracy: 0.9951 - val_loss: 0.4488 - val_accuracy: 0.8916\n","\n","Epoch 00070: val_accuracy did not improve from 0.91379\n","Epoch 71/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 0.3959 - val_accuracy: 0.9187\n","\n","Epoch 00071: val_accuracy improved from 0.91379 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 72/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0380 - accuracy: 0.9896 - val_loss: 0.5944 - val_accuracy: 0.8670\n","\n","Epoch 00072: val_accuracy did not improve from 0.91872\n","Epoch 73/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0640 - accuracy: 0.9781 - val_loss: 1.3029 - val_accuracy: 0.7808\n","\n","Epoch 00073: val_accuracy did not improve from 0.91872\n","Epoch 74/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.2482 - accuracy: 0.9275 - val_loss: 2.9398 - val_accuracy: 0.6601\n","\n","Epoch 00074: val_accuracy did not improve from 0.91872\n","Epoch 75/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.1837 - accuracy: 0.9385 - val_loss: 2.8547 - val_accuracy: 0.6108\n","\n","Epoch 00075: val_accuracy did not improve from 0.91872\n","Epoch 76/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.1248 - accuracy: 0.9568 - val_loss: 0.7992 - val_accuracy: 0.8473\n","\n","Epoch 00076: val_accuracy did not improve from 0.91872\n","Epoch 77/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0598 - accuracy: 0.9799 - val_loss: 0.5693 - val_accuracy: 0.8818\n","\n","Epoch 00077: val_accuracy did not improve from 0.91872\n","Epoch 78/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0480 - accuracy: 0.9854 - val_loss: 0.4970 - val_accuracy: 0.8892\n","\n","Epoch 00078: val_accuracy did not improve from 0.91872\n","Epoch 79/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0425 - accuracy: 0.9890 - val_loss: 0.7237 - val_accuracy: 0.8670\n","\n","Epoch 00079: val_accuracy did not improve from 0.91872\n","Epoch 80/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.4461 - val_accuracy: 0.8941\n","\n","Epoch 00080: val_accuracy did not improve from 0.91872\n","Epoch 81/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0668 - accuracy: 0.9787 - val_loss: 1.0721 - val_accuracy: 0.8251\n","\n","Epoch 00081: val_accuracy did not improve from 0.91872\n","Epoch 82/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0569 - accuracy: 0.9781 - val_loss: 0.7297 - val_accuracy: 0.8596\n","\n","Epoch 00082: val_accuracy did not improve from 0.91872\n","Epoch 83/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 0.5647 - val_accuracy: 0.8744\n","\n","Epoch 00083: val_accuracy did not improve from 0.91872\n","Epoch 84/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0526 - accuracy: 0.9793 - val_loss: 0.4821 - val_accuracy: 0.8867\n","\n","Epoch 00084: val_accuracy did not improve from 0.91872\n","Epoch 85/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 0.4890 - val_accuracy: 0.8818\n","\n","Epoch 00085: val_accuracy did not improve from 0.91872\n","Epoch 86/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.3644 - val_accuracy: 0.8990\n","\n","Epoch 00086: val_accuracy did not improve from 0.91872\n","Epoch 87/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.7147 - val_accuracy: 0.8571\n","\n","Epoch 00087: val_accuracy did not improve from 0.91872\n","Epoch 88/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0550 - accuracy: 0.9811 - val_loss: 0.8486 - val_accuracy: 0.8300\n","\n","Epoch 00088: val_accuracy did not improve from 0.91872\n","Epoch 89/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0891 - accuracy: 0.9683 - val_loss: 0.5731 - val_accuracy: 0.8522\n","\n","Epoch 00089: val_accuracy did not improve from 0.91872\n","Epoch 90/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.1346 - accuracy: 0.9580 - val_loss: 1.8911 - val_accuracy: 0.7192\n","\n","Epoch 00090: val_accuracy did not improve from 0.91872\n","Epoch 91/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0709 - accuracy: 0.9750 - val_loss: 0.8451 - val_accuracy: 0.8547\n","\n","Epoch 00091: val_accuracy did not improve from 0.91872\n","Epoch 92/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0585 - accuracy: 0.9817 - val_loss: 0.5743 - val_accuracy: 0.8719\n","\n","Epoch 00092: val_accuracy did not improve from 0.91872\n","Epoch 93/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0550 - accuracy: 0.9854 - val_loss: 0.5037 - val_accuracy: 0.8744\n","\n","Epoch 00093: val_accuracy did not improve from 0.91872\n","Epoch 94/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0301 - accuracy: 0.9890 - val_loss: 0.4413 - val_accuracy: 0.9015\n","\n","Epoch 00094: val_accuracy did not improve from 0.91872\n","Epoch 95/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.4027 - val_accuracy: 0.8941\n","\n","Epoch 00095: val_accuracy did not improve from 0.91872\n","Epoch 96/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.4885 - val_accuracy: 0.8768\n","\n","Epoch 00096: val_accuracy did not improve from 0.91872\n","Epoch 97/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0187 - accuracy: 0.9927 - val_loss: 0.4879 - val_accuracy: 0.8990\n","\n","Epoch 00097: val_accuracy did not improve from 0.91872\n","Epoch 98/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0229 - accuracy: 0.9945 - val_loss: 0.4474 - val_accuracy: 0.9039\n","\n","Epoch 00098: val_accuracy did not improve from 0.91872\n","Epoch 99/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0258 - accuracy: 0.9890 - val_loss: 0.6295 - val_accuracy: 0.8621\n","\n","Epoch 00099: val_accuracy did not improve from 0.91872\n","Epoch 100/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0369 - accuracy: 0.9872 - val_loss: 0.6326 - val_accuracy: 0.8596\n","\n","Epoch 00100: val_accuracy did not improve from 0.91872\n","Epoch 101/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0340 - accuracy: 0.9903 - val_loss: 0.7975 - val_accuracy: 0.8202\n","\n","Epoch 00101: val_accuracy did not improve from 0.91872\n","Epoch 102/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 1.0204 - val_accuracy: 0.8227\n","\n","Epoch 00102: val_accuracy did not improve from 0.91872\n","Epoch 103/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0543 - accuracy: 0.9860 - val_loss: 0.6630 - val_accuracy: 0.8596\n","\n","Epoch 00103: val_accuracy did not improve from 0.91872\n","Epoch 104/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0303 - accuracy: 0.9903 - val_loss: 0.5864 - val_accuracy: 0.8498\n","\n","Epoch 00104: val_accuracy did not improve from 0.91872\n","Epoch 105/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0710 - accuracy: 0.9787 - val_loss: 1.0593 - val_accuracy: 0.8300\n","\n","Epoch 00105: val_accuracy did not improve from 0.91872\n","Epoch 106/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0740 - accuracy: 0.9775 - val_loss: 0.8490 - val_accuracy: 0.8645\n","\n","Epoch 00106: val_accuracy did not improve from 0.91872\n","Epoch 107/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.1037 - accuracy: 0.9714 - val_loss: 0.7480 - val_accuracy: 0.8670\n","\n","Epoch 00107: val_accuracy did not improve from 0.91872\n","Epoch 108/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0523 - accuracy: 0.9817 - val_loss: 0.7570 - val_accuracy: 0.8596\n","\n","Epoch 00108: val_accuracy did not improve from 0.91872\n","Epoch 109/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0609 - accuracy: 0.9769 - val_loss: 0.7085 - val_accuracy: 0.8793\n","\n","Epoch 00109: val_accuracy did not improve from 0.91872\n","Epoch 110/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 0.7674 - val_accuracy: 0.8670\n","\n","Epoch 00110: val_accuracy did not improve from 0.91872\n","Epoch 111/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0480 - accuracy: 0.9842 - val_loss: 1.0820 - val_accuracy: 0.8424\n","\n","Epoch 00111: val_accuracy did not improve from 0.91872\n","Epoch 112/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0650 - accuracy: 0.9799 - val_loss: 1.2592 - val_accuracy: 0.7931\n","\n","Epoch 00112: val_accuracy did not improve from 0.91872\n","Epoch 113/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0590 - accuracy: 0.9811 - val_loss: 0.6222 - val_accuracy: 0.8596\n","\n","Epoch 00113: val_accuracy did not improve from 0.91872\n","Epoch 114/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0488 - accuracy: 0.9848 - val_loss: 0.8633 - val_accuracy: 0.8448\n","\n","Epoch 00114: val_accuracy did not improve from 0.91872\n","Epoch 115/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0345 - accuracy: 0.9872 - val_loss: 0.5696 - val_accuracy: 0.8793\n","\n","Epoch 00115: val_accuracy did not improve from 0.91872\n","Epoch 116/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.3384 - val_accuracy: 0.9310\n","\n","Epoch 00116: val_accuracy improved from 0.91872 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 117/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0146 - accuracy: 0.9933 - val_loss: 0.4401 - val_accuracy: 0.8941\n","\n","Epoch 00117: val_accuracy did not improve from 0.93103\n","Epoch 118/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0259 - accuracy: 0.9903 - val_loss: 0.7713 - val_accuracy: 0.8399\n","\n","Epoch 00118: val_accuracy did not improve from 0.93103\n","Epoch 119/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0608 - accuracy: 0.9829 - val_loss: 0.6482 - val_accuracy: 0.8695\n","\n","Epoch 00119: val_accuracy did not improve from 0.93103\n","Epoch 120/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0313 - accuracy: 0.9890 - val_loss: 0.6065 - val_accuracy: 0.8695\n","\n","Epoch 00120: val_accuracy did not improve from 0.93103\n","Epoch 121/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0351 - accuracy: 0.9872 - val_loss: 0.5517 - val_accuracy: 0.8719\n","\n","Epoch 00121: val_accuracy did not improve from 0.93103\n","Epoch 122/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.9907 - val_accuracy: 0.8374\n","\n","Epoch 00122: val_accuracy did not improve from 0.93103\n","Epoch 123/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0221 - accuracy: 0.9915 - val_loss: 0.5479 - val_accuracy: 0.8867\n","\n","Epoch 00123: val_accuracy did not improve from 0.93103\n","Epoch 124/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0301 - accuracy: 0.9896 - val_loss: 1.2082 - val_accuracy: 0.7734\n","\n","Epoch 00124: val_accuracy did not improve from 0.93103\n","Epoch 125/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0406 - accuracy: 0.9866 - val_loss: 0.6248 - val_accuracy: 0.8621\n","\n","Epoch 00125: val_accuracy did not improve from 0.93103\n","Epoch 126/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.4557 - val_accuracy: 0.8990\n","\n","Epoch 00126: val_accuracy did not improve from 0.93103\n","Epoch 127/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.5338 - val_accuracy: 0.8892\n","\n","Epoch 00127: val_accuracy did not improve from 0.93103\n","Epoch 128/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.5524 - val_accuracy: 0.8966\n","\n","Epoch 00128: val_accuracy did not improve from 0.93103\n","Epoch 129/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.5434 - val_accuracy: 0.8768\n","\n","Epoch 00129: val_accuracy did not improve from 0.93103\n","Epoch 130/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.5939 - val_accuracy: 0.8842\n","\n","Epoch 00130: val_accuracy did not improve from 0.93103\n","Epoch 131/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5658 - val_accuracy: 0.8941\n","\n","Epoch 00131: val_accuracy did not improve from 0.93103\n","Epoch 132/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.9089\n","\n","Epoch 00132: val_accuracy did not improve from 0.93103\n","Epoch 133/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9015\n","\n","Epoch 00133: val_accuracy did not improve from 0.93103\n","Epoch 134/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.8966\n","\n","Epoch 00134: val_accuracy did not improve from 0.93103\n","Epoch 135/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0098 - accuracy: 0.9957 - val_loss: 0.5698 - val_accuracy: 0.8818\n","\n","Epoch 00135: val_accuracy did not improve from 0.93103\n","Epoch 136/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.1442 - accuracy: 0.9641 - val_loss: 2.0440 - val_accuracy: 0.7512\n","\n","Epoch 00136: val_accuracy did not improve from 0.93103\n","Epoch 137/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.2143 - accuracy: 0.9409 - val_loss: 0.8059 - val_accuracy: 0.8695\n","\n","Epoch 00137: val_accuracy did not improve from 0.93103\n","Epoch 138/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0938 - accuracy: 0.9732 - val_loss: 0.7706 - val_accuracy: 0.8670\n","\n","Epoch 00138: val_accuracy did not improve from 0.93103\n","Epoch 139/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0472 - accuracy: 0.9823 - val_loss: 0.6784 - val_accuracy: 0.8719\n","\n","Epoch 00139: val_accuracy did not improve from 0.93103\n","Epoch 140/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0376 - accuracy: 0.9872 - val_loss: 0.7615 - val_accuracy: 0.8571\n","\n","Epoch 00140: val_accuracy did not improve from 0.93103\n","Epoch 141/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0352 - accuracy: 0.9896 - val_loss: 0.7566 - val_accuracy: 0.8547\n","\n","Epoch 00141: val_accuracy did not improve from 0.93103\n","Epoch 142/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0414 - accuracy: 0.9836 - val_loss: 0.6293 - val_accuracy: 0.8695\n","\n","Epoch 00142: val_accuracy did not improve from 0.93103\n","Epoch 143/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0346 - accuracy: 0.9842 - val_loss: 0.6563 - val_accuracy: 0.8867\n","\n","Epoch 00143: val_accuracy did not improve from 0.93103\n","Epoch 144/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 0.8111 - val_accuracy: 0.8645\n","\n","Epoch 00144: val_accuracy did not improve from 0.93103\n","Epoch 145/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.4637 - val_accuracy: 0.9064\n","\n","Epoch 00145: val_accuracy did not improve from 0.93103\n","Epoch 146/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5156 - val_accuracy: 0.9113\n","\n","Epoch 00146: val_accuracy did not improve from 0.93103\n","Epoch 147/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.3493 - val_accuracy: 0.9286\n","\n","Epoch 00147: val_accuracy did not improve from 0.93103\n","Epoch 148/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0116 - accuracy: 0.9951 - val_loss: 0.5996 - val_accuracy: 0.8916\n","\n","Epoch 00148: val_accuracy did not improve from 0.93103\n","Epoch 149/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.8023 - val_accuracy: 0.8645\n","\n","Epoch 00149: val_accuracy did not improve from 0.93103\n","Epoch 150/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0454 - accuracy: 0.9872 - val_loss: 0.6092 - val_accuracy: 0.8916\n","\n","Epoch 00150: val_accuracy did not improve from 0.93103\n","Epoch 151/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0383 - accuracy: 0.9878 - val_loss: 0.6161 - val_accuracy: 0.8966\n","\n","Epoch 00151: val_accuracy did not improve from 0.93103\n","Epoch 152/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0712 - accuracy: 0.9744 - val_loss: 1.1861 - val_accuracy: 0.7980\n","\n","Epoch 00152: val_accuracy did not improve from 0.93103\n","Epoch 153/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0509 - accuracy: 0.9829 - val_loss: 0.6368 - val_accuracy: 0.8719\n","\n","Epoch 00153: val_accuracy did not improve from 0.93103\n","Epoch 154/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0345 - accuracy: 0.9896 - val_loss: 0.5588 - val_accuracy: 0.8916\n","\n","Epoch 00154: val_accuracy did not improve from 0.93103\n","Epoch 155/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.4884 - val_accuracy: 0.9163\n","\n","Epoch 00155: val_accuracy did not improve from 0.93103\n","Epoch 156/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.3922 - val_accuracy: 0.9064\n","\n","Epoch 00156: val_accuracy did not improve from 0.93103\n","Epoch 157/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3889 - val_accuracy: 0.9113\n","\n","Epoch 00157: val_accuracy did not improve from 0.93103\n","Epoch 158/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.3425 - val_accuracy: 0.9163\n","\n","Epoch 00158: val_accuracy did not improve from 0.93103\n","Epoch 159/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4468 - val_accuracy: 0.9064\n","\n","Epoch 00159: val_accuracy did not improve from 0.93103\n","Epoch 160/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5237 - val_accuracy: 0.8941\n","\n","Epoch 00160: val_accuracy did not improve from 0.93103\n","Epoch 161/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.4643 - val_accuracy: 0.8966\n","\n","Epoch 00161: val_accuracy did not improve from 0.93103\n","Epoch 162/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 0.4864 - val_accuracy: 0.8892\n","\n","Epoch 00162: val_accuracy did not improve from 0.93103\n","Epoch 163/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.5649 - val_accuracy: 0.8867\n","\n","Epoch 00163: val_accuracy did not improve from 0.93103\n","Epoch 164/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0389 - accuracy: 0.9884 - val_loss: 0.8572 - val_accuracy: 0.8596\n","\n","Epoch 00164: val_accuracy did not improve from 0.93103\n","Epoch 165/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0683 - accuracy: 0.9762 - val_loss: 0.9088 - val_accuracy: 0.8498\n","\n","Epoch 00165: val_accuracy did not improve from 0.93103\n","Epoch 166/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0811 - accuracy: 0.9732 - val_loss: 0.7169 - val_accuracy: 0.8818\n","\n","Epoch 00166: val_accuracy did not improve from 0.93103\n","Epoch 167/500\n","52/52 [==============================] - 13s 250ms/step - loss: 0.0522 - accuracy: 0.9854 - val_loss: 0.6987 - val_accuracy: 0.8571\n","\n","Epoch 00167: val_accuracy did not improve from 0.93103\n","Epoch 168/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.6594 - val_accuracy: 0.8818\n","\n","Epoch 00168: val_accuracy did not improve from 0.93103\n","Epoch 169/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.4837 - val_accuracy: 0.8867\n","\n","Epoch 00169: val_accuracy did not improve from 0.93103\n","Epoch 170/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0278 - accuracy: 0.9921 - val_loss: 0.5383 - val_accuracy: 0.8990\n","\n","Epoch 00170: val_accuracy did not improve from 0.93103\n","Epoch 171/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.9223 - val_accuracy: 0.8522\n","\n","Epoch 00171: val_accuracy did not improve from 0.93103\n","Epoch 172/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.5613 - val_accuracy: 0.8966\n","\n","Epoch 00172: val_accuracy did not improve from 0.93103\n","Epoch 173/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.7688 - val_accuracy: 0.8571\n","\n","Epoch 00173: val_accuracy did not improve from 0.93103\n","Epoch 174/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0223 - accuracy: 0.9945 - val_loss: 0.6209 - val_accuracy: 0.8547\n","\n","Epoch 00174: val_accuracy did not improve from 0.93103\n","Epoch 175/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0178 - accuracy: 0.9927 - val_loss: 0.6456 - val_accuracy: 0.8744\n","\n","Epoch 00175: val_accuracy did not improve from 0.93103\n","Epoch 176/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.4992 - val_accuracy: 0.8842\n","\n","Epoch 00176: val_accuracy did not improve from 0.93103\n","Epoch 177/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.4959 - val_accuracy: 0.8916\n","\n","Epoch 00177: val_accuracy did not improve from 0.93103\n","Epoch 178/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.5147 - val_accuracy: 0.9113\n","\n","Epoch 00178: val_accuracy did not improve from 0.93103\n","Epoch 179/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4528 - val_accuracy: 0.9015\n","\n","Epoch 00179: val_accuracy did not improve from 0.93103\n","Epoch 180/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4431 - val_accuracy: 0.9113\n","\n","Epoch 00180: val_accuracy did not improve from 0.93103\n","Epoch 181/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0270 - accuracy: 0.9890 - val_loss: 0.6052 - val_accuracy: 0.8645\n","\n","Epoch 00181: val_accuracy did not improve from 0.93103\n","Epoch 182/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0396 - accuracy: 0.9872 - val_loss: 1.0444 - val_accuracy: 0.8399\n","\n","Epoch 00182: val_accuracy did not improve from 0.93103\n","Epoch 183/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.6887 - val_accuracy: 0.8522\n","\n","Epoch 00183: val_accuracy did not improve from 0.93103\n","Epoch 184/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.7127 - val_accuracy: 0.8670\n","\n","Epoch 00184: val_accuracy did not improve from 0.93103\n","Epoch 185/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.5885 - val_accuracy: 0.8941\n","\n","Epoch 00185: val_accuracy did not improve from 0.93103\n","Epoch 186/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0180 - accuracy: 0.9933 - val_loss: 1.0812 - val_accuracy: 0.8424\n","\n","Epoch 00186: val_accuracy did not improve from 0.93103\n","Epoch 187/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 1.1104 - val_accuracy: 0.8522\n","\n","Epoch 00187: val_accuracy did not improve from 0.93103\n","Epoch 188/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0277 - accuracy: 0.9903 - val_loss: 0.6297 - val_accuracy: 0.8768\n","\n","Epoch 00188: val_accuracy did not improve from 0.93103\n","Epoch 189/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 1.0368 - val_accuracy: 0.8202\n","\n","Epoch 00189: val_accuracy did not improve from 0.93103\n","Epoch 190/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.9333 - val_accuracy: 0.8424\n","\n","Epoch 00190: val_accuracy did not improve from 0.93103\n","Epoch 191/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0300 - accuracy: 0.9890 - val_loss: 0.7716 - val_accuracy: 0.8621\n","\n","Epoch 00191: val_accuracy did not improve from 0.93103\n","Epoch 192/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0357 - accuracy: 0.9909 - val_loss: 0.7306 - val_accuracy: 0.8842\n","\n","Epoch 00192: val_accuracy did not improve from 0.93103\n","Epoch 193/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0323 - accuracy: 0.9909 - val_loss: 0.6240 - val_accuracy: 0.8695\n","\n","Epoch 00193: val_accuracy did not improve from 0.93103\n","Epoch 194/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 0.8450 - val_accuracy: 0.8030\n","\n","Epoch 00194: val_accuracy did not improve from 0.93103\n","Epoch 195/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0535 - accuracy: 0.9817 - val_loss: 0.8681 - val_accuracy: 0.8498\n","\n","Epoch 00195: val_accuracy did not improve from 0.93103\n","Epoch 196/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0932 - accuracy: 0.9787 - val_loss: 0.8506 - val_accuracy: 0.8522\n","\n","Epoch 00196: val_accuracy did not improve from 0.93103\n","Epoch 197/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0463 - accuracy: 0.9829 - val_loss: 0.6677 - val_accuracy: 0.8768\n","\n","Epoch 00197: val_accuracy did not improve from 0.93103\n","Epoch 198/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.5678 - val_accuracy: 0.8990\n","\n","Epoch 00198: val_accuracy did not improve from 0.93103\n","Epoch 199/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0567 - accuracy: 0.9842 - val_loss: 0.7133 - val_accuracy: 0.8744\n","\n","Epoch 00199: val_accuracy did not improve from 0.93103\n","Epoch 200/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0303 - accuracy: 0.9884 - val_loss: 0.6032 - val_accuracy: 0.8818\n","\n","Epoch 00200: val_accuracy did not improve from 0.93103\n","Epoch 201/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.6693 - val_accuracy: 0.8818\n","\n","Epoch 00201: val_accuracy did not improve from 0.93103\n","Epoch 202/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.4222 - val_accuracy: 0.9039\n","\n","Epoch 00202: val_accuracy did not improve from 0.93103\n","Epoch 203/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9089\n","\n","Epoch 00203: val_accuracy did not improve from 0.93103\n","Epoch 204/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0376 - accuracy: 0.9890 - val_loss: 0.8793 - val_accuracy: 0.8571\n","\n","Epoch 00204: val_accuracy did not improve from 0.93103\n","Epoch 205/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.6642 - val_accuracy: 0.8842\n","\n","Epoch 00205: val_accuracy did not improve from 0.93103\n","Epoch 206/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.5829 - val_accuracy: 0.8966\n","\n","Epoch 00206: val_accuracy did not improve from 0.93103\n","Epoch 207/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.6034 - val_accuracy: 0.8818\n","\n","Epoch 00207: val_accuracy did not improve from 0.93103\n","Epoch 208/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.6661 - val_accuracy: 0.8867\n","\n","Epoch 00208: val_accuracy did not improve from 0.93103\n","Epoch 209/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.5883 - val_accuracy: 0.8941\n","\n","Epoch 00209: val_accuracy did not improve from 0.93103\n","Epoch 210/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5221 - val_accuracy: 0.9113\n","\n","Epoch 00210: val_accuracy did not improve from 0.93103\n","Epoch 211/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5887 - val_accuracy: 0.8990\n","\n","Epoch 00211: val_accuracy did not improve from 0.93103\n","Epoch 212/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5532 - val_accuracy: 0.9039\n","\n","Epoch 00212: val_accuracy did not improve from 0.93103\n","Epoch 213/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.6273 - val_accuracy: 0.8867\n","\n","Epoch 00213: val_accuracy did not improve from 0.93103\n","Epoch 214/500\n","52/52 [==============================] - 13s 244ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5404 - val_accuracy: 0.9089\n","\n","Epoch 00214: val_accuracy did not improve from 0.93103\n","Epoch 215/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.6229 - val_accuracy: 0.8768\n","\n","Epoch 00215: val_accuracy did not improve from 0.93103\n","Epoch 216/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.6341 - val_accuracy: 0.8990\n","\n","Epoch 00216: val_accuracy did not improve from 0.93103\n","Epoch 217/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.5791 - val_accuracy: 0.8744\n","\n","Epoch 00217: val_accuracy did not improve from 0.93103\n","Epoch 218/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6753 - val_accuracy: 0.8892\n","\n","Epoch 00218: val_accuracy did not improve from 0.93103\n","Epoch 219/500\n","52/52 [==============================] - 13s 245ms/step - loss: 6.5818e-04 - accuracy: 1.0000 - val_loss: 0.6310 - val_accuracy: 0.8793\n","\n","Epoch 00219: val_accuracy did not improve from 0.93103\n","Epoch 220/500\n","52/52 [==============================] - 13s 246ms/step - loss: 4.6089e-04 - accuracy: 1.0000 - val_loss: 0.5609 - val_accuracy: 0.9064\n","\n","Epoch 00220: val_accuracy did not improve from 0.93103\n","Epoch 221/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5821 - val_accuracy: 0.8941\n","\n","Epoch 00221: val_accuracy did not improve from 0.93103\n","Epoch 222/500\n","52/52 [==============================] - 13s 248ms/step - loss: 6.1761e-04 - accuracy: 1.0000 - val_loss: 0.5590 - val_accuracy: 0.8966\n","\n","Epoch 00222: val_accuracy did not improve from 0.93103\n","Epoch 223/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.6475 - val_accuracy: 0.8818\n","\n","Epoch 00223: val_accuracy did not improve from 0.93103\n","Epoch 224/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0487 - accuracy: 0.9817 - val_loss: 1.0139 - val_accuracy: 0.8350\n","\n","Epoch 00224: val_accuracy did not improve from 0.93103\n","Epoch 225/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0724 - accuracy: 0.9781 - val_loss: 0.8982 - val_accuracy: 0.8498\n","\n","Epoch 00225: val_accuracy did not improve from 0.93103\n","Epoch 226/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0882 - accuracy: 0.9714 - val_loss: 3.4131 - val_accuracy: 0.6330\n","\n","Epoch 00226: val_accuracy did not improve from 0.93103\n","Epoch 227/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0864 - accuracy: 0.9744 - val_loss: 0.8496 - val_accuracy: 0.8522\n","\n","Epoch 00227: val_accuracy did not improve from 0.93103\n","Epoch 228/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0532 - accuracy: 0.9823 - val_loss: 1.6699 - val_accuracy: 0.7438\n","\n","Epoch 00228: val_accuracy did not improve from 0.93103\n","Epoch 229/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.5707 - val_accuracy: 0.8941\n","\n","Epoch 00229: val_accuracy did not improve from 0.93103\n","Epoch 230/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.5608 - val_accuracy: 0.8892\n","\n","Epoch 00230: val_accuracy did not improve from 0.93103\n","Epoch 231/500\n","52/52 [==============================] - 14s 268ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5448 - val_accuracy: 0.9064\n","\n","Epoch 00231: val_accuracy did not improve from 0.93103\n","Epoch 232/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.6535 - val_accuracy: 0.8793\n","\n","Epoch 00232: val_accuracy did not improve from 0.93103\n","Epoch 233/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0677 - accuracy: 0.9805 - val_loss: 0.6716 - val_accuracy: 0.8892\n","\n","Epoch 00233: val_accuracy did not improve from 0.93103\n","Epoch 234/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0189 - accuracy: 0.9957 - val_loss: 0.5698 - val_accuracy: 0.8719\n","\n","Epoch 00234: val_accuracy did not improve from 0.93103\n","Epoch 235/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.3826 - val_accuracy: 0.9113\n","\n","Epoch 00235: val_accuracy did not improve from 0.93103\n","Epoch 236/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4506 - val_accuracy: 0.9163\n","\n","Epoch 00236: val_accuracy did not improve from 0.93103\n","Epoch 237/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.6342 - val_accuracy: 0.8768\n","\n","Epoch 00237: val_accuracy did not improve from 0.93103\n","Epoch 238/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5998 - val_accuracy: 0.8768\n","\n","Epoch 00238: val_accuracy did not improve from 0.93103\n","Epoch 239/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.5242 - val_accuracy: 0.9039\n","\n","Epoch 00239: val_accuracy did not improve from 0.93103\n","Epoch 240/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.6580 - val_accuracy: 0.8768\n","\n","Epoch 00240: val_accuracy did not improve from 0.93103\n","Epoch 241/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.7579 - val_accuracy: 0.8719\n","\n","Epoch 00241: val_accuracy did not improve from 0.93103\n","Epoch 242/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.5733 - val_accuracy: 0.8744\n","\n","Epoch 00242: val_accuracy did not improve from 0.93103\n","Epoch 243/500\n","52/52 [==============================] - 13s 250ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.5744 - val_accuracy: 0.8990\n","\n","Epoch 00243: val_accuracy did not improve from 0.93103\n","Epoch 244/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.4979 - val_accuracy: 0.8941\n","\n","Epoch 00244: val_accuracy did not improve from 0.93103\n","Epoch 245/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.5489 - val_accuracy: 0.8867\n","\n","Epoch 00245: val_accuracy did not improve from 0.93103\n","Epoch 246/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.4613 - val_accuracy: 0.9039\n","\n","Epoch 00246: val_accuracy did not improve from 0.93103\n","Epoch 247/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4816 - val_accuracy: 0.9163\n","\n","Epoch 00247: val_accuracy did not improve from 0.93103\n","Epoch 248/500\n","52/52 [==============================] - 13s 250ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.9138\n","\n","Epoch 00248: val_accuracy did not improve from 0.93103\n","Epoch 249/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4540 - val_accuracy: 0.9064\n","\n","Epoch 00249: val_accuracy did not improve from 0.93103\n","Epoch 250/500\n","52/52 [==============================] - 13s 249ms/step - loss: 7.8504e-04 - accuracy: 1.0000 - val_loss: 0.3837 - val_accuracy: 0.9360\n","\n","Epoch 00250: val_accuracy improved from 0.93103 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5\n","Epoch 251/500\n","52/52 [==============================] - 13s 251ms/step - loss: 4.2361e-04 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.9138\n","\n","Epoch 00251: val_accuracy did not improve from 0.93596\n","Epoch 252/500\n","52/52 [==============================] - 13s 251ms/step - loss: 7.0247e-04 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.9138\n","\n","Epoch 00252: val_accuracy did not improve from 0.93596\n","Epoch 253/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.4339 - val_accuracy: 0.9138\n","\n","Epoch 00253: val_accuracy did not improve from 0.93596\n","Epoch 254/500\n","52/52 [==============================] - 13s 250ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.4999 - val_accuracy: 0.9064\n","\n","Epoch 00254: val_accuracy did not improve from 0.93596\n","Epoch 255/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4876 - val_accuracy: 0.8941\n","\n","Epoch 00255: val_accuracy did not improve from 0.93596\n","Epoch 256/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5029 - val_accuracy: 0.9187\n","\n","Epoch 00256: val_accuracy did not improve from 0.93596\n","Epoch 257/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.8309 - val_accuracy: 0.8596\n","\n","Epoch 00257: val_accuracy did not improve from 0.93596\n","Epoch 258/500\n","52/52 [==============================] - 13s 250ms/step - loss: 0.1065 - accuracy: 0.9708 - val_loss: 2.4037 - val_accuracy: 0.7020\n","\n","Epoch 00258: val_accuracy did not improve from 0.93596\n","Epoch 259/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0724 - accuracy: 0.9781 - val_loss: 1.0472 - val_accuracy: 0.8374\n","\n","Epoch 00259: val_accuracy did not improve from 0.93596\n","Epoch 260/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0891 - accuracy: 0.9781 - val_loss: 1.0688 - val_accuracy: 0.8300\n","\n","Epoch 00260: val_accuracy did not improve from 0.93596\n","Epoch 261/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0685 - accuracy: 0.9781 - val_loss: 0.8470 - val_accuracy: 0.8547\n","\n","Epoch 00261: val_accuracy did not improve from 0.93596\n","Epoch 262/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0227 - accuracy: 0.9945 - val_loss: 0.6317 - val_accuracy: 0.8941\n","\n","Epoch 00262: val_accuracy did not improve from 0.93596\n","Epoch 263/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.4449 - val_accuracy: 0.9089\n","\n","Epoch 00263: val_accuracy did not improve from 0.93596\n","Epoch 264/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0163 - accuracy: 0.9927 - val_loss: 0.5716 - val_accuracy: 0.8990\n","\n","Epoch 00264: val_accuracy did not improve from 0.93596\n","Epoch 265/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.4828 - val_accuracy: 0.9236\n","\n","Epoch 00265: val_accuracy did not improve from 0.93596\n","Epoch 266/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.5100 - val_accuracy: 0.9187\n","\n","Epoch 00266: val_accuracy did not improve from 0.93596\n","Epoch 267/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0130 - accuracy: 0.9945 - val_loss: 0.7591 - val_accuracy: 0.8645\n","\n","Epoch 00267: val_accuracy did not improve from 0.93596\n","Epoch 268/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.4941 - val_accuracy: 0.8990\n","\n","Epoch 00268: val_accuracy did not improve from 0.93596\n","Epoch 269/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.9212\n","\n","Epoch 00269: val_accuracy did not improve from 0.93596\n","Epoch 270/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 0.4826 - val_accuracy: 0.9212\n","\n","Epoch 00270: val_accuracy did not improve from 0.93596\n","Epoch 271/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4660 - val_accuracy: 0.9064\n","\n","Epoch 00271: val_accuracy did not improve from 0.93596\n","Epoch 272/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4253 - val_accuracy: 0.9236\n","\n","Epoch 00272: val_accuracy did not improve from 0.93596\n","Epoch 273/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.9113\n","\n","Epoch 00273: val_accuracy did not improve from 0.93596\n","Epoch 274/500\n","52/52 [==============================] - 13s 246ms/step - loss: 5.6660e-04 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9310\n","\n","Epoch 00274: val_accuracy did not improve from 0.93596\n","Epoch 275/500\n","52/52 [==============================] - 13s 249ms/step - loss: 4.9679e-04 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9212\n","\n","Epoch 00275: val_accuracy did not improve from 0.93596\n","Epoch 276/500\n","52/52 [==============================] - 13s 246ms/step - loss: 9.3149e-04 - accuracy: 0.9994 - val_loss: 0.4755 - val_accuracy: 0.9113\n","\n","Epoch 00276: val_accuracy did not improve from 0.93596\n","Epoch 277/500\n","52/52 [==============================] - 13s 247ms/step - loss: 5.8731e-04 - accuracy: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.9064\n","\n","Epoch 00277: val_accuracy did not improve from 0.93596\n","Epoch 278/500\n","52/52 [==============================] - 13s 249ms/step - loss: 5.1490e-04 - accuracy: 1.0000 - val_loss: 0.4278 - val_accuracy: 0.9310\n","\n","Epoch 00278: val_accuracy did not improve from 0.93596\n","Epoch 279/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9113\n","\n","Epoch 00279: val_accuracy did not improve from 0.93596\n","Epoch 280/500\n","52/52 [==============================] - 13s 247ms/step - loss: 4.1097e-04 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9163\n","\n","Epoch 00280: val_accuracy did not improve from 0.93596\n","Epoch 281/500\n","52/52 [==============================] - 13s 246ms/step - loss: 3.3399e-04 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.9212\n","\n","Epoch 00281: val_accuracy did not improve from 0.93596\n","Epoch 282/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 1.4298 - val_accuracy: 0.7759\n","\n","Epoch 00282: val_accuracy did not improve from 0.93596\n","Epoch 283/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0483 - accuracy: 0.9811 - val_loss: 1.3294 - val_accuracy: 0.7783\n","\n","Epoch 00283: val_accuracy did not improve from 0.93596\n","Epoch 284/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0651 - accuracy: 0.9817 - val_loss: 1.2549 - val_accuracy: 0.8424\n","\n","Epoch 00284: val_accuracy did not improve from 0.93596\n","Epoch 285/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.9422 - val_accuracy: 0.8522\n","\n","Epoch 00285: val_accuracy did not improve from 0.93596\n","Epoch 286/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.7925 - val_accuracy: 0.8842\n","\n","Epoch 00286: val_accuracy did not improve from 0.93596\n","Epoch 287/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.7365 - val_accuracy: 0.8719\n","\n","Epoch 00287: val_accuracy did not improve from 0.93596\n","Epoch 288/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.5732 - val_accuracy: 0.8892\n","\n","Epoch 00288: val_accuracy did not improve from 0.93596\n","Epoch 289/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.5608 - val_accuracy: 0.8966\n","\n","Epoch 00289: val_accuracy did not improve from 0.93596\n","Epoch 290/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0349 - accuracy: 0.9915 - val_loss: 0.7678 - val_accuracy: 0.8522\n","\n","Epoch 00290: val_accuracy did not improve from 0.93596\n","Epoch 291/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.6427 - val_accuracy: 0.8645\n","\n","Epoch 00291: val_accuracy did not improve from 0.93596\n","Epoch 292/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.4583 - val_accuracy: 0.8990\n","\n","Epoch 00292: val_accuracy did not improve from 0.93596\n","Epoch 293/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.6739 - val_accuracy: 0.8842\n","\n","Epoch 00293: val_accuracy did not improve from 0.93596\n","Epoch 294/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.5105 - val_accuracy: 0.9113\n","\n","Epoch 00294: val_accuracy did not improve from 0.93596\n","Epoch 295/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.4276 - val_accuracy: 0.8990\n","\n","Epoch 00295: val_accuracy did not improve from 0.93596\n","Epoch 296/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9113\n","\n","Epoch 00296: val_accuracy did not improve from 0.93596\n","Epoch 297/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.6220 - val_accuracy: 0.8793\n","\n","Epoch 00297: val_accuracy did not improve from 0.93596\n","Epoch 298/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.4660 - val_accuracy: 0.9138\n","\n","Epoch 00298: val_accuracy did not improve from 0.93596\n","Epoch 299/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5049 - val_accuracy: 0.8892\n","\n","Epoch 00299: val_accuracy did not improve from 0.93596\n","Epoch 300/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4332 - val_accuracy: 0.9163\n","\n","Epoch 00300: val_accuracy did not improve from 0.93596\n","Epoch 301/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4826 - val_accuracy: 0.9163\n","\n","Epoch 00301: val_accuracy did not improve from 0.93596\n","Epoch 302/500\n","52/52 [==============================] - 13s 248ms/step - loss: 4.9449e-04 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.9138\n","\n","Epoch 00302: val_accuracy did not improve from 0.93596\n","Epoch 303/500\n","52/52 [==============================] - 13s 247ms/step - loss: 4.6161e-04 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.9286\n","\n","Epoch 00303: val_accuracy did not improve from 0.93596\n","Epoch 304/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.9064\n","\n","Epoch 00304: val_accuracy did not improve from 0.93596\n","Epoch 305/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.4578 - val_accuracy: 0.9064\n","\n","Epoch 00305: val_accuracy did not improve from 0.93596\n","Epoch 306/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4827 - val_accuracy: 0.9138\n","\n","Epoch 00306: val_accuracy did not improve from 0.93596\n","Epoch 307/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.6317 - val_accuracy: 0.8941\n","\n","Epoch 00307: val_accuracy did not improve from 0.93596\n","Epoch 308/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.4805 - val_accuracy: 0.9212\n","\n","Epoch 00308: val_accuracy did not improve from 0.93596\n","Epoch 309/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0170 - accuracy: 0.9933 - val_loss: 0.6055 - val_accuracy: 0.8695\n","\n","Epoch 00309: val_accuracy did not improve from 0.93596\n","Epoch 310/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0887 - accuracy: 0.9744 - val_loss: 1.3860 - val_accuracy: 0.8005\n","\n","Epoch 00310: val_accuracy did not improve from 0.93596\n","Epoch 311/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0410 - accuracy: 0.9860 - val_loss: 0.8726 - val_accuracy: 0.8621\n","\n","Epoch 00311: val_accuracy did not improve from 0.93596\n","Epoch 312/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0172 - accuracy: 0.9933 - val_loss: 0.6632 - val_accuracy: 0.8695\n","\n","Epoch 00312: val_accuracy did not improve from 0.93596\n","Epoch 313/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.5944 - val_accuracy: 0.8744\n","\n","Epoch 00313: val_accuracy did not improve from 0.93596\n","Epoch 314/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.4542 - val_accuracy: 0.9064\n","\n","Epoch 00314: val_accuracy did not improve from 0.93596\n","Epoch 315/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.5981 - val_accuracy: 0.8842\n","\n","Epoch 00315: val_accuracy did not improve from 0.93596\n","Epoch 316/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4827 - val_accuracy: 0.9138\n","\n","Epoch 00316: val_accuracy did not improve from 0.93596\n","Epoch 317/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5415 - val_accuracy: 0.8966\n","\n","Epoch 00317: val_accuracy did not improve from 0.93596\n","Epoch 318/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4261 - val_accuracy: 0.9187\n","\n","Epoch 00318: val_accuracy did not improve from 0.93596\n","Epoch 319/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.5286 - val_accuracy: 0.9015\n","\n","Epoch 00319: val_accuracy did not improve from 0.93596\n","Epoch 320/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5907 - val_accuracy: 0.9089\n","\n","Epoch 00320: val_accuracy did not improve from 0.93596\n","Epoch 321/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.6249 - val_accuracy: 0.8966\n","\n","Epoch 00321: val_accuracy did not improve from 0.93596\n","Epoch 322/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.5282 - val_accuracy: 0.8990\n","\n","Epoch 00322: val_accuracy did not improve from 0.93596\n","Epoch 323/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0095 - accuracy: 0.9951 - val_loss: 0.6504 - val_accuracy: 0.8966\n","\n","Epoch 00323: val_accuracy did not improve from 0.93596\n","Epoch 324/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0388 - accuracy: 0.9915 - val_loss: 1.0219 - val_accuracy: 0.8498\n","\n","Epoch 00324: val_accuracy did not improve from 0.93596\n","Epoch 325/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.9350 - val_accuracy: 0.8744\n","\n","Epoch 00325: val_accuracy did not improve from 0.93596\n","Epoch 326/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.7274 - val_accuracy: 0.8793\n","\n","Epoch 00326: val_accuracy did not improve from 0.93596\n","Epoch 327/500\n","52/52 [==============================] - 13s 244ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.8883 - val_accuracy: 0.8276\n","\n","Epoch 00327: val_accuracy did not improve from 0.93596\n","Epoch 328/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.8144 - val_accuracy: 0.8571\n","\n","Epoch 00328: val_accuracy did not improve from 0.93596\n","Epoch 329/500\n","52/52 [==============================] - 13s 252ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.6997 - val_accuracy: 0.8990\n","\n","Epoch 00329: val_accuracy did not improve from 0.93596\n","Epoch 330/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0164 - accuracy: 0.9963 - val_loss: 0.9140 - val_accuracy: 0.8424\n","\n","Epoch 00330: val_accuracy did not improve from 0.93596\n","Epoch 331/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0572 - accuracy: 0.9854 - val_loss: 5.2249 - val_accuracy: 0.5320\n","\n","Epoch 00331: val_accuracy did not improve from 0.93596\n","Epoch 332/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0311 - accuracy: 0.9884 - val_loss: 1.1492 - val_accuracy: 0.8128\n","\n","Epoch 00332: val_accuracy did not improve from 0.93596\n","Epoch 333/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.6337 - val_accuracy: 0.8621\n","\n","Epoch 00333: val_accuracy did not improve from 0.93596\n","Epoch 334/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0093 - accuracy: 0.9988 - val_loss: 0.5386 - val_accuracy: 0.8892\n","\n","Epoch 00334: val_accuracy did not improve from 0.93596\n","Epoch 335/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5855 - val_accuracy: 0.8990\n","\n","Epoch 00335: val_accuracy did not improve from 0.93596\n","Epoch 336/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5100 - val_accuracy: 0.8990\n","\n","Epoch 00336: val_accuracy did not improve from 0.93596\n","Epoch 337/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.8990\n","\n","Epoch 00337: val_accuracy did not improve from 0.93596\n","Epoch 338/500\n","52/52 [==============================] - 13s 247ms/step - loss: 5.8731e-04 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.9039\n","\n","Epoch 00338: val_accuracy did not improve from 0.93596\n","Epoch 339/500\n","52/52 [==============================] - 13s 246ms/step - loss: 5.3454e-04 - accuracy: 1.0000 - val_loss: 0.5060 - val_accuracy: 0.9064\n","\n","Epoch 00339: val_accuracy did not improve from 0.93596\n","Epoch 340/500\n","52/52 [==============================] - 13s 247ms/step - loss: 5.4236e-04 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.9064\n","\n","Epoch 00340: val_accuracy did not improve from 0.93596\n","Epoch 341/500\n","52/52 [==============================] - 13s 249ms/step - loss: 8.6705e-04 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9089\n","\n","Epoch 00341: val_accuracy did not improve from 0.93596\n","Epoch 342/500\n","52/52 [==============================] - 13s 249ms/step - loss: 5.8650e-04 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.9015\n","\n","Epoch 00342: val_accuracy did not improve from 0.93596\n","Epoch 343/500\n","52/52 [==============================] - 13s 247ms/step - loss: 7.9491e-04 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.9039\n","\n","Epoch 00343: val_accuracy did not improve from 0.93596\n","Epoch 344/500\n","52/52 [==============================] - 13s 247ms/step - loss: 3.5856e-04 - accuracy: 1.0000 - val_loss: 0.5342 - val_accuracy: 0.8941\n","\n","Epoch 00344: val_accuracy did not improve from 0.93596\n","Epoch 345/500\n","52/52 [==============================] - 13s 246ms/step - loss: 3.9539e-04 - accuracy: 1.0000 - val_loss: 0.5308 - val_accuracy: 0.9039\n","\n","Epoch 00345: val_accuracy did not improve from 0.93596\n","Epoch 346/500\n","52/52 [==============================] - 13s 247ms/step - loss: 9.4945e-04 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.9138\n","\n","Epoch 00346: val_accuracy did not improve from 0.93596\n","Epoch 347/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5487 - val_accuracy: 0.9089\n","\n","Epoch 00347: val_accuracy did not improve from 0.93596\n","Epoch 348/500\n","52/52 [==============================] - 13s 246ms/step - loss: 5.4574e-04 - accuracy: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.9039\n","\n","Epoch 00348: val_accuracy did not improve from 0.93596\n","Epoch 349/500\n","52/52 [==============================] - 13s 246ms/step - loss: 5.3108e-04 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.9113\n","\n","Epoch 00349: val_accuracy did not improve from 0.93596\n","Epoch 350/500\n","52/52 [==============================] - 13s 245ms/step - loss: 3.0809e-04 - accuracy: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.9089\n","\n","Epoch 00350: val_accuracy did not improve from 0.93596\n","Epoch 351/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.2730e-04 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.9212\n","\n","Epoch 00351: val_accuracy did not improve from 0.93596\n","Epoch 352/500\n","52/52 [==============================] - 13s 248ms/step - loss: 3.0324e-04 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.9138\n","\n","Epoch 00352: val_accuracy did not improve from 0.93596\n","Epoch 353/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.5228 - val_accuracy: 0.9039\n","\n","Epoch 00353: val_accuracy did not improve from 0.93596\n","Epoch 354/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.5883 - val_accuracy: 0.8941\n","\n","Epoch 00354: val_accuracy did not improve from 0.93596\n","Epoch 355/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.5463 - val_accuracy: 0.8941\n","\n","Epoch 00355: val_accuracy did not improve from 0.93596\n","Epoch 356/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.8730 - val_accuracy: 0.8621\n","\n","Epoch 00356: val_accuracy did not improve from 0.93596\n","Epoch 357/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0259 - accuracy: 0.9890 - val_loss: 1.1878 - val_accuracy: 0.8547\n","\n","Epoch 00357: val_accuracy did not improve from 0.93596\n","Epoch 358/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0470 - accuracy: 0.9860 - val_loss: 0.9118 - val_accuracy: 0.8325\n","\n","Epoch 00358: val_accuracy did not improve from 0.93596\n","Epoch 359/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0362 - accuracy: 0.9890 - val_loss: 0.7541 - val_accuracy: 0.8547\n","\n","Epoch 00359: val_accuracy did not improve from 0.93596\n","Epoch 360/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0278 - accuracy: 0.9896 - val_loss: 0.5592 - val_accuracy: 0.9089\n","\n","Epoch 00360: val_accuracy did not improve from 0.93596\n","Epoch 361/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 0.5381 - val_accuracy: 0.9163\n","\n","Epoch 00361: val_accuracy did not improve from 0.93596\n","Epoch 362/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.8678 - val_accuracy: 0.8571\n","\n","Epoch 00362: val_accuracy did not improve from 0.93596\n","Epoch 363/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.6574 - val_accuracy: 0.8793\n","\n","Epoch 00363: val_accuracy did not improve from 0.93596\n","Epoch 364/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.5927 - val_accuracy: 0.9089\n","\n","Epoch 00364: val_accuracy did not improve from 0.93596\n","Epoch 365/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0098 - accuracy: 0.9957 - val_loss: 0.9622 - val_accuracy: 0.8448\n","\n","Epoch 00365: val_accuracy did not improve from 0.93596\n","Epoch 366/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.6168 - val_accuracy: 0.8744\n","\n","Epoch 00366: val_accuracy did not improve from 0.93596\n","Epoch 367/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0203 - accuracy: 0.9921 - val_loss: 0.6607 - val_accuracy: 0.8719\n","\n","Epoch 00367: val_accuracy did not improve from 0.93596\n","Epoch 368/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.6189 - val_accuracy: 0.8990\n","\n","Epoch 00368: val_accuracy did not improve from 0.93596\n","Epoch 369/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.6041 - val_accuracy: 0.8719\n","\n","Epoch 00369: val_accuracy did not improve from 0.93596\n","Epoch 370/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.4955 - val_accuracy: 0.9039\n","\n","Epoch 00370: val_accuracy did not improve from 0.93596\n","Epoch 371/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.6671 - val_accuracy: 0.8892\n","\n","Epoch 00371: val_accuracy did not improve from 0.93596\n","Epoch 372/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.5745 - val_accuracy: 0.9089\n","\n","Epoch 00372: val_accuracy did not improve from 0.93596\n","Epoch 373/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.4936 - val_accuracy: 0.9039\n","\n","Epoch 00373: val_accuracy did not improve from 0.93596\n","Epoch 374/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.6334 - val_accuracy: 0.8768\n","\n","Epoch 00374: val_accuracy did not improve from 0.93596\n","Epoch 375/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0652 - accuracy: 0.9829 - val_loss: 0.9786 - val_accuracy: 0.8424\n","\n","Epoch 00375: val_accuracy did not improve from 0.93596\n","Epoch 376/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0284 - accuracy: 0.9915 - val_loss: 0.7657 - val_accuracy: 0.8695\n","\n","Epoch 00376: val_accuracy did not improve from 0.93596\n","Epoch 377/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.7081 - val_accuracy: 0.8818\n","\n","Epoch 00377: val_accuracy did not improve from 0.93596\n","Epoch 378/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.6206 - val_accuracy: 0.8966\n","\n","Epoch 00378: val_accuracy did not improve from 0.93596\n","Epoch 379/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.6033 - val_accuracy: 0.8916\n","\n","Epoch 00379: val_accuracy did not improve from 0.93596\n","Epoch 380/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0042 - accuracy: 0.9976 - val_loss: 0.5208 - val_accuracy: 0.8990\n","\n","Epoch 00380: val_accuracy did not improve from 0.93596\n","Epoch 381/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.6411 - val_accuracy: 0.8892\n","\n","Epoch 00381: val_accuracy did not improve from 0.93596\n","Epoch 382/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0222 - accuracy: 0.9939 - val_loss: 0.5595 - val_accuracy: 0.9089\n","\n","Epoch 00382: val_accuracy did not improve from 0.93596\n","Epoch 383/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.8429 - val_accuracy: 0.8793\n","\n","Epoch 00383: val_accuracy did not improve from 0.93596\n","Epoch 384/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.6034 - val_accuracy: 0.9015\n","\n","Epoch 00384: val_accuracy did not improve from 0.93596\n","Epoch 385/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5321 - val_accuracy: 0.9089\n","\n","Epoch 00385: val_accuracy did not improve from 0.93596\n","Epoch 386/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4656 - val_accuracy: 0.9064\n","\n","Epoch 00386: val_accuracy did not improve from 0.93596\n","Epoch 387/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.6285 - val_accuracy: 0.8768\n","\n","Epoch 00387: val_accuracy did not improve from 0.93596\n","Epoch 388/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0204 - accuracy: 0.9915 - val_loss: 0.5721 - val_accuracy: 0.8842\n","\n","Epoch 00388: val_accuracy did not improve from 0.93596\n","Epoch 389/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.5794 - val_accuracy: 0.8768\n","\n","Epoch 00389: val_accuracy did not improve from 0.93596\n","Epoch 390/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0263 - accuracy: 0.9945 - val_loss: 0.6234 - val_accuracy: 0.8941\n","\n","Epoch 00390: val_accuracy did not improve from 0.93596\n","Epoch 391/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.5636 - val_accuracy: 0.8916\n","\n","Epoch 00391: val_accuracy did not improve from 0.93596\n","Epoch 392/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.9212\n","\n","Epoch 00392: val_accuracy did not improve from 0.93596\n","Epoch 393/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3698 - val_accuracy: 0.9286\n","\n","Epoch 00393: val_accuracy did not improve from 0.93596\n","Epoch 394/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5160 - val_accuracy: 0.8966\n","\n","Epoch 00394: val_accuracy did not improve from 0.93596\n","Epoch 395/500\n","52/52 [==============================] - 13s 246ms/step - loss: 6.5921e-04 - accuracy: 1.0000 - val_loss: 0.4855 - val_accuracy: 0.9212\n","\n","Epoch 00395: val_accuracy did not improve from 0.93596\n","Epoch 396/500\n","52/52 [==============================] - 13s 246ms/step - loss: 4.9921e-04 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9163\n","\n","Epoch 00396: val_accuracy did not improve from 0.93596\n","Epoch 397/500\n","52/52 [==============================] - 13s 248ms/step - loss: 3.8736e-04 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9039\n","\n","Epoch 00397: val_accuracy did not improve from 0.93596\n","Epoch 398/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.2889e-04 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9138\n","\n","Epoch 00398: val_accuracy did not improve from 0.93596\n","Epoch 399/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4706 - val_accuracy: 0.9039\n","\n","Epoch 00399: val_accuracy did not improve from 0.93596\n","Epoch 400/500\n","52/52 [==============================] - 13s 246ms/step - loss: 2.7804e-04 - accuracy: 1.0000 - val_loss: 0.3959 - val_accuracy: 0.9163\n","\n","Epoch 00400: val_accuracy did not improve from 0.93596\n","Epoch 401/500\n","52/52 [==============================] - 13s 245ms/step - loss: 5.0685e-04 - accuracy: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.9212\n","\n","Epoch 00401: val_accuracy did not improve from 0.93596\n","Epoch 402/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.5900 - val_accuracy: 0.8842\n","\n","Epoch 00402: val_accuracy did not improve from 0.93596\n","Epoch 403/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4675 - val_accuracy: 0.9236\n","\n","Epoch 00403: val_accuracy did not improve from 0.93596\n","Epoch 404/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5059 - val_accuracy: 0.9039\n","\n","Epoch 00404: val_accuracy did not improve from 0.93596\n","Epoch 405/500\n","52/52 [==============================] - 13s 245ms/step - loss: 4.8533e-04 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9187\n","\n","Epoch 00405: val_accuracy did not improve from 0.93596\n","Epoch 406/500\n","52/52 [==============================] - 13s 246ms/step - loss: 3.9930e-04 - accuracy: 1.0000 - val_loss: 0.4591 - val_accuracy: 0.9187\n","\n","Epoch 00406: val_accuracy did not improve from 0.93596\n","Epoch 407/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4986 - val_accuracy: 0.9163\n","\n","Epoch 00407: val_accuracy did not improve from 0.93596\n","Epoch 408/500\n","52/52 [==============================] - 13s 248ms/step - loss: 9.8452e-04 - accuracy: 1.0000 - val_loss: 0.5292 - val_accuracy: 0.9113\n","\n","Epoch 00408: val_accuracy did not improve from 0.93596\n","Epoch 409/500\n","52/52 [==============================] - 13s 247ms/step - loss: 3.4825e-04 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.9089\n","\n","Epoch 00409: val_accuracy did not improve from 0.93596\n","Epoch 410/500\n","52/52 [==============================] - 13s 248ms/step - loss: 4.9216e-04 - accuracy: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.9138\n","\n","Epoch 00410: val_accuracy did not improve from 0.93596\n","Epoch 411/500\n","52/52 [==============================] - 13s 250ms/step - loss: 4.5610e-04 - accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.9015\n","\n","Epoch 00411: val_accuracy did not improve from 0.93596\n","Epoch 412/500\n","52/52 [==============================] - 13s 246ms/step - loss: 3.4089e-04 - accuracy: 1.0000 - val_loss: 0.5288 - val_accuracy: 0.9163\n","\n","Epoch 00412: val_accuracy did not improve from 0.93596\n","Epoch 413/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6499 - val_accuracy: 0.9039\n","\n","Epoch 00413: val_accuracy did not improve from 0.93596\n","Epoch 414/500\n","52/52 [==============================] - 13s 247ms/step - loss: 6.3122e-04 - accuracy: 1.0000 - val_loss: 0.5621 - val_accuracy: 0.9015\n","\n","Epoch 00414: val_accuracy did not improve from 0.93596\n","Epoch 415/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.8442e-04 - accuracy: 1.0000 - val_loss: 0.5428 - val_accuracy: 0.9015\n","\n","Epoch 00415: val_accuracy did not improve from 0.93596\n","Epoch 416/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.8633 - val_accuracy: 0.8818\n","\n","Epoch 00416: val_accuracy did not improve from 0.93596\n","Epoch 417/500\n","52/52 [==============================] - 13s 245ms/step - loss: 0.0630 - accuracy: 0.9775 - val_loss: 1.4821 - val_accuracy: 0.8300\n","\n","Epoch 00417: val_accuracy did not improve from 0.93596\n","Epoch 418/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 1.1419 - val_accuracy: 0.8399\n","\n","Epoch 00418: val_accuracy did not improve from 0.93596\n","Epoch 419/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.7326 - val_accuracy: 0.8695\n","\n","Epoch 00419: val_accuracy did not improve from 0.93596\n","Epoch 420/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 0.7669 - val_accuracy: 0.8670\n","\n","Epoch 00420: val_accuracy did not improve from 0.93596\n","Epoch 421/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.7989 - val_accuracy: 0.8596\n","\n","Epoch 00421: val_accuracy did not improve from 0.93596\n","Epoch 422/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.5186 - val_accuracy: 0.8941\n","\n","Epoch 00422: val_accuracy did not improve from 0.93596\n","Epoch 423/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5212 - val_accuracy: 0.8916\n","\n","Epoch 00423: val_accuracy did not improve from 0.93596\n","Epoch 424/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.5892 - val_accuracy: 0.8966\n","\n","Epoch 00424: val_accuracy did not improve from 0.93596\n","Epoch 425/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0396 - accuracy: 0.9884 - val_loss: 1.1658 - val_accuracy: 0.8177\n","\n","Epoch 00425: val_accuracy did not improve from 0.93596\n","Epoch 426/500\n","52/52 [==============================] - 13s 250ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.7811 - val_accuracy: 0.8571\n","\n","Epoch 00426: val_accuracy did not improve from 0.93596\n","Epoch 427/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.5077 - val_accuracy: 0.8941\n","\n","Epoch 00427: val_accuracy did not improve from 0.93596\n","Epoch 428/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.5733 - val_accuracy: 0.9089\n","\n","Epoch 00428: val_accuracy did not improve from 0.93596\n","Epoch 429/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.9233 - val_accuracy: 0.8153\n","\n","Epoch 00429: val_accuracy did not improve from 0.93596\n","Epoch 430/500\n","52/52 [==============================] - 13s 251ms/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.6035 - val_accuracy: 0.8596\n","\n","Epoch 00430: val_accuracy did not improve from 0.93596\n","Epoch 431/500\n","52/52 [==============================] - 13s 250ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.5172 - val_accuracy: 0.9015\n","\n","Epoch 00431: val_accuracy did not improve from 0.93596\n","Epoch 432/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.6041 - val_accuracy: 0.8990\n","\n","Epoch 00432: val_accuracy did not improve from 0.93596\n","Epoch 433/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.6544 - val_accuracy: 0.8966\n","\n","Epoch 00433: val_accuracy did not improve from 0.93596\n","Epoch 434/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.8495 - val_accuracy: 0.8744\n","\n","Epoch 00434: val_accuracy did not improve from 0.93596\n","Epoch 435/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.8145 - val_accuracy: 0.8695\n","\n","Epoch 00435: val_accuracy did not improve from 0.93596\n","Epoch 436/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.9593 - val_accuracy: 0.8448\n","\n","Epoch 00436: val_accuracy did not improve from 0.93596\n","Epoch 437/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.5199 - val_accuracy: 0.8867\n","\n","Epoch 00437: val_accuracy did not improve from 0.93596\n","Epoch 438/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0116 - accuracy: 0.9988 - val_loss: 0.6764 - val_accuracy: 0.8695\n","\n","Epoch 00438: val_accuracy did not improve from 0.93596\n","Epoch 439/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.6036 - val_accuracy: 0.8892\n","\n","Epoch 00439: val_accuracy did not improve from 0.93596\n","Epoch 440/500\n","52/52 [==============================] - 13s 247ms/step - loss: 6.0936e-04 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.9039\n","\n","Epoch 00440: val_accuracy did not improve from 0.93596\n","Epoch 441/500\n","52/52 [==============================] - 13s 248ms/step - loss: 7.2761e-04 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.9039\n","\n","Epoch 00441: val_accuracy did not improve from 0.93596\n","Epoch 442/500\n","52/52 [==============================] - 13s 248ms/step - loss: 9.4560e-04 - accuracy: 1.0000 - val_loss: 0.5559 - val_accuracy: 0.8941\n","\n","Epoch 00442: val_accuracy did not improve from 0.93596\n","Epoch 443/500\n","52/52 [==============================] - 13s 248ms/step - loss: 5.0443e-04 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.9138\n","\n","Epoch 00443: val_accuracy did not improve from 0.93596\n","Epoch 444/500\n","52/52 [==============================] - 13s 247ms/step - loss: 5.5330e-04 - accuracy: 1.0000 - val_loss: 0.5585 - val_accuracy: 0.9015\n","\n","Epoch 00444: val_accuracy did not improve from 0.93596\n","Epoch 445/500\n","52/52 [==============================] - 13s 247ms/step - loss: 3.6590e-04 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.9113\n","\n","Epoch 00445: val_accuracy did not improve from 0.93596\n","Epoch 446/500\n","52/52 [==============================] - 13s 246ms/step - loss: 5.1164e-04 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.9138\n","\n","Epoch 00446: val_accuracy did not improve from 0.93596\n","Epoch 447/500\n","52/52 [==============================] - 13s 247ms/step - loss: 1.6281e-04 - accuracy: 1.0000 - val_loss: 0.4509 - val_accuracy: 0.9015\n","\n","Epoch 00447: val_accuracy did not improve from 0.93596\n","Epoch 448/500\n","52/52 [==============================] - 13s 250ms/step - loss: 6.1435e-04 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.9163\n","\n","Epoch 00448: val_accuracy did not improve from 0.93596\n","Epoch 449/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.4046e-04 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9163\n","\n","Epoch 00449: val_accuracy did not improve from 0.93596\n","Epoch 450/500\n","52/52 [==============================] - 13s 247ms/step - loss: 3.7158e-04 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9236\n","\n","Epoch 00450: val_accuracy did not improve from 0.93596\n","Epoch 451/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.7305 - val_accuracy: 0.8941\n","\n","Epoch 00451: val_accuracy did not improve from 0.93596\n","Epoch 452/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0191 - accuracy: 0.9970 - val_loss: 0.9891 - val_accuracy: 0.8424\n","\n","Epoch 00452: val_accuracy did not improve from 0.93596\n","Epoch 453/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.6713 - val_accuracy: 0.8695\n","\n","Epoch 00453: val_accuracy did not improve from 0.93596\n","Epoch 454/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.5917 - val_accuracy: 0.8941\n","\n","Epoch 00454: val_accuracy did not improve from 0.93596\n","Epoch 455/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.7174 - val_accuracy: 0.8670\n","\n","Epoch 00455: val_accuracy did not improve from 0.93596\n","Epoch 456/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.5091 - val_accuracy: 0.8719\n","\n","Epoch 00456: val_accuracy did not improve from 0.93596\n","Epoch 457/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0097 - accuracy: 0.9957 - val_loss: 0.4618 - val_accuracy: 0.9089\n","\n","Epoch 00457: val_accuracy did not improve from 0.93596\n","Epoch 458/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.4267 - val_accuracy: 0.9163\n","\n","Epoch 00458: val_accuracy did not improve from 0.93596\n","Epoch 459/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.4120 - val_accuracy: 0.9212\n","\n","Epoch 00459: val_accuracy did not improve from 0.93596\n","Epoch 460/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4577 - val_accuracy: 0.9039\n","\n","Epoch 00460: val_accuracy did not improve from 0.93596\n","Epoch 461/500\n","52/52 [==============================] - 13s 250ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.8688 - val_accuracy: 0.8695\n","\n","Epoch 00461: val_accuracy did not improve from 0.93596\n","Epoch 462/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0273 - accuracy: 0.9909 - val_loss: 0.9017 - val_accuracy: 0.8251\n","\n","Epoch 00462: val_accuracy did not improve from 0.93596\n","Epoch 463/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0332 - accuracy: 0.9866 - val_loss: 0.7982 - val_accuracy: 0.8571\n","\n","Epoch 00463: val_accuracy did not improve from 0.93596\n","Epoch 464/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.5568 - val_accuracy: 0.9089\n","\n","Epoch 00464: val_accuracy did not improve from 0.93596\n","Epoch 465/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.5585 - val_accuracy: 0.8941\n","\n","Epoch 00465: val_accuracy did not improve from 0.93596\n","Epoch 466/500\n","52/52 [==============================] - 13s 250ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.5625 - val_accuracy: 0.9039\n","\n","Epoch 00466: val_accuracy did not improve from 0.93596\n","Epoch 467/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5233 - val_accuracy: 0.9138\n","\n","Epoch 00467: val_accuracy did not improve from 0.93596\n","Epoch 468/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.5670 - val_accuracy: 0.8941\n","\n","Epoch 00468: val_accuracy did not improve from 0.93596\n","Epoch 469/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.6649 - val_accuracy: 0.8744\n","\n","Epoch 00469: val_accuracy did not improve from 0.93596\n","Epoch 470/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.6748 - val_accuracy: 0.9015\n","\n","Epoch 00470: val_accuracy did not improve from 0.93596\n","Epoch 471/500\n","52/52 [==============================] - 13s 249ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.5116 - val_accuracy: 0.9138\n","\n","Epoch 00471: val_accuracy did not improve from 0.93596\n","Epoch 472/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 1.1621 - val_accuracy: 0.8621\n","\n","Epoch 00472: val_accuracy did not improve from 0.93596\n","Epoch 473/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0756 - accuracy: 0.9775 - val_loss: 0.8521 - val_accuracy: 0.8695\n","\n","Epoch 00473: val_accuracy did not improve from 0.93596\n","Epoch 474/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.7772 - val_accuracy: 0.8571\n","\n","Epoch 00474: val_accuracy did not improve from 0.93596\n","Epoch 475/500\n","52/52 [==============================] - 13s 250ms/step - loss: 6.4095e-04 - accuracy: 1.0000 - val_loss: 0.5713 - val_accuracy: 0.8966\n","\n","Epoch 00475: val_accuracy did not improve from 0.93596\n","Epoch 476/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.6292 - val_accuracy: 0.8818\n","\n","Epoch 00476: val_accuracy did not improve from 0.93596\n","Epoch 477/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.5295 - val_accuracy: 0.8966\n","\n","Epoch 00477: val_accuracy did not improve from 0.93596\n","Epoch 478/500\n","52/52 [==============================] - 13s 250ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.4606 - val_accuracy: 0.9089\n","\n","Epoch 00478: val_accuracy did not improve from 0.93596\n","Epoch 479/500\n","52/52 [==============================] - 13s 246ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5221 - val_accuracy: 0.9064\n","\n","Epoch 00479: val_accuracy did not improve from 0.93596\n","Epoch 480/500\n","52/52 [==============================] - 13s 250ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.8588 - val_accuracy: 0.8892\n","\n","Epoch 00480: val_accuracy did not improve from 0.93596\n","Epoch 481/500\n","52/52 [==============================] - 13s 250ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.6123 - val_accuracy: 0.8966\n","\n","Epoch 00481: val_accuracy did not improve from 0.93596\n","Epoch 482/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.7109 - val_accuracy: 0.9015\n","\n","Epoch 00482: val_accuracy did not improve from 0.93596\n","Epoch 483/500\n","52/52 [==============================] - 13s 251ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.8481 - val_accuracy: 0.8695\n","\n","Epoch 00483: val_accuracy did not improve from 0.93596\n","Epoch 484/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.6131 - val_accuracy: 0.8768\n","\n","Epoch 00484: val_accuracy did not improve from 0.93596\n","Epoch 485/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.6182 - val_accuracy: 0.9015\n","\n","Epoch 00485: val_accuracy did not improve from 0.93596\n","Epoch 486/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4815 - val_accuracy: 0.9064\n","\n","Epoch 00486: val_accuracy did not improve from 0.93596\n","Epoch 487/500\n","52/52 [==============================] - 13s 247ms/step - loss: 4.4485e-04 - accuracy: 1.0000 - val_loss: 0.5617 - val_accuracy: 0.9138\n","\n","Epoch 00487: val_accuracy did not improve from 0.93596\n","Epoch 488/500\n","52/52 [==============================] - 13s 250ms/step - loss: 8.5334e-04 - accuracy: 0.9994 - val_loss: 0.5583 - val_accuracy: 0.9089\n","\n","Epoch 00488: val_accuracy did not improve from 0.93596\n","Epoch 489/500\n","52/52 [==============================] - 13s 253ms/step - loss: 4.9860e-04 - accuracy: 1.0000 - val_loss: 0.5870 - val_accuracy: 0.9163\n","\n","Epoch 00489: val_accuracy did not improve from 0.93596\n","Epoch 490/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.6139 - val_accuracy: 0.9113\n","\n","Epoch 00490: val_accuracy did not improve from 0.93596\n","Epoch 491/500\n","52/52 [==============================] - 13s 247ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6760 - val_accuracy: 0.8916\n","\n","Epoch 00491: val_accuracy did not improve from 0.93596\n","Epoch 492/500\n","52/52 [==============================] - 13s 248ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.6638 - val_accuracy: 0.8916\n","\n","Epoch 00492: val_accuracy did not improve from 0.93596\n","Epoch 493/500\n","52/52 [==============================] - 13s 250ms/step - loss: 7.9850e-04 - accuracy: 1.0000 - val_loss: 0.5693 - val_accuracy: 0.9089\n","\n","Epoch 00493: val_accuracy did not improve from 0.93596\n","Epoch 494/500\n","52/52 [==============================] - 13s 249ms/step - loss: 3.8194e-04 - accuracy: 1.0000 - val_loss: 0.5482 - val_accuracy: 0.8941\n","\n","Epoch 00494: val_accuracy did not improve from 0.93596\n","Epoch 495/500\n","52/52 [==============================] - 13s 248ms/step - loss: 1.3386e-04 - accuracy: 1.0000 - val_loss: 0.5981 - val_accuracy: 0.9064\n","\n","Epoch 00495: val_accuracy did not improve from 0.93596\n","Epoch 496/500\n","52/52 [==============================] - 13s 248ms/step - loss: 2.5645e-04 - accuracy: 1.0000 - val_loss: 0.5439 - val_accuracy: 0.9113\n","\n","Epoch 00496: val_accuracy did not improve from 0.93596\n","Epoch 497/500\n","52/52 [==============================] - 13s 249ms/step - loss: 7.9232e-04 - accuracy: 0.9994 - val_loss: 0.5887 - val_accuracy: 0.9089\n","\n","Epoch 00497: val_accuracy did not improve from 0.93596\n","Epoch 498/500\n","52/52 [==============================] - 13s 249ms/step - loss: 2.2969e-04 - accuracy: 1.0000 - val_loss: 0.5732 - val_accuracy: 0.9089\n","\n","Epoch 00498: val_accuracy did not improve from 0.93596\n","Epoch 499/500\n","52/52 [==============================] - 13s 248ms/step - loss: 3.1509e-04 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 0.9039\n","\n","Epoch 00499: val_accuracy did not improve from 0.93596\n","Epoch 500/500\n","52/52 [==============================] - 13s 246ms/step - loss: 2.6328e-04 - accuracy: 1.0000 - val_loss: 0.5284 - val_accuracy: 0.9212\n","\n","Epoch 00500: val_accuracy did not improve from 0.93596\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff3ef23b450>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"pdc05G6CDCmp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628190267071,"user_tz":-540,"elapsed":8159034,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"a14db35a-80b0-4ffb-ca53-e14a3981f3a2"},"source":["DenseNet201_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[DenseNet201_checkpoint])\n","# files.download('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["52/52 [==============================] - 35s 370ms/step - loss: 1.9964 - accuracy: 0.3356 - val_loss: 8.6459 - val_accuracy: 0.1133\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.11330, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 2/500\n","52/52 [==============================] - 16s 305ms/step - loss: 1.2809 - accuracy: 0.5542 - val_loss: 82.2816 - val_accuracy: 0.1010\n","\n","Epoch 00002: val_accuracy did not improve from 0.11330\n","Epoch 3/500\n","52/52 [==============================] - 16s 304ms/step - loss: 1.0284 - accuracy: 0.6626 - val_loss: 16.8355 - val_accuracy: 0.0936\n","\n","Epoch 00003: val_accuracy did not improve from 0.11330\n","Epoch 4/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.8122 - accuracy: 0.7296 - val_loss: 10.7464 - val_accuracy: 0.0961\n","\n","Epoch 00004: val_accuracy did not improve from 0.11330\n","Epoch 5/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.8486 - accuracy: 0.7162 - val_loss: 8.8402 - val_accuracy: 0.1995\n","\n","Epoch 00005: val_accuracy improved from 0.11330 to 0.19951, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 6/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.6767 - accuracy: 0.7759 - val_loss: 12.7705 - val_accuracy: 0.1650\n","\n","Epoch 00006: val_accuracy did not improve from 0.19951\n","Epoch 7/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.6376 - accuracy: 0.7795 - val_loss: 8.9215 - val_accuracy: 0.1700\n","\n","Epoch 00007: val_accuracy did not improve from 0.19951\n","Epoch 8/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.5431 - accuracy: 0.8118 - val_loss: 6.1482 - val_accuracy: 0.3448\n","\n","Epoch 00008: val_accuracy improved from 0.19951 to 0.34483, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 9/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.5499 - accuracy: 0.8051 - val_loss: 1.7968 - val_accuracy: 0.5640\n","\n","Epoch 00009: val_accuracy improved from 0.34483 to 0.56404, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 10/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.5075 - accuracy: 0.8356 - val_loss: 1.5465 - val_accuracy: 0.6034\n","\n","Epoch 00010: val_accuracy improved from 0.56404 to 0.60345, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 11/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.4433 - accuracy: 0.8465 - val_loss: 3.2564 - val_accuracy: 0.4754\n","\n","Epoch 00011: val_accuracy did not improve from 0.60345\n","Epoch 12/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.4279 - accuracy: 0.8599 - val_loss: 0.8534 - val_accuracy: 0.7783\n","\n","Epoch 00012: val_accuracy improved from 0.60345 to 0.77833, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 13/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.3723 - accuracy: 0.8709 - val_loss: 1.1929 - val_accuracy: 0.7020\n","\n","Epoch 00013: val_accuracy did not improve from 0.77833\n","Epoch 14/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.3464 - accuracy: 0.8776 - val_loss: 1.3429 - val_accuracy: 0.7020\n","\n","Epoch 00014: val_accuracy did not improve from 0.77833\n","Epoch 15/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.3905 - accuracy: 0.8666 - val_loss: 2.3817 - val_accuracy: 0.5985\n","\n","Epoch 00015: val_accuracy did not improve from 0.77833\n","Epoch 16/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.3089 - accuracy: 0.8977 - val_loss: 0.9886 - val_accuracy: 0.7537\n","\n","Epoch 00016: val_accuracy did not improve from 0.77833\n","Epoch 17/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.2926 - accuracy: 0.9001 - val_loss: 1.1905 - val_accuracy: 0.7143\n","\n","Epoch 00017: val_accuracy did not improve from 0.77833\n","Epoch 18/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.2831 - accuracy: 0.9026 - val_loss: 0.8449 - val_accuracy: 0.7734\n","\n","Epoch 00018: val_accuracy did not improve from 0.77833\n","Epoch 19/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.2989 - accuracy: 0.8977 - val_loss: 1.0087 - val_accuracy: 0.7685\n","\n","Epoch 00019: val_accuracy did not improve from 0.77833\n","Epoch 20/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.2827 - accuracy: 0.9135 - val_loss: 0.6457 - val_accuracy: 0.8079\n","\n","Epoch 00020: val_accuracy improved from 0.77833 to 0.80788, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 21/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1994 - accuracy: 0.9300 - val_loss: 0.5776 - val_accuracy: 0.8276\n","\n","Epoch 00021: val_accuracy improved from 0.80788 to 0.82759, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 22/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.2429 - accuracy: 0.9178 - val_loss: 0.8638 - val_accuracy: 0.8005\n","\n","Epoch 00022: val_accuracy did not improve from 0.82759\n","Epoch 23/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.2501 - accuracy: 0.9099 - val_loss: 1.0765 - val_accuracy: 0.7365\n","\n","Epoch 00023: val_accuracy did not improve from 0.82759\n","Epoch 24/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.3325 - accuracy: 0.8916 - val_loss: 1.4944 - val_accuracy: 0.6675\n","\n","Epoch 00024: val_accuracy did not improve from 0.82759\n","Epoch 25/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.2326 - accuracy: 0.9208 - val_loss: 0.6232 - val_accuracy: 0.8350\n","\n","Epoch 00025: val_accuracy improved from 0.82759 to 0.83498, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 26/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.2144 - accuracy: 0.9257 - val_loss: 0.4123 - val_accuracy: 0.8571\n","\n","Epoch 00026: val_accuracy improved from 0.83498 to 0.85714, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 27/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.1510 - accuracy: 0.9470 - val_loss: 0.6667 - val_accuracy: 0.8350\n","\n","Epoch 00027: val_accuracy did not improve from 0.85714\n","Epoch 28/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.1975 - accuracy: 0.9330 - val_loss: 0.8228 - val_accuracy: 0.8153\n","\n","Epoch 00028: val_accuracy did not improve from 0.85714\n","Epoch 29/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.2832 - accuracy: 0.9086 - val_loss: 0.6325 - val_accuracy: 0.8227\n","\n","Epoch 00029: val_accuracy did not improve from 0.85714\n","Epoch 30/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.2128 - accuracy: 0.9306 - val_loss: 0.9359 - val_accuracy: 0.7759\n","\n","Epoch 00030: val_accuracy did not improve from 0.85714\n","Epoch 31/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.2081 - accuracy: 0.9324 - val_loss: 0.6354 - val_accuracy: 0.8547\n","\n","Epoch 00031: val_accuracy did not improve from 0.85714\n","Epoch 32/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.1951 - accuracy: 0.9330 - val_loss: 0.4440 - val_accuracy: 0.8695\n","\n","Epoch 00032: val_accuracy improved from 0.85714 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 33/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1637 - accuracy: 0.9385 - val_loss: 0.5710 - val_accuracy: 0.8399\n","\n","Epoch 00033: val_accuracy did not improve from 0.86946\n","Epoch 34/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1245 - accuracy: 0.9543 - val_loss: 0.6212 - val_accuracy: 0.8227\n","\n","Epoch 00034: val_accuracy did not improve from 0.86946\n","Epoch 35/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.1795 - accuracy: 0.9391 - val_loss: 0.7050 - val_accuracy: 0.8498\n","\n","Epoch 00035: val_accuracy did not improve from 0.86946\n","Epoch 36/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1210 - accuracy: 0.9622 - val_loss: 0.6099 - val_accuracy: 0.8202\n","\n","Epoch 00036: val_accuracy did not improve from 0.86946\n","Epoch 37/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.1666 - accuracy: 0.9403 - val_loss: 0.6977 - val_accuracy: 0.8399\n","\n","Epoch 00037: val_accuracy did not improve from 0.86946\n","Epoch 38/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1920 - accuracy: 0.9330 - val_loss: 0.8097 - val_accuracy: 0.8128\n","\n","Epoch 00038: val_accuracy did not improve from 0.86946\n","Epoch 39/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.1110 - accuracy: 0.9629 - val_loss: 0.6401 - val_accuracy: 0.8424\n","\n","Epoch 00039: val_accuracy did not improve from 0.86946\n","Epoch 40/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.1066 - accuracy: 0.9622 - val_loss: 0.5144 - val_accuracy: 0.8571\n","\n","Epoch 00040: val_accuracy did not improve from 0.86946\n","Epoch 41/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.2012 - accuracy: 0.9367 - val_loss: 0.6248 - val_accuracy: 0.8448\n","\n","Epoch 00041: val_accuracy did not improve from 0.86946\n","Epoch 42/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1772 - accuracy: 0.9312 - val_loss: 0.7422 - val_accuracy: 0.7980\n","\n","Epoch 00042: val_accuracy did not improve from 0.86946\n","Epoch 43/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.1157 - accuracy: 0.9610 - val_loss: 0.6995 - val_accuracy: 0.8300\n","\n","Epoch 00043: val_accuracy did not improve from 0.86946\n","Epoch 44/500\n","52/52 [==============================] - 16s 310ms/step - loss: 0.0925 - accuracy: 0.9659 - val_loss: 0.7408 - val_accuracy: 0.8473\n","\n","Epoch 00044: val_accuracy did not improve from 0.86946\n","Epoch 45/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0809 - accuracy: 0.9738 - val_loss: 0.7277 - val_accuracy: 0.8251\n","\n","Epoch 00045: val_accuracy did not improve from 0.86946\n","Epoch 46/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.1052 - accuracy: 0.9629 - val_loss: 0.6858 - val_accuracy: 0.8522\n","\n","Epoch 00046: val_accuracy did not improve from 0.86946\n","Epoch 47/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1608 - accuracy: 0.9495 - val_loss: 0.6306 - val_accuracy: 0.8547\n","\n","Epoch 00047: val_accuracy did not improve from 0.86946\n","Epoch 48/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1270 - accuracy: 0.9555 - val_loss: 0.4821 - val_accuracy: 0.8966\n","\n","Epoch 00048: val_accuracy improved from 0.86946 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 49/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.1085 - accuracy: 0.9616 - val_loss: 0.5215 - val_accuracy: 0.8596\n","\n","Epoch 00049: val_accuracy did not improve from 0.89655\n","Epoch 50/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.1051 - accuracy: 0.9586 - val_loss: 0.9055 - val_accuracy: 0.8030\n","\n","Epoch 00050: val_accuracy did not improve from 0.89655\n","Epoch 51/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1192 - accuracy: 0.9568 - val_loss: 0.7556 - val_accuracy: 0.8473\n","\n","Epoch 00051: val_accuracy did not improve from 0.89655\n","Epoch 52/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0796 - accuracy: 0.9708 - val_loss: 0.6554 - val_accuracy: 0.8670\n","\n","Epoch 00052: val_accuracy did not improve from 0.89655\n","Epoch 53/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.1404 - accuracy: 0.9525 - val_loss: 5.1266 - val_accuracy: 0.4458\n","\n","Epoch 00053: val_accuracy did not improve from 0.89655\n","Epoch 54/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.1162 - accuracy: 0.9604 - val_loss: 0.9143 - val_accuracy: 0.8103\n","\n","Epoch 00054: val_accuracy did not improve from 0.89655\n","Epoch 55/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0770 - accuracy: 0.9762 - val_loss: 0.4772 - val_accuracy: 0.8695\n","\n","Epoch 00055: val_accuracy did not improve from 0.89655\n","Epoch 56/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0812 - accuracy: 0.9726 - val_loss: 0.4770 - val_accuracy: 0.8670\n","\n","Epoch 00056: val_accuracy did not improve from 0.89655\n","Epoch 57/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0665 - accuracy: 0.9762 - val_loss: 0.7520 - val_accuracy: 0.8177\n","\n","Epoch 00057: val_accuracy did not improve from 0.89655\n","Epoch 58/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0827 - accuracy: 0.9744 - val_loss: 0.7120 - val_accuracy: 0.8350\n","\n","Epoch 00058: val_accuracy did not improve from 0.89655\n","Epoch 59/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0721 - accuracy: 0.9750 - val_loss: 0.7133 - val_accuracy: 0.8473\n","\n","Epoch 00059: val_accuracy did not improve from 0.89655\n","Epoch 60/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0795 - accuracy: 0.9708 - val_loss: 0.7251 - val_accuracy: 0.8448\n","\n","Epoch 00060: val_accuracy did not improve from 0.89655\n","Epoch 61/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0488 - accuracy: 0.9854 - val_loss: 0.6708 - val_accuracy: 0.8571\n","\n","Epoch 00061: val_accuracy did not improve from 0.89655\n","Epoch 62/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0763 - accuracy: 0.9762 - val_loss: 0.7881 - val_accuracy: 0.8350\n","\n","Epoch 00062: val_accuracy did not improve from 0.89655\n","Epoch 63/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.1698 - accuracy: 0.9458 - val_loss: 0.9135 - val_accuracy: 0.7808\n","\n","Epoch 00063: val_accuracy did not improve from 0.89655\n","Epoch 64/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.1148 - accuracy: 0.9610 - val_loss: 0.7492 - val_accuracy: 0.8251\n","\n","Epoch 00064: val_accuracy did not improve from 0.89655\n","Epoch 65/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0993 - accuracy: 0.9659 - val_loss: 0.6083 - val_accuracy: 0.8768\n","\n","Epoch 00065: val_accuracy did not improve from 0.89655\n","Epoch 66/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0602 - accuracy: 0.9811 - val_loss: 0.4675 - val_accuracy: 0.8966\n","\n","Epoch 00066: val_accuracy did not improve from 0.89655\n","Epoch 67/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0667 - accuracy: 0.9750 - val_loss: 0.5290 - val_accuracy: 0.8744\n","\n","Epoch 00067: val_accuracy did not improve from 0.89655\n","Epoch 68/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.4475 - val_accuracy: 0.9039\n","\n","Epoch 00068: val_accuracy improved from 0.89655 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 69/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0453 - accuracy: 0.9854 - val_loss: 0.7595 - val_accuracy: 0.8670\n","\n","Epoch 00069: val_accuracy did not improve from 0.90394\n","Epoch 70/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0459 - accuracy: 0.9829 - val_loss: 0.5244 - val_accuracy: 0.8793\n","\n","Epoch 00070: val_accuracy did not improve from 0.90394\n","Epoch 71/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0278 - accuracy: 0.9896 - val_loss: 0.3394 - val_accuracy: 0.8990\n","\n","Epoch 00071: val_accuracy did not improve from 0.90394\n","Epoch 72/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.4649 - val_accuracy: 0.8867\n","\n","Epoch 00072: val_accuracy did not improve from 0.90394\n","Epoch 73/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0426 - accuracy: 0.9848 - val_loss: 0.7928 - val_accuracy: 0.8350\n","\n","Epoch 00073: val_accuracy did not improve from 0.90394\n","Epoch 74/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1198 - accuracy: 0.9629 - val_loss: 0.9115 - val_accuracy: 0.8251\n","\n","Epoch 00074: val_accuracy did not improve from 0.90394\n","Epoch 75/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1714 - accuracy: 0.9513 - val_loss: 0.8313 - val_accuracy: 0.8547\n","\n","Epoch 00075: val_accuracy did not improve from 0.90394\n","Epoch 76/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0995 - accuracy: 0.9683 - val_loss: 0.8226 - val_accuracy: 0.8374\n","\n","Epoch 00076: val_accuracy did not improve from 0.90394\n","Epoch 77/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0798 - accuracy: 0.9732 - val_loss: 0.8066 - val_accuracy: 0.8227\n","\n","Epoch 00077: val_accuracy did not improve from 0.90394\n","Epoch 78/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0564 - accuracy: 0.9793 - val_loss: 0.5768 - val_accuracy: 0.8571\n","\n","Epoch 00078: val_accuracy did not improve from 0.90394\n","Epoch 79/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.4689 - val_accuracy: 0.8867\n","\n","Epoch 00079: val_accuracy did not improve from 0.90394\n","Epoch 80/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.4972 - val_accuracy: 0.8793\n","\n","Epoch 00080: val_accuracy did not improve from 0.90394\n","Epoch 81/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.4350 - val_accuracy: 0.9064\n","\n","Epoch 00081: val_accuracy improved from 0.90394 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 82/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.4110 - val_accuracy: 0.8941\n","\n","Epoch 00082: val_accuracy did not improve from 0.90640\n","Epoch 83/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.5386 - val_accuracy: 0.8793\n","\n","Epoch 00083: val_accuracy did not improve from 0.90640\n","Epoch 84/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.4836 - val_accuracy: 0.8867\n","\n","Epoch 00084: val_accuracy did not improve from 0.90640\n","Epoch 85/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0321 - accuracy: 0.9896 - val_loss: 0.6588 - val_accuracy: 0.8571\n","\n","Epoch 00085: val_accuracy did not improve from 0.90640\n","Epoch 86/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0260 - accuracy: 0.9890 - val_loss: 0.5255 - val_accuracy: 0.8842\n","\n","Epoch 00086: val_accuracy did not improve from 0.90640\n","Epoch 87/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0516 - accuracy: 0.9823 - val_loss: 1.3833 - val_accuracy: 0.7315\n","\n","Epoch 00087: val_accuracy did not improve from 0.90640\n","Epoch 88/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0944 - accuracy: 0.9689 - val_loss: 1.1206 - val_accuracy: 0.8177\n","\n","Epoch 00088: val_accuracy did not improve from 0.90640\n","Epoch 89/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0541 - accuracy: 0.9811 - val_loss: 0.9888 - val_accuracy: 0.8128\n","\n","Epoch 00089: val_accuracy did not improve from 0.90640\n","Epoch 90/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0393 - accuracy: 0.9842 - val_loss: 1.0131 - val_accuracy: 0.8300\n","\n","Epoch 00090: val_accuracy did not improve from 0.90640\n","Epoch 91/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0625 - accuracy: 0.9805 - val_loss: 0.6719 - val_accuracy: 0.8892\n","\n","Epoch 00091: val_accuracy did not improve from 0.90640\n","Epoch 92/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1001 - accuracy: 0.9635 - val_loss: 0.8484 - val_accuracy: 0.8670\n","\n","Epoch 00092: val_accuracy did not improve from 0.90640\n","Epoch 93/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1234 - accuracy: 0.9641 - val_loss: 0.7695 - val_accuracy: 0.8621\n","\n","Epoch 00093: val_accuracy did not improve from 0.90640\n","Epoch 94/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0602 - accuracy: 0.9781 - val_loss: 0.6986 - val_accuracy: 0.8768\n","\n","Epoch 00094: val_accuracy did not improve from 0.90640\n","Epoch 95/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.1124 - accuracy: 0.9653 - val_loss: 0.9108 - val_accuracy: 0.8276\n","\n","Epoch 00095: val_accuracy did not improve from 0.90640\n","Epoch 96/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0861 - accuracy: 0.9702 - val_loss: 0.9046 - val_accuracy: 0.8350\n","\n","Epoch 00096: val_accuracy did not improve from 0.90640\n","Epoch 97/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.5245 - val_accuracy: 0.8892\n","\n","Epoch 00097: val_accuracy did not improve from 0.90640\n","Epoch 98/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0258 - accuracy: 0.9903 - val_loss: 0.5319 - val_accuracy: 0.8793\n","\n","Epoch 00098: val_accuracy did not improve from 0.90640\n","Epoch 99/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.6015 - val_accuracy: 0.8818\n","\n","Epoch 00099: val_accuracy did not improve from 0.90640\n","Epoch 100/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.4977 - val_accuracy: 0.8818\n","\n","Epoch 00100: val_accuracy did not improve from 0.90640\n","Epoch 101/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.4862 - val_accuracy: 0.8892\n","\n","Epoch 00101: val_accuracy did not improve from 0.90640\n","Epoch 102/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.4553 - val_accuracy: 0.8941\n","\n","Epoch 00102: val_accuracy did not improve from 0.90640\n","Epoch 103/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0597 - accuracy: 0.9884 - val_loss: 1.3713 - val_accuracy: 0.7906\n","\n","Epoch 00103: val_accuracy did not improve from 0.90640\n","Epoch 104/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.1028 - accuracy: 0.9714 - val_loss: 0.9081 - val_accuracy: 0.8424\n","\n","Epoch 00104: val_accuracy did not improve from 0.90640\n","Epoch 105/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0758 - accuracy: 0.9750 - val_loss: 0.8676 - val_accuracy: 0.8350\n","\n","Epoch 00105: val_accuracy did not improve from 0.90640\n","Epoch 106/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0602 - accuracy: 0.9781 - val_loss: 1.0366 - val_accuracy: 0.8251\n","\n","Epoch 00106: val_accuracy did not improve from 0.90640\n","Epoch 107/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.6704 - val_accuracy: 0.8621\n","\n","Epoch 00107: val_accuracy did not improve from 0.90640\n","Epoch 108/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0516 - accuracy: 0.9829 - val_loss: 0.5546 - val_accuracy: 0.8867\n","\n","Epoch 00108: val_accuracy did not improve from 0.90640\n","Epoch 109/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.5858 - val_accuracy: 0.8547\n","\n","Epoch 00109: val_accuracy did not improve from 0.90640\n","Epoch 110/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0177 - accuracy: 0.9933 - val_loss: 0.4728 - val_accuracy: 0.8941\n","\n","Epoch 00110: val_accuracy did not improve from 0.90640\n","Epoch 111/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.6948 - val_accuracy: 0.8571\n","\n","Epoch 00111: val_accuracy did not improve from 0.90640\n","Epoch 112/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 1.3942 - val_accuracy: 0.7660\n","\n","Epoch 00112: val_accuracy did not improve from 0.90640\n","Epoch 113/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0816 - accuracy: 0.9750 - val_loss: 0.9522 - val_accuracy: 0.8645\n","\n","Epoch 00113: val_accuracy did not improve from 0.90640\n","Epoch 114/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0430 - accuracy: 0.9890 - val_loss: 0.6168 - val_accuracy: 0.8793\n","\n","Epoch 00114: val_accuracy did not improve from 0.90640\n","Epoch 115/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0383 - accuracy: 0.9872 - val_loss: 0.5869 - val_accuracy: 0.8621\n","\n","Epoch 00115: val_accuracy did not improve from 0.90640\n","Epoch 116/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0173 - accuracy: 0.9927 - val_loss: 0.5463 - val_accuracy: 0.8818\n","\n","Epoch 00116: val_accuracy did not improve from 0.90640\n","Epoch 117/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0315 - accuracy: 0.9915 - val_loss: 0.6320 - val_accuracy: 0.8719\n","\n","Epoch 00117: val_accuracy did not improve from 0.90640\n","Epoch 118/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0215 - accuracy: 0.9915 - val_loss: 0.6729 - val_accuracy: 0.8768\n","\n","Epoch 00118: val_accuracy did not improve from 0.90640\n","Epoch 119/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0381 - accuracy: 0.9854 - val_loss: 0.5986 - val_accuracy: 0.8842\n","\n","Epoch 00119: val_accuracy did not improve from 0.90640\n","Epoch 120/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 0.7408 - val_accuracy: 0.8177\n","\n","Epoch 00120: val_accuracy did not improve from 0.90640\n","Epoch 121/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0498 - accuracy: 0.9836 - val_loss: 1.1018 - val_accuracy: 0.8177\n","\n","Epoch 00121: val_accuracy did not improve from 0.90640\n","Epoch 122/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0321 - accuracy: 0.9884 - val_loss: 0.7615 - val_accuracy: 0.8695\n","\n","Epoch 00122: val_accuracy did not improve from 0.90640\n","Epoch 123/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0238 - accuracy: 0.9903 - val_loss: 0.8077 - val_accuracy: 0.8621\n","\n","Epoch 00123: val_accuracy did not improve from 0.90640\n","Epoch 124/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0166 - accuracy: 0.9933 - val_loss: 0.7030 - val_accuracy: 0.8571\n","\n","Epoch 00124: val_accuracy did not improve from 0.90640\n","Epoch 125/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 0.6886 - val_accuracy: 0.8719\n","\n","Epoch 00125: val_accuracy did not improve from 0.90640\n","Epoch 126/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 0.9425 - val_accuracy: 0.8399\n","\n","Epoch 00126: val_accuracy did not improve from 0.90640\n","Epoch 127/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0713 - accuracy: 0.9738 - val_loss: 0.8237 - val_accuracy: 0.8522\n","\n","Epoch 00127: val_accuracy did not improve from 0.90640\n","Epoch 128/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0920 - accuracy: 0.9726 - val_loss: 1.4098 - val_accuracy: 0.7586\n","\n","Epoch 00128: val_accuracy did not improve from 0.90640\n","Epoch 129/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.6342 - val_accuracy: 0.8793\n","\n","Epoch 00129: val_accuracy did not improve from 0.90640\n","Epoch 130/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0215 - accuracy: 0.9957 - val_loss: 0.5665 - val_accuracy: 0.8818\n","\n","Epoch 00130: val_accuracy did not improve from 0.90640\n","Epoch 131/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0365 - accuracy: 0.9872 - val_loss: 0.5555 - val_accuracy: 0.8941\n","\n","Epoch 00131: val_accuracy did not improve from 0.90640\n","Epoch 132/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0487 - accuracy: 0.9872 - val_loss: 2.0337 - val_accuracy: 0.6576\n","\n","Epoch 00132: val_accuracy did not improve from 0.90640\n","Epoch 133/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0997 - accuracy: 0.9726 - val_loss: 0.6757 - val_accuracy: 0.8695\n","\n","Epoch 00133: val_accuracy did not improve from 0.90640\n","Epoch 134/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0438 - accuracy: 0.9848 - val_loss: 0.5601 - val_accuracy: 0.8793\n","\n","Epoch 00134: val_accuracy did not improve from 0.90640\n","Epoch 135/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.5625 - val_accuracy: 0.8966\n","\n","Epoch 00135: val_accuracy did not improve from 0.90640\n","Epoch 136/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.5711 - val_accuracy: 0.8916\n","\n","Epoch 00136: val_accuracy did not improve from 0.90640\n","Epoch 137/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0176 - accuracy: 0.9921 - val_loss: 0.6054 - val_accuracy: 0.8744\n","\n","Epoch 00137: val_accuracy did not improve from 0.90640\n","Epoch 138/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 0.6679 - val_accuracy: 0.8818\n","\n","Epoch 00138: val_accuracy did not improve from 0.90640\n","Epoch 139/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.7285 - val_accuracy: 0.8818\n","\n","Epoch 00139: val_accuracy did not improve from 0.90640\n","Epoch 140/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.6081 - val_accuracy: 0.8498\n","\n","Epoch 00140: val_accuracy did not improve from 0.90640\n","Epoch 141/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0304 - accuracy: 0.9878 - val_loss: 0.5709 - val_accuracy: 0.8793\n","\n","Epoch 00141: val_accuracy did not improve from 0.90640\n","Epoch 142/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0649 - accuracy: 0.9811 - val_loss: 0.9262 - val_accuracy: 0.8030\n","\n","Epoch 00142: val_accuracy did not improve from 0.90640\n","Epoch 143/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0250 - accuracy: 0.9884 - val_loss: 0.6655 - val_accuracy: 0.8916\n","\n","Epoch 00143: val_accuracy did not improve from 0.90640\n","Epoch 144/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0574 - accuracy: 0.9842 - val_loss: 0.8505 - val_accuracy: 0.8522\n","\n","Epoch 00144: val_accuracy did not improve from 0.90640\n","Epoch 145/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0512 - accuracy: 0.9854 - val_loss: 0.7369 - val_accuracy: 0.8621\n","\n","Epoch 00145: val_accuracy did not improve from 0.90640\n","Epoch 146/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0363 - accuracy: 0.9872 - val_loss: 0.7002 - val_accuracy: 0.8645\n","\n","Epoch 00146: val_accuracy did not improve from 0.90640\n","Epoch 147/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0544 - accuracy: 0.9829 - val_loss: 1.1010 - val_accuracy: 0.7562\n","\n","Epoch 00147: val_accuracy did not improve from 0.90640\n","Epoch 148/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0360 - accuracy: 0.9872 - val_loss: 0.5975 - val_accuracy: 0.8744\n","\n","Epoch 00148: val_accuracy did not improve from 0.90640\n","Epoch 149/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.9455 - val_accuracy: 0.8473\n","\n","Epoch 00149: val_accuracy did not improve from 0.90640\n","Epoch 150/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0300 - accuracy: 0.9884 - val_loss: 0.6695 - val_accuracy: 0.8990\n","\n","Epoch 00150: val_accuracy did not improve from 0.90640\n","Epoch 151/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 0.5330 - val_accuracy: 0.8966\n","\n","Epoch 00151: val_accuracy did not improve from 0.90640\n","Epoch 152/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0172 - accuracy: 0.9921 - val_loss: 0.4887 - val_accuracy: 0.8966\n","\n","Epoch 00152: val_accuracy did not improve from 0.90640\n","Epoch 153/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.4340 - val_accuracy: 0.9064\n","\n","Epoch 00153: val_accuracy did not improve from 0.90640\n","Epoch 154/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.4992 - val_accuracy: 0.8793\n","\n","Epoch 00154: val_accuracy did not improve from 0.90640\n","Epoch 155/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.4492 - val_accuracy: 0.8966\n","\n","Epoch 00155: val_accuracy did not improve from 0.90640\n","Epoch 156/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.6185 - val_accuracy: 0.8695\n","\n","Epoch 00156: val_accuracy did not improve from 0.90640\n","Epoch 157/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.6265 - val_accuracy: 0.8818\n","\n","Epoch 00157: val_accuracy did not improve from 0.90640\n","Epoch 158/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.5804 - val_accuracy: 0.8916\n","\n","Epoch 00158: val_accuracy did not improve from 0.90640\n","Epoch 159/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.5101 - val_accuracy: 0.8990\n","\n","Epoch 00159: val_accuracy did not improve from 0.90640\n","Epoch 160/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0228 - accuracy: 0.9945 - val_loss: 0.8780 - val_accuracy: 0.8350\n","\n","Epoch 00160: val_accuracy did not improve from 0.90640\n","Epoch 161/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.1035 - accuracy: 0.9744 - val_loss: 0.7108 - val_accuracy: 0.8670\n","\n","Epoch 00161: val_accuracy did not improve from 0.90640\n","Epoch 162/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0576 - accuracy: 0.9805 - val_loss: 0.7549 - val_accuracy: 0.8744\n","\n","Epoch 00162: val_accuracy did not improve from 0.90640\n","Epoch 163/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0527 - accuracy: 0.9811 - val_loss: 0.8292 - val_accuracy: 0.8103\n","\n","Epoch 00163: val_accuracy did not improve from 0.90640\n","Epoch 164/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0956 - accuracy: 0.9702 - val_loss: 0.8026 - val_accuracy: 0.8571\n","\n","Epoch 00164: val_accuracy did not improve from 0.90640\n","Epoch 165/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0241 - accuracy: 0.9915 - val_loss: 0.5237 - val_accuracy: 0.8793\n","\n","Epoch 00165: val_accuracy did not improve from 0.90640\n","Epoch 166/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.5578 - val_accuracy: 0.8744\n","\n","Epoch 00166: val_accuracy did not improve from 0.90640\n","Epoch 167/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.6701 - val_accuracy: 0.8744\n","\n","Epoch 00167: val_accuracy did not improve from 0.90640\n","Epoch 168/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.6869 - val_accuracy: 0.8300\n","\n","Epoch 00168: val_accuracy did not improve from 0.90640\n","Epoch 169/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.5584 - val_accuracy: 0.8768\n","\n","Epoch 00169: val_accuracy did not improve from 0.90640\n","Epoch 170/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.5065 - val_accuracy: 0.9039\n","\n","Epoch 00170: val_accuracy did not improve from 0.90640\n","Epoch 171/500\n","52/52 [==============================] - 16s 302ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5166 - val_accuracy: 0.8966\n","\n","Epoch 00171: val_accuracy did not improve from 0.90640\n","Epoch 172/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.5199 - val_accuracy: 0.8941\n","\n","Epoch 00172: val_accuracy did not improve from 0.90640\n","Epoch 173/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 1.1222 - val_accuracy: 0.8547\n","\n","Epoch 00173: val_accuracy did not improve from 0.90640\n","Epoch 174/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0288 - accuracy: 0.9933 - val_loss: 0.9539 - val_accuracy: 0.8670\n","\n","Epoch 00174: val_accuracy did not improve from 0.90640\n","Epoch 175/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.6873 - val_accuracy: 0.8695\n","\n","Epoch 00175: val_accuracy did not improve from 0.90640\n","Epoch 176/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.6030 - val_accuracy: 0.8867\n","\n","Epoch 00176: val_accuracy did not improve from 0.90640\n","Epoch 177/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0324 - accuracy: 0.9921 - val_loss: 0.7338 - val_accuracy: 0.8695\n","\n","Epoch 00177: val_accuracy did not improve from 0.90640\n","Epoch 178/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 1.1146 - val_accuracy: 0.8276\n","\n","Epoch 00178: val_accuracy did not improve from 0.90640\n","Epoch 179/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0406 - accuracy: 0.9848 - val_loss: 0.8330 - val_accuracy: 0.8695\n","\n","Epoch 00179: val_accuracy did not improve from 0.90640\n","Epoch 180/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0340 - accuracy: 0.9848 - val_loss: 0.8028 - val_accuracy: 0.8842\n","\n","Epoch 00180: val_accuracy did not improve from 0.90640\n","Epoch 181/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.6086 - val_accuracy: 0.8842\n","\n","Epoch 00181: val_accuracy did not improve from 0.90640\n","Epoch 182/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0566 - accuracy: 0.9854 - val_loss: 0.9351 - val_accuracy: 0.8448\n","\n","Epoch 00182: val_accuracy did not improve from 0.90640\n","Epoch 183/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0549 - accuracy: 0.9854 - val_loss: 1.1828 - val_accuracy: 0.8103\n","\n","Epoch 00183: val_accuracy did not improve from 0.90640\n","Epoch 184/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0411 - accuracy: 0.9860 - val_loss: 0.6372 - val_accuracy: 0.8793\n","\n","Epoch 00184: val_accuracy did not improve from 0.90640\n","Epoch 185/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 0.5341 - val_accuracy: 0.9015\n","\n","Epoch 00185: val_accuracy did not improve from 0.90640\n","Epoch 186/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.8282 - val_accuracy: 0.8571\n","\n","Epoch 00186: val_accuracy did not improve from 0.90640\n","Epoch 187/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.5865 - val_accuracy: 0.8867\n","\n","Epoch 00187: val_accuracy did not improve from 0.90640\n","Epoch 188/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0283 - accuracy: 0.9927 - val_loss: 0.6479 - val_accuracy: 0.8695\n","\n","Epoch 00188: val_accuracy did not improve from 0.90640\n","Epoch 189/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0228 - accuracy: 0.9939 - val_loss: 0.4511 - val_accuracy: 0.9039\n","\n","Epoch 00189: val_accuracy did not improve from 0.90640\n","Epoch 190/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.4516 - val_accuracy: 0.9163\n","\n","Epoch 00190: val_accuracy improved from 0.90640 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 191/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.4684 - val_accuracy: 0.9015\n","\n","Epoch 00191: val_accuracy did not improve from 0.91626\n","Epoch 192/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 0.5181 - val_accuracy: 0.9039\n","\n","Epoch 00192: val_accuracy did not improve from 0.91626\n","Epoch 193/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0040 - accuracy: 0.9976 - val_loss: 0.4820 - val_accuracy: 0.9039\n","\n","Epoch 00193: val_accuracy did not improve from 0.91626\n","Epoch 194/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4267 - val_accuracy: 0.9064\n","\n","Epoch 00194: val_accuracy did not improve from 0.91626\n","Epoch 195/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.6361 - val_accuracy: 0.8966\n","\n","Epoch 00195: val_accuracy did not improve from 0.91626\n","Epoch 196/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5639 - val_accuracy: 0.9039\n","\n","Epoch 00196: val_accuracy did not improve from 0.91626\n","Epoch 197/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.4310 - val_accuracy: 0.9187\n","\n","Epoch 00197: val_accuracy improved from 0.91626 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 198/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0221 - accuracy: 0.9951 - val_loss: 0.7730 - val_accuracy: 0.8202\n","\n","Epoch 00198: val_accuracy did not improve from 0.91872\n","Epoch 199/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0600 - accuracy: 0.9793 - val_loss: 1.2639 - val_accuracy: 0.7980\n","\n","Epoch 00199: val_accuracy did not improve from 0.91872\n","Epoch 200/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 0.9073 - val_accuracy: 0.8473\n","\n","Epoch 00200: val_accuracy did not improve from 0.91872\n","Epoch 201/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0300 - accuracy: 0.9909 - val_loss: 0.5686 - val_accuracy: 0.9015\n","\n","Epoch 00201: val_accuracy did not improve from 0.91872\n","Epoch 202/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.9514 - val_accuracy: 0.8399\n","\n","Epoch 00202: val_accuracy did not improve from 0.91872\n","Epoch 203/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0349 - accuracy: 0.9909 - val_loss: 0.8586 - val_accuracy: 0.8596\n","\n","Epoch 00203: val_accuracy did not improve from 0.91872\n","Epoch 204/500\n","52/52 [==============================] - 16s 310ms/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 0.5877 - val_accuracy: 0.8916\n","\n","Epoch 00204: val_accuracy did not improve from 0.91872\n","Epoch 205/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.5972 - val_accuracy: 0.8793\n","\n","Epoch 00205: val_accuracy did not improve from 0.91872\n","Epoch 206/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.6878 - val_accuracy: 0.8719\n","\n","Epoch 00206: val_accuracy did not improve from 0.91872\n","Epoch 207/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.6613 - val_accuracy: 0.8941\n","\n","Epoch 00207: val_accuracy did not improve from 0.91872\n","Epoch 208/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.6492 - val_accuracy: 0.8990\n","\n","Epoch 00208: val_accuracy did not improve from 0.91872\n","Epoch 209/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.7012 - val_accuracy: 0.8916\n","\n","Epoch 00209: val_accuracy did not improve from 0.91872\n","Epoch 210/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0556 - accuracy: 0.9836 - val_loss: 0.7671 - val_accuracy: 0.8892\n","\n","Epoch 00210: val_accuracy did not improve from 0.91872\n","Epoch 211/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0842 - accuracy: 0.9744 - val_loss: 0.6987 - val_accuracy: 0.8719\n","\n","Epoch 00211: val_accuracy did not improve from 0.91872\n","Epoch 212/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0645 - accuracy: 0.9805 - val_loss: 1.1536 - val_accuracy: 0.8153\n","\n","Epoch 00212: val_accuracy did not improve from 0.91872\n","Epoch 213/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0395 - accuracy: 0.9866 - val_loss: 0.6144 - val_accuracy: 0.8768\n","\n","Epoch 00213: val_accuracy did not improve from 0.91872\n","Epoch 214/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.5565 - val_accuracy: 0.9015\n","\n","Epoch 00214: val_accuracy did not improve from 0.91872\n","Epoch 215/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.5141 - val_accuracy: 0.9015\n","\n","Epoch 00215: val_accuracy did not improve from 0.91872\n","Epoch 216/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0392 - accuracy: 0.9909 - val_loss: 0.6026 - val_accuracy: 0.8744\n","\n","Epoch 00216: val_accuracy did not improve from 0.91872\n","Epoch 217/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.4801 - val_accuracy: 0.9064\n","\n","Epoch 00217: val_accuracy did not improve from 0.91872\n","Epoch 218/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.3885 - val_accuracy: 0.9236\n","\n","Epoch 00218: val_accuracy improved from 0.91872 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 219/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.4734 - val_accuracy: 0.9113\n","\n","Epoch 00219: val_accuracy did not improve from 0.92365\n","Epoch 220/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.6289 - val_accuracy: 0.8695\n","\n","Epoch 00220: val_accuracy did not improve from 0.92365\n","Epoch 221/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4863 - val_accuracy: 0.8892\n","\n","Epoch 00221: val_accuracy did not improve from 0.92365\n","Epoch 222/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.5714 - val_accuracy: 0.8916\n","\n","Epoch 00222: val_accuracy did not improve from 0.92365\n","Epoch 223/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4819 - val_accuracy: 0.9039\n","\n","Epoch 00223: val_accuracy did not improve from 0.92365\n","Epoch 224/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4585 - val_accuracy: 0.9163\n","\n","Epoch 00224: val_accuracy did not improve from 0.92365\n","Epoch 225/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4618 - val_accuracy: 0.9064\n","\n","Epoch 00225: val_accuracy did not improve from 0.92365\n","Epoch 226/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.9089\n","\n","Epoch 00226: val_accuracy did not improve from 0.92365\n","Epoch 227/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9163\n","\n","Epoch 00227: val_accuracy did not improve from 0.92365\n","Epoch 228/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.4438 - val_accuracy: 0.9163\n","\n","Epoch 00228: val_accuracy did not improve from 0.92365\n","Epoch 229/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4880 - val_accuracy: 0.9015\n","\n","Epoch 00229: val_accuracy did not improve from 0.92365\n","Epoch 230/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.7025 - val_accuracy: 0.9015\n","\n","Epoch 00230: val_accuracy did not improve from 0.92365\n","Epoch 231/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0134 - accuracy: 0.9976 - val_loss: 0.5258 - val_accuracy: 0.8966\n","\n","Epoch 00231: val_accuracy did not improve from 0.92365\n","Epoch 232/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.5014 - val_accuracy: 0.9039\n","\n","Epoch 00232: val_accuracy did not improve from 0.92365\n","Epoch 233/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.8867\n","\n","Epoch 00233: val_accuracy did not improve from 0.92365\n","Epoch 234/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.4832 - val_accuracy: 0.9113\n","\n","Epoch 00234: val_accuracy did not improve from 0.92365\n","Epoch 235/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.5646 - val_accuracy: 0.9039\n","\n","Epoch 00235: val_accuracy did not improve from 0.92365\n","Epoch 236/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.6414 - val_accuracy: 0.8941\n","\n","Epoch 00236: val_accuracy did not improve from 0.92365\n","Epoch 237/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.9113\n","\n","Epoch 00237: val_accuracy did not improve from 0.92365\n","Epoch 238/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.9138\n","\n","Epoch 00238: val_accuracy did not improve from 0.92365\n","Epoch 239/500\n","52/52 [==============================] - 16s 304ms/step - loss: 9.9281e-04 - accuracy: 0.9994 - val_loss: 0.4753 - val_accuracy: 0.9187\n","\n","Epoch 00239: val_accuracy did not improve from 0.92365\n","Epoch 240/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5135 - val_accuracy: 0.9039\n","\n","Epoch 00240: val_accuracy did not improve from 0.92365\n","Epoch 241/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.9138\n","\n","Epoch 00241: val_accuracy did not improve from 0.92365\n","Epoch 242/500\n","52/52 [==============================] - 16s 306ms/step - loss: 5.7233e-04 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.9113\n","\n","Epoch 00242: val_accuracy did not improve from 0.92365\n","Epoch 243/500\n","52/52 [==============================] - 16s 304ms/step - loss: 5.8166e-04 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.9015\n","\n","Epoch 00243: val_accuracy did not improve from 0.92365\n","Epoch 244/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.5107 - val_accuracy: 0.8695\n","\n","Epoch 00244: val_accuracy did not improve from 0.92365\n","Epoch 245/500\n","52/52 [==============================] - 16s 309ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5473 - val_accuracy: 0.8793\n","\n","Epoch 00245: val_accuracy did not improve from 0.92365\n","Epoch 246/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.7465 - val_accuracy: 0.8744\n","\n","Epoch 00246: val_accuracy did not improve from 0.92365\n","Epoch 247/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.7886 - val_accuracy: 0.8621\n","\n","Epoch 00247: val_accuracy did not improve from 0.92365\n","Epoch 248/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.2334 - accuracy: 0.9482 - val_loss: 4.2072 - val_accuracy: 0.5813\n","\n","Epoch 00248: val_accuracy did not improve from 0.92365\n","Epoch 249/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1269 - accuracy: 0.9622 - val_loss: 2.0267 - val_accuracy: 0.6773\n","\n","Epoch 00249: val_accuracy did not improve from 0.92365\n","Epoch 250/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0439 - accuracy: 0.9854 - val_loss: 0.8925 - val_accuracy: 0.8719\n","\n","Epoch 00250: val_accuracy did not improve from 0.92365\n","Epoch 251/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.7804 - val_accuracy: 0.8719\n","\n","Epoch 00251: val_accuracy did not improve from 0.92365\n","Epoch 252/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0139 - accuracy: 0.9945 - val_loss: 0.6310 - val_accuracy: 0.8867\n","\n","Epoch 00252: val_accuracy did not improve from 0.92365\n","Epoch 253/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.6843 - val_accuracy: 0.8916\n","\n","Epoch 00253: val_accuracy did not improve from 0.92365\n","Epoch 254/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.6186 - val_accuracy: 0.8990\n","\n","Epoch 00254: val_accuracy did not improve from 0.92365\n","Epoch 255/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4899 - val_accuracy: 0.9064\n","\n","Epoch 00255: val_accuracy did not improve from 0.92365\n","Epoch 256/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 0.6594 - val_accuracy: 0.8916\n","\n","Epoch 00256: val_accuracy did not improve from 0.92365\n","Epoch 257/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0316 - accuracy: 0.9921 - val_loss: 0.6446 - val_accuracy: 0.8818\n","\n","Epoch 00257: val_accuracy did not improve from 0.92365\n","Epoch 258/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.6471 - val_accuracy: 0.8818\n","\n","Epoch 00258: val_accuracy did not improve from 0.92365\n","Epoch 259/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.6402 - val_accuracy: 0.8867\n","\n","Epoch 00259: val_accuracy did not improve from 0.92365\n","Epoch 260/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.8966\n","\n","Epoch 00260: val_accuracy did not improve from 0.92365\n","Epoch 261/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.6037 - val_accuracy: 0.8941\n","\n","Epoch 00261: val_accuracy did not improve from 0.92365\n","Epoch 262/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.5452 - val_accuracy: 0.9015\n","\n","Epoch 00262: val_accuracy did not improve from 0.92365\n","Epoch 263/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.7343 - val_accuracy: 0.8621\n","\n","Epoch 00263: val_accuracy did not improve from 0.92365\n","Epoch 264/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.6557 - val_accuracy: 0.8793\n","\n","Epoch 00264: val_accuracy did not improve from 0.92365\n","Epoch 265/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.5380 - val_accuracy: 0.8916\n","\n","Epoch 00265: val_accuracy did not improve from 0.92365\n","Epoch 266/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.1221 - accuracy: 0.9714 - val_loss: 1.3044 - val_accuracy: 0.7734\n","\n","Epoch 00266: val_accuracy did not improve from 0.92365\n","Epoch 267/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0417 - accuracy: 0.9854 - val_loss: 0.9256 - val_accuracy: 0.8571\n","\n","Epoch 00267: val_accuracy did not improve from 0.92365\n","Epoch 268/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.6289 - val_accuracy: 0.8842\n","\n","Epoch 00268: val_accuracy did not improve from 0.92365\n","Epoch 269/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.6841 - val_accuracy: 0.8867\n","\n","Epoch 00269: val_accuracy did not improve from 0.92365\n","Epoch 270/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.5612 - val_accuracy: 0.8892\n","\n","Epoch 00270: val_accuracy did not improve from 0.92365\n","Epoch 271/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.6281 - val_accuracy: 0.8842\n","\n","Epoch 00271: val_accuracy did not improve from 0.92365\n","Epoch 272/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.6275 - val_accuracy: 0.8768\n","\n","Epoch 00272: val_accuracy did not improve from 0.92365\n","Epoch 273/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.5931 - val_accuracy: 0.8941\n","\n","Epoch 00273: val_accuracy did not improve from 0.92365\n","Epoch 274/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5538 - val_accuracy: 0.9089\n","\n","Epoch 00274: val_accuracy did not improve from 0.92365\n","Epoch 275/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4836 - val_accuracy: 0.8966\n","\n","Epoch 00275: val_accuracy did not improve from 0.92365\n","Epoch 276/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.9113\n","\n","Epoch 00276: val_accuracy did not improve from 0.92365\n","Epoch 277/500\n","52/52 [==============================] - 16s 307ms/step - loss: 9.6108e-04 - accuracy: 1.0000 - val_loss: 0.5349 - val_accuracy: 0.9039\n","\n","Epoch 00277: val_accuracy did not improve from 0.92365\n","Epoch 278/500\n","52/52 [==============================] - 16s 305ms/step - loss: 4.9526e-04 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.9163\n","\n","Epoch 00278: val_accuracy did not improve from 0.92365\n","Epoch 279/500\n","52/52 [==============================] - 16s 305ms/step - loss: 3.7968e-04 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.8966\n","\n","Epoch 00279: val_accuracy did not improve from 0.92365\n","Epoch 280/500\n","52/52 [==============================] - 16s 303ms/step - loss: 9.0960e-04 - accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.9039\n","\n","Epoch 00280: val_accuracy did not improve from 0.92365\n","Epoch 281/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.6151 - val_accuracy: 0.8966\n","\n","Epoch 00281: val_accuracy did not improve from 0.92365\n","Epoch 282/500\n","52/52 [==============================] - 16s 309ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.7156 - val_accuracy: 0.8768\n","\n","Epoch 00282: val_accuracy did not improve from 0.92365\n","Epoch 283/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.6942 - val_accuracy: 0.8768\n","\n","Epoch 00283: val_accuracy did not improve from 0.92365\n","Epoch 284/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.7396 - val_accuracy: 0.8645\n","\n","Epoch 00284: val_accuracy did not improve from 0.92365\n","Epoch 285/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.7098 - val_accuracy: 0.8768\n","\n","Epoch 00285: val_accuracy did not improve from 0.92365\n","Epoch 286/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.6349 - val_accuracy: 0.8793\n","\n","Epoch 00286: val_accuracy did not improve from 0.92365\n","Epoch 287/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0291 - accuracy: 0.9903 - val_loss: 0.8469 - val_accuracy: 0.8522\n","\n","Epoch 00287: val_accuracy did not improve from 0.92365\n","Epoch 288/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0800 - accuracy: 0.9769 - val_loss: 1.7037 - val_accuracy: 0.7833\n","\n","Epoch 00288: val_accuracy did not improve from 0.92365\n","Epoch 289/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0375 - accuracy: 0.9878 - val_loss: 0.7712 - val_accuracy: 0.8670\n","\n","Epoch 00289: val_accuracy did not improve from 0.92365\n","Epoch 290/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.5070 - val_accuracy: 0.9015\n","\n","Epoch 00290: val_accuracy did not improve from 0.92365\n","Epoch 291/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.5485 - val_accuracy: 0.8916\n","\n","Epoch 00291: val_accuracy did not improve from 0.92365\n","Epoch 292/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.5458 - val_accuracy: 0.8941\n","\n","Epoch 00292: val_accuracy did not improve from 0.92365\n","Epoch 293/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.5753 - val_accuracy: 0.9015\n","\n","Epoch 00293: val_accuracy did not improve from 0.92365\n","Epoch 294/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.7022 - val_accuracy: 0.8842\n","\n","Epoch 00294: val_accuracy did not improve from 0.92365\n","Epoch 295/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.6229 - val_accuracy: 0.8966\n","\n","Epoch 00295: val_accuracy did not improve from 0.92365\n","Epoch 296/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.7011 - val_accuracy: 0.8719\n","\n","Epoch 00296: val_accuracy did not improve from 0.92365\n","Epoch 297/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5928 - val_accuracy: 0.9015\n","\n","Epoch 00297: val_accuracy did not improve from 0.92365\n","Epoch 298/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.6068 - val_accuracy: 0.9015\n","\n","Epoch 00298: val_accuracy did not improve from 0.92365\n","Epoch 299/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.6331 - val_accuracy: 0.8990\n","\n","Epoch 00299: val_accuracy did not improve from 0.92365\n","Epoch 300/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.5887 - val_accuracy: 0.8867\n","\n","Epoch 00300: val_accuracy did not improve from 0.92365\n","Epoch 301/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.6056 - val_accuracy: 0.8941\n","\n","Epoch 00301: val_accuracy did not improve from 0.92365\n","Epoch 302/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0490 - accuracy: 0.9878 - val_loss: 1.3761 - val_accuracy: 0.8374\n","\n","Epoch 00302: val_accuracy did not improve from 0.92365\n","Epoch 303/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0299 - accuracy: 0.9896 - val_loss: 0.9692 - val_accuracy: 0.8645\n","\n","Epoch 00303: val_accuracy did not improve from 0.92365\n","Epoch 304/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.5888 - val_accuracy: 0.8941\n","\n","Epoch 00304: val_accuracy did not improve from 0.92365\n","Epoch 305/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.5944 - val_accuracy: 0.8768\n","\n","Epoch 00305: val_accuracy did not improve from 0.92365\n","Epoch 306/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4583 - val_accuracy: 0.9113\n","\n","Epoch 00306: val_accuracy did not improve from 0.92365\n","Epoch 307/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5389 - val_accuracy: 0.9015\n","\n","Epoch 00307: val_accuracy did not improve from 0.92365\n","Epoch 308/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.5119 - val_accuracy: 0.8892\n","\n","Epoch 00308: val_accuracy did not improve from 0.92365\n","Epoch 309/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4826 - val_accuracy: 0.8966\n","\n","Epoch 00309: val_accuracy did not improve from 0.92365\n","Epoch 310/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.5226 - val_accuracy: 0.8842\n","\n","Epoch 00310: val_accuracy did not improve from 0.92365\n","Epoch 311/500\n","52/52 [==============================] - 16s 309ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5586 - val_accuracy: 0.8768\n","\n","Epoch 00311: val_accuracy did not improve from 0.92365\n","Epoch 312/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.8842\n","\n","Epoch 00312: val_accuracy did not improve from 0.92365\n","Epoch 313/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4699 - val_accuracy: 0.8916\n","\n","Epoch 00313: val_accuracy did not improve from 0.92365\n","Epoch 314/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4959 - val_accuracy: 0.8867\n","\n","Epoch 00314: val_accuracy did not improve from 0.92365\n","Epoch 315/500\n","52/52 [==============================] - 16s 308ms/step - loss: 9.1956e-04 - accuracy: 1.0000 - val_loss: 0.4527 - val_accuracy: 0.8990\n","\n","Epoch 00315: val_accuracy did not improve from 0.92365\n","Epoch 316/500\n","52/52 [==============================] - 16s 306ms/step - loss: 9.7353e-04 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.9113\n","\n","Epoch 00316: val_accuracy did not improve from 0.92365\n","Epoch 317/500\n","52/52 [==============================] - 16s 305ms/step - loss: 3.3825e-04 - accuracy: 1.0000 - val_loss: 0.4596 - val_accuracy: 0.9113\n","\n","Epoch 00317: val_accuracy did not improve from 0.92365\n","Epoch 318/500\n","52/52 [==============================] - 16s 307ms/step - loss: 6.7759e-04 - accuracy: 1.0000 - val_loss: 0.4809 - val_accuracy: 0.9064\n","\n","Epoch 00318: val_accuracy did not improve from 0.92365\n","Epoch 319/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.4850 - val_accuracy: 0.8892\n","\n","Epoch 00319: val_accuracy did not improve from 0.92365\n","Epoch 320/500\n","52/52 [==============================] - 16s 304ms/step - loss: 4.7304e-04 - accuracy: 1.0000 - val_loss: 0.3974 - val_accuracy: 0.9138\n","\n","Epoch 00320: val_accuracy did not improve from 0.92365\n","Epoch 321/500\n","52/52 [==============================] - 16s 305ms/step - loss: 4.5645e-04 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.9039\n","\n","Epoch 00321: val_accuracy did not improve from 0.92365\n","Epoch 322/500\n","52/52 [==============================] - 16s 307ms/step - loss: 5.7615e-04 - accuracy: 1.0000 - val_loss: 0.4938 - val_accuracy: 0.9138\n","\n","Epoch 00322: val_accuracy did not improve from 0.92365\n","Epoch 323/500\n","52/52 [==============================] - 16s 307ms/step - loss: 2.4791e-04 - accuracy: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.9039\n","\n","Epoch 00323: val_accuracy did not improve from 0.92365\n","Epoch 324/500\n","52/52 [==============================] - 16s 306ms/step - loss: 2.3522e-04 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.9163\n","\n","Epoch 00324: val_accuracy did not improve from 0.92365\n","Epoch 325/500\n","52/52 [==============================] - 16s 304ms/step - loss: 3.1403e-04 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9089\n","\n","Epoch 00325: val_accuracy did not improve from 0.92365\n","Epoch 326/500\n","52/52 [==============================] - 16s 307ms/step - loss: 8.1324e-04 - accuracy: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.9113\n","\n","Epoch 00326: val_accuracy did not improve from 0.92365\n","Epoch 327/500\n","52/52 [==============================] - 16s 308ms/step - loss: 3.7245e-04 - accuracy: 1.0000 - val_loss: 0.5193 - val_accuracy: 0.9089\n","\n","Epoch 00327: val_accuracy did not improve from 0.92365\n","Epoch 328/500\n","52/52 [==============================] - 16s 310ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5439 - val_accuracy: 0.9064\n","\n","Epoch 00328: val_accuracy did not improve from 0.92365\n","Epoch 329/500\n","52/52 [==============================] - 16s 309ms/step - loss: 8.4998e-04 - accuracy: 1.0000 - val_loss: 0.5631 - val_accuracy: 0.9015\n","\n","Epoch 00329: val_accuracy did not improve from 0.92365\n","Epoch 330/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.6184 - val_accuracy: 0.8990\n","\n","Epoch 00330: val_accuracy did not improve from 0.92365\n","Epoch 331/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.6718 - val_accuracy: 0.8842\n","\n","Epoch 00331: val_accuracy did not improve from 0.92365\n","Epoch 332/500\n","52/52 [==============================] - 16s 303ms/step - loss: 0.1044 - accuracy: 0.9750 - val_loss: 1.9658 - val_accuracy: 0.6773\n","\n","Epoch 00332: val_accuracy did not improve from 0.92365\n","Epoch 333/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0688 - accuracy: 0.9762 - val_loss: 1.0311 - val_accuracy: 0.7882\n","\n","Epoch 00333: val_accuracy did not improve from 0.92365\n","Epoch 334/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.8373 - val_accuracy: 0.8596\n","\n","Epoch 00334: val_accuracy did not improve from 0.92365\n","Epoch 335/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0237 - accuracy: 0.9915 - val_loss: 0.8084 - val_accuracy: 0.8670\n","\n","Epoch 00335: val_accuracy did not improve from 0.92365\n","Epoch 336/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0125 - accuracy: 0.9945 - val_loss: 0.7794 - val_accuracy: 0.8744\n","\n","Epoch 00336: val_accuracy did not improve from 0.92365\n","Epoch 337/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.6232 - val_accuracy: 0.8892\n","\n","Epoch 00337: val_accuracy did not improve from 0.92365\n","Epoch 338/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.6384 - val_accuracy: 0.8744\n","\n","Epoch 00338: val_accuracy did not improve from 0.92365\n","Epoch 339/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0059 - accuracy: 0.9970 - val_loss: 0.6388 - val_accuracy: 0.8818\n","\n","Epoch 00339: val_accuracy did not improve from 0.92365\n","Epoch 340/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5658 - val_accuracy: 0.8818\n","\n","Epoch 00340: val_accuracy did not improve from 0.92365\n","Epoch 341/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.5760 - val_accuracy: 0.8892\n","\n","Epoch 00341: val_accuracy did not improve from 0.92365\n","Epoch 342/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5797 - val_accuracy: 0.9015\n","\n","Epoch 00342: val_accuracy did not improve from 0.92365\n","Epoch 343/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5876 - val_accuracy: 0.8966\n","\n","Epoch 00343: val_accuracy did not improve from 0.92365\n","Epoch 344/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.7883 - val_accuracy: 0.8744\n","\n","Epoch 00344: val_accuracy did not improve from 0.92365\n","Epoch 345/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.6411 - val_accuracy: 0.8818\n","\n","Epoch 00345: val_accuracy did not improve from 0.92365\n","Epoch 346/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.6726 - val_accuracy: 0.8768\n","\n","Epoch 00346: val_accuracy did not improve from 0.92365\n","Epoch 347/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.6279 - val_accuracy: 0.8941\n","\n","Epoch 00347: val_accuracy did not improve from 0.92365\n","Epoch 348/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.6133 - val_accuracy: 0.8941\n","\n","Epoch 00348: val_accuracy did not improve from 0.92365\n","Epoch 349/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.7305 - val_accuracy: 0.8744\n","\n","Epoch 00349: val_accuracy did not improve from 0.92365\n","Epoch 350/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0277 - accuracy: 0.9939 - val_loss: 0.6491 - val_accuracy: 0.8547\n","\n","Epoch 00350: val_accuracy did not improve from 0.92365\n","Epoch 351/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0178 - accuracy: 0.9933 - val_loss: 0.5719 - val_accuracy: 0.8793\n","\n","Epoch 00351: val_accuracy did not improve from 0.92365\n","Epoch 352/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.6134 - val_accuracy: 0.8867\n","\n","Epoch 00352: val_accuracy did not improve from 0.92365\n","Epoch 353/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.4956 - val_accuracy: 0.9089\n","\n","Epoch 00353: val_accuracy did not improve from 0.92365\n","Epoch 354/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6251 - val_accuracy: 0.8941\n","\n","Epoch 00354: val_accuracy did not improve from 0.92365\n","Epoch 355/500\n","52/52 [==============================] - 16s 306ms/step - loss: 6.5791e-04 - accuracy: 1.0000 - val_loss: 0.5876 - val_accuracy: 0.9138\n","\n","Epoch 00355: val_accuracy did not improve from 0.92365\n","Epoch 356/500\n","52/52 [==============================] - 16s 307ms/step - loss: 7.1228e-04 - accuracy: 1.0000 - val_loss: 0.5805 - val_accuracy: 0.8941\n","\n","Epoch 00356: val_accuracy did not improve from 0.92365\n","Epoch 357/500\n","52/52 [==============================] - 16s 307ms/step - loss: 5.7769e-04 - accuracy: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.9138\n","\n","Epoch 00357: val_accuracy did not improve from 0.92365\n","Epoch 358/500\n","52/52 [==============================] - 16s 304ms/step - loss: 3.2844e-04 - accuracy: 1.0000 - val_loss: 0.5518 - val_accuracy: 0.9039\n","\n","Epoch 00358: val_accuracy did not improve from 0.92365\n","Epoch 359/500\n","52/52 [==============================] - 16s 307ms/step - loss: 6.9299e-04 - accuracy: 1.0000 - val_loss: 0.5313 - val_accuracy: 0.9089\n","\n","Epoch 00359: val_accuracy did not improve from 0.92365\n","Epoch 360/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.7212 - val_accuracy: 0.8892\n","\n","Epoch 00360: val_accuracy did not improve from 0.92365\n","Epoch 361/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5648 - val_accuracy: 0.9113\n","\n","Epoch 00361: val_accuracy did not improve from 0.92365\n","Epoch 362/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5203 - val_accuracy: 0.8941\n","\n","Epoch 00362: val_accuracy did not improve from 0.92365\n","Epoch 363/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.5657 - val_accuracy: 0.8842\n","\n","Epoch 00363: val_accuracy did not improve from 0.92365\n","Epoch 364/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0261 - accuracy: 0.9945 - val_loss: 0.7783 - val_accuracy: 0.8966\n","\n","Epoch 00364: val_accuracy did not improve from 0.92365\n","Epoch 365/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 0.7553 - val_accuracy: 0.8916\n","\n","Epoch 00365: val_accuracy did not improve from 0.92365\n","Epoch 366/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.7580 - val_accuracy: 0.8842\n","\n","Epoch 00366: val_accuracy did not improve from 0.92365\n","Epoch 367/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0105 - accuracy: 0.9957 - val_loss: 0.5083 - val_accuracy: 0.8990\n","\n","Epoch 00367: val_accuracy did not improve from 0.92365\n","Epoch 368/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.5348 - val_accuracy: 0.8966\n","\n","Epoch 00368: val_accuracy did not improve from 0.92365\n","Epoch 369/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.5816 - val_accuracy: 0.8842\n","\n","Epoch 00369: val_accuracy did not improve from 0.92365\n","Epoch 370/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0317 - accuracy: 0.9921 - val_loss: 0.6289 - val_accuracy: 0.8744\n","\n","Epoch 00370: val_accuracy did not improve from 0.92365\n","Epoch 371/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.5960 - val_accuracy: 0.8695\n","\n","Epoch 00371: val_accuracy did not improve from 0.92365\n","Epoch 372/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.8136 - val_accuracy: 0.8695\n","\n","Epoch 00372: val_accuracy did not improve from 0.92365\n","Epoch 373/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0199 - accuracy: 0.9909 - val_loss: 0.7601 - val_accuracy: 0.8892\n","\n","Epoch 00373: val_accuracy did not improve from 0.92365\n","Epoch 374/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0095 - accuracy: 0.9957 - val_loss: 0.6153 - val_accuracy: 0.8916\n","\n","Epoch 00374: val_accuracy did not improve from 0.92365\n","Epoch 375/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.8308 - val_accuracy: 0.8670\n","\n","Epoch 00375: val_accuracy did not improve from 0.92365\n","Epoch 376/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.5952 - val_accuracy: 0.8768\n","\n","Epoch 00376: val_accuracy did not improve from 0.92365\n","Epoch 377/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.6141 - val_accuracy: 0.8818\n","\n","Epoch 00377: val_accuracy did not improve from 0.92365\n","Epoch 378/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.5664 - val_accuracy: 0.8892\n","\n","Epoch 00378: val_accuracy did not improve from 0.92365\n","Epoch 379/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4479 - val_accuracy: 0.9039\n","\n","Epoch 00379: val_accuracy did not improve from 0.92365\n","Epoch 380/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.6357 - val_accuracy: 0.8768\n","\n","Epoch 00380: val_accuracy did not improve from 0.92365\n","Epoch 381/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5500 - val_accuracy: 0.8941\n","\n","Epoch 00381: val_accuracy did not improve from 0.92365\n","Epoch 382/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5369 - val_accuracy: 0.8892\n","\n","Epoch 00382: val_accuracy did not improve from 0.92365\n","Epoch 383/500\n","52/52 [==============================] - 16s 306ms/step - loss: 7.6491e-04 - accuracy: 1.0000 - val_loss: 0.6122 - val_accuracy: 0.8916\n","\n","Epoch 00383: val_accuracy did not improve from 0.92365\n","Epoch 384/500\n","52/52 [==============================] - 16s 306ms/step - loss: 5.5245e-04 - accuracy: 1.0000 - val_loss: 0.6114 - val_accuracy: 0.8941\n","\n","Epoch 00384: val_accuracy did not improve from 0.92365\n","Epoch 385/500\n","52/52 [==============================] - 16s 304ms/step - loss: 4.2706e-04 - accuracy: 1.0000 - val_loss: 0.5474 - val_accuracy: 0.9039\n","\n","Epoch 00385: val_accuracy did not improve from 0.92365\n","Epoch 386/500\n","52/52 [==============================] - 16s 307ms/step - loss: 3.3064e-04 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.8990\n","\n","Epoch 00386: val_accuracy did not improve from 0.92365\n","Epoch 387/500\n","52/52 [==============================] - 16s 307ms/step - loss: 4.5494e-04 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.9212\n","\n","Epoch 00387: val_accuracy did not improve from 0.92365\n","Epoch 388/500\n","52/52 [==============================] - 16s 307ms/step - loss: 1.9957e-04 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.8990\n","\n","Epoch 00388: val_accuracy did not improve from 0.92365\n","Epoch 389/500\n","52/52 [==============================] - 16s 305ms/step - loss: 9.7930e-04 - accuracy: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.9138\n","\n","Epoch 00389: val_accuracy did not improve from 0.92365\n","Epoch 390/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.7608 - val_accuracy: 0.8941\n","\n","Epoch 00390: val_accuracy did not improve from 0.92365\n","Epoch 391/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 0.8842\n","\n","Epoch 00391: val_accuracy did not improve from 0.92365\n","Epoch 392/500\n","52/52 [==============================] - 16s 307ms/step - loss: 6.2003e-04 - accuracy: 1.0000 - val_loss: 0.6093 - val_accuracy: 0.8818\n","\n","Epoch 00392: val_accuracy did not improve from 0.92365\n","Epoch 393/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.6308 - val_accuracy: 0.9064\n","\n","Epoch 00393: val_accuracy did not improve from 0.92365\n","Epoch 394/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.6729 - val_accuracy: 0.8818\n","\n","Epoch 00394: val_accuracy did not improve from 0.92365\n","Epoch 395/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 1.6331 - val_accuracy: 0.7611\n","\n","Epoch 00395: val_accuracy did not improve from 0.92365\n","Epoch 396/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 1.0097 - val_accuracy: 0.8251\n","\n","Epoch 00396: val_accuracy did not improve from 0.92365\n","Epoch 397/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0369 - accuracy: 0.9872 - val_loss: 1.1243 - val_accuracy: 0.8448\n","\n","Epoch 00397: val_accuracy did not improve from 0.92365\n","Epoch 398/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 0.7980 - val_accuracy: 0.8842\n","\n","Epoch 00398: val_accuracy did not improve from 0.92365\n","Epoch 399/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0277 - accuracy: 0.9927 - val_loss: 0.7082 - val_accuracy: 0.8744\n","\n","Epoch 00399: val_accuracy did not improve from 0.92365\n","Epoch 400/500\n","52/52 [==============================] - 16s 310ms/step - loss: 0.0240 - accuracy: 0.9945 - val_loss: 0.8823 - val_accuracy: 0.8842\n","\n","Epoch 00400: val_accuracy did not improve from 0.92365\n","Epoch 401/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.6860 - val_accuracy: 0.8793\n","\n","Epoch 00401: val_accuracy did not improve from 0.92365\n","Epoch 402/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.7614 - val_accuracy: 0.8793\n","\n","Epoch 00402: val_accuracy did not improve from 0.92365\n","Epoch 403/500\n","52/52 [==============================] - 16s 309ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.7793 - val_accuracy: 0.8744\n","\n","Epoch 00403: val_accuracy did not improve from 0.92365\n","Epoch 404/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.6962 - val_accuracy: 0.8793\n","\n","Epoch 00404: val_accuracy did not improve from 0.92365\n","Epoch 405/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.6232 - val_accuracy: 0.8892\n","\n","Epoch 00405: val_accuracy did not improve from 0.92365\n","Epoch 406/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6912 - val_accuracy: 0.8695\n","\n","Epoch 00406: val_accuracy did not improve from 0.92365\n","Epoch 407/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.5159 - val_accuracy: 0.8892\n","\n","Epoch 00407: val_accuracy did not improve from 0.92365\n","Epoch 408/500\n","52/52 [==============================] - 16s 309ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.6561 - val_accuracy: 0.8867\n","\n","Epoch 00408: val_accuracy did not improve from 0.92365\n","Epoch 409/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5342 - val_accuracy: 0.8892\n","\n","Epoch 00409: val_accuracy did not improve from 0.92365\n","Epoch 410/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5877 - val_accuracy: 0.8892\n","\n","Epoch 00410: val_accuracy did not improve from 0.92365\n","Epoch 411/500\n","52/52 [==============================] - 16s 305ms/step - loss: 6.0684e-04 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.9039\n","\n","Epoch 00411: val_accuracy did not improve from 0.92365\n","Epoch 412/500\n","52/52 [==============================] - 16s 304ms/step - loss: 3.8966e-04 - accuracy: 1.0000 - val_loss: 0.5854 - val_accuracy: 0.9138\n","\n","Epoch 00412: val_accuracy did not improve from 0.92365\n","Epoch 413/500\n","52/52 [==============================] - 16s 306ms/step - loss: 2.8322e-04 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.9089\n","\n","Epoch 00413: val_accuracy did not improve from 0.92365\n","Epoch 414/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.7586 - val_accuracy: 0.8990\n","\n","Epoch 00414: val_accuracy did not improve from 0.92365\n","Epoch 415/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5617 - val_accuracy: 0.9064\n","\n","Epoch 00415: val_accuracy did not improve from 0.92365\n","Epoch 416/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.7460 - val_accuracy: 0.8744\n","\n","Epoch 00416: val_accuracy did not improve from 0.92365\n","Epoch 417/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 0.5898 - val_accuracy: 0.8842\n","\n","Epoch 00417: val_accuracy did not improve from 0.92365\n","Epoch 418/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.8951 - val_accuracy: 0.8596\n","\n","Epoch 00418: val_accuracy did not improve from 0.92365\n","Epoch 419/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.7635 - val_accuracy: 0.8695\n","\n","Epoch 00419: val_accuracy did not improve from 0.92365\n","Epoch 420/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.7343 - val_accuracy: 0.8793\n","\n","Epoch 00420: val_accuracy did not improve from 0.92365\n","Epoch 421/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5889 - val_accuracy: 0.9039\n","\n","Epoch 00421: val_accuracy did not improve from 0.92365\n","Epoch 422/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6308 - val_accuracy: 0.8966\n","\n","Epoch 00422: val_accuracy did not improve from 0.92365\n","Epoch 423/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 1.5293 - val_accuracy: 0.7291\n","\n","Epoch 00423: val_accuracy did not improve from 0.92365\n","Epoch 424/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0963 - accuracy: 0.9762 - val_loss: 0.8124 - val_accuracy: 0.8670\n","\n","Epoch 00424: val_accuracy did not improve from 0.92365\n","Epoch 425/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.7483 - val_accuracy: 0.8966\n","\n","Epoch 00425: val_accuracy did not improve from 0.92365\n","Epoch 426/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.5822 - val_accuracy: 0.8892\n","\n","Epoch 00426: val_accuracy did not improve from 0.92365\n","Epoch 427/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.5680 - val_accuracy: 0.8966\n","\n","Epoch 00427: val_accuracy did not improve from 0.92365\n","Epoch 428/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0114 - accuracy: 0.9945 - val_loss: 0.5848 - val_accuracy: 0.8793\n","\n","Epoch 00428: val_accuracy did not improve from 0.92365\n","Epoch 429/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.5868 - val_accuracy: 0.8670\n","\n","Epoch 00429: val_accuracy did not improve from 0.92365\n","Epoch 430/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.7347 - val_accuracy: 0.8522\n","\n","Epoch 00430: val_accuracy did not improve from 0.92365\n","Epoch 431/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0494 - accuracy: 0.9890 - val_loss: 0.8974 - val_accuracy: 0.8621\n","\n","Epoch 00431: val_accuracy did not improve from 0.92365\n","Epoch 432/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.6853 - val_accuracy: 0.8892\n","\n","Epoch 00432: val_accuracy did not improve from 0.92365\n","Epoch 433/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.5582 - val_accuracy: 0.8892\n","\n","Epoch 00433: val_accuracy did not improve from 0.92365\n","Epoch 434/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5751 - val_accuracy: 0.9039\n","\n","Epoch 00434: val_accuracy did not improve from 0.92365\n","Epoch 435/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.6038 - val_accuracy: 0.8793\n","\n","Epoch 00435: val_accuracy did not improve from 0.92365\n","Epoch 436/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.4487 - val_accuracy: 0.9064\n","\n","Epoch 00436: val_accuracy did not improve from 0.92365\n","Epoch 437/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.5747 - val_accuracy: 0.9089\n","\n","Epoch 00437: val_accuracy did not improve from 0.92365\n","Epoch 438/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4106 - val_accuracy: 0.9064\n","\n","Epoch 00438: val_accuracy did not improve from 0.92365\n","Epoch 439/500\n","52/52 [==============================] - 16s 305ms/step - loss: 9.1545e-04 - accuracy: 1.0000 - val_loss: 0.6181 - val_accuracy: 0.8916\n","\n","Epoch 00439: val_accuracy did not improve from 0.92365\n","Epoch 440/500\n","52/52 [==============================] - 16s 309ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.6163 - val_accuracy: 0.8916\n","\n","Epoch 00440: val_accuracy did not improve from 0.92365\n","Epoch 441/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.6341 - val_accuracy: 0.8916\n","\n","Epoch 00441: val_accuracy did not improve from 0.92365\n","Epoch 442/500\n","52/52 [==============================] - 16s 304ms/step - loss: 8.4047e-04 - accuracy: 1.0000 - val_loss: 0.5746 - val_accuracy: 0.9015\n","\n","Epoch 00442: val_accuracy did not improve from 0.92365\n","Epoch 443/500\n","52/52 [==============================] - 16s 306ms/step - loss: 2.6542e-04 - accuracy: 1.0000 - val_loss: 0.6210 - val_accuracy: 0.8941\n","\n","Epoch 00443: val_accuracy did not improve from 0.92365\n","Epoch 444/500\n","52/52 [==============================] - 16s 307ms/step - loss: 5.7543e-04 - accuracy: 1.0000 - val_loss: 0.5726 - val_accuracy: 0.8966\n","\n","Epoch 00444: val_accuracy did not improve from 0.92365\n","Epoch 445/500\n","52/52 [==============================] - 16s 308ms/step - loss: 7.1274e-04 - accuracy: 1.0000 - val_loss: 0.5182 - val_accuracy: 0.9064\n","\n","Epoch 00445: val_accuracy did not improve from 0.92365\n","Epoch 446/500\n","52/52 [==============================] - 16s 307ms/step - loss: 2.4362e-04 - accuracy: 1.0000 - val_loss: 0.5438 - val_accuracy: 0.9113\n","\n","Epoch 00446: val_accuracy did not improve from 0.92365\n","Epoch 447/500\n","52/52 [==============================] - 16s 304ms/step - loss: 5.5109e-04 - accuracy: 1.0000 - val_loss: 0.5824 - val_accuracy: 0.9015\n","\n","Epoch 00447: val_accuracy did not improve from 0.92365\n","Epoch 448/500\n","52/52 [==============================] - 16s 307ms/step - loss: 3.6570e-04 - accuracy: 1.0000 - val_loss: 0.5841 - val_accuracy: 0.8941\n","\n","Epoch 00448: val_accuracy did not improve from 0.92365\n","Epoch 449/500\n","52/52 [==============================] - 16s 309ms/step - loss: 1.6285e-04 - accuracy: 1.0000 - val_loss: 0.5415 - val_accuracy: 0.9064\n","\n","Epoch 00449: val_accuracy did not improve from 0.92365\n","Epoch 450/500\n","52/52 [==============================] - 16s 307ms/step - loss: 9.0575e-04 - accuracy: 0.9994 - val_loss: 0.5575 - val_accuracy: 0.9089\n","\n","Epoch 00450: val_accuracy did not improve from 0.92365\n","Epoch 451/500\n","52/52 [==============================] - 16s 308ms/step - loss: 5.2025e-04 - accuracy: 1.0000 - val_loss: 0.5707 - val_accuracy: 0.9064\n","\n","Epoch 00451: val_accuracy did not improve from 0.92365\n","Epoch 452/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.5353 - val_accuracy: 0.8941\n","\n","Epoch 00452: val_accuracy did not improve from 0.92365\n","Epoch 453/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5710 - val_accuracy: 0.9064\n","\n","Epoch 00453: val_accuracy did not improve from 0.92365\n","Epoch 454/500\n","52/52 [==============================] - 16s 308ms/step - loss: 9.9142e-04 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.9089\n","\n","Epoch 00454: val_accuracy did not improve from 0.92365\n","Epoch 455/500\n","52/52 [==============================] - 16s 307ms/step - loss: 4.8931e-04 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.9015\n","\n","Epoch 00455: val_accuracy did not improve from 0.92365\n","Epoch 456/500\n","52/52 [==============================] - 16s 304ms/step - loss: 3.9435e-04 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.9310\n","\n","Epoch 00456: val_accuracy improved from 0.92365 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5\n","Epoch 457/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.5469 - val_accuracy: 0.9039\n","\n","Epoch 00457: val_accuracy did not improve from 0.93103\n","Epoch 458/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5563 - val_accuracy: 0.9163\n","\n","Epoch 00458: val_accuracy did not improve from 0.93103\n","Epoch 459/500\n","52/52 [==============================] - 16s 306ms/step - loss: 6.2539e-04 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9163\n","\n","Epoch 00459: val_accuracy did not improve from 0.93103\n","Epoch 460/500\n","52/52 [==============================] - 16s 306ms/step - loss: 2.9588e-04 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.9089\n","\n","Epoch 00460: val_accuracy did not improve from 0.93103\n","Epoch 461/500\n","52/52 [==============================] - 16s 307ms/step - loss: 5.1921e-04 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9310\n","\n","Epoch 00461: val_accuracy did not improve from 0.93103\n","Epoch 462/500\n","52/52 [==============================] - 16s 307ms/step - loss: 6.2238e-04 - accuracy: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.9138\n","\n","Epoch 00462: val_accuracy did not improve from 0.93103\n","Epoch 463/500\n","52/52 [==============================] - 16s 306ms/step - loss: 2.0787e-04 - accuracy: 1.0000 - val_loss: 0.5462 - val_accuracy: 0.9113\n","\n","Epoch 00463: val_accuracy did not improve from 0.93103\n","Epoch 464/500\n","52/52 [==============================] - 16s 306ms/step - loss: 1.8795e-04 - accuracy: 1.0000 - val_loss: 0.6424 - val_accuracy: 0.8941\n","\n","Epoch 00464: val_accuracy did not improve from 0.93103\n","Epoch 465/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5779 - val_accuracy: 0.8966\n","\n","Epoch 00465: val_accuracy did not improve from 0.93103\n","Epoch 466/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.8122 - val_accuracy: 0.8719\n","\n","Epoch 00466: val_accuracy did not improve from 0.93103\n","Epoch 467/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.8684 - val_accuracy: 0.8793\n","\n","Epoch 00467: val_accuracy did not improve from 0.93103\n","Epoch 468/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0533 - accuracy: 0.9878 - val_loss: 0.6581 - val_accuracy: 0.8916\n","\n","Epoch 00468: val_accuracy did not improve from 0.93103\n","Epoch 469/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.7934 - val_accuracy: 0.8768\n","\n","Epoch 00469: val_accuracy did not improve from 0.93103\n","Epoch 470/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0284 - accuracy: 0.9927 - val_loss: 1.2493 - val_accuracy: 0.8325\n","\n","Epoch 00470: val_accuracy did not improve from 0.93103\n","Epoch 471/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0254 - accuracy: 0.9951 - val_loss: 0.6638 - val_accuracy: 0.8498\n","\n","Epoch 00471: val_accuracy did not improve from 0.93103\n","Epoch 472/500\n","52/52 [==============================] - 16s 309ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 1.5701 - val_accuracy: 0.7808\n","\n","Epoch 00472: val_accuracy did not improve from 0.93103\n","Epoch 473/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0372 - accuracy: 0.9890 - val_loss: 0.8751 - val_accuracy: 0.8695\n","\n","Epoch 00473: val_accuracy did not improve from 0.93103\n","Epoch 474/500\n","52/52 [==============================] - 16s 306ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.5422 - val_accuracy: 0.8990\n","\n","Epoch 00474: val_accuracy did not improve from 0.93103\n","Epoch 475/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4995 - val_accuracy: 0.9039\n","\n","Epoch 00475: val_accuracy did not improve from 0.93103\n","Epoch 476/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.5045 - val_accuracy: 0.8916\n","\n","Epoch 00476: val_accuracy did not improve from 0.93103\n","Epoch 477/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.9015\n","\n","Epoch 00477: val_accuracy did not improve from 0.93103\n","Epoch 478/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.9039\n","\n","Epoch 00478: val_accuracy did not improve from 0.93103\n","Epoch 479/500\n","52/52 [==============================] - 16s 307ms/step - loss: 7.6935e-04 - accuracy: 1.0000 - val_loss: 0.5473 - val_accuracy: 0.9015\n","\n","Epoch 00479: val_accuracy did not improve from 0.93103\n","Epoch 480/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 0.5686 - val_accuracy: 0.9113\n","\n","Epoch 00480: val_accuracy did not improve from 0.93103\n","Epoch 481/500\n","52/52 [==============================] - 16s 306ms/step - loss: 7.6476e-04 - accuracy: 1.0000 - val_loss: 0.5139 - val_accuracy: 0.9089\n","\n","Epoch 00481: val_accuracy did not improve from 0.93103\n","Epoch 482/500\n","52/52 [==============================] - 16s 304ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.5484 - val_accuracy: 0.9089\n","\n","Epoch 00482: val_accuracy did not improve from 0.93103\n","Epoch 483/500\n","52/52 [==============================] - 16s 305ms/step - loss: 5.0561e-04 - accuracy: 1.0000 - val_loss: 0.5708 - val_accuracy: 0.9064\n","\n","Epoch 00483: val_accuracy did not improve from 0.93103\n","Epoch 484/500\n","52/52 [==============================] - 16s 308ms/step - loss: 5.7595e-04 - accuracy: 1.0000 - val_loss: 0.5576 - val_accuracy: 0.8941\n","\n","Epoch 00484: val_accuracy did not improve from 0.93103\n","Epoch 485/500\n","52/52 [==============================] - 16s 308ms/step - loss: 2.9979e-04 - accuracy: 1.0000 - val_loss: 0.5778 - val_accuracy: 0.8941\n","\n","Epoch 00485: val_accuracy did not improve from 0.93103\n","Epoch 486/500\n","52/52 [==============================] - 16s 306ms/step - loss: 6.8600e-04 - accuracy: 1.0000 - val_loss: 0.5846 - val_accuracy: 0.8966\n","\n","Epoch 00486: val_accuracy did not improve from 0.93103\n","Epoch 487/500\n","52/52 [==============================] - 16s 305ms/step - loss: 2.9136e-04 - accuracy: 1.0000 - val_loss: 0.5678 - val_accuracy: 0.8941\n","\n","Epoch 00487: val_accuracy did not improve from 0.93103\n","Epoch 488/500\n","52/52 [==============================] - 16s 306ms/step - loss: 3.2140e-04 - accuracy: 1.0000 - val_loss: 0.5305 - val_accuracy: 0.8966\n","\n","Epoch 00488: val_accuracy did not improve from 0.93103\n","Epoch 489/500\n","52/52 [==============================] - 16s 307ms/step - loss: 2.8804e-04 - accuracy: 1.0000 - val_loss: 0.5215 - val_accuracy: 0.9039\n","\n","Epoch 00489: val_accuracy did not improve from 0.93103\n","Epoch 490/500\n","52/52 [==============================] - 16s 307ms/step - loss: 2.2587e-04 - accuracy: 1.0000 - val_loss: 0.5507 - val_accuracy: 0.8990\n","\n","Epoch 00490: val_accuracy did not improve from 0.93103\n","Epoch 491/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 0.6911 - val_accuracy: 0.8990\n","\n","Epoch 00491: val_accuracy did not improve from 0.93103\n","Epoch 492/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.8332 - val_accuracy: 0.8621\n","\n","Epoch 00492: val_accuracy did not improve from 0.93103\n","Epoch 493/500\n","52/52 [==============================] - 16s 305ms/step - loss: 0.0261 - accuracy: 0.9909 - val_loss: 1.2447 - val_accuracy: 0.8374\n","\n","Epoch 00493: val_accuracy did not improve from 0.93103\n","Epoch 494/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0428 - accuracy: 0.9848 - val_loss: 0.8601 - val_accuracy: 0.8867\n","\n","Epoch 00494: val_accuracy did not improve from 0.93103\n","Epoch 495/500\n","52/52 [==============================] - 16s 309ms/step - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.4395 - val_accuracy: 0.8916\n","\n","Epoch 00495: val_accuracy did not improve from 0.93103\n","Epoch 496/500\n","52/52 [==============================] - 16s 309ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.9668 - val_accuracy: 0.8424\n","\n","Epoch 00496: val_accuracy did not improve from 0.93103\n","Epoch 497/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0177 - accuracy: 0.9933 - val_loss: 1.0356 - val_accuracy: 0.8498\n","\n","Epoch 00497: val_accuracy did not improve from 0.93103\n","Epoch 498/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0134 - accuracy: 0.9945 - val_loss: 0.9343 - val_accuracy: 0.8079\n","\n","Epoch 00498: val_accuracy did not improve from 0.93103\n","Epoch 499/500\n","52/52 [==============================] - 16s 307ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6002 - val_accuracy: 0.8719\n","\n","Epoch 00499: val_accuracy did not improve from 0.93103\n","Epoch 500/500\n","52/52 [==============================] - 16s 308ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5840 - val_accuracy: 0.8966\n","\n","Epoch 00500: val_accuracy did not improve from 0.93103\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff227db9bd0>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"jwCU-wIQ2ov5"},"source":["# import matplotlib.pyplot as plt\n","\n","# plt.plot(ResNet50_model.history.history[\"accuracy\"], label='ResNet50_ACC')\n","# plt.plot(ResNet50_model.history.history[\"val_accuracy\"], label='ResNet50_VAL')\n","\n","# plt.plot(ResNet101_model.history.history[\"accuracy\"], label='ResNet101_ACC')\n","# plt.plot(ResNet101_model.history.history[\"val_accuracy\"], label='ResNet101_VAL')\n","\n","# plt.plot(ResNet152_model.history.history[\"accuracy\"], label='ResNet152_ACC')\n","# plt.plot(ResNet152_model.history.history[\"val_accuracy\"], label='ResNet152_VAL')\n","\n","# plt.plot(ResNet50V2_model.history.history[\"accuracy\"], label='ResNet50V2_ACC')\n","# plt.plot(ResNet50V2_model.history.history[\"val_accuracy\"], label='ResNet50V2_VAL')\n","\n","# plt.plot(ResNet101V2_model.history.history[\"accuracy\"], label='ResNet101V2_ACC')\n","# plt.plot(ResNet101V2_model.history.history[\"val_accuracy\"], label='ResNet101V2_VAL')\n","\n","# plt.plot(ResNet152V2_model.history.history[\"accuracy\"], label='ResNet152V2_ACC')\n","# plt.plot(ResNet152V2_model.history.history[\"val_accuracy\"], label='ResNet152V2_VAL')\n","\n","# plt.plot(VGG16_model.history.history[\"accuracy\"], label='VGG16_ACC')\n","# plt.plot(VGG16_model.history.history[\"val_accuracy\"], label='VGG16_VAL')\n","\n","# plt.plot(VGG19_model.history.history[\"accuracy\"], label='VGG19_ACC')\n","# plt.plot(VGG19_model.history.history[\"val_accuracy\"], label='VGG19_VAL')\n","\n","# plt.plot(InceptionV3_model.history.history[\"accuracy\"], label='InceptionV3_ACC')\n","# plt.plot(InceptionV3_model.history.history[\"val_accuracy\"], label='InceptionV3_VAL')\n","\n","# plt.plot(InceptionV2_model.history.history[\"accuracy\"], label='InceptionResNetV2_ACC')\n","# plt.plot(InceptionV2_model.history.history[\"val_accuracy\"], label='InceptionResNetV2_VAL')\n","\n","# plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_ACC')\n","# plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_VAL')\n","\n","# plt.plot(DenseNet169_model.history.history[\"accuracy\"], label='DenseNet169_ACC')\n","# plt.plot(DenseNet169_model.history.history[\"val_accuracy\"], label='DenseNet169_VAL')\n","\n","# plt.plot(DenseNet201_model.history.history[\"accuracy\"], label='DenseNet201_ACC')\n","# plt.plot(DenseNet201_model.history.history[\"val_accuracy\"], label='DenseNet201_VAL')\n","\n","# plt.legend()\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2_ixogRq2rPq","executionInfo":{"status":"ok","timestamp":1628190557884,"user_tz":-540,"elapsed":280909,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["ResNet50_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50.h5', compile=False)\n","ResNet101_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101.h5', compile=False)\n","ResNet152_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152.h5', compile=False)\n","ResNet50V2_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet50V2.h5', compile=False)\n","ResNet101V2_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet101V2.h5', compile=False)\n","ResNet152V2_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_ResNet152V2.h5', compile=False)\n","VGG16_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_VGG16.h5', compile=False)\n","VGG19_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_VGG19.h5', compile=False)\n","InceptionV3_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionV3.h5', compile=False)\n","InceptionResNetV2_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_InceptionResNetV2.h5', compile=False)\n","DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet121.h5', compile=False)\n","DenseNet169_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet169.h5', compile=False)\n","DenseNet201_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_07_DenseNet201.h5', compile=False)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"fh6zt68w12-Q","executionInfo":{"status":"ok","timestamp":1628190558403,"user_tz":-540,"elapsed":532,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"4O3HCJC21Act","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628190559198,"user_tz":-540,"elapsed":798,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"31579ac3-5dbd-4237-b126-f2a8fc87492c"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Found 20480 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nFEcoCR-3DNH","executionInfo":{"status":"ok","timestamp":1628191184517,"user_tz":-540,"elapsed":625327,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"3135dbfa-b079-44b4-bb23-3f3edd421646"},"source":["ResNet50_predict = ResNet50_model.predict_generator(test_generator).argmax(axis=1)\n","ResNet101_predict = ResNet101_model.predict_generator(test_generator).argmax(axis=1)\n","ResNet152_predict = ResNet152_model.predict_generator(test_generator).argmax(axis=1)\n","ResNet50V2_predict = ResNet50V2_model.predict_generator(test_generator).argmax(axis=1)\n","ResNet101V2_predict = ResNet101V2_model.predict_generator(test_generator).argmax(axis=1)\n","ResNet152V2_predict = ResNet152V2_model.predict_generator(test_generator).argmax(axis=1)\n","VGG16_predict = VGG16_model.predict_generator(test_generator).argmax(axis=1)\n","VGG19_predict = VGG19_model.predict_generator(test_generator).argmax(axis=1)\n","InceptionV3_predict = InceptionV3_model.predict_generator(test_generator).argmax(axis=1)\n","InceptionResNetV2_predict = InceptionResNetV2_model.predict_generator(test_generator).argmax(axis=1)\n","DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)\n","DenseNet169_predict = DenseNet169_model.predict_generator(test_generator).argmax(axis=1)\n","DenseNet201_predict = DenseNet201_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1628191234148,"user_tz":-540,"elapsed":628,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c8fe5ddd-60a7-4b3f-fae3-d81fe02907f4"},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')\n","submission.head()"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2049</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2050</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2051</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2052</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2053</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     id  digit\n","0  2049      0\n","1  2050      0\n","2  2051      0\n","3  2052      0\n","4  2053      0"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1628191235472,"user_tz":-540,"elapsed":894,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"1727ab1a-1c45-42c8-9064-17db3603f6ed"},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)\n","print(mylist)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["['10000', '10001', '10002', '10003', '10004', '10005', '10006', '10007', '10008', '10009', '10010', '10011', '10012', '10013', '10014', '10015', '10016', '10017', '10018', '10019', '10020', '10021', '10022', '10023', '10024', '10025', '10026', '10027', '10028', '10029', '10030', '10031', '10032', '10033', '10034', '10035', '10036', '10037', '10038', '10039', '10040', '10041', '10042', '10043', '10044', '10045', '10046', '10047', '10048', '10049', '10050', '10051', '10052', '10053', '10054', '10055', '10056', '10057', '10058', '10059', '10060', '10061', '10062', '10063', '10064', '10065', '10066', '10067', '10068', '10069', '10070', '10071', '10072', '10073', '10074', '10075', '10076', '10077', '10078', '10079', '10080', '10081', '10082', '10083', '10084', '10085', '10086', '10087', '10088', '10089', '10090', '10091', '10092', '10093', '10094', '10095', '10096', '10097', '10098', '10099', '10100', '10101', '10102', '10103', '10104', '10105', '10106', '10107', '10108', '10109', '10110', '10111', '10112', '10113', '10114', '10115', '10116', '10117', '10118', '10119', '10120', '10121', '10122', '10123', '10124', '10125', '10126', '10127', '10128', '10129', '10130', '10131', '10132', '10133', '10134', '10135', '10136', '10137', '10138', '10139', '10140', '10141', '10142', '10143', '10144', '10145', '10146', '10147', '10148', '10149', '10150', '10151', '10152', '10153', '10154', '10155', '10156', '10157', '10158', '10159', '10160', '10161', '10162', '10163', '10164', '10165', '10166', '10167', '10168', '10169', '10170', '10171', '10172', '10173', '10174', '10175', '10176', '10177', '10178', '10179', '10180', '10181', '10182', '10183', '10184', '10185', '10186', '10187', '10188', '10189', '10190', '10191', '10192', '10193', '10194', '10195', '10196', '10197', '10198', '10199', '10200', '10201', '10202', '10203', '10204', '10205', '10206', '10207', '10208', '10209', '10210', '10211', '10212', '10213', '10214', '10215', '10216', '10217', '10218', '10219', '10220', '10221', '10222', '10223', '10224', '10225', '10226', '10227', '10228', '10229', '10230', '10231', '10232', '10233', '10234', '10235', '10236', '10237', '10238', '10239', '10240', '10241', '10242', '10243', '10244', '10245', '10246', '10247', '10248', '10249', '10250', '10251', '10252', '10253', '10254', '10255', '10256', '10257', '10258', '10259', '10260', '10261', '10262', '10263', '10264', '10265', '10266', '10267', '10268', '10269', '10270', '10271', '10272', '10273', '10274', '10275', '10276', '10277', '10278', '10279', '10280', '10281', '10282', '10283', '10284', '10285', '10286', '10287', '10288', '10289', '10290', '10291', '10292', '10293', '10294', '10295', '10296', '10297', '10298', '10299', '10300', '10301', '10302', '10303', '10304', '10305', '10306', '10307', '10308', '10309', '10310', '10311', '10312', '10313', '10314', '10315', '10316', '10317', '10318', '10319', '10320', '10321', '10322', '10323', '10324', '10325', '10326', '10327', '10328', '10329', '10330', '10331', '10332', '10333', '10334', '10335', '10336', '10337', '10338', '10339', '10340', '10341', '10342', '10343', '10344', '10345', '10346', '10347', '10348', '10349', '10350', '10351', '10352', '10353', '10354', '10355', '10356', '10357', '10358', '10359', '10360', '10361', '10362', '10363', '10364', '10365', '10366', '10367', '10368', '10369', '10370', '10371', '10372', '10373', '10374', '10375', '10376', '10377', '10378', '10379', '10380', '10381', '10382', '10383', '10384', '10385', '10386', '10387', '10388', '10389', '10390', '10391', '10392', '10393', '10394', '10395', '10396', '10397', '10398', '10399', '10400', '10401', '10402', '10403', '10404', '10405', '10406', '10407', '10408', '10409', '10410', '10411', '10412', '10413', '10414', '10415', '10416', '10417', '10418', '10419', '10420', '10421', '10422', '10423', '10424', '10425', '10426', '10427', '10428', '10429', '10430', '10431', '10432', '10433', '10434', '10435', '10436', '10437', '10438', '10439', '10440', '10441', '10442', '10443', '10444', '10445', '10446', '10447', '10448', '10449', '10450', '10451', '10452', '10453', '10454', '10455', '10456', '10457', '10458', '10459', '10460', '10461', '10462', '10463', '10464', '10465', '10466', '10467', '10468', '10469', '10470', '10471', '10472', '10473', '10474', '10475', '10476', '10477', '10478', '10479', '10480', '10481', '10482', '10483', '10484', '10485', '10486', '10487', '10488', '10489', '10490', '10491', '10492', '10493', '10494', '10495', '10496', '10497', '10498', '10499', '10500', '10501', '10502', '10503', '10504', '10505', '10506', '10507', '10508', '10509', '10510', '10511', '10512', '10513', '10514', '10515', '10516', '10517', '10518', '10519', '10520', '10521', '10522', '10523', '10524', '10525', '10526', '10527', '10528', '10529', '10530', '10531', '10532', '10533', '10534', '10535', '10536', '10537', '10538', '10539', '10540', '10541', '10542', '10543', '10544', '10545', '10546', '10547', '10548', '10549', '10550', '10551', '10552', '10553', '10554', '10555', '10556', '10557', '10558', '10559', '10560', '10561', '10562', '10563', '10564', '10565', '10566', '10567', '10568', '10569', '10570', '10571', '10572', '10573', '10574', '10575', '10576', '10577', '10578', '10579', '10580', '10581', '10582', '10583', '10584', '10585', '10586', '10587', '10588', '10589', '10590', '10591', '10592', '10593', '10594', '10595', '10596', '10597', '10598', '10599', '10600', '10601', '10602', '10603', '10604', '10605', '10606', '10607', '10608', '10609', '10610', '10611', '10612', '10613', '10614', '10615', '10616', '10617', '10618', '10619', '10620', '10621', '10622', '10623', '10624', '10625', '10626', '10627', '10628', '10629', '10630', '10631', '10632', '10633', '10634', '10635', '10636', '10637', '10638', '10639', '10640', '10641', '10642', '10643', '10644', '10645', '10646', '10647', '10648', '10649', '10650', '10651', '10652', '10653', '10654', '10655', '10656', '10657', '10658', '10659', '10660', '10661', '10662', '10663', '10664', '10665', '10666', '10667', '10668', '10669', '10670', '10671', '10672', '10673', '10674', '10675', '10676', '10677', '10678', '10679', '10680', '10681', '10682', '10683', '10684', '10685', '10686', '10687', '10688', '10689', '10690', '10691', '10692', '10693', '10694', '10695', '10696', '10697', '10698', '10699', '10700', '10701', '10702', '10703', '10704', '10705', '10706', '10707', '10708', '10709', '10710', '10711', '10712', '10713', '10714', '10715', '10716', '10717', '10718', '10719', '10720', '10721', '10722', '10723', '10724', '10725', '10726', '10727', '10728', '10729', '10730', '10731', '10732', '10733', '10734', '10735', '10736', '10737', '10738', '10739', '10740', '10741', '10742', '10743', '10744', '10745', '10746', '10747', '10748', '10749', '10750', '10751', '10752', '10753', '10754', '10755', '10756', '10757', '10758', '10759', '10760', '10761', '10762', '10763', '10764', '10765', '10766', '10767', '10768', '10769', '10770', '10771', '10772', '10773', '10774', '10775', '10776', '10777', '10778', '10779', '10780', '10781', '10782', '10783', '10784', '10785', '10786', '10787', '10788', '10789', '10790', '10791', '10792', '10793', '10794', '10795', '10796', '10797', '10798', '10799', '10800', '10801', '10802', '10803', '10804', '10805', '10806', '10807', '10808', '10809', '10810', '10811', '10812', '10813', '10814', '10815', '10816', '10817', '10818', '10819', '10820', '10821', '10822', '10823', '10824', '10825', '10826', '10827', '10828', '10829', '10830', '10831', '10832', '10833', '10834', '10835', '10836', '10837', '10838', '10839', '10840', '10841', '10842', '10843', '10844', '10845', '10846', '10847', '10848', '10849', '10850', '10851', '10852', '10853', '10854', '10855', '10856', '10857', '10858', '10859', '10860', '10861', '10862', '10863', '10864', '10865', '10866', '10867', '10868', '10869', '10870', '10871', '10872', '10873', '10874', '10875', '10876', '10877', '10878', '10879', '10880', '10881', '10882', '10883', '10884', '10885', '10886', '10887', '10888', '10889', '10890', '10891', '10892', '10893', '10894', '10895', '10896', '10897', '10898', '10899', '10900', '10901', '10902', '10903', '10904', '10905', '10906', '10907', '10908', '10909', '10910', '10911', '10912', '10913', '10914', '10915', '10916', '10917', '10918', '10919', '10920', '10921', '10922', '10923', '10924', '10925', '10926', '10927', '10928', '10929', '10930', '10931', '10932', '10933', '10934', '10935', '10936', '10937', '10938', '10939', '10940', '10941', '10942', '10943', '10944', '10945', '10946', '10947', '10948', '10949', '10950', '10951', '10952', '10953', '10954', '10955', '10956', '10957', '10958', '10959', '10960', '10961', '10962', '10963', '10964', '10965', '10966', '10967', '10968', '10969', '10970', '10971', '10972', '10973', '10974', '10975', '10976', '10977', '10978', '10979', '10980', '10981', '10982', '10983', '10984', '10985', '10986', '10987', '10988', '10989', '10990', '10991', '10992', '10993', '10994', '10995', '10996', '10997', '10998', '10999', '11000', '11001', '11002', '11003', '11004', '11005', '11006', '11007', '11008', '11009', '11010', '11011', '11012', '11013', '11014', '11015', '11016', '11017', '11018', '11019', '11020', '11021', '11022', '11023', '11024', '11025', '11026', '11027', '11028', '11029', '11030', '11031', '11032', '11033', '11034', '11035', '11036', '11037', '11038', '11039', '11040', '11041', '11042', '11043', '11044', '11045', '11046', '11047', '11048', '11049', '11050', '11051', '11052', '11053', '11054', '11055', '11056', '11057', '11058', '11059', '11060', '11061', '11062', '11063', '11064', '11065', '11066', '11067', '11068', '11069', '11070', '11071', '11072', '11073', '11074', '11075', '11076', '11077', '11078', '11079', '11080', '11081', '11082', '11083', '11084', '11085', '11086', '11087', '11088', '11089', '11090', '11091', '11092', '11093', '11094', '11095', '11096', '11097', '11098', '11099', '11100', '11101', '11102', '11103', '11104', '11105', '11106', '11107', '11108', '11109', '11110', '11111', '11112', '11113', '11114', '11115', '11116', '11117', '11118', '11119', '11120', '11121', '11122', '11123', '11124', '11125', '11126', '11127', '11128', '11129', '11130', '11131', '11132', '11133', '11134', '11135', '11136', '11137', '11138', '11139', '11140', '11141', '11142', '11143', '11144', '11145', '11146', '11147', '11148', '11149', '11150', '11151', '11152', '11153', '11154', '11155', '11156', '11157', '11158', '11159', '11160', '11161', '11162', '11163', '11164', '11165', '11166', '11167', '11168', '11169', '11170', '11171', '11172', '11173', '11174', '11175', '11176', '11177', '11178', '11179', '11180', '11181', '11182', '11183', '11184', '11185', '11186', '11187', '11188', '11189', '11190', '11191', '11192', '11193', '11194', '11195', '11196', '11197', '11198', '11199', '11200', '11201', '11202', '11203', '11204', '11205', '11206', '11207', '11208', '11209', '11210', '11211', '11212', '11213', '11214', '11215', '11216', '11217', '11218', '11219', '11220', '11221', '11222', '11223', '11224', '11225', '11226', '11227', '11228', '11229', '11230', '11231', '11232', '11233', '11234', '11235', '11236', '11237', '11238', '11239', '11240', '11241', '11242', '11243', '11244', '11245', '11246', '11247', '11248', '11249', '11250', '11251', '11252', '11253', '11254', '11255', '11256', '11257', '11258', '11259', '11260', '11261', '11262', '11263', '11264', '11265', '11266', '11267', '11268', '11269', '11270', '11271', '11272', '11273', '11274', '11275', '11276', '11277', '11278', '11279', '11280', '11281', '11282', '11283', '11284', '11285', '11286', '11287', '11288', '11289', '11290', '11291', '11292', '11293', '11294', '11295', '11296', '11297', '11298', '11299', '11300', '11301', '11302', '11303', '11304', '11305', '11306', '11307', '11308', '11309', '11310', '11311', '11312', '11313', '11314', '11315', '11316', '11317', '11318', '11319', '11320', '11321', '11322', '11323', '11324', '11325', '11326', '11327', '11328', '11329', '11330', '11331', '11332', '11333', '11334', '11335', '11336', '11337', '11338', '11339', '11340', '11341', '11342', '11343', '11344', '11345', '11346', '11347', '11348', '11349', '11350', '11351', '11352', '11353', '11354', '11355', '11356', '11357', '11358', '11359', '11360', '11361', '11362', '11363', '11364', '11365', '11366', '11367', '11368', '11369', '11370', '11371', '11372', '11373', '11374', '11375', '11376', '11377', '11378', '11379', '11380', '11381', '11382', '11383', '11384', '11385', '11386', '11387', '11388', '11389', '11390', '11391', '11392', '11393', '11394', '11395', '11396', '11397', '11398', '11399', '11400', '11401', '11402', '11403', '11404', '11405', '11406', '11407', '11408', '11409', '11410', '11411', '11412', '11413', '11414', '11415', '11416', '11417', '11418', '11419', '11420', '11421', '11422', '11423', '11424', '11425', '11426', '11427', '11428', '11429', '11430', '11431', '11432', '11433', '11434', '11435', '11436', '11437', '11438', '11439', '11440', '11441', '11442', '11443', '11444', '11445', '11446', '11447', '11448', '11449', '11450', '11451', '11452', '11453', '11454', '11455', '11456', '11457', '11458', '11459', '11460', '11461', '11462', '11463', '11464', '11465', '11466', '11467', '11468', '11469', '11470', '11471', '11472', '11473', '11474', '11475', '11476', '11477', '11478', '11479', '11480', '11481', '11482', '11483', '11484', '11485', '11486', '11487', '11488', '11489', '11490', '11491', '11492', '11493', '11494', '11495', '11496', '11497', '11498', '11499', '11500', '11501', '11502', '11503', '11504', '11505', '11506', '11507', '11508', '11509', '11510', '11511', '11512', '11513', '11514', '11515', '11516', '11517', '11518', '11519', '11520', '11521', '11522', '11523', '11524', '11525', '11526', '11527', '11528', '11529', '11530', '11531', '11532', '11533', '11534', '11535', '11536', '11537', '11538', '11539', '11540', '11541', '11542', '11543', '11544', '11545', '11546', '11547', '11548', '11549', '11550', '11551', '11552', '11553', '11554', '11555', '11556', '11557', '11558', '11559', '11560', '11561', '11562', '11563', '11564', '11565', '11566', '11567', '11568', '11569', '11570', '11571', '11572', '11573', '11574', '11575', '11576', '11577', '11578', '11579', '11580', '11581', '11582', '11583', '11584', '11585', '11586', '11587', '11588', '11589', '11590', '11591', '11592', '11593', '11594', '11595', '11596', '11597', '11598', '11599', '11600', '11601', '11602', '11603', '11604', '11605', '11606', '11607', '11608', '11609', '11610', '11611', '11612', '11613', '11614', '11615', '11616', '11617', '11618', '11619', '11620', '11621', '11622', '11623', '11624', '11625', '11626', '11627', '11628', '11629', '11630', '11631', '11632', '11633', '11634', '11635', '11636', '11637', '11638', '11639', '11640', '11641', '11642', '11643', '11644', '11645', '11646', '11647', '11648', '11649', '11650', '11651', '11652', '11653', '11654', '11655', '11656', '11657', '11658', '11659', '11660', '11661', '11662', '11663', '11664', '11665', '11666', '11667', '11668', '11669', '11670', '11671', '11672', '11673', '11674', '11675', '11676', '11677', '11678', '11679', '11680', '11681', '11682', '11683', '11684', '11685', '11686', '11687', '11688', '11689', '11690', '11691', '11692', '11693', '11694', '11695', '11696', '11697', '11698', '11699', '11700', '11701', '11702', '11703', '11704', '11705', '11706', '11707', '11708', '11709', '11710', '11711', '11712', '11713', '11714', '11715', '11716', '11717', '11718', '11719', '11720', '11721', '11722', '11723', '11724', '11725', '11726', '11727', '11728', '11729', '11730', '11731', '11732', '11733', '11734', '11735', '11736', '11737', '11738', '11739', '11740', '11741', '11742', '11743', '11744', '11745', '11746', '11747', '11748', '11749', '11750', '11751', '11752', '11753', '11754', '11755', '11756', '11757', '11758', '11759', '11760', '11761', '11762', '11763', '11764', '11765', '11766', '11767', '11768', '11769', '11770', '11771', '11772', '11773', '11774', '11775', '11776', '11777', '11778', '11779', '11780', '11781', '11782', '11783', '11784', '11785', '11786', '11787', '11788', '11789', '11790', '11791', '11792', '11793', '11794', '11795', '11796', '11797', '11798', '11799', '11800', '11801', '11802', '11803', '11804', '11805', '11806', '11807', '11808', '11809', '11810', '11811', '11812', '11813', '11814', '11815', '11816', '11817', '11818', '11819', '11820', '11821', '11822', '11823', '11824', '11825', '11826', '11827', '11828', '11829', '11830', '11831', '11832', '11833', '11834', '11835', '11836', '11837', '11838', '11839', '11840', '11841', '11842', '11843', '11844', '11845', '11846', '11847', '11848', '11849', '11850', '11851', '11852', '11853', '11854', '11855', '11856', '11857', '11858', '11859', '11860', '11861', '11862', '11863', '11864', '11865', '11866', '11867', '11868', '11869', '11870', '11871', '11872', '11873', '11874', '11875', '11876', '11877', '11878', '11879', '11880', '11881', '11882', '11883', '11884', '11885', '11886', '11887', '11888', '11889', '11890', '11891', '11892', '11893', '11894', '11895', '11896', '11897', '11898', '11899', '11900', '11901', '11902', '11903', '11904', '11905', '11906', '11907', '11908', '11909', '11910', '11911', '11912', '11913', '11914', '11915', '11916', '11917', '11918', '11919', '11920', '11921', '11922', '11923', '11924', '11925', '11926', '11927', '11928', '11929', '11930', '11931', '11932', '11933', '11934', '11935', '11936', '11937', '11938', '11939', '11940', '11941', '11942', '11943', '11944', '11945', '11946', '11947', '11948', '11949', '11950', '11951', '11952', '11953', '11954', '11955', '11956', '11957', '11958', '11959', '11960', '11961', '11962', '11963', '11964', '11965', '11966', '11967', '11968', '11969', '11970', '11971', '11972', '11973', '11974', '11975', '11976', '11977', '11978', '11979', '11980', '11981', '11982', '11983', '11984', '11985', '11986', '11987', '11988', '11989', '11990', '11991', '11992', '11993', '11994', '11995', '11996', '11997', '11998', '11999', '12000', '12001', '12002', '12003', '12004', '12005', '12006', '12007', '12008', '12009', '12010', '12011', '12012', '12013', '12014', '12015', '12016', '12017', '12018', '12019', '12020', '12021', '12022', '12023', '12024', '12025', '12026', '12027', '12028', '12029', '12030', '12031', '12032', '12033', '12034', '12035', '12036', '12037', '12038', '12039', '12040', '12041', '12042', '12043', '12044', '12045', '12046', '12047', '12048', '12049', '12050', '12051', '12052', '12053', '12054', '12055', '12056', '12057', '12058', '12059', '12060', '12061', '12062', '12063', '12064', '12065', '12066', '12067', '12068', '12069', '12070', '12071', '12072', '12073', '12074', '12075', '12076', '12077', '12078', '12079', '12080', '12081', '12082', '12083', '12084', '12085', '12086', '12087', '12088', '12089', '12090', '12091', '12092', '12093', '12094', '12095', '12096', '12097', '12098', '12099', '12100', '12101', '12102', '12103', '12104', '12105', '12106', '12107', '12108', '12109', '12110', '12111', '12112', '12113', '12114', '12115', '12116', '12117', '12118', '12119', '12120', '12121', '12122', '12123', '12124', '12125', '12126', '12127', '12128', '12129', '12130', '12131', '12132', '12133', '12134', '12135', '12136', '12137', '12138', '12139', '12140', '12141', '12142', '12143', '12144', '12145', '12146', '12147', '12148', '12149', '12150', '12151', '12152', '12153', '12154', '12155', '12156', '12157', '12158', '12159', '12160', '12161', '12162', '12163', '12164', '12165', '12166', '12167', '12168', '12169', '12170', '12171', '12172', '12173', '12174', '12175', '12176', '12177', '12178', '12179', '12180', '12181', '12182', '12183', '12184', '12185', '12186', '12187', '12188', '12189', '12190', '12191', '12192', '12193', '12194', '12195', '12196', '12197', '12198', '12199', '12200', '12201', '12202', '12203', '12204', '12205', '12206', '12207', '12208', '12209', '12210', '12211', '12212', '12213', '12214', '12215', '12216', '12217', '12218', '12219', '12220', '12221', '12222', '12223', '12224', '12225', '12226', '12227', '12228', '12229', '12230', '12231', '12232', '12233', '12234', '12235', '12236', '12237', '12238', '12239', '12240', '12241', '12242', '12243', '12244', '12245', '12246', '12247', '12248', '12249', '12250', '12251', '12252', '12253', '12254', '12255', '12256', '12257', '12258', '12259', '12260', '12261', '12262', '12263', '12264', '12265', '12266', '12267', '12268', '12269', '12270', '12271', '12272', '12273', '12274', '12275', '12276', '12277', '12278', '12279', '12280', '12281', '12282', '12283', '12284', '12285', '12286', '12287', '12288', '12289', '12290', '12291', '12292', '12293', '12294', '12295', '12296', '12297', '12298', '12299', '12300', '12301', '12302', '12303', '12304', '12305', '12306', '12307', '12308', '12309', '12310', '12311', '12312', '12313', '12314', '12315', '12316', '12317', '12318', '12319', '12320', '12321', '12322', '12323', '12324', '12325', '12326', '12327', '12328', '12329', '12330', '12331', '12332', '12333', '12334', '12335', '12336', '12337', '12338', '12339', '12340', '12341', '12342', '12343', '12344', '12345', '12346', '12347', '12348', '12349', '12350', '12351', '12352', '12353', '12354', '12355', '12356', '12357', '12358', '12359', '12360', '12361', '12362', '12363', '12364', '12365', '12366', '12367', '12368', '12369', '12370', '12371', '12372', '12373', '12374', '12375', '12376', '12377', '12378', '12379', '12380', '12381', '12382', '12383', '12384', '12385', '12386', '12387', '12388', '12389', '12390', '12391', '12392', '12393', '12394', '12395', '12396', '12397', '12398', '12399', '12400', '12401', '12402', '12403', '12404', '12405', '12406', '12407', '12408', '12409', '12410', '12411', '12412', '12413', '12414', '12415', '12416', '12417', '12418', '12419', '12420', '12421', '12422', '12423', '12424', '12425', '12426', '12427', '12428', '12429', '12430', '12431', '12432', '12433', '12434', '12435', '12436', '12437', '12438', '12439', '12440', '12441', '12442', '12443', '12444', '12445', '12446', '12447', '12448', '12449', '12450', '12451', '12452', '12453', '12454', '12455', '12456', '12457', '12458', '12459', '12460', '12461', '12462', '12463', '12464', '12465', '12466', '12467', '12468', '12469', '12470', '12471', '12472', '12473', '12474', '12475', '12476', '12477', '12478', '12479', '12480', '12481', '12482', '12483', '12484', '12485', '12486', '12487', '12488', '12489', '12490', '12491', '12492', '12493', '12494', '12495', '12496', '12497', '12498', '12499', '12500', '12501', '12502', '12503', '12504', '12505', '12506', '12507', '12508', '12509', '12510', '12511', '12512', '12513', '12514', '12515', '12516', '12517', '12518', '12519', '12520', '12521', '12522', '12523', '12524', '12525', '12526', '12527', '12528', '12529', '12530', '12531', '12532', '12533', '12534', '12535', '12536', '12537', '12538', '12539', '12540', '12541', '12542', '12543', '12544', '12545', '12546', '12547', '12548', '12549', '12550', '12551', '12552', '12553', '12554', '12555', '12556', '12557', '12558', '12559', '12560', '12561', '12562', '12563', '12564', '12565', '12566', '12567', '12568', '12569', '12570', '12571', '12572', '12573', '12574', '12575', '12576', '12577', '12578', '12579', '12580', '12581', '12582', '12583', '12584', '12585', '12586', '12587', '12588', '12589', '12590', '12591', '12592', '12593', '12594', '12595', '12596', '12597', '12598', '12599', '12600', '12601', '12602', '12603', '12604', '12605', '12606', '12607', '12608', '12609', '12610', '12611', '12612', '12613', '12614', '12615', '12616', '12617', '12618', '12619', '12620', '12621', '12622', '12623', '12624', '12625', '12626', '12627', '12628', '12629', '12630', '12631', '12632', '12633', '12634', '12635', '12636', '12637', '12638', '12639', '12640', '12641', '12642', '12643', '12644', '12645', '12646', '12647', '12648', '12649', '12650', '12651', '12652', '12653', '12654', '12655', '12656', '12657', '12658', '12659', '12660', '12661', '12662', '12663', '12664', '12665', '12666', '12667', '12668', '12669', '12670', '12671', '12672', '12673', '12674', '12675', '12676', '12677', '12678', '12679', '12680', '12681', '12682', '12683', '12684', '12685', '12686', '12687', '12688', '12689', '12690', '12691', '12692', '12693', '12694', '12695', '12696', '12697', '12698', '12699', '12700', '12701', '12702', '12703', '12704', '12705', '12706', '12707', '12708', '12709', '12710', '12711', '12712', '12713', '12714', '12715', '12716', '12717', '12718', '12719', '12720', '12721', '12722', '12723', '12724', '12725', '12726', '12727', '12728', '12729', '12730', '12731', '12732', '12733', '12734', '12735', '12736', '12737', '12738', '12739', '12740', '12741', '12742', '12743', '12744', '12745', '12746', '12747', '12748', '12749', '12750', '12751', '12752', '12753', '12754', '12755', '12756', '12757', '12758', '12759', '12760', '12761', '12762', '12763', '12764', '12765', '12766', '12767', '12768', '12769', '12770', '12771', '12772', '12773', '12774', '12775', '12776', '12777', '12778', '12779', '12780', '12781', '12782', '12783', '12784', '12785', '12786', '12787', '12788', '12789', '12790', '12791', '12792', '12793', '12794', '12795', '12796', '12797', '12798', '12799', '12800', '12801', '12802', '12803', '12804', '12805', '12806', '12807', '12808', '12809', '12810', '12811', '12812', '12813', '12814', '12815', '12816', '12817', '12818', '12819', '12820', '12821', '12822', '12823', '12824', '12825', '12826', '12827', '12828', '12829', '12830', '12831', '12832', '12833', '12834', '12835', '12836', '12837', '12838', '12839', '12840', '12841', '12842', '12843', '12844', '12845', '12846', '12847', '12848', '12849', '12850', '12851', '12852', '12853', '12854', '12855', '12856', '12857', '12858', '12859', '12860', '12861', '12862', '12863', '12864', '12865', '12866', '12867', '12868', '12869', '12870', '12871', '12872', '12873', '12874', '12875', '12876', '12877', '12878', '12879', '12880', '12881', '12882', '12883', '12884', '12885', '12886', '12887', '12888', '12889', '12890', '12891', '12892', '12893', '12894', '12895', '12896', '12897', '12898', '12899', '12900', '12901', '12902', '12903', '12904', '12905', '12906', '12907', '12908', '12909', '12910', '12911', '12912', '12913', '12914', '12915', '12916', '12917', '12918', '12919', '12920', '12921', '12922', '12923', '12924', '12925', '12926', '12927', '12928', '12929', '12930', '12931', '12932', '12933', '12934', '12935', '12936', '12937', '12938', '12939', '12940', '12941', '12942', '12943', '12944', '12945', '12946', '12947', '12948', '12949', '12950', '12951', '12952', '12953', '12954', '12955', '12956', '12957', '12958', '12959', '12960', '12961', '12962', '12963', '12964', '12965', '12966', '12967', '12968', '12969', '12970', '12971', '12972', '12973', '12974', '12975', '12976', '12977', '12978', '12979', '12980', '12981', '12982', '12983', '12984', '12985', '12986', '12987', '12988', '12989', '12990', '12991', '12992', '12993', '12994', '12995', '12996', '12997', '12998', '12999', '13000', '13001', '13002', '13003', '13004', '13005', '13006', '13007', '13008', '13009', '13010', '13011', '13012', '13013', '13014', '13015', '13016', '13017', '13018', '13019', '13020', '13021', '13022', '13023', '13024', '13025', '13026', '13027', '13028', '13029', '13030', '13031', '13032', '13033', '13034', '13035', '13036', '13037', '13038', '13039', '13040', '13041', '13042', '13043', '13044', '13045', '13046', '13047', '13048', '13049', '13050', '13051', '13052', '13053', '13054', '13055', '13056', '13057', '13058', '13059', '13060', '13061', '13062', '13063', '13064', '13065', '13066', '13067', '13068', '13069', '13070', '13071', '13072', '13073', '13074', '13075', '13076', '13077', '13078', '13079', '13080', '13081', '13082', '13083', '13084', '13085', '13086', '13087', '13088', '13089', '13090', '13091', '13092', '13093', '13094', '13095', '13096', '13097', '13098', '13099', '13100', '13101', '13102', '13103', '13104', '13105', '13106', '13107', '13108', '13109', '13110', '13111', '13112', '13113', '13114', '13115', '13116', '13117', '13118', '13119', '13120', '13121', '13122', '13123', '13124', '13125', '13126', '13127', '13128', '13129', '13130', '13131', '13132', '13133', '13134', '13135', '13136', '13137', '13138', '13139', '13140', '13141', '13142', '13143', '13144', '13145', '13146', '13147', '13148', '13149', '13150', '13151', '13152', '13153', '13154', '13155', '13156', '13157', '13158', '13159', '13160', '13161', '13162', '13163', '13164', '13165', '13166', '13167', '13168', '13169', '13170', '13171', '13172', '13173', '13174', '13175', '13176', '13177', '13178', '13179', '13180', '13181', '13182', '13183', '13184', '13185', '13186', '13187', '13188', '13189', '13190', '13191', '13192', '13193', '13194', '13195', '13196', '13197', '13198', '13199', '13200', '13201', '13202', '13203', '13204', '13205', '13206', '13207', '13208', '13209', '13210', '13211', '13212', '13213', '13214', '13215', '13216', '13217', '13218', '13219', '13220', '13221', '13222', '13223', '13224', '13225', '13226', '13227', '13228', '13229', '13230', '13231', '13232', '13233', '13234', '13235', '13236', '13237', '13238', '13239', '13240', '13241', '13242', '13243', '13244', '13245', '13246', '13247', '13248', '13249', '13250', '13251', '13252', '13253', '13254', '13255', '13256', '13257', '13258', '13259', '13260', '13261', '13262', '13263', '13264', '13265', '13266', '13267', '13268', '13269', '13270', '13271', '13272', '13273', '13274', '13275', '13276', '13277', '13278', '13279', '13280', '13281', '13282', '13283', '13284', '13285', '13286', '13287', '13288', '13289', '13290', '13291', '13292', '13293', '13294', '13295', '13296', '13297', '13298', '13299', '13300', '13301', '13302', '13303', '13304', '13305', '13306', '13307', '13308', '13309', '13310', '13311', '13312', '13313', '13314', '13315', '13316', '13317', '13318', '13319', '13320', '13321', '13322', '13323', '13324', '13325', '13326', '13327', '13328', '13329', '13330', '13331', '13332', '13333', '13334', '13335', '13336', '13337', '13338', '13339', '13340', '13341', '13342', '13343', '13344', '13345', '13346', '13347', '13348', '13349', '13350', '13351', '13352', '13353', '13354', '13355', '13356', '13357', '13358', '13359', '13360', '13361', '13362', '13363', '13364', '13365', '13366', '13367', '13368', '13369', '13370', '13371', '13372', '13373', '13374', '13375', '13376', '13377', '13378', '13379', '13380', '13381', '13382', '13383', '13384', '13385', '13386', '13387', '13388', '13389', '13390', '13391', '13392', '13393', '13394', '13395', '13396', '13397', '13398', '13399', '13400', '13401', '13402', '13403', '13404', '13405', '13406', '13407', '13408', '13409', '13410', '13411', '13412', '13413', '13414', '13415', '13416', '13417', '13418', '13419', '13420', '13421', '13422', '13423', '13424', '13425', '13426', '13427', '13428', '13429', '13430', '13431', '13432', '13433', '13434', '13435', '13436', '13437', '13438', '13439', '13440', '13441', '13442', '13443', '13444', '13445', '13446', '13447', '13448', '13449', '13450', '13451', '13452', '13453', '13454', '13455', '13456', '13457', '13458', '13459', '13460', '13461', '13462', '13463', '13464', '13465', '13466', '13467', '13468', '13469', '13470', '13471', '13472', '13473', '13474', '13475', '13476', '13477', '13478', '13479', '13480', '13481', '13482', '13483', '13484', '13485', '13486', '13487', '13488', '13489', '13490', '13491', '13492', '13493', '13494', '13495', '13496', '13497', '13498', '13499', '13500', '13501', '13502', '13503', '13504', '13505', '13506', '13507', '13508', '13509', '13510', '13511', '13512', '13513', '13514', '13515', '13516', '13517', '13518', '13519', '13520', '13521', '13522', '13523', '13524', '13525', '13526', '13527', '13528', '13529', '13530', '13531', '13532', '13533', '13534', '13535', '13536', '13537', '13538', '13539', '13540', '13541', '13542', '13543', '13544', '13545', '13546', '13547', '13548', '13549', '13550', '13551', '13552', '13553', '13554', '13555', '13556', '13557', '13558', '13559', '13560', '13561', '13562', '13563', '13564', '13565', '13566', '13567', '13568', '13569', '13570', '13571', '13572', '13573', '13574', '13575', '13576', '13577', '13578', '13579', '13580', '13581', '13582', '13583', '13584', '13585', '13586', '13587', '13588', '13589', '13590', '13591', '13592', '13593', '13594', '13595', '13596', '13597', '13598', '13599', '13600', '13601', '13602', '13603', '13604', '13605', '13606', '13607', '13608', '13609', '13610', '13611', '13612', '13613', '13614', '13615', '13616', '13617', '13618', '13619', '13620', '13621', '13622', '13623', '13624', '13625', '13626', '13627', '13628', '13629', '13630', '13631', '13632', '13633', '13634', '13635', '13636', '13637', '13638', '13639', '13640', '13641', '13642', '13643', '13644', '13645', '13646', '13647', '13648', '13649', '13650', '13651', '13652', '13653', '13654', '13655', '13656', '13657', '13658', '13659', '13660', '13661', '13662', '13663', '13664', '13665', '13666', '13667', '13668', '13669', '13670', '13671', '13672', '13673', '13674', '13675', '13676', '13677', '13678', '13679', '13680', '13681', '13682', '13683', '13684', '13685', '13686', '13687', '13688', '13689', '13690', '13691', '13692', '13693', '13694', '13695', '13696', '13697', '13698', '13699', '13700', '13701', '13702', '13703', '13704', '13705', '13706', '13707', '13708', '13709', '13710', '13711', '13712', '13713', '13714', '13715', '13716', '13717', '13718', '13719', '13720', '13721', '13722', '13723', '13724', '13725', '13726', '13727', '13728', '13729', '13730', '13731', '13732', '13733', '13734', '13735', '13736', '13737', '13738', '13739', '13740', '13741', '13742', '13743', '13744', '13745', '13746', '13747', '13748', '13749', '13750', '13751', '13752', '13753', '13754', '13755', '13756', '13757', '13758', '13759', '13760', '13761', '13762', '13763', '13764', '13765', '13766', '13767', '13768', '13769', '13770', '13771', '13772', '13773', '13774', '13775', '13776', '13777', '13778', '13779', '13780', '13781', '13782', '13783', '13784', '13785', '13786', '13787', '13788', '13789', '13790', '13791', '13792', '13793', '13794', '13795', '13796', '13797', '13798', '13799', '13800', '13801', '13802', '13803', '13804', '13805', '13806', '13807', '13808', '13809', '13810', '13811', '13812', '13813', '13814', '13815', '13816', '13817', '13818', '13819', '13820', '13821', '13822', '13823', '13824', '13825', '13826', '13827', '13828', '13829', '13830', '13831', '13832', '13833', '13834', '13835', '13836', '13837', '13838', '13839', '13840', '13841', '13842', '13843', '13844', '13845', '13846', '13847', '13848', '13849', '13850', '13851', '13852', '13853', '13854', '13855', '13856', '13857', '13858', '13859', '13860', '13861', '13862', '13863', '13864', '13865', '13866', '13867', '13868', '13869', '13870', '13871', '13872', '13873', '13874', '13875', '13876', '13877', '13878', '13879', '13880', '13881', '13882', '13883', '13884', '13885', '13886', '13887', '13888', '13889', '13890', '13891', '13892', '13893', '13894', '13895', '13896', '13897', '13898', '13899', '13900', '13901', '13902', '13903', '13904', '13905', '13906', '13907', '13908', '13909', '13910', '13911', '13912', '13913', '13914', '13915', '13916', '13917', '13918', '13919', '13920', '13921', '13922', '13923', '13924', '13925', '13926', '13927', '13928', '13929', '13930', '13931', '13932', '13933', '13934', '13935', '13936', '13937', '13938', '13939', '13940', '13941', '13942', '13943', '13944', '13945', '13946', '13947', '13948', '13949', '13950', '13951', '13952', '13953', '13954', '13955', '13956', '13957', '13958', '13959', '13960', '13961', '13962', '13963', '13964', '13965', '13966', '13967', '13968', '13969', '13970', '13971', '13972', '13973', '13974', '13975', '13976', '13977', '13978', '13979', '13980', '13981', '13982', '13983', '13984', '13985', '13986', '13987', '13988', '13989', '13990', '13991', '13992', '13993', '13994', '13995', '13996', '13997', '13998', '13999', '14000', '14001', '14002', '14003', '14004', '14005', '14006', '14007', '14008', '14009', '14010', '14011', '14012', '14013', '14014', '14015', '14016', '14017', '14018', '14019', '14020', '14021', '14022', '14023', '14024', '14025', '14026', '14027', '14028', '14029', '14030', '14031', '14032', '14033', '14034', '14035', '14036', '14037', '14038', '14039', '14040', '14041', '14042', '14043', '14044', '14045', '14046', '14047', '14048', '14049', '14050', '14051', '14052', '14053', '14054', '14055', '14056', '14057', '14058', '14059', '14060', '14061', '14062', '14063', '14064', '14065', '14066', '14067', '14068', '14069', '14070', '14071', '14072', '14073', '14074', '14075', '14076', '14077', '14078', '14079', '14080', '14081', '14082', '14083', '14084', '14085', '14086', '14087', '14088', '14089', '14090', '14091', '14092', '14093', '14094', '14095', '14096', '14097', '14098', '14099', '14100', '14101', '14102', '14103', '14104', '14105', '14106', '14107', '14108', '14109', '14110', '14111', '14112', '14113', '14114', '14115', '14116', '14117', '14118', '14119', '14120', '14121', '14122', '14123', '14124', '14125', '14126', '14127', '14128', '14129', '14130', '14131', '14132', '14133', '14134', '14135', '14136', '14137', '14138', '14139', '14140', '14141', '14142', '14143', '14144', '14145', '14146', '14147', '14148', '14149', '14150', '14151', '14152', '14153', '14154', '14155', '14156', '14157', '14158', '14159', '14160', '14161', '14162', '14163', '14164', '14165', '14166', '14167', '14168', '14169', '14170', '14171', '14172', '14173', '14174', '14175', '14176', '14177', '14178', '14179', '14180', '14181', '14182', '14183', '14184', '14185', '14186', '14187', '14188', '14189', '14190', '14191', '14192', '14193', '14194', '14195', '14196', '14197', '14198', '14199', '14200', '14201', '14202', '14203', '14204', '14205', '14206', '14207', '14208', '14209', '14210', '14211', '14212', '14213', '14214', '14215', '14216', '14217', '14218', '14219', '14220', '14221', '14222', '14223', '14224', '14225', '14226', '14227', '14228', '14229', '14230', '14231', '14232', '14233', '14234', '14235', '14236', '14237', '14238', '14239', '14240', '14241', '14242', '14243', '14244', '14245', '14246', '14247', '14248', '14249', '14250', '14251', '14252', '14253', '14254', '14255', '14256', '14257', '14258', '14259', '14260', '14261', '14262', '14263', '14264', '14265', '14266', '14267', '14268', '14269', '14270', '14271', '14272', '14273', '14274', '14275', '14276', '14277', '14278', '14279', '14280', '14281', '14282', '14283', '14284', '14285', '14286', '14287', '14288', '14289', '14290', '14291', '14292', '14293', '14294', '14295', '14296', '14297', '14298', '14299', '14300', '14301', '14302', '14303', '14304', '14305', '14306', '14307', '14308', '14309', '14310', '14311', '14312', '14313', '14314', '14315', '14316', '14317', '14318', '14319', '14320', '14321', '14322', '14323', '14324', '14325', '14326', '14327', '14328', '14329', '14330', '14331', '14332', '14333', '14334', '14335', '14336', '14337', '14338', '14339', '14340', '14341', '14342', '14343', '14344', '14345', '14346', '14347', '14348', '14349', '14350', '14351', '14352', '14353', '14354', '14355', '14356', '14357', '14358', '14359', '14360', '14361', '14362', '14363', '14364', '14365', '14366', '14367', '14368', '14369', '14370', '14371', '14372', '14373', '14374', '14375', '14376', '14377', '14378', '14379', '14380', '14381', '14382', '14383', '14384', '14385', '14386', '14387', '14388', '14389', '14390', '14391', '14392', '14393', '14394', '14395', '14396', '14397', '14398', '14399', '14400', '14401', '14402', '14403', '14404', '14405', '14406', '14407', '14408', '14409', '14410', '14411', '14412', '14413', '14414', '14415', '14416', '14417', '14418', '14419', '14420', '14421', '14422', '14423', '14424', '14425', '14426', '14427', '14428', '14429', '14430', '14431', '14432', '14433', '14434', '14435', '14436', '14437', '14438', '14439', '14440', '14441', '14442', '14443', '14444', '14445', '14446', '14447', '14448', '14449', '14450', '14451', '14452', '14453', '14454', '14455', '14456', '14457', '14458', '14459', '14460', '14461', '14462', '14463', '14464', '14465', '14466', '14467', '14468', '14469', '14470', '14471', '14472', '14473', '14474', '14475', '14476', '14477', '14478', '14479', '14480', '14481', '14482', '14483', '14484', '14485', '14486', '14487', '14488', '14489', '14490', '14491', '14492', '14493', '14494', '14495', '14496', '14497', '14498', '14499', '14500', '14501', '14502', '14503', '14504', '14505', '14506', '14507', '14508', '14509', '14510', '14511', '14512', '14513', '14514', '14515', '14516', '14517', '14518', '14519', '14520', '14521', '14522', '14523', '14524', '14525', '14526', '14527', '14528', '14529', '14530', '14531', '14532', '14533', '14534', '14535', '14536', '14537', '14538', '14539', '14540', '14541', '14542', '14543', '14544', '14545', '14546', '14547', '14548', '14549', '14550', '14551', '14552', '14553', '14554', '14555', '14556', '14557', '14558', '14559', '14560', '14561', '14562', '14563', '14564', '14565', '14566', '14567', '14568', '14569', '14570', '14571', '14572', '14573', '14574', '14575', '14576', '14577', '14578', '14579', '14580', '14581', '14582', '14583', '14584', '14585', '14586', '14587', '14588', '14589', '14590', '14591', '14592', '14593', '14594', '14595', '14596', '14597', '14598', '14599', '14600', '14601', '14602', '14603', '14604', '14605', '14606', '14607', '14608', '14609', '14610', '14611', '14612', '14613', '14614', '14615', '14616', '14617', '14618', '14619', '14620', '14621', '14622', '14623', '14624', '14625', '14626', '14627', '14628', '14629', '14630', '14631', '14632', '14633', '14634', '14635', '14636', '14637', '14638', '14639', '14640', '14641', '14642', '14643', '14644', '14645', '14646', '14647', '14648', '14649', '14650', '14651', '14652', '14653', '14654', '14655', '14656', '14657', '14658', '14659', '14660', '14661', '14662', '14663', '14664', '14665', '14666', '14667', '14668', '14669', '14670', '14671', '14672', '14673', '14674', '14675', '14676', '14677', '14678', '14679', '14680', '14681', '14682', '14683', '14684', '14685', '14686', '14687', '14688', '14689', '14690', '14691', '14692', '14693', '14694', '14695', '14696', '14697', '14698', '14699', '14700', '14701', '14702', '14703', '14704', '14705', '14706', '14707', '14708', '14709', '14710', '14711', '14712', '14713', '14714', '14715', '14716', '14717', '14718', '14719', '14720', '14721', '14722', '14723', '14724', '14725', '14726', '14727', '14728', '14729', '14730', '14731', '14732', '14733', '14734', '14735', '14736', '14737', '14738', '14739', '14740', '14741', '14742', '14743', '14744', '14745', '14746', '14747', '14748', '14749', '14750', '14751', '14752', '14753', '14754', '14755', '14756', '14757', '14758', '14759', '14760', '14761', '14762', '14763', '14764', '14765', '14766', '14767', '14768', '14769', '14770', '14771', '14772', '14773', '14774', '14775', '14776', '14777', '14778', '14779', '14780', '14781', '14782', '14783', '14784', '14785', '14786', '14787', '14788', '14789', '14790', '14791', '14792', '14793', '14794', '14795', '14796', '14797', '14798', '14799', '14800', '14801', '14802', '14803', '14804', '14805', '14806', '14807', '14808', '14809', '14810', '14811', '14812', '14813', '14814', '14815', '14816', '14817', '14818', '14819', '14820', '14821', '14822', '14823', '14824', '14825', '14826', '14827', '14828', '14829', '14830', '14831', '14832', '14833', '14834', '14835', '14836', '14837', '14838', '14839', '14840', '14841', '14842', '14843', '14844', '14845', '14846', '14847', '14848', '14849', '14850', '14851', '14852', '14853', '14854', '14855', '14856', '14857', '14858', '14859', '14860', '14861', '14862', '14863', '14864', '14865', '14866', '14867', '14868', '14869', '14870', '14871', '14872', '14873', '14874', '14875', '14876', '14877', '14878', '14879', '14880', '14881', '14882', '14883', '14884', '14885', '14886', '14887', '14888', '14889', '14890', '14891', '14892', '14893', '14894', '14895', '14896', '14897', '14898', '14899', '14900', '14901', '14902', '14903', '14904', '14905', '14906', '14907', '14908', '14909', '14910', '14911', '14912', '14913', '14914', '14915', '14916', '14917', '14918', '14919', '14920', '14921', '14922', '14923', '14924', '14925', '14926', '14927', '14928', '14929', '14930', '14931', '14932', '14933', '14934', '14935', '14936', '14937', '14938', '14939', '14940', '14941', '14942', '14943', '14944', '14945', '14946', '14947', '14948', '14949', '14950', '14951', '14952', '14953', '14954', '14955', '14956', '14957', '14958', '14959', '14960', '14961', '14962', '14963', '14964', '14965', '14966', '14967', '14968', '14969', '14970', '14971', '14972', '14973', '14974', '14975', '14976', '14977', '14978', '14979', '14980', '14981', '14982', '14983', '14984', '14985', '14986', '14987', '14988', '14989', '14990', '14991', '14992', '14993', '14994', '14995', '14996', '14997', '14998', '14999', '15000', '15001', '15002', '15003', '15004', '15005', '15006', '15007', '15008', '15009', '15010', '15011', '15012', '15013', '15014', '15015', '15016', '15017', '15018', '15019', '15020', '15021', '15022', '15023', '15024', '15025', '15026', '15027', '15028', '15029', '15030', '15031', '15032', '15033', '15034', '15035', '15036', '15037', '15038', '15039', '15040', '15041', '15042', '15043', '15044', '15045', '15046', '15047', '15048', '15049', '15050', '15051', '15052', '15053', '15054', '15055', '15056', '15057', '15058', '15059', '15060', '15061', '15062', '15063', '15064', '15065', '15066', '15067', '15068', '15069', '15070', '15071', '15072', '15073', '15074', '15075', '15076', '15077', '15078', '15079', '15080', '15081', '15082', '15083', '15084', '15085', '15086', '15087', '15088', '15089', '15090', '15091', '15092', '15093', '15094', '15095', '15096', '15097', '15098', '15099', '15100', '15101', '15102', '15103', '15104', '15105', '15106', '15107', '15108', '15109', '15110', '15111', '15112', '15113', '15114', '15115', '15116', '15117', '15118', '15119', '15120', '15121', '15122', '15123', '15124', '15125', '15126', '15127', '15128', '15129', '15130', '15131', '15132', '15133', '15134', '15135', '15136', '15137', '15138', '15139', '15140', '15141', '15142', '15143', '15144', '15145', '15146', '15147', '15148', '15149', '15150', '15151', '15152', '15153', '15154', '15155', '15156', '15157', '15158', '15159', '15160', '15161', '15162', '15163', '15164', '15165', '15166', '15167', '15168', '15169', '15170', '15171', '15172', '15173', '15174', '15175', '15176', '15177', '15178', '15179', '15180', '15181', '15182', '15183', '15184', '15185', '15186', '15187', '15188', '15189', '15190', '15191', '15192', '15193', '15194', '15195', '15196', '15197', '15198', '15199', '15200', '15201', '15202', '15203', '15204', '15205', '15206', '15207', '15208', '15209', '15210', '15211', '15212', '15213', '15214', '15215', '15216', '15217', '15218', '15219', '15220', '15221', '15222', '15223', '15224', '15225', '15226', '15227', '15228', '15229', '15230', '15231', '15232', '15233', '15234', '15235', '15236', '15237', '15238', '15239', '15240', '15241', '15242', '15243', '15244', '15245', '15246', '15247', '15248', '15249', '15250', '15251', '15252', '15253', '15254', '15255', '15256', '15257', '15258', '15259', '15260', '15261', '15262', '15263', '15264', '15265', '15266', '15267', '15268', '15269', '15270', '15271', '15272', '15273', '15274', '15275', '15276', '15277', '15278', '15279', '15280', '15281', '15282', '15283', '15284', '15285', '15286', '15287', '15288', '15289', '15290', '15291', '15292', '15293', '15294', '15295', '15296', '15297', '15298', '15299', '15300', '15301', '15302', '15303', '15304', '15305', '15306', '15307', '15308', '15309', '15310', '15311', '15312', '15313', '15314', '15315', '15316', '15317', '15318', '15319', '15320', '15321', '15322', '15323', '15324', '15325', '15326', '15327', '15328', '15329', '15330', '15331', '15332', '15333', '15334', '15335', '15336', '15337', '15338', '15339', '15340', '15341', '15342', '15343', '15344', '15345', '15346', '15347', '15348', '15349', '15350', '15351', '15352', '15353', '15354', '15355', '15356', '15357', '15358', '15359', '15360', '15361', '15362', '15363', '15364', '15365', '15366', '15367', '15368', '15369', '15370', '15371', '15372', '15373', '15374', '15375', '15376', '15377', '15378', '15379', '15380', '15381', '15382', '15383', '15384', '15385', '15386', '15387', '15388', '15389', '15390', '15391', '15392', '15393', '15394', '15395', '15396', '15397', '15398', '15399', '15400', '15401', '15402', '15403', '15404', '15405', '15406', '15407', '15408', '15409', '15410', '15411', '15412', '15413', '15414', '15415', '15416', '15417', '15418', '15419', '15420', '15421', '15422', '15423', '15424', '15425', '15426', '15427', '15428', '15429', '15430', '15431', '15432', '15433', '15434', '15435', '15436', '15437', '15438', '15439', '15440', '15441', '15442', '15443', '15444', '15445', '15446', '15447', '15448', '15449', '15450', '15451', '15452', '15453', '15454', '15455', '15456', '15457', '15458', '15459', '15460', '15461', '15462', '15463', '15464', '15465', '15466', '15467', '15468', '15469', '15470', '15471', '15472', '15473', '15474', '15475', '15476', '15477', '15478', '15479', '15480', '15481', '15482', '15483', '15484', '15485', '15486', '15487', '15488', '15489', '15490', '15491', '15492', '15493', '15494', '15495', '15496', '15497', '15498', '15499', '15500', '15501', '15502', '15503', '15504', '15505', '15506', '15507', '15508', '15509', '15510', '15511', '15512', '15513', '15514', '15515', '15516', '15517', '15518', '15519', '15520', '15521', '15522', '15523', '15524', '15525', '15526', '15527', '15528', '15529', '15530', '15531', '15532', '15533', '15534', '15535', '15536', '15537', '15538', '15539', '15540', '15541', '15542', '15543', '15544', '15545', '15546', '15547', '15548', '15549', '15550', '15551', '15552', '15553', '15554', '15555', '15556', '15557', '15558', '15559', '15560', '15561', '15562', '15563', '15564', '15565', '15566', '15567', '15568', '15569', '15570', '15571', '15572', '15573', '15574', '15575', '15576', '15577', '15578', '15579', '15580', '15581', '15582', '15583', '15584', '15585', '15586', '15587', '15588', '15589', '15590', '15591', '15592', '15593', '15594', '15595', '15596', '15597', '15598', '15599', '15600', '15601', '15602', '15603', '15604', '15605', '15606', '15607', '15608', '15609', '15610', '15611', '15612', '15613', '15614', '15615', '15616', '15617', '15618', '15619', '15620', '15621', '15622', '15623', '15624', '15625', '15626', '15627', '15628', '15629', '15630', '15631', '15632', '15633', '15634', '15635', '15636', '15637', '15638', '15639', '15640', '15641', '15642', '15643', '15644', '15645', '15646', '15647', '15648', '15649', '15650', '15651', '15652', '15653', '15654', '15655', '15656', '15657', '15658', '15659', '15660', '15661', '15662', '15663', '15664', '15665', '15666', '15667', '15668', '15669', '15670', '15671', '15672', '15673', '15674', '15675', '15676', '15677', '15678', '15679', '15680', '15681', '15682', '15683', '15684', '15685', '15686', '15687', '15688', '15689', '15690', '15691', '15692', '15693', '15694', '15695', '15696', '15697', '15698', '15699', '15700', '15701', '15702', '15703', '15704', '15705', '15706', '15707', '15708', '15709', '15710', '15711', '15712', '15713', '15714', '15715', '15716', '15717', '15718', '15719', '15720', '15721', '15722', '15723', '15724', '15725', '15726', '15727', '15728', '15729', '15730', '15731', '15732', '15733', '15734', '15735', '15736', '15737', '15738', '15739', '15740', '15741', '15742', '15743', '15744', '15745', '15746', '15747', '15748', '15749', '15750', '15751', '15752', '15753', '15754', '15755', '15756', '15757', '15758', '15759', '15760', '15761', '15762', '15763', '15764', '15765', '15766', '15767', '15768', '15769', '15770', '15771', '15772', '15773', '15774', '15775', '15776', '15777', '15778', '15779', '15780', '15781', '15782', '15783', '15784', '15785', '15786', '15787', '15788', '15789', '15790', '15791', '15792', '15793', '15794', '15795', '15796', '15797', '15798', '15799', '15800', '15801', '15802', '15803', '15804', '15805', '15806', '15807', '15808', '15809', '15810', '15811', '15812', '15813', '15814', '15815', '15816', '15817', '15818', '15819', '15820', '15821', '15822', '15823', '15824', '15825', '15826', '15827', '15828', '15829', '15830', '15831', '15832', '15833', '15834', '15835', '15836', '15837', '15838', '15839', '15840', '15841', '15842', '15843', '15844', '15845', '15846', '15847', '15848', '15849', '15850', '15851', '15852', '15853', '15854', '15855', '15856', '15857', '15858', '15859', '15860', '15861', '15862', '15863', '15864', '15865', '15866', '15867', '15868', '15869', '15870', '15871', '15872', '15873', '15874', '15875', '15876', '15877', '15878', '15879', '15880', '15881', '15882', '15883', '15884', '15885', '15886', '15887', '15888', '15889', '15890', '15891', '15892', '15893', '15894', '15895', '15896', '15897', '15898', '15899', '15900', '15901', '15902', '15903', '15904', '15905', '15906', '15907', '15908', '15909', '15910', '15911', '15912', '15913', '15914', '15915', '15916', '15917', '15918', '15919', '15920', '15921', '15922', '15923', '15924', '15925', '15926', '15927', '15928', '15929', '15930', '15931', '15932', '15933', '15934', '15935', '15936', '15937', '15938', '15939', '15940', '15941', '15942', '15943', '15944', '15945', '15946', '15947', '15948', '15949', '15950', '15951', '15952', '15953', '15954', '15955', '15956', '15957', '15958', '15959', '15960', '15961', '15962', '15963', '15964', '15965', '15966', '15967', '15968', '15969', '15970', '15971', '15972', '15973', '15974', '15975', '15976', '15977', '15978', '15979', '15980', '15981', '15982', '15983', '15984', '15985', '15986', '15987', '15988', '15989', '15990', '15991', '15992', '15993', '15994', '15995', '15996', '15997', '15998', '15999', '16000', '16001', '16002', '16003', '16004', '16005', '16006', '16007', '16008', '16009', '16010', '16011', '16012', '16013', '16014', '16015', '16016', '16017', '16018', '16019', '16020', '16021', '16022', '16023', '16024', '16025', '16026', '16027', '16028', '16029', '16030', '16031', '16032', '16033', '16034', '16035', '16036', '16037', '16038', '16039', '16040', '16041', '16042', '16043', '16044', '16045', '16046', '16047', '16048', '16049', '16050', '16051', '16052', '16053', '16054', '16055', '16056', '16057', '16058', '16059', '16060', '16061', '16062', '16063', '16064', '16065', '16066', '16067', '16068', '16069', '16070', '16071', '16072', '16073', '16074', '16075', '16076', '16077', '16078', '16079', '16080', '16081', '16082', '16083', '16084', '16085', '16086', '16087', '16088', '16089', '16090', '16091', '16092', '16093', '16094', '16095', '16096', '16097', '16098', '16099', '16100', '16101', '16102', '16103', '16104', '16105', '16106', '16107', '16108', '16109', '16110', '16111', '16112', '16113', '16114', '16115', '16116', '16117', '16118', '16119', '16120', '16121', '16122', '16123', '16124', '16125', '16126', '16127', '16128', '16129', '16130', '16131', '16132', '16133', '16134', '16135', '16136', '16137', '16138', '16139', '16140', '16141', '16142', '16143', '16144', '16145', '16146', '16147', '16148', '16149', '16150', '16151', '16152', '16153', '16154', '16155', '16156', '16157', '16158', '16159', '16160', '16161', '16162', '16163', '16164', '16165', '16166', '16167', '16168', '16169', '16170', '16171', '16172', '16173', '16174', '16175', '16176', '16177', '16178', '16179', '16180', '16181', '16182', '16183', '16184', '16185', '16186', '16187', '16188', '16189', '16190', '16191', '16192', '16193', '16194', '16195', '16196', '16197', '16198', '16199', '16200', '16201', '16202', '16203', '16204', '16205', '16206', '16207', '16208', '16209', '16210', '16211', '16212', '16213', '16214', '16215', '16216', '16217', '16218', '16219', '16220', '16221', '16222', '16223', '16224', '16225', '16226', '16227', '16228', '16229', '16230', '16231', '16232', '16233', '16234', '16235', '16236', '16237', '16238', '16239', '16240', '16241', '16242', '16243', '16244', '16245', '16246', '16247', '16248', '16249', '16250', '16251', '16252', '16253', '16254', '16255', '16256', '16257', '16258', '16259', '16260', '16261', '16262', '16263', '16264', '16265', '16266', '16267', '16268', '16269', '16270', '16271', '16272', '16273', '16274', '16275', '16276', '16277', '16278', '16279', '16280', '16281', '16282', '16283', '16284', '16285', '16286', '16287', '16288', '16289', '16290', '16291', '16292', '16293', '16294', '16295', '16296', '16297', '16298', '16299', '16300', '16301', '16302', '16303', '16304', '16305', '16306', '16307', '16308', '16309', '16310', '16311', '16312', '16313', '16314', '16315', '16316', '16317', '16318', '16319', '16320', '16321', '16322', '16323', '16324', '16325', '16326', '16327', '16328', '16329', '16330', '16331', '16332', '16333', '16334', '16335', '16336', '16337', '16338', '16339', '16340', '16341', '16342', '16343', '16344', '16345', '16346', '16347', '16348', '16349', '16350', '16351', '16352', '16353', '16354', '16355', '16356', '16357', '16358', '16359', '16360', '16361', '16362', '16363', '16364', '16365', '16366', '16367', '16368', '16369', '16370', '16371', '16372', '16373', '16374', '16375', '16376', '16377', '16378', '16379', '16380', '16381', '16382', '16383', '16384', '16385', '16386', '16387', '16388', '16389', '16390', '16391', '16392', '16393', '16394', '16395', '16396', '16397', '16398', '16399', '16400', '16401', '16402', '16403', '16404', '16405', '16406', '16407', '16408', '16409', '16410', '16411', '16412', '16413', '16414', '16415', '16416', '16417', '16418', '16419', '16420', '16421', '16422', '16423', '16424', '16425', '16426', '16427', '16428', '16429', '16430', '16431', '16432', '16433', '16434', '16435', '16436', '16437', '16438', '16439', '16440', '16441', '16442', '16443', '16444', '16445', '16446', '16447', '16448', '16449', '16450', '16451', '16452', '16453', '16454', '16455', '16456', '16457', '16458', '16459', '16460', '16461', '16462', '16463', '16464', '16465', '16466', '16467', '16468', '16469', '16470', '16471', '16472', '16473', '16474', '16475', '16476', '16477', '16478', '16479', '16480', '16481', '16482', '16483', '16484', '16485', '16486', '16487', '16488', '16489', '16490', '16491', '16492', '16493', '16494', '16495', '16496', '16497', '16498', '16499', '16500', '16501', '16502', '16503', '16504', '16505', '16506', '16507', '16508', '16509', '16510', '16511', '16512', '16513', '16514', '16515', '16516', '16517', '16518', '16519', '16520', '16521', '16522', '16523', '16524', '16525', '16526', '16527', '16528', '16529', '16530', '16531', '16532', '16533', '16534', '16535', '16536', '16537', '16538', '16539', '16540', '16541', '16542', '16543', '16544', '16545', '16546', '16547', '16548', '16549', '16550', '16551', '16552', '16553', '16554', '16555', '16556', '16557', '16558', '16559', '16560', '16561', '16562', '16563', '16564', '16565', '16566', '16567', '16568', '16569', '16570', '16571', '16572', '16573', '16574', '16575', '16576', '16577', '16578', '16579', '16580', '16581', '16582', '16583', '16584', '16585', '16586', '16587', '16588', '16589', '16590', '16591', '16592', '16593', '16594', '16595', '16596', '16597', '16598', '16599', '16600', '16601', '16602', '16603', '16604', '16605', '16606', '16607', '16608', '16609', '16610', '16611', '16612', '16613', '16614', '16615', '16616', '16617', '16618', '16619', '16620', '16621', '16622', '16623', '16624', '16625', '16626', '16627', '16628', '16629', '16630', '16631', '16632', '16633', '16634', '16635', '16636', '16637', '16638', '16639', '16640', '16641', '16642', '16643', '16644', '16645', '16646', '16647', '16648', '16649', '16650', '16651', '16652', '16653', '16654', '16655', '16656', '16657', '16658', '16659', '16660', '16661', '16662', '16663', '16664', '16665', '16666', '16667', '16668', '16669', '16670', '16671', '16672', '16673', '16674', '16675', '16676', '16677', '16678', '16679', '16680', '16681', '16682', '16683', '16684', '16685', '16686', '16687', '16688', '16689', '16690', '16691', '16692', '16693', '16694', '16695', '16696', '16697', '16698', '16699', '16700', '16701', '16702', '16703', '16704', '16705', '16706', '16707', '16708', '16709', '16710', '16711', '16712', '16713', '16714', '16715', '16716', '16717', '16718', '16719', '16720', '16721', '16722', '16723', '16724', '16725', '16726', '16727', '16728', '16729', '16730', '16731', '16732', '16733', '16734', '16735', '16736', '16737', '16738', '16739', '16740', '16741', '16742', '16743', '16744', '16745', '16746', '16747', '16748', '16749', '16750', '16751', '16752', '16753', '16754', '16755', '16756', '16757', '16758', '16759', '16760', '16761', '16762', '16763', '16764', '16765', '16766', '16767', '16768', '16769', '16770', '16771', '16772', '16773', '16774', '16775', '16776', '16777', '16778', '16779', '16780', '16781', '16782', '16783', '16784', '16785', '16786', '16787', '16788', '16789', '16790', '16791', '16792', '16793', '16794', '16795', '16796', '16797', '16798', '16799', '16800', '16801', '16802', '16803', '16804', '16805', '16806', '16807', '16808', '16809', '16810', '16811', '16812', '16813', '16814', '16815', '16816', '16817', '16818', '16819', '16820', '16821', '16822', '16823', '16824', '16825', '16826', '16827', '16828', '16829', '16830', '16831', '16832', '16833', '16834', '16835', '16836', '16837', '16838', '16839', '16840', '16841', '16842', '16843', '16844', '16845', '16846', '16847', '16848', '16849', '16850', '16851', '16852', '16853', '16854', '16855', '16856', '16857', '16858', '16859', '16860', '16861', '16862', '16863', '16864', '16865', '16866', '16867', '16868', '16869', '16870', '16871', '16872', '16873', '16874', '16875', '16876', '16877', '16878', '16879', '16880', '16881', '16882', '16883', '16884', '16885', '16886', '16887', '16888', '16889', '16890', '16891', '16892', '16893', '16894', '16895', '16896', '16897', '16898', '16899', '16900', '16901', '16902', '16903', '16904', '16905', '16906', '16907', '16908', '16909', '16910', '16911', '16912', '16913', '16914', '16915', '16916', '16917', '16918', '16919', '16920', '16921', '16922', '16923', '16924', '16925', '16926', '16927', '16928', '16929', '16930', '16931', '16932', '16933', '16934', '16935', '16936', '16937', '16938', '16939', '16940', '16941', '16942', '16943', '16944', '16945', '16946', '16947', '16948', '16949', '16950', '16951', '16952', '16953', '16954', '16955', '16956', '16957', '16958', '16959', '16960', '16961', '16962', '16963', '16964', '16965', '16966', '16967', '16968', '16969', '16970', '16971', '16972', '16973', '16974', '16975', '16976', '16977', '16978', '16979', '16980', '16981', '16982', '16983', '16984', '16985', '16986', '16987', '16988', '16989', '16990', '16991', '16992', '16993', '16994', '16995', '16996', '16997', '16998', '16999', '17000', '17001', '17002', '17003', '17004', '17005', '17006', '17007', '17008', '17009', '17010', '17011', '17012', '17013', '17014', '17015', '17016', '17017', '17018', '17019', '17020', '17021', '17022', '17023', '17024', '17025', '17026', '17027', '17028', '17029', '17030', '17031', '17032', '17033', '17034', '17035', '17036', '17037', '17038', '17039', '17040', '17041', '17042', '17043', '17044', '17045', '17046', '17047', '17048', '17049', '17050', '17051', '17052', '17053', '17054', '17055', '17056', '17057', '17058', '17059', '17060', '17061', '17062', '17063', '17064', '17065', '17066', '17067', '17068', '17069', '17070', '17071', '17072', '17073', '17074', '17075', '17076', '17077', '17078', '17079', '17080', '17081', '17082', '17083', '17084', '17085', '17086', '17087', '17088', '17089', '17090', '17091', '17092', '17093', '17094', '17095', '17096', '17097', '17098', '17099', '17100', '17101', '17102', '17103', '17104', '17105', '17106', '17107', '17108', '17109', '17110', '17111', '17112', '17113', '17114', '17115', '17116', '17117', '17118', '17119', '17120', '17121', '17122', '17123', '17124', '17125', '17126', '17127', '17128', '17129', '17130', '17131', '17132', '17133', '17134', '17135', '17136', '17137', '17138', '17139', '17140', '17141', '17142', '17143', '17144', '17145', '17146', '17147', '17148', '17149', '17150', '17151', '17152', '17153', '17154', '17155', '17156', '17157', '17158', '17159', '17160', '17161', '17162', '17163', '17164', '17165', '17166', '17167', '17168', '17169', '17170', '17171', '17172', '17173', '17174', '17175', '17176', '17177', '17178', '17179', '17180', '17181', '17182', '17183', '17184', '17185', '17186', '17187', '17188', '17189', '17190', '17191', '17192', '17193', '17194', '17195', '17196', '17197', '17198', '17199', '17200', '17201', '17202', '17203', '17204', '17205', '17206', '17207', '17208', '17209', '17210', '17211', '17212', '17213', '17214', '17215', '17216', '17217', '17218', '17219', '17220', '17221', '17222', '17223', '17224', '17225', '17226', '17227', '17228', '17229', '17230', '17231', '17232', '17233', '17234', '17235', '17236', '17237', '17238', '17239', '17240', '17241', '17242', '17243', '17244', '17245', '17246', '17247', '17248', '17249', '17250', '17251', '17252', '17253', '17254', '17255', '17256', '17257', '17258', '17259', '17260', '17261', '17262', '17263', '17264', '17265', '17266', '17267', '17268', '17269', '17270', '17271', '17272', '17273', '17274', '17275', '17276', '17277', '17278', '17279', '17280', '17281', '17282', '17283', '17284', '17285', '17286', '17287', '17288', '17289', '17290', '17291', '17292', '17293', '17294', '17295', '17296', '17297', '17298', '17299', '17300', '17301', '17302', '17303', '17304', '17305', '17306', '17307', '17308', '17309', '17310', '17311', '17312', '17313', '17314', '17315', '17316', '17317', '17318', '17319', '17320', '17321', '17322', '17323', '17324', '17325', '17326', '17327', '17328', '17329', '17330', '17331', '17332', '17333', '17334', '17335', '17336', '17337', '17338', '17339', '17340', '17341', '17342', '17343', '17344', '17345', '17346', '17347', '17348', '17349', '17350', '17351', '17352', '17353', '17354', '17355', '17356', '17357', '17358', '17359', '17360', '17361', '17362', '17363', '17364', '17365', '17366', '17367', '17368', '17369', '17370', '17371', '17372', '17373', '17374', '17375', '17376', '17377', '17378', '17379', '17380', '17381', '17382', '17383', '17384', '17385', '17386', '17387', '17388', '17389', '17390', '17391', '17392', '17393', '17394', '17395', '17396', '17397', '17398', '17399', '17400', '17401', '17402', '17403', '17404', '17405', '17406', '17407', '17408', '17409', '17410', '17411', '17412', '17413', '17414', '17415', '17416', '17417', '17418', '17419', '17420', '17421', '17422', '17423', '17424', '17425', '17426', '17427', '17428', '17429', '17430', '17431', '17432', '17433', '17434', '17435', '17436', '17437', '17438', '17439', '17440', '17441', '17442', '17443', '17444', '17445', '17446', '17447', '17448', '17449', '17450', '17451', '17452', '17453', '17454', '17455', '17456', '17457', '17458', '17459', '17460', '17461', '17462', '17463', '17464', '17465', '17466', '17467', '17468', '17469', '17470', '17471', '17472', '17473', '17474', '17475', '17476', '17477', '17478', '17479', '17480', '17481', '17482', '17483', '17484', '17485', '17486', '17487', '17488', '17489', '17490', '17491', '17492', '17493', '17494', '17495', '17496', '17497', '17498', '17499', '17500', '17501', '17502', '17503', '17504', '17505', '17506', '17507', '17508', '17509', '17510', '17511', '17512', '17513', '17514', '17515', '17516', '17517', '17518', '17519', '17520', '17521', '17522', '17523', '17524', '17525', '17526', '17527', '17528', '17529', '17530', '17531', '17532', '17533', '17534', '17535', '17536', '17537', '17538', '17539', '17540', '17541', '17542', '17543', '17544', '17545', '17546', '17547', '17548', '17549', '17550', '17551', '17552', '17553', '17554', '17555', '17556', '17557', '17558', '17559', '17560', '17561', '17562', '17563', '17564', '17565', '17566', '17567', '17568', '17569', '17570', '17571', '17572', '17573', '17574', '17575', '17576', '17577', '17578', '17579', '17580', '17581', '17582', '17583', '17584', '17585', '17586', '17587', '17588', '17589', '17590', '17591', '17592', '17593', '17594', '17595', '17596', '17597', '17598', '17599', '17600', '17601', '17602', '17603', '17604', '17605', '17606', '17607', '17608', '17609', '17610', '17611', '17612', '17613', '17614', '17615', '17616', '17617', '17618', '17619', '17620', '17621', '17622', '17623', '17624', '17625', '17626', '17627', '17628', '17629', '17630', '17631', '17632', '17633', '17634', '17635', '17636', '17637', '17638', '17639', '17640', '17641', '17642', '17643', '17644', '17645', '17646', '17647', '17648', '17649', '17650', '17651', '17652', '17653', '17654', '17655', '17656', '17657', '17658', '17659', '17660', '17661', '17662', '17663', '17664', '17665', '17666', '17667', '17668', '17669', '17670', '17671', '17672', '17673', '17674', '17675', '17676', '17677', '17678', '17679', '17680', '17681', '17682', '17683', '17684', '17685', '17686', '17687', '17688', '17689', '17690', '17691', '17692', '17693', '17694', '17695', '17696', '17697', '17698', '17699', '17700', '17701', '17702', '17703', '17704', '17705', '17706', '17707', '17708', '17709', '17710', '17711', '17712', '17713', '17714', '17715', '17716', '17717', '17718', '17719', '17720', '17721', '17722', '17723', '17724', '17725', '17726', '17727', '17728', '17729', '17730', '17731', '17732', '17733', '17734', '17735', '17736', '17737', '17738', '17739', '17740', '17741', '17742', '17743', '17744', '17745', '17746', '17747', '17748', '17749', '17750', '17751', '17752', '17753', '17754', '17755', '17756', '17757', '17758', '17759', '17760', '17761', '17762', '17763', '17764', '17765', '17766', '17767', '17768', '17769', '17770', '17771', '17772', '17773', '17774', '17775', '17776', '17777', '17778', '17779', '17780', '17781', '17782', '17783', '17784', '17785', '17786', '17787', '17788', '17789', '17790', '17791', '17792', '17793', '17794', '17795', '17796', '17797', '17798', '17799', '17800', '17801', '17802', '17803', '17804', '17805', '17806', '17807', '17808', '17809', '17810', '17811', '17812', '17813', '17814', '17815', '17816', '17817', '17818', '17819', '17820', '17821', '17822', '17823', '17824', '17825', '17826', '17827', '17828', '17829', '17830', '17831', '17832', '17833', '17834', '17835', '17836', '17837', '17838', '17839', '17840', '17841', '17842', '17843', '17844', '17845', '17846', '17847', '17848', '17849', '17850', '17851', '17852', '17853', '17854', '17855', '17856', '17857', '17858', '17859', '17860', '17861', '17862', '17863', '17864', '17865', '17866', '17867', '17868', '17869', '17870', '17871', '17872', '17873', '17874', '17875', '17876', '17877', '17878', '17879', '17880', '17881', '17882', '17883', '17884', '17885', '17886', '17887', '17888', '17889', '17890', '17891', '17892', '17893', '17894', '17895', '17896', '17897', '17898', '17899', '17900', '17901', '17902', '17903', '17904', '17905', '17906', '17907', '17908', '17909', '17910', '17911', '17912', '17913', '17914', '17915', '17916', '17917', '17918', '17919', '17920', '17921', '17922', '17923', '17924', '17925', '17926', '17927', '17928', '17929', '17930', '17931', '17932', '17933', '17934', '17935', '17936', '17937', '17938', '17939', '17940', '17941', '17942', '17943', '17944', '17945', '17946', '17947', '17948', '17949', '17950', '17951', '17952', '17953', '17954', '17955', '17956', '17957', '17958', '17959', '17960', '17961', '17962', '17963', '17964', '17965', '17966', '17967', '17968', '17969', '17970', '17971', '17972', '17973', '17974', '17975', '17976', '17977', '17978', '17979', '17980', '17981', '17982', '17983', '17984', '17985', '17986', '17987', '17988', '17989', '17990', '17991', '17992', '17993', '17994', '17995', '17996', '17997', '17998', '17999', '18000', '18001', '18002', '18003', '18004', '18005', '18006', '18007', '18008', '18009', '18010', '18011', '18012', '18013', '18014', '18015', '18016', '18017', '18018', '18019', '18020', '18021', '18022', '18023', '18024', '18025', '18026', '18027', '18028', '18029', '18030', '18031', '18032', '18033', '18034', '18035', '18036', '18037', '18038', '18039', '18040', '18041', '18042', '18043', '18044', '18045', '18046', '18047', '18048', '18049', '18050', '18051', '18052', '18053', '18054', '18055', '18056', '18057', '18058', '18059', '18060', '18061', '18062', '18063', '18064', '18065', '18066', '18067', '18068', '18069', '18070', '18071', '18072', '18073', '18074', '18075', '18076', '18077', '18078', '18079', '18080', '18081', '18082', '18083', '18084', '18085', '18086', '18087', '18088', '18089', '18090', '18091', '18092', '18093', '18094', '18095', '18096', '18097', '18098', '18099', '18100', '18101', '18102', '18103', '18104', '18105', '18106', '18107', '18108', '18109', '18110', '18111', '18112', '18113', '18114', '18115', '18116', '18117', '18118', '18119', '18120', '18121', '18122', '18123', '18124', '18125', '18126', '18127', '18128', '18129', '18130', '18131', '18132', '18133', '18134', '18135', '18136', '18137', '18138', '18139', '18140', '18141', '18142', '18143', '18144', '18145', '18146', '18147', '18148', '18149', '18150', '18151', '18152', '18153', '18154', '18155', '18156', '18157', '18158', '18159', '18160', '18161', '18162', '18163', '18164', '18165', '18166', '18167', '18168', '18169', '18170', '18171', '18172', '18173', '18174', '18175', '18176', '18177', '18178', '18179', '18180', '18181', '18182', '18183', '18184', '18185', '18186', '18187', '18188', '18189', '18190', '18191', '18192', '18193', '18194', '18195', '18196', '18197', '18198', '18199', '18200', '18201', '18202', '18203', '18204', '18205', '18206', '18207', '18208', '18209', '18210', '18211', '18212', '18213', '18214', '18215', '18216', '18217', '18218', '18219', '18220', '18221', '18222', '18223', '18224', '18225', '18226', '18227', '18228', '18229', '18230', '18231', '18232', '18233', '18234', '18235', '18236', '18237', '18238', '18239', '18240', '18241', '18242', '18243', '18244', '18245', '18246', '18247', '18248', '18249', '18250', '18251', '18252', '18253', '18254', '18255', '18256', '18257', '18258', '18259', '18260', '18261', '18262', '18263', '18264', '18265', '18266', '18267', '18268', '18269', '18270', '18271', '18272', '18273', '18274', '18275', '18276', '18277', '18278', '18279', '18280', '18281', '18282', '18283', '18284', '18285', '18286', '18287', '18288', '18289', '18290', '18291', '18292', '18293', '18294', '18295', '18296', '18297', '18298', '18299', '18300', '18301', '18302', '18303', '18304', '18305', '18306', '18307', '18308', '18309', '18310', '18311', '18312', '18313', '18314', '18315', '18316', '18317', '18318', '18319', '18320', '18321', '18322', '18323', '18324', '18325', '18326', '18327', '18328', '18329', '18330', '18331', '18332', '18333', '18334', '18335', '18336', '18337', '18338', '18339', '18340', '18341', '18342', '18343', '18344', '18345', '18346', '18347', '18348', '18349', '18350', '18351', '18352', '18353', '18354', '18355', '18356', '18357', '18358', '18359', '18360', '18361', '18362', '18363', '18364', '18365', '18366', '18367', '18368', '18369', '18370', '18371', '18372', '18373', '18374', '18375', '18376', '18377', '18378', '18379', '18380', '18381', '18382', '18383', '18384', '18385', '18386', '18387', '18388', '18389', '18390', '18391', '18392', '18393', '18394', '18395', '18396', '18397', '18398', '18399', '18400', '18401', '18402', '18403', '18404', '18405', '18406', '18407', '18408', '18409', '18410', '18411', '18412', '18413', '18414', '18415', '18416', '18417', '18418', '18419', '18420', '18421', '18422', '18423', '18424', '18425', '18426', '18427', '18428', '18429', '18430', '18431', '18432', '18433', '18434', '18435', '18436', '18437', '18438', '18439', '18440', '18441', '18442', '18443', '18444', '18445', '18446', '18447', '18448', '18449', '18450', '18451', '18452', '18453', '18454', '18455', '18456', '18457', '18458', '18459', '18460', '18461', '18462', '18463', '18464', '18465', '18466', '18467', '18468', '18469', '18470', '18471', '18472', '18473', '18474', '18475', '18476', '18477', '18478', '18479', '18480', '18481', '18482', '18483', '18484', '18485', '18486', '18487', '18488', '18489', '18490', '18491', '18492', '18493', '18494', '18495', '18496', '18497', '18498', '18499', '18500', '18501', '18502', '18503', '18504', '18505', '18506', '18507', '18508', '18509', '18510', '18511', '18512', '18513', '18514', '18515', '18516', '18517', '18518', '18519', '18520', '18521', '18522', '18523', '18524', '18525', '18526', '18527', '18528', '18529', '18530', '18531', '18532', '18533', '18534', '18535', '18536', '18537', '18538', '18539', '18540', '18541', '18542', '18543', '18544', '18545', '18546', '18547', '18548', '18549', '18550', '18551', '18552', '18553', '18554', '18555', '18556', '18557', '18558', '18559', '18560', '18561', '18562', '18563', '18564', '18565', '18566', '18567', '18568', '18569', '18570', '18571', '18572', '18573', '18574', '18575', '18576', '18577', '18578', '18579', '18580', '18581', '18582', '18583', '18584', '18585', '18586', '18587', '18588', '18589', '18590', '18591', '18592', '18593', '18594', '18595', '18596', '18597', '18598', '18599', '18600', '18601', '18602', '18603', '18604', '18605', '18606', '18607', '18608', '18609', '18610', '18611', '18612', '18613', '18614', '18615', '18616', '18617', '18618', '18619', '18620', '18621', '18622', '18623', '18624', '18625', '18626', '18627', '18628', '18629', '18630', '18631', '18632', '18633', '18634', '18635', '18636', '18637', '18638', '18639', '18640', '18641', '18642', '18643', '18644', '18645', '18646', '18647', '18648', '18649', '18650', '18651', '18652', '18653', '18654', '18655', '18656', '18657', '18658', '18659', '18660', '18661', '18662', '18663', '18664', '18665', '18666', '18667', '18668', '18669', '18670', '18671', '18672', '18673', '18674', '18675', '18676', '18677', '18678', '18679', '18680', '18681', '18682', '18683', '18684', '18685', '18686', '18687', '18688', '18689', '18690', '18691', '18692', '18693', '18694', '18695', '18696', '18697', '18698', '18699', '18700', '18701', '18702', '18703', '18704', '18705', '18706', '18707', '18708', '18709', '18710', '18711', '18712', '18713', '18714', '18715', '18716', '18717', '18718', '18719', '18720', '18721', '18722', '18723', '18724', '18725', '18726', '18727', '18728', '18729', '18730', '18731', '18732', '18733', '18734', '18735', '18736', '18737', '18738', '18739', '18740', '18741', '18742', '18743', '18744', '18745', '18746', '18747', '18748', '18749', '18750', '18751', '18752', '18753', '18754', '18755', '18756', '18757', '18758', '18759', '18760', '18761', '18762', '18763', '18764', '18765', '18766', '18767', '18768', '18769', '18770', '18771', '18772', '18773', '18774', '18775', '18776', '18777', '18778', '18779', '18780', '18781', '18782', '18783', '18784', '18785', '18786', '18787', '18788', '18789', '18790', '18791', '18792', '18793', '18794', '18795', '18796', '18797', '18798', '18799', '18800', '18801', '18802', '18803', '18804', '18805', '18806', '18807', '18808', '18809', '18810', '18811', '18812', '18813', '18814', '18815', '18816', '18817', '18818', '18819', '18820', '18821', '18822', '18823', '18824', '18825', '18826', '18827', '18828', '18829', '18830', '18831', '18832', '18833', '18834', '18835', '18836', '18837', '18838', '18839', '18840', '18841', '18842', '18843', '18844', '18845', '18846', '18847', '18848', '18849', '18850', '18851', '18852', '18853', '18854', '18855', '18856', '18857', '18858', '18859', '18860', '18861', '18862', '18863', '18864', '18865', '18866', '18867', '18868', '18869', '18870', '18871', '18872', '18873', '18874', '18875', '18876', '18877', '18878', '18879', '18880', '18881', '18882', '18883', '18884', '18885', '18886', '18887', '18888', '18889', '18890', '18891', '18892', '18893', '18894', '18895', '18896', '18897', '18898', '18899', '18900', '18901', '18902', '18903', '18904', '18905', '18906', '18907', '18908', '18909', '18910', '18911', '18912', '18913', '18914', '18915', '18916', '18917', '18918', '18919', '18920', '18921', '18922', '18923', '18924', '18925', '18926', '18927', '18928', '18929', '18930', '18931', '18932', '18933', '18934', '18935', '18936', '18937', '18938', '18939', '18940', '18941', '18942', '18943', '18944', '18945', '18946', '18947', '18948', '18949', '18950', '18951', '18952', '18953', '18954', '18955', '18956', '18957', '18958', '18959', '18960', '18961', '18962', '18963', '18964', '18965', '18966', '18967', '18968', '18969', '18970', '18971', '18972', '18973', '18974', '18975', '18976', '18977', '18978', '18979', '18980', '18981', '18982', '18983', '18984', '18985', '18986', '18987', '18988', '18989', '18990', '18991', '18992', '18993', '18994', '18995', '18996', '18997', '18998', '18999', '19000', '19001', '19002', '19003', '19004', '19005', '19006', '19007', '19008', '19009', '19010', '19011', '19012', '19013', '19014', '19015', '19016', '19017', '19018', '19019', '19020', '19021', '19022', '19023', '19024', '19025', '19026', '19027', '19028', '19029', '19030', '19031', '19032', '19033', '19034', '19035', '19036', '19037', '19038', '19039', '19040', '19041', '19042', '19043', '19044', '19045', '19046', '19047', '19048', '19049', '19050', '19051', '19052', '19053', '19054', '19055', '19056', '19057', '19058', '19059', '19060', '19061', '19062', '19063', '19064', '19065', '19066', '19067', '19068', '19069', '19070', '19071', '19072', '19073', '19074', '19075', '19076', '19077', '19078', '19079', '19080', '19081', '19082', '19083', '19084', '19085', '19086', '19087', '19088', '19089', '19090', '19091', '19092', '19093', '19094', '19095', '19096', '19097', '19098', '19099', '19100', '19101', '19102', '19103', '19104', '19105', '19106', '19107', '19108', '19109', '19110', '19111', '19112', '19113', '19114', '19115', '19116', '19117', '19118', '19119', '19120', '19121', '19122', '19123', '19124', '19125', '19126', '19127', '19128', '19129', '19130', '19131', '19132', '19133', '19134', '19135', '19136', '19137', '19138', '19139', '19140', '19141', '19142', '19143', '19144', '19145', '19146', '19147', '19148', '19149', '19150', '19151', '19152', '19153', '19154', '19155', '19156', '19157', '19158', '19159', '19160', '19161', '19162', '19163', '19164', '19165', '19166', '19167', '19168', '19169', '19170', '19171', '19172', '19173', '19174', '19175', '19176', '19177', '19178', '19179', '19180', '19181', '19182', '19183', '19184', '19185', '19186', '19187', '19188', '19189', '19190', '19191', '19192', '19193', '19194', '19195', '19196', '19197', '19198', '19199', '19200', '19201', '19202', '19203', '19204', '19205', '19206', '19207', '19208', '19209', '19210', '19211', '19212', '19213', '19214', '19215', '19216', '19217', '19218', '19219', '19220', '19221', '19222', '19223', '19224', '19225', '19226', '19227', '19228', '19229', '19230', '19231', '19232', '19233', '19234', '19235', '19236', '19237', '19238', '19239', '19240', '19241', '19242', '19243', '19244', '19245', '19246', '19247', '19248', '19249', '19250', '19251', '19252', '19253', '19254', '19255', '19256', '19257', '19258', '19259', '19260', '19261', '19262', '19263', '19264', '19265', '19266', '19267', '19268', '19269', '19270', '19271', '19272', '19273', '19274', '19275', '19276', '19277', '19278', '19279', '19280', '19281', '19282', '19283', '19284', '19285', '19286', '19287', '19288', '19289', '19290', '19291', '19292', '19293', '19294', '19295', '19296', '19297', '19298', '19299', '19300', '19301', '19302', '19303', '19304', '19305', '19306', '19307', '19308', '19309', '19310', '19311', '19312', '19313', '19314', '19315', '19316', '19317', '19318', '19319', '19320', '19321', '19322', '19323', '19324', '19325', '19326', '19327', '19328', '19329', '19330', '19331', '19332', '19333', '19334', '19335', '19336', '19337', '19338', '19339', '19340', '19341', '19342', '19343', '19344', '19345', '19346', '19347', '19348', '19349', '19350', '19351', '19352', '19353', '19354', '19355', '19356', '19357', '19358', '19359', '19360', '19361', '19362', '19363', '19364', '19365', '19366', '19367', '19368', '19369', '19370', '19371', '19372', '19373', '19374', '19375', '19376', '19377', '19378', '19379', '19380', '19381', '19382', '19383', '19384', '19385', '19386', '19387', '19388', '19389', '19390', '19391', '19392', '19393', '19394', '19395', '19396', '19397', '19398', '19399', '19400', '19401', '19402', '19403', '19404', '19405', '19406', '19407', '19408', '19409', '19410', '19411', '19412', '19413', '19414', '19415', '19416', '19417', '19418', '19419', '19420', '19421', '19422', '19423', '19424', '19425', '19426', '19427', '19428', '19429', '19430', '19431', '19432', '19433', '19434', '19435', '19436', '19437', '19438', '19439', '19440', '19441', '19442', '19443', '19444', '19445', '19446', '19447', '19448', '19449', '19450', '19451', '19452', '19453', '19454', '19455', '19456', '19457', '19458', '19459', '19460', '19461', '19462', '19463', '19464', '19465', '19466', '19467', '19468', '19469', '19470', '19471', '19472', '19473', '19474', '19475', '19476', '19477', '19478', '19479', '19480', '19481', '19482', '19483', '19484', '19485', '19486', '19487', '19488', '19489', '19490', '19491', '19492', '19493', '19494', '19495', '19496', '19497', '19498', '19499', '19500', '19501', '19502', '19503', '19504', '19505', '19506', '19507', '19508', '19509', '19510', '19511', '19512', '19513', '19514', '19515', '19516', '19517', '19518', '19519', '19520', '19521', '19522', '19523', '19524', '19525', '19526', '19527', '19528', '19529', '19530', '19531', '19532', '19533', '19534', '19535', '19536', '19537', '19538', '19539', '19540', '19541', '19542', '19543', '19544', '19545', '19546', '19547', '19548', '19549', '19550', '19551', '19552', '19553', '19554', '19555', '19556', '19557', '19558', '19559', '19560', '19561', '19562', '19563', '19564', '19565', '19566', '19567', '19568', '19569', '19570', '19571', '19572', '19573', '19574', '19575', '19576', '19577', '19578', '19579', '19580', '19581', '19582', '19583', '19584', '19585', '19586', '19587', '19588', '19589', '19590', '19591', '19592', '19593', '19594', '19595', '19596', '19597', '19598', '19599', '19600', '19601', '19602', '19603', '19604', '19605', '19606', '19607', '19608', '19609', '19610', '19611', '19612', '19613', '19614', '19615', '19616', '19617', '19618', '19619', '19620', '19621', '19622', '19623', '19624', '19625', '19626', '19627', '19628', '19629', '19630', '19631', '19632', '19633', '19634', '19635', '19636', '19637', '19638', '19639', '19640', '19641', '19642', '19643', '19644', '19645', '19646', '19647', '19648', '19649', '19650', '19651', '19652', '19653', '19654', '19655', '19656', '19657', '19658', '19659', '19660', '19661', '19662', '19663', '19664', '19665', '19666', '19667', '19668', '19669', '19670', '19671', '19672', '19673', '19674', '19675', '19676', '19677', '19678', '19679', '19680', '19681', '19682', '19683', '19684', '19685', '19686', '19687', '19688', '19689', '19690', '19691', '19692', '19693', '19694', '19695', '19696', '19697', '19698', '19699', '19700', '19701', '19702', '19703', '19704', '19705', '19706', '19707', '19708', '19709', '19710', '19711', '19712', '19713', '19714', '19715', '19716', '19717', '19718', '19719', '19720', '19721', '19722', '19723', '19724', '19725', '19726', '19727', '19728', '19729', '19730', '19731', '19732', '19733', '19734', '19735', '19736', '19737', '19738', '19739', '19740', '19741', '19742', '19743', '19744', '19745', '19746', '19747', '19748', '19749', '19750', '19751', '19752', '19753', '19754', '19755', '19756', '19757', '19758', '19759', '19760', '19761', '19762', '19763', '19764', '19765', '19766', '19767', '19768', '19769', '19770', '19771', '19772', '19773', '19774', '19775', '19776', '19777', '19778', '19779', '19780', '19781', '19782', '19783', '19784', '19785', '19786', '19787', '19788', '19789', '19790', '19791', '19792', '19793', '19794', '19795', '19796', '19797', '19798', '19799', '19800', '19801', '19802', '19803', '19804', '19805', '19806', '19807', '19808', '19809', '19810', '19811', '19812', '19813', '19814', '19815', '19816', '19817', '19818', '19819', '19820', '19821', '19822', '19823', '19824', '19825', '19826', '19827', '19828', '19829', '19830', '19831', '19832', '19833', '19834', '19835', '19836', '19837', '19838', '19839', '19840', '19841', '19842', '19843', '19844', '19845', '19846', '19847', '19848', '19849', '19850', '19851', '19852', '19853', '19854', '19855', '19856', '19857', '19858', '19859', '19860', '19861', '19862', '19863', '19864', '19865', '19866', '19867', '19868', '19869', '19870', '19871', '19872', '19873', '19874', '19875', '19876', '19877', '19878', '19879', '19880', '19881', '19882', '19883', '19884', '19885', '19886', '19887', '19888', '19889', '19890', '19891', '19892', '19893', '19894', '19895', '19896', '19897', '19898', '19899', '19900', '19901', '19902', '19903', '19904', '19905', '19906', '19907', '19908', '19909', '19910', '19911', '19912', '19913', '19914', '19915', '19916', '19917', '19918', '19919', '19920', '19921', '19922', '19923', '19924', '19925', '19926', '19927', '19928', '19929', '19930', '19931', '19932', '19933', '19934', '19935', '19936', '19937', '19938', '19939', '19940', '19941', '19942', '19943', '19944', '19945', '19946', '19947', '19948', '19949', '19950', '19951', '19952', '19953', '19954', '19955', '19956', '19957', '19958', '19959', '19960', '19961', '19962', '19963', '19964', '19965', '19966', '19967', '19968', '19969', '19970', '19971', '19972', '19973', '19974', '19975', '19976', '19977', '19978', '19979', '19980', '19981', '19982', '19983', '19984', '19985', '19986', '19987', '19988', '19989', '19990', '19991', '19992', '19993', '19994', '19995', '19996', '19997', '19998', '19999', '20000', '20001', '20002', '20003', '20004', '20005', '20006', '20007', '20008', '20009', '20010', '20011', '20012', '20013', '20014', '20015', '20016', '20017', '20018', '20019', '20020', '20021', '20022', '20023', '20024', '20025', '20026', '20027', '20028', '20029', '20030', '20031', '20032', '20033', '20034', '20035', '20036', '20037', '20038', '20039', '20040', '20041', '20042', '20043', '20044', '20045', '20046', '20047', '20048', '20049', '20050', '20051', '20052', '20053', '20054', '20055', '20056', '20057', '20058', '20059', '20060', '20061', '20062', '20063', '20064', '20065', '20066', '20067', '20068', '20069', '20070', '20071', '20072', '20073', '20074', '20075', '20076', '20077', '20078', '20079', '20080', '20081', '20082', '20083', '20084', '20085', '20086', '20087', '20088', '20089', '20090', '20091', '20092', '20093', '20094', '20095', '20096', '20097', '20098', '20099', '20100', '20101', '20102', '20103', '20104', '20105', '20106', '20107', '20108', '20109', '20110', '20111', '20112', '20113', '20114', '20115', '20116', '20117', '20118', '20119', '20120', '20121', '20122', '20123', '20124', '20125', '20126', '20127', '20128', '20129', '20130', '20131', '20132', '20133', '20134', '20135', '20136', '20137', '20138', '20139', '20140', '20141', '20142', '20143', '20144', '20145', '20146', '20147', '20148', '20149', '20150', '20151', '20152', '20153', '20154', '20155', '20156', '20157', '20158', '20159', '20160', '20161', '20162', '20163', '20164', '20165', '20166', '20167', '20168', '20169', '20170', '20171', '20172', '20173', '20174', '20175', '20176', '20177', '20178', '20179', '20180', '20181', '20182', '20183', '20184', '20185', '20186', '20187', '20188', '20189', '20190', '20191', '20192', '20193', '20194', '20195', '20196', '20197', '20198', '20199', '20200', '20201', '20202', '20203', '20204', '20205', '20206', '20207', '20208', '20209', '20210', '20211', '20212', '20213', '20214', '20215', '20216', '20217', '20218', '20219', '20220', '20221', '20222', '20223', '20224', '20225', '20226', '20227', '20228', '20229', '20230', '20231', '20232', '20233', '20234', '20235', '20236', '20237', '20238', '20239', '20240', '20241', '20242', '20243', '20244', '20245', '20246', '20247', '20248', '20249', '20250', '20251', '20252', '20253', '20254', '20255', '20256', '20257', '20258', '20259', '20260', '20261', '20262', '20263', '20264', '20265', '20266', '20267', '20268', '20269', '20270', '20271', '20272', '20273', '20274', '20275', '20276', '20277', '20278', '20279', '20280', '20281', '20282', '20283', '20284', '20285', '20286', '20287', '20288', '20289', '20290', '20291', '20292', '20293', '20294', '20295', '20296', '20297', '20298', '20299', '20300', '20301', '20302', '20303', '20304', '20305', '20306', '20307', '20308', '20309', '20310', '20311', '20312', '20313', '20314', '20315', '20316', '20317', '20318', '20319', '20320', '20321', '20322', '20323', '20324', '20325', '20326', '20327', '20328', '20329', '20330', '20331', '20332', '20333', '20334', '20335', '20336', '20337', '20338', '20339', '20340', '20341', '20342', '20343', '20344', '20345', '20346', '20347', '20348', '20349', '20350', '20351', '20352', '20353', '20354', '20355', '20356', '20357', '20358', '20359', '20360', '20361', '20362', '20363', '20364', '20365', '20366', '20367', '20368', '20369', '20370', '20371', '20372', '20373', '20374', '20375', '20376', '20377', '20378', '20379', '20380', '20381', '20382', '20383', '20384', '20385', '20386', '20387', '20388', '20389', '20390', '20391', '20392', '20393', '20394', '20395', '20396', '20397', '20398', '20399', '20400', '20401', '20402', '20403', '20404', '20405', '20406', '20407', '20408', '20409', '20410', '20411', '20412', '20413', '20414', '20415', '20416', '20417', '20418', '20419', '20420', '20421', '20422', '20423', '20424', '20425', '20426', '20427', '20428', '20429', '20430', '20431', '20432', '20433', '20434', '20435', '20436', '20437', '20438', '20439', '20440', '20441', '20442', '20443', '20444', '20445', '20446', '20447', '20448', '20449', '20450', '20451', '20452', '20453', '20454', '20455', '20456', '20457', '20458', '20459', '20460', '20461', '20462', '20463', '20464', '20465', '20466', '20467', '20468', '20469', '20470', '20471', '20472', '20473', '20474', '20475', '20476', '20477', '20478', '20479', '20480', '20481', '20482', '20483', '20484', '20485', '20486', '20487', '20488', '20489', '2049', '20490', '20491', '20492', '20493', '20494', '20495', '20496', '20497', '20498', '20499', '2050', '20500', '20501', '20502', '20503', '20504', '20505', '20506', '20507', '20508', '20509', '2051', '20510', '20511', '20512', '20513', '20514', '20515', '20516', '20517', '20518', '20519', '2052', '20520', '20521', '20522', '20523', '20524', '20525', '20526', '20527', '20528', '20529', '2053', '20530', '20531', '20532', '20533', '20534', '20535', '20536', '20537', '20538', '20539', '2054', '20540', '20541', '20542', '20543', '20544', '20545', '20546', '20547', '20548', '20549', '2055', '20550', '20551', '20552', '20553', '20554', '20555', '20556', '20557', '20558', '20559', '2056', '20560', '20561', '20562', '20563', '20564', '20565', '20566', '20567', '20568', '20569', '2057', '20570', '20571', '20572', '20573', '20574', '20575', '20576', '20577', '20578', '20579', '2058', '20580', '20581', '20582', '20583', '20584', '20585', '20586', '20587', '20588', '20589', '2059', '20590', '20591', '20592', '20593', '20594', '20595', '20596', '20597', '20598', '20599', '2060', '20600', '20601', '20602', '20603', '20604', '20605', '20606', '20607', '20608', '20609', '2061', '20610', '20611', '20612', '20613', '20614', '20615', '20616', '20617', '20618', '20619', '2062', '20620', '20621', '20622', '20623', '20624', '20625', '20626', '20627', '20628', '20629', '2063', '20630', '20631', '20632', '20633', '20634', '20635', '20636', '20637', '20638', '20639', '2064', '20640', '20641', '20642', '20643', '20644', '20645', '20646', '20647', '20648', '20649', '2065', '20650', '20651', '20652', '20653', '20654', '20655', '20656', '20657', '20658', '20659', '2066', '20660', '20661', '20662', '20663', '20664', '20665', '20666', '20667', '20668', '20669', '2067', '20670', '20671', '20672', '20673', '20674', '20675', '20676', '20677', '20678', '20679', '2068', '20680', '20681', '20682', '20683', '20684', '20685', '20686', '20687', '20688', '20689', '2069', '20690', '20691', '20692', '20693', '20694', '20695', '20696', '20697', '20698', '20699', '2070', '20700', '20701', '20702', '20703', '20704', '20705', '20706', '20707', '20708', '20709', '2071', '20710', '20711', '20712', '20713', '20714', '20715', '20716', '20717', '20718', '20719', '2072', '20720', '20721', '20722', '20723', '20724', '20725', '20726', '20727', '20728', '20729', '2073', '20730', '20731', '20732', '20733', '20734', '20735', '20736', '20737', '20738', '20739', '2074', '20740', '20741', '20742', '20743', '20744', '20745', '20746', '20747', '20748', '20749', '2075', '20750', '20751', '20752', '20753', '20754', '20755', '20756', '20757', '20758', '20759', '2076', '20760', '20761', '20762', '20763', '20764', '20765', '20766', '20767', '20768', '20769', '2077', '20770', '20771', '20772', '20773', '20774', '20775', '20776', '20777', '20778', '20779', '2078', '20780', '20781', '20782', '20783', '20784', '20785', '20786', '20787', '20788', '20789', '2079', '20790', '20791', '20792', '20793', '20794', '20795', '20796', '20797', '20798', '20799', '2080', '20800', '20801', '20802', '20803', '20804', '20805', '20806', '20807', '20808', '20809', '2081', '20810', '20811', '20812', '20813', '20814', '20815', '20816', '20817', '20818', '20819', '2082', '20820', '20821', '20822', '20823', '20824', '20825', '20826', '20827', '20828', '20829', '2083', '20830', '20831', '20832', '20833', '20834', '20835', '20836', '20837', '20838', '20839', '2084', '20840', '20841', '20842', '20843', '20844', '20845', '20846', '20847', '20848', '20849', '2085', '20850', '20851', '20852', '20853', '20854', '20855', '20856', '20857', '20858', '20859', '2086', '20860', '20861', '20862', '20863', '20864', '20865', '20866', '20867', '20868', '20869', '2087', '20870', '20871', '20872', '20873', '20874', '20875', '20876', '20877', '20878', '20879', '2088', '20880', '20881', '20882', '20883', '20884', '20885', '20886', '20887', '20888', '20889', '2089', '20890', '20891', '20892', '20893', '20894', '20895', '20896', '20897', '20898', '20899', '2090', '20900', '20901', '20902', '20903', '20904', '20905', '20906', '20907', '20908', '20909', '2091', '20910', '20911', '20912', '20913', '20914', '20915', '20916', '20917', '20918', '20919', '2092', '20920', '20921', '20922', '20923', '20924', '20925', '20926', '20927', '20928', '20929', '2093', '20930', '20931', '20932', '20933', '20934', '20935', '20936', '20937', '20938', '20939', '2094', '20940', '20941', '20942', '20943', '20944', '20945', '20946', '20947', '20948', '20949', '2095', '20950', '20951', '20952', '20953', '20954', '20955', '20956', '20957', '20958', '20959', '2096', '20960', '20961', '20962', '20963', '20964', '20965', '20966', '20967', '20968', '20969', '2097', '20970', '20971', '20972', '20973', '20974', '20975', '20976', '20977', '20978', '20979', '2098', '20980', '20981', '20982', '20983', '20984', '20985', '20986', '20987', '20988', '20989', '2099', '20990', '20991', '20992', '20993', '20994', '20995', '20996', '20997', '20998', '20999', '2100', '21000', '21001', '21002', '21003', '21004', '21005', '21006', '21007', '21008', '21009', '2101', '21010', '21011', '21012', '21013', '21014', '21015', '21016', '21017', '21018', '21019', '2102', '21020', '21021', '21022', '21023', '21024', '21025', '21026', '21027', '21028', '21029', '2103', '21030', '21031', '21032', '21033', '21034', '21035', '21036', '21037', '21038', '21039', '2104', '21040', '21041', '21042', '21043', '21044', '21045', '21046', '21047', '21048', '21049', '2105', '21050', '21051', '21052', '21053', '21054', '21055', '21056', '21057', '21058', '21059', '2106', '21060', '21061', '21062', '21063', '21064', '21065', '21066', '21067', '21068', '21069', '2107', '21070', '21071', '21072', '21073', '21074', '21075', '21076', '21077', '21078', '21079', '2108', '21080', '21081', '21082', '21083', '21084', '21085', '21086', '21087', '21088', '21089', '2109', '21090', '21091', '21092', '21093', '21094', '21095', '21096', '21097', '21098', '21099', '2110', '21100', '21101', '21102', '21103', '21104', '21105', '21106', '21107', '21108', '21109', '2111', '21110', '21111', '21112', '21113', '21114', '21115', '21116', '21117', '21118', '21119', '2112', '21120', '21121', '21122', '21123', '21124', '21125', '21126', '21127', '21128', '21129', '2113', '21130', '21131', '21132', '21133', '21134', '21135', '21136', '21137', '21138', '21139', '2114', '21140', '21141', '21142', '21143', '21144', '21145', '21146', '21147', '21148', '21149', '2115', '21150', '21151', '21152', '21153', '21154', '21155', '21156', '21157', '21158', '21159', '2116', '21160', '21161', '21162', '21163', '21164', '21165', '21166', '21167', '21168', '21169', '2117', '21170', '21171', '21172', '21173', '21174', '21175', '21176', '21177', '21178', '21179', '2118', '21180', '21181', '21182', '21183', '21184', '21185', '21186', '21187', '21188', '21189', '2119', '21190', '21191', '21192', '21193', '21194', '21195', '21196', '21197', '21198', '21199', '2120', '21200', '21201', '21202', '21203', '21204', '21205', '21206', '21207', '21208', '21209', '2121', '21210', '21211', '21212', '21213', '21214', '21215', '21216', '21217', '21218', '21219', '2122', '21220', '21221', '21222', '21223', '21224', '21225', '21226', '21227', '21228', '21229', '2123', '21230', '21231', '21232', '21233', '21234', '21235', '21236', '21237', '21238', '21239', '2124', '21240', '21241', '21242', '21243', '21244', '21245', '21246', '21247', '21248', '21249', '2125', '21250', '21251', '21252', '21253', '21254', '21255', '21256', '21257', '21258', '21259', '2126', '21260', '21261', '21262', '21263', '21264', '21265', '21266', '21267', '21268', '21269', '2127', '21270', '21271', '21272', '21273', '21274', '21275', '21276', '21277', '21278', '21279', '2128', '21280', '21281', '21282', '21283', '21284', '21285', '21286', '21287', '21288', '21289', '2129', '21290', '21291', '21292', '21293', '21294', '21295', '21296', '21297', '21298', '21299', '2130', '21300', '21301', '21302', '21303', '21304', '21305', '21306', '21307', '21308', '21309', '2131', '21310', '21311', '21312', '21313', '21314', '21315', '21316', '21317', '21318', '21319', '2132', '21320', '21321', '21322', '21323', '21324', '21325', '21326', '21327', '21328', '21329', '2133', '21330', '21331', '21332', '21333', '21334', '21335', '21336', '21337', '21338', '21339', '2134', '21340', '21341', '21342', '21343', '21344', '21345', '21346', '21347', '21348', '21349', '2135', '21350', '21351', '21352', '21353', '21354', '21355', '21356', '21357', '21358', '21359', '2136', '21360', '21361', '21362', '21363', '21364', '21365', '21366', '21367', '21368', '21369', '2137', '21370', '21371', '21372', '21373', '21374', '21375', '21376', '21377', '21378', '21379', '2138', '21380', '21381', '21382', '21383', '21384', '21385', '21386', '21387', '21388', '21389', '2139', '21390', '21391', '21392', '21393', '21394', '21395', '21396', '21397', '21398', '21399', '2140', '21400', '21401', '21402', '21403', '21404', '21405', '21406', '21407', '21408', '21409', '2141', '21410', '21411', '21412', '21413', '21414', '21415', '21416', '21417', '21418', '21419', '2142', '21420', '21421', '21422', '21423', '21424', '21425', '21426', '21427', '21428', '21429', '2143', '21430', '21431', '21432', '21433', '21434', '21435', '21436', '21437', '21438', '21439', '2144', '21440', '21441', '21442', '21443', '21444', '21445', '21446', '21447', '21448', '21449', '2145', '21450', '21451', '21452', '21453', '21454', '21455', '21456', '21457', '21458', '21459', '2146', '21460', '21461', '21462', '21463', '21464', '21465', '21466', '21467', '21468', '21469', '2147', '21470', '21471', '21472', '21473', '21474', '21475', '21476', '21477', '21478', '21479', '2148', '21480', '21481', '21482', '21483', '21484', '21485', '21486', '21487', '21488', '21489', '2149', '21490', '21491', '21492', '21493', '21494', '21495', '21496', '21497', '21498', '21499', '2150', '21500', '21501', '21502', '21503', '21504', '21505', '21506', '21507', '21508', '21509', '2151', '21510', '21511', '21512', '21513', '21514', '21515', '21516', '21517', '21518', '21519', '2152', '21520', '21521', '21522', '21523', '21524', '21525', '21526', '21527', '21528', '21529', '2153', '21530', '21531', '21532', '21533', '21534', '21535', '21536', '21537', '21538', '21539', '2154', '21540', '21541', '21542', '21543', '21544', '21545', '21546', '21547', '21548', '21549', '2155', '21550', '21551', '21552', '21553', '21554', '21555', '21556', '21557', '21558', '21559', '2156', '21560', '21561', '21562', '21563', '21564', '21565', '21566', '21567', '21568', '21569', '2157', '21570', '21571', '21572', '21573', '21574', '21575', '21576', '21577', '21578', '21579', '2158', '21580', '21581', '21582', '21583', '21584', '21585', '21586', '21587', '21588', '21589', '2159', '21590', '21591', '21592', '21593', '21594', '21595', '21596', '21597', '21598', '21599', '2160', '21600', '21601', '21602', '21603', '21604', '21605', '21606', '21607', '21608', '21609', '2161', '21610', '21611', '21612', '21613', '21614', '21615', '21616', '21617', '21618', '21619', '2162', '21620', '21621', '21622', '21623', '21624', '21625', '21626', '21627', '21628', '21629', '2163', '21630', '21631', '21632', '21633', '21634', '21635', '21636', '21637', '21638', '21639', '2164', '21640', '21641', '21642', '21643', '21644', '21645', '21646', '21647', '21648', '21649', '2165', '21650', '21651', '21652', '21653', '21654', '21655', '21656', '21657', '21658', '21659', '2166', '21660', '21661', '21662', '21663', '21664', '21665', '21666', '21667', '21668', '21669', '2167', '21670', '21671', '21672', '21673', '21674', '21675', '21676', '21677', '21678', '21679', '2168', '21680', '21681', '21682', '21683', '21684', '21685', '21686', '21687', '21688', '21689', '2169', '21690', '21691', '21692', '21693', '21694', '21695', '21696', '21697', '21698', '21699', '2170', '21700', '21701', '21702', '21703', '21704', '21705', '21706', '21707', '21708', '21709', '2171', '21710', '21711', '21712', '21713', '21714', '21715', '21716', '21717', '21718', '21719', '2172', '21720', '21721', '21722', '21723', '21724', '21725', '21726', '21727', '21728', '21729', '2173', '21730', '21731', '21732', '21733', '21734', '21735', '21736', '21737', '21738', '21739', '2174', '21740', '21741', '21742', '21743', '21744', '21745', '21746', '21747', '21748', '21749', '2175', '21750', '21751', '21752', '21753', '21754', '21755', '21756', '21757', '21758', '21759', '2176', '21760', '21761', '21762', '21763', '21764', '21765', '21766', '21767', '21768', '21769', '2177', '21770', '21771', '21772', '21773', '21774', '21775', '21776', '21777', '21778', '21779', '2178', '21780', '21781', '21782', '21783', '21784', '21785', '21786', '21787', '21788', '21789', '2179', '21790', '21791', '21792', '21793', '21794', '21795', '21796', '21797', '21798', '21799', '2180', '21800', '21801', '21802', '21803', '21804', '21805', '21806', '21807', '21808', '21809', '2181', '21810', '21811', '21812', '21813', '21814', '21815', '21816', '21817', '21818', '21819', '2182', '21820', '21821', '21822', '21823', '21824', '21825', '21826', '21827', '21828', '21829', '2183', '21830', '21831', '21832', '21833', '21834', '21835', '21836', '21837', '21838', '21839', '2184', '21840', '21841', '21842', '21843', '21844', '21845', '21846', '21847', '21848', '21849', '2185', '21850', '21851', '21852', '21853', '21854', '21855', '21856', '21857', '21858', '21859', '2186', '21860', '21861', '21862', '21863', '21864', '21865', '21866', '21867', '21868', '21869', '2187', '21870', '21871', '21872', '21873', '21874', '21875', '21876', '21877', '21878', '21879', '2188', '21880', '21881', '21882', '21883', '21884', '21885', '21886', '21887', '21888', '21889', '2189', '21890', '21891', '21892', '21893', '21894', '21895', '21896', '21897', '21898', '21899', '2190', '21900', '21901', '21902', '21903', '21904', '21905', '21906', '21907', '21908', '21909', '2191', '21910', '21911', '21912', '21913', '21914', '21915', '21916', '21917', '21918', '21919', '2192', '21920', '21921', '21922', '21923', '21924', '21925', '21926', '21927', '21928', '21929', '2193', '21930', '21931', '21932', '21933', '21934', '21935', '21936', '21937', '21938', '21939', '2194', '21940', '21941', '21942', '21943', '21944', '21945', '21946', '21947', '21948', '21949', '2195', '21950', '21951', '21952', '21953', '21954', '21955', '21956', '21957', '21958', '21959', '2196', '21960', '21961', '21962', '21963', '21964', '21965', '21966', '21967', '21968', '21969', '2197', '21970', '21971', '21972', '21973', '21974', '21975', '21976', '21977', '21978', '21979', '2198', '21980', '21981', '21982', '21983', '21984', '21985', '21986', '21987', '21988', '21989', '2199', '21990', '21991', '21992', '21993', '21994', '21995', '21996', '21997', '21998', '21999', '2200', '22000', '22001', '22002', '22003', '22004', '22005', '22006', '22007', '22008', '22009', '2201', '22010', '22011', '22012', '22013', '22014', '22015', '22016', '22017', '22018', '22019', '2202', '22020', '22021', '22022', '22023', '22024', '22025', '22026', '22027', '22028', '22029', '2203', '22030', '22031', '22032', '22033', '22034', '22035', '22036', '22037', '22038', '22039', '2204', '22040', '22041', '22042', '22043', '22044', '22045', '22046', '22047', '22048', '22049', '2205', '22050', '22051', '22052', '22053', '22054', '22055', '22056', '22057', '22058', '22059', '2206', '22060', '22061', '22062', '22063', '22064', '22065', '22066', '22067', '22068', '22069', '2207', '22070', '22071', '22072', '22073', '22074', '22075', '22076', '22077', '22078', '22079', '2208', '22080', '22081', '22082', '22083', '22084', '22085', '22086', '22087', '22088', '22089', '2209', '22090', '22091', '22092', '22093', '22094', '22095', '22096', '22097', '22098', '22099', '2210', '22100', '22101', '22102', '22103', '22104', '22105', '22106', '22107', '22108', '22109', '2211', '22110', '22111', '22112', '22113', '22114', '22115', '22116', '22117', '22118', '22119', '2212', '22120', '22121', '22122', '22123', '22124', '22125', '22126', '22127', '22128', '22129', '2213', '22130', '22131', '22132', '22133', '22134', '22135', '22136', '22137', '22138', '22139', '2214', '22140', '22141', '22142', '22143', '22144', '22145', '22146', '22147', '22148', '22149', '2215', '22150', '22151', '22152', '22153', '22154', '22155', '22156', '22157', '22158', '22159', '2216', '22160', '22161', '22162', '22163', '22164', '22165', '22166', '22167', '22168', '22169', '2217', '22170', '22171', '22172', '22173', '22174', '22175', '22176', '22177', '22178', '22179', '2218', '22180', '22181', '22182', '22183', '22184', '22185', '22186', '22187', '22188', '22189', '2219', '22190', '22191', '22192', '22193', '22194', '22195', '22196', '22197', '22198', '22199', '2220', '22200', '22201', '22202', '22203', '22204', '22205', '22206', '22207', '22208', '22209', '2221', '22210', '22211', '22212', '22213', '22214', '22215', '22216', '22217', '22218', '22219', '2222', '22220', '22221', '22222', '22223', '22224', '22225', '22226', '22227', '22228', '22229', '2223', '22230', '22231', '22232', '22233', '22234', '22235', '22236', '22237', '22238', '22239', '2224', '22240', '22241', '22242', '22243', '22244', '22245', '22246', '22247', '22248', '22249', '2225', '22250', '22251', '22252', '22253', '22254', '22255', '22256', '22257', '22258', '22259', '2226', '22260', '22261', '22262', '22263', '22264', '22265', '22266', '22267', '22268', '22269', '2227', '22270', '22271', '22272', '22273', '22274', '22275', '22276', '22277', '22278', '22279', '2228', '22280', '22281', '22282', '22283', '22284', '22285', '22286', '22287', '22288', '22289', '2229', '22290', '22291', '22292', '22293', '22294', '22295', '22296', '22297', '22298', '22299', '2230', '22300', '22301', '22302', '22303', '22304', '22305', '22306', '22307', '22308', '22309', '2231', '22310', '22311', '22312', '22313', '22314', '22315', '22316', '22317', '22318', '22319', '2232', '22320', '22321', '22322', '22323', '22324', '22325', '22326', '22327', '22328', '22329', '2233', '22330', '22331', '22332', '22333', '22334', '22335', '22336', '22337', '22338', '22339', '2234', '22340', '22341', '22342', '22343', '22344', '22345', '22346', '22347', '22348', '22349', '2235', '22350', '22351', '22352', '22353', '22354', '22355', '22356', '22357', '22358', '22359', '2236', '22360', '22361', '22362', '22363', '22364', '22365', '22366', '22367', '22368', '22369', '2237', '22370', '22371', '22372', '22373', '22374', '22375', '22376', '22377', '22378', '22379', '2238', '22380', '22381', '22382', '22383', '22384', '22385', '22386', '22387', '22388', '22389', '2239', '22390', '22391', '22392', '22393', '22394', '22395', '22396', '22397', '22398', '22399', '2240', '22400', '22401', '22402', '22403', '22404', '22405', '22406', '22407', '22408', '22409', '2241', '22410', '22411', '22412', '22413', '22414', '22415', '22416', '22417', '22418', '22419', '2242', '22420', '22421', '22422', '22423', '22424', '22425', '22426', '22427', '22428', '22429', '2243', '22430', '22431', '22432', '22433', '22434', '22435', '22436', '22437', '22438', '22439', '2244', '22440', '22441', '22442', '22443', '22444', '22445', '22446', '22447', '22448', '22449', '2245', '22450', '22451', '22452', '22453', '22454', '22455', '22456', '22457', '22458', '22459', '2246', '22460', '22461', '22462', '22463', '22464', '22465', '22466', '22467', '22468', '22469', '2247', '22470', '22471', '22472', '22473', '22474', '22475', '22476', '22477', '22478', '22479', '2248', '22480', '22481', '22482', '22483', '22484', '22485', '22486', '22487', '22488', '22489', '2249', '22490', '22491', '22492', '22493', '22494', '22495', '22496', '22497', '22498', '22499', '2250', '22500', '22501', '22502', '22503', '22504', '22505', '22506', '22507', '22508', '22509', '2251', '22510', '22511', '22512', '22513', '22514', '22515', '22516', '22517', '22518', '22519', '2252', '22520', '22521', '22522', '22523', '22524', '22525', '22526', '22527', '22528', '2253', '2254', '2255', '2256', '2257', '2258', '2259', '2260', '2261', '2262', '2263', '2264', '2265', '2266', '2267', '2268', '2269', '2270', '2271', '2272', '2273', '2274', '2275', '2276', '2277', '2278', '2279', '2280', '2281', '2282', '2283', '2284', '2285', '2286', '2287', '2288', '2289', '2290', '2291', '2292', '2293', '2294', '2295', '2296', '2297', '2298', '2299', '2300', '2301', '2302', '2303', '2304', '2305', '2306', '2307', '2308', '2309', '2310', '2311', '2312', '2313', '2314', '2315', '2316', '2317', '2318', '2319', '2320', '2321', '2322', '2323', '2324', '2325', '2326', '2327', '2328', '2329', '2330', '2331', '2332', '2333', '2334', '2335', '2336', '2337', '2338', '2339', '2340', '2341', '2342', '2343', '2344', '2345', '2346', '2347', '2348', '2349', '2350', '2351', '2352', '2353', '2354', '2355', '2356', '2357', '2358', '2359', '2360', '2361', '2362', '2363', '2364', '2365', '2366', '2367', '2368', '2369', '2370', '2371', '2372', '2373', '2374', '2375', '2376', '2377', '2378', '2379', '2380', '2381', '2382', '2383', '2384', '2385', '2386', '2387', '2388', '2389', '2390', '2391', '2392', '2393', '2394', '2395', '2396', '2397', '2398', '2399', '2400', '2401', '2402', '2403', '2404', '2405', '2406', '2407', '2408', '2409', '2410', '2411', '2412', '2413', '2414', '2415', '2416', '2417', '2418', '2419', '2420', '2421', '2422', '2423', '2424', '2425', '2426', '2427', '2428', '2429', '2430', '2431', '2432', '2433', '2434', '2435', '2436', '2437', '2438', '2439', '2440', '2441', '2442', '2443', '2444', '2445', '2446', '2447', '2448', '2449', '2450', '2451', '2452', '2453', '2454', '2455', '2456', '2457', '2458', '2459', '2460', '2461', '2462', '2463', '2464', '2465', '2466', '2467', '2468', '2469', '2470', '2471', '2472', '2473', '2474', '2475', '2476', '2477', '2478', '2479', '2480', '2481', '2482', '2483', '2484', '2485', '2486', '2487', '2488', '2489', '2490', '2491', '2492', '2493', '2494', '2495', '2496', '2497', '2498', '2499', '2500', '2501', '2502', '2503', '2504', '2505', '2506', '2507', '2508', '2509', '2510', '2511', '2512', '2513', '2514', '2515', '2516', '2517', '2518', '2519', '2520', '2521', '2522', '2523', '2524', '2525', '2526', '2527', '2528', '2529', '2530', '2531', '2532', '2533', '2534', '2535', '2536', '2537', '2538', '2539', '2540', '2541', '2542', '2543', '2544', '2545', '2546', '2547', '2548', '2549', '2550', '2551', '2552', '2553', '2554', '2555', '2556', '2557', '2558', '2559', '2560', '2561', '2562', '2563', '2564', '2565', '2566', '2567', '2568', '2569', '2570', '2571', '2572', '2573', '2574', '2575', '2576', '2577', '2578', '2579', '2580', '2581', '2582', '2583', '2584', '2585', '2586', '2587', '2588', '2589', '2590', '2591', '2592', '2593', '2594', '2595', '2596', '2597', '2598', '2599', '2600', '2601', '2602', '2603', '2604', '2605', '2606', '2607', '2608', '2609', '2610', '2611', '2612', '2613', '2614', '2615', '2616', '2617', '2618', '2619', '2620', '2621', '2622', '2623', '2624', '2625', '2626', '2627', '2628', '2629', '2630', '2631', '2632', '2633', '2634', '2635', '2636', '2637', '2638', '2639', '2640', '2641', '2642', '2643', '2644', '2645', '2646', '2647', '2648', '2649', '2650', '2651', '2652', '2653', '2654', '2655', '2656', '2657', '2658', '2659', '2660', '2661', '2662', '2663', '2664', '2665', '2666', '2667', '2668', '2669', '2670', '2671', '2672', '2673', '2674', '2675', '2676', '2677', '2678', '2679', '2680', '2681', '2682', '2683', '2684', '2685', '2686', '2687', '2688', '2689', '2690', '2691', '2692', '2693', '2694', '2695', '2696', '2697', '2698', '2699', '2700', '2701', '2702', '2703', '2704', '2705', '2706', '2707', '2708', '2709', '2710', '2711', '2712', '2713', '2714', '2715', '2716', '2717', '2718', '2719', '2720', '2721', '2722', '2723', '2724', '2725', '2726', '2727', '2728', '2729', '2730', '2731', '2732', '2733', '2734', '2735', '2736', '2737', '2738', '2739', '2740', '2741', '2742', '2743', '2744', '2745', '2746', '2747', '2748', '2749', '2750', '2751', '2752', '2753', '2754', '2755', '2756', '2757', '2758', '2759', '2760', '2761', '2762', '2763', '2764', '2765', '2766', '2767', '2768', '2769', '2770', '2771', '2772', '2773', '2774', '2775', '2776', '2777', '2778', '2779', '2780', '2781', '2782', '2783', '2784', '2785', '2786', '2787', '2788', '2789', '2790', '2791', '2792', '2793', '2794', '2795', '2796', '2797', '2798', '2799', '2800', '2801', '2802', '2803', '2804', '2805', '2806', '2807', '2808', '2809', '2810', '2811', '2812', '2813', '2814', '2815', '2816', '2817', '2818', '2819', '2820', '2821', '2822', '2823', '2824', '2825', '2826', '2827', '2828', '2829', '2830', '2831', '2832', '2833', '2834', '2835', '2836', '2837', '2838', '2839', '2840', '2841', '2842', '2843', '2844', '2845', '2846', '2847', '2848', '2849', '2850', '2851', '2852', '2853', '2854', '2855', '2856', '2857', '2858', '2859', '2860', '2861', '2862', '2863', '2864', '2865', '2866', '2867', '2868', '2869', '2870', '2871', '2872', '2873', '2874', '2875', '2876', '2877', '2878', '2879', '2880', '2881', '2882', '2883', '2884', '2885', '2886', '2887', '2888', '2889', '2890', '2891', '2892', '2893', '2894', '2895', '2896', '2897', '2898', '2899', '2900', '2901', '2902', '2903', '2904', '2905', '2906', '2907', '2908', '2909', '2910', '2911', '2912', '2913', '2914', '2915', '2916', '2917', '2918', '2919', '2920', '2921', '2922', '2923', '2924', '2925', '2926', '2927', '2928', '2929', '2930', '2931', '2932', '2933', '2934', '2935', '2936', '2937', '2938', '2939', '2940', '2941', '2942', '2943', '2944', '2945', '2946', '2947', '2948', '2949', '2950', '2951', '2952', '2953', '2954', '2955', '2956', '2957', '2958', '2959', '2960', '2961', '2962', '2963', '2964', '2965', '2966', '2967', '2968', '2969', '2970', '2971', '2972', '2973', '2974', '2975', '2976', '2977', '2978', '2979', '2980', '2981', '2982', '2983', '2984', '2985', '2986', '2987', '2988', '2989', '2990', '2991', '2992', '2993', '2994', '2995', '2996', '2997', '2998', '2999', '3000', '3001', '3002', '3003', '3004', '3005', '3006', '3007', '3008', '3009', '3010', '3011', '3012', '3013', '3014', '3015', '3016', '3017', '3018', '3019', '3020', '3021', '3022', '3023', '3024', '3025', '3026', '3027', '3028', '3029', '3030', '3031', '3032', '3033', '3034', '3035', '3036', '3037', '3038', '3039', '3040', '3041', '3042', '3043', '3044', '3045', '3046', '3047', '3048', '3049', '3050', '3051', '3052', '3053', '3054', '3055', '3056', '3057', '3058', '3059', '3060', '3061', '3062', '3063', '3064', '3065', '3066', '3067', '3068', '3069', '3070', '3071', '3072', '3073', '3074', '3075', '3076', '3077', '3078', '3079', '3080', '3081', '3082', '3083', '3084', '3085', '3086', '3087', '3088', '3089', '3090', '3091', '3092', '3093', '3094', '3095', '3096', '3097', '3098', '3099', '3100', '3101', '3102', '3103', '3104', '3105', '3106', '3107', '3108', '3109', '3110', '3111', '3112', '3113', '3114', '3115', '3116', '3117', '3118', '3119', '3120', '3121', '3122', '3123', '3124', '3125', '3126', '3127', '3128', '3129', '3130', '3131', '3132', '3133', '3134', '3135', '3136', '3137', '3138', '3139', '3140', '3141', '3142', '3143', '3144', '3145', '3146', '3147', '3148', '3149', '3150', '3151', '3152', '3153', '3154', '3155', '3156', '3157', '3158', '3159', '3160', '3161', '3162', '3163', '3164', '3165', '3166', '3167', '3168', '3169', '3170', '3171', '3172', '3173', '3174', '3175', '3176', '3177', '3178', '3179', '3180', '3181', '3182', '3183', '3184', '3185', '3186', '3187', '3188', '3189', '3190', '3191', '3192', '3193', '3194', '3195', '3196', '3197', '3198', '3199', '3200', '3201', '3202', '3203', '3204', '3205', '3206', '3207', '3208', '3209', '3210', '3211', '3212', '3213', '3214', '3215', '3216', '3217', '3218', '3219', '3220', '3221', '3222', '3223', '3224', '3225', '3226', '3227', '3228', '3229', '3230', '3231', '3232', '3233', '3234', '3235', '3236', '3237', '3238', '3239', '3240', '3241', '3242', '3243', '3244', '3245', '3246', '3247', '3248', '3249', '3250', '3251', '3252', '3253', '3254', '3255', '3256', '3257', '3258', '3259', '3260', '3261', '3262', '3263', '3264', '3265', '3266', '3267', '3268', '3269', '3270', '3271', '3272', '3273', '3274', '3275', '3276', '3277', '3278', '3279', '3280', '3281', '3282', '3283', '3284', '3285', '3286', '3287', '3288', '3289', '3290', '3291', '3292', '3293', '3294', '3295', '3296', '3297', '3298', '3299', '3300', '3301', '3302', '3303', '3304', '3305', '3306', '3307', '3308', '3309', '3310', '3311', '3312', '3313', '3314', '3315', '3316', '3317', '3318', '3319', '3320', '3321', '3322', '3323', '3324', '3325', '3326', '3327', '3328', '3329', '3330', '3331', '3332', '3333', '3334', '3335', '3336', '3337', '3338', '3339', '3340', '3341', '3342', '3343', '3344', '3345', '3346', '3347', '3348', '3349', '3350', '3351', '3352', '3353', '3354', '3355', '3356', '3357', '3358', '3359', '3360', '3361', '3362', '3363', '3364', '3365', '3366', '3367', '3368', '3369', '3370', '3371', '3372', '3373', '3374', '3375', '3376', '3377', '3378', '3379', '3380', '3381', '3382', '3383', '3384', '3385', '3386', '3387', '3388', '3389', '3390', '3391', '3392', '3393', '3394', '3395', '3396', '3397', '3398', '3399', '3400', '3401', '3402', '3403', '3404', '3405', '3406', '3407', '3408', '3409', '3410', '3411', '3412', '3413', '3414', '3415', '3416', '3417', '3418', '3419', '3420', '3421', '3422', '3423', '3424', '3425', '3426', '3427', '3428', '3429', '3430', '3431', '3432', '3433', '3434', '3435', '3436', '3437', '3438', '3439', '3440', '3441', '3442', '3443', '3444', '3445', '3446', '3447', '3448', '3449', '3450', '3451', '3452', '3453', '3454', '3455', '3456', '3457', '3458', '3459', '3460', '3461', '3462', '3463', '3464', '3465', '3466', '3467', '3468', '3469', '3470', '3471', '3472', '3473', '3474', '3475', '3476', '3477', '3478', '3479', '3480', '3481', '3482', '3483', '3484', '3485', '3486', '3487', '3488', '3489', '3490', '3491', '3492', '3493', '3494', '3495', '3496', '3497', '3498', '3499', '3500', '3501', '3502', '3503', '3504', '3505', '3506', '3507', '3508', '3509', '3510', '3511', '3512', '3513', '3514', '3515', '3516', '3517', '3518', '3519', '3520', '3521', '3522', '3523', '3524', '3525', '3526', '3527', '3528', '3529', '3530', '3531', '3532', '3533', '3534', '3535', '3536', '3537', '3538', '3539', '3540', '3541', '3542', '3543', '3544', '3545', '3546', '3547', '3548', '3549', '3550', '3551', '3552', '3553', '3554', '3555', '3556', '3557', '3558', '3559', '3560', '3561', '3562', '3563', '3564', '3565', '3566', '3567', '3568', '3569', '3570', '3571', '3572', '3573', '3574', '3575', '3576', '3577', '3578', '3579', '3580', '3581', '3582', '3583', '3584', '3585', '3586', '3587', '3588', '3589', '3590', '3591', '3592', '3593', '3594', '3595', '3596', '3597', '3598', '3599', '3600', '3601', '3602', '3603', '3604', '3605', '3606', '3607', '3608', '3609', '3610', '3611', '3612', '3613', '3614', '3615', '3616', '3617', '3618', '3619', '3620', '3621', '3622', '3623', '3624', '3625', '3626', '3627', '3628', '3629', '3630', '3631', '3632', '3633', '3634', '3635', '3636', '3637', '3638', '3639', '3640', '3641', '3642', '3643', '3644', '3645', '3646', '3647', '3648', '3649', '3650', '3651', '3652', '3653', '3654', '3655', '3656', '3657', '3658', '3659', '3660', '3661', '3662', '3663', '3664', '3665', '3666', '3667', '3668', '3669', '3670', '3671', '3672', '3673', '3674', '3675', '3676', '3677', '3678', '3679', '3680', '3681', '3682', '3683', '3684', '3685', '3686', '3687', '3688', '3689', '3690', '3691', '3692', '3693', '3694', '3695', '3696', '3697', '3698', '3699', '3700', '3701', '3702', '3703', '3704', '3705', '3706', '3707', '3708', '3709', '3710', '3711', '3712', '3713', '3714', '3715', '3716', '3717', '3718', '3719', '3720', '3721', '3722', '3723', '3724', '3725', '3726', '3727', '3728', '3729', '3730', '3731', '3732', '3733', '3734', '3735', '3736', '3737', '3738', '3739', '3740', '3741', '3742', '3743', '3744', '3745', '3746', '3747', '3748', '3749', '3750', '3751', '3752', '3753', '3754', '3755', '3756', '3757', '3758', '3759', '3760', '3761', '3762', '3763', '3764', '3765', '3766', '3767', '3768', '3769', '3770', '3771', '3772', '3773', '3774', '3775', '3776', '3777', '3778', '3779', '3780', '3781', '3782', '3783', '3784', '3785', '3786', '3787', '3788', '3789', '3790', '3791', '3792', '3793', '3794', '3795', '3796', '3797', '3798', '3799', '3800', '3801', '3802', '3803', '3804', '3805', '3806', '3807', '3808', '3809', '3810', '3811', '3812', '3813', '3814', '3815', '3816', '3817', '3818', '3819', '3820', '3821', '3822', '3823', '3824', '3825', '3826', '3827', '3828', '3829', '3830', '3831', '3832', '3833', '3834', '3835', '3836', '3837', '3838', '3839', '3840', '3841', '3842', '3843', '3844', '3845', '3846', '3847', '3848', '3849', '3850', '3851', '3852', '3853', '3854', '3855', '3856', '3857', '3858', '3859', '3860', '3861', '3862', '3863', '3864', '3865', '3866', '3867', '3868', '3869', '3870', '3871', '3872', '3873', '3874', '3875', '3876', '3877', '3878', '3879', '3880', '3881', '3882', '3883', '3884', '3885', '3886', '3887', '3888', '3889', '3890', '3891', '3892', '3893', '3894', '3895', '3896', '3897', '3898', '3899', '3900', '3901', '3902', '3903', '3904', '3905', '3906', '3907', '3908', '3909', '3910', '3911', '3912', '3913', '3914', '3915', '3916', '3917', '3918', '3919', '3920', '3921', '3922', '3923', '3924', '3925', '3926', '3927', '3928', '3929', '3930', '3931', '3932', '3933', '3934', '3935', '3936', '3937', '3938', '3939', '3940', '3941', '3942', '3943', '3944', '3945', '3946', '3947', '3948', '3949', '3950', '3951', '3952', '3953', '3954', '3955', '3956', '3957', '3958', '3959', '3960', '3961', '3962', '3963', '3964', '3965', '3966', '3967', '3968', '3969', '3970', '3971', '3972', '3973', '3974', '3975', '3976', '3977', '3978', '3979', '3980', '3981', '3982', '3983', '3984', '3985', '3986', '3987', '3988', '3989', '3990', '3991', '3992', '3993', '3994', '3995', '3996', '3997', '3998', '3999', '4000', '4001', '4002', '4003', '4004', '4005', '4006', '4007', '4008', '4009', '4010', '4011', '4012', '4013', '4014', '4015', '4016', '4017', '4018', '4019', '4020', '4021', '4022', '4023', '4024', '4025', '4026', '4027', '4028', '4029', '4030', '4031', '4032', '4033', '4034', '4035', '4036', '4037', '4038', '4039', '4040', '4041', '4042', '4043', '4044', '4045', '4046', '4047', '4048', '4049', '4050', '4051', '4052', '4053', '4054', '4055', '4056', '4057', '4058', '4059', '4060', '4061', '4062', '4063', '4064', '4065', '4066', '4067', '4068', '4069', '4070', '4071', '4072', '4073', '4074', '4075', '4076', '4077', '4078', '4079', '4080', '4081', '4082', '4083', '4084', '4085', '4086', '4087', '4088', '4089', '4090', '4091', '4092', '4093', '4094', '4095', '4096', '4097', '4098', '4099', '4100', '4101', '4102', '4103', '4104', '4105', '4106', '4107', '4108', '4109', '4110', '4111', '4112', '4113', '4114', '4115', '4116', '4117', '4118', '4119', '4120', '4121', '4122', '4123', '4124', '4125', '4126', '4127', '4128', '4129', '4130', '4131', '4132', '4133', '4134', '4135', '4136', '4137', '4138', '4139', '4140', '4141', '4142', '4143', '4144', '4145', '4146', '4147', '4148', '4149', '4150', '4151', '4152', '4153', '4154', '4155', '4156', '4157', '4158', '4159', '4160', '4161', '4162', '4163', '4164', '4165', '4166', '4167', '4168', '4169', '4170', '4171', '4172', '4173', '4174', '4175', '4176', '4177', '4178', '4179', '4180', '4181', '4182', '4183', '4184', '4185', '4186', '4187', '4188', '4189', '4190', '4191', '4192', '4193', '4194', '4195', '4196', '4197', '4198', '4199', '4200', '4201', '4202', '4203', '4204', '4205', '4206', '4207', '4208', '4209', '4210', '4211', '4212', '4213', '4214', '4215', '4216', '4217', '4218', '4219', '4220', '4221', '4222', '4223', '4224', '4225', '4226', '4227', '4228', '4229', '4230', '4231', '4232', '4233', '4234', '4235', '4236', '4237', '4238', '4239', '4240', '4241', '4242', '4243', '4244', '4245', '4246', '4247', '4248', '4249', '4250', '4251', '4252', '4253', '4254', '4255', '4256', '4257', '4258', '4259', '4260', '4261', '4262', '4263', '4264', '4265', '4266', '4267', '4268', '4269', '4270', '4271', '4272', '4273', '4274', '4275', '4276', '4277', '4278', '4279', '4280', '4281', '4282', '4283', '4284', '4285', '4286', '4287', '4288', '4289', '4290', '4291', '4292', '4293', '4294', '4295', '4296', '4297', '4298', '4299', '4300', '4301', '4302', '4303', '4304', '4305', '4306', '4307', '4308', '4309', '4310', '4311', '4312', '4313', '4314', '4315', '4316', '4317', '4318', '4319', '4320', '4321', '4322', '4323', '4324', '4325', '4326', '4327', '4328', '4329', '4330', '4331', '4332', '4333', '4334', '4335', '4336', '4337', '4338', '4339', '4340', '4341', '4342', '4343', '4344', '4345', '4346', '4347', '4348', '4349', '4350', '4351', '4352', '4353', '4354', '4355', '4356', '4357', '4358', '4359', '4360', '4361', '4362', '4363', '4364', '4365', '4366', '4367', '4368', '4369', '4370', '4371', '4372', '4373', '4374', '4375', '4376', '4377', '4378', '4379', '4380', '4381', '4382', '4383', '4384', '4385', '4386', '4387', '4388', '4389', '4390', '4391', '4392', '4393', '4394', '4395', '4396', '4397', '4398', '4399', '4400', '4401', '4402', '4403', '4404', '4405', '4406', '4407', '4408', '4409', '4410', '4411', '4412', '4413', '4414', '4415', '4416', '4417', '4418', '4419', '4420', '4421', '4422', '4423', '4424', '4425', '4426', '4427', '4428', '4429', '4430', '4431', '4432', '4433', '4434', '4435', '4436', '4437', '4438', '4439', '4440', '4441', '4442', '4443', '4444', '4445', '4446', '4447', '4448', '4449', '4450', '4451', '4452', '4453', '4454', '4455', '4456', '4457', '4458', '4459', '4460', '4461', '4462', '4463', '4464', '4465', '4466', '4467', '4468', '4469', '4470', '4471', '4472', '4473', '4474', '4475', '4476', '4477', '4478', '4479', '4480', '4481', '4482', '4483', '4484', '4485', '4486', '4487', '4488', '4489', '4490', '4491', '4492', '4493', '4494', '4495', '4496', '4497', '4498', '4499', '4500', '4501', '4502', '4503', '4504', '4505', '4506', '4507', '4508', '4509', '4510', '4511', '4512', '4513', '4514', '4515', '4516', '4517', '4518', '4519', '4520', '4521', '4522', '4523', '4524', '4525', '4526', '4527', '4528', '4529', '4530', '4531', '4532', '4533', '4534', '4535', '4536', '4537', '4538', '4539', '4540', '4541', '4542', '4543', '4544', '4545', '4546', '4547', '4548', '4549', '4550', '4551', '4552', '4553', '4554', '4555', '4556', '4557', '4558', '4559', '4560', '4561', '4562', '4563', '4564', '4565', '4566', '4567', '4568', '4569', '4570', '4571', '4572', '4573', '4574', '4575', '4576', '4577', '4578', '4579', '4580', '4581', '4582', '4583', '4584', '4585', '4586', '4587', '4588', '4589', '4590', '4591', '4592', '4593', '4594', '4595', '4596', '4597', '4598', '4599', '4600', '4601', '4602', '4603', '4604', '4605', '4606', '4607', '4608', '4609', '4610', '4611', '4612', '4613', '4614', '4615', '4616', '4617', '4618', '4619', '4620', '4621', '4622', '4623', '4624', '4625', '4626', '4627', '4628', '4629', '4630', '4631', '4632', '4633', '4634', '4635', '4636', '4637', '4638', '4639', '4640', '4641', '4642', '4643', '4644', '4645', '4646', '4647', '4648', '4649', '4650', '4651', '4652', '4653', '4654', '4655', '4656', '4657', '4658', '4659', '4660', '4661', '4662', '4663', '4664', '4665', '4666', '4667', '4668', '4669', '4670', '4671', '4672', '4673', '4674', '4675', '4676', '4677', '4678', '4679', '4680', '4681', '4682', '4683', '4684', '4685', '4686', '4687', '4688', '4689', '4690', '4691', '4692', '4693', '4694', '4695', '4696', '4697', '4698', '4699', '4700', '4701', '4702', '4703', '4704', '4705', '4706', '4707', '4708', '4709', '4710', '4711', '4712', '4713', '4714', '4715', '4716', '4717', '4718', '4719', '4720', '4721', '4722', '4723', '4724', '4725', '4726', '4727', '4728', '4729', '4730', '4731', '4732', '4733', '4734', '4735', '4736', '4737', '4738', '4739', '4740', '4741', '4742', '4743', '4744', '4745', '4746', '4747', '4748', '4749', '4750', '4751', '4752', '4753', '4754', '4755', '4756', '4757', '4758', '4759', '4760', '4761', '4762', '4763', '4764', '4765', '4766', '4767', '4768', '4769', '4770', '4771', '4772', '4773', '4774', '4775', '4776', '4777', '4778', '4779', '4780', '4781', '4782', '4783', '4784', '4785', '4786', '4787', '4788', '4789', '4790', '4791', '4792', '4793', '4794', '4795', '4796', '4797', '4798', '4799', '4800', '4801', '4802', '4803', '4804', '4805', '4806', '4807', '4808', '4809', '4810', '4811', '4812', '4813', '4814', '4815', '4816', '4817', '4818', '4819', '4820', '4821', '4822', '4823', '4824', '4825', '4826', '4827', '4828', '4829', '4830', '4831', '4832', '4833', '4834', '4835', '4836', '4837', '4838', '4839', '4840', '4841', '4842', '4843', '4844', '4845', '4846', '4847', '4848', '4849', '4850', '4851', '4852', '4853', '4854', '4855', '4856', '4857', '4858', '4859', '4860', '4861', '4862', '4863', '4864', '4865', '4866', '4867', '4868', '4869', '4870', '4871', '4872', '4873', '4874', '4875', '4876', '4877', '4878', '4879', '4880', '4881', '4882', '4883', '4884', '4885', '4886', '4887', '4888', '4889', '4890', '4891', '4892', '4893', '4894', '4895', '4896', '4897', '4898', '4899', '4900', '4901', '4902', '4903', '4904', '4905', '4906', '4907', '4908', '4909', '4910', '4911', '4912', '4913', '4914', '4915', '4916', '4917', '4918', '4919', '4920', '4921', '4922', '4923', '4924', '4925', '4926', '4927', '4928', '4929', '4930', '4931', '4932', '4933', '4934', '4935', '4936', '4937', '4938', '4939', '4940', '4941', '4942', '4943', '4944', '4945', '4946', '4947', '4948', '4949', '4950', '4951', '4952', '4953', '4954', '4955', '4956', '4957', '4958', '4959', '4960', '4961', '4962', '4963', '4964', '4965', '4966', '4967', '4968', '4969', '4970', '4971', '4972', '4973', '4974', '4975', '4976', '4977', '4978', '4979', '4980', '4981', '4982', '4983', '4984', '4985', '4986', '4987', '4988', '4989', '4990', '4991', '4992', '4993', '4994', '4995', '4996', '4997', '4998', '4999', '5000', '5001', '5002', '5003', '5004', '5005', '5006', '5007', '5008', '5009', '5010', '5011', '5012', '5013', '5014', '5015', '5016', '5017', '5018', '5019', '5020', '5021', '5022', '5023', '5024', '5025', '5026', '5027', '5028', '5029', '5030', '5031', '5032', '5033', '5034', '5035', '5036', '5037', '5038', '5039', '5040', '5041', '5042', '5043', '5044', '5045', '5046', '5047', '5048', '5049', '5050', '5051', '5052', '5053', '5054', '5055', '5056', '5057', '5058', '5059', '5060', '5061', '5062', '5063', '5064', '5065', '5066', '5067', '5068', '5069', '5070', '5071', '5072', '5073', '5074', '5075', '5076', '5077', '5078', '5079', '5080', '5081', '5082', '5083', '5084', '5085', '5086', '5087', '5088', '5089', '5090', '5091', '5092', '5093', '5094', '5095', '5096', '5097', '5098', '5099', '5100', '5101', '5102', '5103', '5104', '5105', '5106', '5107', '5108', '5109', '5110', '5111', '5112', '5113', '5114', '5115', '5116', '5117', '5118', '5119', '5120', '5121', '5122', '5123', '5124', '5125', '5126', '5127', '5128', '5129', '5130', '5131', '5132', '5133', '5134', '5135', '5136', '5137', '5138', '5139', '5140', '5141', '5142', '5143', '5144', '5145', '5146', '5147', '5148', '5149', '5150', '5151', '5152', '5153', '5154', '5155', '5156', '5157', '5158', '5159', '5160', '5161', '5162', '5163', '5164', '5165', '5166', '5167', '5168', '5169', '5170', '5171', '5172', '5173', '5174', '5175', '5176', '5177', '5178', '5179', '5180', '5181', '5182', '5183', '5184', '5185', '5186', '5187', '5188', '5189', '5190', '5191', '5192', '5193', '5194', '5195', '5196', '5197', '5198', '5199', '5200', '5201', '5202', '5203', '5204', '5205', '5206', '5207', '5208', '5209', '5210', '5211', '5212', '5213', '5214', '5215', '5216', '5217', '5218', '5219', '5220', '5221', '5222', '5223', '5224', '5225', '5226', '5227', '5228', '5229', '5230', '5231', '5232', '5233', '5234', '5235', '5236', '5237', '5238', '5239', '5240', '5241', '5242', '5243', '5244', '5245', '5246', '5247', '5248', '5249', '5250', '5251', '5252', '5253', '5254', '5255', '5256', '5257', '5258', '5259', '5260', '5261', '5262', '5263', '5264', '5265', '5266', '5267', '5268', '5269', '5270', '5271', '5272', '5273', '5274', '5275', '5276', '5277', '5278', '5279', '5280', '5281', '5282', '5283', '5284', '5285', '5286', '5287', '5288', '5289', '5290', '5291', '5292', '5293', '5294', '5295', '5296', '5297', '5298', '5299', '5300', '5301', '5302', '5303', '5304', '5305', '5306', '5307', '5308', '5309', '5310', '5311', '5312', '5313', '5314', '5315', '5316', '5317', '5318', '5319', '5320', '5321', '5322', '5323', '5324', '5325', '5326', '5327', '5328', '5329', '5330', '5331', '5332', '5333', '5334', '5335', '5336', '5337', '5338', '5339', '5340', '5341', '5342', '5343', '5344', '5345', '5346', '5347', '5348', '5349', '5350', '5351', '5352', '5353', '5354', '5355', '5356', '5357', '5358', '5359', '5360', '5361', '5362', '5363', '5364', '5365', '5366', '5367', '5368', '5369', '5370', '5371', '5372', '5373', '5374', '5375', '5376', '5377', '5378', '5379', '5380', '5381', '5382', '5383', '5384', '5385', '5386', '5387', '5388', '5389', '5390', '5391', '5392', '5393', '5394', '5395', '5396', '5397', '5398', '5399', '5400', '5401', '5402', '5403', '5404', '5405', '5406', '5407', '5408', '5409', '5410', '5411', '5412', '5413', '5414', '5415', '5416', '5417', '5418', '5419', '5420', '5421', '5422', '5423', '5424', '5425', '5426', '5427', '5428', '5429', '5430', '5431', '5432', '5433', '5434', '5435', '5436', '5437', '5438', '5439', '5440', '5441', '5442', '5443', '5444', '5445', '5446', '5447', '5448', '5449', '5450', '5451', '5452', '5453', '5454', '5455', '5456', '5457', '5458', '5459', '5460', '5461', '5462', '5463', '5464', '5465', '5466', '5467', '5468', '5469', '5470', '5471', '5472', '5473', '5474', '5475', '5476', '5477', '5478', '5479', '5480', '5481', '5482', '5483', '5484', '5485', '5486', '5487', '5488', '5489', '5490', '5491', '5492', '5493', '5494', '5495', '5496', '5497', '5498', '5499', '5500', '5501', '5502', '5503', '5504', '5505', '5506', '5507', '5508', '5509', '5510', '5511', '5512', '5513', '5514', '5515', '5516', '5517', '5518', '5519', '5520', '5521', '5522', '5523', '5524', '5525', '5526', '5527', '5528', '5529', '5530', '5531', '5532', '5533', '5534', '5535', '5536', '5537', '5538', '5539', '5540', '5541', '5542', '5543', '5544', '5545', '5546', '5547', '5548', '5549', '5550', '5551', '5552', '5553', '5554', '5555', '5556', '5557', '5558', '5559', '5560', '5561', '5562', '5563', '5564', '5565', '5566', '5567', '5568', '5569', '5570', '5571', '5572', '5573', '5574', '5575', '5576', '5577', '5578', '5579', '5580', '5581', '5582', '5583', '5584', '5585', '5586', '5587', '5588', '5589', '5590', '5591', '5592', '5593', '5594', '5595', '5596', '5597', '5598', '5599', '5600', '5601', '5602', '5603', '5604', '5605', '5606', '5607', '5608', '5609', '5610', '5611', '5612', '5613', '5614', '5615', '5616', '5617', '5618', '5619', '5620', '5621', '5622', '5623', '5624', '5625', '5626', '5627', '5628', '5629', '5630', '5631', '5632', '5633', '5634', '5635', '5636', '5637', '5638', '5639', '5640', '5641', '5642', '5643', '5644', '5645', '5646', '5647', '5648', '5649', '5650', '5651', '5652', '5653', '5654', '5655', '5656', '5657', '5658', '5659', '5660', '5661', '5662', '5663', '5664', '5665', '5666', '5667', '5668', '5669', '5670', '5671', '5672', '5673', '5674', '5675', '5676', '5677', '5678', '5679', '5680', '5681', '5682', '5683', '5684', '5685', '5686', '5687', '5688', '5689', '5690', '5691', '5692', '5693', '5694', '5695', '5696', '5697', '5698', '5699', '5700', '5701', '5702', '5703', '5704', '5705', '5706', '5707', '5708', '5709', '5710', '5711', '5712', '5713', '5714', '5715', '5716', '5717', '5718', '5719', '5720', '5721', '5722', '5723', '5724', '5725', '5726', '5727', '5728', '5729', '5730', '5731', '5732', '5733', '5734', '5735', '5736', '5737', '5738', '5739', '5740', '5741', '5742', '5743', '5744', '5745', '5746', '5747', '5748', '5749', '5750', '5751', '5752', '5753', '5754', '5755', '5756', '5757', '5758', '5759', '5760', '5761', '5762', '5763', '5764', '5765', '5766', '5767', '5768', '5769', '5770', '5771', '5772', '5773', '5774', '5775', '5776', '5777', '5778', '5779', '5780', '5781', '5782', '5783', '5784', '5785', '5786', '5787', '5788', '5789', '5790', '5791', '5792', '5793', '5794', '5795', '5796', '5797', '5798', '5799', '5800', '5801', '5802', '5803', '5804', '5805', '5806', '5807', '5808', '5809', '5810', '5811', '5812', '5813', '5814', '5815', '5816', '5817', '5818', '5819', '5820', '5821', '5822', '5823', '5824', '5825', '5826', '5827', '5828', '5829', '5830', '5831', '5832', '5833', '5834', '5835', '5836', '5837', '5838', '5839', '5840', '5841', '5842', '5843', '5844', '5845', '5846', '5847', '5848', '5849', '5850', '5851', '5852', '5853', '5854', '5855', '5856', '5857', '5858', '5859', '5860', '5861', '5862', '5863', '5864', '5865', '5866', '5867', '5868', '5869', '5870', '5871', '5872', '5873', '5874', '5875', '5876', '5877', '5878', '5879', '5880', '5881', '5882', '5883', '5884', '5885', '5886', '5887', '5888', '5889', '5890', '5891', '5892', '5893', '5894', '5895', '5896', '5897', '5898', '5899', '5900', '5901', '5902', '5903', '5904', '5905', '5906', '5907', '5908', '5909', '5910', '5911', '5912', '5913', '5914', '5915', '5916', '5917', '5918', '5919', '5920', '5921', '5922', '5923', '5924', '5925', '5926', '5927', '5928', '5929', '5930', '5931', '5932', '5933', '5934', '5935', '5936', '5937', '5938', '5939', '5940', '5941', '5942', '5943', '5944', '5945', '5946', '5947', '5948', '5949', '5950', '5951', '5952', '5953', '5954', '5955', '5956', '5957', '5958', '5959', '5960', '5961', '5962', '5963', '5964', '5965', '5966', '5967', '5968', '5969', '5970', '5971', '5972', '5973', '5974', '5975', '5976', '5977', '5978', '5979', '5980', '5981', '5982', '5983', '5984', '5985', '5986', '5987', '5988', '5989', '5990', '5991', '5992', '5993', '5994', '5995', '5996', '5997', '5998', '5999', '6000', '6001', '6002', '6003', '6004', '6005', '6006', '6007', '6008', '6009', '6010', '6011', '6012', '6013', '6014', '6015', '6016', '6017', '6018', '6019', '6020', '6021', '6022', '6023', '6024', '6025', '6026', '6027', '6028', '6029', '6030', '6031', '6032', '6033', '6034', '6035', '6036', '6037', '6038', '6039', '6040', '6041', '6042', '6043', '6044', '6045', '6046', '6047', '6048', '6049', '6050', '6051', '6052', '6053', '6054', '6055', '6056', '6057', '6058', '6059', '6060', '6061', '6062', '6063', '6064', '6065', '6066', '6067', '6068', '6069', '6070', '6071', '6072', '6073', '6074', '6075', '6076', '6077', '6078', '6079', '6080', '6081', '6082', '6083', '6084', '6085', '6086', '6087', '6088', '6089', '6090', '6091', '6092', '6093', '6094', '6095', '6096', '6097', '6098', '6099', '6100', '6101', '6102', '6103', '6104', '6105', '6106', '6107', '6108', '6109', '6110', '6111', '6112', '6113', '6114', '6115', '6116', '6117', '6118', '6119', '6120', '6121', '6122', '6123', '6124', '6125', '6126', '6127', '6128', '6129', '6130', '6131', '6132', '6133', '6134', '6135', '6136', '6137', '6138', '6139', '6140', '6141', '6142', '6143', '6144', '6145', '6146', '6147', '6148', '6149', '6150', '6151', '6152', '6153', '6154', '6155', '6156', '6157', '6158', '6159', '6160', '6161', '6162', '6163', '6164', '6165', '6166', '6167', '6168', '6169', '6170', '6171', '6172', '6173', '6174', '6175', '6176', '6177', '6178', '6179', '6180', '6181', '6182', '6183', '6184', '6185', '6186', '6187', '6188', '6189', '6190', '6191', '6192', '6193', '6194', '6195', '6196', '6197', '6198', '6199', '6200', '6201', '6202', '6203', '6204', '6205', '6206', '6207', '6208', '6209', '6210', '6211', '6212', '6213', '6214', '6215', '6216', '6217', '6218', '6219', '6220', '6221', '6222', '6223', '6224', '6225', '6226', '6227', '6228', '6229', '6230', '6231', '6232', '6233', '6234', '6235', '6236', '6237', '6238', '6239', '6240', '6241', '6242', '6243', '6244', '6245', '6246', '6247', '6248', '6249', '6250', '6251', '6252', '6253', '6254', '6255', '6256', '6257', '6258', '6259', '6260', '6261', '6262', '6263', '6264', '6265', '6266', '6267', '6268', '6269', '6270', '6271', '6272', '6273', '6274', '6275', '6276', '6277', '6278', '6279', '6280', '6281', '6282', '6283', '6284', '6285', '6286', '6287', '6288', '6289', '6290', '6291', '6292', '6293', '6294', '6295', '6296', '6297', '6298', '6299', '6300', '6301', '6302', '6303', '6304', '6305', '6306', '6307', '6308', '6309', '6310', '6311', '6312', '6313', '6314', '6315', '6316', '6317', '6318', '6319', '6320', '6321', '6322', '6323', '6324', '6325', '6326', '6327', '6328', '6329', '6330', '6331', '6332', '6333', '6334', '6335', '6336', '6337', '6338', '6339', '6340', '6341', '6342', '6343', '6344', '6345', '6346', '6347', '6348', '6349', '6350', '6351', '6352', '6353', '6354', '6355', '6356', '6357', '6358', '6359', '6360', '6361', '6362', '6363', '6364', '6365', '6366', '6367', '6368', '6369', '6370', '6371', '6372', '6373', '6374', '6375', '6376', '6377', '6378', '6379', '6380', '6381', '6382', '6383', '6384', '6385', '6386', '6387', '6388', '6389', '6390', '6391', '6392', '6393', '6394', '6395', '6396', '6397', '6398', '6399', '6400', '6401', '6402', '6403', '6404', '6405', '6406', '6407', '6408', '6409', '6410', '6411', '6412', '6413', '6414', '6415', '6416', '6417', '6418', '6419', '6420', '6421', '6422', '6423', '6424', '6425', '6426', '6427', '6428', '6429', '6430', '6431', '6432', '6433', '6434', '6435', '6436', '6437', '6438', '6439', '6440', '6441', '6442', '6443', '6444', '6445', '6446', '6447', '6448', '6449', '6450', '6451', '6452', '6453', '6454', '6455', '6456', '6457', '6458', '6459', '6460', '6461', '6462', '6463', '6464', '6465', '6466', '6467', '6468', '6469', '6470', '6471', '6472', '6473', '6474', '6475', '6476', '6477', '6478', '6479', '6480', '6481', '6482', '6483', '6484', '6485', '6486', '6487', '6488', '6489', '6490', '6491', '6492', '6493', '6494', '6495', '6496', '6497', '6498', '6499', '6500', '6501', '6502', '6503', '6504', '6505', '6506', '6507', '6508', '6509', '6510', '6511', '6512', '6513', '6514', '6515', '6516', '6517', '6518', '6519', '6520', '6521', '6522', '6523', '6524', '6525', '6526', '6527', '6528', '6529', '6530', '6531', '6532', '6533', '6534', '6535', '6536', '6537', '6538', '6539', '6540', '6541', '6542', '6543', '6544', '6545', '6546', '6547', '6548', '6549', '6550', '6551', '6552', '6553', '6554', '6555', '6556', '6557', '6558', '6559', '6560', '6561', '6562', '6563', '6564', '6565', '6566', '6567', '6568', '6569', '6570', '6571', '6572', '6573', '6574', '6575', '6576', '6577', '6578', '6579', '6580', '6581', '6582', '6583', '6584', '6585', '6586', '6587', '6588', '6589', '6590', '6591', '6592', '6593', '6594', '6595', '6596', '6597', '6598', '6599', '6600', '6601', '6602', '6603', '6604', '6605', '6606', '6607', '6608', '6609', '6610', '6611', '6612', '6613', '6614', '6615', '6616', '6617', '6618', '6619', '6620', '6621', '6622', '6623', '6624', '6625', '6626', '6627', '6628', '6629', '6630', '6631', '6632', '6633', '6634', '6635', '6636', '6637', '6638', '6639', '6640', '6641', '6642', '6643', '6644', '6645', '6646', '6647', '6648', '6649', '6650', '6651', '6652', '6653', '6654', '6655', '6656', '6657', '6658', '6659', '6660', '6661', '6662', '6663', '6664', '6665', '6666', '6667', '6668', '6669', '6670', '6671', '6672', '6673', '6674', '6675', '6676', '6677', '6678', '6679', '6680', '6681', '6682', '6683', '6684', '6685', '6686', '6687', '6688', '6689', '6690', '6691', '6692', '6693', '6694', '6695', '6696', '6697', '6698', '6699', '6700', '6701', '6702', '6703', '6704', '6705', '6706', '6707', '6708', '6709', '6710', '6711', '6712', '6713', '6714', '6715', '6716', '6717', '6718', '6719', '6720', '6721', '6722', '6723', '6724', '6725', '6726', '6727', '6728', '6729', '6730', '6731', '6732', '6733', '6734', '6735', '6736', '6737', '6738', '6739', '6740', '6741', '6742', '6743', '6744', '6745', '6746', '6747', '6748', '6749', '6750', '6751', '6752', '6753', '6754', '6755', '6756', '6757', '6758', '6759', '6760', '6761', '6762', '6763', '6764', '6765', '6766', '6767', '6768', '6769', '6770', '6771', '6772', '6773', '6774', '6775', '6776', '6777', '6778', '6779', '6780', '6781', '6782', '6783', '6784', '6785', '6786', '6787', '6788', '6789', '6790', '6791', '6792', '6793', '6794', '6795', '6796', '6797', '6798', '6799', '6800', '6801', '6802', '6803', '6804', '6805', '6806', '6807', '6808', '6809', '6810', '6811', '6812', '6813', '6814', '6815', '6816', '6817', '6818', '6819', '6820', '6821', '6822', '6823', '6824', '6825', '6826', '6827', '6828', '6829', '6830', '6831', '6832', '6833', '6834', '6835', '6836', '6837', '6838', '6839', '6840', '6841', '6842', '6843', '6844', '6845', '6846', '6847', '6848', '6849', '6850', '6851', '6852', '6853', '6854', '6855', '6856', '6857', '6858', '6859', '6860', '6861', '6862', '6863', '6864', '6865', '6866', '6867', '6868', '6869', '6870', '6871', '6872', '6873', '6874', '6875', '6876', '6877', '6878', '6879', '6880', '6881', '6882', '6883', '6884', '6885', '6886', '6887', '6888', '6889', '6890', '6891', '6892', '6893', '6894', '6895', '6896', '6897', '6898', '6899', '6900', '6901', '6902', '6903', '6904', '6905', '6906', '6907', '6908', '6909', '6910', '6911', '6912', '6913', '6914', '6915', '6916', '6917', '6918', '6919', '6920', '6921', '6922', '6923', '6924', '6925', '6926', '6927', '6928', '6929', '6930', '6931', '6932', '6933', '6934', '6935', '6936', '6937', '6938', '6939', '6940', '6941', '6942', '6943', '6944', '6945', '6946', '6947', '6948', '6949', '6950', '6951', '6952', '6953', '6954', '6955', '6956', '6957', '6958', '6959', '6960', '6961', '6962', '6963', '6964', '6965', '6966', '6967', '6968', '6969', '6970', '6971', '6972', '6973', '6974', '6975', '6976', '6977', '6978', '6979', '6980', '6981', '6982', '6983', '6984', '6985', '6986', '6987', '6988', '6989', '6990', '6991', '6992', '6993', '6994', '6995', '6996', '6997', '6998', '6999', '7000', '7001', '7002', '7003', '7004', '7005', '7006', '7007', '7008', '7009', '7010', '7011', '7012', '7013', '7014', '7015', '7016', '7017', '7018', '7019', '7020', '7021', '7022', '7023', '7024', '7025', '7026', '7027', '7028', '7029', '7030', '7031', '7032', '7033', '7034', '7035', '7036', '7037', '7038', '7039', '7040', '7041', '7042', '7043', '7044', '7045', '7046', '7047', '7048', '7049', '7050', '7051', '7052', '7053', '7054', '7055', '7056', '7057', '7058', '7059', '7060', '7061', '7062', '7063', '7064', '7065', '7066', '7067', '7068', '7069', '7070', '7071', '7072', '7073', '7074', '7075', '7076', '7077', '7078', '7079', '7080', '7081', '7082', '7083', '7084', '7085', '7086', '7087', '7088', '7089', '7090', '7091', '7092', '7093', '7094', '7095', '7096', '7097', '7098', '7099', '7100', '7101', '7102', '7103', '7104', '7105', '7106', '7107', '7108', '7109', '7110', '7111', '7112', '7113', '7114', '7115', '7116', '7117', '7118', '7119', '7120', '7121', '7122', '7123', '7124', '7125', '7126', '7127', '7128', '7129', '7130', '7131', '7132', '7133', '7134', '7135', '7136', '7137', '7138', '7139', '7140', '7141', '7142', '7143', '7144', '7145', '7146', '7147', '7148', '7149', '7150', '7151', '7152', '7153', '7154', '7155', '7156', '7157', '7158', '7159', '7160', '7161', '7162', '7163', '7164', '7165', '7166', '7167', '7168', '7169', '7170', '7171', '7172', '7173', '7174', '7175', '7176', '7177', '7178', '7179', '7180', '7181', '7182', '7183', '7184', '7185', '7186', '7187', '7188', '7189', '7190', '7191', '7192', '7193', '7194', '7195', '7196', '7197', '7198', '7199', '7200', '7201', '7202', '7203', '7204', '7205', '7206', '7207', '7208', '7209', '7210', '7211', '7212', '7213', '7214', '7215', '7216', '7217', '7218', '7219', '7220', '7221', '7222', '7223', '7224', '7225', '7226', '7227', '7228', '7229', '7230', '7231', '7232', '7233', '7234', '7235', '7236', '7237', '7238', '7239', '7240', '7241', '7242', '7243', '7244', '7245', '7246', '7247', '7248', '7249', '7250', '7251', '7252', '7253', '7254', '7255', '7256', '7257', '7258', '7259', '7260', '7261', '7262', '7263', '7264', '7265', '7266', '7267', '7268', '7269', '7270', '7271', '7272', '7273', '7274', '7275', '7276', '7277', '7278', '7279', '7280', '7281', '7282', '7283', '7284', '7285', '7286', '7287', '7288', '7289', '7290', '7291', '7292', '7293', '7294', '7295', '7296', '7297', '7298', '7299', '7300', '7301', '7302', '7303', '7304', '7305', '7306', '7307', '7308', '7309', '7310', '7311', '7312', '7313', '7314', '7315', '7316', '7317', '7318', '7319', '7320', '7321', '7322', '7323', '7324', '7325', '7326', '7327', '7328', '7329', '7330', '7331', '7332', '7333', '7334', '7335', '7336', '7337', '7338', '7339', '7340', '7341', '7342', '7343', '7344', '7345', '7346', '7347', '7348', '7349', '7350', '7351', '7352', '7353', '7354', '7355', '7356', '7357', '7358', '7359', '7360', '7361', '7362', '7363', '7364', '7365', '7366', '7367', '7368', '7369', '7370', '7371', '7372', '7373', '7374', '7375', '7376', '7377', '7378', '7379', '7380', '7381', '7382', '7383', '7384', '7385', '7386', '7387', '7388', '7389', '7390', '7391', '7392', '7393', '7394', '7395', '7396', '7397', '7398', '7399', '7400', '7401', '7402', '7403', '7404', '7405', '7406', '7407', '7408', '7409', '7410', '7411', '7412', '7413', '7414', '7415', '7416', '7417', '7418', '7419', '7420', '7421', '7422', '7423', '7424', '7425', '7426', '7427', '7428', '7429', '7430', '7431', '7432', '7433', '7434', '7435', '7436', '7437', '7438', '7439', '7440', '7441', '7442', '7443', '7444', '7445', '7446', '7447', '7448', '7449', '7450', '7451', '7452', '7453', '7454', '7455', '7456', '7457', '7458', '7459', '7460', '7461', '7462', '7463', '7464', '7465', '7466', '7467', '7468', '7469', '7470', '7471', '7472', '7473', '7474', '7475', '7476', '7477', '7478', '7479', '7480', '7481', '7482', '7483', '7484', '7485', '7486', '7487', '7488', '7489', '7490', '7491', '7492', '7493', '7494', '7495', '7496', '7497', '7498', '7499', '7500', '7501', '7502', '7503', '7504', '7505', '7506', '7507', '7508', '7509', '7510', '7511', '7512', '7513', '7514', '7515', '7516', '7517', '7518', '7519', '7520', '7521', '7522', '7523', '7524', '7525', '7526', '7527', '7528', '7529', '7530', '7531', '7532', '7533', '7534', '7535', '7536', '7537', '7538', '7539', '7540', '7541', '7542', '7543', '7544', '7545', '7546', '7547', '7548', '7549', '7550', '7551', '7552', '7553', '7554', '7555', '7556', '7557', '7558', '7559', '7560', '7561', '7562', '7563', '7564', '7565', '7566', '7567', '7568', '7569', '7570', '7571', '7572', '7573', '7574', '7575', '7576', '7577', '7578', '7579', '7580', '7581', '7582', '7583', '7584', '7585', '7586', '7587', '7588', '7589', '7590', '7591', '7592', '7593', '7594', '7595', '7596', '7597', '7598', '7599', '7600', '7601', '7602', '7603', '7604', '7605', '7606', '7607', '7608', '7609', '7610', '7611', '7612', '7613', '7614', '7615', '7616', '7617', '7618', '7619', '7620', '7621', '7622', '7623', '7624', '7625', '7626', '7627', '7628', '7629', '7630', '7631', '7632', '7633', '7634', '7635', '7636', '7637', '7638', '7639', '7640', '7641', '7642', '7643', '7644', '7645', '7646', '7647', '7648', '7649', '7650', '7651', '7652', '7653', '7654', '7655', '7656', '7657', '7658', '7659', '7660', '7661', '7662', '7663', '7664', '7665', '7666', '7667', '7668', '7669', '7670', '7671', '7672', '7673', '7674', '7675', '7676', '7677', '7678', '7679', '7680', '7681', '7682', '7683', '7684', '7685', '7686', '7687', '7688', '7689', '7690', '7691', '7692', '7693', '7694', '7695', '7696', '7697', '7698', '7699', '7700', '7701', '7702', '7703', '7704', '7705', '7706', '7707', '7708', '7709', '7710', '7711', '7712', '7713', '7714', '7715', '7716', '7717', '7718', '7719', '7720', '7721', '7722', '7723', '7724', '7725', '7726', '7727', '7728', '7729', '7730', '7731', '7732', '7733', '7734', '7735', '7736', '7737', '7738', '7739', '7740', '7741', '7742', '7743', '7744', '7745', '7746', '7747', '7748', '7749', '7750', '7751', '7752', '7753', '7754', '7755', '7756', '7757', '7758', '7759', '7760', '7761', '7762', '7763', '7764', '7765', '7766', '7767', '7768', '7769', '7770', '7771', '7772', '7773', '7774', '7775', '7776', '7777', '7778', '7779', '7780', '7781', '7782', '7783', '7784', '7785', '7786', '7787', '7788', '7789', '7790', '7791', '7792', '7793', '7794', '7795', '7796', '7797', '7798', '7799', '7800', '7801', '7802', '7803', '7804', '7805', '7806', '7807', '7808', '7809', '7810', '7811', '7812', '7813', '7814', '7815', '7816', '7817', '7818', '7819', '7820', '7821', '7822', '7823', '7824', '7825', '7826', '7827', '7828', '7829', '7830', '7831', '7832', '7833', '7834', '7835', '7836', '7837', '7838', '7839', '7840', '7841', '7842', '7843', '7844', '7845', '7846', '7847', '7848', '7849', '7850', '7851', '7852', '7853', '7854', '7855', '7856', '7857', '7858', '7859', '7860', '7861', '7862', '7863', '7864', '7865', '7866', '7867', '7868', '7869', '7870', '7871', '7872', '7873', '7874', '7875', '7876', '7877', '7878', '7879', '7880', '7881', '7882', '7883', '7884', '7885', '7886', '7887', '7888', '7889', '7890', '7891', '7892', '7893', '7894', '7895', '7896', '7897', '7898', '7899', '7900', '7901', '7902', '7903', '7904', '7905', '7906', '7907', '7908', '7909', '7910', '7911', '7912', '7913', '7914', '7915', '7916', '7917', '7918', '7919', '7920', '7921', '7922', '7923', '7924', '7925', '7926', '7927', '7928', '7929', '7930', '7931', '7932', '7933', '7934', '7935', '7936', '7937', '7938', '7939', '7940', '7941', '7942', '7943', '7944', '7945', '7946', '7947', '7948', '7949', '7950', '7951', '7952', '7953', '7954', '7955', '7956', '7957', '7958', '7959', '7960', '7961', '7962', '7963', '7964', '7965', '7966', '7967', '7968', '7969', '7970', '7971', '7972', '7973', '7974', '7975', '7976', '7977', '7978', '7979', '7980', '7981', '7982', '7983', '7984', '7985', '7986', '7987', '7988', '7989', '7990', '7991', '7992', '7993', '7994', '7995', '7996', '7997', '7998', '7999', '8000', '8001', '8002', '8003', '8004', '8005', '8006', '8007', '8008', '8009', '8010', '8011', '8012', '8013', '8014', '8015', '8016', '8017', '8018', '8019', '8020', '8021', '8022', '8023', '8024', '8025', '8026', '8027', '8028', '8029', '8030', '8031', '8032', '8033', '8034', '8035', '8036', '8037', '8038', '8039', '8040', '8041', '8042', '8043', '8044', '8045', '8046', '8047', '8048', '8049', '8050', '8051', '8052', '8053', '8054', '8055', '8056', '8057', '8058', '8059', '8060', '8061', '8062', '8063', '8064', '8065', '8066', '8067', '8068', '8069', '8070', '8071', '8072', '8073', '8074', '8075', '8076', '8077', '8078', '8079', '8080', '8081', '8082', '8083', '8084', '8085', '8086', '8087', '8088', '8089', '8090', '8091', '8092', '8093', '8094', '8095', '8096', '8097', '8098', '8099', '8100', '8101', '8102', '8103', '8104', '8105', '8106', '8107', '8108', '8109', '8110', '8111', '8112', '8113', '8114', '8115', '8116', '8117', '8118', '8119', '8120', '8121', '8122', '8123', '8124', '8125', '8126', '8127', '8128', '8129', '8130', '8131', '8132', '8133', '8134', '8135', '8136', '8137', '8138', '8139', '8140', '8141', '8142', '8143', '8144', '8145', '8146', '8147', '8148', '8149', '8150', '8151', '8152', '8153', '8154', '8155', '8156', '8157', '8158', '8159', '8160', '8161', '8162', '8163', '8164', '8165', '8166', '8167', '8168', '8169', '8170', '8171', '8172', '8173', '8174', '8175', '8176', '8177', '8178', '8179', '8180', '8181', '8182', '8183', '8184', '8185', '8186', '8187', '8188', '8189', '8190', '8191', '8192', '8193', '8194', '8195', '8196', '8197', '8198', '8199', '8200', '8201', '8202', '8203', '8204', '8205', '8206', '8207', '8208', '8209', '8210', '8211', '8212', '8213', '8214', '8215', '8216', '8217', '8218', '8219', '8220', '8221', '8222', '8223', '8224', '8225', '8226', '8227', '8228', '8229', '8230', '8231', '8232', '8233', '8234', '8235', '8236', '8237', '8238', '8239', '8240', '8241', '8242', '8243', '8244', '8245', '8246', '8247', '8248', '8249', '8250', '8251', '8252', '8253', '8254', '8255', '8256', '8257', '8258', '8259', '8260', '8261', '8262', '8263', '8264', '8265', '8266', '8267', '8268', '8269', '8270', '8271', '8272', '8273', '8274', '8275', '8276', '8277', '8278', '8279', '8280', '8281', '8282', '8283', '8284', '8285', '8286', '8287', '8288', '8289', '8290', '8291', '8292', '8293', '8294', '8295', '8296', '8297', '8298', '8299', '8300', '8301', '8302', '8303', '8304', '8305', '8306', '8307', '8308', '8309', '8310', '8311', '8312', '8313', '8314', '8315', '8316', '8317', '8318', '8319', '8320', '8321', '8322', '8323', '8324', '8325', '8326', '8327', '8328', '8329', '8330', '8331', '8332', '8333', '8334', '8335', '8336', '8337', '8338', '8339', '8340', '8341', '8342', '8343', '8344', '8345', '8346', '8347', '8348', '8349', '8350', '8351', '8352', '8353', '8354', '8355', '8356', '8357', '8358', '8359', '8360', '8361', '8362', '8363', '8364', '8365', '8366', '8367', '8368', '8369', '8370', '8371', '8372', '8373', '8374', '8375', '8376', '8377', '8378', '8379', '8380', '8381', '8382', '8383', '8384', '8385', '8386', '8387', '8388', '8389', '8390', '8391', '8392', '8393', '8394', '8395', '8396', '8397', '8398', '8399', '8400', '8401', '8402', '8403', '8404', '8405', '8406', '8407', '8408', '8409', '8410', '8411', '8412', '8413', '8414', '8415', '8416', '8417', '8418', '8419', '8420', '8421', '8422', '8423', '8424', '8425', '8426', '8427', '8428', '8429', '8430', '8431', '8432', '8433', '8434', '8435', '8436', '8437', '8438', '8439', '8440', '8441', '8442', '8443', '8444', '8445', '8446', '8447', '8448', '8449', '8450', '8451', '8452', '8453', '8454', '8455', '8456', '8457', '8458', '8459', '8460', '8461', '8462', '8463', '8464', '8465', '8466', '8467', '8468', '8469', '8470', '8471', '8472', '8473', '8474', '8475', '8476', '8477', '8478', '8479', '8480', '8481', '8482', '8483', '8484', '8485', '8486', '8487', '8488', '8489', '8490', '8491', '8492', '8493', '8494', '8495', '8496', '8497', '8498', '8499', '8500', '8501', '8502', '8503', '8504', '8505', '8506', '8507', '8508', '8509', '8510', '8511', '8512', '8513', '8514', '8515', '8516', '8517', '8518', '8519', '8520', '8521', '8522', '8523', '8524', '8525', '8526', '8527', '8528', '8529', '8530', '8531', '8532', '8533', '8534', '8535', '8536', '8537', '8538', '8539', '8540', '8541', '8542', '8543', '8544', '8545', '8546', '8547', '8548', '8549', '8550', '8551', '8552', '8553', '8554', '8555', '8556', '8557', '8558', '8559', '8560', '8561', '8562', '8563', '8564', '8565', '8566', '8567', '8568', '8569', '8570', '8571', '8572', '8573', '8574', '8575', '8576', '8577', '8578', '8579', '8580', '8581', '8582', '8583', '8584', '8585', '8586', '8587', '8588', '8589', '8590', '8591', '8592', '8593', '8594', '8595', '8596', '8597', '8598', '8599', '8600', '8601', '8602', '8603', '8604', '8605', '8606', '8607', '8608', '8609', '8610', '8611', '8612', '8613', '8614', '8615', '8616', '8617', '8618', '8619', '8620', '8621', '8622', '8623', '8624', '8625', '8626', '8627', '8628', '8629', '8630', '8631', '8632', '8633', '8634', '8635', '8636', '8637', '8638', '8639', '8640', '8641', '8642', '8643', '8644', '8645', '8646', '8647', '8648', '8649', '8650', '8651', '8652', '8653', '8654', '8655', '8656', '8657', '8658', '8659', '8660', '8661', '8662', '8663', '8664', '8665', '8666', '8667', '8668', '8669', '8670', '8671', '8672', '8673', '8674', '8675', '8676', '8677', '8678', '8679', '8680', '8681', '8682', '8683', '8684', '8685', '8686', '8687', '8688', '8689', '8690', '8691', '8692', '8693', '8694', '8695', '8696', '8697', '8698', '8699', '8700', '8701', '8702', '8703', '8704', '8705', '8706', '8707', '8708', '8709', '8710', '8711', '8712', '8713', '8714', '8715', '8716', '8717', '8718', '8719', '8720', '8721', '8722', '8723', '8724', '8725', '8726', '8727', '8728', '8729', '8730', '8731', '8732', '8733', '8734', '8735', '8736', '8737', '8738', '8739', '8740', '8741', '8742', '8743', '8744', '8745', '8746', '8747', '8748', '8749', '8750', '8751', '8752', '8753', '8754', '8755', '8756', '8757', '8758', '8759', '8760', '8761', '8762', '8763', '8764', '8765', '8766', '8767', '8768', '8769', '8770', '8771', '8772', '8773', '8774', '8775', '8776', '8777', '8778', '8779', '8780', '8781', '8782', '8783', '8784', '8785', '8786', '8787', '8788', '8789', '8790', '8791', '8792', '8793', '8794', '8795', '8796', '8797', '8798', '8799', '8800', '8801', '8802', '8803', '8804', '8805', '8806', '8807', '8808', '8809', '8810', '8811', '8812', '8813', '8814', '8815', '8816', '8817', '8818', '8819', '8820', '8821', '8822', '8823', '8824', '8825', '8826', '8827', '8828', '8829', '8830', '8831', '8832', '8833', '8834', '8835', '8836', '8837', '8838', '8839', '8840', '8841', '8842', '8843', '8844', '8845', '8846', '8847', '8848', '8849', '8850', '8851', '8852', '8853', '8854', '8855', '8856', '8857', '8858', '8859', '8860', '8861', '8862', '8863', '8864', '8865', '8866', '8867', '8868', '8869', '8870', '8871', '8872', '8873', '8874', '8875', '8876', '8877', '8878', '8879', '8880', '8881', '8882', '8883', '8884', '8885', '8886', '8887', '8888', '8889', '8890', '8891', '8892', '8893', '8894', '8895', '8896', '8897', '8898', '8899', '8900', '8901', '8902', '8903', '8904', '8905', '8906', '8907', '8908', '8909', '8910', '8911', '8912', '8913', '8914', '8915', '8916', '8917', '8918', '8919', '8920', '8921', '8922', '8923', '8924', '8925', '8926', '8927', '8928', '8929', '8930', '8931', '8932', '8933', '8934', '8935', '8936', '8937', '8938', '8939', '8940', '8941', '8942', '8943', '8944', '8945', '8946', '8947', '8948', '8949', '8950', '8951', '8952', '8953', '8954', '8955', '8956', '8957', '8958', '8959', '8960', '8961', '8962', '8963', '8964', '8965', '8966', '8967', '8968', '8969', '8970', '8971', '8972', '8973', '8974', '8975', '8976', '8977', '8978', '8979', '8980', '8981', '8982', '8983', '8984', '8985', '8986', '8987', '8988', '8989', '8990', '8991', '8992', '8993', '8994', '8995', '8996', '8997', '8998', '8999', '9000', '9001', '9002', '9003', '9004', '9005', '9006', '9007', '9008', '9009', '9010', '9011', '9012', '9013', '9014', '9015', '9016', '9017', '9018', '9019', '9020', '9021', '9022', '9023', '9024', '9025', '9026', '9027', '9028', '9029', '9030', '9031', '9032', '9033', '9034', '9035', '9036', '9037', '9038', '9039', '9040', '9041', '9042', '9043', '9044', '9045', '9046', '9047', '9048', '9049', '9050', '9051', '9052', '9053', '9054', '9055', '9056', '9057', '9058', '9059', '9060', '9061', '9062', '9063', '9064', '9065', '9066', '9067', '9068', '9069', '9070', '9071', '9072', '9073', '9074', '9075', '9076', '9077', '9078', '9079', '9080', '9081', '9082', '9083', '9084', '9085', '9086', '9087', '9088', '9089', '9090', '9091', '9092', '9093', '9094', '9095', '9096', '9097', '9098', '9099', '9100', '9101', '9102', '9103', '9104', '9105', '9106', '9107', '9108', '9109', '9110', '9111', '9112', '9113', '9114', '9115', '9116', '9117', '9118', '9119', '9120', '9121', '9122', '9123', '9124', '9125', '9126', '9127', '9128', '9129', '9130', '9131', '9132', '9133', '9134', '9135', '9136', '9137', '9138', '9139', '9140', '9141', '9142', '9143', '9144', '9145', '9146', '9147', '9148', '9149', '9150', '9151', '9152', '9153', '9154', '9155', '9156', '9157', '9158', '9159', '9160', '9161', '9162', '9163', '9164', '9165', '9166', '9167', '9168', '9169', '9170', '9171', '9172', '9173', '9174', '9175', '9176', '9177', '9178', '9179', '9180', '9181', '9182', '9183', '9184', '9185', '9186', '9187', '9188', '9189', '9190', '9191', '9192', '9193', '9194', '9195', '9196', '9197', '9198', '9199', '9200', '9201', '9202', '9203', '9204', '9205', '9206', '9207', '9208', '9209', '9210', '9211', '9212', '9213', '9214', '9215', '9216', '9217', '9218', '9219', '9220', '9221', '9222', '9223', '9224', '9225', '9226', '9227', '9228', '9229', '9230', '9231', '9232', '9233', '9234', '9235', '9236', '9237', '9238', '9239', '9240', '9241', '9242', '9243', '9244', '9245', '9246', '9247', '9248', '9249', '9250', '9251', '9252', '9253', '9254', '9255', '9256', '9257', '9258', '9259', '9260', '9261', '9262', '9263', '9264', '9265', '9266', '9267', '9268', '9269', '9270', '9271', '9272', '9273', '9274', '9275', '9276', '9277', '9278', '9279', '9280', '9281', '9282', '9283', '9284', '9285', '9286', '9287', '9288', '9289', '9290', '9291', '9292', '9293', '9294', '9295', '9296', '9297', '9298', '9299', '9300', '9301', '9302', '9303', '9304', '9305', '9306', '9307', '9308', '9309', '9310', '9311', '9312', '9313', '9314', '9315', '9316', '9317', '9318', '9319', '9320', '9321', '9322', '9323', '9324', '9325', '9326', '9327', '9328', '9329', '9330', '9331', '9332', '9333', '9334', '9335', '9336', '9337', '9338', '9339', '9340', '9341', '9342', '9343', '9344', '9345', '9346', '9347', '9348', '9349', '9350', '9351', '9352', '9353', '9354', '9355', '9356', '9357', '9358', '9359', '9360', '9361', '9362', '9363', '9364', '9365', '9366', '9367', '9368', '9369', '9370', '9371', '9372', '9373', '9374', '9375', '9376', '9377', '9378', '9379', '9380', '9381', '9382', '9383', '9384', '9385', '9386', '9387', '9388', '9389', '9390', '9391', '9392', '9393', '9394', '9395', '9396', '9397', '9398', '9399', '9400', '9401', '9402', '9403', '9404', '9405', '9406', '9407', '9408', '9409', '9410', '9411', '9412', '9413', '9414', '9415', '9416', '9417', '9418', '9419', '9420', '9421', '9422', '9423', '9424', '9425', '9426', '9427', '9428', '9429', '9430', '9431', '9432', '9433', '9434', '9435', '9436', '9437', '9438', '9439', '9440', '9441', '9442', '9443', '9444', '9445', '9446', '9447', '9448', '9449', '9450', '9451', '9452', '9453', '9454', '9455', '9456', '9457', '9458', '9459', '9460', '9461', '9462', '9463', '9464', '9465', '9466', '9467', '9468', '9469', '9470', '9471', '9472', '9473', '9474', '9475', '9476', '9477', '9478', '9479', '9480', '9481', '9482', '9483', '9484', '9485', '9486', '9487', '9488', '9489', '9490', '9491', '9492', '9493', '9494', '9495', '9496', '9497', '9498', '9499', '9500', '9501', '9502', '9503', '9504', '9505', '9506', '9507', '9508', '9509', '9510', '9511', '9512', '9513', '9514', '9515', '9516', '9517', '9518', '9519', '9520', '9521', '9522', '9523', '9524', '9525', '9526', '9527', '9528', '9529', '9530', '9531', '9532', '9533', '9534', '9535', '9536', '9537', '9538', '9539', '9540', '9541', '9542', '9543', '9544', '9545', '9546', '9547', '9548', '9549', '9550', '9551', '9552', '9553', '9554', '9555', '9556', '9557', '9558', '9559', '9560', '9561', '9562', '9563', '9564', '9565', '9566', '9567', '9568', '9569', '9570', '9571', '9572', '9573', '9574', '9575', '9576', '9577', '9578', '9579', '9580', '9581', '9582', '9583', '9584', '9585', '9586', '9587', '9588', '9589', '9590', '9591', '9592', '9593', '9594', '9595', '9596', '9597', '9598', '9599', '9600', '9601', '9602', '9603', '9604', '9605', '9606', '9607', '9608', '9609', '9610', '9611', '9612', '9613', '9614', '9615', '9616', '9617', '9618', '9619', '9620', '9621', '9622', '9623', '9624', '9625', '9626', '9627', '9628', '9629', '9630', '9631', '9632', '9633', '9634', '9635', '9636', '9637', '9638', '9639', '9640', '9641', '9642', '9643', '9644', '9645', '9646', '9647', '9648', '9649', '9650', '9651', '9652', '9653', '9654', '9655', '9656', '9657', '9658', '9659', '9660', '9661', '9662', '9663', '9664', '9665', '9666', '9667', '9668', '9669', '9670', '9671', '9672', '9673', '9674', '9675', '9676', '9677', '9678', '9679', '9680', '9681', '9682', '9683', '9684', '9685', '9686', '9687', '9688', '9689', '9690', '9691', '9692', '9693', '9694', '9695', '9696', '9697', '9698', '9699', '9700', '9701', '9702', '9703', '9704', '9705', '9706', '9707', '9708', '9709', '9710', '9711', '9712', '9713', '9714', '9715', '9716', '9717', '9718', '9719', '9720', '9721', '9722', '9723', '9724', '9725', '9726', '9727', '9728', '9729', '9730', '9731', '9732', '9733', '9734', '9735', '9736', '9737', '9738', '9739', '9740', '9741', '9742', '9743', '9744', '9745', '9746', '9747', '9748', '9749', '9750', '9751', '9752', '9753', '9754', '9755', '9756', '9757', '9758', '9759', '9760', '9761', '9762', '9763', '9764', '9765', '9766', '9767', '9768', '9769', '9770', '9771', '9772', '9773', '9774', '9775', '9776', '9777', '9778', '9779', '9780', '9781', '9782', '9783', '9784', '9785', '9786', '9787', '9788', '9789', '9790', '9791', '9792', '9793', '9794', '9795', '9796', '9797', '9798', '9799', '9800', '9801', '9802', '9803', '9804', '9805', '9806', '9807', '9808', '9809', '9810', '9811', '9812', '9813', '9814', '9815', '9816', '9817', '9818', '9819', '9820', '9821', '9822', '9823', '9824', '9825', '9826', '9827', '9828', '9829', '9830', '9831', '9832', '9833', '9834', '9835', '9836', '9837', '9838', '9839', '9840', '9841', '9842', '9843', '9844', '9845', '9846', '9847', '9848', '9849', '9850', '9851', '9852', '9853', '9854', '9855', '9856', '9857', '9858', '9859', '9860', '9861', '9862', '9863', '9864', '9865', '9866', '9867', '9868', '9869', '9870', '9871', '9872', '9873', '9874', '9875', '9876', '9877', '9878', '9879', '9880', '9881', '9882', '9883', '9884', '9885', '9886', '9887', '9888', '9889', '9890', '9891', '9892', '9893', '9894', '9895', '9896', '9897', '9898', '9899', '9900', '9901', '9902', '9903', '9904', '9905', '9906', '9907', '9908', '9909', '9910', '9911', '9912', '9913', '9914', '9915', '9916', '9917', '9918', '9919', '9920', '9921', '9922', '9923', '9924', '9925', '9926', '9927', '9928', '9929', '9930', '9931', '9932', '9933', '9934', '9935', '9936', '9937', '9938', '9939', '9940', '9941', '9942', '9943', '9944', '9945', '9946', '9947', '9948', '9949', '9950', '9951', '9952', '9953', '9954', '9955', '9956', '9957', '9958', '9959', '9960', '9961', '9962', '9963', '9964', '9965', '9966', '9967', '9968', '9969', '9970', '9971', '9972', '9973', '9974', '9975', '9976', '9977', '9978', '9979', '9980', '9981', '9982', '9983', '9984', '9985', '9986', '9987', '9988', '9989', '9990', '9991', '9992', '9993', '9994', '9995', '9996', '9997', '9998', '9999']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1628191236037,"user_tz":-540,"elapsed":568,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1628191236038,"user_tz":-540,"elapsed":28,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"5bd2e691-63e6-4947-efc6-7745dee476e2"},"source":["submission[\"ResNet50_predict\"] = ResNet50_predict\n","submission[\"ResNet101_predict\"] = ResNet101_predict\n","submission[\"ResNet152_predict\"] = ResNet152_predict\n","submission[\"ResNet50V2_predict\"] = ResNet50V2_predict\n","submission[\"ResNet101V2_predict\"] = ResNet101V2_predict\n","submission[\"ResNet152V2_predict\"] = ResNet152V2_predict\n","# submission[\"VGG16_predict\"] = VGG16_predict\n","# submission[\"VGG19_predict\"] = VGG19_predict\n","submission[\"InceptionV3_predict\"] = InceptionV3_predict\n","submission[\"InceptionResNetV2_predict\"] = InceptionResNetV2_predict\n","submission[\"DenseNet121_predict\"] = DenseNet121_predict\n","submission[\"DenseNet169_predict\"] = DenseNet169_predict\n","submission[\"DenseNet201_predict\"] = DenseNet201_predict\n","submission.head()"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","      <th>ResNet50_predict</th>\n","      <th>ResNet101_predict</th>\n","      <th>ResNet152_predict</th>\n","      <th>ResNet50V2_predict</th>\n","      <th>ResNet101V2_predict</th>\n","      <th>ResNet152V2_predict</th>\n","      <th>InceptionV3_predict</th>\n","      <th>InceptionResNetV2_predict</th>\n","      <th>DenseNet121_predict</th>\n","      <th>DenseNet169_predict</th>\n","      <th>DenseNet201_predict</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit  ...  DenseNet169_predict  DenseNet201_predict\n","0  10000      0  ...                    4                    4\n","1  10001      0  ...                    4                    4\n","2  10002      0  ...                    6                    6\n","3  10003      0  ...                    9                    9\n","4  10004      0  ...                    5                    5\n","\n","[5 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1628191247100,"user_tz":-540,"elapsed":11086,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"859dc019-e693-465e-be7c-0ee31bff4311"},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['ResNet50_predict','ResNet101_predict','ResNet152_predict','ResNet50V2_predict','ResNet101V2_predict','ResNet152V2_predict','InceptionV3_predict','InceptionResNetV2_predict','DenseNet121_predict','DenseNet169_predict','DenseNet201_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]\n","\n","submission.head()"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","      <th>ResNet50_predict</th>\n","      <th>ResNet101_predict</th>\n","      <th>ResNet152_predict</th>\n","      <th>ResNet50V2_predict</th>\n","      <th>ResNet101V2_predict</th>\n","      <th>ResNet152V2_predict</th>\n","      <th>InceptionV3_predict</th>\n","      <th>InceptionResNetV2_predict</th>\n","      <th>DenseNet121_predict</th>\n","      <th>DenseNet169_predict</th>\n","      <th>DenseNet201_predict</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit  ...  DenseNet169_predict  DenseNet201_predict\n","0  10000      4  ...                    4                    4\n","1  10001      4  ...                    4                    4\n","2  10002      6  ...                    6                    6\n","3  10003      9  ...                    9                    9\n","4  10004      5  ...                    5                    5\n","\n","[5 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1628191247102,"user_tz":-540,"elapsed":18,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"8ff12f5c-b4ad-4445-b882-139ef5ae9313"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1628191247103,"user_tz":-540,"elapsed":15,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"073fa158-6177-4c49-c9bb-8bcbeb244fa8"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/submission_ensemble_11.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/submission_ensemble_11.csv')"],"execution_count":35,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_3a36751d-cb0d-4c62-bbc2-873c6854b58a\", \"submission_ensemble_11.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]}]}