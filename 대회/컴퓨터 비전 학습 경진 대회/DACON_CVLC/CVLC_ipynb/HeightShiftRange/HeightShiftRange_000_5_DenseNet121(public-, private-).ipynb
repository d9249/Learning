{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HeightShiftRange_000_5_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1fKp4Svl_srbEAv_YpXTvSwqDozb4bj9H","timestamp":1630484105207},{"file_id":"1y9kcnOXGhn5ArjCk66kqJCIvgyfTRSkk","timestamp":1630483907553},{"file_id":"1o9CD4AI2tKzcdbdLJ4A6xkENgqmZG7oW","timestamp":1630475138628},{"file_id":"17KUAlMIBl9TgxSnuNYcPwx2zScEUw5W-","timestamp":1630475103015},{"file_id":"12cn5R3wN6-IWoeS68BSqi4LxqlCxJxYt","timestamp":1630464969114},{"file_id":"1KLLc8roFaz12DcPj1WHhuKt9ZBQqi76a","timestamp":1630464678834},{"file_id":"1VZIQ1plZ8Dw3dEaOdrcDkgTjXOv0OcTp","timestamp":1630464589009},{"file_id":"1HiqQpOR-bo5ZelQ96RenE8K365HqE7Lv","timestamp":1630438189228},{"file_id":"1ltViornnQGTXyCDuiYgIGfZy1m46LTW_","timestamp":1630438122242},{"file_id":"12vcTsqE7nuRUe3r9-4k5efqml3ud1k9Z","timestamp":1630438078632},{"file_id":"1EdFynNtlBeF206lf5xA2umzEqK_Pjyi5","timestamp":1630437839162},{"file_id":"1pKJK3lnnRPxX28V0U_A45uk_SI4WlDZr","timestamp":1630432659647},{"file_id":"1soBcJ0zzhkPsMINjzGMbYGcga7VX-2Be","timestamp":1630432634550},{"file_id":"12jPQ_wSDDvGyzTBUV-h-pRZ8N-lp9bkW","timestamp":1630425888718},{"file_id":"1ik1ECJq6EbWwGegXLisYoxytv0-7JQcn","timestamp":1630425853722},{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyNJkYCSEnJ57qddsHkW4gI+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630494806807,"user_tz":-540,"elapsed":481,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"3f7a0d6f-6eee-4ea1-9648-3542c932fa41"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Sep  1 11:13:26 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630494825930,"user_tz":-540,"elapsed":19128,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"1872eaac-e747-4aa2-8a33-318fac7aafc3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1630494830455,"user_tz":-540,"elapsed":4530,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1630494832055,"user_tz":-540,"elapsed":1610,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1630494834003,"user_tz":-540,"elapsed":1951,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1630494850957,"user_tz":-540,"elapsed":16958,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1630494857879,"user_tz":-540,"elapsed":6923,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630494857880,"user_tz":-540,"elapsed":18,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"f2332fc3-d1fd-4bb3-f8e5-365d2020e66d"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630494857881,"user_tz":-540,"elapsed":13,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"f3988e45-3b82-46e1-abff-1bbc9c301981"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.0)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1630494857882,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630501331296,"user_tz":-540,"elapsed":6473424,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"1c2883b7-11fc-48be-e7ac-d59db4e1f522"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 39s 270ms/step - loss: 1.8210 - accuracy: 0.3630 - val_loss: 32.0119 - val_accuracy: 0.0936\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09360, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 12s 220ms/step - loss: 1.1212 - accuracy: 0.6291 - val_loss: 23.5844 - val_accuracy: 0.1084\n","\n","Epoch 00002: val_accuracy improved from 0.09360 to 0.10837, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 3/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.8857 - accuracy: 0.7192 - val_loss: 4.9569 - val_accuracy: 0.0862\n","\n","Epoch 00003: val_accuracy did not improve from 0.10837\n","Epoch 4/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.8211 - accuracy: 0.7284 - val_loss: 8.0111 - val_accuracy: 0.0985\n","\n","Epoch 00004: val_accuracy did not improve from 0.10837\n","Epoch 5/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.6343 - accuracy: 0.7935 - val_loss: 11.1094 - val_accuracy: 0.1527\n","\n","Epoch 00005: val_accuracy improved from 0.10837 to 0.15271, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.6296 - accuracy: 0.7978 - val_loss: 5.4215 - val_accuracy: 0.2044\n","\n","Epoch 00006: val_accuracy improved from 0.15271 to 0.20443, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.5137 - accuracy: 0.8337 - val_loss: 5.4952 - val_accuracy: 0.2389\n","\n","Epoch 00007: val_accuracy improved from 0.20443 to 0.23892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.4337 - accuracy: 0.8520 - val_loss: 2.8758 - val_accuracy: 0.3867\n","\n","Epoch 00008: val_accuracy improved from 0.23892 to 0.38670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.4622 - accuracy: 0.8380 - val_loss: 2.2549 - val_accuracy: 0.5000\n","\n","Epoch 00009: val_accuracy improved from 0.38670 to 0.50000, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.3727 - accuracy: 0.8752 - val_loss: 1.0307 - val_accuracy: 0.7020\n","\n","Epoch 00010: val_accuracy improved from 0.50000 to 0.70197, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3220 - accuracy: 0.8892 - val_loss: 0.9075 - val_accuracy: 0.7020\n","\n","Epoch 00011: val_accuracy did not improve from 0.70197\n","Epoch 12/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.2773 - accuracy: 0.9062 - val_loss: 1.0549 - val_accuracy: 0.7488\n","\n","Epoch 00012: val_accuracy improved from 0.70197 to 0.74877, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 13/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.2840 - accuracy: 0.9001 - val_loss: 1.4079 - val_accuracy: 0.6675\n","\n","Epoch 00013: val_accuracy did not improve from 0.74877\n","Epoch 14/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.3412 - accuracy: 0.8855 - val_loss: 1.1649 - val_accuracy: 0.7143\n","\n","Epoch 00014: val_accuracy did not improve from 0.74877\n","Epoch 15/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.2563 - accuracy: 0.9147 - val_loss: 1.1184 - val_accuracy: 0.7143\n","\n","Epoch 00015: val_accuracy did not improve from 0.74877\n","Epoch 16/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.2522 - accuracy: 0.9147 - val_loss: 0.8494 - val_accuracy: 0.7759\n","\n","Epoch 00016: val_accuracy improved from 0.74877 to 0.77586, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 17/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.2410 - accuracy: 0.9160 - val_loss: 1.1698 - val_accuracy: 0.7020\n","\n","Epoch 00017: val_accuracy did not improve from 0.77586\n","Epoch 18/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.3348 - accuracy: 0.8831 - val_loss: 2.4171 - val_accuracy: 0.5542\n","\n","Epoch 00018: val_accuracy did not improve from 0.77586\n","Epoch 19/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.2301 - accuracy: 0.9220 - val_loss: 0.8580 - val_accuracy: 0.7635\n","\n","Epoch 00019: val_accuracy did not improve from 0.77586\n","Epoch 20/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1824 - accuracy: 0.9391 - val_loss: 0.8789 - val_accuracy: 0.7660\n","\n","Epoch 00020: val_accuracy did not improve from 0.77586\n","Epoch 21/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1848 - accuracy: 0.9354 - val_loss: 1.2514 - val_accuracy: 0.7217\n","\n","Epoch 00021: val_accuracy did not improve from 0.77586\n","Epoch 22/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1720 - accuracy: 0.9373 - val_loss: 0.7610 - val_accuracy: 0.7956\n","\n","Epoch 00022: val_accuracy improved from 0.77586 to 0.79557, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 23/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1923 - accuracy: 0.9336 - val_loss: 0.5299 - val_accuracy: 0.8350\n","\n","Epoch 00023: val_accuracy improved from 0.79557 to 0.83498, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 24/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1294 - accuracy: 0.9537 - val_loss: 0.3775 - val_accuracy: 0.8842\n","\n","Epoch 00024: val_accuracy improved from 0.83498 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 25/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1504 - accuracy: 0.9519 - val_loss: 1.6194 - val_accuracy: 0.6724\n","\n","Epoch 00025: val_accuracy did not improve from 0.88424\n","Epoch 26/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1862 - accuracy: 0.9385 - val_loss: 0.7159 - val_accuracy: 0.8054\n","\n","Epoch 00026: val_accuracy did not improve from 0.88424\n","Epoch 27/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.1398 - accuracy: 0.9555 - val_loss: 0.7461 - val_accuracy: 0.8300\n","\n","Epoch 00027: val_accuracy did not improve from 0.88424\n","Epoch 28/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.2052 - accuracy: 0.9306 - val_loss: 0.8513 - val_accuracy: 0.8103\n","\n","Epoch 00028: val_accuracy did not improve from 0.88424\n","Epoch 29/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1275 - accuracy: 0.9549 - val_loss: 0.4327 - val_accuracy: 0.8793\n","\n","Epoch 00029: val_accuracy did not improve from 0.88424\n","Epoch 30/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0949 - accuracy: 0.9695 - val_loss: 0.3611 - val_accuracy: 0.8818\n","\n","Epoch 00030: val_accuracy did not improve from 0.88424\n","Epoch 31/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0852 - accuracy: 0.9695 - val_loss: 0.4018 - val_accuracy: 0.8916\n","\n","Epoch 00031: val_accuracy improved from 0.88424 to 0.89163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 32/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.1155 - accuracy: 0.9647 - val_loss: 0.4675 - val_accuracy: 0.8695\n","\n","Epoch 00032: val_accuracy did not improve from 0.89163\n","Epoch 33/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0710 - accuracy: 0.9787 - val_loss: 0.9492 - val_accuracy: 0.7906\n","\n","Epoch 00033: val_accuracy did not improve from 0.89163\n","Epoch 34/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.1297 - accuracy: 0.9574 - val_loss: 0.5484 - val_accuracy: 0.8448\n","\n","Epoch 00034: val_accuracy did not improve from 0.89163\n","Epoch 35/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1114 - accuracy: 0.9647 - val_loss: 0.4257 - val_accuracy: 0.8670\n","\n","Epoch 00035: val_accuracy did not improve from 0.89163\n","Epoch 36/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0679 - accuracy: 0.9805 - val_loss: 0.3621 - val_accuracy: 0.9064\n","\n","Epoch 00036: val_accuracy improved from 0.89163 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 37/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1273 - accuracy: 0.9604 - val_loss: 1.8526 - val_accuracy: 0.6478\n","\n","Epoch 00037: val_accuracy did not improve from 0.90640\n","Epoch 38/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1068 - accuracy: 0.9659 - val_loss: 0.4744 - val_accuracy: 0.8522\n","\n","Epoch 00038: val_accuracy did not improve from 0.90640\n","Epoch 39/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0874 - accuracy: 0.9708 - val_loss: 0.4652 - val_accuracy: 0.8768\n","\n","Epoch 00039: val_accuracy did not improve from 0.90640\n","Epoch 40/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0867 - accuracy: 0.9695 - val_loss: 0.5978 - val_accuracy: 0.8645\n","\n","Epoch 00040: val_accuracy did not improve from 0.90640\n","Epoch 41/500\n","52/52 [==============================] - 12s 236ms/step - loss: 0.0977 - accuracy: 0.9629 - val_loss: 1.2854 - val_accuracy: 0.7586\n","\n","Epoch 00041: val_accuracy did not improve from 0.90640\n","Epoch 42/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0999 - accuracy: 0.9702 - val_loss: 0.4358 - val_accuracy: 0.8768\n","\n","Epoch 00042: val_accuracy did not improve from 0.90640\n","Epoch 43/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0711 - accuracy: 0.9775 - val_loss: 0.5958 - val_accuracy: 0.8448\n","\n","Epoch 00043: val_accuracy did not improve from 0.90640\n","Epoch 44/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0544 - accuracy: 0.9817 - val_loss: 0.5538 - val_accuracy: 0.8695\n","\n","Epoch 00044: val_accuracy did not improve from 0.90640\n","Epoch 45/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0546 - accuracy: 0.9811 - val_loss: 0.4684 - val_accuracy: 0.8867\n","\n","Epoch 00045: val_accuracy did not improve from 0.90640\n","Epoch 46/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0505 - accuracy: 0.9829 - val_loss: 0.6574 - val_accuracy: 0.8645\n","\n","Epoch 00046: val_accuracy did not improve from 0.90640\n","Epoch 47/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0557 - accuracy: 0.9817 - val_loss: 0.5294 - val_accuracy: 0.8916\n","\n","Epoch 00047: val_accuracy did not improve from 0.90640\n","Epoch 48/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0758 - accuracy: 0.9744 - val_loss: 0.5445 - val_accuracy: 0.8571\n","\n","Epoch 00048: val_accuracy did not improve from 0.90640\n","Epoch 49/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0724 - accuracy: 0.9775 - val_loss: 0.8528 - val_accuracy: 0.8153\n","\n","Epoch 00049: val_accuracy did not improve from 0.90640\n","Epoch 50/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0657 - accuracy: 0.9762 - val_loss: 0.4691 - val_accuracy: 0.8941\n","\n","Epoch 00050: val_accuracy did not improve from 0.90640\n","Epoch 51/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0299 - accuracy: 0.9933 - val_loss: 0.3746 - val_accuracy: 0.8966\n","\n","Epoch 00051: val_accuracy did not improve from 0.90640\n","Epoch 52/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0289 - accuracy: 0.9896 - val_loss: 0.4369 - val_accuracy: 0.8966\n","\n","Epoch 00052: val_accuracy did not improve from 0.90640\n","Epoch 53/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0372 - accuracy: 0.9896 - val_loss: 0.5126 - val_accuracy: 0.8744\n","\n","Epoch 00053: val_accuracy did not improve from 0.90640\n","Epoch 54/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.1131 - accuracy: 0.9665 - val_loss: 1.3326 - val_accuracy: 0.7414\n","\n","Epoch 00054: val_accuracy did not improve from 0.90640\n","Epoch 55/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.1069 - accuracy: 0.9677 - val_loss: 0.8165 - val_accuracy: 0.7857\n","\n","Epoch 00055: val_accuracy did not improve from 0.90640\n","Epoch 56/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0807 - accuracy: 0.9720 - val_loss: 0.3811 - val_accuracy: 0.8892\n","\n","Epoch 00056: val_accuracy did not improve from 0.90640\n","Epoch 57/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0767 - accuracy: 0.9683 - val_loss: 0.5306 - val_accuracy: 0.8768\n","\n","Epoch 00057: val_accuracy did not improve from 0.90640\n","Epoch 58/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0891 - accuracy: 0.9714 - val_loss: 1.2696 - val_accuracy: 0.7709\n","\n","Epoch 00058: val_accuracy did not improve from 0.90640\n","Epoch 59/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0822 - accuracy: 0.9720 - val_loss: 0.6564 - val_accuracy: 0.8621\n","\n","Epoch 00059: val_accuracy did not improve from 0.90640\n","Epoch 60/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0730 - accuracy: 0.9775 - val_loss: 0.4092 - val_accuracy: 0.8941\n","\n","Epoch 00060: val_accuracy did not improve from 0.90640\n","Epoch 61/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0834 - accuracy: 0.9720 - val_loss: 0.5380 - val_accuracy: 0.8670\n","\n","Epoch 00061: val_accuracy did not improve from 0.90640\n","Epoch 62/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0516 - accuracy: 0.9829 - val_loss: 0.5662 - val_accuracy: 0.8621\n","\n","Epoch 00062: val_accuracy did not improve from 0.90640\n","Epoch 63/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0353 - accuracy: 0.9872 - val_loss: 0.4675 - val_accuracy: 0.8966\n","\n","Epoch 00063: val_accuracy did not improve from 0.90640\n","Epoch 64/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1088 - accuracy: 0.9750 - val_loss: 5.8388 - val_accuracy: 0.5123\n","\n","Epoch 00064: val_accuracy did not improve from 0.90640\n","Epoch 65/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1563 - accuracy: 0.9434 - val_loss: 1.9532 - val_accuracy: 0.6675\n","\n","Epoch 00065: val_accuracy did not improve from 0.90640\n","Epoch 66/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0796 - accuracy: 0.9708 - val_loss: 0.8605 - val_accuracy: 0.8424\n","\n","Epoch 00066: val_accuracy did not improve from 0.90640\n","Epoch 67/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0429 - accuracy: 0.9872 - val_loss: 0.3740 - val_accuracy: 0.8990\n","\n","Epoch 00067: val_accuracy did not improve from 0.90640\n","Epoch 68/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0313 - accuracy: 0.9878 - val_loss: 0.4981 - val_accuracy: 0.8744\n","\n","Epoch 00068: val_accuracy did not improve from 0.90640\n","Epoch 69/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.5511 - val_accuracy: 0.8768\n","\n","Epoch 00069: val_accuracy did not improve from 0.90640\n","Epoch 70/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.4229 - val_accuracy: 0.8892\n","\n","Epoch 00070: val_accuracy did not improve from 0.90640\n","Epoch 71/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.3555 - val_accuracy: 0.9212\n","\n","Epoch 00071: val_accuracy improved from 0.90640 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 72/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0231 - accuracy: 0.9909 - val_loss: 0.4381 - val_accuracy: 0.8941\n","\n","Epoch 00072: val_accuracy did not improve from 0.92118\n","Epoch 73/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.4780 - val_accuracy: 0.8818\n","\n","Epoch 00073: val_accuracy did not improve from 0.92118\n","Epoch 74/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.4103 - val_accuracy: 0.9015\n","\n","Epoch 00074: val_accuracy did not improve from 0.92118\n","Epoch 75/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.4202 - val_accuracy: 0.9064\n","\n","Epoch 00075: val_accuracy did not improve from 0.92118\n","Epoch 76/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.6362 - val_accuracy: 0.8867\n","\n","Epoch 00076: val_accuracy did not improve from 0.92118\n","Epoch 77/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0321 - accuracy: 0.9915 - val_loss: 0.5626 - val_accuracy: 0.8719\n","\n","Epoch 00077: val_accuracy did not improve from 0.92118\n","Epoch 78/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 0.5022 - val_accuracy: 0.8818\n","\n","Epoch 00078: val_accuracy did not improve from 0.92118\n","Epoch 79/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0327 - accuracy: 0.9915 - val_loss: 0.5481 - val_accuracy: 0.8966\n","\n","Epoch 00079: val_accuracy did not improve from 0.92118\n","Epoch 80/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.5182 - val_accuracy: 0.8695\n","\n","Epoch 00080: val_accuracy did not improve from 0.92118\n","Epoch 81/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0290 - accuracy: 0.9927 - val_loss: 0.5002 - val_accuracy: 0.8867\n","\n","Epoch 00081: val_accuracy did not improve from 0.92118\n","Epoch 82/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0490 - accuracy: 0.9848 - val_loss: 0.5101 - val_accuracy: 0.8793\n","\n","Epoch 00082: val_accuracy did not improve from 0.92118\n","Epoch 83/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0241 - accuracy: 0.9951 - val_loss: 0.6705 - val_accuracy: 0.8547\n","\n","Epoch 00083: val_accuracy did not improve from 0.92118\n","Epoch 84/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.6666 - val_accuracy: 0.8473\n","\n","Epoch 00084: val_accuracy did not improve from 0.92118\n","Epoch 85/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0370 - accuracy: 0.9854 - val_loss: 0.6379 - val_accuracy: 0.8670\n","\n","Epoch 00085: val_accuracy did not improve from 0.92118\n","Epoch 86/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0557 - accuracy: 0.9793 - val_loss: 0.5971 - val_accuracy: 0.8621\n","\n","Epoch 00086: val_accuracy did not improve from 0.92118\n","Epoch 87/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1375 - accuracy: 0.9610 - val_loss: 1.4372 - val_accuracy: 0.7709\n","\n","Epoch 00087: val_accuracy did not improve from 0.92118\n","Epoch 88/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.2168 - accuracy: 0.9379 - val_loss: 1.7647 - val_accuracy: 0.7143\n","\n","Epoch 00088: val_accuracy did not improve from 0.92118\n","Epoch 89/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0678 - accuracy: 0.9775 - val_loss: 0.4203 - val_accuracy: 0.8966\n","\n","Epoch 00089: val_accuracy did not improve from 0.92118\n","Epoch 90/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0484 - accuracy: 0.9854 - val_loss: 0.5212 - val_accuracy: 0.8867\n","\n","Epoch 00090: val_accuracy did not improve from 0.92118\n","Epoch 91/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0375 - accuracy: 0.9915 - val_loss: 0.5698 - val_accuracy: 0.8793\n","\n","Epoch 00091: val_accuracy did not improve from 0.92118\n","Epoch 92/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.3503 - val_accuracy: 0.9187\n","\n","Epoch 00092: val_accuracy did not improve from 0.92118\n","Epoch 93/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.4435 - val_accuracy: 0.8892\n","\n","Epoch 00093: val_accuracy did not improve from 0.92118\n","Epoch 94/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0130 - accuracy: 0.9945 - val_loss: 0.3527 - val_accuracy: 0.9187\n","\n","Epoch 00094: val_accuracy did not improve from 0.92118\n","Epoch 95/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.4671 - val_accuracy: 0.8941\n","\n","Epoch 00095: val_accuracy did not improve from 0.92118\n","Epoch 96/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0301 - accuracy: 0.9866 - val_loss: 0.6600 - val_accuracy: 0.8596\n","\n","Epoch 00096: val_accuracy did not improve from 0.92118\n","Epoch 97/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0505 - accuracy: 0.9829 - val_loss: 0.7945 - val_accuracy: 0.8596\n","\n","Epoch 00097: val_accuracy did not improve from 0.92118\n","Epoch 98/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1372 - accuracy: 0.9580 - val_loss: 1.1626 - val_accuracy: 0.7833\n","\n","Epoch 00098: val_accuracy did not improve from 0.92118\n","Epoch 99/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0869 - accuracy: 0.9726 - val_loss: 0.9025 - val_accuracy: 0.8276\n","\n","Epoch 00099: val_accuracy did not improve from 0.92118\n","Epoch 100/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0593 - accuracy: 0.9799 - val_loss: 0.6352 - val_accuracy: 0.8818\n","\n","Epoch 00100: val_accuracy did not improve from 0.92118\n","Epoch 101/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.4181 - val_accuracy: 0.9064\n","\n","Epoch 00101: val_accuracy did not improve from 0.92118\n","Epoch 102/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0195 - accuracy: 0.9903 - val_loss: 0.4096 - val_accuracy: 0.8892\n","\n","Epoch 00102: val_accuracy did not improve from 0.92118\n","Epoch 103/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.3540 - val_accuracy: 0.9187\n","\n","Epoch 00103: val_accuracy did not improve from 0.92118\n","Epoch 104/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.4803 - val_accuracy: 0.8916\n","\n","Epoch 00104: val_accuracy did not improve from 0.92118\n","Epoch 105/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9015\n","\n","Epoch 00105: val_accuracy did not improve from 0.92118\n","Epoch 106/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.3518 - val_accuracy: 0.9236\n","\n","Epoch 00106: val_accuracy improved from 0.92118 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 107/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.3381 - val_accuracy: 0.9212\n","\n","Epoch 00107: val_accuracy did not improve from 0.92365\n","Epoch 108/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3989 - val_accuracy: 0.9187\n","\n","Epoch 00108: val_accuracy did not improve from 0.92365\n","Epoch 109/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.3708 - val_accuracy: 0.9163\n","\n","Epoch 00109: val_accuracy did not improve from 0.92365\n","Epoch 110/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.3393 - val_accuracy: 0.9236\n","\n","Epoch 00110: val_accuracy did not improve from 0.92365\n","Epoch 111/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.4142 - val_accuracy: 0.9064\n","\n","Epoch 00111: val_accuracy did not improve from 0.92365\n","Epoch 112/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9187\n","\n","Epoch 00112: val_accuracy did not improve from 0.92365\n","Epoch 113/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9236\n","\n","Epoch 00113: val_accuracy did not improve from 0.92365\n","Epoch 114/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9335\n","\n","Epoch 00114: val_accuracy improved from 0.92365 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 115/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4630 - val_accuracy: 0.8916\n","\n","Epoch 00115: val_accuracy did not improve from 0.93350\n","Epoch 116/500\n","52/52 [==============================] - 11s 214ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.5150 - val_accuracy: 0.8768\n","\n","Epoch 00116: val_accuracy did not improve from 0.93350\n","Epoch 117/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.3694 - val_accuracy: 0.9261\n","\n","Epoch 00117: val_accuracy did not improve from 0.93350\n","Epoch 118/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0360 - accuracy: 0.9903 - val_loss: 0.8093 - val_accuracy: 0.8473\n","\n","Epoch 00118: val_accuracy did not improve from 0.93350\n","Epoch 119/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1864 - accuracy: 0.9434 - val_loss: 4.3314 - val_accuracy: 0.5961\n","\n","Epoch 00119: val_accuracy did not improve from 0.93350\n","Epoch 120/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0917 - accuracy: 0.9689 - val_loss: 0.5273 - val_accuracy: 0.8818\n","\n","Epoch 00120: val_accuracy did not improve from 0.93350\n","Epoch 121/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0406 - accuracy: 0.9860 - val_loss: 0.4293 - val_accuracy: 0.8990\n","\n","Epoch 00121: val_accuracy did not improve from 0.93350\n","Epoch 122/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0430 - accuracy: 0.9854 - val_loss: 0.5228 - val_accuracy: 0.8842\n","\n","Epoch 00122: val_accuracy did not improve from 0.93350\n","Epoch 123/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0490 - accuracy: 0.9854 - val_loss: 0.5224 - val_accuracy: 0.8842\n","\n","Epoch 00123: val_accuracy did not improve from 0.93350\n","Epoch 124/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0382 - accuracy: 0.9890 - val_loss: 0.5687 - val_accuracy: 0.8719\n","\n","Epoch 00124: val_accuracy did not improve from 0.93350\n","Epoch 125/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0241 - accuracy: 0.9909 - val_loss: 0.4293 - val_accuracy: 0.8941\n","\n","Epoch 00125: val_accuracy did not improve from 0.93350\n","Epoch 126/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 0.4087 - val_accuracy: 0.9138\n","\n","Epoch 00126: val_accuracy did not improve from 0.93350\n","Epoch 127/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.5022 - val_accuracy: 0.8941\n","\n","Epoch 00127: val_accuracy did not improve from 0.93350\n","Epoch 128/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.4477 - val_accuracy: 0.8966\n","\n","Epoch 00128: val_accuracy did not improve from 0.93350\n","Epoch 129/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.4055 - val_accuracy: 0.9261\n","\n","Epoch 00129: val_accuracy did not improve from 0.93350\n","Epoch 130/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.7813 - val_accuracy: 0.8695\n","\n","Epoch 00130: val_accuracy did not improve from 0.93350\n","Epoch 131/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0390 - accuracy: 0.9884 - val_loss: 0.6368 - val_accuracy: 0.8695\n","\n","Epoch 00131: val_accuracy did not improve from 0.93350\n","Epoch 132/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0239 - accuracy: 0.9884 - val_loss: 0.6741 - val_accuracy: 0.8670\n","\n","Epoch 00132: val_accuracy did not improve from 0.93350\n","Epoch 133/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.4830 - val_accuracy: 0.8966\n","\n","Epoch 00133: val_accuracy did not improve from 0.93350\n","Epoch 134/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.6755 - val_accuracy: 0.8744\n","\n","Epoch 00134: val_accuracy did not improve from 0.93350\n","Epoch 135/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.4101 - val_accuracy: 0.8941\n","\n","Epoch 00135: val_accuracy did not improve from 0.93350\n","Epoch 136/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0197 - accuracy: 0.9921 - val_loss: 0.6105 - val_accuracy: 0.8719\n","\n","Epoch 00136: val_accuracy did not improve from 0.93350\n","Epoch 137/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0256 - accuracy: 0.9927 - val_loss: 0.4115 - val_accuracy: 0.9138\n","\n","Epoch 00137: val_accuracy did not improve from 0.93350\n","Epoch 138/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0375 - accuracy: 0.9866 - val_loss: 0.7532 - val_accuracy: 0.8571\n","\n","Epoch 00138: val_accuracy did not improve from 0.93350\n","Epoch 139/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0917 - accuracy: 0.9720 - val_loss: 1.1727 - val_accuracy: 0.7931\n","\n","Epoch 00139: val_accuracy did not improve from 0.93350\n","Epoch 140/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0710 - accuracy: 0.9787 - val_loss: 2.4114 - val_accuracy: 0.6921\n","\n","Epoch 00140: val_accuracy did not improve from 0.93350\n","Epoch 141/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0496 - accuracy: 0.9829 - val_loss: 0.5801 - val_accuracy: 0.8768\n","\n","Epoch 00141: val_accuracy did not improve from 0.93350\n","Epoch 142/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0386 - accuracy: 0.9866 - val_loss: 0.7482 - val_accuracy: 0.8645\n","\n","Epoch 00142: val_accuracy did not improve from 0.93350\n","Epoch 143/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0216 - accuracy: 0.9945 - val_loss: 0.4022 - val_accuracy: 0.9163\n","\n","Epoch 00143: val_accuracy did not improve from 0.93350\n","Epoch 144/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.3817 - val_accuracy: 0.9113\n","\n","Epoch 00144: val_accuracy did not improve from 0.93350\n","Epoch 145/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0101 - accuracy: 0.9957 - val_loss: 0.3917 - val_accuracy: 0.9163\n","\n","Epoch 00145: val_accuracy did not improve from 0.93350\n","Epoch 146/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.4655 - val_accuracy: 0.8892\n","\n","Epoch 00146: val_accuracy did not improve from 0.93350\n","Epoch 147/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.4158 - val_accuracy: 0.9187\n","\n","Epoch 00147: val_accuracy did not improve from 0.93350\n","Epoch 148/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3194 - val_accuracy: 0.9212\n","\n","Epoch 00148: val_accuracy did not improve from 0.93350\n","Epoch 149/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.4326 - val_accuracy: 0.9163\n","\n","Epoch 00149: val_accuracy did not improve from 0.93350\n","Epoch 150/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4674 - val_accuracy: 0.9015\n","\n","Epoch 00150: val_accuracy did not improve from 0.93350\n","Epoch 151/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.5111 - val_accuracy: 0.8966\n","\n","Epoch 00151: val_accuracy did not improve from 0.93350\n","Epoch 152/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.4761 - val_accuracy: 0.8892\n","\n","Epoch 00152: val_accuracy did not improve from 0.93350\n","Epoch 153/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0287 - accuracy: 0.9927 - val_loss: 0.4407 - val_accuracy: 0.9039\n","\n","Epoch 00153: val_accuracy did not improve from 0.93350\n","Epoch 154/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0284 - accuracy: 0.9896 - val_loss: 0.6381 - val_accuracy: 0.8744\n","\n","Epoch 00154: val_accuracy did not improve from 0.93350\n","Epoch 155/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0954 - accuracy: 0.9702 - val_loss: 0.7119 - val_accuracy: 0.8547\n","\n","Epoch 00155: val_accuracy did not improve from 0.93350\n","Epoch 156/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0543 - accuracy: 0.9781 - val_loss: 1.8490 - val_accuracy: 0.7685\n","\n","Epoch 00156: val_accuracy did not improve from 0.93350\n","Epoch 157/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0417 - accuracy: 0.9878 - val_loss: 0.7711 - val_accuracy: 0.8522\n","\n","Epoch 00157: val_accuracy did not improve from 0.93350\n","Epoch 158/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0341 - accuracy: 0.9872 - val_loss: 0.4968 - val_accuracy: 0.8916\n","\n","Epoch 00158: val_accuracy did not improve from 0.93350\n","Epoch 159/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0542 - accuracy: 0.9811 - val_loss: 0.8192 - val_accuracy: 0.8276\n","\n","Epoch 00159: val_accuracy did not improve from 0.93350\n","Epoch 160/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0387 - accuracy: 0.9860 - val_loss: 0.4802 - val_accuracy: 0.9039\n","\n","Epoch 00160: val_accuracy did not improve from 0.93350\n","Epoch 161/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.4889 - val_accuracy: 0.9089\n","\n","Epoch 00161: val_accuracy did not improve from 0.93350\n","Epoch 162/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.4222 - val_accuracy: 0.9113\n","\n","Epoch 00162: val_accuracy did not improve from 0.93350\n","Epoch 163/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.6213 - val_accuracy: 0.8448\n","\n","Epoch 00163: val_accuracy did not improve from 0.93350\n","Epoch 164/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0147 - accuracy: 0.9939 - val_loss: 0.5899 - val_accuracy: 0.8941\n","\n","Epoch 00164: val_accuracy did not improve from 0.93350\n","Epoch 165/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0078 - accuracy: 0.9957 - val_loss: 0.4430 - val_accuracy: 0.9113\n","\n","Epoch 00165: val_accuracy did not improve from 0.93350\n","Epoch 166/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.3870 - val_accuracy: 0.9163\n","\n","Epoch 00166: val_accuracy did not improve from 0.93350\n","Epoch 167/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.5126 - val_accuracy: 0.9138\n","\n","Epoch 00167: val_accuracy did not improve from 0.93350\n","Epoch 168/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0064 - accuracy: 0.9970 - val_loss: 0.3858 - val_accuracy: 0.9261\n","\n","Epoch 00168: val_accuracy did not improve from 0.93350\n","Epoch 169/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.4511 - val_accuracy: 0.9163\n","\n","Epoch 00169: val_accuracy did not improve from 0.93350\n","Epoch 170/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0209 - accuracy: 0.9963 - val_loss: 0.3340 - val_accuracy: 0.9286\n","\n","Epoch 00170: val_accuracy did not improve from 0.93350\n","Epoch 171/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.7413 - val_accuracy: 0.8768\n","\n","Epoch 00171: val_accuracy did not improve from 0.93350\n","Epoch 172/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.4582 - val_accuracy: 0.8941\n","\n","Epoch 00172: val_accuracy did not improve from 0.93350\n","Epoch 173/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.3504 - val_accuracy: 0.9384\n","\n","Epoch 00173: val_accuracy improved from 0.93350 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 174/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.5658 - val_accuracy: 0.8892\n","\n","Epoch 00174: val_accuracy did not improve from 0.93842\n","Epoch 175/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.4768 - val_accuracy: 0.8916\n","\n","Epoch 00175: val_accuracy did not improve from 0.93842\n","Epoch 176/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 0.4410 - val_accuracy: 0.9089\n","\n","Epoch 00176: val_accuracy did not improve from 0.93842\n","Epoch 177/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.4015 - val_accuracy: 0.9212\n","\n","Epoch 00177: val_accuracy did not improve from 0.93842\n","Epoch 178/500\n","52/52 [==============================] - 12s 236ms/step - loss: 0.0068 - accuracy: 0.9963 - val_loss: 0.4562 - val_accuracy: 0.9039\n","\n","Epoch 00178: val_accuracy did not improve from 0.93842\n","Epoch 179/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9163\n","\n","Epoch 00179: val_accuracy did not improve from 0.93842\n","Epoch 180/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0295 - accuracy: 0.9921 - val_loss: 1.2193 - val_accuracy: 0.8103\n","\n","Epoch 00180: val_accuracy did not improve from 0.93842\n","Epoch 181/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0853 - accuracy: 0.9695 - val_loss: 1.2306 - val_accuracy: 0.8325\n","\n","Epoch 00181: val_accuracy did not improve from 0.93842\n","Epoch 182/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0400 - accuracy: 0.9860 - val_loss: 0.5201 - val_accuracy: 0.9163\n","\n","Epoch 00182: val_accuracy did not improve from 0.93842\n","Epoch 183/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.9006 - val_accuracy: 0.8448\n","\n","Epoch 00183: val_accuracy did not improve from 0.93842\n","Epoch 184/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.6290 - val_accuracy: 0.8744\n","\n","Epoch 00184: val_accuracy did not improve from 0.93842\n","Epoch 185/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.4237 - val_accuracy: 0.9113\n","\n","Epoch 00185: val_accuracy did not improve from 0.93842\n","Epoch 186/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0661 - accuracy: 0.9872 - val_loss: 0.6748 - val_accuracy: 0.8424\n","\n","Epoch 00186: val_accuracy did not improve from 0.93842\n","Epoch 187/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0781 - accuracy: 0.9805 - val_loss: 0.8732 - val_accuracy: 0.8719\n","\n","Epoch 00187: val_accuracy did not improve from 0.93842\n","Epoch 188/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0204 - accuracy: 0.9963 - val_loss: 0.4104 - val_accuracy: 0.9236\n","\n","Epoch 00188: val_accuracy did not improve from 0.93842\n","Epoch 189/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0119 - accuracy: 0.9939 - val_loss: 0.5080 - val_accuracy: 0.8842\n","\n","Epoch 00189: val_accuracy did not improve from 0.93842\n","Epoch 190/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0220 - accuracy: 0.9963 - val_loss: 0.5365 - val_accuracy: 0.8867\n","\n","Epoch 00190: val_accuracy did not improve from 0.93842\n","Epoch 191/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0198 - accuracy: 0.9915 - val_loss: 0.6296 - val_accuracy: 0.8842\n","\n","Epoch 00191: val_accuracy did not improve from 0.93842\n","Epoch 192/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.5830 - val_accuracy: 0.8818\n","\n","Epoch 00192: val_accuracy did not improve from 0.93842\n","Epoch 193/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.4310 - val_accuracy: 0.8892\n","\n","Epoch 00193: val_accuracy did not improve from 0.93842\n","Epoch 194/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0226 - accuracy: 0.9909 - val_loss: 0.6932 - val_accuracy: 0.8596\n","\n","Epoch 00194: val_accuracy did not improve from 0.93842\n","Epoch 195/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0317 - accuracy: 0.9878 - val_loss: 0.4778 - val_accuracy: 0.8990\n","\n","Epoch 00195: val_accuracy did not improve from 0.93842\n","Epoch 196/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0233 - accuracy: 0.9945 - val_loss: 0.4037 - val_accuracy: 0.9039\n","\n","Epoch 00196: val_accuracy did not improve from 0.93842\n","Epoch 197/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.4997 - val_accuracy: 0.8941\n","\n","Epoch 00197: val_accuracy did not improve from 0.93842\n","Epoch 198/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.3697 - val_accuracy: 0.9138\n","\n","Epoch 00198: val_accuracy did not improve from 0.93842\n","Epoch 199/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4014 - val_accuracy: 0.9113\n","\n","Epoch 00199: val_accuracy did not improve from 0.93842\n","Epoch 200/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3795 - val_accuracy: 0.9113\n","\n","Epoch 00200: val_accuracy did not improve from 0.93842\n","Epoch 201/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.3876 - val_accuracy: 0.9187\n","\n","Epoch 00201: val_accuracy did not improve from 0.93842\n","Epoch 202/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.4655 - val_accuracy: 0.9113\n","\n","Epoch 00202: val_accuracy did not improve from 0.93842\n","Epoch 203/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4530 - val_accuracy: 0.9015\n","\n","Epoch 00203: val_accuracy did not improve from 0.93842\n","Epoch 204/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.9138\n","\n","Epoch 00204: val_accuracy did not improve from 0.93842\n","Epoch 205/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.4514 - val_accuracy: 0.9064\n","\n","Epoch 00205: val_accuracy did not improve from 0.93842\n","Epoch 206/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0093 - accuracy: 0.9951 - val_loss: 0.5751 - val_accuracy: 0.9089\n","\n","Epoch 00206: val_accuracy did not improve from 0.93842\n","Epoch 207/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.5372 - val_accuracy: 0.8941\n","\n","Epoch 00207: val_accuracy did not improve from 0.93842\n","Epoch 208/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.4905 - val_accuracy: 0.9113\n","\n","Epoch 00208: val_accuracy did not improve from 0.93842\n","Epoch 209/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0147 - accuracy: 0.9927 - val_loss: 0.7798 - val_accuracy: 0.8300\n","\n","Epoch 00209: val_accuracy did not improve from 0.93842\n","Epoch 210/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0115 - accuracy: 0.9988 - val_loss: 0.7454 - val_accuracy: 0.8719\n","\n","Epoch 00210: val_accuracy did not improve from 0.93842\n","Epoch 211/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0479 - accuracy: 0.9884 - val_loss: 0.8966 - val_accuracy: 0.8399\n","\n","Epoch 00211: val_accuracy did not improve from 0.93842\n","Epoch 212/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0490 - accuracy: 0.9866 - val_loss: 0.8463 - val_accuracy: 0.8325\n","\n","Epoch 00212: val_accuracy did not improve from 0.93842\n","Epoch 213/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0410 - accuracy: 0.9860 - val_loss: 0.4873 - val_accuracy: 0.8842\n","\n","Epoch 00213: val_accuracy did not improve from 0.93842\n","Epoch 214/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.4352 - val_accuracy: 0.8916\n","\n","Epoch 00214: val_accuracy did not improve from 0.93842\n","Epoch 215/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4687 - val_accuracy: 0.9015\n","\n","Epoch 00215: val_accuracy did not improve from 0.93842\n","Epoch 216/500\n","52/52 [==============================] - 11s 218ms/step - loss: 8.9643e-04 - accuracy: 1.0000 - val_loss: 0.3671 - val_accuracy: 0.9138\n","\n","Epoch 00216: val_accuracy did not improve from 0.93842\n","Epoch 217/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.9089\n","\n","Epoch 00217: val_accuracy did not improve from 0.93842\n","Epoch 218/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9113\n","\n","Epoch 00218: val_accuracy did not improve from 0.93842\n","Epoch 219/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3970 - val_accuracy: 0.9089\n","\n","Epoch 00219: val_accuracy did not improve from 0.93842\n","Epoch 220/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.9138\n","\n","Epoch 00220: val_accuracy did not improve from 0.93842\n","Epoch 221/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.9212\n","\n","Epoch 00221: val_accuracy did not improve from 0.93842\n","Epoch 222/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.5384 - val_accuracy: 0.9113\n","\n","Epoch 00222: val_accuracy did not improve from 0.93842\n","Epoch 223/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.4427 - val_accuracy: 0.9113\n","\n","Epoch 00223: val_accuracy did not improve from 0.93842\n","Epoch 224/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0127 - accuracy: 0.9933 - val_loss: 0.5173 - val_accuracy: 0.8916\n","\n","Epoch 00224: val_accuracy did not improve from 0.93842\n","Epoch 225/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0113 - accuracy: 0.9951 - val_loss: 0.5560 - val_accuracy: 0.8842\n","\n","Epoch 00225: val_accuracy did not improve from 0.93842\n","Epoch 226/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.4205 - val_accuracy: 0.9187\n","\n","Epoch 00226: val_accuracy did not improve from 0.93842\n","Epoch 227/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.9402 - val_accuracy: 0.8448\n","\n","Epoch 00227: val_accuracy did not improve from 0.93842\n","Epoch 228/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0507 - accuracy: 0.9860 - val_loss: 2.7139 - val_accuracy: 0.6502\n","\n","Epoch 00228: val_accuracy did not improve from 0.93842\n","Epoch 229/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0347 - accuracy: 0.9878 - val_loss: 0.7154 - val_accuracy: 0.8768\n","\n","Epoch 00229: val_accuracy did not improve from 0.93842\n","Epoch 230/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.5962 - val_accuracy: 0.8695\n","\n","Epoch 00230: val_accuracy did not improve from 0.93842\n","Epoch 231/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.6927 - val_accuracy: 0.8670\n","\n","Epoch 00231: val_accuracy did not improve from 0.93842\n","Epoch 232/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.6276 - val_accuracy: 0.8744\n","\n","Epoch 00232: val_accuracy did not improve from 0.93842\n","Epoch 233/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 1.0397 - val_accuracy: 0.8547\n","\n","Epoch 00233: val_accuracy did not improve from 0.93842\n","Epoch 234/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0431 - accuracy: 0.9866 - val_loss: 0.7215 - val_accuracy: 0.8768\n","\n","Epoch 00234: val_accuracy did not improve from 0.93842\n","Epoch 235/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.4914 - val_accuracy: 0.9163\n","\n","Epoch 00235: val_accuracy did not improve from 0.93842\n","Epoch 236/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4066 - val_accuracy: 0.8990\n","\n","Epoch 00236: val_accuracy did not improve from 0.93842\n","Epoch 237/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.4286 - val_accuracy: 0.9064\n","\n","Epoch 00237: val_accuracy did not improve from 0.93842\n","Epoch 238/500\n","52/52 [==============================] - 11s 217ms/step - loss: 7.8418e-04 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.9113\n","\n","Epoch 00238: val_accuracy did not improve from 0.93842\n","Epoch 239/500\n","52/52 [==============================] - 11s 220ms/step - loss: 8.2631e-04 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.9015\n","\n","Epoch 00239: val_accuracy did not improve from 0.93842\n","Epoch 240/500\n","52/52 [==============================] - 11s 216ms/step - loss: 7.3005e-04 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9089\n","\n","Epoch 00240: val_accuracy did not improve from 0.93842\n","Epoch 241/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4906 - val_accuracy: 0.9039\n","\n","Epoch 00241: val_accuracy did not improve from 0.93842\n","Epoch 242/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4369 - val_accuracy: 0.9064\n","\n","Epoch 00242: val_accuracy did not improve from 0.93842\n","Epoch 243/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4368 - val_accuracy: 0.9039\n","\n","Epoch 00243: val_accuracy did not improve from 0.93842\n","Epoch 244/500\n","52/52 [==============================] - 11s 217ms/step - loss: 5.1665e-04 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9138\n","\n","Epoch 00244: val_accuracy did not improve from 0.93842\n","Epoch 245/500\n","52/52 [==============================] - 11s 217ms/step - loss: 3.4632e-04 - accuracy: 1.0000 - val_loss: 0.3723 - val_accuracy: 0.9261\n","\n","Epoch 00245: val_accuracy did not improve from 0.93842\n","Epoch 246/500\n","52/52 [==============================] - 11s 216ms/step - loss: 5.3348e-04 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9113\n","\n","Epoch 00246: val_accuracy did not improve from 0.93842\n","Epoch 247/500\n","52/52 [==============================] - 11s 218ms/step - loss: 9.5526e-04 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.9286\n","\n","Epoch 00247: val_accuracy did not improve from 0.93842\n","Epoch 248/500\n","52/52 [==============================] - 11s 218ms/step - loss: 5.2734e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9384\n","\n","Epoch 00248: val_accuracy did not improve from 0.93842\n","Epoch 249/500\n","52/52 [==============================] - 11s 217ms/step - loss: 7.0512e-04 - accuracy: 1.0000 - val_loss: 0.3565 - val_accuracy: 0.9335\n","\n","Epoch 00249: val_accuracy did not improve from 0.93842\n","Epoch 250/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9039\n","\n","Epoch 00250: val_accuracy did not improve from 0.93842\n","Epoch 251/500\n","52/52 [==============================] - 11s 216ms/step - loss: 3.2449e-04 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9187\n","\n","Epoch 00251: val_accuracy did not improve from 0.93842\n","Epoch 252/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.8079e-04 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.9187\n","\n","Epoch 00252: val_accuracy did not improve from 0.93842\n","Epoch 253/500\n","52/52 [==============================] - 11s 218ms/step - loss: 1.5591e-04 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9212\n","\n","Epoch 00253: val_accuracy did not improve from 0.93842\n","Epoch 254/500\n","52/52 [==============================] - 11s 217ms/step - loss: 5.0566e-04 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9286\n","\n","Epoch 00254: val_accuracy did not improve from 0.93842\n","Epoch 255/500\n","52/52 [==============================] - 11s 218ms/step - loss: 3.1984e-04 - accuracy: 1.0000 - val_loss: 0.3377 - val_accuracy: 0.9236\n","\n","Epoch 00255: val_accuracy did not improve from 0.93842\n","Epoch 256/500\n","52/52 [==============================] - 11s 217ms/step - loss: 1.5934e-04 - accuracy: 1.0000 - val_loss: 0.3261 - val_accuracy: 0.9335\n","\n","Epoch 00256: val_accuracy did not improve from 0.93842\n","Epoch 257/500\n","52/52 [==============================] - 11s 218ms/step - loss: 4.7922e-04 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.9261\n","\n","Epoch 00257: val_accuracy did not improve from 0.93842\n","Epoch 258/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.2904e-04 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.9187\n","\n","Epoch 00258: val_accuracy did not improve from 0.93842\n","Epoch 259/500\n","52/52 [==============================] - 11s 216ms/step - loss: 5.9825e-04 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9187\n","\n","Epoch 00259: val_accuracy did not improve from 0.93842\n","Epoch 260/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.6240e-04 - accuracy: 1.0000 - val_loss: 0.4189 - val_accuracy: 0.9163\n","\n","Epoch 00260: val_accuracy did not improve from 0.93842\n","Epoch 261/500\n","52/52 [==============================] - 12s 236ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5466 - val_accuracy: 0.9064\n","\n","Epoch 00261: val_accuracy did not improve from 0.93842\n","Epoch 262/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0568 - accuracy: 0.9829 - val_loss: 1.0406 - val_accuracy: 0.8547\n","\n","Epoch 00262: val_accuracy did not improve from 0.93842\n","Epoch 263/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1591 - accuracy: 0.9580 - val_loss: 4.2295 - val_accuracy: 0.5616\n","\n","Epoch 00263: val_accuracy did not improve from 0.93842\n","Epoch 264/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1300 - accuracy: 0.9689 - val_loss: 0.7773 - val_accuracy: 0.8695\n","\n","Epoch 00264: val_accuracy did not improve from 0.93842\n","Epoch 265/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0435 - accuracy: 0.9872 - val_loss: 0.7871 - val_accuracy: 0.8645\n","\n","Epoch 00265: val_accuracy did not improve from 0.93842\n","Epoch 266/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 0.5369 - val_accuracy: 0.8892\n","\n","Epoch 00266: val_accuracy did not improve from 0.93842\n","Epoch 267/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.5409 - val_accuracy: 0.8818\n","\n","Epoch 00267: val_accuracy did not improve from 0.93842\n","Epoch 268/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5173 - val_accuracy: 0.9039\n","\n","Epoch 00268: val_accuracy did not improve from 0.93842\n","Epoch 269/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.4759 - val_accuracy: 0.9163\n","\n","Epoch 00269: val_accuracy did not improve from 0.93842\n","Epoch 270/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.6009 - val_accuracy: 0.8966\n","\n","Epoch 00270: val_accuracy did not improve from 0.93842\n","Epoch 271/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3908 - val_accuracy: 0.9138\n","\n","Epoch 00271: val_accuracy did not improve from 0.93842\n","Epoch 272/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0428 - accuracy: 0.9890 - val_loss: 0.5990 - val_accuracy: 0.8842\n","\n","Epoch 00272: val_accuracy did not improve from 0.93842\n","Epoch 273/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.5859 - val_accuracy: 0.8768\n","\n","Epoch 00273: val_accuracy did not improve from 0.93842\n","Epoch 274/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5124 - val_accuracy: 0.8966\n","\n","Epoch 00274: val_accuracy did not improve from 0.93842\n","Epoch 275/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.4164 - val_accuracy: 0.9064\n","\n","Epoch 00275: val_accuracy did not improve from 0.93842\n","Epoch 276/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.4974 - val_accuracy: 0.9039\n","\n","Epoch 00276: val_accuracy did not improve from 0.93842\n","Epoch 277/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4252 - val_accuracy: 0.9138\n","\n","Epoch 00277: val_accuracy did not improve from 0.93842\n","Epoch 278/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4163 - val_accuracy: 0.9039\n","\n","Epoch 00278: val_accuracy did not improve from 0.93842\n","Epoch 279/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 0.3854 - val_accuracy: 0.9089\n","\n","Epoch 00279: val_accuracy did not improve from 0.93842\n","Epoch 280/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.9113\n","\n","Epoch 00280: val_accuracy did not improve from 0.93842\n","Epoch 281/500\n","52/52 [==============================] - 11s 218ms/step - loss: 5.1356e-04 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.9089\n","\n","Epoch 00281: val_accuracy did not improve from 0.93842\n","Epoch 282/500\n","52/52 [==============================] - 11s 218ms/step - loss: 7.1589e-04 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.9163\n","\n","Epoch 00282: val_accuracy did not improve from 0.93842\n","Epoch 283/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5139 - val_accuracy: 0.9015\n","\n","Epoch 00283: val_accuracy did not improve from 0.93842\n","Epoch 284/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.7507 - val_accuracy: 0.8719\n","\n","Epoch 00284: val_accuracy did not improve from 0.93842\n","Epoch 285/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5964 - val_accuracy: 0.8818\n","\n","Epoch 00285: val_accuracy did not improve from 0.93842\n","Epoch 286/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.5136 - val_accuracy: 0.9015\n","\n","Epoch 00286: val_accuracy did not improve from 0.93842\n","Epoch 287/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4954 - val_accuracy: 0.9187\n","\n","Epoch 00287: val_accuracy did not improve from 0.93842\n","Epoch 288/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0254 - accuracy: 0.9909 - val_loss: 0.5898 - val_accuracy: 0.8842\n","\n","Epoch 00288: val_accuracy did not improve from 0.93842\n","Epoch 289/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0158 - accuracy: 0.9939 - val_loss: 0.7362 - val_accuracy: 0.8793\n","\n","Epoch 00289: val_accuracy did not improve from 0.93842\n","Epoch 290/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.5824 - val_accuracy: 0.8966\n","\n","Epoch 00290: val_accuracy did not improve from 0.93842\n","Epoch 291/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4634 - val_accuracy: 0.8990\n","\n","Epoch 00291: val_accuracy did not improve from 0.93842\n","Epoch 292/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5250 - val_accuracy: 0.8990\n","\n","Epoch 00292: val_accuracy did not improve from 0.93842\n","Epoch 293/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5303 - val_accuracy: 0.9064\n","\n","Epoch 00293: val_accuracy did not improve from 0.93842\n","Epoch 294/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4433 - val_accuracy: 0.9089\n","\n","Epoch 00294: val_accuracy did not improve from 0.93842\n","Epoch 295/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.7101 - val_accuracy: 0.8966\n","\n","Epoch 00295: val_accuracy did not improve from 0.93842\n","Epoch 296/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.5637 - val_accuracy: 0.8941\n","\n","Epoch 00296: val_accuracy did not improve from 0.93842\n","Epoch 297/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.9212\n","\n","Epoch 00297: val_accuracy did not improve from 0.93842\n","Epoch 298/500\n","52/52 [==============================] - 11s 219ms/step - loss: 7.9047e-04 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.9138\n","\n","Epoch 00298: val_accuracy did not improve from 0.93842\n","Epoch 299/500\n","52/52 [==============================] - 11s 217ms/step - loss: 3.9503e-04 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.9187\n","\n","Epoch 00299: val_accuracy did not improve from 0.93842\n","Epoch 300/500\n","52/52 [==============================] - 11s 218ms/step - loss: 4.0249e-04 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.9212\n","\n","Epoch 00300: val_accuracy did not improve from 0.93842\n","Epoch 301/500\n","52/52 [==============================] - 11s 219ms/step - loss: 4.2022e-04 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.9113\n","\n","Epoch 00301: val_accuracy did not improve from 0.93842\n","Epoch 302/500\n","52/52 [==============================] - 11s 219ms/step - loss: 3.6257e-04 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.9138\n","\n","Epoch 00302: val_accuracy did not improve from 0.93842\n","Epoch 303/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.7812 - val_accuracy: 0.8793\n","\n","Epoch 00303: val_accuracy did not improve from 0.93842\n","Epoch 304/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1307 - accuracy: 0.9653 - val_loss: 0.7814 - val_accuracy: 0.8498\n","\n","Epoch 00304: val_accuracy did not improve from 0.93842\n","Epoch 305/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.7674 - val_accuracy: 0.8719\n","\n","Epoch 00305: val_accuracy did not improve from 0.93842\n","Epoch 306/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0115 - accuracy: 0.9951 - val_loss: 0.6202 - val_accuracy: 0.8744\n","\n","Epoch 00306: val_accuracy did not improve from 0.93842\n","Epoch 307/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.4046 - val_accuracy: 0.9089\n","\n","Epoch 00307: val_accuracy did not improve from 0.93842\n","Epoch 308/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.5548 - val_accuracy: 0.9113\n","\n","Epoch 00308: val_accuracy did not improve from 0.93842\n","Epoch 309/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4916 - val_accuracy: 0.9089\n","\n","Epoch 00309: val_accuracy did not improve from 0.93842\n","Epoch 310/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4847 - val_accuracy: 0.9113\n","\n","Epoch 00310: val_accuracy did not improve from 0.93842\n","Epoch 311/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0405 - accuracy: 0.9878 - val_loss: 1.0241 - val_accuracy: 0.8424\n","\n","Epoch 00311: val_accuracy did not improve from 0.93842\n","Epoch 312/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.5032 - val_accuracy: 0.8966\n","\n","Epoch 00312: val_accuracy did not improve from 0.93842\n","Epoch 313/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.5768 - val_accuracy: 0.8990\n","\n","Epoch 00313: val_accuracy did not improve from 0.93842\n","Epoch 314/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0307 - accuracy: 0.9933 - val_loss: 0.5393 - val_accuracy: 0.9039\n","\n","Epoch 00314: val_accuracy did not improve from 0.93842\n","Epoch 315/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.6855 - val_accuracy: 0.8670\n","\n","Epoch 00315: val_accuracy did not improve from 0.93842\n","Epoch 316/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.4637 - val_accuracy: 0.9064\n","\n","Epoch 00316: val_accuracy did not improve from 0.93842\n","Epoch 317/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4327 - val_accuracy: 0.9212\n","\n","Epoch 00317: val_accuracy did not improve from 0.93842\n","Epoch 318/500\n","52/52 [==============================] - 11s 218ms/step - loss: 9.8365e-04 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.9261\n","\n","Epoch 00318: val_accuracy did not improve from 0.93842\n","Epoch 319/500\n","52/52 [==============================] - 11s 217ms/step - loss: 8.7407e-04 - accuracy: 1.0000 - val_loss: 0.4757 - val_accuracy: 0.9113\n","\n","Epoch 00319: val_accuracy did not improve from 0.93842\n","Epoch 320/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.5819 - val_accuracy: 0.9089\n","\n","Epoch 00320: val_accuracy did not improve from 0.93842\n","Epoch 321/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5633 - val_accuracy: 0.8892\n","\n","Epoch 00321: val_accuracy did not improve from 0.93842\n","Epoch 322/500\n","52/52 [==============================] - 11s 217ms/step - loss: 5.7638e-04 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.9138\n","\n","Epoch 00322: val_accuracy did not improve from 0.93842\n","Epoch 323/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.6547 - val_accuracy: 0.8842\n","\n","Epoch 00323: val_accuracy did not improve from 0.93842\n","Epoch 324/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5037 - val_accuracy: 0.8966\n","\n","Epoch 00324: val_accuracy did not improve from 0.93842\n","Epoch 325/500\n","52/52 [==============================] - 12s 220ms/step - loss: 5.6815e-04 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.9113\n","\n","Epoch 00325: val_accuracy did not improve from 0.93842\n","Epoch 326/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.5913 - val_accuracy: 0.8941\n","\n","Epoch 00326: val_accuracy did not improve from 0.93842\n","Epoch 327/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0521 - accuracy: 0.9848 - val_loss: 1.2879 - val_accuracy: 0.8202\n","\n","Epoch 00327: val_accuracy did not improve from 0.93842\n","Epoch 328/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.9627 - val_accuracy: 0.8399\n","\n","Epoch 00328: val_accuracy did not improve from 0.93842\n","Epoch 329/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0265 - accuracy: 0.9884 - val_loss: 0.4581 - val_accuracy: 0.9113\n","\n","Epoch 00329: val_accuracy did not improve from 0.93842\n","Epoch 330/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.4419 - val_accuracy: 0.9113\n","\n","Epoch 00330: val_accuracy did not improve from 0.93842\n","Epoch 331/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.4688 - val_accuracy: 0.9089\n","\n","Epoch 00331: val_accuracy did not improve from 0.93842\n","Epoch 332/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4616 - val_accuracy: 0.9015\n","\n","Epoch 00332: val_accuracy did not improve from 0.93842\n","Epoch 333/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.8990\n","\n","Epoch 00333: val_accuracy did not improve from 0.93842\n","Epoch 334/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4466 - val_accuracy: 0.8990\n","\n","Epoch 00334: val_accuracy did not improve from 0.93842\n","Epoch 335/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.9113\n","\n","Epoch 00335: val_accuracy did not improve from 0.93842\n","Epoch 336/500\n","52/52 [==============================] - 11s 217ms/step - loss: 9.6086e-04 - accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.9138\n","\n","Epoch 00336: val_accuracy did not improve from 0.93842\n","Epoch 337/500\n","52/52 [==============================] - 11s 219ms/step - loss: 5.2793e-04 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.9187\n","\n","Epoch 00337: val_accuracy did not improve from 0.93842\n","Epoch 338/500\n","52/52 [==============================] - 11s 219ms/step - loss: 5.2862e-04 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9212\n","\n","Epoch 00338: val_accuracy did not improve from 0.93842\n","Epoch 339/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.5413 - val_accuracy: 0.9039\n","\n","Epoch 00339: val_accuracy did not improve from 0.93842\n","Epoch 340/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.5448 - val_accuracy: 0.9064\n","\n","Epoch 00340: val_accuracy did not improve from 0.93842\n","Epoch 341/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.6226 - val_accuracy: 0.8941\n","\n","Epoch 00341: val_accuracy did not improve from 0.93842\n","Epoch 342/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.4465 - val_accuracy: 0.9138\n","\n","Epoch 00342: val_accuracy did not improve from 0.93842\n","Epoch 343/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.6273 - val_accuracy: 0.8892\n","\n","Epoch 00343: val_accuracy did not improve from 0.93842\n","Epoch 344/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4432 - val_accuracy: 0.9015\n","\n","Epoch 00344: val_accuracy did not improve from 0.93842\n","Epoch 345/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5314 - val_accuracy: 0.9015\n","\n","Epoch 00345: val_accuracy did not improve from 0.93842\n","Epoch 346/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.5783 - val_accuracy: 0.9064\n","\n","Epoch 00346: val_accuracy did not improve from 0.93842\n","Epoch 347/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 0.4711 - val_accuracy: 0.9187\n","\n","Epoch 00347: val_accuracy did not improve from 0.93842\n","Epoch 348/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4302 - val_accuracy: 0.9015\n","\n","Epoch 00348: val_accuracy did not improve from 0.93842\n","Epoch 349/500\n","52/52 [==============================] - 11s 220ms/step - loss: 7.4700e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9187\n","\n","Epoch 00349: val_accuracy did not improve from 0.93842\n","Epoch 350/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.9605e-04 - accuracy: 1.0000 - val_loss: 0.4561 - val_accuracy: 0.9138\n","\n","Epoch 00350: val_accuracy did not improve from 0.93842\n","Epoch 351/500\n","52/52 [==============================] - 11s 219ms/step - loss: 7.5814e-04 - accuracy: 1.0000 - val_loss: 0.4805 - val_accuracy: 0.9039\n","\n","Epoch 00351: val_accuracy did not improve from 0.93842\n","Epoch 352/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.6780 - val_accuracy: 0.8966\n","\n","Epoch 00352: val_accuracy did not improve from 0.93842\n","Epoch 353/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5581 - val_accuracy: 0.9089\n","\n","Epoch 00353: val_accuracy did not improve from 0.93842\n","Epoch 354/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6278 - val_accuracy: 0.8818\n","\n","Epoch 00354: val_accuracy did not improve from 0.93842\n","Epoch 355/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.9089\n","\n","Epoch 00355: val_accuracy did not improve from 0.93842\n","Epoch 356/500\n","52/52 [==============================] - 11s 218ms/step - loss: 5.0539e-04 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.9138\n","\n","Epoch 00356: val_accuracy did not improve from 0.93842\n","Epoch 357/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.4916 - val_accuracy: 0.8941\n","\n","Epoch 00357: val_accuracy did not improve from 0.93842\n","Epoch 358/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5226 - val_accuracy: 0.9113\n","\n","Epoch 00358: val_accuracy did not improve from 0.93842\n","Epoch 359/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6198 - val_accuracy: 0.9064\n","\n","Epoch 00359: val_accuracy did not improve from 0.93842\n","Epoch 360/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.8775 - val_accuracy: 0.8719\n","\n","Epoch 00360: val_accuracy did not improve from 0.93842\n","Epoch 361/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0355 - accuracy: 0.9878 - val_loss: 0.9049 - val_accuracy: 0.8424\n","\n","Epoch 00361: val_accuracy did not improve from 0.93842\n","Epoch 362/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0367 - accuracy: 0.9860 - val_loss: 0.6096 - val_accuracy: 0.8818\n","\n","Epoch 00362: val_accuracy did not improve from 0.93842\n","Epoch 363/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.5451 - val_accuracy: 0.9138\n","\n","Epoch 00363: val_accuracy did not improve from 0.93842\n","Epoch 364/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.4985 - val_accuracy: 0.9089\n","\n","Epoch 00364: val_accuracy did not improve from 0.93842\n","Epoch 365/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.9163\n","\n","Epoch 00365: val_accuracy did not improve from 0.93842\n","Epoch 366/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.8990\n","\n","Epoch 00366: val_accuracy did not improve from 0.93842\n","Epoch 367/500\n","52/52 [==============================] - 11s 219ms/step - loss: 8.1230e-04 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.9138\n","\n","Epoch 00367: val_accuracy did not improve from 0.93842\n","Epoch 368/500\n","52/52 [==============================] - 12s 221ms/step - loss: 6.2447e-04 - accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 0.9187\n","\n","Epoch 00368: val_accuracy did not improve from 0.93842\n","Epoch 369/500\n","52/52 [==============================] - 12s 220ms/step - loss: 8.1246e-04 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9064\n","\n","Epoch 00369: val_accuracy did not improve from 0.93842\n","Epoch 370/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5417 - val_accuracy: 0.9064\n","\n","Epoch 00370: val_accuracy did not improve from 0.93842\n","Epoch 371/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9089\n","\n","Epoch 00371: val_accuracy did not improve from 0.93842\n","Epoch 372/500\n","52/52 [==============================] - 11s 219ms/step - loss: 4.1276e-04 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.9212\n","\n","Epoch 00372: val_accuracy did not improve from 0.93842\n","Epoch 373/500\n","52/52 [==============================] - 12s 220ms/step - loss: 2.5057e-04 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.9039\n","\n","Epoch 00373: val_accuracy did not improve from 0.93842\n","Epoch 374/500\n","52/52 [==============================] - 12s 221ms/step - loss: 8.8214e-04 - accuracy: 1.0000 - val_loss: 0.5187 - val_accuracy: 0.8941\n","\n","Epoch 00374: val_accuracy did not improve from 0.93842\n","Epoch 375/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 1.4169 - val_accuracy: 0.7906\n","\n","Epoch 00375: val_accuracy did not improve from 0.93842\n","Epoch 376/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0577 - accuracy: 0.9823 - val_loss: 1.0690 - val_accuracy: 0.8276\n","\n","Epoch 00376: val_accuracy did not improve from 0.93842\n","Epoch 377/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0474 - accuracy: 0.9866 - val_loss: 1.0251 - val_accuracy: 0.8424\n","\n","Epoch 00377: val_accuracy did not improve from 0.93842\n","Epoch 378/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0181 - accuracy: 0.9927 - val_loss: 0.7368 - val_accuracy: 0.8892\n","\n","Epoch 00378: val_accuracy did not improve from 0.93842\n","Epoch 379/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0108 - accuracy: 0.9945 - val_loss: 0.6674 - val_accuracy: 0.8818\n","\n","Epoch 00379: val_accuracy did not improve from 0.93842\n","Epoch 380/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.5257 - val_accuracy: 0.9089\n","\n","Epoch 00380: val_accuracy did not improve from 0.93842\n","Epoch 381/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.7341 - val_accuracy: 0.8916\n","\n","Epoch 00381: val_accuracy did not improve from 0.93842\n","Epoch 382/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.6517 - val_accuracy: 0.8867\n","\n","Epoch 00382: val_accuracy did not improve from 0.93842\n","Epoch 383/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.5854 - val_accuracy: 0.8990\n","\n","Epoch 00383: val_accuracy did not improve from 0.93842\n","Epoch 384/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5043 - val_accuracy: 0.9039\n","\n","Epoch 00384: val_accuracy did not improve from 0.93842\n","Epoch 385/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.6475 - val_accuracy: 0.8842\n","\n","Epoch 00385: val_accuracy did not improve from 0.93842\n","Epoch 386/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.6012 - val_accuracy: 0.9015\n","\n","Epoch 00386: val_accuracy did not improve from 0.93842\n","Epoch 387/500\n","52/52 [==============================] - 12s 220ms/step - loss: 6.5620e-04 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.8941\n","\n","Epoch 00387: val_accuracy did not improve from 0.93842\n","Epoch 388/500\n","52/52 [==============================] - 11s 219ms/step - loss: 5.4952e-04 - accuracy: 1.0000 - val_loss: 0.5351 - val_accuracy: 0.9064\n","\n","Epoch 00388: val_accuracy did not improve from 0.93842\n","Epoch 389/500\n","52/52 [==============================] - 12s 221ms/step - loss: 6.6661e-04 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9113\n","\n","Epoch 00389: val_accuracy did not improve from 0.93842\n","Epoch 390/500\n","52/52 [==============================] - 12s 220ms/step - loss: 2.6590e-04 - accuracy: 1.0000 - val_loss: 0.5039 - val_accuracy: 0.9138\n","\n","Epoch 00390: val_accuracy did not improve from 0.93842\n","Epoch 391/500\n","52/52 [==============================] - 11s 220ms/step - loss: 2.2935e-04 - accuracy: 1.0000 - val_loss: 0.5271 - val_accuracy: 0.9039\n","\n","Epoch 00391: val_accuracy did not improve from 0.93842\n","Epoch 392/500\n","52/52 [==============================] - 11s 220ms/step - loss: 3.6497e-04 - accuracy: 1.0000 - val_loss: 0.5423 - val_accuracy: 0.9064\n","\n","Epoch 00392: val_accuracy did not improve from 0.93842\n","Epoch 393/500\n","52/52 [==============================] - 12s 221ms/step - loss: 4.9143e-04 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9163\n","\n","Epoch 00393: val_accuracy did not improve from 0.93842\n","Epoch 394/500\n","52/52 [==============================] - 11s 217ms/step - loss: 3.7857e-04 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.9236\n","\n","Epoch 00394: val_accuracy did not improve from 0.93842\n","Epoch 395/500\n","52/52 [==============================] - 12s 220ms/step - loss: 3.4212e-04 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.9335\n","\n","Epoch 00395: val_accuracy did not improve from 0.93842\n","Epoch 396/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0266 - accuracy: 0.9933 - val_loss: 0.9950 - val_accuracy: 0.8522\n","\n","Epoch 00396: val_accuracy did not improve from 0.93842\n","Epoch 397/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.7604 - val_accuracy: 0.8842\n","\n","Epoch 00397: val_accuracy did not improve from 0.93842\n","Epoch 398/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.5843 - val_accuracy: 0.8941\n","\n","Epoch 00398: val_accuracy did not improve from 0.93842\n","Epoch 399/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.5205 - val_accuracy: 0.9113\n","\n","Epoch 00399: val_accuracy did not improve from 0.93842\n","Epoch 400/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.5996 - val_accuracy: 0.9015\n","\n","Epoch 00400: val_accuracy did not improve from 0.93842\n","Epoch 401/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.5265 - val_accuracy: 0.8966\n","\n","Epoch 00401: val_accuracy did not improve from 0.93842\n","Epoch 402/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0111 - accuracy: 0.9994 - val_loss: 0.6502 - val_accuracy: 0.9015\n","\n","Epoch 00402: val_accuracy did not improve from 0.93842\n","Epoch 403/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5170 - val_accuracy: 0.9113\n","\n","Epoch 00403: val_accuracy did not improve from 0.93842\n","Epoch 404/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5849 - val_accuracy: 0.8941\n","\n","Epoch 00404: val_accuracy did not improve from 0.93842\n","Epoch 405/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.5630 - val_accuracy: 0.8966\n","\n","Epoch 00405: val_accuracy did not improve from 0.93842\n","Epoch 406/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.7124 - val_accuracy: 0.8842\n","\n","Epoch 00406: val_accuracy did not improve from 0.93842\n","Epoch 407/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.6886 - val_accuracy: 0.8842\n","\n","Epoch 00407: val_accuracy did not improve from 0.93842\n","Epoch 408/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.4667 - val_accuracy: 0.9015\n","\n","Epoch 00408: val_accuracy did not improve from 0.93842\n","Epoch 409/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.4725 - val_accuracy: 0.9113\n","\n","Epoch 00409: val_accuracy did not improve from 0.93842\n","Epoch 410/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0447 - accuracy: 0.9921 - val_loss: 0.4378 - val_accuracy: 0.9064\n","\n","Epoch 00410: val_accuracy did not improve from 0.93842\n","Epoch 411/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.5168 - val_accuracy: 0.8990\n","\n","Epoch 00411: val_accuracy did not improve from 0.93842\n","Epoch 412/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.5349 - val_accuracy: 0.8867\n","\n","Epoch 00412: val_accuracy did not improve from 0.93842\n","Epoch 413/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 0.5203 - val_accuracy: 0.9089\n","\n","Epoch 00413: val_accuracy did not improve from 0.93842\n","Epoch 414/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4608 - val_accuracy: 0.9113\n","\n","Epoch 00414: val_accuracy did not improve from 0.93842\n","Epoch 415/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 0.4037 - val_accuracy: 0.9064\n","\n","Epoch 00415: val_accuracy did not improve from 0.93842\n","Epoch 416/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9236\n","\n","Epoch 00416: val_accuracy did not improve from 0.93842\n","Epoch 417/500\n","52/52 [==============================] - 11s 219ms/step - loss: 6.6459e-04 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.9187\n","\n","Epoch 00417: val_accuracy did not improve from 0.93842\n","Epoch 418/500\n","52/52 [==============================] - 12s 220ms/step - loss: 3.6387e-04 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.9163\n","\n","Epoch 00418: val_accuracy did not improve from 0.93842\n","Epoch 419/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.7088 - val_accuracy: 0.8867\n","\n","Epoch 00419: val_accuracy did not improve from 0.93842\n","Epoch 420/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.6760 - val_accuracy: 0.8892\n","\n","Epoch 00420: val_accuracy did not improve from 0.93842\n","Epoch 421/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4845 - val_accuracy: 0.9064\n","\n","Epoch 00421: val_accuracy did not improve from 0.93842\n","Epoch 422/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5018 - val_accuracy: 0.8941\n","\n","Epoch 00422: val_accuracy did not improve from 0.93842\n","Epoch 423/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.9089\n","\n","Epoch 00423: val_accuracy did not improve from 0.93842\n","Epoch 424/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4464 - val_accuracy: 0.9187\n","\n","Epoch 00424: val_accuracy did not improve from 0.93842\n","Epoch 425/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.5553 - val_accuracy: 0.8842\n","\n","Epoch 00425: val_accuracy did not improve from 0.93842\n","Epoch 426/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4775 - val_accuracy: 0.9138\n","\n","Epoch 00426: val_accuracy did not improve from 0.93842\n","Epoch 427/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5561 - val_accuracy: 0.9015\n","\n","Epoch 00427: val_accuracy did not improve from 0.93842\n","Epoch 428/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5675 - val_accuracy: 0.9138\n","\n","Epoch 00428: val_accuracy did not improve from 0.93842\n","Epoch 429/500\n","52/52 [==============================] - 11s 219ms/step - loss: 4.1596e-04 - accuracy: 1.0000 - val_loss: 0.5139 - val_accuracy: 0.9163\n","\n","Epoch 00429: val_accuracy did not improve from 0.93842\n","Epoch 430/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.0746e-04 - accuracy: 1.0000 - val_loss: 0.4781 - val_accuracy: 0.9113\n","\n","Epoch 00430: val_accuracy did not improve from 0.93842\n","Epoch 431/500\n","52/52 [==============================] - 11s 218ms/step - loss: 3.9013e-04 - accuracy: 1.0000 - val_loss: 0.4528 - val_accuracy: 0.9187\n","\n","Epoch 00431: val_accuracy did not improve from 0.93842\n","Epoch 432/500\n","52/52 [==============================] - 12s 220ms/step - loss: 1.8232e-04 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.9015\n","\n","Epoch 00432: val_accuracy did not improve from 0.93842\n","Epoch 433/500\n","52/52 [==============================] - 12s 220ms/step - loss: 1.1693e-04 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.9163\n","\n","Epoch 00433: val_accuracy did not improve from 0.93842\n","Epoch 434/500\n","52/52 [==============================] - 11s 219ms/step - loss: 3.1157e-04 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9236\n","\n","Epoch 00434: val_accuracy did not improve from 0.93842\n","Epoch 435/500\n","52/52 [==============================] - 11s 220ms/step - loss: 2.8026e-04 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.9261\n","\n","Epoch 00435: val_accuracy did not improve from 0.93842\n","Epoch 436/500\n","52/52 [==============================] - 12s 220ms/step - loss: 8.2098e-04 - accuracy: 0.9994 - val_loss: 0.7285 - val_accuracy: 0.8842\n","\n","Epoch 00436: val_accuracy did not improve from 0.93842\n","Epoch 437/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 1.0639 - val_accuracy: 0.8670\n","\n","Epoch 00437: val_accuracy did not improve from 0.93842\n","Epoch 438/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.6498 - val_accuracy: 0.8941\n","\n","Epoch 00438: val_accuracy did not improve from 0.93842\n","Epoch 439/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.8201 - val_accuracy: 0.8793\n","\n","Epoch 00439: val_accuracy did not improve from 0.93842\n","Epoch 440/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.7053 - val_accuracy: 0.8793\n","\n","Epoch 00440: val_accuracy did not improve from 0.93842\n","Epoch 441/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.7005 - val_accuracy: 0.8966\n","\n","Epoch 00441: val_accuracy did not improve from 0.93842\n","Epoch 442/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.6015 - val_accuracy: 0.8941\n","\n","Epoch 00442: val_accuracy did not improve from 0.93842\n","Epoch 443/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.5703 - val_accuracy: 0.9064\n","\n","Epoch 00443: val_accuracy did not improve from 0.93842\n","Epoch 444/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.7446 - val_accuracy: 0.8916\n","\n","Epoch 00444: val_accuracy did not improve from 0.93842\n","Epoch 445/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.7756 - val_accuracy: 0.8744\n","\n","Epoch 00445: val_accuracy did not improve from 0.93842\n","Epoch 446/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8867\n","\n","Epoch 00446: val_accuracy did not improve from 0.93842\n","Epoch 447/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4716 - val_accuracy: 0.8990\n","\n","Epoch 00447: val_accuracy did not improve from 0.93842\n","Epoch 448/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9187\n","\n","Epoch 00448: val_accuracy did not improve from 0.93842\n","Epoch 449/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4319 - val_accuracy: 0.9187\n","\n","Epoch 00449: val_accuracy did not improve from 0.93842\n","Epoch 450/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4559 - val_accuracy: 0.9187\n","\n","Epoch 00450: val_accuracy did not improve from 0.93842\n","Epoch 451/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0046 - accuracy: 0.9976 - val_loss: 0.4367 - val_accuracy: 0.9064\n","\n","Epoch 00451: val_accuracy did not improve from 0.93842\n","Epoch 452/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.9261\n","\n","Epoch 00452: val_accuracy did not improve from 0.93842\n","Epoch 453/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3631 - val_accuracy: 0.9335\n","\n","Epoch 00453: val_accuracy did not improve from 0.93842\n","Epoch 454/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.3983 - val_accuracy: 0.9360\n","\n","Epoch 00454: val_accuracy did not improve from 0.93842\n","Epoch 455/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9187\n","\n","Epoch 00455: val_accuracy did not improve from 0.93842\n","Epoch 456/500\n","52/52 [==============================] - 11s 220ms/step - loss: 3.6058e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.9236\n","\n","Epoch 00456: val_accuracy did not improve from 0.93842\n","Epoch 457/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4539 - val_accuracy: 0.9089\n","\n","Epoch 00457: val_accuracy did not improve from 0.93842\n","Epoch 458/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5494 - val_accuracy: 0.9015\n","\n","Epoch 00458: val_accuracy did not improve from 0.93842\n","Epoch 459/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.6843 - val_accuracy: 0.8941\n","\n","Epoch 00459: val_accuracy did not improve from 0.93842\n","Epoch 460/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.6103 - val_accuracy: 0.8990\n","\n","Epoch 00460: val_accuracy did not improve from 0.93842\n","Epoch 461/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.6877 - val_accuracy: 0.8941\n","\n","Epoch 00461: val_accuracy did not improve from 0.93842\n","Epoch 462/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.8744 - val_accuracy: 0.8596\n","\n","Epoch 00462: val_accuracy did not improve from 0.93842\n","Epoch 463/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.5789 - val_accuracy: 0.9015\n","\n","Epoch 00463: val_accuracy did not improve from 0.93842\n","Epoch 464/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0262 - accuracy: 0.9903 - val_loss: 0.9819 - val_accuracy: 0.8645\n","\n","Epoch 00464: val_accuracy did not improve from 0.93842\n","Epoch 465/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0242 - accuracy: 0.9951 - val_loss: 0.6092 - val_accuracy: 0.9064\n","\n","Epoch 00465: val_accuracy did not improve from 0.93842\n","Epoch 466/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5620 - val_accuracy: 0.9015\n","\n","Epoch 00466: val_accuracy did not improve from 0.93842\n","Epoch 467/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.4283 - val_accuracy: 0.9335\n","\n","Epoch 00467: val_accuracy did not improve from 0.93842\n","Epoch 468/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.4598 - val_accuracy: 0.9089\n","\n","Epoch 00468: val_accuracy did not improve from 0.93842\n","Epoch 469/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.6031 - val_accuracy: 0.8892\n","\n","Epoch 00469: val_accuracy did not improve from 0.93842\n","Epoch 470/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.6318 - val_accuracy: 0.8941\n","\n","Epoch 00470: val_accuracy did not improve from 0.93842\n","Epoch 471/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.9187\n","\n","Epoch 00471: val_accuracy did not improve from 0.93842\n","Epoch 472/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4787 - val_accuracy: 0.9138\n","\n","Epoch 00472: val_accuracy did not improve from 0.93842\n","Epoch 473/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.4593 - val_accuracy: 0.9089\n","\n","Epoch 00473: val_accuracy did not improve from 0.93842\n","Epoch 474/500\n","52/52 [==============================] - 12s 221ms/step - loss: 5.7395e-04 - accuracy: 1.0000 - val_loss: 0.4801 - val_accuracy: 0.9163\n","\n","Epoch 00474: val_accuracy did not improve from 0.93842\n","Epoch 475/500\n","52/52 [==============================] - 12s 220ms/step - loss: 2.6696e-04 - accuracy: 1.0000 - val_loss: 0.4416 - val_accuracy: 0.9212\n","\n","Epoch 00475: val_accuracy did not improve from 0.93842\n","Epoch 476/500\n","52/52 [==============================] - 12s 222ms/step - loss: 2.5319e-04 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9187\n","\n","Epoch 00476: val_accuracy did not improve from 0.93842\n","Epoch 477/500\n","52/52 [==============================] - 12s 222ms/step - loss: 2.2777e-04 - accuracy: 1.0000 - val_loss: 0.4811 - val_accuracy: 0.9039\n","\n","Epoch 00477: val_accuracy did not improve from 0.93842\n","Epoch 478/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.5132 - val_accuracy: 0.9163\n","\n","Epoch 00478: val_accuracy did not improve from 0.93842\n","Epoch 479/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.3875 - val_accuracy: 0.9163\n","\n","Epoch 00479: val_accuracy did not improve from 0.93842\n","Epoch 480/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.7591 - val_accuracy: 0.8941\n","\n","Epoch 00480: val_accuracy did not improve from 0.93842\n","Epoch 481/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.6927 - val_accuracy: 0.8793\n","\n","Epoch 00481: val_accuracy did not improve from 0.93842\n","Epoch 482/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0588 - accuracy: 0.9872 - val_loss: 4.7737 - val_accuracy: 0.5961\n","\n","Epoch 00482: val_accuracy did not improve from 0.93842\n","Epoch 483/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0489 - accuracy: 0.9829 - val_loss: 1.4750 - val_accuracy: 0.7734\n","\n","Epoch 00483: val_accuracy did not improve from 0.93842\n","Epoch 484/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0318 - accuracy: 0.9909 - val_loss: 0.4961 - val_accuracy: 0.8941\n","\n","Epoch 00484: val_accuracy did not improve from 0.93842\n","Epoch 485/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.3986 - val_accuracy: 0.9138\n","\n","Epoch 00485: val_accuracy did not improve from 0.93842\n","Epoch 486/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.4194 - val_accuracy: 0.9113\n","\n","Epoch 00486: val_accuracy did not improve from 0.93842\n","Epoch 487/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4101 - val_accuracy: 0.9236\n","\n","Epoch 00487: val_accuracy did not improve from 0.93842\n","Epoch 488/500\n","52/52 [==============================] - 12s 222ms/step - loss: 7.5617e-04 - accuracy: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.9089\n","\n","Epoch 00488: val_accuracy did not improve from 0.93842\n","Epoch 489/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.3780 - val_accuracy: 0.9286\n","\n","Epoch 00489: val_accuracy did not improve from 0.93842\n","Epoch 490/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3713 - val_accuracy: 0.9286\n","\n","Epoch 00490: val_accuracy did not improve from 0.93842\n","Epoch 491/500\n","52/52 [==============================] - 12s 222ms/step - loss: 5.6689e-04 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.9286\n","\n","Epoch 00491: val_accuracy did not improve from 0.93842\n","Epoch 492/500\n","52/52 [==============================] - 12s 223ms/step - loss: 4.9768e-04 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9310\n","\n","Epoch 00492: val_accuracy did not improve from 0.93842\n","Epoch 493/500\n","52/52 [==============================] - 12s 221ms/step - loss: 5.1755e-04 - accuracy: 1.0000 - val_loss: 0.3711 - val_accuracy: 0.9335\n","\n","Epoch 00493: val_accuracy did not improve from 0.93842\n","Epoch 494/500\n","52/52 [==============================] - 12s 223ms/step - loss: 1.9765e-04 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9286\n","\n","Epoch 00494: val_accuracy did not improve from 0.93842\n","Epoch 495/500\n","52/52 [==============================] - 12s 222ms/step - loss: 2.4193e-04 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9433\n","\n","Epoch 00495: val_accuracy improved from 0.93842 to 0.94335, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 496/500\n","52/52 [==============================] - 12s 224ms/step - loss: 1.5685e-04 - accuracy: 1.0000 - val_loss: 0.3365 - val_accuracy: 0.9335\n","\n","Epoch 00496: val_accuracy did not improve from 0.94335\n","Epoch 497/500\n","52/52 [==============================] - 12s 221ms/step - loss: 1.7302e-04 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.9409\n","\n","Epoch 00497: val_accuracy did not improve from 0.94335\n","Epoch 498/500\n","52/52 [==============================] - 12s 223ms/step - loss: 7.6343e-04 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9236\n","\n","Epoch 00498: val_accuracy did not improve from 0.94335\n","Epoch 499/500\n","52/52 [==============================] - 12s 221ms/step - loss: 1.3873e-04 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9458\n","\n","Epoch 00499: val_accuracy improved from 0.94335 to 0.94581, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5\n","Epoch 500/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0359 - accuracy: 0.9909 - val_loss: 1.6613 - val_accuracy: 0.7783\n","\n","Epoch 00500: val_accuracy did not improve from 0.94581\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb8a032cfd0>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1630501331299,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"a380892a-065a-4fb9-ab96-fc85c727c265"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1630501364263,"user_tz":-540,"elapsed":32976,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_5_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1630501364736,"user_tz":-540,"elapsed":479,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630501365218,"user_tz":-540,"elapsed":498,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"564bc04e-dd6e-4491-f3ea-043873dbcef4"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630501396120,"user_tz":-540,"elapsed":30905,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"396be1f6-6026-4ce3-d9ba-e7105adfef71"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1630501396584,"user_tz":-540,"elapsed":467,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1630501396585,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1630501397626,"user_tz":-540,"elapsed":1047,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1630501397629,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1630501408916,"user_tz":-540,"elapsed":11291,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1630501408917,"user_tz":-540,"elapsed":32,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"70322353-65f0-4cab-a73e-1652196d95d3"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1630501408918,"user_tz":-540,"elapsed":18,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"4d0db6b0-3488-45ac-801d-f0e9af7e3d8a"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_000_5_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_000_5_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_66c97dd1-7f4f-4cbd-8781-6f8c503aed99\", \"HeightShiftRange_000_5_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}