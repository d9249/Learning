{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HeightShiftRange_005_2_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1ZyJ9--fiBCqqZIpZYXBwYIGMXZPnoPvu","timestamp":1630484173863},{"file_id":"1abkZGMd_cSctW05mIZfosyOPOLNr-LK9","timestamp":1630484131331},{"file_id":"1fKp4Svl_srbEAv_YpXTvSwqDozb4bj9H","timestamp":1630484105207},{"file_id":"1y9kcnOXGhn5ArjCk66kqJCIvgyfTRSkk","timestamp":1630483907553},{"file_id":"1o9CD4AI2tKzcdbdLJ4A6xkENgqmZG7oW","timestamp":1630475138628},{"file_id":"17KUAlMIBl9TgxSnuNYcPwx2zScEUw5W-","timestamp":1630475103015},{"file_id":"12cn5R3wN6-IWoeS68BSqi4LxqlCxJxYt","timestamp":1630464969114},{"file_id":"1KLLc8roFaz12DcPj1WHhuKt9ZBQqi76a","timestamp":1630464678834},{"file_id":"1VZIQ1plZ8Dw3dEaOdrcDkgTjXOv0OcTp","timestamp":1630464589009},{"file_id":"1HiqQpOR-bo5ZelQ96RenE8K365HqE7Lv","timestamp":1630438189228},{"file_id":"1ltViornnQGTXyCDuiYgIGfZy1m46LTW_","timestamp":1630438122242},{"file_id":"12vcTsqE7nuRUe3r9-4k5efqml3ud1k9Z","timestamp":1630438078632},{"file_id":"1EdFynNtlBeF206lf5xA2umzEqK_Pjyi5","timestamp":1630437839162},{"file_id":"1pKJK3lnnRPxX28V0U_A45uk_SI4WlDZr","timestamp":1630432659647},{"file_id":"1soBcJ0zzhkPsMINjzGMbYGcga7VX-2Be","timestamp":1630432634550},{"file_id":"12jPQ_wSDDvGyzTBUV-h-pRZ8N-lp9bkW","timestamp":1630425888718},{"file_id":"1ik1ECJq6EbWwGegXLisYoxytv0-7JQcn","timestamp":1630425853722},{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyO4OnyvjXTAJytzG6UjNNS3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630495870132,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0d34cdd5-f043-40af-cf58-2341e16f59c1"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Sep  1 11:31:09 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630495886173,"user_tz":-540,"elapsed":16046,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"08f53fa9-39b6-4654-94b6-1f7fa2a13b86"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1630495889230,"user_tz":-540,"elapsed":3066,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1630495890650,"user_tz":-540,"elapsed":1422,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1630495893059,"user_tz":-540,"elapsed":2413,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1630495912247,"user_tz":-540,"elapsed":19192,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1630495919691,"user_tz":-540,"elapsed":7464,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630495919696,"user_tz":-540,"elapsed":13,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ed580a89-876c-4b19-e8f3-d957ee7b489a"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630495920075,"user_tz":-540,"elapsed":386,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"158a32c7-88b3-4719-ba13-ab2a9582f84a"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.05)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1630495920076,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630501902376,"user_tz":-540,"elapsed":5982308,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b6afff21-bf93-4841-9407-c60c5b72367a"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 42s 281ms/step - loss: 1.7753 - accuracy: 0.3776 - val_loss: 34.3081 - val_accuracy: 0.0985\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 11s 217ms/step - loss: 1.1314 - accuracy: 0.6145 - val_loss: 22.2549 - val_accuracy: 0.1010\n","\n","Epoch 00002: val_accuracy improved from 0.09852 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 3/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.9503 - accuracy: 0.6906 - val_loss: 5.2861 - val_accuracy: 0.0985\n","\n","Epoch 00003: val_accuracy did not improve from 0.10099\n","Epoch 4/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.7743 - accuracy: 0.7406 - val_loss: 13.6601 - val_accuracy: 0.0739\n","\n","Epoch 00004: val_accuracy did not improve from 0.10099\n","Epoch 5/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.6241 - accuracy: 0.7917 - val_loss: 10.9348 - val_accuracy: 0.1108\n","\n","Epoch 00005: val_accuracy improved from 0.10099 to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.5999 - accuracy: 0.8002 - val_loss: 4.6676 - val_accuracy: 0.2488\n","\n","Epoch 00006: val_accuracy improved from 0.11084 to 0.24877, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.5066 - accuracy: 0.8362 - val_loss: 5.0464 - val_accuracy: 0.2808\n","\n","Epoch 00007: val_accuracy improved from 0.24877 to 0.28079, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.4667 - accuracy: 0.8465 - val_loss: 1.7893 - val_accuracy: 0.4975\n","\n","Epoch 00008: val_accuracy improved from 0.28079 to 0.49754, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.4306 - accuracy: 0.8618 - val_loss: 1.6854 - val_accuracy: 0.5640\n","\n","Epoch 00009: val_accuracy improved from 0.49754 to 0.56404, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3747 - accuracy: 0.8709 - val_loss: 0.7269 - val_accuracy: 0.7931\n","\n","Epoch 00010: val_accuracy improved from 0.56404 to 0.79310, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.4085 - accuracy: 0.8642 - val_loss: 0.7739 - val_accuracy: 0.7857\n","\n","Epoch 00011: val_accuracy did not improve from 0.79310\n","Epoch 12/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.3755 - accuracy: 0.8654 - val_loss: 1.5179 - val_accuracy: 0.6453\n","\n","Epoch 00012: val_accuracy did not improve from 0.79310\n","Epoch 13/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.3940 - accuracy: 0.8624 - val_loss: 1.2074 - val_accuracy: 0.7143\n","\n","Epoch 00013: val_accuracy did not improve from 0.79310\n","Epoch 14/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3480 - accuracy: 0.8806 - val_loss: 1.7476 - val_accuracy: 0.5443\n","\n","Epoch 00014: val_accuracy did not improve from 0.79310\n","Epoch 15/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2852 - accuracy: 0.9038 - val_loss: 0.7686 - val_accuracy: 0.7906\n","\n","Epoch 00015: val_accuracy did not improve from 0.79310\n","Epoch 16/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.3099 - accuracy: 0.8922 - val_loss: 1.5546 - val_accuracy: 0.6034\n","\n","Epoch 00016: val_accuracy did not improve from 0.79310\n","Epoch 17/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2220 - accuracy: 0.9269 - val_loss: 0.4731 - val_accuracy: 0.8547\n","\n","Epoch 00017: val_accuracy improved from 0.79310 to 0.85468, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 18/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2452 - accuracy: 0.9184 - val_loss: 1.3646 - val_accuracy: 0.6576\n","\n","Epoch 00018: val_accuracy did not improve from 0.85468\n","Epoch 19/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2626 - accuracy: 0.9105 - val_loss: 1.0523 - val_accuracy: 0.7217\n","\n","Epoch 00019: val_accuracy did not improve from 0.85468\n","Epoch 20/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2704 - accuracy: 0.9099 - val_loss: 0.8063 - val_accuracy: 0.7931\n","\n","Epoch 00020: val_accuracy did not improve from 0.85468\n","Epoch 21/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.2073 - accuracy: 0.9300 - val_loss: 0.7203 - val_accuracy: 0.7980\n","\n","Epoch 00021: val_accuracy did not improve from 0.85468\n","Epoch 22/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2509 - accuracy: 0.9166 - val_loss: 1.6098 - val_accuracy: 0.6527\n","\n","Epoch 00022: val_accuracy did not improve from 0.85468\n","Epoch 23/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2265 - accuracy: 0.9257 - val_loss: 0.6413 - val_accuracy: 0.8325\n","\n","Epoch 00023: val_accuracy did not improve from 0.85468\n","Epoch 24/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1969 - accuracy: 0.9330 - val_loss: 0.6004 - val_accuracy: 0.8128\n","\n","Epoch 00024: val_accuracy did not improve from 0.85468\n","Epoch 25/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1472 - accuracy: 0.9495 - val_loss: 0.3687 - val_accuracy: 0.8916\n","\n","Epoch 00025: val_accuracy improved from 0.85468 to 0.89163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 26/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1434 - accuracy: 0.9519 - val_loss: 0.9938 - val_accuracy: 0.7783\n","\n","Epoch 00026: val_accuracy did not improve from 0.89163\n","Epoch 27/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1900 - accuracy: 0.9367 - val_loss: 0.9820 - val_accuracy: 0.7562\n","\n","Epoch 00027: val_accuracy did not improve from 0.89163\n","Epoch 28/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1640 - accuracy: 0.9397 - val_loss: 0.8467 - val_accuracy: 0.7906\n","\n","Epoch 00028: val_accuracy did not improve from 0.89163\n","Epoch 29/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1492 - accuracy: 0.9482 - val_loss: 0.7035 - val_accuracy: 0.8251\n","\n","Epoch 00029: val_accuracy did not improve from 0.89163\n","Epoch 30/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1583 - accuracy: 0.9428 - val_loss: 0.9114 - val_accuracy: 0.7512\n","\n","Epoch 00030: val_accuracy did not improve from 0.89163\n","Epoch 31/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1674 - accuracy: 0.9452 - val_loss: 0.8020 - val_accuracy: 0.7931\n","\n","Epoch 00031: val_accuracy did not improve from 0.89163\n","Epoch 32/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1518 - accuracy: 0.9428 - val_loss: 0.9576 - val_accuracy: 0.7660\n","\n","Epoch 00032: val_accuracy did not improve from 0.89163\n","Epoch 33/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1448 - accuracy: 0.9525 - val_loss: 0.4367 - val_accuracy: 0.8695\n","\n","Epoch 00033: val_accuracy did not improve from 0.89163\n","Epoch 34/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1282 - accuracy: 0.9549 - val_loss: 0.5797 - val_accuracy: 0.8498\n","\n","Epoch 00034: val_accuracy did not improve from 0.89163\n","Epoch 35/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1288 - accuracy: 0.9531 - val_loss: 0.8035 - val_accuracy: 0.8325\n","\n","Epoch 00035: val_accuracy did not improve from 0.89163\n","Epoch 36/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1672 - accuracy: 0.9446 - val_loss: 1.2647 - val_accuracy: 0.7611\n","\n","Epoch 00036: val_accuracy did not improve from 0.89163\n","Epoch 37/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1268 - accuracy: 0.9574 - val_loss: 1.0139 - val_accuracy: 0.7660\n","\n","Epoch 00037: val_accuracy did not improve from 0.89163\n","Epoch 38/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0956 - accuracy: 0.9726 - val_loss: 0.3929 - val_accuracy: 0.8892\n","\n","Epoch 00038: val_accuracy did not improve from 0.89163\n","Epoch 39/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0830 - accuracy: 0.9750 - val_loss: 0.4924 - val_accuracy: 0.8719\n","\n","Epoch 00039: val_accuracy did not improve from 0.89163\n","Epoch 40/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0961 - accuracy: 0.9653 - val_loss: 0.7071 - val_accuracy: 0.8374\n","\n","Epoch 00040: val_accuracy did not improve from 0.89163\n","Epoch 41/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0754 - accuracy: 0.9726 - val_loss: 0.2870 - val_accuracy: 0.9113\n","\n","Epoch 00041: val_accuracy improved from 0.89163 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 42/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0568 - accuracy: 0.9805 - val_loss: 0.3778 - val_accuracy: 0.8916\n","\n","Epoch 00042: val_accuracy did not improve from 0.91133\n","Epoch 43/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1330 - accuracy: 0.9525 - val_loss: 0.6576 - val_accuracy: 0.8448\n","\n","Epoch 00043: val_accuracy did not improve from 0.91133\n","Epoch 44/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1169 - accuracy: 0.9604 - val_loss: 0.5572 - val_accuracy: 0.8399\n","\n","Epoch 00044: val_accuracy did not improve from 0.91133\n","Epoch 45/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1009 - accuracy: 0.9689 - val_loss: 0.7296 - val_accuracy: 0.8325\n","\n","Epoch 00045: val_accuracy did not improve from 0.91133\n","Epoch 46/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0844 - accuracy: 0.9726 - val_loss: 0.6000 - val_accuracy: 0.8818\n","\n","Epoch 00046: val_accuracy did not improve from 0.91133\n","Epoch 47/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0537 - accuracy: 0.9799 - val_loss: 0.4294 - val_accuracy: 0.8941\n","\n","Epoch 00047: val_accuracy did not improve from 0.91133\n","Epoch 48/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0764 - accuracy: 0.9732 - val_loss: 0.4926 - val_accuracy: 0.8498\n","\n","Epoch 00048: val_accuracy did not improve from 0.91133\n","Epoch 49/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0675 - accuracy: 0.9762 - val_loss: 0.4020 - val_accuracy: 0.8892\n","\n","Epoch 00049: val_accuracy did not improve from 0.91133\n","Epoch 50/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 0.3749 - val_accuracy: 0.9113\n","\n","Epoch 00050: val_accuracy did not improve from 0.91133\n","Epoch 51/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0834 - accuracy: 0.9689 - val_loss: 0.7389 - val_accuracy: 0.8079\n","\n","Epoch 00051: val_accuracy did not improve from 0.91133\n","Epoch 52/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0848 - accuracy: 0.9683 - val_loss: 0.8831 - val_accuracy: 0.8153\n","\n","Epoch 00052: val_accuracy did not improve from 0.91133\n","Epoch 53/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0729 - accuracy: 0.9750 - val_loss: 0.4746 - val_accuracy: 0.8941\n","\n","Epoch 00053: val_accuracy did not improve from 0.91133\n","Epoch 54/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0606 - accuracy: 0.9829 - val_loss: 0.5180 - val_accuracy: 0.8768\n","\n","Epoch 00054: val_accuracy did not improve from 0.91133\n","Epoch 55/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0886 - accuracy: 0.9714 - val_loss: 0.6935 - val_accuracy: 0.8547\n","\n","Epoch 00055: val_accuracy did not improve from 0.91133\n","Epoch 56/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1124 - accuracy: 0.9604 - val_loss: 0.7542 - val_accuracy: 0.8350\n","\n","Epoch 00056: val_accuracy did not improve from 0.91133\n","Epoch 57/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1213 - accuracy: 0.9598 - val_loss: 0.5682 - val_accuracy: 0.8744\n","\n","Epoch 00057: val_accuracy did not improve from 0.91133\n","Epoch 58/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0654 - accuracy: 0.9756 - val_loss: 0.3751 - val_accuracy: 0.9089\n","\n","Epoch 00058: val_accuracy did not improve from 0.91133\n","Epoch 59/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0491 - accuracy: 0.9805 - val_loss: 0.3490 - val_accuracy: 0.8941\n","\n","Epoch 00059: val_accuracy did not improve from 0.91133\n","Epoch 60/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0285 - accuracy: 0.9927 - val_loss: 0.3378 - val_accuracy: 0.9261\n","\n","Epoch 00060: val_accuracy improved from 0.91133 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 61/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0484 - accuracy: 0.9823 - val_loss: 0.5611 - val_accuracy: 0.8670\n","\n","Epoch 00061: val_accuracy did not improve from 0.92611\n","Epoch 62/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0639 - accuracy: 0.9787 - val_loss: 0.6914 - val_accuracy: 0.8547\n","\n","Epoch 00062: val_accuracy did not improve from 0.92611\n","Epoch 63/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0563 - accuracy: 0.9817 - val_loss: 0.7282 - val_accuracy: 0.8448\n","\n","Epoch 00063: val_accuracy did not improve from 0.92611\n","Epoch 64/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0893 - accuracy: 0.9695 - val_loss: 1.1003 - val_accuracy: 0.7882\n","\n","Epoch 00064: val_accuracy did not improve from 0.92611\n","Epoch 65/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0538 - accuracy: 0.9805 - val_loss: 0.4343 - val_accuracy: 0.9113\n","\n","Epoch 00065: val_accuracy did not improve from 0.92611\n","Epoch 66/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0627 - accuracy: 0.9805 - val_loss: 0.6172 - val_accuracy: 0.8768\n","\n","Epoch 00066: val_accuracy did not improve from 0.92611\n","Epoch 67/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0521 - accuracy: 0.9829 - val_loss: 0.4636 - val_accuracy: 0.8892\n","\n","Epoch 00067: val_accuracy did not improve from 0.92611\n","Epoch 68/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0344 - accuracy: 0.9878 - val_loss: 0.4850 - val_accuracy: 0.8892\n","\n","Epoch 00068: val_accuracy did not improve from 0.92611\n","Epoch 69/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0567 - accuracy: 0.9842 - val_loss: 0.5295 - val_accuracy: 0.8744\n","\n","Epoch 00069: val_accuracy did not improve from 0.92611\n","Epoch 70/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0793 - accuracy: 0.9750 - val_loss: 0.7456 - val_accuracy: 0.8522\n","\n","Epoch 00070: val_accuracy did not improve from 0.92611\n","Epoch 71/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0723 - accuracy: 0.9799 - val_loss: 0.7135 - val_accuracy: 0.8325\n","\n","Epoch 00071: val_accuracy did not improve from 0.92611\n","Epoch 72/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0855 - accuracy: 0.9695 - val_loss: 0.8323 - val_accuracy: 0.8251\n","\n","Epoch 00072: val_accuracy did not improve from 0.92611\n","Epoch 73/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0977 - accuracy: 0.9635 - val_loss: 0.7330 - val_accuracy: 0.8645\n","\n","Epoch 00073: val_accuracy did not improve from 0.92611\n","Epoch 74/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0697 - accuracy: 0.9744 - val_loss: 0.4794 - val_accuracy: 0.8892\n","\n","Epoch 00074: val_accuracy did not improve from 0.92611\n","Epoch 75/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0722 - accuracy: 0.9744 - val_loss: 0.4154 - val_accuracy: 0.9039\n","\n","Epoch 00075: val_accuracy did not improve from 0.92611\n","Epoch 76/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0451 - accuracy: 0.9817 - val_loss: 0.5648 - val_accuracy: 0.8645\n","\n","Epoch 00076: val_accuracy did not improve from 0.92611\n","Epoch 77/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0444 - accuracy: 0.9842 - val_loss: 0.5296 - val_accuracy: 0.8768\n","\n","Epoch 00077: val_accuracy did not improve from 0.92611\n","Epoch 78/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0367 - accuracy: 0.9860 - val_loss: 0.6809 - val_accuracy: 0.8325\n","\n","Epoch 00078: val_accuracy did not improve from 0.92611\n","Epoch 79/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0850 - accuracy: 0.9714 - val_loss: 1.2434 - val_accuracy: 0.7808\n","\n","Epoch 00079: val_accuracy did not improve from 0.92611\n","Epoch 80/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0821 - accuracy: 0.9714 - val_loss: 0.7606 - val_accuracy: 0.8374\n","\n","Epoch 00080: val_accuracy did not improve from 0.92611\n","Epoch 81/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0568 - accuracy: 0.9829 - val_loss: 0.6390 - val_accuracy: 0.8424\n","\n","Epoch 00081: val_accuracy did not improve from 0.92611\n","Epoch 82/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1021 - accuracy: 0.9683 - val_loss: 0.4279 - val_accuracy: 0.8941\n","\n","Epoch 00082: val_accuracy did not improve from 0.92611\n","Epoch 83/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0475 - accuracy: 0.9854 - val_loss: 0.3901 - val_accuracy: 0.8966\n","\n","Epoch 00083: val_accuracy did not improve from 0.92611\n","Epoch 84/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0386 - accuracy: 0.9878 - val_loss: 0.4908 - val_accuracy: 0.8818\n","\n","Epoch 00084: val_accuracy did not improve from 0.92611\n","Epoch 85/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.4948 - val_accuracy: 0.8990\n","\n","Epoch 00085: val_accuracy did not improve from 0.92611\n","Epoch 86/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0547 - accuracy: 0.9823 - val_loss: 0.4375 - val_accuracy: 0.8793\n","\n","Epoch 00086: val_accuracy did not improve from 0.92611\n","Epoch 87/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 0.8066 - val_accuracy: 0.8227\n","\n","Epoch 00087: val_accuracy did not improve from 0.92611\n","Epoch 88/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0458 - accuracy: 0.9860 - val_loss: 0.5273 - val_accuracy: 0.8842\n","\n","Epoch 00088: val_accuracy did not improve from 0.92611\n","Epoch 89/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0391 - accuracy: 0.9878 - val_loss: 0.5459 - val_accuracy: 0.9015\n","\n","Epoch 00089: val_accuracy did not improve from 0.92611\n","Epoch 90/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 0.5233 - val_accuracy: 0.8941\n","\n","Epoch 00090: val_accuracy did not improve from 0.92611\n","Epoch 91/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.5505 - val_accuracy: 0.8842\n","\n","Epoch 00091: val_accuracy did not improve from 0.92611\n","Epoch 92/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0089 - accuracy: 0.9994 - val_loss: 0.3891 - val_accuracy: 0.9039\n","\n","Epoch 00092: val_accuracy did not improve from 0.92611\n","Epoch 93/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.4030 - val_accuracy: 0.9039\n","\n","Epoch 00093: val_accuracy did not improve from 0.92611\n","Epoch 94/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.5949 - val_accuracy: 0.8793\n","\n","Epoch 00094: val_accuracy did not improve from 0.92611\n","Epoch 95/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.4759 - val_accuracy: 0.8966\n","\n","Epoch 00095: val_accuracy did not improve from 0.92611\n","Epoch 96/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.5830 - val_accuracy: 0.8793\n","\n","Epoch 00096: val_accuracy did not improve from 0.92611\n","Epoch 97/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0447 - accuracy: 0.9848 - val_loss: 0.6611 - val_accuracy: 0.8645\n","\n","Epoch 00097: val_accuracy did not improve from 0.92611\n","Epoch 98/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0597 - accuracy: 0.9836 - val_loss: 0.8209 - val_accuracy: 0.8473\n","\n","Epoch 00098: val_accuracy did not improve from 0.92611\n","Epoch 99/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0314 - accuracy: 0.9909 - val_loss: 0.4577 - val_accuracy: 0.8941\n","\n","Epoch 00099: val_accuracy did not improve from 0.92611\n","Epoch 100/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0244 - accuracy: 0.9903 - val_loss: 0.6791 - val_accuracy: 0.8596\n","\n","Epoch 00100: val_accuracy did not improve from 0.92611\n","Epoch 101/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0845 - accuracy: 0.9756 - val_loss: 0.5825 - val_accuracy: 0.8719\n","\n","Epoch 00101: val_accuracy did not improve from 0.92611\n","Epoch 102/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0897 - accuracy: 0.9750 - val_loss: 2.6708 - val_accuracy: 0.6305\n","\n","Epoch 00102: val_accuracy did not improve from 0.92611\n","Epoch 103/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0864 - accuracy: 0.9720 - val_loss: 1.3613 - val_accuracy: 0.7635\n","\n","Epoch 00103: val_accuracy did not improve from 0.92611\n","Epoch 104/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0880 - accuracy: 0.9732 - val_loss: 0.7280 - val_accuracy: 0.8670\n","\n","Epoch 00104: val_accuracy did not improve from 0.92611\n","Epoch 105/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0555 - accuracy: 0.9811 - val_loss: 0.6013 - val_accuracy: 0.8818\n","\n","Epoch 00105: val_accuracy did not improve from 0.92611\n","Epoch 106/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0428 - accuracy: 0.9860 - val_loss: 0.4847 - val_accuracy: 0.9015\n","\n","Epoch 00106: val_accuracy did not improve from 0.92611\n","Epoch 107/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 0.5161 - val_accuracy: 0.8916\n","\n","Epoch 00107: val_accuracy did not improve from 0.92611\n","Epoch 108/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.4152 - val_accuracy: 0.9236\n","\n","Epoch 00108: val_accuracy did not improve from 0.92611\n","Epoch 109/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.3439 - val_accuracy: 0.9064\n","\n","Epoch 00109: val_accuracy did not improve from 0.92611\n","Epoch 110/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 0.3755 - val_accuracy: 0.9039\n","\n","Epoch 00110: val_accuracy did not improve from 0.92611\n","Epoch 111/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.3339 - val_accuracy: 0.9310\n","\n","Epoch 00111: val_accuracy improved from 0.92611 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 112/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.3625 - val_accuracy: 0.9187\n","\n","Epoch 00112: val_accuracy did not improve from 0.93103\n","Epoch 113/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0149 - accuracy: 0.9939 - val_loss: 0.3674 - val_accuracy: 0.9089\n","\n","Epoch 00113: val_accuracy did not improve from 0.93103\n","Epoch 114/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0168 - accuracy: 0.9927 - val_loss: 0.4099 - val_accuracy: 0.9163\n","\n","Epoch 00114: val_accuracy did not improve from 0.93103\n","Epoch 115/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0396 - accuracy: 0.9872 - val_loss: 0.9194 - val_accuracy: 0.8571\n","\n","Epoch 00115: val_accuracy did not improve from 0.93103\n","Epoch 116/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0453 - accuracy: 0.9854 - val_loss: 0.7950 - val_accuracy: 0.8399\n","\n","Epoch 00116: val_accuracy did not improve from 0.93103\n","Epoch 117/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0605 - accuracy: 0.9787 - val_loss: 0.8427 - val_accuracy: 0.8719\n","\n","Epoch 00117: val_accuracy did not improve from 0.93103\n","Epoch 118/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0428 - accuracy: 0.9823 - val_loss: 0.5008 - val_accuracy: 0.8941\n","\n","Epoch 00118: val_accuracy did not improve from 0.93103\n","Epoch 119/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0338 - accuracy: 0.9890 - val_loss: 0.6967 - val_accuracy: 0.8768\n","\n","Epoch 00119: val_accuracy did not improve from 0.93103\n","Epoch 120/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0796 - accuracy: 0.9787 - val_loss: 1.7686 - val_accuracy: 0.7906\n","\n","Epoch 00120: val_accuracy did not improve from 0.93103\n","Epoch 121/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1333 - accuracy: 0.9635 - val_loss: 1.5366 - val_accuracy: 0.8030\n","\n","Epoch 00121: val_accuracy did not improve from 0.93103\n","Epoch 122/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0506 - accuracy: 0.9787 - val_loss: 0.6576 - val_accuracy: 0.8645\n","\n","Epoch 00122: val_accuracy did not improve from 0.93103\n","Epoch 123/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0426 - accuracy: 0.9884 - val_loss: 0.9424 - val_accuracy: 0.8227\n","\n","Epoch 00123: val_accuracy did not improve from 0.93103\n","Epoch 124/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0325 - accuracy: 0.9927 - val_loss: 0.4962 - val_accuracy: 0.8966\n","\n","Epoch 00124: val_accuracy did not improve from 0.93103\n","Epoch 125/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0539 - accuracy: 0.9872 - val_loss: 0.6826 - val_accuracy: 0.8842\n","\n","Epoch 00125: val_accuracy did not improve from 0.93103\n","Epoch 126/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0560 - accuracy: 0.9793 - val_loss: 0.4270 - val_accuracy: 0.8892\n","\n","Epoch 00126: val_accuracy did not improve from 0.93103\n","Epoch 127/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0557 - accuracy: 0.9811 - val_loss: 0.5146 - val_accuracy: 0.8842\n","\n","Epoch 00127: val_accuracy did not improve from 0.93103\n","Epoch 128/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0506 - accuracy: 0.9854 - val_loss: 0.6125 - val_accuracy: 0.8892\n","\n","Epoch 00128: val_accuracy did not improve from 0.93103\n","Epoch 129/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0167 - accuracy: 0.9933 - val_loss: 0.5292 - val_accuracy: 0.8719\n","\n","Epoch 00129: val_accuracy did not improve from 0.93103\n","Epoch 130/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.6163 - val_accuracy: 0.8842\n","\n","Epoch 00130: val_accuracy did not improve from 0.93103\n","Epoch 131/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.3612 - val_accuracy: 0.9113\n","\n","Epoch 00131: val_accuracy did not improve from 0.93103\n","Epoch 132/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.4051 - val_accuracy: 0.9163\n","\n","Epoch 00132: val_accuracy did not improve from 0.93103\n","Epoch 133/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.3836 - val_accuracy: 0.9138\n","\n","Epoch 00133: val_accuracy did not improve from 0.93103\n","Epoch 134/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.4147 - val_accuracy: 0.9236\n","\n","Epoch 00134: val_accuracy did not improve from 0.93103\n","Epoch 135/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4018 - val_accuracy: 0.9138\n","\n","Epoch 00135: val_accuracy did not improve from 0.93103\n","Epoch 136/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.4328 - val_accuracy: 0.9089\n","\n","Epoch 00136: val_accuracy did not improve from 0.93103\n","Epoch 137/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4101 - val_accuracy: 0.9187\n","\n","Epoch 00137: val_accuracy did not improve from 0.93103\n","Epoch 138/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.6746 - val_accuracy: 0.8818\n","\n","Epoch 00138: val_accuracy did not improve from 0.93103\n","Epoch 139/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.5202 - val_accuracy: 0.9015\n","\n","Epoch 00139: val_accuracy did not improve from 0.93103\n","Epoch 140/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.5654 - val_accuracy: 0.9089\n","\n","Epoch 00140: val_accuracy did not improve from 0.93103\n","Epoch 141/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0665 - accuracy: 0.9799 - val_loss: 1.3812 - val_accuracy: 0.8054\n","\n","Epoch 00141: val_accuracy did not improve from 0.93103\n","Epoch 142/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0885 - accuracy: 0.9695 - val_loss: 0.7353 - val_accuracy: 0.8645\n","\n","Epoch 00142: val_accuracy did not improve from 0.93103\n","Epoch 143/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0449 - accuracy: 0.9860 - val_loss: 0.5809 - val_accuracy: 0.8719\n","\n","Epoch 00143: val_accuracy did not improve from 0.93103\n","Epoch 144/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0460 - accuracy: 0.9848 - val_loss: 0.7855 - val_accuracy: 0.8695\n","\n","Epoch 00144: val_accuracy did not improve from 0.93103\n","Epoch 145/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0273 - accuracy: 0.9909 - val_loss: 0.6141 - val_accuracy: 0.8793\n","\n","Epoch 00145: val_accuracy did not improve from 0.93103\n","Epoch 146/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.5191 - val_accuracy: 0.8941\n","\n","Epoch 00146: val_accuracy did not improve from 0.93103\n","Epoch 147/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0124 - accuracy: 0.9939 - val_loss: 0.4027 - val_accuracy: 0.9039\n","\n","Epoch 00147: val_accuracy did not improve from 0.93103\n","Epoch 148/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.5917 - val_accuracy: 0.8867\n","\n","Epoch 00148: val_accuracy did not improve from 0.93103\n","Epoch 149/500\n","52/52 [==============================] - 12s 236ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.4559 - val_accuracy: 0.9089\n","\n","Epoch 00149: val_accuracy did not improve from 0.93103\n","Epoch 150/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.9064\n","\n","Epoch 00150: val_accuracy did not improve from 0.93103\n","Epoch 151/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.9163\n","\n","Epoch 00151: val_accuracy did not improve from 0.93103\n","Epoch 152/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.9138\n","\n","Epoch 00152: val_accuracy did not improve from 0.93103\n","Epoch 153/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0316 - accuracy: 0.9909 - val_loss: 0.5350 - val_accuracy: 0.8941\n","\n","Epoch 00153: val_accuracy did not improve from 0.93103\n","Epoch 154/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 0.5426 - val_accuracy: 0.8842\n","\n","Epoch 00154: val_accuracy did not improve from 0.93103\n","Epoch 155/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0853 - accuracy: 0.9799 - val_loss: 1.1898 - val_accuracy: 0.8128\n","\n","Epoch 00155: val_accuracy did not improve from 0.93103\n","Epoch 156/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1091 - accuracy: 0.9592 - val_loss: 1.1392 - val_accuracy: 0.8202\n","\n","Epoch 00156: val_accuracy did not improve from 0.93103\n","Epoch 157/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0811 - accuracy: 0.9720 - val_loss: 0.9041 - val_accuracy: 0.8547\n","\n","Epoch 00157: val_accuracy did not improve from 0.93103\n","Epoch 158/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0332 - accuracy: 0.9884 - val_loss: 0.4439 - val_accuracy: 0.8990\n","\n","Epoch 00158: val_accuracy did not improve from 0.93103\n","Epoch 159/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.4503 - val_accuracy: 0.8867\n","\n","Epoch 00159: val_accuracy did not improve from 0.93103\n","Epoch 160/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.3782 - val_accuracy: 0.9064\n","\n","Epoch 00160: val_accuracy did not improve from 0.93103\n","Epoch 161/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.4589 - val_accuracy: 0.8990\n","\n","Epoch 00161: val_accuracy did not improve from 0.93103\n","Epoch 162/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.4132 - val_accuracy: 0.9015\n","\n","Epoch 00162: val_accuracy did not improve from 0.93103\n","Epoch 163/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.6558 - val_accuracy: 0.8744\n","\n","Epoch 00163: val_accuracy did not improve from 0.93103\n","Epoch 164/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0210 - accuracy: 0.9921 - val_loss: 0.4578 - val_accuracy: 0.9089\n","\n","Epoch 00164: val_accuracy did not improve from 0.93103\n","Epoch 165/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 0.4839 - val_accuracy: 0.8941\n","\n","Epoch 00165: val_accuracy did not improve from 0.93103\n","Epoch 166/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.4143 - val_accuracy: 0.9113\n","\n","Epoch 00166: val_accuracy did not improve from 0.93103\n","Epoch 167/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 0.4728 - val_accuracy: 0.9039\n","\n","Epoch 00167: val_accuracy did not improve from 0.93103\n","Epoch 168/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.4682 - val_accuracy: 0.9187\n","\n","Epoch 00168: val_accuracy did not improve from 0.93103\n","Epoch 169/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0481 - accuracy: 0.9836 - val_loss: 0.8336 - val_accuracy: 0.8645\n","\n","Epoch 00169: val_accuracy did not improve from 0.93103\n","Epoch 170/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0674 - accuracy: 0.9787 - val_loss: 1.3057 - val_accuracy: 0.8054\n","\n","Epoch 00170: val_accuracy did not improve from 0.93103\n","Epoch 171/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0547 - accuracy: 0.9811 - val_loss: 0.7797 - val_accuracy: 0.8842\n","\n","Epoch 00171: val_accuracy did not improve from 0.93103\n","Epoch 172/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0202 - accuracy: 0.9915 - val_loss: 0.5813 - val_accuracy: 0.8990\n","\n","Epoch 00172: val_accuracy did not improve from 0.93103\n","Epoch 173/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.4578 - val_accuracy: 0.9163\n","\n","Epoch 00173: val_accuracy did not improve from 0.93103\n","Epoch 174/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.7368 - val_accuracy: 0.8892\n","\n","Epoch 00174: val_accuracy did not improve from 0.93103\n","Epoch 175/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0151 - accuracy: 0.9939 - val_loss: 0.4962 - val_accuracy: 0.9089\n","\n","Epoch 00175: val_accuracy did not improve from 0.93103\n","Epoch 176/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.4721 - val_accuracy: 0.8966\n","\n","Epoch 00176: val_accuracy did not improve from 0.93103\n","Epoch 177/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.9212\n","\n","Epoch 00177: val_accuracy did not improve from 0.93103\n","Epoch 178/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.4528 - val_accuracy: 0.9212\n","\n","Epoch 00178: val_accuracy did not improve from 0.93103\n","Epoch 179/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.4993 - val_accuracy: 0.9039\n","\n","Epoch 00179: val_accuracy did not improve from 0.93103\n","Epoch 180/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.5660 - val_accuracy: 0.8966\n","\n","Epoch 00180: val_accuracy did not improve from 0.93103\n","Epoch 181/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.5247 - val_accuracy: 0.9039\n","\n","Epoch 00181: val_accuracy did not improve from 0.93103\n","Epoch 182/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0359 - accuracy: 0.9890 - val_loss: 0.5941 - val_accuracy: 0.8818\n","\n","Epoch 00182: val_accuracy did not improve from 0.93103\n","Epoch 183/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.6648 - val_accuracy: 0.8818\n","\n","Epoch 00183: val_accuracy did not improve from 0.93103\n","Epoch 184/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0434 - accuracy: 0.9890 - val_loss: 0.8010 - val_accuracy: 0.8522\n","\n","Epoch 00184: val_accuracy did not improve from 0.93103\n","Epoch 185/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0471 - accuracy: 0.9866 - val_loss: 0.5924 - val_accuracy: 0.8818\n","\n","Epoch 00185: val_accuracy did not improve from 0.93103\n","Epoch 186/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0501 - accuracy: 0.9860 - val_loss: 0.4267 - val_accuracy: 0.9212\n","\n","Epoch 00186: val_accuracy did not improve from 0.93103\n","Epoch 187/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.4747 - val_accuracy: 0.8990\n","\n","Epoch 00187: val_accuracy did not improve from 0.93103\n","Epoch 188/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 0.7235 - val_accuracy: 0.8867\n","\n","Epoch 00188: val_accuracy did not improve from 0.93103\n","Epoch 189/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0718 - accuracy: 0.9799 - val_loss: 0.6545 - val_accuracy: 0.8793\n","\n","Epoch 00189: val_accuracy did not improve from 0.93103\n","Epoch 190/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0279 - accuracy: 0.9933 - val_loss: 0.5090 - val_accuracy: 0.9015\n","\n","Epoch 00190: val_accuracy did not improve from 0.93103\n","Epoch 191/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.4393 - val_accuracy: 0.9015\n","\n","Epoch 00191: val_accuracy did not improve from 0.93103\n","Epoch 192/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.5490 - val_accuracy: 0.8941\n","\n","Epoch 00192: val_accuracy did not improve from 0.93103\n","Epoch 193/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 1.0033 - val_accuracy: 0.8399\n","\n","Epoch 00193: val_accuracy did not improve from 0.93103\n","Epoch 194/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0564 - accuracy: 0.9842 - val_loss: 0.9049 - val_accuracy: 0.8645\n","\n","Epoch 00194: val_accuracy did not improve from 0.93103\n","Epoch 195/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 0.6430 - val_accuracy: 0.8744\n","\n","Epoch 00195: val_accuracy did not improve from 0.93103\n","Epoch 196/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.4038 - val_accuracy: 0.8990\n","\n","Epoch 00196: val_accuracy did not improve from 0.93103\n","Epoch 197/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0075 - accuracy: 0.9970 - val_loss: 0.5196 - val_accuracy: 0.8990\n","\n","Epoch 00197: val_accuracy did not improve from 0.93103\n","Epoch 198/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.3691 - val_accuracy: 0.9187\n","\n","Epoch 00198: val_accuracy did not improve from 0.93103\n","Epoch 199/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.5274 - val_accuracy: 0.8892\n","\n","Epoch 00199: val_accuracy did not improve from 0.93103\n","Epoch 200/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0329 - accuracy: 0.9884 - val_loss: 0.5565 - val_accuracy: 0.8966\n","\n","Epoch 00200: val_accuracy did not improve from 0.93103\n","Epoch 201/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.5103 - val_accuracy: 0.9064\n","\n","Epoch 00201: val_accuracy did not improve from 0.93103\n","Epoch 202/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.5505 - val_accuracy: 0.9015\n","\n","Epoch 00202: val_accuracy did not improve from 0.93103\n","Epoch 203/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.4178 - val_accuracy: 0.9236\n","\n","Epoch 00203: val_accuracy did not improve from 0.93103\n","Epoch 204/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.3635 - val_accuracy: 0.9138\n","\n","Epoch 00204: val_accuracy did not improve from 0.93103\n","Epoch 205/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.9089\n","\n","Epoch 00205: val_accuracy did not improve from 0.93103\n","Epoch 206/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.5563 - val_accuracy: 0.9039\n","\n","Epoch 00206: val_accuracy did not improve from 0.93103\n","Epoch 207/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0337 - accuracy: 0.9896 - val_loss: 0.7597 - val_accuracy: 0.8744\n","\n","Epoch 00207: val_accuracy did not improve from 0.93103\n","Epoch 208/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0639 - accuracy: 0.9793 - val_loss: 0.8869 - val_accuracy: 0.8645\n","\n","Epoch 00208: val_accuracy did not improve from 0.93103\n","Epoch 209/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0537 - accuracy: 0.9829 - val_loss: 0.7374 - val_accuracy: 0.8892\n","\n","Epoch 00209: val_accuracy did not improve from 0.93103\n","Epoch 210/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.5567 - val_accuracy: 0.8867\n","\n","Epoch 00210: val_accuracy did not improve from 0.93103\n","Epoch 211/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.5474 - val_accuracy: 0.9039\n","\n","Epoch 00211: val_accuracy did not improve from 0.93103\n","Epoch 212/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0435 - accuracy: 0.9829 - val_loss: 1.1796 - val_accuracy: 0.8103\n","\n","Epoch 00212: val_accuracy did not improve from 0.93103\n","Epoch 213/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.5711 - val_accuracy: 0.8867\n","\n","Epoch 00213: val_accuracy did not improve from 0.93103\n","Epoch 214/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.4375 - val_accuracy: 0.9138\n","\n","Epoch 00214: val_accuracy did not improve from 0.93103\n","Epoch 215/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.6159 - val_accuracy: 0.8966\n","\n","Epoch 00215: val_accuracy did not improve from 0.93103\n","Epoch 216/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.5223 - val_accuracy: 0.9064\n","\n","Epoch 00216: val_accuracy did not improve from 0.93103\n","Epoch 217/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.4405 - val_accuracy: 0.9089\n","\n","Epoch 00217: val_accuracy did not improve from 0.93103\n","Epoch 218/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9163\n","\n","Epoch 00218: val_accuracy did not improve from 0.93103\n","Epoch 219/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4269 - val_accuracy: 0.9212\n","\n","Epoch 00219: val_accuracy did not improve from 0.93103\n","Epoch 220/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.4415 - val_accuracy: 0.9163\n","\n","Epoch 00220: val_accuracy did not improve from 0.93103\n","Epoch 221/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4430 - val_accuracy: 0.9113\n","\n","Epoch 00221: val_accuracy did not improve from 0.93103\n","Epoch 222/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4924 - val_accuracy: 0.8867\n","\n","Epoch 00222: val_accuracy did not improve from 0.93103\n","Epoch 223/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0073 - accuracy: 0.9963 - val_loss: 0.4596 - val_accuracy: 0.9163\n","\n","Epoch 00223: val_accuracy did not improve from 0.93103\n","Epoch 224/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.5188 - val_accuracy: 0.9039\n","\n","Epoch 00224: val_accuracy did not improve from 0.93103\n","Epoch 225/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.4622 - val_accuracy: 0.9113\n","\n","Epoch 00225: val_accuracy did not improve from 0.93103\n","Epoch 226/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.6272 - val_accuracy: 0.8990\n","\n","Epoch 00226: val_accuracy did not improve from 0.93103\n","Epoch 227/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.7334 - val_accuracy: 0.8768\n","\n","Epoch 00227: val_accuracy did not improve from 0.93103\n","Epoch 228/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 1.0922 - val_accuracy: 0.8498\n","\n","Epoch 00228: val_accuracy did not improve from 0.93103\n","Epoch 229/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0428 - accuracy: 0.9860 - val_loss: 0.9871 - val_accuracy: 0.8473\n","\n","Epoch 00229: val_accuracy did not improve from 0.93103\n","Epoch 230/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0365 - accuracy: 0.9866 - val_loss: 0.8783 - val_accuracy: 0.8818\n","\n","Epoch 00230: val_accuracy did not improve from 0.93103\n","Epoch 231/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0360 - accuracy: 0.9842 - val_loss: 0.6464 - val_accuracy: 0.8818\n","\n","Epoch 00231: val_accuracy did not improve from 0.93103\n","Epoch 232/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0937 - accuracy: 0.9769 - val_loss: 1.1965 - val_accuracy: 0.8424\n","\n","Epoch 00232: val_accuracy did not improve from 0.93103\n","Epoch 233/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.7443 - val_accuracy: 0.8768\n","\n","Epoch 00233: val_accuracy did not improve from 0.93103\n","Epoch 234/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.8133 - val_accuracy: 0.8768\n","\n","Epoch 00234: val_accuracy did not improve from 0.93103\n","Epoch 235/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.6218 - val_accuracy: 0.8842\n","\n","Epoch 00235: val_accuracy did not improve from 0.93103\n","Epoch 236/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0431 - accuracy: 0.9866 - val_loss: 0.9250 - val_accuracy: 0.8177\n","\n","Epoch 00236: val_accuracy did not improve from 0.93103\n","Epoch 237/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0207 - accuracy: 0.9921 - val_loss: 0.4392 - val_accuracy: 0.9015\n","\n","Epoch 00237: val_accuracy did not improve from 0.93103\n","Epoch 238/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.4972 - val_accuracy: 0.9039\n","\n","Epoch 00238: val_accuracy did not improve from 0.93103\n","Epoch 239/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4261 - val_accuracy: 0.9089\n","\n","Epoch 00239: val_accuracy did not improve from 0.93103\n","Epoch 240/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.4401 - val_accuracy: 0.9064\n","\n","Epoch 00240: val_accuracy did not improve from 0.93103\n","Epoch 241/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0089 - accuracy: 0.9945 - val_loss: 0.7278 - val_accuracy: 0.8744\n","\n","Epoch 00241: val_accuracy did not improve from 0.93103\n","Epoch 242/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 0.7001 - val_accuracy: 0.8966\n","\n","Epoch 00242: val_accuracy did not improve from 0.93103\n","Epoch 243/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.5955 - val_accuracy: 0.8990\n","\n","Epoch 00243: val_accuracy did not improve from 0.93103\n","Epoch 244/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4584 - val_accuracy: 0.9089\n","\n","Epoch 00244: val_accuracy did not improve from 0.93103\n","Epoch 245/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.9138\n","\n","Epoch 00245: val_accuracy did not improve from 0.93103\n","Epoch 246/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 0.9113\n","\n","Epoch 00246: val_accuracy did not improve from 0.93103\n","Epoch 247/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4631 - val_accuracy: 0.9113\n","\n","Epoch 00247: val_accuracy did not improve from 0.93103\n","Epoch 248/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.9039\n","\n","Epoch 00248: val_accuracy did not improve from 0.93103\n","Epoch 249/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3952 - val_accuracy: 0.9064\n","\n","Epoch 00249: val_accuracy did not improve from 0.93103\n","Epoch 250/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.9138\n","\n","Epoch 00250: val_accuracy did not improve from 0.93103\n","Epoch 251/500\n","52/52 [==============================] - 11s 219ms/step - loss: 6.5525e-04 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.9089\n","\n","Epoch 00251: val_accuracy did not improve from 0.93103\n","Epoch 252/500\n","52/52 [==============================] - 11s 218ms/step - loss: 8.0644e-04 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.9310\n","\n","Epoch 00252: val_accuracy did not improve from 0.93103\n","Epoch 253/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.9212\n","\n","Epoch 00253: val_accuracy did not improve from 0.93103\n","Epoch 254/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.9212\n","\n","Epoch 00254: val_accuracy did not improve from 0.93103\n","Epoch 255/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.4701 - val_accuracy: 0.9113\n","\n","Epoch 00255: val_accuracy did not improve from 0.93103\n","Epoch 256/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.6694 - val_accuracy: 0.8793\n","\n","Epoch 00256: val_accuracy did not improve from 0.93103\n","Epoch 257/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0258 - accuracy: 0.9903 - val_loss: 0.9044 - val_accuracy: 0.8768\n","\n","Epoch 00257: val_accuracy did not improve from 0.93103\n","Epoch 258/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 1.0431 - val_accuracy: 0.8522\n","\n","Epoch 00258: val_accuracy did not improve from 0.93103\n","Epoch 259/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.7219 - val_accuracy: 0.8818\n","\n","Epoch 00259: val_accuracy did not improve from 0.93103\n","Epoch 260/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4256 - val_accuracy: 0.9138\n","\n","Epoch 00260: val_accuracy did not improve from 0.93103\n","Epoch 261/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0326 - accuracy: 0.9921 - val_loss: 0.6748 - val_accuracy: 0.8645\n","\n","Epoch 00261: val_accuracy did not improve from 0.93103\n","Epoch 262/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0331 - accuracy: 0.9878 - val_loss: 0.8672 - val_accuracy: 0.8547\n","\n","Epoch 00262: val_accuracy did not improve from 0.93103\n","Epoch 263/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.5278 - val_accuracy: 0.9015\n","\n","Epoch 00263: val_accuracy did not improve from 0.93103\n","Epoch 264/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.4928 - val_accuracy: 0.9163\n","\n","Epoch 00264: val_accuracy did not improve from 0.93103\n","Epoch 265/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.5298 - val_accuracy: 0.9064\n","\n","Epoch 00265: val_accuracy did not improve from 0.93103\n","Epoch 266/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.6392 - val_accuracy: 0.8768\n","\n","Epoch 00266: val_accuracy did not improve from 0.93103\n","Epoch 267/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.5536 - val_accuracy: 0.8966\n","\n","Epoch 00267: val_accuracy did not improve from 0.93103\n","Epoch 268/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.5130 - val_accuracy: 0.9064\n","\n","Epoch 00268: val_accuracy did not improve from 0.93103\n","Epoch 269/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.5672 - val_accuracy: 0.8990\n","\n","Epoch 00269: val_accuracy did not improve from 0.93103\n","Epoch 270/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0133 - accuracy: 0.9927 - val_loss: 0.7820 - val_accuracy: 0.8596\n","\n","Epoch 00270: val_accuracy did not improve from 0.93103\n","Epoch 271/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5075 - val_accuracy: 0.9113\n","\n","Epoch 00271: val_accuracy did not improve from 0.93103\n","Epoch 272/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.9089\n","\n","Epoch 00272: val_accuracy did not improve from 0.93103\n","Epoch 273/500\n","52/52 [==============================] - 11s 219ms/step - loss: 9.7391e-04 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.9138\n","\n","Epoch 00273: val_accuracy did not improve from 0.93103\n","Epoch 274/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9113\n","\n","Epoch 00274: val_accuracy did not improve from 0.93103\n","Epoch 275/500\n","52/52 [==============================] - 11s 220ms/step - loss: 9.1378e-04 - accuracy: 1.0000 - val_loss: 0.4579 - val_accuracy: 0.8966\n","\n","Epoch 00275: val_accuracy did not improve from 0.93103\n","Epoch 276/500\n","52/52 [==============================] - 11s 217ms/step - loss: 6.4482e-04 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9163\n","\n","Epoch 00276: val_accuracy did not improve from 0.93103\n","Epoch 277/500\n","52/52 [==============================] - 11s 218ms/step - loss: 6.2882e-04 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.9113\n","\n","Epoch 00277: val_accuracy did not improve from 0.93103\n","Epoch 278/500\n","52/52 [==============================] - 11s 218ms/step - loss: 4.4414e-04 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9236\n","\n","Epoch 00278: val_accuracy did not improve from 0.93103\n","Epoch 279/500\n","52/52 [==============================] - 11s 218ms/step - loss: 2.6502e-04 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.9187\n","\n","Epoch 00279: val_accuracy did not improve from 0.93103\n","Epoch 280/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.7506e-04 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.9286\n","\n","Epoch 00280: val_accuracy did not improve from 0.93103\n","Epoch 281/500\n","52/52 [==============================] - 11s 218ms/step - loss: 2.3504e-04 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.9310\n","\n","Epoch 00281: val_accuracy did not improve from 0.93103\n","Epoch 282/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.1360e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9212\n","\n","Epoch 00282: val_accuracy did not improve from 0.93103\n","Epoch 283/500\n","52/52 [==============================] - 11s 219ms/step - loss: 4.5841e-04 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.9261\n","\n","Epoch 00283: val_accuracy did not improve from 0.93103\n","Epoch 284/500\n","52/52 [==============================] - 11s 218ms/step - loss: 2.4405e-04 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9187\n","\n","Epoch 00284: val_accuracy did not improve from 0.93103\n","Epoch 285/500\n","52/52 [==============================] - 11s 218ms/step - loss: 6.2302e-04 - accuracy: 1.0000 - val_loss: 0.4469 - val_accuracy: 0.9064\n","\n","Epoch 00285: val_accuracy did not improve from 0.93103\n","Epoch 286/500\n","52/52 [==============================] - 11s 219ms/step - loss: 4.9577e-04 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9163\n","\n","Epoch 00286: val_accuracy did not improve from 0.93103\n","Epoch 287/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.4417 - val_accuracy: 0.9138\n","\n","Epoch 00287: val_accuracy did not improve from 0.93103\n","Epoch 288/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.7088 - val_accuracy: 0.8941\n","\n","Epoch 00288: val_accuracy did not improve from 0.93103\n","Epoch 289/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0218 - accuracy: 0.9915 - val_loss: 1.3255 - val_accuracy: 0.8153\n","\n","Epoch 00289: val_accuracy did not improve from 0.93103\n","Epoch 290/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0960 - accuracy: 0.9689 - val_loss: 1.3335 - val_accuracy: 0.8276\n","\n","Epoch 00290: val_accuracy did not improve from 0.93103\n","Epoch 291/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1120 - accuracy: 0.9635 - val_loss: 0.9794 - val_accuracy: 0.8522\n","\n","Epoch 00291: val_accuracy did not improve from 0.93103\n","Epoch 292/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1165 - accuracy: 0.9641 - val_loss: 0.8432 - val_accuracy: 0.8842\n","\n","Epoch 00292: val_accuracy did not improve from 0.93103\n","Epoch 293/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0339 - accuracy: 0.9884 - val_loss: 0.8181 - val_accuracy: 0.8670\n","\n","Epoch 00293: val_accuracy did not improve from 0.93103\n","Epoch 294/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.4869 - val_accuracy: 0.9039\n","\n","Epoch 00294: val_accuracy did not improve from 0.93103\n","Epoch 295/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4404 - val_accuracy: 0.9089\n","\n","Epoch 00295: val_accuracy did not improve from 0.93103\n","Epoch 296/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9163\n","\n","Epoch 00296: val_accuracy did not improve from 0.93103\n","Epoch 297/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.9286\n","\n","Epoch 00297: val_accuracy did not improve from 0.93103\n","Epoch 298/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.3908 - val_accuracy: 0.9236\n","\n","Epoch 00298: val_accuracy did not improve from 0.93103\n","Epoch 299/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.3824 - val_accuracy: 0.9335\n","\n","Epoch 00299: val_accuracy improved from 0.93103 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 300/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4268 - val_accuracy: 0.9187\n","\n","Epoch 00300: val_accuracy did not improve from 0.93350\n","Epoch 301/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.9113\n","\n","Epoch 00301: val_accuracy did not improve from 0.93350\n","Epoch 302/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9236\n","\n","Epoch 00302: val_accuracy did not improve from 0.93350\n","Epoch 303/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.3675 - val_accuracy: 0.9261\n","\n","Epoch 00303: val_accuracy did not improve from 0.93350\n","Epoch 304/500\n","52/52 [==============================] - 11s 218ms/step - loss: 7.2508e-04 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.9286\n","\n","Epoch 00304: val_accuracy did not improve from 0.93350\n","Epoch 305/500\n","52/52 [==============================] - 11s 218ms/step - loss: 7.2771e-04 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9187\n","\n","Epoch 00305: val_accuracy did not improve from 0.93350\n","Epoch 306/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4023 - val_accuracy: 0.9236\n","\n","Epoch 00306: val_accuracy did not improve from 0.93350\n","Epoch 307/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.4016 - val_accuracy: 0.9261\n","\n","Epoch 00307: val_accuracy did not improve from 0.93350\n","Epoch 308/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.3730 - val_accuracy: 0.9236\n","\n","Epoch 00308: val_accuracy did not improve from 0.93350\n","Epoch 309/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4176 - val_accuracy: 0.9261\n","\n","Epoch 00309: val_accuracy did not improve from 0.93350\n","Epoch 310/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.4262 - val_accuracy: 0.9261\n","\n","Epoch 00310: val_accuracy did not improve from 0.93350\n","Epoch 311/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.5618 - val_accuracy: 0.9015\n","\n","Epoch 00311: val_accuracy did not improve from 0.93350\n","Epoch 312/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.5663 - val_accuracy: 0.8892\n","\n","Epoch 00312: val_accuracy did not improve from 0.93350\n","Epoch 313/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.5818 - val_accuracy: 0.9015\n","\n","Epoch 00313: val_accuracy did not improve from 0.93350\n","Epoch 314/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0171 - accuracy: 0.9976 - val_loss: 0.5056 - val_accuracy: 0.9064\n","\n","Epoch 00314: val_accuracy did not improve from 0.93350\n","Epoch 315/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 1.5162 - val_accuracy: 0.8103\n","\n","Epoch 00315: val_accuracy did not improve from 0.93350\n","Epoch 316/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0360 - accuracy: 0.9896 - val_loss: 0.6507 - val_accuracy: 0.8744\n","\n","Epoch 00316: val_accuracy did not improve from 0.93350\n","Epoch 317/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 0.5205 - val_accuracy: 0.9015\n","\n","Epoch 00317: val_accuracy did not improve from 0.93350\n","Epoch 318/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.4883 - val_accuracy: 0.9039\n","\n","Epoch 00318: val_accuracy did not improve from 0.93350\n","Epoch 319/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0166 - accuracy: 0.9933 - val_loss: 0.6022 - val_accuracy: 0.8818\n","\n","Epoch 00319: val_accuracy did not improve from 0.93350\n","Epoch 320/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0056 - accuracy: 0.9970 - val_loss: 0.5161 - val_accuracy: 0.9138\n","\n","Epoch 00320: val_accuracy did not improve from 0.93350\n","Epoch 321/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4753 - val_accuracy: 0.9236\n","\n","Epoch 00321: val_accuracy did not improve from 0.93350\n","Epoch 322/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4932 - val_accuracy: 0.9187\n","\n","Epoch 00322: val_accuracy did not improve from 0.93350\n","Epoch 323/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4338 - val_accuracy: 0.9335\n","\n","Epoch 00323: val_accuracy did not improve from 0.93350\n","Epoch 324/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0438 - accuracy: 0.9890 - val_loss: 0.9041 - val_accuracy: 0.8719\n","\n","Epoch 00324: val_accuracy did not improve from 0.93350\n","Epoch 325/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.8726 - val_accuracy: 0.8645\n","\n","Epoch 00325: val_accuracy did not improve from 0.93350\n","Epoch 326/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.4144 - val_accuracy: 0.9113\n","\n","Epoch 00326: val_accuracy did not improve from 0.93350\n","Epoch 327/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.5200 - val_accuracy: 0.9015\n","\n","Epoch 00327: val_accuracy did not improve from 0.93350\n","Epoch 328/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.9384\n","\n","Epoch 00328: val_accuracy improved from 0.93350 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 329/500\n","52/52 [==============================] - 11s 219ms/step - loss: 9.5372e-04 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.9163\n","\n","Epoch 00329: val_accuracy did not improve from 0.93842\n","Epoch 330/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.9236\n","\n","Epoch 00330: val_accuracy did not improve from 0.93842\n","Epoch 331/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.9335\n","\n","Epoch 00331: val_accuracy did not improve from 0.93842\n","Epoch 332/500\n","52/52 [==============================] - 11s 219ms/step - loss: 5.0500e-04 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.9187\n","\n","Epoch 00332: val_accuracy did not improve from 0.93842\n","Epoch 333/500\n","52/52 [==============================] - 11s 218ms/step - loss: 8.8469e-04 - accuracy: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.9089\n","\n","Epoch 00333: val_accuracy did not improve from 0.93842\n","Epoch 334/500\n","52/52 [==============================] - 11s 218ms/step - loss: 8.5490e-04 - accuracy: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.9064\n","\n","Epoch 00334: val_accuracy did not improve from 0.93842\n","Epoch 335/500\n","52/52 [==============================] - 12s 220ms/step - loss: 5.4692e-04 - accuracy: 1.0000 - val_loss: 0.5225 - val_accuracy: 0.9015\n","\n","Epoch 00335: val_accuracy did not improve from 0.93842\n","Epoch 336/500\n","52/52 [==============================] - 11s 219ms/step - loss: 5.5498e-04 - accuracy: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.9187\n","\n","Epoch 00336: val_accuracy did not improve from 0.93842\n","Epoch 337/500\n","52/52 [==============================] - 11s 219ms/step - loss: 5.4496e-04 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9212\n","\n","Epoch 00337: val_accuracy did not improve from 0.93842\n","Epoch 338/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 0.5055 - val_accuracy: 0.9286\n","\n","Epoch 00338: val_accuracy did not improve from 0.93842\n","Epoch 339/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4483 - val_accuracy: 0.9187\n","\n","Epoch 00339: val_accuracy did not improve from 0.93842\n","Epoch 340/500\n","52/52 [==============================] - 11s 219ms/step - loss: 9.0663e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.9163\n","\n","Epoch 00340: val_accuracy did not improve from 0.93842\n","Epoch 341/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.5842 - val_accuracy: 0.9113\n","\n","Epoch 00341: val_accuracy did not improve from 0.93842\n","Epoch 342/500\n","52/52 [==============================] - 11s 218ms/step - loss: 5.3413e-04 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9212\n","\n","Epoch 00342: val_accuracy did not improve from 0.93842\n","Epoch 343/500\n","52/52 [==============================] - 11s 219ms/step - loss: 6.6592e-04 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.9163\n","\n","Epoch 00343: val_accuracy did not improve from 0.93842\n","Epoch 344/500\n","52/52 [==============================] - 11s 218ms/step - loss: 3.6743e-04 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9187\n","\n","Epoch 00344: val_accuracy did not improve from 0.93842\n","Epoch 345/500\n","52/52 [==============================] - 11s 219ms/step - loss: 1.7696e-04 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.9212\n","\n","Epoch 00345: val_accuracy did not improve from 0.93842\n","Epoch 346/500\n","52/52 [==============================] - 11s 219ms/step - loss: 3.7690e-04 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9236\n","\n","Epoch 00346: val_accuracy did not improve from 0.93842\n","Epoch 347/500\n","52/52 [==============================] - 11s 218ms/step - loss: 2.7837e-04 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.9212\n","\n","Epoch 00347: val_accuracy did not improve from 0.93842\n","Epoch 348/500\n","52/52 [==============================] - 11s 217ms/step - loss: 1.9763e-04 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9261\n","\n","Epoch 00348: val_accuracy did not improve from 0.93842\n","Epoch 349/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4910 - val_accuracy: 0.9138\n","\n","Epoch 00349: val_accuracy did not improve from 0.93842\n","Epoch 350/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 0.5599 - val_accuracy: 0.9039\n","\n","Epoch 00350: val_accuracy did not improve from 0.93842\n","Epoch 351/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0818 - accuracy: 0.9738 - val_loss: 1.0087 - val_accuracy: 0.8670\n","\n","Epoch 00351: val_accuracy did not improve from 0.93842\n","Epoch 352/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0821 - accuracy: 0.9744 - val_loss: 1.0241 - val_accuracy: 0.8892\n","\n","Epoch 00352: val_accuracy did not improve from 0.93842\n","Epoch 353/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0217 - accuracy: 0.9909 - val_loss: 1.0868 - val_accuracy: 0.8793\n","\n","Epoch 00353: val_accuracy did not improve from 0.93842\n","Epoch 354/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0191 - accuracy: 0.9951 - val_loss: 0.6120 - val_accuracy: 0.8966\n","\n","Epoch 00354: val_accuracy did not improve from 0.93842\n","Epoch 355/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0983 - accuracy: 0.9787 - val_loss: 0.8011 - val_accuracy: 0.8695\n","\n","Epoch 00355: val_accuracy did not improve from 0.93842\n","Epoch 356/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.5225 - val_accuracy: 0.8966\n","\n","Epoch 00356: val_accuracy did not improve from 0.93842\n","Epoch 357/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.4748 - val_accuracy: 0.9064\n","\n","Epoch 00357: val_accuracy did not improve from 0.93842\n","Epoch 358/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.4597 - val_accuracy: 0.9187\n","\n","Epoch 00358: val_accuracy did not improve from 0.93842\n","Epoch 359/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.3667 - val_accuracy: 0.9163\n","\n","Epoch 00359: val_accuracy did not improve from 0.93842\n","Epoch 360/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4556 - val_accuracy: 0.9163\n","\n","Epoch 00360: val_accuracy did not improve from 0.93842\n","Epoch 361/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.4535 - val_accuracy: 0.9138\n","\n","Epoch 00361: val_accuracy did not improve from 0.93842\n","Epoch 362/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3867 - val_accuracy: 0.9113\n","\n","Epoch 00362: val_accuracy did not improve from 0.93842\n","Epoch 363/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9187\n","\n","Epoch 00363: val_accuracy did not improve from 0.93842\n","Epoch 364/500\n","52/52 [==============================] - 11s 218ms/step - loss: 7.9847e-04 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9310\n","\n","Epoch 00364: val_accuracy did not improve from 0.93842\n","Epoch 365/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9310\n","\n","Epoch 00365: val_accuracy did not improve from 0.93842\n","Epoch 366/500\n","52/52 [==============================] - 11s 218ms/step - loss: 8.7820e-04 - accuracy: 1.0000 - val_loss: 0.4651 - val_accuracy: 0.9187\n","\n","Epoch 00366: val_accuracy did not improve from 0.93842\n","Epoch 367/500\n","52/52 [==============================] - 11s 218ms/step - loss: 5.4545e-04 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.9163\n","\n","Epoch 00367: val_accuracy did not improve from 0.93842\n","Epoch 368/500\n","52/52 [==============================] - 11s 218ms/step - loss: 3.5722e-04 - accuracy: 1.0000 - val_loss: 0.3749 - val_accuracy: 0.9335\n","\n","Epoch 00368: val_accuracy did not improve from 0.93842\n","Epoch 369/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.3969 - val_accuracy: 0.9261\n","\n","Epoch 00369: val_accuracy did not improve from 0.93842\n","Epoch 370/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4844 - val_accuracy: 0.9163\n","\n","Epoch 00370: val_accuracy did not improve from 0.93842\n","Epoch 371/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5663 - val_accuracy: 0.9089\n","\n","Epoch 00371: val_accuracy did not improve from 0.93842\n","Epoch 372/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4722 - val_accuracy: 0.9236\n","\n","Epoch 00372: val_accuracy did not improve from 0.93842\n","Epoch 373/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.4342 - val_accuracy: 0.9212\n","\n","Epoch 00373: val_accuracy did not improve from 0.93842\n","Epoch 374/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4124 - val_accuracy: 0.9236\n","\n","Epoch 00374: val_accuracy did not improve from 0.93842\n","Epoch 375/500\n","52/52 [==============================] - 11s 219ms/step - loss: 7.3702e-04 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.9286\n","\n","Epoch 00375: val_accuracy did not improve from 0.93842\n","Epoch 376/500\n","52/52 [==============================] - 11s 220ms/step - loss: 2.4833e-04 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.9433\n","\n","Epoch 00376: val_accuracy improved from 0.93842 to 0.94335, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 377/500\n","52/52 [==============================] - 12s 221ms/step - loss: 4.3008e-04 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9384\n","\n","Epoch 00377: val_accuracy did not improve from 0.94335\n","Epoch 378/500\n","52/52 [==============================] - 11s 219ms/step - loss: 5.4816e-04 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.9384\n","\n","Epoch 00378: val_accuracy did not improve from 0.94335\n","Epoch 379/500\n","52/52 [==============================] - 12s 220ms/step - loss: 6.4588e-04 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.9138\n","\n","Epoch 00379: val_accuracy did not improve from 0.94335\n","Epoch 380/500\n","52/52 [==============================] - 11s 219ms/step - loss: 5.1570e-04 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.9286\n","\n","Epoch 00380: val_accuracy did not improve from 0.94335\n","Epoch 381/500\n","52/52 [==============================] - 11s 218ms/step - loss: 8.1032e-04 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.9261\n","\n","Epoch 00381: val_accuracy did not improve from 0.94335\n","Epoch 382/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.3978 - val_accuracy: 0.9310\n","\n","Epoch 00382: val_accuracy did not improve from 0.94335\n","Epoch 383/500\n","52/52 [==============================] - 11s 218ms/step - loss: 4.1168e-04 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9187\n","\n","Epoch 00383: val_accuracy did not improve from 0.94335\n","Epoch 384/500\n","52/52 [==============================] - 11s 218ms/step - loss: 4.4530e-04 - accuracy: 1.0000 - val_loss: 0.3655 - val_accuracy: 0.9384\n","\n","Epoch 00384: val_accuracy did not improve from 0.94335\n","Epoch 385/500\n","52/52 [==============================] - 11s 218ms/step - loss: 2.7816e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9360\n","\n","Epoch 00385: val_accuracy did not improve from 0.94335\n","Epoch 386/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.1769e-04 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9458\n","\n","Epoch 00386: val_accuracy improved from 0.94335 to 0.94581, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5\n","Epoch 387/500\n","52/52 [==============================] - 11s 219ms/step - loss: 5.5364e-04 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9433\n","\n","Epoch 00387: val_accuracy did not improve from 0.94581\n","Epoch 388/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 0.6748 - val_accuracy: 0.8842\n","\n","Epoch 00388: val_accuracy did not improve from 0.94581\n","Epoch 389/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0577 - accuracy: 0.9848 - val_loss: 0.8591 - val_accuracy: 0.8645\n","\n","Epoch 00389: val_accuracy did not improve from 0.94581\n","Epoch 390/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1621 - accuracy: 0.9543 - val_loss: 1.1832 - val_accuracy: 0.8424\n","\n","Epoch 00390: val_accuracy did not improve from 0.94581\n","Epoch 391/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0433 - accuracy: 0.9829 - val_loss: 1.0349 - val_accuracy: 0.8473\n","\n","Epoch 00391: val_accuracy did not improve from 0.94581\n","Epoch 392/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.5053 - val_accuracy: 0.8990\n","\n","Epoch 00392: val_accuracy did not improve from 0.94581\n","Epoch 393/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.5084 - val_accuracy: 0.8990\n","\n","Epoch 00393: val_accuracy did not improve from 0.94581\n","Epoch 394/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.4715 - val_accuracy: 0.9163\n","\n","Epoch 00394: val_accuracy did not improve from 0.94581\n","Epoch 395/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.4423 - val_accuracy: 0.9089\n","\n","Epoch 00395: val_accuracy did not improve from 0.94581\n","Epoch 396/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.4669 - val_accuracy: 0.9163\n","\n","Epoch 00396: val_accuracy did not improve from 0.94581\n","Epoch 397/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4178 - val_accuracy: 0.9310\n","\n","Epoch 00397: val_accuracy did not improve from 0.94581\n","Epoch 398/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4316 - val_accuracy: 0.9187\n","\n","Epoch 00398: val_accuracy did not improve from 0.94581\n","Epoch 399/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4373 - val_accuracy: 0.9089\n","\n","Epoch 00399: val_accuracy did not improve from 0.94581\n","Epoch 400/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9261\n","\n","Epoch 00400: val_accuracy did not improve from 0.94581\n","Epoch 401/500\n","52/52 [==============================] - 11s 219ms/step - loss: 8.7454e-04 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9212\n","\n","Epoch 00401: val_accuracy did not improve from 0.94581\n","Epoch 402/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.3936 - val_accuracy: 0.9236\n","\n","Epoch 00402: val_accuracy did not improve from 0.94581\n","Epoch 403/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.4166 - val_accuracy: 0.9064\n","\n","Epoch 00403: val_accuracy did not improve from 0.94581\n","Epoch 404/500\n","52/52 [==============================] - 11s 218ms/step - loss: 8.6621e-04 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9163\n","\n","Epoch 00404: val_accuracy did not improve from 0.94581\n","Epoch 405/500\n","52/52 [==============================] - 11s 219ms/step - loss: 7.1705e-04 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.9187\n","\n","Epoch 00405: val_accuracy did not improve from 0.94581\n","Epoch 406/500\n","52/52 [==============================] - 11s 219ms/step - loss: 3.2913e-04 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9138\n","\n","Epoch 00406: val_accuracy did not improve from 0.94581\n","Epoch 407/500\n","52/52 [==============================] - 11s 219ms/step - loss: 8.3578e-04 - accuracy: 1.0000 - val_loss: 0.4469 - val_accuracy: 0.9064\n","\n","Epoch 00407: val_accuracy did not improve from 0.94581\n","Epoch 408/500\n","52/52 [==============================] - 11s 219ms/step - loss: 8.6945e-04 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.9286\n","\n","Epoch 00408: val_accuracy did not improve from 0.94581\n","Epoch 409/500\n","52/52 [==============================] - 11s 218ms/step - loss: 3.4721e-04 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9360\n","\n","Epoch 00409: val_accuracy did not improve from 0.94581\n","Epoch 410/500\n","52/52 [==============================] - 11s 218ms/step - loss: 2.7504e-04 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9212\n","\n","Epoch 00410: val_accuracy did not improve from 0.94581\n","Epoch 411/500\n","52/52 [==============================] - 11s 218ms/step - loss: 8.3798e-04 - accuracy: 0.9994 - val_loss: 0.3849 - val_accuracy: 0.9236\n","\n","Epoch 00411: val_accuracy did not improve from 0.94581\n","Epoch 412/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3785 - val_accuracy: 0.9187\n","\n","Epoch 00412: val_accuracy did not improve from 0.94581\n","Epoch 413/500\n","52/52 [==============================] - 11s 218ms/step - loss: 5.1876e-04 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.9187\n","\n","Epoch 00413: val_accuracy did not improve from 0.94581\n","Epoch 414/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.6446e-04 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.9113\n","\n","Epoch 00414: val_accuracy did not improve from 0.94581\n","Epoch 415/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4617 - val_accuracy: 0.9113\n","\n","Epoch 00415: val_accuracy did not improve from 0.94581\n","Epoch 416/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.5093 - val_accuracy: 0.9163\n","\n","Epoch 00416: val_accuracy did not improve from 0.94581\n","Epoch 417/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5129 - val_accuracy: 0.9089\n","\n","Epoch 00417: val_accuracy did not improve from 0.94581\n","Epoch 418/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0499 - accuracy: 0.9872 - val_loss: 0.8910 - val_accuracy: 0.8473\n","\n","Epoch 00418: val_accuracy did not improve from 0.94581\n","Epoch 419/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0366 - accuracy: 0.9866 - val_loss: 0.6161 - val_accuracy: 0.8768\n","\n","Epoch 00419: val_accuracy did not improve from 0.94581\n","Epoch 420/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0313 - accuracy: 0.9903 - val_loss: 0.8866 - val_accuracy: 0.8522\n","\n","Epoch 00420: val_accuracy did not improve from 0.94581\n","Epoch 421/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.6565 - val_accuracy: 0.8966\n","\n","Epoch 00421: val_accuracy did not improve from 0.94581\n","Epoch 422/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.7229 - val_accuracy: 0.8719\n","\n","Epoch 00422: val_accuracy did not improve from 0.94581\n","Epoch 423/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.7349 - val_accuracy: 0.8719\n","\n","Epoch 00423: val_accuracy did not improve from 0.94581\n","Epoch 424/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.6852 - val_accuracy: 0.8818\n","\n","Epoch 00424: val_accuracy did not improve from 0.94581\n","Epoch 425/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0168 - accuracy: 0.9970 - val_loss: 0.6224 - val_accuracy: 0.8892\n","\n","Epoch 00425: val_accuracy did not improve from 0.94581\n","Epoch 426/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 1.0159 - val_accuracy: 0.8424\n","\n","Epoch 00426: val_accuracy did not improve from 0.94581\n","Epoch 427/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.6036 - val_accuracy: 0.9089\n","\n","Epoch 00427: val_accuracy did not improve from 0.94581\n","Epoch 428/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.6078 - val_accuracy: 0.8990\n","\n","Epoch 00428: val_accuracy did not improve from 0.94581\n","Epoch 429/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.4108 - val_accuracy: 0.9113\n","\n","Epoch 00429: val_accuracy did not improve from 0.94581\n","Epoch 430/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.9163\n","\n","Epoch 00430: val_accuracy did not improve from 0.94581\n","Epoch 431/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.4631 - val_accuracy: 0.9039\n","\n","Epoch 00431: val_accuracy did not improve from 0.94581\n","Epoch 432/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.9187\n","\n","Epoch 00432: val_accuracy did not improve from 0.94581\n","Epoch 433/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4201 - val_accuracy: 0.9064\n","\n","Epoch 00433: val_accuracy did not improve from 0.94581\n","Epoch 434/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4848 - val_accuracy: 0.9089\n","\n","Epoch 00434: val_accuracy did not improve from 0.94581\n","Epoch 435/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.9113\n","\n","Epoch 00435: val_accuracy did not improve from 0.94581\n","Epoch 436/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5231 - val_accuracy: 0.9138\n","\n","Epoch 00436: val_accuracy did not improve from 0.94581\n","Epoch 437/500\n","52/52 [==============================] - 12s 220ms/step - loss: 9.6783e-04 - accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.9212\n","\n","Epoch 00437: val_accuracy did not improve from 0.94581\n","Epoch 438/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5073 - val_accuracy: 0.9236\n","\n","Epoch 00438: val_accuracy did not improve from 0.94581\n","Epoch 439/500\n","52/52 [==============================] - 11s 219ms/step - loss: 6.8467e-04 - accuracy: 1.0000 - val_loss: 0.3652 - val_accuracy: 0.9261\n","\n","Epoch 00439: val_accuracy did not improve from 0.94581\n","Epoch 440/500\n","52/52 [==============================] - 11s 219ms/step - loss: 8.5808e-04 - accuracy: 0.9994 - val_loss: 0.4063 - val_accuracy: 0.9384\n","\n","Epoch 00440: val_accuracy did not improve from 0.94581\n","Epoch 441/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4432 - val_accuracy: 0.9360\n","\n","Epoch 00441: val_accuracy did not improve from 0.94581\n","Epoch 442/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.5752 - val_accuracy: 0.9064\n","\n","Epoch 00442: val_accuracy did not improve from 0.94581\n","Epoch 443/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4516 - val_accuracy: 0.9138\n","\n","Epoch 00443: val_accuracy did not improve from 0.94581\n","Epoch 444/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.3924 - val_accuracy: 0.9360\n","\n","Epoch 00444: val_accuracy did not improve from 0.94581\n","Epoch 445/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4375 - val_accuracy: 0.9089\n","\n","Epoch 00445: val_accuracy did not improve from 0.94581\n","Epoch 446/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4973 - val_accuracy: 0.9113\n","\n","Epoch 00446: val_accuracy did not improve from 0.94581\n","Epoch 447/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4223 - val_accuracy: 0.9163\n","\n","Epoch 00447: val_accuracy did not improve from 0.94581\n","Epoch 448/500\n","52/52 [==============================] - 11s 219ms/step - loss: 5.4712e-04 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.9286\n","\n","Epoch 00448: val_accuracy did not improve from 0.94581\n","Epoch 449/500\n","52/52 [==============================] - 11s 219ms/step - loss: 5.8689e-04 - accuracy: 1.0000 - val_loss: 0.4081 - val_accuracy: 0.9212\n","\n","Epoch 00449: val_accuracy did not improve from 0.94581\n","Epoch 450/500\n","52/52 [==============================] - 11s 219ms/step - loss: 3.1228e-04 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.9236\n","\n","Epoch 00450: val_accuracy did not improve from 0.94581\n","Epoch 451/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 1.2407 - val_accuracy: 0.8300\n","\n","Epoch 00451: val_accuracy did not improve from 0.94581\n","Epoch 452/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.6089 - val_accuracy: 0.9113\n","\n","Epoch 00452: val_accuracy did not improve from 0.94581\n","Epoch 453/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5421 - val_accuracy: 0.9138\n","\n","Epoch 00453: val_accuracy did not improve from 0.94581\n","Epoch 454/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 0.8247 - val_accuracy: 0.8842\n","\n","Epoch 00454: val_accuracy did not improve from 0.94581\n","Epoch 455/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0173 - accuracy: 0.9933 - val_loss: 0.6811 - val_accuracy: 0.8670\n","\n","Epoch 00455: val_accuracy did not improve from 0.94581\n","Epoch 456/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.5254 - val_accuracy: 0.9039\n","\n","Epoch 00456: val_accuracy did not improve from 0.94581\n","Epoch 457/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.8541 - val_accuracy: 0.8867\n","\n","Epoch 00457: val_accuracy did not improve from 0.94581\n","Epoch 458/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0858 - accuracy: 0.9769 - val_loss: 1.0540 - val_accuracy: 0.8325\n","\n","Epoch 00458: val_accuracy did not improve from 0.94581\n","Epoch 459/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0269 - accuracy: 0.9896 - val_loss: 0.9864 - val_accuracy: 0.8473\n","\n","Epoch 00459: val_accuracy did not improve from 0.94581\n","Epoch 460/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5796 - val_accuracy: 0.9039\n","\n","Epoch 00460: val_accuracy did not improve from 0.94581\n","Epoch 461/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4970 - val_accuracy: 0.9187\n","\n","Epoch 00461: val_accuracy did not improve from 0.94581\n","Epoch 462/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.4288 - val_accuracy: 0.9236\n","\n","Epoch 00462: val_accuracy did not improve from 0.94581\n","Epoch 463/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4184 - val_accuracy: 0.9236\n","\n","Epoch 00463: val_accuracy did not improve from 0.94581\n","Epoch 464/500\n","52/52 [==============================] - 11s 218ms/step - loss: 8.1135e-04 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.9286\n","\n","Epoch 00464: val_accuracy did not improve from 0.94581\n","Epoch 465/500\n","52/52 [==============================] - 11s 219ms/step - loss: 6.7010e-04 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.9187\n","\n","Epoch 00465: val_accuracy did not improve from 0.94581\n","Epoch 466/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5278 - val_accuracy: 0.9261\n","\n","Epoch 00466: val_accuracy did not improve from 0.94581\n","Epoch 467/500\n","52/52 [==============================] - 11s 219ms/step - loss: 8.0465e-04 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.9212\n","\n","Epoch 00467: val_accuracy did not improve from 0.94581\n","Epoch 468/500\n","52/52 [==============================] - 11s 219ms/step - loss: 7.4890e-04 - accuracy: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.9187\n","\n","Epoch 00468: val_accuracy did not improve from 0.94581\n","Epoch 469/500\n","52/52 [==============================] - 12s 220ms/step - loss: 3.0013e-04 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.9335\n","\n","Epoch 00469: val_accuracy did not improve from 0.94581\n","Epoch 470/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.0342 - accuracy: 0.9909 - val_loss: 0.6272 - val_accuracy: 0.8793\n","\n","Epoch 00470: val_accuracy did not improve from 0.94581\n","Epoch 471/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0231 - accuracy: 0.9945 - val_loss: 0.7028 - val_accuracy: 0.9064\n","\n","Epoch 00471: val_accuracy did not improve from 0.94581\n","Epoch 472/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.6527 - val_accuracy: 0.8941\n","\n","Epoch 00472: val_accuracy did not improve from 0.94581\n","Epoch 473/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5721 - val_accuracy: 0.9039\n","\n","Epoch 00473: val_accuracy did not improve from 0.94581\n","Epoch 474/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5807 - val_accuracy: 0.9064\n","\n","Epoch 00474: val_accuracy did not improve from 0.94581\n","Epoch 475/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5273 - val_accuracy: 0.9187\n","\n","Epoch 00475: val_accuracy did not improve from 0.94581\n","Epoch 476/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5518 - val_accuracy: 0.9089\n","\n","Epoch 00476: val_accuracy did not improve from 0.94581\n","Epoch 477/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5177 - val_accuracy: 0.9113\n","\n","Epoch 00477: val_accuracy did not improve from 0.94581\n","Epoch 478/500\n","52/52 [==============================] - 11s 219ms/step - loss: 3.6677e-04 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9163\n","\n","Epoch 00478: val_accuracy did not improve from 0.94581\n","Epoch 479/500\n","52/52 [==============================] - 11s 219ms/step - loss: 4.5098e-04 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.9212\n","\n","Epoch 00479: val_accuracy did not improve from 0.94581\n","Epoch 480/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5540 - val_accuracy: 0.9039\n","\n","Epoch 00480: val_accuracy did not improve from 0.94581\n","Epoch 481/500\n","52/52 [==============================] - 12s 220ms/step - loss: 7.6095e-04 - accuracy: 1.0000 - val_loss: 0.5226 - val_accuracy: 0.9089\n","\n","Epoch 00481: val_accuracy did not improve from 0.94581\n","Epoch 482/500\n","52/52 [==============================] - 11s 219ms/step - loss: 1.3677e-04 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.9163\n","\n","Epoch 00482: val_accuracy did not improve from 0.94581\n","Epoch 483/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.6817e-04 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9310\n","\n","Epoch 00483: val_accuracy did not improve from 0.94581\n","Epoch 484/500\n","52/52 [==============================] - 11s 219ms/step - loss: 6.7189e-04 - accuracy: 1.0000 - val_loss: 0.4769 - val_accuracy: 0.9187\n","\n","Epoch 00484: val_accuracy did not improve from 0.94581\n","Epoch 485/500\n","52/52 [==============================] - 12s 220ms/step - loss: 4.0768e-04 - accuracy: 1.0000 - val_loss: 0.5391 - val_accuracy: 0.9163\n","\n","Epoch 00485: val_accuracy did not improve from 0.94581\n","Epoch 486/500\n","52/52 [==============================] - 12s 220ms/step - loss: 3.0120e-04 - accuracy: 1.0000 - val_loss: 0.4771 - val_accuracy: 0.9236\n","\n","Epoch 00486: val_accuracy did not improve from 0.94581\n","Epoch 487/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5494 - val_accuracy: 0.9163\n","\n","Epoch 00487: val_accuracy did not improve from 0.94581\n","Epoch 488/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.5795 - val_accuracy: 0.9113\n","\n","Epoch 00488: val_accuracy did not improve from 0.94581\n","Epoch 489/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0126 - accuracy: 0.9982 - val_loss: 0.6294 - val_accuracy: 0.9138\n","\n","Epoch 00489: val_accuracy did not improve from 0.94581\n","Epoch 490/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 0.6885 - val_accuracy: 0.8793\n","\n","Epoch 00490: val_accuracy did not improve from 0.94581\n","Epoch 491/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.6306 - val_accuracy: 0.9089\n","\n","Epoch 00491: val_accuracy did not improve from 0.94581\n","Epoch 492/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.5550 - val_accuracy: 0.9039\n","\n","Epoch 00492: val_accuracy did not improve from 0.94581\n","Epoch 493/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.5005 - val_accuracy: 0.9113\n","\n","Epoch 00493: val_accuracy did not improve from 0.94581\n","Epoch 494/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5291 - val_accuracy: 0.9187\n","\n","Epoch 00494: val_accuracy did not improve from 0.94581\n","Epoch 495/500\n","52/52 [==============================] - 11s 218ms/step - loss: 4.8470e-04 - accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.9212\n","\n","Epoch 00495: val_accuracy did not improve from 0.94581\n","Epoch 496/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4731 - val_accuracy: 0.9236\n","\n","Epoch 00496: val_accuracy did not improve from 0.94581\n","Epoch 497/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.6184 - val_accuracy: 0.9039\n","\n","Epoch 00497: val_accuracy did not improve from 0.94581\n","Epoch 498/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.6778 - val_accuracy: 0.8990\n","\n","Epoch 00498: val_accuracy did not improve from 0.94581\n","Epoch 499/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.5845 - val_accuracy: 0.8966\n","\n","Epoch 00499: val_accuracy did not improve from 0.94581\n","Epoch 500/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0257 - accuracy: 0.9951 - val_loss: 0.8387 - val_accuracy: 0.8645\n","\n","Epoch 00500: val_accuracy did not improve from 0.94581\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f25e232f950>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1630501903007,"user_tz":-540,"elapsed":644,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d77ff244-5f10-47f7-a14b-9c01c774e737"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1630501914189,"user_tz":-540,"elapsed":11189,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_2_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1630501915032,"user_tz":-540,"elapsed":849,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630501915595,"user_tz":-540,"elapsed":579,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"87922dfa-5b8e-4114-97e9-e08836abe8ac"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630501947574,"user_tz":-540,"elapsed":31990,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"5d2954a3-a64b-4804-bcc2-8e35979951f8"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1630501947576,"user_tz":-540,"elapsed":25,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1630501947577,"user_tz":-540,"elapsed":24,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1630501949301,"user_tz":-540,"elapsed":1746,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1630501949303,"user_tz":-540,"elapsed":10,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1630501964107,"user_tz":-540,"elapsed":14810,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1630501964108,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d1b5f074-1190-431f-f214-6da8b712a42e"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1630501966346,"user_tz":-540,"elapsed":2244,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"190a643b-4268-4ed0-e709-ecd3f44b237b"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_005_2_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_005_2_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_1ba9855f-08e4-4af0-8dca-29afb2981bb0\", \"HeightShiftRange_005_2_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}