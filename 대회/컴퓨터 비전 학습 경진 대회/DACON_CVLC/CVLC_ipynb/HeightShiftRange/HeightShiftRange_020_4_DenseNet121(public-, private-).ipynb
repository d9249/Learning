{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HeightShiftRange_020_4_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1ZYwQgfbGvCmGKmNM25goBD839_1yJrul","timestamp":1630602408672},{"file_id":"1_j6u69eFZFR-bV-7FdC_KmRhJ8AI-Ifh","timestamp":1630602370180},{"file_id":"1unjV74CiTTQsLla4T4r8Xawlb_l1_ego","timestamp":1630602293534},{"file_id":"1MSEaTlfMh47aob3-U8yPBQNcpxSO0RC6","timestamp":1630524166308},{"file_id":"1uj1q7VaxDNJ4v0Qnpewz9OO5vDawvGL1","timestamp":1630524142681},{"file_id":"1SXi4BHkyVdQzSXMkx23PhKLYG_cgy9Ne","timestamp":1630524118198},{"file_id":"1ktumtKU2gng5uaTndy4q6ORrf_vm1MB5","timestamp":1630516331014},{"file_id":"19fk2AWJq9X3zvPm2WSAtKO7ljZBPUG5l","timestamp":1630516290119},{"file_id":"1ZOrlvLwHgJ8yqXlMzsUBuNpAS1leHpTw","timestamp":1630516251869},{"file_id":"1lrAXMllo7_hAtAVIxPhE7Xno3vS6aFxT","timestamp":1630515420255},{"file_id":"17dTh7DEVFlzrmiHY5X5ldlDVaanaV9e-","timestamp":1630504418101},{"file_id":"1mqEzmVKqNVAF_0chUK1joEpZK_PYc0_4","timestamp":1630504394196},{"file_id":"1mzp8pt1OJt9CAaiKKe25s3yNAqrGew9R","timestamp":1630504147646},{"file_id":"1FMgk3jn7Q2dQ8p_Hu7bJRfcSBb13Rnvo","timestamp":1630504098889},{"file_id":"1hhBZ077MXyvhUnuxI7SD86ahYiLsCzOG","timestamp":1630500513841},{"file_id":"1EEfvNr8ZybJmpeRuKJ-r7__rhnDnaIM7","timestamp":1630495179853},{"file_id":"17e4zKJb3AvCBXA5MdPqutbvT9s1-CP6A","timestamp":1630484224103},{"file_id":"1ZyJ9--fiBCqqZIpZYXBwYIGMXZPnoPvu","timestamp":1630484173863},{"file_id":"1abkZGMd_cSctW05mIZfosyOPOLNr-LK9","timestamp":1630484131331},{"file_id":"1fKp4Svl_srbEAv_YpXTvSwqDozb4bj9H","timestamp":1630484105207},{"file_id":"1y9kcnOXGhn5ArjCk66kqJCIvgyfTRSkk","timestamp":1630483907553},{"file_id":"1o9CD4AI2tKzcdbdLJ4A6xkENgqmZG7oW","timestamp":1630475138628},{"file_id":"17KUAlMIBl9TgxSnuNYcPwx2zScEUw5W-","timestamp":1630475103015},{"file_id":"12cn5R3wN6-IWoeS68BSqi4LxqlCxJxYt","timestamp":1630464969114},{"file_id":"1KLLc8roFaz12DcPj1WHhuKt9ZBQqi76a","timestamp":1630464678834},{"file_id":"1VZIQ1plZ8Dw3dEaOdrcDkgTjXOv0OcTp","timestamp":1630464589009},{"file_id":"1HiqQpOR-bo5ZelQ96RenE8K365HqE7Lv","timestamp":1630438189228},{"file_id":"1ltViornnQGTXyCDuiYgIGfZy1m46LTW_","timestamp":1630438122242},{"file_id":"12vcTsqE7nuRUe3r9-4k5efqml3ud1k9Z","timestamp":1630438078632},{"file_id":"1EdFynNtlBeF206lf5xA2umzEqK_Pjyi5","timestamp":1630437839162},{"file_id":"1pKJK3lnnRPxX28V0U_A45uk_SI4WlDZr","timestamp":1630432659647},{"file_id":"1soBcJ0zzhkPsMINjzGMbYGcga7VX-2Be","timestamp":1630432634550},{"file_id":"12jPQ_wSDDvGyzTBUV-h-pRZ8N-lp9bkW","timestamp":1630425888718},{"file_id":"1ik1ECJq6EbWwGegXLisYoxytv0-7JQcn","timestamp":1630425853722},{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMXthk6YzL8OoMXvHHjwSlf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630608565647,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"04eb0749-d36a-4c62-dce3-7f2b034e1b9e"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Sep  2 18:49:25 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630608581105,"user_tz":-540,"elapsed":15462,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ca5b70a0-dd4d-4245-f01f-b85ec59b29c3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1630608584832,"user_tz":-540,"elapsed":3732,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1630608585917,"user_tz":-540,"elapsed":1100,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1630608588722,"user_tz":-540,"elapsed":2808,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1630608608444,"user_tz":-540,"elapsed":19724,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1630608616325,"user_tz":-540,"elapsed":7883,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630608616326,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"209f6b05-b427-416d-c824-6d954401562b"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630608616751,"user_tz":-540,"elapsed":429,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"bf4e1ad8-dfda-4991-f1e9-5efa7c411a2e"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.2)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1630608616752,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630614660544,"user_tz":-540,"elapsed":6043802,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"e942abb9-e35c-4258-809e-60d9af9c78ef"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 42s 284ms/step - loss: 1.9359 - accuracy: 0.3143 - val_loss: 2.7477 - val_accuracy: 0.1010\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 12s 221ms/step - loss: 1.2461 - accuracy: 0.5719 - val_loss: 15.6508 - val_accuracy: 0.0911\n","\n","Epoch 00002: val_accuracy did not improve from 0.10099\n","Epoch 3/500\n","52/52 [==============================] - 12s 220ms/step - loss: 1.0238 - accuracy: 0.6602 - val_loss: 11.6853 - val_accuracy: 0.0985\n","\n","Epoch 00003: val_accuracy did not improve from 0.10099\n","Epoch 4/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.8669 - accuracy: 0.7083 - val_loss: 9.1801 - val_accuracy: 0.0887\n","\n","Epoch 00004: val_accuracy did not improve from 0.10099\n","Epoch 5/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.7897 - accuracy: 0.7259 - val_loss: 13.6659 - val_accuracy: 0.1133\n","\n","Epoch 00005: val_accuracy improved from 0.10099 to 0.11330, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.7094 - accuracy: 0.7674 - val_loss: 6.3660 - val_accuracy: 0.2488\n","\n","Epoch 00006: val_accuracy improved from 0.11330 to 0.24877, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.6246 - accuracy: 0.7972 - val_loss: 4.8843 - val_accuracy: 0.2438\n","\n","Epoch 00007: val_accuracy did not improve from 0.24877\n","Epoch 8/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.6576 - accuracy: 0.7862 - val_loss: 4.1938 - val_accuracy: 0.2857\n","\n","Epoch 00008: val_accuracy improved from 0.24877 to 0.28571, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.5837 - accuracy: 0.7972 - val_loss: 1.7397 - val_accuracy: 0.5419\n","\n","Epoch 00009: val_accuracy improved from 0.28571 to 0.54187, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.5031 - accuracy: 0.8307 - val_loss: 1.6612 - val_accuracy: 0.5640\n","\n","Epoch 00010: val_accuracy improved from 0.54187 to 0.56404, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.4722 - accuracy: 0.8453 - val_loss: 1.5167 - val_accuracy: 0.6182\n","\n","Epoch 00011: val_accuracy improved from 0.56404 to 0.61823, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.4702 - accuracy: 0.8526 - val_loss: 1.3212 - val_accuracy: 0.6872\n","\n","Epoch 00012: val_accuracy improved from 0.61823 to 0.68719, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 13/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.4381 - accuracy: 0.8520 - val_loss: 0.5570 - val_accuracy: 0.8202\n","\n","Epoch 00013: val_accuracy improved from 0.68719 to 0.82020, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 14/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.3892 - accuracy: 0.8660 - val_loss: 0.8341 - val_accuracy: 0.7537\n","\n","Epoch 00014: val_accuracy did not improve from 0.82020\n","Epoch 15/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.3552 - accuracy: 0.8782 - val_loss: 0.9175 - val_accuracy: 0.7537\n","\n","Epoch 00015: val_accuracy did not improve from 0.82020\n","Epoch 16/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.3535 - accuracy: 0.8770 - val_loss: 0.7800 - val_accuracy: 0.7635\n","\n","Epoch 00016: val_accuracy did not improve from 0.82020\n","Epoch 17/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.3360 - accuracy: 0.8940 - val_loss: 0.7207 - val_accuracy: 0.7882\n","\n","Epoch 00017: val_accuracy did not improve from 0.82020\n","Epoch 18/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.3185 - accuracy: 0.8959 - val_loss: 1.2391 - val_accuracy: 0.6773\n","\n","Epoch 00018: val_accuracy did not improve from 0.82020\n","Epoch 19/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.3133 - accuracy: 0.8873 - val_loss: 0.8488 - val_accuracy: 0.7635\n","\n","Epoch 00019: val_accuracy did not improve from 0.82020\n","Epoch 20/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.3228 - accuracy: 0.8904 - val_loss: 0.8042 - val_accuracy: 0.7808\n","\n","Epoch 00020: val_accuracy did not improve from 0.82020\n","Epoch 21/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.3203 - accuracy: 0.8849 - val_loss: 1.1492 - val_accuracy: 0.7069\n","\n","Epoch 00021: val_accuracy did not improve from 0.82020\n","Epoch 22/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.2521 - accuracy: 0.9214 - val_loss: 0.6028 - val_accuracy: 0.8325\n","\n","Epoch 00022: val_accuracy improved from 0.82020 to 0.83251, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 23/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.3081 - accuracy: 0.9038 - val_loss: 0.5893 - val_accuracy: 0.8227\n","\n","Epoch 00023: val_accuracy did not improve from 0.83251\n","Epoch 24/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.2426 - accuracy: 0.9190 - val_loss: 0.8783 - val_accuracy: 0.7438\n","\n","Epoch 00024: val_accuracy did not improve from 0.83251\n","Epoch 25/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.2599 - accuracy: 0.9129 - val_loss: 0.6965 - val_accuracy: 0.8251\n","\n","Epoch 00025: val_accuracy did not improve from 0.83251\n","Epoch 26/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.2015 - accuracy: 0.9324 - val_loss: 0.5958 - val_accuracy: 0.7833\n","\n","Epoch 00026: val_accuracy did not improve from 0.83251\n","Epoch 27/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1787 - accuracy: 0.9409 - val_loss: 1.2482 - val_accuracy: 0.7044\n","\n","Epoch 00027: val_accuracy did not improve from 0.83251\n","Epoch 28/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1868 - accuracy: 0.9348 - val_loss: 0.5149 - val_accuracy: 0.8448\n","\n","Epoch 00028: val_accuracy improved from 0.83251 to 0.84483, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 29/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1938 - accuracy: 0.9348 - val_loss: 0.5925 - val_accuracy: 0.8596\n","\n","Epoch 00029: val_accuracy improved from 0.84483 to 0.85961, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 30/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1876 - accuracy: 0.9354 - val_loss: 0.5131 - val_accuracy: 0.8571\n","\n","Epoch 00030: val_accuracy did not improve from 0.85961\n","Epoch 31/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1912 - accuracy: 0.9348 - val_loss: 1.1911 - val_accuracy: 0.7315\n","\n","Epoch 00031: val_accuracy did not improve from 0.85961\n","Epoch 32/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1832 - accuracy: 0.9391 - val_loss: 0.8855 - val_accuracy: 0.7833\n","\n","Epoch 00032: val_accuracy did not improve from 0.85961\n","Epoch 33/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1836 - accuracy: 0.9373 - val_loss: 1.2438 - val_accuracy: 0.6970\n","\n","Epoch 00033: val_accuracy did not improve from 0.85961\n","Epoch 34/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1609 - accuracy: 0.9421 - val_loss: 0.5911 - val_accuracy: 0.8399\n","\n","Epoch 00034: val_accuracy did not improve from 0.85961\n","Epoch 35/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1425 - accuracy: 0.9476 - val_loss: 0.3941 - val_accuracy: 0.8768\n","\n","Epoch 00035: val_accuracy improved from 0.85961 to 0.87685, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 36/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1284 - accuracy: 0.9568 - val_loss: 0.5304 - val_accuracy: 0.8522\n","\n","Epoch 00036: val_accuracy did not improve from 0.87685\n","Epoch 37/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1314 - accuracy: 0.9574 - val_loss: 0.5644 - val_accuracy: 0.8547\n","\n","Epoch 00037: val_accuracy did not improve from 0.87685\n","Epoch 38/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1350 - accuracy: 0.9495 - val_loss: 0.7877 - val_accuracy: 0.8079\n","\n","Epoch 00038: val_accuracy did not improve from 0.87685\n","Epoch 39/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1743 - accuracy: 0.9519 - val_loss: 1.3178 - val_accuracy: 0.7167\n","\n","Epoch 00039: val_accuracy did not improve from 0.87685\n","Epoch 40/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1882 - accuracy: 0.9324 - val_loss: 0.7456 - val_accuracy: 0.7956\n","\n","Epoch 00040: val_accuracy did not improve from 0.87685\n","Epoch 41/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1214 - accuracy: 0.9574 - val_loss: 0.6761 - val_accuracy: 0.8202\n","\n","Epoch 00041: val_accuracy did not improve from 0.87685\n","Epoch 42/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0802 - accuracy: 0.9738 - val_loss: 0.4263 - val_accuracy: 0.8818\n","\n","Epoch 00042: val_accuracy improved from 0.87685 to 0.88177, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 43/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.1012 - accuracy: 0.9622 - val_loss: 0.7972 - val_accuracy: 0.8079\n","\n","Epoch 00043: val_accuracy did not improve from 0.88177\n","Epoch 44/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1252 - accuracy: 0.9574 - val_loss: 0.8156 - val_accuracy: 0.8128\n","\n","Epoch 00044: val_accuracy did not improve from 0.88177\n","Epoch 45/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1324 - accuracy: 0.9568 - val_loss: 0.5019 - val_accuracy: 0.8645\n","\n","Epoch 00045: val_accuracy did not improve from 0.88177\n","Epoch 46/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1524 - accuracy: 0.9464 - val_loss: 0.7588 - val_accuracy: 0.8005\n","\n","Epoch 00046: val_accuracy did not improve from 0.88177\n","Epoch 47/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1364 - accuracy: 0.9525 - val_loss: 0.6199 - val_accuracy: 0.8276\n","\n","Epoch 00047: val_accuracy did not improve from 0.88177\n","Epoch 48/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1022 - accuracy: 0.9659 - val_loss: 0.4402 - val_accuracy: 0.8916\n","\n","Epoch 00048: val_accuracy improved from 0.88177 to 0.89163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 49/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0892 - accuracy: 0.9714 - val_loss: 0.7055 - val_accuracy: 0.8177\n","\n","Epoch 00049: val_accuracy did not improve from 0.89163\n","Epoch 50/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.1077 - accuracy: 0.9689 - val_loss: 0.4308 - val_accuracy: 0.8793\n","\n","Epoch 00050: val_accuracy did not improve from 0.89163\n","Epoch 51/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0871 - accuracy: 0.9714 - val_loss: 0.7683 - val_accuracy: 0.8128\n","\n","Epoch 00051: val_accuracy did not improve from 0.89163\n","Epoch 52/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0783 - accuracy: 0.9732 - val_loss: 0.8184 - val_accuracy: 0.8399\n","\n","Epoch 00052: val_accuracy did not improve from 0.89163\n","Epoch 53/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0929 - accuracy: 0.9629 - val_loss: 0.4597 - val_accuracy: 0.8744\n","\n","Epoch 00053: val_accuracy did not improve from 0.89163\n","Epoch 54/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0934 - accuracy: 0.9671 - val_loss: 0.8347 - val_accuracy: 0.8079\n","\n","Epoch 00054: val_accuracy did not improve from 0.89163\n","Epoch 55/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1671 - accuracy: 0.9440 - val_loss: 1.9413 - val_accuracy: 0.6552\n","\n","Epoch 00055: val_accuracy did not improve from 0.89163\n","Epoch 56/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1742 - accuracy: 0.9440 - val_loss: 0.7832 - val_accuracy: 0.8251\n","\n","Epoch 00056: val_accuracy did not improve from 0.89163\n","Epoch 57/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0884 - accuracy: 0.9732 - val_loss: 7.4783 - val_accuracy: 0.3571\n","\n","Epoch 00057: val_accuracy did not improve from 0.89163\n","Epoch 58/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.2799 - accuracy: 0.9141 - val_loss: 0.6491 - val_accuracy: 0.8374\n","\n","Epoch 00058: val_accuracy did not improve from 0.89163\n","Epoch 59/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0987 - accuracy: 0.9689 - val_loss: 0.4797 - val_accuracy: 0.8645\n","\n","Epoch 00059: val_accuracy did not improve from 0.89163\n","Epoch 60/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0730 - accuracy: 0.9750 - val_loss: 0.4621 - val_accuracy: 0.8621\n","\n","Epoch 00060: val_accuracy did not improve from 0.89163\n","Epoch 61/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0462 - accuracy: 0.9848 - val_loss: 0.6888 - val_accuracy: 0.8399\n","\n","Epoch 00061: val_accuracy did not improve from 0.89163\n","Epoch 62/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0670 - accuracy: 0.9781 - val_loss: 0.5294 - val_accuracy: 0.8571\n","\n","Epoch 00062: val_accuracy did not improve from 0.89163\n","Epoch 63/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0413 - accuracy: 0.9884 - val_loss: 0.4526 - val_accuracy: 0.8621\n","\n","Epoch 00063: val_accuracy did not improve from 0.89163\n","Epoch 64/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0604 - accuracy: 0.9769 - val_loss: 0.6300 - val_accuracy: 0.8621\n","\n","Epoch 00064: val_accuracy did not improve from 0.89163\n","Epoch 65/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1021 - accuracy: 0.9653 - val_loss: 1.0456 - val_accuracy: 0.7808\n","\n","Epoch 00065: val_accuracy did not improve from 0.89163\n","Epoch 66/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0671 - accuracy: 0.9756 - val_loss: 0.6649 - val_accuracy: 0.8670\n","\n","Epoch 00066: val_accuracy did not improve from 0.89163\n","Epoch 67/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0483 - accuracy: 0.9854 - val_loss: 0.4938 - val_accuracy: 0.8892\n","\n","Epoch 00067: val_accuracy did not improve from 0.89163\n","Epoch 68/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0506 - accuracy: 0.9787 - val_loss: 0.6958 - val_accuracy: 0.8325\n","\n","Epoch 00068: val_accuracy did not improve from 0.89163\n","Epoch 69/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0632 - accuracy: 0.9775 - val_loss: 0.7813 - val_accuracy: 0.8202\n","\n","Epoch 00069: val_accuracy did not improve from 0.89163\n","Epoch 70/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1089 - accuracy: 0.9647 - val_loss: 0.7781 - val_accuracy: 0.8325\n","\n","Epoch 00070: val_accuracy did not improve from 0.89163\n","Epoch 71/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0781 - accuracy: 0.9708 - val_loss: 0.6210 - val_accuracy: 0.8522\n","\n","Epoch 00071: val_accuracy did not improve from 0.89163\n","Epoch 72/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0670 - accuracy: 0.9769 - val_loss: 0.5924 - val_accuracy: 0.8571\n","\n","Epoch 00072: val_accuracy did not improve from 0.89163\n","Epoch 73/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0553 - accuracy: 0.9775 - val_loss: 0.6011 - val_accuracy: 0.8473\n","\n","Epoch 00073: val_accuracy did not improve from 0.89163\n","Epoch 74/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0538 - accuracy: 0.9823 - val_loss: 0.7230 - val_accuracy: 0.8325\n","\n","Epoch 00074: val_accuracy did not improve from 0.89163\n","Epoch 75/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.6510 - val_accuracy: 0.8621\n","\n","Epoch 00075: val_accuracy did not improve from 0.89163\n","Epoch 76/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0401 - accuracy: 0.9854 - val_loss: 0.7398 - val_accuracy: 0.8473\n","\n","Epoch 00076: val_accuracy did not improve from 0.89163\n","Epoch 77/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0428 - accuracy: 0.9848 - val_loss: 0.5687 - val_accuracy: 0.8621\n","\n","Epoch 00077: val_accuracy did not improve from 0.89163\n","Epoch 78/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1081 - accuracy: 0.9641 - val_loss: 0.8341 - val_accuracy: 0.8005\n","\n","Epoch 00078: val_accuracy did not improve from 0.89163\n","Epoch 79/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0943 - accuracy: 0.9720 - val_loss: 0.9153 - val_accuracy: 0.8202\n","\n","Epoch 00079: val_accuracy did not improve from 0.89163\n","Epoch 80/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.1099 - accuracy: 0.9653 - val_loss: 0.9571 - val_accuracy: 0.7808\n","\n","Epoch 00080: val_accuracy did not improve from 0.89163\n","Epoch 81/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1386 - accuracy: 0.9537 - val_loss: 1.0842 - val_accuracy: 0.7734\n","\n","Epoch 00081: val_accuracy did not improve from 0.89163\n","Epoch 82/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0841 - accuracy: 0.9671 - val_loss: 0.8477 - val_accuracy: 0.8276\n","\n","Epoch 00082: val_accuracy did not improve from 0.89163\n","Epoch 83/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0739 - accuracy: 0.9738 - val_loss: 0.6492 - val_accuracy: 0.8448\n","\n","Epoch 00083: val_accuracy did not improve from 0.89163\n","Epoch 84/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0358 - accuracy: 0.9866 - val_loss: 0.5214 - val_accuracy: 0.8571\n","\n","Epoch 00084: val_accuracy did not improve from 0.89163\n","Epoch 85/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0418 - accuracy: 0.9860 - val_loss: 0.6498 - val_accuracy: 0.8596\n","\n","Epoch 00085: val_accuracy did not improve from 0.89163\n","Epoch 86/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 0.5007 - val_accuracy: 0.8966\n","\n","Epoch 00086: val_accuracy improved from 0.89163 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 87/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0274 - accuracy: 0.9903 - val_loss: 0.5771 - val_accuracy: 0.8842\n","\n","Epoch 00087: val_accuracy did not improve from 0.89655\n","Epoch 88/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0275 - accuracy: 0.9945 - val_loss: 0.5112 - val_accuracy: 0.8867\n","\n","Epoch 00088: val_accuracy did not improve from 0.89655\n","Epoch 89/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0437 - accuracy: 0.9805 - val_loss: 0.8357 - val_accuracy: 0.8448\n","\n","Epoch 00089: val_accuracy did not improve from 0.89655\n","Epoch 90/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0650 - accuracy: 0.9762 - val_loss: 0.8126 - val_accuracy: 0.8424\n","\n","Epoch 00090: val_accuracy did not improve from 0.89655\n","Epoch 91/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0618 - accuracy: 0.9762 - val_loss: 0.8827 - val_accuracy: 0.8300\n","\n","Epoch 00091: val_accuracy did not improve from 0.89655\n","Epoch 92/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0739 - accuracy: 0.9787 - val_loss: 1.5835 - val_accuracy: 0.7685\n","\n","Epoch 00092: val_accuracy did not improve from 0.89655\n","Epoch 93/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0580 - accuracy: 0.9823 - val_loss: 0.6300 - val_accuracy: 0.8325\n","\n","Epoch 00093: val_accuracy did not improve from 0.89655\n","Epoch 94/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0503 - accuracy: 0.9829 - val_loss: 0.6628 - val_accuracy: 0.8399\n","\n","Epoch 00094: val_accuracy did not improve from 0.89655\n","Epoch 95/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0512 - accuracy: 0.9829 - val_loss: 0.5619 - val_accuracy: 0.8892\n","\n","Epoch 00095: val_accuracy did not improve from 0.89655\n","Epoch 96/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0402 - accuracy: 0.9878 - val_loss: 0.7919 - val_accuracy: 0.8325\n","\n","Epoch 00096: val_accuracy did not improve from 0.89655\n","Epoch 97/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0550 - accuracy: 0.9799 - val_loss: 0.9850 - val_accuracy: 0.8325\n","\n","Epoch 00097: val_accuracy did not improve from 0.89655\n","Epoch 98/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0659 - accuracy: 0.9793 - val_loss: 0.5151 - val_accuracy: 0.8867\n","\n","Epoch 00098: val_accuracy did not improve from 0.89655\n","Epoch 99/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 0.5338 - val_accuracy: 0.8818\n","\n","Epoch 00099: val_accuracy did not improve from 0.89655\n","Epoch 100/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0303 - accuracy: 0.9884 - val_loss: 0.5547 - val_accuracy: 0.8842\n","\n","Epoch 00100: val_accuracy did not improve from 0.89655\n","Epoch 101/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0373 - accuracy: 0.9890 - val_loss: 0.6062 - val_accuracy: 0.8645\n","\n","Epoch 00101: val_accuracy did not improve from 0.89655\n","Epoch 102/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0243 - accuracy: 0.9903 - val_loss: 0.5838 - val_accuracy: 0.8842\n","\n","Epoch 00102: val_accuracy did not improve from 0.89655\n","Epoch 103/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.4752 - val_accuracy: 0.8867\n","\n","Epoch 00103: val_accuracy did not improve from 0.89655\n","Epoch 104/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.5830 - val_accuracy: 0.8793\n","\n","Epoch 00104: val_accuracy did not improve from 0.89655\n","Epoch 105/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.7453 - val_accuracy: 0.8596\n","\n","Epoch 00105: val_accuracy did not improve from 0.89655\n","Epoch 106/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0337 - accuracy: 0.9872 - val_loss: 0.5392 - val_accuracy: 0.8867\n","\n","Epoch 00106: val_accuracy did not improve from 0.89655\n","Epoch 107/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0507 - accuracy: 0.9866 - val_loss: 0.7550 - val_accuracy: 0.8448\n","\n","Epoch 00107: val_accuracy did not improve from 0.89655\n","Epoch 108/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0651 - accuracy: 0.9799 - val_loss: 0.9743 - val_accuracy: 0.8300\n","\n","Epoch 00108: val_accuracy did not improve from 0.89655\n","Epoch 109/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0998 - accuracy: 0.9720 - val_loss: 0.6937 - val_accuracy: 0.8547\n","\n","Epoch 00109: val_accuracy did not improve from 0.89655\n","Epoch 110/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0659 - accuracy: 0.9750 - val_loss: 1.0303 - val_accuracy: 0.8103\n","\n","Epoch 00110: val_accuracy did not improve from 0.89655\n","Epoch 111/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1659 - accuracy: 0.9495 - val_loss: 1.1077 - val_accuracy: 0.7734\n","\n","Epoch 00111: val_accuracy did not improve from 0.89655\n","Epoch 112/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1429 - accuracy: 0.9586 - val_loss: 0.9548 - val_accuracy: 0.7980\n","\n","Epoch 00112: val_accuracy did not improve from 0.89655\n","Epoch 113/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0407 - accuracy: 0.9854 - val_loss: 0.6710 - val_accuracy: 0.8448\n","\n","Epoch 00113: val_accuracy did not improve from 0.89655\n","Epoch 114/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0418 - accuracy: 0.9878 - val_loss: 0.4663 - val_accuracy: 0.8966\n","\n","Epoch 00114: val_accuracy did not improve from 0.89655\n","Epoch 115/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0349 - accuracy: 0.9878 - val_loss: 0.3922 - val_accuracy: 0.8966\n","\n","Epoch 00115: val_accuracy did not improve from 0.89655\n","Epoch 116/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0289 - accuracy: 0.9884 - val_loss: 0.4152 - val_accuracy: 0.9089\n","\n","Epoch 00116: val_accuracy improved from 0.89655 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 117/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0284 - accuracy: 0.9890 - val_loss: 0.5834 - val_accuracy: 0.8916\n","\n","Epoch 00117: val_accuracy did not improve from 0.90887\n","Epoch 118/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0453 - accuracy: 0.9829 - val_loss: 0.5880 - val_accuracy: 0.8916\n","\n","Epoch 00118: val_accuracy did not improve from 0.90887\n","Epoch 119/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0254 - accuracy: 0.9909 - val_loss: 0.4691 - val_accuracy: 0.8941\n","\n","Epoch 00119: val_accuracy did not improve from 0.90887\n","Epoch 120/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.4337 - val_accuracy: 0.8892\n","\n","Epoch 00120: val_accuracy did not improve from 0.90887\n","Epoch 121/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0115 - accuracy: 0.9982 - val_loss: 0.5136 - val_accuracy: 0.8916\n","\n","Epoch 00121: val_accuracy did not improve from 0.90887\n","Epoch 122/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0282 - accuracy: 0.9878 - val_loss: 0.6828 - val_accuracy: 0.8695\n","\n","Epoch 00122: val_accuracy did not improve from 0.90887\n","Epoch 123/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0536 - accuracy: 0.9799 - val_loss: 1.2816 - val_accuracy: 0.7709\n","\n","Epoch 00123: val_accuracy did not improve from 0.90887\n","Epoch 124/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0682 - accuracy: 0.9793 - val_loss: 0.6745 - val_accuracy: 0.8768\n","\n","Epoch 00124: val_accuracy did not improve from 0.90887\n","Epoch 125/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0474 - accuracy: 0.9787 - val_loss: 1.1161 - val_accuracy: 0.8030\n","\n","Epoch 00125: val_accuracy did not improve from 0.90887\n","Epoch 126/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0300 - accuracy: 0.9884 - val_loss: 0.4612 - val_accuracy: 0.8966\n","\n","Epoch 00126: val_accuracy did not improve from 0.90887\n","Epoch 127/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0327 - accuracy: 0.9866 - val_loss: 0.5845 - val_accuracy: 0.8695\n","\n","Epoch 00127: val_accuracy did not improve from 0.90887\n","Epoch 128/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.9130 - val_accuracy: 0.8227\n","\n","Epoch 00128: val_accuracy did not improve from 0.90887\n","Epoch 129/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0564 - accuracy: 0.9787 - val_loss: 0.8895 - val_accuracy: 0.8596\n","\n","Epoch 00129: val_accuracy did not improve from 0.90887\n","Epoch 130/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0459 - accuracy: 0.9860 - val_loss: 1.6524 - val_accuracy: 0.7463\n","\n","Epoch 00130: val_accuracy did not improve from 0.90887\n","Epoch 131/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0603 - accuracy: 0.9811 - val_loss: 0.6378 - val_accuracy: 0.8793\n","\n","Epoch 00131: val_accuracy did not improve from 0.90887\n","Epoch 132/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.5679 - val_accuracy: 0.8719\n","\n","Epoch 00132: val_accuracy did not improve from 0.90887\n","Epoch 133/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0193 - accuracy: 0.9927 - val_loss: 0.6021 - val_accuracy: 0.8793\n","\n","Epoch 00133: val_accuracy did not improve from 0.90887\n","Epoch 134/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 0.5978 - val_accuracy: 0.8695\n","\n","Epoch 00134: val_accuracy did not improve from 0.90887\n","Epoch 135/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.5809 - val_accuracy: 0.8695\n","\n","Epoch 00135: val_accuracy did not improve from 0.90887\n","Epoch 136/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.4969 - val_accuracy: 0.9039\n","\n","Epoch 00136: val_accuracy did not improve from 0.90887\n","Epoch 137/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0285 - accuracy: 0.9915 - val_loss: 0.6777 - val_accuracy: 0.8768\n","\n","Epoch 00137: val_accuracy did not improve from 0.90887\n","Epoch 138/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0514 - accuracy: 0.9890 - val_loss: 0.5298 - val_accuracy: 0.8818\n","\n","Epoch 00138: val_accuracy did not improve from 0.90887\n","Epoch 139/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0235 - accuracy: 0.9909 - val_loss: 0.5837 - val_accuracy: 0.8695\n","\n","Epoch 00139: val_accuracy did not improve from 0.90887\n","Epoch 140/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0322 - accuracy: 0.9903 - val_loss: 0.5638 - val_accuracy: 0.8719\n","\n","Epoch 00140: val_accuracy did not improve from 0.90887\n","Epoch 141/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.6165 - val_accuracy: 0.8768\n","\n","Epoch 00141: val_accuracy did not improve from 0.90887\n","Epoch 142/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.5705 - val_accuracy: 0.8818\n","\n","Epoch 00142: val_accuracy did not improve from 0.90887\n","Epoch 143/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.6028 - val_accuracy: 0.8793\n","\n","Epoch 00143: val_accuracy did not improve from 0.90887\n","Epoch 144/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.5930 - val_accuracy: 0.8842\n","\n","Epoch 00144: val_accuracy did not improve from 0.90887\n","Epoch 145/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.4546 - val_accuracy: 0.8916\n","\n","Epoch 00145: val_accuracy did not improve from 0.90887\n","Epoch 146/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0355 - accuracy: 0.9878 - val_loss: 1.1200 - val_accuracy: 0.8030\n","\n","Epoch 00146: val_accuracy did not improve from 0.90887\n","Epoch 147/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0498 - accuracy: 0.9829 - val_loss: 0.6182 - val_accuracy: 0.8719\n","\n","Epoch 00147: val_accuracy did not improve from 0.90887\n","Epoch 148/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0635 - accuracy: 0.9805 - val_loss: 0.9542 - val_accuracy: 0.8374\n","\n","Epoch 00148: val_accuracy did not improve from 0.90887\n","Epoch 149/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0578 - accuracy: 0.9805 - val_loss: 0.6254 - val_accuracy: 0.8448\n","\n","Epoch 00149: val_accuracy did not improve from 0.90887\n","Epoch 150/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0799 - accuracy: 0.9738 - val_loss: 1.0234 - val_accuracy: 0.8153\n","\n","Epoch 00150: val_accuracy did not improve from 0.90887\n","Epoch 151/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0915 - accuracy: 0.9695 - val_loss: 1.0649 - val_accuracy: 0.8128\n","\n","Epoch 00151: val_accuracy did not improve from 0.90887\n","Epoch 152/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 0.6888 - val_accuracy: 0.8621\n","\n","Epoch 00152: val_accuracy did not improve from 0.90887\n","Epoch 153/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0334 - accuracy: 0.9896 - val_loss: 0.6864 - val_accuracy: 0.8547\n","\n","Epoch 00153: val_accuracy did not improve from 0.90887\n","Epoch 154/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.5575 - val_accuracy: 0.8818\n","\n","Epoch 00154: val_accuracy did not improve from 0.90887\n","Epoch 155/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.4858 - val_accuracy: 0.9064\n","\n","Epoch 00155: val_accuracy did not improve from 0.90887\n","Epoch 156/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.6015 - val_accuracy: 0.8892\n","\n","Epoch 00156: val_accuracy did not improve from 0.90887\n","Epoch 157/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0222 - accuracy: 0.9945 - val_loss: 0.5008 - val_accuracy: 0.9039\n","\n","Epoch 00157: val_accuracy did not improve from 0.90887\n","Epoch 158/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 0.4220 - val_accuracy: 0.9015\n","\n","Epoch 00158: val_accuracy did not improve from 0.90887\n","Epoch 159/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.4432 - val_accuracy: 0.8916\n","\n","Epoch 00159: val_accuracy did not improve from 0.90887\n","Epoch 160/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.5101 - val_accuracy: 0.8818\n","\n","Epoch 00160: val_accuracy did not improve from 0.90887\n","Epoch 161/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.6192 - val_accuracy: 0.8892\n","\n","Epoch 00161: val_accuracy did not improve from 0.90887\n","Epoch 162/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.6292 - val_accuracy: 0.8695\n","\n","Epoch 00162: val_accuracy did not improve from 0.90887\n","Epoch 163/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.5249 - val_accuracy: 0.8842\n","\n","Epoch 00163: val_accuracy did not improve from 0.90887\n","Epoch 164/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.6701 - val_accuracy: 0.8941\n","\n","Epoch 00164: val_accuracy did not improve from 0.90887\n","Epoch 165/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 0.7912 - val_accuracy: 0.8325\n","\n","Epoch 00165: val_accuracy did not improve from 0.90887\n","Epoch 166/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0215 - accuracy: 0.9915 - val_loss: 0.7330 - val_accuracy: 0.8596\n","\n","Epoch 00166: val_accuracy did not improve from 0.90887\n","Epoch 167/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0322 - accuracy: 0.9896 - val_loss: 1.1591 - val_accuracy: 0.7857\n","\n","Epoch 00167: val_accuracy did not improve from 0.90887\n","Epoch 168/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0572 - accuracy: 0.9811 - val_loss: 0.7110 - val_accuracy: 0.8621\n","\n","Epoch 00168: val_accuracy did not improve from 0.90887\n","Epoch 169/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0729 - accuracy: 0.9781 - val_loss: 0.6814 - val_accuracy: 0.8670\n","\n","Epoch 00169: val_accuracy did not improve from 0.90887\n","Epoch 170/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0366 - accuracy: 0.9866 - val_loss: 0.5125 - val_accuracy: 0.8941\n","\n","Epoch 00170: val_accuracy did not improve from 0.90887\n","Epoch 171/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.8644 - val_accuracy: 0.8350\n","\n","Epoch 00171: val_accuracy did not improve from 0.90887\n","Epoch 172/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0948 - accuracy: 0.9738 - val_loss: 0.6986 - val_accuracy: 0.8818\n","\n","Epoch 00172: val_accuracy did not improve from 0.90887\n","Epoch 173/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 0.9590 - val_accuracy: 0.8251\n","\n","Epoch 00173: val_accuracy did not improve from 0.90887\n","Epoch 174/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 0.7020 - val_accuracy: 0.8842\n","\n","Epoch 00174: val_accuracy did not improve from 0.90887\n","Epoch 175/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0519 - accuracy: 0.9848 - val_loss: 0.8637 - val_accuracy: 0.8498\n","\n","Epoch 00175: val_accuracy did not improve from 0.90887\n","Epoch 176/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0647 - accuracy: 0.9762 - val_loss: 0.6119 - val_accuracy: 0.8719\n","\n","Epoch 00176: val_accuracy did not improve from 0.90887\n","Epoch 177/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 0.6469 - val_accuracy: 0.8842\n","\n","Epoch 00177: val_accuracy did not improve from 0.90887\n","Epoch 178/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 1.1636 - val_accuracy: 0.7980\n","\n","Epoch 00178: val_accuracy did not improve from 0.90887\n","Epoch 179/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.5883 - val_accuracy: 0.8793\n","\n","Epoch 00179: val_accuracy did not improve from 0.90887\n","Epoch 180/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.7197 - val_accuracy: 0.8744\n","\n","Epoch 00180: val_accuracy did not improve from 0.90887\n","Epoch 181/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.6800 - val_accuracy: 0.8695\n","\n","Epoch 00181: val_accuracy did not improve from 0.90887\n","Epoch 182/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0182 - accuracy: 0.9927 - val_loss: 0.4307 - val_accuracy: 0.9039\n","\n","Epoch 00182: val_accuracy did not improve from 0.90887\n","Epoch 183/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.5198 - val_accuracy: 0.8793\n","\n","Epoch 00183: val_accuracy did not improve from 0.90887\n","Epoch 184/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.6202 - val_accuracy: 0.8768\n","\n","Epoch 00184: val_accuracy did not improve from 0.90887\n","Epoch 185/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0144 - accuracy: 0.9939 - val_loss: 0.6345 - val_accuracy: 0.8744\n","\n","Epoch 00185: val_accuracy did not improve from 0.90887\n","Epoch 186/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.5429 - val_accuracy: 0.8719\n","\n","Epoch 00186: val_accuracy did not improve from 0.90887\n","Epoch 187/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0222 - accuracy: 0.9939 - val_loss: 0.6732 - val_accuracy: 0.8695\n","\n","Epoch 00187: val_accuracy did not improve from 0.90887\n","Epoch 188/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.7613 - val_accuracy: 0.8621\n","\n","Epoch 00188: val_accuracy did not improve from 0.90887\n","Epoch 189/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.4450 - val_accuracy: 0.9039\n","\n","Epoch 00189: val_accuracy did not improve from 0.90887\n","Epoch 190/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0104 - accuracy: 0.9957 - val_loss: 0.5411 - val_accuracy: 0.8892\n","\n","Epoch 00190: val_accuracy did not improve from 0.90887\n","Epoch 191/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.4827 - val_accuracy: 0.8916\n","\n","Epoch 00191: val_accuracy did not improve from 0.90887\n","Epoch 192/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.5516 - val_accuracy: 0.8941\n","\n","Epoch 00192: val_accuracy did not improve from 0.90887\n","Epoch 193/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0191 - accuracy: 0.9951 - val_loss: 0.6964 - val_accuracy: 0.8818\n","\n","Epoch 00193: val_accuracy did not improve from 0.90887\n","Epoch 194/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.4381 - val_accuracy: 0.9163\n","\n","Epoch 00194: val_accuracy improved from 0.90887 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 195/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.5406 - val_accuracy: 0.9089\n","\n","Epoch 00195: val_accuracy did not improve from 0.91626\n","Epoch 196/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.4993 - val_accuracy: 0.8966\n","\n","Epoch 00196: val_accuracy did not improve from 0.91626\n","Epoch 197/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.5503 - val_accuracy: 0.8966\n","\n","Epoch 00197: val_accuracy did not improve from 0.91626\n","Epoch 198/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.5007 - val_accuracy: 0.8892\n","\n","Epoch 00198: val_accuracy did not improve from 0.91626\n","Epoch 199/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.4917 - val_accuracy: 0.8892\n","\n","Epoch 00199: val_accuracy did not improve from 0.91626\n","Epoch 200/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0450 - accuracy: 0.9896 - val_loss: 0.8145 - val_accuracy: 0.8547\n","\n","Epoch 00200: val_accuracy did not improve from 0.91626\n","Epoch 201/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0519 - accuracy: 0.9842 - val_loss: 0.6307 - val_accuracy: 0.8695\n","\n","Epoch 00201: val_accuracy did not improve from 0.91626\n","Epoch 202/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0659 - accuracy: 0.9811 - val_loss: 0.9129 - val_accuracy: 0.8300\n","\n","Epoch 00202: val_accuracy did not improve from 0.91626\n","Epoch 203/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0439 - accuracy: 0.9884 - val_loss: 0.8295 - val_accuracy: 0.8448\n","\n","Epoch 00203: val_accuracy did not improve from 0.91626\n","Epoch 204/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0418 - accuracy: 0.9878 - val_loss: 0.4969 - val_accuracy: 0.8966\n","\n","Epoch 00204: val_accuracy did not improve from 0.91626\n","Epoch 205/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0180 - accuracy: 0.9921 - val_loss: 0.5140 - val_accuracy: 0.8793\n","\n","Epoch 00205: val_accuracy did not improve from 0.91626\n","Epoch 206/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.4908 - val_accuracy: 0.8916\n","\n","Epoch 00206: val_accuracy did not improve from 0.91626\n","Epoch 207/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.4725 - val_accuracy: 0.8916\n","\n","Epoch 00207: val_accuracy did not improve from 0.91626\n","Epoch 208/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.5366 - val_accuracy: 0.8966\n","\n","Epoch 00208: val_accuracy did not improve from 0.91626\n","Epoch 209/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.8990\n","\n","Epoch 00209: val_accuracy did not improve from 0.91626\n","Epoch 210/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.8990\n","\n","Epoch 00210: val_accuracy did not improve from 0.91626\n","Epoch 211/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4610 - val_accuracy: 0.9015\n","\n","Epoch 00211: val_accuracy did not improve from 0.91626\n","Epoch 212/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.5489 - val_accuracy: 0.8966\n","\n","Epoch 00212: val_accuracy did not improve from 0.91626\n","Epoch 213/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.7022 - val_accuracy: 0.8892\n","\n","Epoch 00213: val_accuracy did not improve from 0.91626\n","Epoch 214/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0494 - accuracy: 0.9848 - val_loss: 0.6847 - val_accuracy: 0.8670\n","\n","Epoch 00214: val_accuracy did not improve from 0.91626\n","Epoch 215/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0546 - accuracy: 0.9860 - val_loss: 0.8087 - val_accuracy: 0.8374\n","\n","Epoch 00215: val_accuracy did not improve from 0.91626\n","Epoch 216/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0668 - accuracy: 0.9756 - val_loss: 0.9254 - val_accuracy: 0.8473\n","\n","Epoch 00216: val_accuracy did not improve from 0.91626\n","Epoch 217/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.6822 - val_accuracy: 0.8645\n","\n","Epoch 00217: val_accuracy did not improve from 0.91626\n","Epoch 218/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0392 - accuracy: 0.9896 - val_loss: 0.6483 - val_accuracy: 0.8719\n","\n","Epoch 00218: val_accuracy did not improve from 0.91626\n","Epoch 219/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.6204 - val_accuracy: 0.8842\n","\n","Epoch 00219: val_accuracy did not improve from 0.91626\n","Epoch 220/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.4927 - val_accuracy: 0.8867\n","\n","Epoch 00220: val_accuracy did not improve from 0.91626\n","Epoch 221/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.5515 - val_accuracy: 0.8842\n","\n","Epoch 00221: val_accuracy did not improve from 0.91626\n","Epoch 222/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.5631 - val_accuracy: 0.8916\n","\n","Epoch 00222: val_accuracy did not improve from 0.91626\n","Epoch 223/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0254 - accuracy: 0.9939 - val_loss: 1.4857 - val_accuracy: 0.7438\n","\n","Epoch 00223: val_accuracy did not improve from 0.91626\n","Epoch 224/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.7462 - val_accuracy: 0.8473\n","\n","Epoch 00224: val_accuracy did not improve from 0.91626\n","Epoch 225/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.7296 - val_accuracy: 0.8744\n","\n","Epoch 00225: val_accuracy did not improve from 0.91626\n","Epoch 226/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0292 - accuracy: 0.9884 - val_loss: 0.9436 - val_accuracy: 0.8325\n","\n","Epoch 00226: val_accuracy did not improve from 0.91626\n","Epoch 227/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0307 - accuracy: 0.9896 - val_loss: 0.7090 - val_accuracy: 0.8793\n","\n","Epoch 00227: val_accuracy did not improve from 0.91626\n","Epoch 228/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.6331 - val_accuracy: 0.8793\n","\n","Epoch 00228: val_accuracy did not improve from 0.91626\n","Epoch 229/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0169 - accuracy: 0.9970 - val_loss: 0.7159 - val_accuracy: 0.8744\n","\n","Epoch 00229: val_accuracy did not improve from 0.91626\n","Epoch 230/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.5926 - val_accuracy: 0.8842\n","\n","Epoch 00230: val_accuracy did not improve from 0.91626\n","Epoch 231/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0111 - accuracy: 0.9951 - val_loss: 0.6312 - val_accuracy: 0.8719\n","\n","Epoch 00231: val_accuracy did not improve from 0.91626\n","Epoch 232/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0126 - accuracy: 0.9945 - val_loss: 0.5733 - val_accuracy: 0.8818\n","\n","Epoch 00232: val_accuracy did not improve from 0.91626\n","Epoch 233/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.5302 - val_accuracy: 0.8842\n","\n","Epoch 00233: val_accuracy did not improve from 0.91626\n","Epoch 234/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5201 - val_accuracy: 0.9039\n","\n","Epoch 00234: val_accuracy did not improve from 0.91626\n","Epoch 235/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5506 - val_accuracy: 0.8892\n","\n","Epoch 00235: val_accuracy did not improve from 0.91626\n","Epoch 236/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.9089\n","\n","Epoch 00236: val_accuracy did not improve from 0.91626\n","Epoch 237/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.5786 - val_accuracy: 0.9187\n","\n","Epoch 00237: val_accuracy improved from 0.91626 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 238/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5498 - val_accuracy: 0.9113\n","\n","Epoch 00238: val_accuracy did not improve from 0.91872\n","Epoch 239/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.7289 - val_accuracy: 0.8596\n","\n","Epoch 00239: val_accuracy did not improve from 0.91872\n","Epoch 240/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0386 - accuracy: 0.9921 - val_loss: 0.8363 - val_accuracy: 0.8768\n","\n","Epoch 00240: val_accuracy did not improve from 0.91872\n","Epoch 241/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0396 - accuracy: 0.9884 - val_loss: 1.2106 - val_accuracy: 0.8177\n","\n","Epoch 00241: val_accuracy did not improve from 0.91872\n","Epoch 242/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.1185 - accuracy: 0.9695 - val_loss: 3.5763 - val_accuracy: 0.6379\n","\n","Epoch 00242: val_accuracy did not improve from 0.91872\n","Epoch 243/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0654 - accuracy: 0.9775 - val_loss: 1.0894 - val_accuracy: 0.8374\n","\n","Epoch 00243: val_accuracy did not improve from 0.91872\n","Epoch 244/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0401 - accuracy: 0.9854 - val_loss: 0.6634 - val_accuracy: 0.8645\n","\n","Epoch 00244: val_accuracy did not improve from 0.91872\n","Epoch 245/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 0.5110 - val_accuracy: 0.8744\n","\n","Epoch 00245: val_accuracy did not improve from 0.91872\n","Epoch 246/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.6104 - val_accuracy: 0.8867\n","\n","Epoch 00246: val_accuracy did not improve from 0.91872\n","Epoch 247/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.4665 - val_accuracy: 0.9039\n","\n","Epoch 00247: val_accuracy did not improve from 0.91872\n","Epoch 248/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.6362 - val_accuracy: 0.8473\n","\n","Epoch 00248: val_accuracy did not improve from 0.91872\n","Epoch 249/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0117 - accuracy: 0.9988 - val_loss: 0.6645 - val_accuracy: 0.8768\n","\n","Epoch 00249: val_accuracy did not improve from 0.91872\n","Epoch 250/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.5635 - val_accuracy: 0.8842\n","\n","Epoch 00250: val_accuracy did not improve from 0.91872\n","Epoch 251/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.5659 - val_accuracy: 0.8941\n","\n","Epoch 00251: val_accuracy did not improve from 0.91872\n","Epoch 252/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0131 - accuracy: 0.9982 - val_loss: 0.6210 - val_accuracy: 0.8695\n","\n","Epoch 00252: val_accuracy did not improve from 0.91872\n","Epoch 253/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.4691 - val_accuracy: 0.9039\n","\n","Epoch 00253: val_accuracy did not improve from 0.91872\n","Epoch 254/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 0.7703 - val_accuracy: 0.8744\n","\n","Epoch 00254: val_accuracy did not improve from 0.91872\n","Epoch 255/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0191 - accuracy: 0.9927 - val_loss: 0.5245 - val_accuracy: 0.8966\n","\n","Epoch 00255: val_accuracy did not improve from 0.91872\n","Epoch 256/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.5458 - val_accuracy: 0.8892\n","\n","Epoch 00256: val_accuracy did not improve from 0.91872\n","Epoch 257/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.5736 - val_accuracy: 0.9015\n","\n","Epoch 00257: val_accuracy did not improve from 0.91872\n","Epoch 258/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.6335 - val_accuracy: 0.8867\n","\n","Epoch 00258: val_accuracy did not improve from 0.91872\n","Epoch 259/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 0.6025 - val_accuracy: 0.9015\n","\n","Epoch 00259: val_accuracy did not improve from 0.91872\n","Epoch 260/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0134 - accuracy: 0.9945 - val_loss: 0.5953 - val_accuracy: 0.8793\n","\n","Epoch 00260: val_accuracy did not improve from 0.91872\n","Epoch 261/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.5614 - val_accuracy: 0.8719\n","\n","Epoch 00261: val_accuracy did not improve from 0.91872\n","Epoch 262/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.5100 - val_accuracy: 0.8941\n","\n","Epoch 00262: val_accuracy did not improve from 0.91872\n","Epoch 263/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 0.4082 - val_accuracy: 0.9138\n","\n","Epoch 00263: val_accuracy did not improve from 0.91872\n","Epoch 264/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0168 - accuracy: 0.9970 - val_loss: 0.7456 - val_accuracy: 0.8818\n","\n","Epoch 00264: val_accuracy did not improve from 0.91872\n","Epoch 265/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.5877 - val_accuracy: 0.8842\n","\n","Epoch 00265: val_accuracy did not improve from 0.91872\n","Epoch 266/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.6072 - val_accuracy: 0.8793\n","\n","Epoch 00266: val_accuracy did not improve from 0.91872\n","Epoch 267/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.5634 - val_accuracy: 0.9015\n","\n","Epoch 00267: val_accuracy did not improve from 0.91872\n","Epoch 268/500\n","52/52 [==============================] - 12s 238ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5304 - val_accuracy: 0.9015\n","\n","Epoch 00268: val_accuracy did not improve from 0.91872\n","Epoch 269/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.5111 - val_accuracy: 0.9015\n","\n","Epoch 00269: val_accuracy did not improve from 0.91872\n","Epoch 270/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.6232 - val_accuracy: 0.8818\n","\n","Epoch 00270: val_accuracy did not improve from 0.91872\n","Epoch 271/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0223 - accuracy: 0.9970 - val_loss: 0.6364 - val_accuracy: 0.8892\n","\n","Epoch 00271: val_accuracy did not improve from 0.91872\n","Epoch 272/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.4943 - val_accuracy: 0.8990\n","\n","Epoch 00272: val_accuracy did not improve from 0.91872\n","Epoch 273/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0132 - accuracy: 0.9945 - val_loss: 0.5080 - val_accuracy: 0.9089\n","\n","Epoch 00273: val_accuracy did not improve from 0.91872\n","Epoch 274/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.7458 - val_accuracy: 0.8744\n","\n","Epoch 00274: val_accuracy did not improve from 0.91872\n","Epoch 275/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.9295 - val_accuracy: 0.8547\n","\n","Epoch 00275: val_accuracy did not improve from 0.91872\n","Epoch 276/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0441 - accuracy: 0.9854 - val_loss: 0.7104 - val_accuracy: 0.8596\n","\n","Epoch 00276: val_accuracy did not improve from 0.91872\n","Epoch 277/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 0.7713 - val_accuracy: 0.8473\n","\n","Epoch 00277: val_accuracy did not improve from 0.91872\n","Epoch 278/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.9167 - val_accuracy: 0.8498\n","\n","Epoch 00278: val_accuracy did not improve from 0.91872\n","Epoch 279/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.6509 - val_accuracy: 0.8842\n","\n","Epoch 00279: val_accuracy did not improve from 0.91872\n","Epoch 280/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.6095 - val_accuracy: 0.9089\n","\n","Epoch 00280: val_accuracy did not improve from 0.91872\n","Epoch 281/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.6847 - val_accuracy: 0.8818\n","\n","Epoch 00281: val_accuracy did not improve from 0.91872\n","Epoch 282/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0192 - accuracy: 0.9957 - val_loss: 0.5345 - val_accuracy: 0.8941\n","\n","Epoch 00282: val_accuracy did not improve from 0.91872\n","Epoch 283/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.6270 - val_accuracy: 0.8695\n","\n","Epoch 00283: val_accuracy did not improve from 0.91872\n","Epoch 284/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0333 - accuracy: 0.9927 - val_loss: 0.8066 - val_accuracy: 0.8744\n","\n","Epoch 00284: val_accuracy did not improve from 0.91872\n","Epoch 285/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0539 - accuracy: 0.9866 - val_loss: 0.6987 - val_accuracy: 0.8571\n","\n","Epoch 00285: val_accuracy did not improve from 0.91872\n","Epoch 286/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.6450 - val_accuracy: 0.8645\n","\n","Epoch 00286: val_accuracy did not improve from 0.91872\n","Epoch 287/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0270 - accuracy: 0.9909 - val_loss: 0.5909 - val_accuracy: 0.8941\n","\n","Epoch 00287: val_accuracy did not improve from 0.91872\n","Epoch 288/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.6296 - val_accuracy: 0.8695\n","\n","Epoch 00288: val_accuracy did not improve from 0.91872\n","Epoch 289/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.5276 - val_accuracy: 0.8892\n","\n","Epoch 00289: val_accuracy did not improve from 0.91872\n","Epoch 290/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.5423 - val_accuracy: 0.8818\n","\n","Epoch 00290: val_accuracy did not improve from 0.91872\n","Epoch 291/500\n","52/52 [==============================] - 11s 222ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.4730 - val_accuracy: 0.9064\n","\n","Epoch 00291: val_accuracy did not improve from 0.91872\n","Epoch 292/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 0.5025 - val_accuracy: 0.9015\n","\n","Epoch 00292: val_accuracy did not improve from 0.91872\n","Epoch 293/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5219 - val_accuracy: 0.9113\n","\n","Epoch 00293: val_accuracy did not improve from 0.91872\n","Epoch 294/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4520 - val_accuracy: 0.8867\n","\n","Epoch 00294: val_accuracy did not improve from 0.91872\n","Epoch 295/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4812 - val_accuracy: 0.8966\n","\n","Epoch 00295: val_accuracy did not improve from 0.91872\n","Epoch 296/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.4934 - val_accuracy: 0.8990\n","\n","Epoch 00296: val_accuracy did not improve from 0.91872\n","Epoch 297/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 0.5233 - val_accuracy: 0.8990\n","\n","Epoch 00297: val_accuracy did not improve from 0.91872\n","Epoch 298/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4904 - val_accuracy: 0.9163\n","\n","Epoch 00298: val_accuracy did not improve from 0.91872\n","Epoch 299/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4827 - val_accuracy: 0.9113\n","\n","Epoch 00299: val_accuracy did not improve from 0.91872\n","Epoch 300/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5355 - val_accuracy: 0.9138\n","\n","Epoch 00300: val_accuracy did not improve from 0.91872\n","Epoch 301/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5646 - val_accuracy: 0.9064\n","\n","Epoch 00301: val_accuracy did not improve from 0.91872\n","Epoch 302/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4582 - val_accuracy: 0.9089\n","\n","Epoch 00302: val_accuracy did not improve from 0.91872\n","Epoch 303/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4975 - val_accuracy: 0.9039\n","\n","Epoch 00303: val_accuracy did not improve from 0.91872\n","Epoch 304/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4840 - val_accuracy: 0.9039\n","\n","Epoch 00304: val_accuracy did not improve from 0.91872\n","Epoch 305/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.5690 - val_accuracy: 0.8892\n","\n","Epoch 00305: val_accuracy did not improve from 0.91872\n","Epoch 306/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.6120 - val_accuracy: 0.8916\n","\n","Epoch 00306: val_accuracy did not improve from 0.91872\n","Epoch 307/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0139 - accuracy: 0.9939 - val_loss: 0.6680 - val_accuracy: 0.8670\n","\n","Epoch 00307: val_accuracy did not improve from 0.91872\n","Epoch 308/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.7090 - val_accuracy: 0.8695\n","\n","Epoch 00308: val_accuracy did not improve from 0.91872\n","Epoch 309/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.6351 - val_accuracy: 0.8645\n","\n","Epoch 00309: val_accuracy did not improve from 0.91872\n","Epoch 310/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.7474 - val_accuracy: 0.8621\n","\n","Epoch 00310: val_accuracy did not improve from 0.91872\n","Epoch 311/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0543 - accuracy: 0.9884 - val_loss: 1.7318 - val_accuracy: 0.7488\n","\n","Epoch 00311: val_accuracy did not improve from 0.91872\n","Epoch 312/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0475 - accuracy: 0.9842 - val_loss: 1.0105 - val_accuracy: 0.7833\n","\n","Epoch 00312: val_accuracy did not improve from 0.91872\n","Epoch 313/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0360 - accuracy: 0.9854 - val_loss: 1.2927 - val_accuracy: 0.8030\n","\n","Epoch 00313: val_accuracy did not improve from 0.91872\n","Epoch 314/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0225 - accuracy: 0.9896 - val_loss: 0.7043 - val_accuracy: 0.8818\n","\n","Epoch 00314: val_accuracy did not improve from 0.91872\n","Epoch 315/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.8250 - val_accuracy: 0.8719\n","\n","Epoch 00315: val_accuracy did not improve from 0.91872\n","Epoch 316/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.6727 - val_accuracy: 0.8621\n","\n","Epoch 00316: val_accuracy did not improve from 0.91872\n","Epoch 317/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.7781 - val_accuracy: 0.8793\n","\n","Epoch 00317: val_accuracy did not improve from 0.91872\n","Epoch 318/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.6475 - val_accuracy: 0.9015\n","\n","Epoch 00318: val_accuracy did not improve from 0.91872\n","Epoch 319/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.9288 - val_accuracy: 0.8571\n","\n","Epoch 00319: val_accuracy did not improve from 0.91872\n","Epoch 320/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.6953 - val_accuracy: 0.8744\n","\n","Epoch 00320: val_accuracy did not improve from 0.91872\n","Epoch 321/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.6039 - val_accuracy: 0.8719\n","\n","Epoch 00321: val_accuracy did not improve from 0.91872\n","Epoch 322/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.6324 - val_accuracy: 0.8793\n","\n","Epoch 00322: val_accuracy did not improve from 0.91872\n","Epoch 323/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.7005 - val_accuracy: 0.8719\n","\n","Epoch 00323: val_accuracy did not improve from 0.91872\n","Epoch 324/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.7416 - val_accuracy: 0.8768\n","\n","Epoch 00324: val_accuracy did not improve from 0.91872\n","Epoch 325/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.6648 - val_accuracy: 0.8744\n","\n","Epoch 00325: val_accuracy did not improve from 0.91872\n","Epoch 326/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.5163 - val_accuracy: 0.8695\n","\n","Epoch 00326: val_accuracy did not improve from 0.91872\n","Epoch 327/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0302 - accuracy: 0.9909 - val_loss: 1.1135 - val_accuracy: 0.7709\n","\n","Epoch 00327: val_accuracy did not improve from 0.91872\n","Epoch 328/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0143 - accuracy: 0.9939 - val_loss: 0.7034 - val_accuracy: 0.8793\n","\n","Epoch 00328: val_accuracy did not improve from 0.91872\n","Epoch 329/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.7669 - val_accuracy: 0.8670\n","\n","Epoch 00329: val_accuracy did not improve from 0.91872\n","Epoch 330/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.6523 - val_accuracy: 0.8892\n","\n","Epoch 00330: val_accuracy did not improve from 0.91872\n","Epoch 331/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.5329 - val_accuracy: 0.8892\n","\n","Epoch 00331: val_accuracy did not improve from 0.91872\n","Epoch 332/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0104 - accuracy: 0.9957 - val_loss: 0.6539 - val_accuracy: 0.8892\n","\n","Epoch 00332: val_accuracy did not improve from 0.91872\n","Epoch 333/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.6202 - val_accuracy: 0.8793\n","\n","Epoch 00333: val_accuracy did not improve from 0.91872\n","Epoch 334/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.8990\n","\n","Epoch 00334: val_accuracy did not improve from 0.91872\n","Epoch 335/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5360 - val_accuracy: 0.9138\n","\n","Epoch 00335: val_accuracy did not improve from 0.91872\n","Epoch 336/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.9039\n","\n","Epoch 00336: val_accuracy did not improve from 0.91872\n","Epoch 337/500\n","52/52 [==============================] - 12s 221ms/step - loss: 8.1642e-04 - accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.9187\n","\n","Epoch 00337: val_accuracy did not improve from 0.91872\n","Epoch 338/500\n","52/52 [==============================] - 12s 221ms/step - loss: 6.1471e-04 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9064\n","\n","Epoch 00338: val_accuracy did not improve from 0.91872\n","Epoch 339/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5912 - val_accuracy: 0.8941\n","\n","Epoch 00339: val_accuracy did not improve from 0.91872\n","Epoch 340/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.8867\n","\n","Epoch 00340: val_accuracy did not improve from 0.91872\n","Epoch 341/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0025 - accuracy: 0.9982 - val_loss: 0.6119 - val_accuracy: 0.9064\n","\n","Epoch 00341: val_accuracy did not improve from 0.91872\n","Epoch 342/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.6116 - val_accuracy: 0.9015\n","\n","Epoch 00342: val_accuracy did not improve from 0.91872\n","Epoch 343/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.5696 - val_accuracy: 0.8941\n","\n","Epoch 00343: val_accuracy did not improve from 0.91872\n","Epoch 344/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.6861 - val_accuracy: 0.8892\n","\n","Epoch 00344: val_accuracy did not improve from 0.91872\n","Epoch 345/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0358 - accuracy: 0.9860 - val_loss: 0.9528 - val_accuracy: 0.8202\n","\n","Epoch 00345: val_accuracy did not improve from 0.91872\n","Epoch 346/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0452 - accuracy: 0.9872 - val_loss: 0.9048 - val_accuracy: 0.8670\n","\n","Epoch 00346: val_accuracy did not improve from 0.91872\n","Epoch 347/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0408 - accuracy: 0.9903 - val_loss: 0.7673 - val_accuracy: 0.8645\n","\n","Epoch 00347: val_accuracy did not improve from 0.91872\n","Epoch 348/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.7180 - val_accuracy: 0.8842\n","\n","Epoch 00348: val_accuracy did not improve from 0.91872\n","Epoch 349/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.6519 - val_accuracy: 0.8966\n","\n","Epoch 00349: val_accuracy did not improve from 0.91872\n","Epoch 350/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.6268 - val_accuracy: 0.8867\n","\n","Epoch 00350: val_accuracy did not improve from 0.91872\n","Epoch 351/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.8206 - val_accuracy: 0.8793\n","\n","Epoch 00351: val_accuracy did not improve from 0.91872\n","Epoch 352/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.6946 - val_accuracy: 0.8966\n","\n","Epoch 00352: val_accuracy did not improve from 0.91872\n","Epoch 353/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.6989 - val_accuracy: 0.8916\n","\n","Epoch 00353: val_accuracy did not improve from 0.91872\n","Epoch 354/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.9064\n","\n","Epoch 00354: val_accuracy did not improve from 0.91872\n","Epoch 355/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5433 - val_accuracy: 0.9039\n","\n","Epoch 00355: val_accuracy did not improve from 0.91872\n","Epoch 356/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5623 - val_accuracy: 0.9212\n","\n","Epoch 00356: val_accuracy improved from 0.91872 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 357/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.6412 - val_accuracy: 0.8966\n","\n","Epoch 00357: val_accuracy did not improve from 0.92118\n","Epoch 358/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.5156 - val_accuracy: 0.9236\n","\n","Epoch 00358: val_accuracy improved from 0.92118 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5\n","Epoch 359/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.7230 - val_accuracy: 0.9015\n","\n","Epoch 00359: val_accuracy did not improve from 0.92365\n","Epoch 360/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.8232 - val_accuracy: 0.8645\n","\n","Epoch 00360: val_accuracy did not improve from 0.92365\n","Epoch 361/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0161 - accuracy: 0.9933 - val_loss: 0.7870 - val_accuracy: 0.8793\n","\n","Epoch 00361: val_accuracy did not improve from 0.92365\n","Epoch 362/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0407 - accuracy: 0.9884 - val_loss: 1.0649 - val_accuracy: 0.8399\n","\n","Epoch 00362: val_accuracy did not improve from 0.92365\n","Epoch 363/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0088 - accuracy: 0.9957 - val_loss: 0.7273 - val_accuracy: 0.8867\n","\n","Epoch 00363: val_accuracy did not improve from 0.92365\n","Epoch 364/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.9676 - val_accuracy: 0.8695\n","\n","Epoch 00364: val_accuracy did not improve from 0.92365\n","Epoch 365/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0101 - accuracy: 0.9951 - val_loss: 0.7038 - val_accuracy: 0.8793\n","\n","Epoch 00365: val_accuracy did not improve from 0.92365\n","Epoch 366/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.6732 - val_accuracy: 0.8990\n","\n","Epoch 00366: val_accuracy did not improve from 0.92365\n","Epoch 367/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.7288 - val_accuracy: 0.8768\n","\n","Epoch 00367: val_accuracy did not improve from 0.92365\n","Epoch 368/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0377 - accuracy: 0.9903 - val_loss: 1.0594 - val_accuracy: 0.8522\n","\n","Epoch 00368: val_accuracy did not improve from 0.92365\n","Epoch 369/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0199 - accuracy: 0.9915 - val_loss: 0.7028 - val_accuracy: 0.8571\n","\n","Epoch 00369: val_accuracy did not improve from 0.92365\n","Epoch 370/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.5528 - val_accuracy: 0.8990\n","\n","Epoch 00370: val_accuracy did not improve from 0.92365\n","Epoch 371/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.5647 - val_accuracy: 0.8966\n","\n","Epoch 00371: val_accuracy did not improve from 0.92365\n","Epoch 372/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.5839 - val_accuracy: 0.8892\n","\n","Epoch 00372: val_accuracy did not improve from 0.92365\n","Epoch 373/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.5574 - val_accuracy: 0.9064\n","\n","Epoch 00373: val_accuracy did not improve from 0.92365\n","Epoch 374/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.7856 - val_accuracy: 0.8744\n","\n","Epoch 00374: val_accuracy did not improve from 0.92365\n","Epoch 375/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.9640 - val_accuracy: 0.8621\n","\n","Epoch 00375: val_accuracy did not improve from 0.92365\n","Epoch 376/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.7734 - val_accuracy: 0.8842\n","\n","Epoch 00376: val_accuracy did not improve from 0.92365\n","Epoch 377/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.7266 - val_accuracy: 0.8768\n","\n","Epoch 00377: val_accuracy did not improve from 0.92365\n","Epoch 378/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.6274 - val_accuracy: 0.9039\n","\n","Epoch 00378: val_accuracy did not improve from 0.92365\n","Epoch 379/500\n","52/52 [==============================] - 12s 221ms/step - loss: 4.1693e-04 - accuracy: 1.0000 - val_loss: 0.6208 - val_accuracy: 0.8916\n","\n","Epoch 00379: val_accuracy did not improve from 0.92365\n","Epoch 380/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6569 - val_accuracy: 0.8966\n","\n","Epoch 00380: val_accuracy did not improve from 0.92365\n","Epoch 381/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0388 - accuracy: 0.9903 - val_loss: 0.8599 - val_accuracy: 0.8424\n","\n","Epoch 00381: val_accuracy did not improve from 0.92365\n","Epoch 382/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0327 - accuracy: 0.9921 - val_loss: 0.9884 - val_accuracy: 0.8153\n","\n","Epoch 00382: val_accuracy did not improve from 0.92365\n","Epoch 383/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0198 - accuracy: 0.9951 - val_loss: 0.5995 - val_accuracy: 0.8818\n","\n","Epoch 00383: val_accuracy did not improve from 0.92365\n","Epoch 384/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0188 - accuracy: 0.9970 - val_loss: 0.6522 - val_accuracy: 0.8768\n","\n","Epoch 00384: val_accuracy did not improve from 0.92365\n","Epoch 385/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4526 - val_accuracy: 0.9212\n","\n","Epoch 00385: val_accuracy did not improve from 0.92365\n","Epoch 386/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.4936 - val_accuracy: 0.8966\n","\n","Epoch 00386: val_accuracy did not improve from 0.92365\n","Epoch 387/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5040 - val_accuracy: 0.8990\n","\n","Epoch 00387: val_accuracy did not improve from 0.92365\n","Epoch 388/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4748 - val_accuracy: 0.9089\n","\n","Epoch 00388: val_accuracy did not improve from 0.92365\n","Epoch 389/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.6025 - val_accuracy: 0.8941\n","\n","Epoch 00389: val_accuracy did not improve from 0.92365\n","Epoch 390/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5803 - val_accuracy: 0.8966\n","\n","Epoch 00390: val_accuracy did not improve from 0.92365\n","Epoch 391/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.5550 - val_accuracy: 0.8867\n","\n","Epoch 00391: val_accuracy did not improve from 0.92365\n","Epoch 392/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.5709 - val_accuracy: 0.8842\n","\n","Epoch 00392: val_accuracy did not improve from 0.92365\n","Epoch 393/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.5528 - val_accuracy: 0.8966\n","\n","Epoch 00393: val_accuracy did not improve from 0.92365\n","Epoch 394/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.6651 - val_accuracy: 0.8547\n","\n","Epoch 00394: val_accuracy did not improve from 0.92365\n","Epoch 395/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.4862 - val_accuracy: 0.8916\n","\n","Epoch 00395: val_accuracy did not improve from 0.92365\n","Epoch 396/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0218 - accuracy: 0.9957 - val_loss: 0.5802 - val_accuracy: 0.8916\n","\n","Epoch 00396: val_accuracy did not improve from 0.92365\n","Epoch 397/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.5791 - val_accuracy: 0.9015\n","\n","Epoch 00397: val_accuracy did not improve from 0.92365\n","Epoch 398/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5385 - val_accuracy: 0.9236\n","\n","Epoch 00398: val_accuracy did not improve from 0.92365\n","Epoch 399/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5289 - val_accuracy: 0.8916\n","\n","Epoch 00399: val_accuracy did not improve from 0.92365\n","Epoch 400/500\n","52/52 [==============================] - 12s 220ms/step - loss: 9.0999e-04 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9064\n","\n","Epoch 00400: val_accuracy did not improve from 0.92365\n","Epoch 401/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.7344 - val_accuracy: 0.8966\n","\n","Epoch 00401: val_accuracy did not improve from 0.92365\n","Epoch 402/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0290 - accuracy: 0.9872 - val_loss: 1.1970 - val_accuracy: 0.8153\n","\n","Epoch 00402: val_accuracy did not improve from 0.92365\n","Epoch 403/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0407 - accuracy: 0.9884 - val_loss: 0.7326 - val_accuracy: 0.8768\n","\n","Epoch 00403: val_accuracy did not improve from 0.92365\n","Epoch 404/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.6777 - val_accuracy: 0.8793\n","\n","Epoch 00404: val_accuracy did not improve from 0.92365\n","Epoch 405/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.6078 - val_accuracy: 0.8916\n","\n","Epoch 00405: val_accuracy did not improve from 0.92365\n","Epoch 406/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.6000 - val_accuracy: 0.8892\n","\n","Epoch 00406: val_accuracy did not improve from 0.92365\n","Epoch 407/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.8941\n","\n","Epoch 00407: val_accuracy did not improve from 0.92365\n","Epoch 408/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.6443 - val_accuracy: 0.8990\n","\n","Epoch 00408: val_accuracy did not improve from 0.92365\n","Epoch 409/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.5131 - val_accuracy: 0.9089\n","\n","Epoch 00409: val_accuracy did not improve from 0.92365\n","Epoch 410/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.5499 - val_accuracy: 0.9064\n","\n","Epoch 00410: val_accuracy did not improve from 0.92365\n","Epoch 411/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4648 - val_accuracy: 0.9138\n","\n","Epoch 00411: val_accuracy did not improve from 0.92365\n","Epoch 412/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.5776 - val_accuracy: 0.8990\n","\n","Epoch 00412: val_accuracy did not improve from 0.92365\n","Epoch 413/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.5010 - val_accuracy: 0.9039\n","\n","Epoch 00413: val_accuracy did not improve from 0.92365\n","Epoch 414/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.8994 - val_accuracy: 0.8645\n","\n","Epoch 00414: val_accuracy did not improve from 0.92365\n","Epoch 415/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0200 - accuracy: 0.9951 - val_loss: 0.6019 - val_accuracy: 0.8768\n","\n","Epoch 00415: val_accuracy did not improve from 0.92365\n","Epoch 416/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5106 - val_accuracy: 0.8990\n","\n","Epoch 00416: val_accuracy did not improve from 0.92365\n","Epoch 417/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.6336 - val_accuracy: 0.8744\n","\n","Epoch 00417: val_accuracy did not improve from 0.92365\n","Epoch 418/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.6454 - val_accuracy: 0.8892\n","\n","Epoch 00418: val_accuracy did not improve from 0.92365\n","Epoch 419/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.6672 - val_accuracy: 0.8793\n","\n","Epoch 00419: val_accuracy did not improve from 0.92365\n","Epoch 420/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.8234 - val_accuracy: 0.8571\n","\n","Epoch 00420: val_accuracy did not improve from 0.92365\n","Epoch 421/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.8112 - val_accuracy: 0.8892\n","\n","Epoch 00421: val_accuracy did not improve from 0.92365\n","Epoch 422/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.6436 - val_accuracy: 0.8892\n","\n","Epoch 00422: val_accuracy did not improve from 0.92365\n","Epoch 423/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.6309 - val_accuracy: 0.9064\n","\n","Epoch 00423: val_accuracy did not improve from 0.92365\n","Epoch 424/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.7261 - val_accuracy: 0.8793\n","\n","Epoch 00424: val_accuracy did not improve from 0.92365\n","Epoch 425/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.5894 - val_accuracy: 0.8842\n","\n","Epoch 00425: val_accuracy did not improve from 0.92365\n","Epoch 426/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0155 - accuracy: 0.9976 - val_loss: 0.5767 - val_accuracy: 0.9138\n","\n","Epoch 00426: val_accuracy did not improve from 0.92365\n","Epoch 427/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.5507 - val_accuracy: 0.9113\n","\n","Epoch 00427: val_accuracy did not improve from 0.92365\n","Epoch 428/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5471 - val_accuracy: 0.9113\n","\n","Epoch 00428: val_accuracy did not improve from 0.92365\n","Epoch 429/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.5720 - val_accuracy: 0.8916\n","\n","Epoch 00429: val_accuracy did not improve from 0.92365\n","Epoch 430/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.7816 - val_accuracy: 0.8424\n","\n","Epoch 00430: val_accuracy did not improve from 0.92365\n","Epoch 431/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0277 - accuracy: 0.9909 - val_loss: 0.9234 - val_accuracy: 0.8695\n","\n","Epoch 00431: val_accuracy did not improve from 0.92365\n","Epoch 432/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.6589 - val_accuracy: 0.8916\n","\n","Epoch 00432: val_accuracy did not improve from 0.92365\n","Epoch 433/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.5629 - val_accuracy: 0.8842\n","\n","Epoch 00433: val_accuracy did not improve from 0.92365\n","Epoch 434/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.6415 - val_accuracy: 0.8793\n","\n","Epoch 00434: val_accuracy did not improve from 0.92365\n","Epoch 435/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9089\n","\n","Epoch 00435: val_accuracy did not improve from 0.92365\n","Epoch 436/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.8681 - val_accuracy: 0.8498\n","\n","Epoch 00436: val_accuracy did not improve from 0.92365\n","Epoch 437/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.5756 - val_accuracy: 0.9064\n","\n","Epoch 00437: val_accuracy did not improve from 0.92365\n","Epoch 438/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5827 - val_accuracy: 0.9089\n","\n","Epoch 00438: val_accuracy did not improve from 0.92365\n","Epoch 439/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5502 - val_accuracy: 0.9138\n","\n","Epoch 00439: val_accuracy did not improve from 0.92365\n","Epoch 440/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5318 - val_accuracy: 0.9187\n","\n","Epoch 00440: val_accuracy did not improve from 0.92365\n","Epoch 441/500\n","52/52 [==============================] - 11s 219ms/step - loss: 9.5768e-04 - accuracy: 1.0000 - val_loss: 0.5152 - val_accuracy: 0.9138\n","\n","Epoch 00441: val_accuracy did not improve from 0.92365\n","Epoch 442/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5892 - val_accuracy: 0.9064\n","\n","Epoch 00442: val_accuracy did not improve from 0.92365\n","Epoch 443/500\n","52/52 [==============================] - 12s 221ms/step - loss: 4.7313e-04 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9113\n","\n","Epoch 00443: val_accuracy did not improve from 0.92365\n","Epoch 444/500\n","52/52 [==============================] - 12s 221ms/step - loss: 6.7532e-04 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9113\n","\n","Epoch 00444: val_accuracy did not improve from 0.92365\n","Epoch 445/500\n","52/52 [==============================] - 12s 220ms/step - loss: 8.5114e-04 - accuracy: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.9163\n","\n","Epoch 00445: val_accuracy did not improve from 0.92365\n","Epoch 446/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5739 - val_accuracy: 0.9064\n","\n","Epoch 00446: val_accuracy did not improve from 0.92365\n","Epoch 447/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4786 - val_accuracy: 0.8916\n","\n","Epoch 00447: val_accuracy did not improve from 0.92365\n","Epoch 448/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.4936 - val_accuracy: 0.8793\n","\n","Epoch 00448: val_accuracy did not improve from 0.92365\n","Epoch 449/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.9365 - val_accuracy: 0.8276\n","\n","Epoch 00449: val_accuracy did not improve from 0.92365\n","Epoch 450/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.7329 - val_accuracy: 0.8719\n","\n","Epoch 00450: val_accuracy did not improve from 0.92365\n","Epoch 451/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.6599 - val_accuracy: 0.8867\n","\n","Epoch 00451: val_accuracy did not improve from 0.92365\n","Epoch 452/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.5735 - val_accuracy: 0.9212\n","\n","Epoch 00452: val_accuracy did not improve from 0.92365\n","Epoch 453/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.7112 - val_accuracy: 0.8892\n","\n","Epoch 00453: val_accuracy did not improve from 0.92365\n","Epoch 454/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.6723 - val_accuracy: 0.8793\n","\n","Epoch 00454: val_accuracy did not improve from 0.92365\n","Epoch 455/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0363 - accuracy: 0.9896 - val_loss: 0.8768 - val_accuracy: 0.8645\n","\n","Epoch 00455: val_accuracy did not improve from 0.92365\n","Epoch 456/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0304 - accuracy: 0.9860 - val_loss: 0.8183 - val_accuracy: 0.8670\n","\n","Epoch 00456: val_accuracy did not improve from 0.92365\n","Epoch 457/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0213 - accuracy: 0.9951 - val_loss: 1.1206 - val_accuracy: 0.8103\n","\n","Epoch 00457: val_accuracy did not improve from 0.92365\n","Epoch 458/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0172 - accuracy: 0.9970 - val_loss: 0.6797 - val_accuracy: 0.8842\n","\n","Epoch 00458: val_accuracy did not improve from 0.92365\n","Epoch 459/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.7008 - val_accuracy: 0.8892\n","\n","Epoch 00459: val_accuracy did not improve from 0.92365\n","Epoch 460/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.5978 - val_accuracy: 0.9015\n","\n","Epoch 00460: val_accuracy did not improve from 0.92365\n","Epoch 461/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.7494 - val_accuracy: 0.8695\n","\n","Epoch 00461: val_accuracy did not improve from 0.92365\n","Epoch 462/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.8092 - val_accuracy: 0.8695\n","\n","Epoch 00462: val_accuracy did not improve from 0.92365\n","Epoch 463/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5769 - val_accuracy: 0.8941\n","\n","Epoch 00463: val_accuracy did not improve from 0.92365\n","Epoch 464/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.7143 - val_accuracy: 0.8768\n","\n","Epoch 00464: val_accuracy did not improve from 0.92365\n","Epoch 465/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.7964 - val_accuracy: 0.8719\n","\n","Epoch 00465: val_accuracy did not improve from 0.92365\n","Epoch 466/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.7049 - val_accuracy: 0.8695\n","\n","Epoch 00466: val_accuracy did not improve from 0.92365\n","Epoch 467/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0229 - accuracy: 0.9939 - val_loss: 1.2563 - val_accuracy: 0.8202\n","\n","Epoch 00467: val_accuracy did not improve from 0.92365\n","Epoch 468/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.7267 - val_accuracy: 0.8645\n","\n","Epoch 00468: val_accuracy did not improve from 0.92365\n","Epoch 469/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.5968 - val_accuracy: 0.9089\n","\n","Epoch 00469: val_accuracy did not improve from 0.92365\n","Epoch 470/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.7411 - val_accuracy: 0.8941\n","\n","Epoch 00470: val_accuracy did not improve from 0.92365\n","Epoch 471/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.7645 - val_accuracy: 0.8867\n","\n","Epoch 00471: val_accuracy did not improve from 0.92365\n","Epoch 472/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.7421 - val_accuracy: 0.8596\n","\n","Epoch 00472: val_accuracy did not improve from 0.92365\n","Epoch 473/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.6752 - val_accuracy: 0.8867\n","\n","Epoch 00473: val_accuracy did not improve from 0.92365\n","Epoch 474/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.6533 - val_accuracy: 0.8892\n","\n","Epoch 00474: val_accuracy did not improve from 0.92365\n","Epoch 475/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.6100 - val_accuracy: 0.8941\n","\n","Epoch 00475: val_accuracy did not improve from 0.92365\n","Epoch 476/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.6126 - val_accuracy: 0.8941\n","\n","Epoch 00476: val_accuracy did not improve from 0.92365\n","Epoch 477/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 1.4206 - val_accuracy: 0.8251\n","\n","Epoch 00477: val_accuracy did not improve from 0.92365\n","Epoch 478/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.7267 - val_accuracy: 0.8842\n","\n","Epoch 00478: val_accuracy did not improve from 0.92365\n","Epoch 479/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.5902 - val_accuracy: 0.9015\n","\n","Epoch 00479: val_accuracy did not improve from 0.92365\n","Epoch 480/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.5796 - val_accuracy: 0.8941\n","\n","Epoch 00480: val_accuracy did not improve from 0.92365\n","Epoch 481/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.5523 - val_accuracy: 0.8990\n","\n","Epoch 00481: val_accuracy did not improve from 0.92365\n","Epoch 482/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.6279 - val_accuracy: 0.9039\n","\n","Epoch 00482: val_accuracy did not improve from 0.92365\n","Epoch 483/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.6559 - val_accuracy: 0.8892\n","\n","Epoch 00483: val_accuracy did not improve from 0.92365\n","Epoch 484/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.6987 - val_accuracy: 0.8744\n","\n","Epoch 00484: val_accuracy did not improve from 0.92365\n","Epoch 485/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.5383 - val_accuracy: 0.8842\n","\n","Epoch 00485: val_accuracy did not improve from 0.92365\n","Epoch 486/500\n","52/52 [==============================] - 12s 223ms/step - loss: 9.7040e-04 - accuracy: 1.0000 - val_loss: 0.5562 - val_accuracy: 0.8990\n","\n","Epoch 00486: val_accuracy did not improve from 0.92365\n","Epoch 487/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.5364 - val_accuracy: 0.8916\n","\n","Epoch 00487: val_accuracy did not improve from 0.92365\n","Epoch 488/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.6405 - val_accuracy: 0.8670\n","\n","Epoch 00488: val_accuracy did not improve from 0.92365\n","Epoch 489/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 0.6942 - val_accuracy: 0.8768\n","\n","Epoch 00489: val_accuracy did not improve from 0.92365\n","Epoch 490/500\n","52/52 [==============================] - 12s 223ms/step - loss: 8.2813e-04 - accuracy: 1.0000 - val_loss: 0.5922 - val_accuracy: 0.8941\n","\n","Epoch 00490: val_accuracy did not improve from 0.92365\n","Epoch 491/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6457 - val_accuracy: 0.8818\n","\n","Epoch 00491: val_accuracy did not improve from 0.92365\n","Epoch 492/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.6744 - val_accuracy: 0.8916\n","\n","Epoch 00492: val_accuracy did not improve from 0.92365\n","Epoch 493/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6155 - val_accuracy: 0.8892\n","\n","Epoch 00493: val_accuracy did not improve from 0.92365\n","Epoch 494/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 0.9089\n","\n","Epoch 00494: val_accuracy did not improve from 0.92365\n","Epoch 495/500\n","52/52 [==============================] - 12s 222ms/step - loss: 4.4954e-04 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.9089\n","\n","Epoch 00495: val_accuracy did not improve from 0.92365\n","Epoch 496/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5586 - val_accuracy: 0.8867\n","\n","Epoch 00496: val_accuracy did not improve from 0.92365\n","Epoch 497/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.6807 - val_accuracy: 0.8793\n","\n","Epoch 00497: val_accuracy did not improve from 0.92365\n","Epoch 498/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5083 - val_accuracy: 0.9064\n","\n","Epoch 00498: val_accuracy did not improve from 0.92365\n","Epoch 499/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.7832 - val_accuracy: 0.8571\n","\n","Epoch 00499: val_accuracy did not improve from 0.92365\n","Epoch 500/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0382 - accuracy: 0.9866 - val_loss: 1.1968 - val_accuracy: 0.8005\n","\n","Epoch 00500: val_accuracy did not improve from 0.92365\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0f78287710>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1630614660545,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"8216d753-a6e2-4d56-f916-41657a8fd511"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1630614680312,"user_tz":-540,"elapsed":19780,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_020_4_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1630614681198,"user_tz":-540,"elapsed":890,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630614681611,"user_tz":-540,"elapsed":415,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"3fa48166-8b70-47b5-891a-d739f6fd0c76"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630614714011,"user_tz":-540,"elapsed":32403,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"546ecc75-eb4c-4a1d-b3cf-62c6fd4b96c9"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1630614714434,"user_tz":-540,"elapsed":425,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1630614714435,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1630614716140,"user_tz":-540,"elapsed":1709,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1630614716142,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1630614731350,"user_tz":-540,"elapsed":15216,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1630614731360,"user_tz":-540,"elapsed":26,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"4edee9fb-0b3a-4356-a809-74bfff0761bf"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1630614731360,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"78bb0f5a-fb1d-4e59-cb53-8380c355bdd6"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_020_4_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_020_4_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_aafce4f6-02cd-41fb-a9ae-34288f60f99a\", \"HeightShiftRange_020_4_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}