{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ImageSize_299_2_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1p5Rg-oC5wgs8kljSDJf6F3i0LQrXsxVc","timestamp":1631269202490},{"file_id":"1f3nznDNfoCy2o3khbtOPBsLH6aWkikaC","timestamp":1631216445247},{"file_id":"1c2MWKPmFEryc2NI5jyKAAWVmxqH1VUCz","timestamp":1631216398169},{"file_id":"1_XM5eXz-mRq_8btoHAcEP8vfGSYFw1LC","timestamp":1631216374547},{"file_id":"1WF9YyXyX0BHUcSI4EfvLCmpIZnkjfht_","timestamp":1631199517663},{"file_id":"1DhKkeZKVN6SnskBHR9I9JhnmnnAvvYsM","timestamp":1631199484204},{"file_id":"1Sb1zx-9JnMoqZN44rSFWtUmopGi9YObV","timestamp":1631049773986},{"file_id":"1Ukz7x6x60p-yX7qFtl681RI02Xq38gil","timestamp":1631047282593},{"file_id":"1a65ZxKUM-ebeKKlnVVwnVW-zuq6YjgE5","timestamp":1631047194111},{"file_id":"1zeTuwcXoX2nrULVuhoDyze5Ppfttrv0w","timestamp":1631045991075},{"file_id":"1Q_w97zg4VwPEfNBX52yhb8QqQexMpqf_","timestamp":1631044605223},{"file_id":"1pqowzoSTmQGAh-N1th_R0C3TI9Gyl4Hc","timestamp":1631043183868},{"file_id":"1fedN2kXOFJ_DCXWKCH9EXVlgwLeCYz7u","timestamp":1631039069646},{"file_id":"1ZXAcHyuCWCyRAdv1K2fjSI7EYUZUzgd-","timestamp":1631037094537},{"file_id":"1QwQAud74jt30tPFhBZB4ST8jpL6yfXId","timestamp":1631035798955},{"file_id":"1HK4HDd8d-ydp1hpjE542SlZzhcebS04s","timestamp":1631035758423},{"file_id":"1BDI3hcYWj0EQ36ajZDAXvOF7hl4SSZLK","timestamp":1631030590142},{"file_id":"1wkcCzuHh8bbAgm3A6BK30Yutz6_lW7Wz","timestamp":1630968808808},{"file_id":"1NBaJvfE-mNYLwaRSb3DmI2VgGlo-L64e","timestamp":1630968784020},{"file_id":"1tuxKDEpXqS10eUFd1BhXSulkLRHwm5Ls","timestamp":1630968742688},{"file_id":"1tT8KjKA8d3WPDIBeqi3Pl2OBSYM0j1vs","timestamp":1630968318011},{"file_id":"1zXLjChcCNAAwvHd2Cpnq9eXPmx2Hxv7v","timestamp":1630968226179},{"file_id":"1my69WIg_k7Dsobadf8IPYHpbt46UeiOr","timestamp":1630961678442},{"file_id":"1FBIwhXm4-AXNBfg_zN4PCqYB4fBkJis9","timestamp":1630961652892},{"file_id":"1aKbh7xPYx3QmxXPNnL4Ibm-oAutHqQmP","timestamp":1630961578285},{"file_id":"1oOSCmJ_elzy5wWrlNC00MqwUHJayiHDY","timestamp":1630961542590},{"file_id":"1t7sTp3m7RRztyvU4tfL8W8lGrMk2FQjn","timestamp":1630951440213},{"file_id":"1fazDZeCuGnik7RX86NUluX6WpNk8nyHy","timestamp":1630949981703},{"file_id":"1hFR9zdRHLq9CD3Qx-qnlkZJvce1OlPUu","timestamp":1630949783061},{"file_id":"1zC6movFvQGJ4fr54cjU-Pu08xt53vVjF","timestamp":1630949772598},{"file_id":"1JjM9eMHh_iT2pY6BNfy6y5ztoX5BznNb","timestamp":1630866486107},{"file_id":"1RJHw6qRW-G23IN47ZOMM1nOcrOv-Lq_k","timestamp":1630866451790},{"file_id":"1--_lXPMfaPxWLicd9uWOpl48GRqT9x9K","timestamp":1630847367248},{"file_id":"1PGeXA-Nb00rJuv1I3ZBF6rpNR4qDErXE","timestamp":1630836207896},{"file_id":"19f4sGczygDy6VCFM6Dc6mfSNNAdh6QMI","timestamp":1630836183988},{"file_id":"1dSlKlnhNkaJD6rX0PnYAwTzru54zKEmb","timestamp":1630836149378},{"file_id":"1GxaesOzgv99NpOY71Qn2A4_a_nbiGScP","timestamp":1630836075710},{"file_id":"1pAOyg2ba1nqW5-60Tb4uA63Qfb9UVr1l","timestamp":1630835987308},{"file_id":"10TnEQPLI8MHQRmh84M8HicSibJfewY9a","timestamp":1630835956891},{"file_id":"1fiIBRDmLIPxB3JYTePwN6q-04wPwAWWN","timestamp":1630778953404},{"file_id":"1vco_0hIBI4evIfDmQDH07Nq5lQJx4Kod","timestamp":1630778923697},{"file_id":"1r3BflNbSZB370f8W3h8PQ5C7NEdbXsJj","timestamp":1630766001155},{"file_id":"1fyedjHIW6-8SHp9ow65apBeykbHxS7oi","timestamp":1630760236494},{"file_id":"1QnPclrYnKmBsAWRJ51Rre-PMBgVa9Cl3","timestamp":1630760206258},{"file_id":"1K7n8RRDie4UKR4IX4z4XcOvrqBpuzCX2","timestamp":1630760179968},{"file_id":"18NxWLqCn6GIqSPUVwANqnaPRMf5i0YEt","timestamp":1630745018066},{"file_id":"1EDWcCOn_TRgBJv_ZMCvsd_r1unwaZzE7","timestamp":1630744974962},{"file_id":"1JA5LGhrhW19laOkeoR8qPDaFWjoqSMzr","timestamp":1630744944221},{"file_id":"1PtmJdXo9AY1M6u1bHhpUHKQ0PGMoOPWZ","timestamp":1630744160988},{"file_id":"1q8viSykqnipNZ_WZtwFtIvj_ZdVFX4vC","timestamp":1630699910907},{"file_id":"1I9ElhTSO4vKs1a5lfr-r0PB1MndT08Nr","timestamp":1630699885519},{"file_id":"14FhoIy7URVKqSDzemys-qARDeDRrpK5D","timestamp":1630676044569},{"file_id":"1SyIKO_pcFSLG_l2VOhA42Qj1Sfgu9xJ5","timestamp":1630675996818},{"file_id":"1bR6CC08w6e4QxXCvbI1hPuVGX4Xr2aS6","timestamp":1630675972365},{"file_id":"1m9zTT841JY7COW8wa0uLUmdxh4mwTROg","timestamp":1630675935279},{"file_id":"1K-M0y6ngoFlaXHKpD1A2obin5bN69rOP","timestamp":1630668564612},{"file_id":"1blwd04nWkDbZIiyYRsoikGHv7D2lN1M7","timestamp":1630663027637},{"file_id":"1OWcGKJuP-Tlx2cd7fYiEF4iFQBw_jTaV","timestamp":1630663004855},{"file_id":"1iIv2T-FeMWjlLKmFmVia0cp_FsKKhP6n","timestamp":1630662692922},{"file_id":"122a3KanHz7tYxI2RkTyd5CDHFsGXxRcD","timestamp":1630652306408},{"file_id":"1rmWpSzQjpXc4LfrgWir30dbjafFqnlzh","timestamp":1630652271928},{"file_id":"1LZU500qd_mzkL28Su52XN_qaRf_yaHht","timestamp":1630646510103},{"file_id":"16JOqSkO3uC_jfclj81AzxJShlzoOMH_B","timestamp":1630613714759},{"file_id":"1eaN7vOK3RK8eeKTKP85BVew6KGSCyH_6","timestamp":1630613687181},{"file_id":"1hFz_giaup3ft5PdsqD18owTBdvEk-9En","timestamp":1630613648785},{"file_id":"15fNytZzTcRPBSdHijbaWLKC0KR8SWzhp","timestamp":1630612864615},{"file_id":"1C8ZNqu7Eb5heuVECStaVKpkxyihLmMkO","timestamp":1630602470521},{"file_id":"1DN9Efw8q90g7HCJ5VhXJYn57jItRUHnr","timestamp":1630602447501},{"file_id":"1ZYwQgfbGvCmGKmNM25goBD839_1yJrul","timestamp":1630602408672},{"file_id":"1_j6u69eFZFR-bV-7FdC_KmRhJ8AI-Ifh","timestamp":1630602370180},{"file_id":"1unjV74CiTTQsLla4T4r8Xawlb_l1_ego","timestamp":1630602293534},{"file_id":"1MSEaTlfMh47aob3-U8yPBQNcpxSO0RC6","timestamp":1630524166308},{"file_id":"1uj1q7VaxDNJ4v0Qnpewz9OO5vDawvGL1","timestamp":1630524142681},{"file_id":"1SXi4BHkyVdQzSXMkx23PhKLYG_cgy9Ne","timestamp":1630524118198},{"file_id":"1ktumtKU2gng5uaTndy4q6ORrf_vm1MB5","timestamp":1630516331014},{"file_id":"19fk2AWJq9X3zvPm2WSAtKO7ljZBPUG5l","timestamp":1630516290119},{"file_id":"1ZOrlvLwHgJ8yqXlMzsUBuNpAS1leHpTw","timestamp":1630516251869},{"file_id":"1lrAXMllo7_hAtAVIxPhE7Xno3vS6aFxT","timestamp":1630515420255},{"file_id":"17dTh7DEVFlzrmiHY5X5ldlDVaanaV9e-","timestamp":1630504418101},{"file_id":"1mqEzmVKqNVAF_0chUK1joEpZK_PYc0_4","timestamp":1630504394196},{"file_id":"1mzp8pt1OJt9CAaiKKe25s3yNAqrGew9R","timestamp":1630504147646},{"file_id":"1FMgk3jn7Q2dQ8p_Hu7bJRfcSBb13Rnvo","timestamp":1630504098889},{"file_id":"1hhBZ077MXyvhUnuxI7SD86ahYiLsCzOG","timestamp":1630500513841},{"file_id":"1EEfvNr8ZybJmpeRuKJ-r7__rhnDnaIM7","timestamp":1630495179853},{"file_id":"17e4zKJb3AvCBXA5MdPqutbvT9s1-CP6A","timestamp":1630484224103},{"file_id":"1ZyJ9--fiBCqqZIpZYXBwYIGMXZPnoPvu","timestamp":1630484173863},{"file_id":"1abkZGMd_cSctW05mIZfosyOPOLNr-LK9","timestamp":1630484131331},{"file_id":"1fKp4Svl_srbEAv_YpXTvSwqDozb4bj9H","timestamp":1630484105207},{"file_id":"1y9kcnOXGhn5ArjCk66kqJCIvgyfTRSkk","timestamp":1630483907553},{"file_id":"1o9CD4AI2tKzcdbdLJ4A6xkENgqmZG7oW","timestamp":1630475138628},{"file_id":"17KUAlMIBl9TgxSnuNYcPwx2zScEUw5W-","timestamp":1630475103015},{"file_id":"12cn5R3wN6-IWoeS68BSqi4LxqlCxJxYt","timestamp":1630464969114},{"file_id":"1KLLc8roFaz12DcPj1WHhuKt9ZBQqi76a","timestamp":1630464678834},{"file_id":"1VZIQ1plZ8Dw3dEaOdrcDkgTjXOv0OcTp","timestamp":1630464589009},{"file_id":"1HiqQpOR-bo5ZelQ96RenE8K365HqE7Lv","timestamp":1630438189228},{"file_id":"1ltViornnQGTXyCDuiYgIGfZy1m46LTW_","timestamp":1630438122242},{"file_id":"12vcTsqE7nuRUe3r9-4k5efqml3ud1k9Z","timestamp":1630438078632},{"file_id":"1EdFynNtlBeF206lf5xA2umzEqK_Pjyi5","timestamp":1630437839162},{"file_id":"1pKJK3lnnRPxX28V0U_A45uk_SI4WlDZr","timestamp":1630432659647},{"file_id":"1soBcJ0zzhkPsMINjzGMbYGcga7VX-2Be","timestamp":1630432634550},{"file_id":"12jPQ_wSDDvGyzTBUV-h-pRZ8N-lp9bkW","timestamp":1630425888718},{"file_id":"1ik1ECJq6EbWwGegXLisYoxytv0-7JQcn","timestamp":1630425853722},{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyM4N+CrUVetycL6QfxknJ33"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631269263650,"user_tz":-540,"elapsed":395,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"2274504a-c160-4cf4-e0a3-471ae70c98db"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Sep 10 10:21:03 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631269283180,"user_tz":-540,"elapsed":19535,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b483812d-8b0a-49a3-a262-4d5ab006e86e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1631269288498,"user_tz":-540,"elapsed":5323,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1631269289676,"user_tz":-540,"elapsed":1188,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1631269292457,"user_tz":-540,"elapsed":2805,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1631269312790,"user_tz":-540,"elapsed":20336,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1631269320579,"user_tz":-540,"elapsed":7795,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(299, 299, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631269320581,"user_tz":-540,"elapsed":23,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d4ac7d38-22dc-4a1e-b399-53cf2fadd793"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631269320583,"user_tz":-540,"elapsed":21,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"60ec6408-7b08-4daf-a34c-a7da1c6ef580"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(299,299), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(299,299), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1631269320584,"user_tz":-540,"elapsed":16,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631304836863,"user_tz":-540,"elapsed":35516293,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"fe9ad718-af2f-4989-f403-111271b7feb4"},"source":["DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 114s 2s/step - loss: 2.0021 - accuracy: 0.2838 - val_loss: 7.0905 - val_accuracy: 0.0985\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 69s 1s/step - loss: 1.3981 - accuracy: 0.5067 - val_loss: 18.2888 - val_accuracy: 0.1108\n","\n","Epoch 00002: val_accuracy improved from 0.09852 to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 3/500\n","52/52 [==============================] - 69s 1s/step - loss: 1.0493 - accuracy: 0.6407 - val_loss: 16.3916 - val_accuracy: 0.0640\n","\n","Epoch 00003: val_accuracy did not improve from 0.11084\n","Epoch 4/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.9695 - accuracy: 0.6620 - val_loss: 8.9948 - val_accuracy: 0.1034\n","\n","Epoch 00004: val_accuracy did not improve from 0.11084\n","Epoch 5/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.8042 - accuracy: 0.7424 - val_loss: 5.8994 - val_accuracy: 0.1798\n","\n","Epoch 00005: val_accuracy improved from 0.11084 to 0.17980, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.7396 - accuracy: 0.7515 - val_loss: 5.1982 - val_accuracy: 0.2734\n","\n","Epoch 00006: val_accuracy improved from 0.17980 to 0.27340, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.6648 - accuracy: 0.7704 - val_loss: 3.5425 - val_accuracy: 0.3300\n","\n","Epoch 00007: val_accuracy improved from 0.27340 to 0.33005, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.5692 - accuracy: 0.7984 - val_loss: 4.8730 - val_accuracy: 0.2217\n","\n","Epoch 00008: val_accuracy did not improve from 0.33005\n","Epoch 9/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.5180 - accuracy: 0.8179 - val_loss: 2.6609 - val_accuracy: 0.4236\n","\n","Epoch 00009: val_accuracy improved from 0.33005 to 0.42365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.5060 - accuracy: 0.8301 - val_loss: 1.8879 - val_accuracy: 0.5665\n","\n","Epoch 00010: val_accuracy improved from 0.42365 to 0.56650, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.4518 - accuracy: 0.8490 - val_loss: 1.0667 - val_accuracy: 0.7069\n","\n","Epoch 00011: val_accuracy improved from 0.56650 to 0.70690, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.4386 - accuracy: 0.8435 - val_loss: 1.0356 - val_accuracy: 0.7389\n","\n","Epoch 00012: val_accuracy improved from 0.70690 to 0.73892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 13/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.3852 - accuracy: 0.8727 - val_loss: 1.0847 - val_accuracy: 0.6872\n","\n","Epoch 00013: val_accuracy did not improve from 0.73892\n","Epoch 14/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.3601 - accuracy: 0.8764 - val_loss: 1.0035 - val_accuracy: 0.7414\n","\n","Epoch 00014: val_accuracy improved from 0.73892 to 0.74138, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 15/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.3761 - accuracy: 0.8660 - val_loss: 2.3404 - val_accuracy: 0.5345\n","\n","Epoch 00015: val_accuracy did not improve from 0.74138\n","Epoch 16/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.3931 - accuracy: 0.8666 - val_loss: 1.1373 - val_accuracy: 0.7044\n","\n","Epoch 00016: val_accuracy did not improve from 0.74138\n","Epoch 17/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.3061 - accuracy: 0.8983 - val_loss: 0.5626 - val_accuracy: 0.8399\n","\n","Epoch 00017: val_accuracy improved from 0.74138 to 0.83990, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 18/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.3328 - accuracy: 0.8849 - val_loss: 0.9102 - val_accuracy: 0.7562\n","\n","Epoch 00018: val_accuracy did not improve from 0.83990\n","Epoch 19/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.2876 - accuracy: 0.8995 - val_loss: 1.3608 - val_accuracy: 0.6921\n","\n","Epoch 00019: val_accuracy did not improve from 0.83990\n","Epoch 20/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.2917 - accuracy: 0.9056 - val_loss: 1.0757 - val_accuracy: 0.7192\n","\n","Epoch 00020: val_accuracy did not improve from 0.83990\n","Epoch 21/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.2726 - accuracy: 0.9044 - val_loss: 0.5541 - val_accuracy: 0.8350\n","\n","Epoch 00021: val_accuracy did not improve from 0.83990\n","Epoch 22/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.2425 - accuracy: 0.9178 - val_loss: 0.5715 - val_accuracy: 0.8177\n","\n","Epoch 00022: val_accuracy did not improve from 0.83990\n","Epoch 23/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.2769 - accuracy: 0.9032 - val_loss: 0.7430 - val_accuracy: 0.8030\n","\n","Epoch 00023: val_accuracy did not improve from 0.83990\n","Epoch 24/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.2240 - accuracy: 0.9269 - val_loss: 0.7299 - val_accuracy: 0.8128\n","\n","Epoch 00024: val_accuracy did not improve from 0.83990\n","Epoch 25/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1718 - accuracy: 0.9415 - val_loss: 1.0286 - val_accuracy: 0.7340\n","\n","Epoch 00025: val_accuracy did not improve from 0.83990\n","Epoch 26/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1578 - accuracy: 0.9501 - val_loss: 0.4687 - val_accuracy: 0.8645\n","\n","Epoch 00026: val_accuracy improved from 0.83990 to 0.86453, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 27/500\n","52/52 [==============================] - 70s 1s/step - loss: 0.1771 - accuracy: 0.9476 - val_loss: 0.6482 - val_accuracy: 0.8079\n","\n","Epoch 00027: val_accuracy did not improve from 0.86453\n","Epoch 28/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1655 - accuracy: 0.9397 - val_loss: 1.2671 - val_accuracy: 0.7217\n","\n","Epoch 00028: val_accuracy did not improve from 0.86453\n","Epoch 29/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1728 - accuracy: 0.9440 - val_loss: 0.5271 - val_accuracy: 0.8498\n","\n","Epoch 00029: val_accuracy did not improve from 0.86453\n","Epoch 30/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.2334 - accuracy: 0.9208 - val_loss: 1.0927 - val_accuracy: 0.7438\n","\n","Epoch 00030: val_accuracy did not improve from 0.86453\n","Epoch 31/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1926 - accuracy: 0.9306 - val_loss: 0.9553 - val_accuracy: 0.7586\n","\n","Epoch 00031: val_accuracy did not improve from 0.86453\n","Epoch 32/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1720 - accuracy: 0.9397 - val_loss: 0.5596 - val_accuracy: 0.8719\n","\n","Epoch 00032: val_accuracy improved from 0.86453 to 0.87192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 33/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.2155 - accuracy: 0.9263 - val_loss: 0.9056 - val_accuracy: 0.7759\n","\n","Epoch 00033: val_accuracy did not improve from 0.87192\n","Epoch 34/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1858 - accuracy: 0.9379 - val_loss: 1.2922 - val_accuracy: 0.6823\n","\n","Epoch 00034: val_accuracy did not improve from 0.87192\n","Epoch 35/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1505 - accuracy: 0.9464 - val_loss: 0.6674 - val_accuracy: 0.8374\n","\n","Epoch 00035: val_accuracy did not improve from 0.87192\n","Epoch 36/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1424 - accuracy: 0.9549 - val_loss: 0.3717 - val_accuracy: 0.8842\n","\n","Epoch 00036: val_accuracy improved from 0.87192 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 37/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1233 - accuracy: 0.9562 - val_loss: 0.5763 - val_accuracy: 0.8325\n","\n","Epoch 00037: val_accuracy did not improve from 0.88424\n","Epoch 38/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1111 - accuracy: 0.9629 - val_loss: 0.8064 - val_accuracy: 0.8251\n","\n","Epoch 00038: val_accuracy did not improve from 0.88424\n","Epoch 39/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1605 - accuracy: 0.9385 - val_loss: 0.6052 - val_accuracy: 0.8251\n","\n","Epoch 00039: val_accuracy did not improve from 0.88424\n","Epoch 40/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1561 - accuracy: 0.9470 - val_loss: 0.5356 - val_accuracy: 0.8522\n","\n","Epoch 00040: val_accuracy did not improve from 0.88424\n","Epoch 41/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0913 - accuracy: 0.9702 - val_loss: 0.5294 - val_accuracy: 0.8719\n","\n","Epoch 00041: val_accuracy did not improve from 0.88424\n","Epoch 42/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1540 - accuracy: 0.9537 - val_loss: 0.6799 - val_accuracy: 0.8350\n","\n","Epoch 00042: val_accuracy did not improve from 0.88424\n","Epoch 43/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1239 - accuracy: 0.9519 - val_loss: 0.7129 - val_accuracy: 0.8054\n","\n","Epoch 00043: val_accuracy did not improve from 0.88424\n","Epoch 44/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1050 - accuracy: 0.9610 - val_loss: 0.4765 - val_accuracy: 0.8621\n","\n","Epoch 00044: val_accuracy did not improve from 0.88424\n","Epoch 45/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1046 - accuracy: 0.9647 - val_loss: 0.5642 - val_accuracy: 0.8300\n","\n","Epoch 00045: val_accuracy did not improve from 0.88424\n","Epoch 46/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0757 - accuracy: 0.9738 - val_loss: 0.5291 - val_accuracy: 0.8719\n","\n","Epoch 00046: val_accuracy did not improve from 0.88424\n","Epoch 47/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0801 - accuracy: 0.9738 - val_loss: 0.6595 - val_accuracy: 0.8522\n","\n","Epoch 00047: val_accuracy did not improve from 0.88424\n","Epoch 48/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0979 - accuracy: 0.9653 - val_loss: 0.7435 - val_accuracy: 0.8424\n","\n","Epoch 00048: val_accuracy did not improve from 0.88424\n","Epoch 49/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1397 - accuracy: 0.9543 - val_loss: 0.9163 - val_accuracy: 0.7906\n","\n","Epoch 00049: val_accuracy did not improve from 0.88424\n","Epoch 50/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1035 - accuracy: 0.9647 - val_loss: 0.7656 - val_accuracy: 0.8325\n","\n","Epoch 00050: val_accuracy did not improve from 0.88424\n","Epoch 51/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0616 - accuracy: 0.9787 - val_loss: 0.4853 - val_accuracy: 0.8867\n","\n","Epoch 00051: val_accuracy improved from 0.88424 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 52/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0431 - accuracy: 0.9884 - val_loss: 0.3286 - val_accuracy: 0.9064\n","\n","Epoch 00052: val_accuracy improved from 0.88670 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 53/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0380 - accuracy: 0.9884 - val_loss: 0.5090 - val_accuracy: 0.8719\n","\n","Epoch 00053: val_accuracy did not improve from 0.90640\n","Epoch 54/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0607 - accuracy: 0.9805 - val_loss: 0.5896 - val_accuracy: 0.8621\n","\n","Epoch 00054: val_accuracy did not improve from 0.90640\n","Epoch 55/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0581 - accuracy: 0.9805 - val_loss: 0.4713 - val_accuracy: 0.8695\n","\n","Epoch 00055: val_accuracy did not improve from 0.90640\n","Epoch 56/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0501 - accuracy: 0.9866 - val_loss: 0.4205 - val_accuracy: 0.8941\n","\n","Epoch 00056: val_accuracy did not improve from 0.90640\n","Epoch 57/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0461 - accuracy: 0.9854 - val_loss: 0.6336 - val_accuracy: 0.8571\n","\n","Epoch 00057: val_accuracy did not improve from 0.90640\n","Epoch 58/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0670 - accuracy: 0.9769 - val_loss: 0.5593 - val_accuracy: 0.8621\n","\n","Epoch 00058: val_accuracy did not improve from 0.90640\n","Epoch 59/500\n","52/52 [==============================] - 70s 1s/step - loss: 0.0532 - accuracy: 0.9811 - val_loss: 0.5012 - val_accuracy: 0.8892\n","\n","Epoch 00059: val_accuracy did not improve from 0.90640\n","Epoch 60/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0670 - accuracy: 0.9781 - val_loss: 1.1153 - val_accuracy: 0.7857\n","\n","Epoch 00060: val_accuracy did not improve from 0.90640\n","Epoch 61/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1356 - accuracy: 0.9537 - val_loss: 0.8460 - val_accuracy: 0.8227\n","\n","Epoch 00061: val_accuracy did not improve from 0.90640\n","Epoch 62/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1309 - accuracy: 0.9568 - val_loss: 0.9678 - val_accuracy: 0.7759\n","\n","Epoch 00062: val_accuracy did not improve from 0.90640\n","Epoch 63/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0939 - accuracy: 0.9689 - val_loss: 0.5420 - val_accuracy: 0.8892\n","\n","Epoch 00063: val_accuracy did not improve from 0.90640\n","Epoch 64/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0690 - accuracy: 0.9793 - val_loss: 0.5500 - val_accuracy: 0.8842\n","\n","Epoch 00064: val_accuracy did not improve from 0.90640\n","Epoch 65/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0713 - accuracy: 0.9756 - val_loss: 0.7381 - val_accuracy: 0.8227\n","\n","Epoch 00065: val_accuracy did not improve from 0.90640\n","Epoch 66/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0710 - accuracy: 0.9720 - val_loss: 0.6874 - val_accuracy: 0.8374\n","\n","Epoch 00066: val_accuracy did not improve from 0.90640\n","Epoch 67/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0793 - accuracy: 0.9714 - val_loss: 1.2107 - val_accuracy: 0.7611\n","\n","Epoch 00067: val_accuracy did not improve from 0.90640\n","Epoch 68/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0962 - accuracy: 0.9683 - val_loss: 0.7543 - val_accuracy: 0.8251\n","\n","Epoch 00068: val_accuracy did not improve from 0.90640\n","Epoch 69/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0911 - accuracy: 0.9671 - val_loss: 0.6247 - val_accuracy: 0.8424\n","\n","Epoch 00069: val_accuracy did not improve from 0.90640\n","Epoch 70/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1069 - accuracy: 0.9671 - val_loss: 0.3831 - val_accuracy: 0.9163\n","\n","Epoch 00070: val_accuracy improved from 0.90640 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 71/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0933 - accuracy: 0.9671 - val_loss: 0.4904 - val_accuracy: 0.8793\n","\n","Epoch 00071: val_accuracy did not improve from 0.91626\n","Epoch 72/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0634 - accuracy: 0.9756 - val_loss: 0.5861 - val_accuracy: 0.8695\n","\n","Epoch 00072: val_accuracy did not improve from 0.91626\n","Epoch 73/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0353 - accuracy: 0.9860 - val_loss: 0.5668 - val_accuracy: 0.8695\n","\n","Epoch 00073: val_accuracy did not improve from 0.91626\n","Epoch 74/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0237 - accuracy: 0.9945 - val_loss: 0.3299 - val_accuracy: 0.9163\n","\n","Epoch 00074: val_accuracy did not improve from 0.91626\n","Epoch 75/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.5216 - val_accuracy: 0.8695\n","\n","Epoch 00075: val_accuracy did not improve from 0.91626\n","Epoch 76/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 0.4526 - val_accuracy: 0.9064\n","\n","Epoch 00076: val_accuracy did not improve from 0.91626\n","Epoch 77/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0366 - accuracy: 0.9890 - val_loss: 0.6346 - val_accuracy: 0.8473\n","\n","Epoch 00077: val_accuracy did not improve from 0.91626\n","Epoch 78/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0750 - accuracy: 0.9762 - val_loss: 0.7174 - val_accuracy: 0.8350\n","\n","Epoch 00078: val_accuracy did not improve from 0.91626\n","Epoch 79/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0887 - accuracy: 0.9683 - val_loss: 0.7649 - val_accuracy: 0.8276\n","\n","Epoch 00079: val_accuracy did not improve from 0.91626\n","Epoch 80/500\n","52/52 [==============================] - 70s 1s/step - loss: 0.0559 - accuracy: 0.9769 - val_loss: 0.5989 - val_accuracy: 0.8645\n","\n","Epoch 00080: val_accuracy did not improve from 0.91626\n","Epoch 81/500\n","52/52 [==============================] - 70s 1s/step - loss: 0.0412 - accuracy: 0.9836 - val_loss: 0.7768 - val_accuracy: 0.8350\n","\n","Epoch 00081: val_accuracy did not improve from 0.91626\n","Epoch 82/500\n","52/52 [==============================] - 70s 1s/step - loss: 0.0333 - accuracy: 0.9890 - val_loss: 0.5827 - val_accuracy: 0.8744\n","\n","Epoch 00082: val_accuracy did not improve from 0.91626\n","Epoch 83/500\n","52/52 [==============================] - 70s 1s/step - loss: 0.0483 - accuracy: 0.9836 - val_loss: 0.5626 - val_accuracy: 0.9064\n","\n","Epoch 00083: val_accuracy did not improve from 0.91626\n","Epoch 84/500\n","52/52 [==============================] - 70s 1s/step - loss: 0.0419 - accuracy: 0.9854 - val_loss: 0.4964 - val_accuracy: 0.8818\n","\n","Epoch 00084: val_accuracy did not improve from 0.91626\n","Epoch 85/500\n","52/52 [==============================] - 70s 1s/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 0.6533 - val_accuracy: 0.8448\n","\n","Epoch 00085: val_accuracy did not improve from 0.91626\n","Epoch 86/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 0.8700 - val_accuracy: 0.7759\n","\n","Epoch 00086: val_accuracy did not improve from 0.91626\n","Epoch 87/500\n","52/52 [==============================] - 70s 1s/step - loss: 0.0370 - accuracy: 0.9866 - val_loss: 0.5178 - val_accuracy: 0.8818\n","\n","Epoch 00087: val_accuracy did not improve from 0.91626\n","Epoch 88/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 0.5335 - val_accuracy: 0.8892\n","\n","Epoch 00088: val_accuracy did not improve from 0.91626\n","Epoch 89/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0471 - accuracy: 0.9799 - val_loss: 0.6972 - val_accuracy: 0.8842\n","\n","Epoch 00089: val_accuracy did not improve from 0.91626\n","Epoch 90/500\n","52/52 [==============================] - 70s 1s/step - loss: 0.0787 - accuracy: 0.9750 - val_loss: 0.4895 - val_accuracy: 0.8966\n","\n","Epoch 00090: val_accuracy did not improve from 0.91626\n","Epoch 91/500\n","52/52 [==============================] - 70s 1s/step - loss: 0.1010 - accuracy: 0.9695 - val_loss: 0.7581 - val_accuracy: 0.8399\n","\n","Epoch 00091: val_accuracy did not improve from 0.91626\n","Epoch 92/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0585 - accuracy: 0.9829 - val_loss: 0.5622 - val_accuracy: 0.8768\n","\n","Epoch 00092: val_accuracy did not improve from 0.91626\n","Epoch 93/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0351 - accuracy: 0.9884 - val_loss: 0.4356 - val_accuracy: 0.8990\n","\n","Epoch 00093: val_accuracy did not improve from 0.91626\n","Epoch 94/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 0.6704 - val_accuracy: 0.8547\n","\n","Epoch 00094: val_accuracy did not improve from 0.91626\n","Epoch 95/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.8368 - val_accuracy: 0.8300\n","\n","Epoch 00095: val_accuracy did not improve from 0.91626\n","Epoch 96/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0500 - accuracy: 0.9854 - val_loss: 0.9051 - val_accuracy: 0.8128\n","\n","Epoch 00096: val_accuracy did not improve from 0.91626\n","Epoch 97/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0351 - accuracy: 0.9878 - val_loss: 0.6822 - val_accuracy: 0.8276\n","\n","Epoch 00097: val_accuracy did not improve from 0.91626\n","Epoch 98/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0293 - accuracy: 0.9933 - val_loss: 0.6496 - val_accuracy: 0.8498\n","\n","Epoch 00098: val_accuracy did not improve from 0.91626\n","Epoch 99/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0559 - accuracy: 0.9817 - val_loss: 0.6959 - val_accuracy: 0.8498\n","\n","Epoch 00099: val_accuracy did not improve from 0.91626\n","Epoch 100/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0498 - accuracy: 0.9829 - val_loss: 1.0889 - val_accuracy: 0.7808\n","\n","Epoch 00100: val_accuracy did not improve from 0.91626\n","Epoch 101/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0511 - accuracy: 0.9829 - val_loss: 0.7215 - val_accuracy: 0.8251\n","\n","Epoch 00101: val_accuracy did not improve from 0.91626\n","Epoch 102/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0623 - accuracy: 0.9799 - val_loss: 0.6024 - val_accuracy: 0.8768\n","\n","Epoch 00102: val_accuracy did not improve from 0.91626\n","Epoch 103/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0950 - accuracy: 0.9659 - val_loss: 1.4344 - val_accuracy: 0.7882\n","\n","Epoch 00103: val_accuracy did not improve from 0.91626\n","Epoch 104/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0632 - accuracy: 0.9799 - val_loss: 0.8828 - val_accuracy: 0.8621\n","\n","Epoch 00104: val_accuracy did not improve from 0.91626\n","Epoch 105/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0506 - accuracy: 0.9829 - val_loss: 0.6547 - val_accuracy: 0.8498\n","\n","Epoch 00105: val_accuracy did not improve from 0.91626\n","Epoch 106/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.7837 - val_accuracy: 0.8374\n","\n","Epoch 00106: val_accuracy did not improve from 0.91626\n","Epoch 107/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 0.4934 - val_accuracy: 0.8916\n","\n","Epoch 00107: val_accuracy did not improve from 0.91626\n","Epoch 108/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0102 - accuracy: 0.9988 - val_loss: 0.3547 - val_accuracy: 0.9113\n","\n","Epoch 00108: val_accuracy did not improve from 0.91626\n","Epoch 109/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0501 - accuracy: 0.9854 - val_loss: 0.5880 - val_accuracy: 0.8768\n","\n","Epoch 00109: val_accuracy did not improve from 0.91626\n","Epoch 110/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0377 - accuracy: 0.9896 - val_loss: 0.8005 - val_accuracy: 0.8300\n","\n","Epoch 00110: val_accuracy did not improve from 0.91626\n","Epoch 111/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0544 - accuracy: 0.9805 - val_loss: 0.5351 - val_accuracy: 0.8990\n","\n","Epoch 00111: val_accuracy did not improve from 0.91626\n","Epoch 112/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 0.4066 - val_accuracy: 0.9089\n","\n","Epoch 00112: val_accuracy did not improve from 0.91626\n","Epoch 113/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0584 - accuracy: 0.9823 - val_loss: 0.4928 - val_accuracy: 0.8793\n","\n","Epoch 00113: val_accuracy did not improve from 0.91626\n","Epoch 114/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0667 - accuracy: 0.9793 - val_loss: 1.2147 - val_accuracy: 0.8054\n","\n","Epoch 00114: val_accuracy did not improve from 0.91626\n","Epoch 115/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0555 - accuracy: 0.9866 - val_loss: 1.1163 - val_accuracy: 0.7833\n","\n","Epoch 00115: val_accuracy did not improve from 0.91626\n","Epoch 116/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0580 - accuracy: 0.9823 - val_loss: 0.6850 - val_accuracy: 0.8596\n","\n","Epoch 00116: val_accuracy did not improve from 0.91626\n","Epoch 117/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0199 - accuracy: 0.9951 - val_loss: 0.5744 - val_accuracy: 0.8916\n","\n","Epoch 00117: val_accuracy did not improve from 0.91626\n","Epoch 118/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.5160 - val_accuracy: 0.8744\n","\n","Epoch 00118: val_accuracy did not improve from 0.91626\n","Epoch 119/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0545 - accuracy: 0.9854 - val_loss: 0.7187 - val_accuracy: 0.8596\n","\n","Epoch 00119: val_accuracy did not improve from 0.91626\n","Epoch 120/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0341 - accuracy: 0.9903 - val_loss: 0.5069 - val_accuracy: 0.8941\n","\n","Epoch 00120: val_accuracy did not improve from 0.91626\n","Epoch 121/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0276 - accuracy: 0.9921 - val_loss: 0.6343 - val_accuracy: 0.8645\n","\n","Epoch 00121: val_accuracy did not improve from 0.91626\n","Epoch 122/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.4464 - val_accuracy: 0.9113\n","\n","Epoch 00122: val_accuracy did not improve from 0.91626\n","Epoch 123/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0261 - accuracy: 0.9927 - val_loss: 0.4699 - val_accuracy: 0.9089\n","\n","Epoch 00123: val_accuracy did not improve from 0.91626\n","Epoch 124/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0194 - accuracy: 0.9915 - val_loss: 0.6437 - val_accuracy: 0.9039\n","\n","Epoch 00124: val_accuracy did not improve from 0.91626\n","Epoch 125/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.4960 - val_accuracy: 0.9113\n","\n","Epoch 00125: val_accuracy did not improve from 0.91626\n","Epoch 126/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 0.7849 - val_accuracy: 0.8202\n","\n","Epoch 00126: val_accuracy did not improve from 0.91626\n","Epoch 127/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.6310 - val_accuracy: 0.8892\n","\n","Epoch 00127: val_accuracy did not improve from 0.91626\n","Epoch 128/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0155 - accuracy: 0.9939 - val_loss: 0.3596 - val_accuracy: 0.9187\n","\n","Epoch 00128: val_accuracy improved from 0.91626 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 129/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 0.6686 - val_accuracy: 0.8596\n","\n","Epoch 00129: val_accuracy did not improve from 0.91872\n","Epoch 130/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0563 - accuracy: 0.9817 - val_loss: 1.0835 - val_accuracy: 0.8030\n","\n","Epoch 00130: val_accuracy did not improve from 0.91872\n","Epoch 131/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0549 - accuracy: 0.9811 - val_loss: 0.7507 - val_accuracy: 0.8054\n","\n","Epoch 00131: val_accuracy did not improve from 0.91872\n","Epoch 132/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0404 - accuracy: 0.9854 - val_loss: 0.5549 - val_accuracy: 0.8695\n","\n","Epoch 00132: val_accuracy did not improve from 0.91872\n","Epoch 133/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0365 - accuracy: 0.9896 - val_loss: 0.4546 - val_accuracy: 0.8990\n","\n","Epoch 00133: val_accuracy did not improve from 0.91872\n","Epoch 134/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.7568 - val_accuracy: 0.8547\n","\n","Epoch 00134: val_accuracy did not improve from 0.91872\n","Epoch 135/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0399 - accuracy: 0.9854 - val_loss: 1.0694 - val_accuracy: 0.8350\n","\n","Epoch 00135: val_accuracy did not improve from 0.91872\n","Epoch 136/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.5924 - val_accuracy: 0.9015\n","\n","Epoch 00136: val_accuracy did not improve from 0.91872\n","Epoch 137/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0212 - accuracy: 0.9915 - val_loss: 0.5640 - val_accuracy: 0.8818\n","\n","Epoch 00137: val_accuracy did not improve from 0.91872\n","Epoch 138/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0534 - accuracy: 0.9823 - val_loss: 0.6544 - val_accuracy: 0.8793\n","\n","Epoch 00138: val_accuracy did not improve from 0.91872\n","Epoch 139/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.6484 - val_accuracy: 0.8818\n","\n","Epoch 00139: val_accuracy did not improve from 0.91872\n","Epoch 140/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0390 - accuracy: 0.9890 - val_loss: 0.4790 - val_accuracy: 0.8768\n","\n","Epoch 00140: val_accuracy did not improve from 0.91872\n","Epoch 141/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0371 - accuracy: 0.9903 - val_loss: 0.7939 - val_accuracy: 0.8251\n","\n","Epoch 00141: val_accuracy did not improve from 0.91872\n","Epoch 142/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0383 - accuracy: 0.9878 - val_loss: 0.7135 - val_accuracy: 0.8522\n","\n","Epoch 00142: val_accuracy did not improve from 0.91872\n","Epoch 143/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0384 - accuracy: 0.9890 - val_loss: 0.4817 - val_accuracy: 0.8990\n","\n","Epoch 00143: val_accuracy did not improve from 0.91872\n","Epoch 144/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.4501 - val_accuracy: 0.9064\n","\n","Epoch 00144: val_accuracy did not improve from 0.91872\n","Epoch 145/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.4516 - val_accuracy: 0.9089\n","\n","Epoch 00145: val_accuracy did not improve from 0.91872\n","Epoch 146/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0122 - accuracy: 0.9976 - val_loss: 0.5055 - val_accuracy: 0.9089\n","\n","Epoch 00146: val_accuracy did not improve from 0.91872\n","Epoch 147/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.5478 - val_accuracy: 0.8990\n","\n","Epoch 00147: val_accuracy did not improve from 0.91872\n","Epoch 148/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0218 - accuracy: 0.9945 - val_loss: 0.4760 - val_accuracy: 0.8990\n","\n","Epoch 00148: val_accuracy did not improve from 0.91872\n","Epoch 149/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.6387 - val_accuracy: 0.8547\n","\n","Epoch 00149: val_accuracy did not improve from 0.91872\n","Epoch 150/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0349 - accuracy: 0.9915 - val_loss: 1.4658 - val_accuracy: 0.7783\n","\n","Epoch 00150: val_accuracy did not improve from 0.91872\n","Epoch 151/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0919 - accuracy: 0.9689 - val_loss: 2.3288 - val_accuracy: 0.6207\n","\n","Epoch 00151: val_accuracy did not improve from 0.91872\n","Epoch 152/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0525 - accuracy: 0.9829 - val_loss: 0.7646 - val_accuracy: 0.8596\n","\n","Epoch 00152: val_accuracy did not improve from 0.91872\n","Epoch 153/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.8208 - val_accuracy: 0.8473\n","\n","Epoch 00153: val_accuracy did not improve from 0.91872\n","Epoch 154/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0451 - accuracy: 0.9829 - val_loss: 0.6981 - val_accuracy: 0.8473\n","\n","Epoch 00154: val_accuracy did not improve from 0.91872\n","Epoch 155/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0263 - accuracy: 0.9896 - val_loss: 0.4186 - val_accuracy: 0.8941\n","\n","Epoch 00155: val_accuracy did not improve from 0.91872\n","Epoch 156/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.4387 - val_accuracy: 0.9089\n","\n","Epoch 00156: val_accuracy did not improve from 0.91872\n","Epoch 157/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0325 - accuracy: 0.9890 - val_loss: 0.5204 - val_accuracy: 0.8842\n","\n","Epoch 00157: val_accuracy did not improve from 0.91872\n","Epoch 158/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0286 - accuracy: 0.9903 - val_loss: 0.6094 - val_accuracy: 0.8793\n","\n","Epoch 00158: val_accuracy did not improve from 0.91872\n","Epoch 159/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0729 - accuracy: 0.9756 - val_loss: 2.1616 - val_accuracy: 0.6921\n","\n","Epoch 00159: val_accuracy did not improve from 0.91872\n","Epoch 160/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0555 - accuracy: 0.9842 - val_loss: 0.8694 - val_accuracy: 0.8424\n","\n","Epoch 00160: val_accuracy did not improve from 0.91872\n","Epoch 161/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.8528 - val_accuracy: 0.8251\n","\n","Epoch 00161: val_accuracy did not improve from 0.91872\n","Epoch 162/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.6762 - val_accuracy: 0.8522\n","\n","Epoch 00162: val_accuracy did not improve from 0.91872\n","Epoch 163/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.5886 - val_accuracy: 0.8793\n","\n","Epoch 00163: val_accuracy did not improve from 0.91872\n","Epoch 164/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.7568 - val_accuracy: 0.8670\n","\n","Epoch 00164: val_accuracy did not improve from 0.91872\n","Epoch 165/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.4693 - val_accuracy: 0.9089\n","\n","Epoch 00165: val_accuracy did not improve from 0.91872\n","Epoch 166/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 0.7227 - val_accuracy: 0.8842\n","\n","Epoch 00166: val_accuracy did not improve from 0.91872\n","Epoch 167/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.5328 - val_accuracy: 0.8892\n","\n","Epoch 00167: val_accuracy did not improve from 0.91872\n","Epoch 168/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.5355 - val_accuracy: 0.8916\n","\n","Epoch 00168: val_accuracy did not improve from 0.91872\n","Epoch 169/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.3717 - val_accuracy: 0.9113\n","\n","Epoch 00169: val_accuracy did not improve from 0.91872\n","Epoch 170/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.4937 - val_accuracy: 0.9064\n","\n","Epoch 00170: val_accuracy did not improve from 0.91872\n","Epoch 171/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4800 - val_accuracy: 0.9089\n","\n","Epoch 00171: val_accuracy did not improve from 0.91872\n","Epoch 172/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.5959 - val_accuracy: 0.8916\n","\n","Epoch 00172: val_accuracy did not improve from 0.91872\n","Epoch 173/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0205 - accuracy: 0.9927 - val_loss: 1.0329 - val_accuracy: 0.8202\n","\n","Epoch 00173: val_accuracy did not improve from 0.91872\n","Epoch 174/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0749 - accuracy: 0.9744 - val_loss: 0.6381 - val_accuracy: 0.8793\n","\n","Epoch 00174: val_accuracy did not improve from 0.91872\n","Epoch 175/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0530 - accuracy: 0.9829 - val_loss: 0.9565 - val_accuracy: 0.8276\n","\n","Epoch 00175: val_accuracy did not improve from 0.91872\n","Epoch 176/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0516 - accuracy: 0.9811 - val_loss: 1.2143 - val_accuracy: 0.7783\n","\n","Epoch 00176: val_accuracy did not improve from 0.91872\n","Epoch 177/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0512 - accuracy: 0.9799 - val_loss: 1.0765 - val_accuracy: 0.8054\n","\n","Epoch 00177: val_accuracy did not improve from 0.91872\n","Epoch 178/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.5813 - val_accuracy: 0.8768\n","\n","Epoch 00178: val_accuracy did not improve from 0.91872\n","Epoch 179/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0090 - accuracy: 0.9951 - val_loss: 0.5281 - val_accuracy: 0.8916\n","\n","Epoch 00179: val_accuracy did not improve from 0.91872\n","Epoch 180/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.5705 - val_accuracy: 0.8744\n","\n","Epoch 00180: val_accuracy did not improve from 0.91872\n","Epoch 181/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0165 - accuracy: 0.9933 - val_loss: 0.5938 - val_accuracy: 0.8916\n","\n","Epoch 00181: val_accuracy did not improve from 0.91872\n","Epoch 182/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.6443 - val_accuracy: 0.8768\n","\n","Epoch 00182: val_accuracy did not improve from 0.91872\n","Epoch 183/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.5556 - val_accuracy: 0.9015\n","\n","Epoch 00183: val_accuracy did not improve from 0.91872\n","Epoch 184/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0083 - accuracy: 0.9994 - val_loss: 0.4700 - val_accuracy: 0.9236\n","\n","Epoch 00184: val_accuracy improved from 0.91872 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 185/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0263 - accuracy: 0.9927 - val_loss: 1.0042 - val_accuracy: 0.7931\n","\n","Epoch 00185: val_accuracy did not improve from 0.92365\n","Epoch 186/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0221 - accuracy: 0.9915 - val_loss: 0.5454 - val_accuracy: 0.8768\n","\n","Epoch 00186: val_accuracy did not improve from 0.92365\n","Epoch 187/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.5471 - val_accuracy: 0.8818\n","\n","Epoch 00187: val_accuracy did not improve from 0.92365\n","Epoch 188/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.4848 - val_accuracy: 0.9039\n","\n","Epoch 00188: val_accuracy did not improve from 0.92365\n","Epoch 189/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.3598 - val_accuracy: 0.9187\n","\n","Epoch 00189: val_accuracy did not improve from 0.92365\n","Epoch 190/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0144 - accuracy: 0.9945 - val_loss: 0.4877 - val_accuracy: 0.9089\n","\n","Epoch 00190: val_accuracy did not improve from 0.92365\n","Epoch 191/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.4214 - val_accuracy: 0.8990\n","\n","Epoch 00191: val_accuracy did not improve from 0.92365\n","Epoch 192/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 1.2257 - val_accuracy: 0.7438\n","\n","Epoch 00192: val_accuracy did not improve from 0.92365\n","Epoch 193/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 2.0353 - val_accuracy: 0.6478\n","\n","Epoch 00193: val_accuracy did not improve from 0.92365\n","Epoch 194/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0516 - accuracy: 0.9848 - val_loss: 0.9817 - val_accuracy: 0.8498\n","\n","Epoch 00194: val_accuracy did not improve from 0.92365\n","Epoch 195/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0288 - accuracy: 0.9921 - val_loss: 0.9531 - val_accuracy: 0.8473\n","\n","Epoch 00195: val_accuracy did not improve from 0.92365\n","Epoch 196/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.3989 - val_accuracy: 0.9039\n","\n","Epoch 00196: val_accuracy did not improve from 0.92365\n","Epoch 197/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 0.4747 - val_accuracy: 0.9015\n","\n","Epoch 00197: val_accuracy did not improve from 0.92365\n","Epoch 198/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.5991 - val_accuracy: 0.8892\n","\n","Epoch 00198: val_accuracy did not improve from 0.92365\n","Epoch 199/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5776 - val_accuracy: 0.8916\n","\n","Epoch 00199: val_accuracy did not improve from 0.92365\n","Epoch 200/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0205 - accuracy: 0.9915 - val_loss: 0.6650 - val_accuracy: 0.8621\n","\n","Epoch 00200: val_accuracy did not improve from 0.92365\n","Epoch 201/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 1.6368 - val_accuracy: 0.7537\n","\n","Epoch 00201: val_accuracy did not improve from 0.92365\n","Epoch 202/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 0.6913 - val_accuracy: 0.8892\n","\n","Epoch 00202: val_accuracy did not improve from 0.92365\n","Epoch 203/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.6299 - val_accuracy: 0.8941\n","\n","Epoch 00203: val_accuracy did not improve from 0.92365\n","Epoch 204/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0062 - accuracy: 0.9970 - val_loss: 0.6653 - val_accuracy: 0.8719\n","\n","Epoch 00204: val_accuracy did not improve from 0.92365\n","Epoch 205/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0152 - accuracy: 0.9970 - val_loss: 0.6956 - val_accuracy: 0.8719\n","\n","Epoch 00205: val_accuracy did not improve from 0.92365\n","Epoch 206/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.8130 - val_accuracy: 0.8793\n","\n","Epoch 00206: val_accuracy did not improve from 0.92365\n","Epoch 207/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0222 - accuracy: 0.9951 - val_loss: 1.1778 - val_accuracy: 0.7783\n","\n","Epoch 00207: val_accuracy did not improve from 0.92365\n","Epoch 208/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 1.1857 - val_accuracy: 0.7833\n","\n","Epoch 00208: val_accuracy did not improve from 0.92365\n","Epoch 209/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0570 - accuracy: 0.9854 - val_loss: 0.7003 - val_accuracy: 0.8424\n","\n","Epoch 00209: val_accuracy did not improve from 0.92365\n","Epoch 210/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 1.1667 - val_accuracy: 0.7931\n","\n","Epoch 00210: val_accuracy did not improve from 0.92365\n","Epoch 211/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0436 - accuracy: 0.9854 - val_loss: 0.6045 - val_accuracy: 0.8448\n","\n","Epoch 00211: val_accuracy did not improve from 0.92365\n","Epoch 212/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.6322 - val_accuracy: 0.8768\n","\n","Epoch 00212: val_accuracy did not improve from 0.92365\n","Epoch 213/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.6275 - val_accuracy: 0.8768\n","\n","Epoch 00213: val_accuracy did not improve from 0.92365\n","Epoch 214/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0193 - accuracy: 0.9963 - val_loss: 0.4381 - val_accuracy: 0.9138\n","\n","Epoch 00214: val_accuracy did not improve from 0.92365\n","Epoch 215/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.4717 - val_accuracy: 0.8941\n","\n","Epoch 00215: val_accuracy did not improve from 0.92365\n","Epoch 216/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.6797 - val_accuracy: 0.8424\n","\n","Epoch 00216: val_accuracy did not improve from 0.92365\n","Epoch 217/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.5541 - val_accuracy: 0.8892\n","\n","Epoch 00217: val_accuracy did not improve from 0.92365\n","Epoch 218/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.6877 - val_accuracy: 0.8768\n","\n","Epoch 00218: val_accuracy did not improve from 0.92365\n","Epoch 219/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0418 - accuracy: 0.9872 - val_loss: 0.8202 - val_accuracy: 0.8227\n","\n","Epoch 00219: val_accuracy did not improve from 0.92365\n","Epoch 220/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0109 - accuracy: 0.9945 - val_loss: 1.1990 - val_accuracy: 0.7685\n","\n","Epoch 00220: val_accuracy did not improve from 0.92365\n","Epoch 221/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0154 - accuracy: 0.9933 - val_loss: 0.5755 - val_accuracy: 0.8719\n","\n","Epoch 00221: val_accuracy did not improve from 0.92365\n","Epoch 222/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0511 - accuracy: 0.9884 - val_loss: 0.7847 - val_accuracy: 0.8547\n","\n","Epoch 00222: val_accuracy did not improve from 0.92365\n","Epoch 223/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 0.6825 - val_accuracy: 0.8719\n","\n","Epoch 00223: val_accuracy did not improve from 0.92365\n","Epoch 224/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.4677 - val_accuracy: 0.9187\n","\n","Epoch 00224: val_accuracy did not improve from 0.92365\n","Epoch 225/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.3889 - val_accuracy: 0.9335\n","\n","Epoch 00225: val_accuracy improved from 0.92365 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 226/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4518 - val_accuracy: 0.9212\n","\n","Epoch 00226: val_accuracy did not improve from 0.93350\n","Epoch 227/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9261\n","\n","Epoch 00227: val_accuracy did not improve from 0.93350\n","Epoch 228/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.4174 - val_accuracy: 0.9089\n","\n","Epoch 00228: val_accuracy did not improve from 0.93350\n","Epoch 229/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.3972 - val_accuracy: 0.9089\n","\n","Epoch 00229: val_accuracy did not improve from 0.93350\n","Epoch 230/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.4892 - val_accuracy: 0.9163\n","\n","Epoch 00230: val_accuracy did not improve from 0.93350\n","Epoch 231/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.7842 - val_accuracy: 0.8768\n","\n","Epoch 00231: val_accuracy did not improve from 0.93350\n","Epoch 232/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.5184 - val_accuracy: 0.9113\n","\n","Epoch 00232: val_accuracy did not improve from 0.93350\n","Epoch 233/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.9212\n","\n","Epoch 00233: val_accuracy did not improve from 0.93350\n","Epoch 234/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 0.5604 - val_accuracy: 0.8966\n","\n","Epoch 00234: val_accuracy did not improve from 0.93350\n","Epoch 235/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 1.0302 - val_accuracy: 0.7906\n","\n","Epoch 00235: val_accuracy did not improve from 0.93350\n","Epoch 236/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.6056 - val_accuracy: 0.8768\n","\n","Epoch 00236: val_accuracy did not improve from 0.93350\n","Epoch 237/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4291 - val_accuracy: 0.9113\n","\n","Epoch 00237: val_accuracy did not improve from 0.93350\n","Epoch 238/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.6352 - val_accuracy: 0.8966\n","\n","Epoch 00238: val_accuracy did not improve from 0.93350\n","Epoch 239/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.5276 - val_accuracy: 0.9039\n","\n","Epoch 00239: val_accuracy did not improve from 0.93350\n","Epoch 240/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.5026 - val_accuracy: 0.8990\n","\n","Epoch 00240: val_accuracy did not improve from 0.93350\n","Epoch 241/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0536 - accuracy: 0.9872 - val_loss: 1.0493 - val_accuracy: 0.8030\n","\n","Epoch 00241: val_accuracy did not improve from 0.93350\n","Epoch 242/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0352 - accuracy: 0.9896 - val_loss: 1.0607 - val_accuracy: 0.7833\n","\n","Epoch 00242: val_accuracy did not improve from 0.93350\n","Epoch 243/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.5367 - val_accuracy: 0.8966\n","\n","Epoch 00243: val_accuracy did not improve from 0.93350\n","Epoch 244/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0117 - accuracy: 0.9951 - val_loss: 0.6461 - val_accuracy: 0.8793\n","\n","Epoch 00244: val_accuracy did not improve from 0.93350\n","Epoch 245/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.7337 - val_accuracy: 0.8473\n","\n","Epoch 00245: val_accuracy did not improve from 0.93350\n","Epoch 246/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.5617 - val_accuracy: 0.8768\n","\n","Epoch 00246: val_accuracy did not improve from 0.93350\n","Epoch 247/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0231 - accuracy: 0.9945 - val_loss: 0.8067 - val_accuracy: 0.8744\n","\n","Epoch 00247: val_accuracy did not improve from 0.93350\n","Epoch 248/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0359 - accuracy: 0.9878 - val_loss: 1.4616 - val_accuracy: 0.7340\n","\n","Epoch 00248: val_accuracy did not improve from 0.93350\n","Epoch 249/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.6886 - val_accuracy: 0.8892\n","\n","Epoch 00249: val_accuracy did not improve from 0.93350\n","Epoch 250/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0901 - accuracy: 0.9775 - val_loss: 1.3989 - val_accuracy: 0.8079\n","\n","Epoch 00250: val_accuracy did not improve from 0.93350\n","Epoch 251/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0614 - accuracy: 0.9775 - val_loss: 0.9548 - val_accuracy: 0.8103\n","\n","Epoch 00251: val_accuracy did not improve from 0.93350\n","Epoch 252/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0318 - accuracy: 0.9933 - val_loss: 0.5569 - val_accuracy: 0.8941\n","\n","Epoch 00252: val_accuracy did not improve from 0.93350\n","Epoch 253/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.5950 - val_accuracy: 0.9113\n","\n","Epoch 00253: val_accuracy did not improve from 0.93350\n","Epoch 254/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.4692 - val_accuracy: 0.9089\n","\n","Epoch 00254: val_accuracy did not improve from 0.93350\n","Epoch 255/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.5746 - val_accuracy: 0.9089\n","\n","Epoch 00255: val_accuracy did not improve from 0.93350\n","Epoch 256/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.5408 - val_accuracy: 0.8744\n","\n","Epoch 00256: val_accuracy did not improve from 0.93350\n","Epoch 257/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.3885 - val_accuracy: 0.9163\n","\n","Epoch 00257: val_accuracy did not improve from 0.93350\n","Epoch 258/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.3540 - val_accuracy: 0.9113\n","\n","Epoch 00258: val_accuracy did not improve from 0.93350\n","Epoch 259/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6549 - val_accuracy: 0.8744\n","\n","Epoch 00259: val_accuracy did not improve from 0.93350\n","Epoch 260/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9212\n","\n","Epoch 00260: val_accuracy did not improve from 0.93350\n","Epoch 261/500\n","52/52 [==============================] - 69s 1s/step - loss: 9.3618e-04 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.9335\n","\n","Epoch 00261: val_accuracy did not improve from 0.93350\n","Epoch 262/500\n","52/52 [==============================] - 68s 1s/step - loss: 5.7277e-04 - accuracy: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.9335\n","\n","Epoch 00262: val_accuracy did not improve from 0.93350\n","Epoch 263/500\n","52/52 [==============================] - 68s 1s/step - loss: 8.6984e-04 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 0.9360\n","\n","Epoch 00263: val_accuracy improved from 0.93350 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 264/500\n","52/52 [==============================] - 69s 1s/step - loss: 8.7737e-04 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.9261\n","\n","Epoch 00264: val_accuracy did not improve from 0.93596\n","Epoch 265/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4494 - val_accuracy: 0.9286\n","\n","Epoch 00265: val_accuracy did not improve from 0.93596\n","Epoch 266/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0256 - accuracy: 0.9957 - val_loss: 0.5161 - val_accuracy: 0.9064\n","\n","Epoch 00266: val_accuracy did not improve from 0.93596\n","Epoch 267/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.5674 - val_accuracy: 0.9089\n","\n","Epoch 00267: val_accuracy did not improve from 0.93596\n","Epoch 268/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5178 - val_accuracy: 0.9163\n","\n","Epoch 00268: val_accuracy did not improve from 0.93596\n","Epoch 269/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.9187\n","\n","Epoch 00269: val_accuracy did not improve from 0.93596\n","Epoch 270/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.9138\n","\n","Epoch 00270: val_accuracy did not improve from 0.93596\n","Epoch 271/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.9163\n","\n","Epoch 00271: val_accuracy did not improve from 0.93596\n","Epoch 272/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.9286\n","\n","Epoch 00272: val_accuracy did not improve from 0.93596\n","Epoch 273/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.9261\n","\n","Epoch 00273: val_accuracy did not improve from 0.93596\n","Epoch 274/500\n","52/52 [==============================] - 68s 1s/step - loss: 3.9155e-04 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.9310\n","\n","Epoch 00274: val_accuracy did not improve from 0.93596\n","Epoch 275/500\n","52/52 [==============================] - 69s 1s/step - loss: 7.9080e-04 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9236\n","\n","Epoch 00275: val_accuracy did not improve from 0.93596\n","Epoch 276/500\n","52/52 [==============================] - 69s 1s/step - loss: 6.0743e-04 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.9089\n","\n","Epoch 00276: val_accuracy did not improve from 0.93596\n","Epoch 277/500\n","52/52 [==============================] - 69s 1s/step - loss: 2.8605e-04 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.9310\n","\n","Epoch 00277: val_accuracy did not improve from 0.93596\n","Epoch 278/500\n","52/52 [==============================] - 68s 1s/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 0.4171 - val_accuracy: 0.9163\n","\n","Epoch 00278: val_accuracy did not improve from 0.93596\n","Epoch 279/500\n","52/52 [==============================] - 68s 1s/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.8520 - val_accuracy: 0.8153\n","\n","Epoch 00279: val_accuracy did not improve from 0.93596\n","Epoch 280/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.7856 - val_accuracy: 0.8522\n","\n","Epoch 00280: val_accuracy did not improve from 0.93596\n","Epoch 281/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.8182 - val_accuracy: 0.8374\n","\n","Epoch 00281: val_accuracy did not improve from 0.93596\n","Epoch 282/500\n","52/52 [==============================] - 68s 1s/step - loss: 0.0702 - accuracy: 0.9762 - val_loss: 1.1210 - val_accuracy: 0.8325\n","\n","Epoch 00282: val_accuracy did not improve from 0.93596\n","Epoch 283/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 0.8204 - val_accuracy: 0.8498\n","\n","Epoch 00283: val_accuracy did not improve from 0.93596\n","Epoch 284/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 0.6040 - val_accuracy: 0.8498\n","\n","Epoch 00284: val_accuracy did not improve from 0.93596\n","Epoch 285/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0266 - accuracy: 0.9939 - val_loss: 0.6601 - val_accuracy: 0.8744\n","\n","Epoch 00285: val_accuracy did not improve from 0.93596\n","Epoch 286/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.6660 - val_accuracy: 0.8768\n","\n","Epoch 00286: val_accuracy did not improve from 0.93596\n","Epoch 287/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.6534 - val_accuracy: 0.8719\n","\n","Epoch 00287: val_accuracy did not improve from 0.93596\n","Epoch 288/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.8344 - val_accuracy: 0.8424\n","\n","Epoch 00288: val_accuracy did not improve from 0.93596\n","Epoch 289/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 3.9341 - val_accuracy: 0.5517\n","\n","Epoch 00289: val_accuracy did not improve from 0.93596\n","Epoch 290/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0615 - accuracy: 0.9762 - val_loss: 0.7290 - val_accuracy: 0.8596\n","\n","Epoch 00290: val_accuracy did not improve from 0.93596\n","Epoch 291/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.8368 - val_accuracy: 0.8399\n","\n","Epoch 00291: val_accuracy did not improve from 0.93596\n","Epoch 292/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.7041 - val_accuracy: 0.8719\n","\n","Epoch 00292: val_accuracy did not improve from 0.93596\n","Epoch 293/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.4872 - val_accuracy: 0.8941\n","\n","Epoch 00293: val_accuracy did not improve from 0.93596\n","Epoch 294/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.6015 - val_accuracy: 0.9064\n","\n","Epoch 00294: val_accuracy did not improve from 0.93596\n","Epoch 295/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4088 - val_accuracy: 0.9113\n","\n","Epoch 00295: val_accuracy did not improve from 0.93596\n","Epoch 296/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4143 - val_accuracy: 0.9286\n","\n","Epoch 00296: val_accuracy did not improve from 0.93596\n","Epoch 297/500\n","52/52 [==============================] - 69s 1s/step - loss: 6.2589e-04 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 0.9310\n","\n","Epoch 00297: val_accuracy did not improve from 0.93596\n","Epoch 298/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.9261\n","\n","Epoch 00298: val_accuracy did not improve from 0.93596\n","Epoch 299/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.3802 - val_accuracy: 0.9310\n","\n","Epoch 00299: val_accuracy did not improve from 0.93596\n","Epoch 300/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.9113\n","\n","Epoch 00300: val_accuracy did not improve from 0.93596\n","Epoch 301/500\n","52/52 [==============================] - 69s 1s/step - loss: 6.4341e-04 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.9310\n","\n","Epoch 00301: val_accuracy did not improve from 0.93596\n","Epoch 302/500\n","52/52 [==============================] - 69s 1s/step - loss: 5.8281e-04 - accuracy: 1.0000 - val_loss: 0.4585 - val_accuracy: 0.9212\n","\n","Epoch 00302: val_accuracy did not improve from 0.93596\n","Epoch 303/500\n","52/52 [==============================] - 69s 1s/step - loss: 6.7393e-04 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9310\n","\n","Epoch 00303: val_accuracy did not improve from 0.93596\n","Epoch 304/500\n","52/52 [==============================] - 69s 1s/step - loss: 6.9076e-04 - accuracy: 0.9994 - val_loss: 0.4158 - val_accuracy: 0.9212\n","\n","Epoch 00304: val_accuracy did not improve from 0.93596\n","Epoch 305/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.4009 - val_accuracy: 0.9310\n","\n","Epoch 00305: val_accuracy did not improve from 0.93596\n","Epoch 306/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.9187\n","\n","Epoch 00306: val_accuracy did not improve from 0.93596\n","Epoch 307/500\n","52/52 [==============================] - 69s 1s/step - loss: 8.5724e-04 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.9236\n","\n","Epoch 00307: val_accuracy did not improve from 0.93596\n","Epoch 308/500\n","52/52 [==============================] - 69s 1s/step - loss: 7.9247e-04 - accuracy: 1.0000 - val_loss: 0.5708 - val_accuracy: 0.8818\n","\n","Epoch 00308: val_accuracy did not improve from 0.93596\n","Epoch 309/500\n","52/52 [==============================] - 69s 1s/step - loss: 3.0374e-04 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.9113\n","\n","Epoch 00309: val_accuracy did not improve from 0.93596\n","Epoch 310/500\n","52/52 [==============================] - 69s 1s/step - loss: 3.9577e-04 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.9310\n","\n","Epoch 00310: val_accuracy did not improve from 0.93596\n","Epoch 311/500\n","52/52 [==============================] - 69s 1s/step - loss: 4.2779e-04 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.9286\n","\n","Epoch 00311: val_accuracy did not improve from 0.93596\n","Epoch 312/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.5396 - val_accuracy: 0.9064\n","\n","Epoch 00312: val_accuracy did not improve from 0.93596\n","Epoch 313/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.7771 - val_accuracy: 0.8892\n","\n","Epoch 00313: val_accuracy did not improve from 0.93596\n","Epoch 314/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 1.7237 - val_accuracy: 0.7759\n","\n","Epoch 00314: val_accuracy did not improve from 0.93596\n","Epoch 315/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1455 - accuracy: 0.9647 - val_loss: 2.3302 - val_accuracy: 0.6823\n","\n","Epoch 00315: val_accuracy did not improve from 0.93596\n","Epoch 316/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1033 - accuracy: 0.9726 - val_loss: 2.2476 - val_accuracy: 0.6576\n","\n","Epoch 00316: val_accuracy did not improve from 0.93596\n","Epoch 317/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0307 - accuracy: 0.9884 - val_loss: 0.9329 - val_accuracy: 0.8202\n","\n","Epoch 00317: val_accuracy did not improve from 0.93596\n","Epoch 318/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0103 - accuracy: 0.9957 - val_loss: 0.8461 - val_accuracy: 0.8300\n","\n","Epoch 00318: val_accuracy did not improve from 0.93596\n","Epoch 319/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 1.0693 - val_accuracy: 0.7956\n","\n","Epoch 00319: val_accuracy did not improve from 0.93596\n","Epoch 320/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.6035 - val_accuracy: 0.8818\n","\n","Epoch 00320: val_accuracy did not improve from 0.93596\n","Epoch 321/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4833 - val_accuracy: 0.8916\n","\n","Epoch 00321: val_accuracy did not improve from 0.93596\n","Epoch 322/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 0.9064\n","\n","Epoch 00322: val_accuracy did not improve from 0.93596\n","Epoch 323/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.9138\n","\n","Epoch 00323: val_accuracy did not improve from 0.93596\n","Epoch 324/500\n","52/52 [==============================] - 69s 1s/step - loss: 9.6239e-04 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.9236\n","\n","Epoch 00324: val_accuracy did not improve from 0.93596\n","Epoch 325/500\n","52/52 [==============================] - 69s 1s/step - loss: 7.4073e-04 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9187\n","\n","Epoch 00325: val_accuracy did not improve from 0.93596\n","Epoch 326/500\n","52/52 [==============================] - 69s 1s/step - loss: 7.5059e-04 - accuracy: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.9261\n","\n","Epoch 00326: val_accuracy did not improve from 0.93596\n","Epoch 327/500\n","52/52 [==============================] - 69s 1s/step - loss: 5.5276e-04 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.9236\n","\n","Epoch 00327: val_accuracy did not improve from 0.93596\n","Epoch 328/500\n","52/52 [==============================] - 69s 1s/step - loss: 7.0842e-04 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.9212\n","\n","Epoch 00328: val_accuracy did not improve from 0.93596\n","Epoch 329/500\n","52/52 [==============================] - 69s 1s/step - loss: 6.9246e-04 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9212\n","\n","Epoch 00329: val_accuracy did not improve from 0.93596\n","Epoch 330/500\n","52/52 [==============================] - 69s 1s/step - loss: 4.2466e-04 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.9236\n","\n","Epoch 00330: val_accuracy did not improve from 0.93596\n","Epoch 331/500\n","52/52 [==============================] - 69s 1s/step - loss: 6.2140e-04 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9310\n","\n","Epoch 00331: val_accuracy did not improve from 0.93596\n","Epoch 332/500\n","52/52 [==============================] - 69s 1s/step - loss: 9.8973e-04 - accuracy: 1.0000 - val_loss: 0.5222 - val_accuracy: 0.9187\n","\n","Epoch 00332: val_accuracy did not improve from 0.93596\n","Epoch 333/500\n","52/52 [==============================] - 69s 1s/step - loss: 7.0225e-04 - accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.9261\n","\n","Epoch 00333: val_accuracy did not improve from 0.93596\n","Epoch 334/500\n","52/52 [==============================] - 69s 1s/step - loss: 3.1861e-04 - accuracy: 1.0000 - val_loss: 0.4508 - val_accuracy: 0.9187\n","\n","Epoch 00334: val_accuracy did not improve from 0.93596\n","Epoch 335/500\n","52/52 [==============================] - 69s 1s/step - loss: 5.9608e-04 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.9261\n","\n","Epoch 00335: val_accuracy did not improve from 0.93596\n","Epoch 336/500\n","52/52 [==============================] - 69s 1s/step - loss: 5.6194e-04 - accuracy: 1.0000 - val_loss: 0.5425 - val_accuracy: 0.9163\n","\n","Epoch 00336: val_accuracy did not improve from 0.93596\n","Epoch 337/500\n","52/52 [==============================] - 69s 1s/step - loss: 3.4330e-04 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.9310\n","\n","Epoch 00337: val_accuracy did not improve from 0.93596\n","Epoch 338/500\n","52/52 [==============================] - 69s 1s/step - loss: 2.5138e-04 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9187\n","\n","Epoch 00338: val_accuracy did not improve from 0.93596\n","Epoch 339/500\n","52/52 [==============================] - 69s 1s/step - loss: 4.1931e-04 - accuracy: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.9212\n","\n","Epoch 00339: val_accuracy did not improve from 0.93596\n","Epoch 340/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5354 - val_accuracy: 0.9163\n","\n","Epoch 00340: val_accuracy did not improve from 0.93596\n","Epoch 341/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4261 - val_accuracy: 0.9187\n","\n","Epoch 00341: val_accuracy did not improve from 0.93596\n","Epoch 342/500\n","52/52 [==============================] - 69s 1s/step - loss: 7.4016e-04 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9138\n","\n","Epoch 00342: val_accuracy did not improve from 0.93596\n","Epoch 343/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.6477 - val_accuracy: 0.8818\n","\n","Epoch 00343: val_accuracy did not improve from 0.93596\n","Epoch 344/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.6431 - val_accuracy: 0.8399\n","\n","Epoch 00344: val_accuracy did not improve from 0.93596\n","Epoch 345/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.6944 - val_accuracy: 0.8842\n","\n","Epoch 00345: val_accuracy did not improve from 0.93596\n","Epoch 346/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.6777 - val_accuracy: 0.8818\n","\n","Epoch 00346: val_accuracy did not improve from 0.93596\n","Epoch 347/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.9337 - val_accuracy: 0.8177\n","\n","Epoch 00347: val_accuracy did not improve from 0.93596\n","Epoch 348/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0343 - accuracy: 0.9890 - val_loss: 5.2699 - val_accuracy: 0.4360\n","\n","Epoch 00348: val_accuracy did not improve from 0.93596\n","Epoch 349/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1289 - accuracy: 0.9610 - val_loss: 1.6881 - val_accuracy: 0.8251\n","\n","Epoch 00349: val_accuracy did not improve from 0.93596\n","Epoch 350/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0541 - accuracy: 0.9805 - val_loss: 1.0872 - val_accuracy: 0.8227\n","\n","Epoch 00350: val_accuracy did not improve from 0.93596\n","Epoch 351/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0362 - accuracy: 0.9903 - val_loss: 0.9940 - val_accuracy: 0.8448\n","\n","Epoch 00351: val_accuracy did not improve from 0.93596\n","Epoch 352/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0233 - accuracy: 0.9939 - val_loss: 0.7042 - val_accuracy: 0.8596\n","\n","Epoch 00352: val_accuracy did not improve from 0.93596\n","Epoch 353/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.6107 - val_accuracy: 0.8842\n","\n","Epoch 00353: val_accuracy did not improve from 0.93596\n","Epoch 354/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.4879 - val_accuracy: 0.8966\n","\n","Epoch 00354: val_accuracy did not improve from 0.93596\n","Epoch 355/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4464 - val_accuracy: 0.9163\n","\n","Epoch 00355: val_accuracy did not improve from 0.93596\n","Epoch 356/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.8683 - val_accuracy: 0.8300\n","\n","Epoch 00356: val_accuracy did not improve from 0.93596\n","Epoch 357/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.5573 - val_accuracy: 0.8892\n","\n","Epoch 00357: val_accuracy did not improve from 0.93596\n","Epoch 358/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0507 - accuracy: 0.9872 - val_loss: 0.5637 - val_accuracy: 0.8966\n","\n","Epoch 00358: val_accuracy did not improve from 0.93596\n","Epoch 359/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.6542 - val_accuracy: 0.8941\n","\n","Epoch 00359: val_accuracy did not improve from 0.93596\n","Epoch 360/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.4801 - val_accuracy: 0.8941\n","\n","Epoch 00360: val_accuracy did not improve from 0.93596\n","Epoch 361/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.8941\n","\n","Epoch 00361: val_accuracy did not improve from 0.93596\n","Epoch 362/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.8916\n","\n","Epoch 00362: val_accuracy did not improve from 0.93596\n","Epoch 363/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.8966\n","\n","Epoch 00363: val_accuracy did not improve from 0.93596\n","Epoch 364/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4167 - val_accuracy: 0.8966\n","\n","Epoch 00364: val_accuracy did not improve from 0.93596\n","Epoch 365/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5574 - val_accuracy: 0.9064\n","\n","Epoch 00365: val_accuracy did not improve from 0.93596\n","Epoch 366/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4522 - val_accuracy: 0.9138\n","\n","Epoch 00366: val_accuracy did not improve from 0.93596\n","Epoch 367/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.3714 - val_accuracy: 0.9310\n","\n","Epoch 00367: val_accuracy did not improve from 0.93596\n","Epoch 368/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5175 - val_accuracy: 0.9113\n","\n","Epoch 00368: val_accuracy did not improve from 0.93596\n","Epoch 369/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5370 - val_accuracy: 0.8892\n","\n","Epoch 00369: val_accuracy did not improve from 0.93596\n","Epoch 370/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5027 - val_accuracy: 0.9163\n","\n","Epoch 00370: val_accuracy did not improve from 0.93596\n","Epoch 371/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5397 - val_accuracy: 0.9064\n","\n","Epoch 00371: val_accuracy did not improve from 0.93596\n","Epoch 372/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.5286 - val_accuracy: 0.9015\n","\n","Epoch 00372: val_accuracy did not improve from 0.93596\n","Epoch 373/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.6114 - val_accuracy: 0.8892\n","\n","Epoch 00373: val_accuracy did not improve from 0.93596\n","Epoch 374/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4710 - val_accuracy: 0.9212\n","\n","Epoch 00374: val_accuracy did not improve from 0.93596\n","Epoch 375/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.6277 - val_accuracy: 0.8719\n","\n","Epoch 00375: val_accuracy did not improve from 0.93596\n","Epoch 376/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5526 - val_accuracy: 0.8719\n","\n","Epoch 00376: val_accuracy did not improve from 0.93596\n","Epoch 377/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.6316 - val_accuracy: 0.8768\n","\n","Epoch 00377: val_accuracy did not improve from 0.93596\n","Epoch 378/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.9795 - val_accuracy: 0.8276\n","\n","Epoch 00378: val_accuracy did not improve from 0.93596\n","Epoch 379/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.5642 - val_accuracy: 0.8916\n","\n","Epoch 00379: val_accuracy did not improve from 0.93596\n","Epoch 380/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0129 - accuracy: 0.9982 - val_loss: 0.6135 - val_accuracy: 0.8621\n","\n","Epoch 00380: val_accuracy did not improve from 0.93596\n","Epoch 381/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.6384 - val_accuracy: 0.8818\n","\n","Epoch 00381: val_accuracy did not improve from 0.93596\n","Epoch 382/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.4489 - val_accuracy: 0.8966\n","\n","Epoch 00382: val_accuracy did not improve from 0.93596\n","Epoch 383/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.5511 - val_accuracy: 0.8867\n","\n","Epoch 00383: val_accuracy did not improve from 0.93596\n","Epoch 384/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.5442 - val_accuracy: 0.9113\n","\n","Epoch 00384: val_accuracy did not improve from 0.93596\n","Epoch 385/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.6366 - val_accuracy: 0.8793\n","\n","Epoch 00385: val_accuracy did not improve from 0.93596\n","Epoch 386/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.7017 - val_accuracy: 0.8719\n","\n","Epoch 00386: val_accuracy did not improve from 0.93596\n","Epoch 387/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.5690 - val_accuracy: 0.8941\n","\n","Epoch 00387: val_accuracy did not improve from 0.93596\n","Epoch 388/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.6167 - val_accuracy: 0.8916\n","\n","Epoch 00388: val_accuracy did not improve from 0.93596\n","Epoch 389/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 0.8867\n","\n","Epoch 00389: val_accuracy did not improve from 0.93596\n","Epoch 390/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0217 - accuracy: 0.9945 - val_loss: 0.7528 - val_accuracy: 0.8768\n","\n","Epoch 00390: val_accuracy did not improve from 0.93596\n","Epoch 391/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.6424 - val_accuracy: 0.8818\n","\n","Epoch 00391: val_accuracy did not improve from 0.93596\n","Epoch 392/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.6608 - val_accuracy: 0.8892\n","\n","Epoch 00392: val_accuracy did not improve from 0.93596\n","Epoch 393/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.6811 - val_accuracy: 0.8892\n","\n","Epoch 00393: val_accuracy did not improve from 0.93596\n","Epoch 394/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 1.2317 - val_accuracy: 0.7906\n","\n","Epoch 00394: val_accuracy did not improve from 0.93596\n","Epoch 395/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.8880 - val_accuracy: 0.8251\n","\n","Epoch 00395: val_accuracy did not improve from 0.93596\n","Epoch 396/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.5300 - val_accuracy: 0.9236\n","\n","Epoch 00396: val_accuracy did not improve from 0.93596\n","Epoch 397/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.6425 - val_accuracy: 0.8916\n","\n","Epoch 00397: val_accuracy did not improve from 0.93596\n","Epoch 398/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.6759 - val_accuracy: 0.8966\n","\n","Epoch 00398: val_accuracy did not improve from 0.93596\n","Epoch 399/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 0.6857 - val_accuracy: 0.8818\n","\n","Epoch 00399: val_accuracy did not improve from 0.93596\n","Epoch 400/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 1.0536 - val_accuracy: 0.8079\n","\n","Epoch 00400: val_accuracy did not improve from 0.93596\n","Epoch 401/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.5370 - val_accuracy: 0.8818\n","\n","Epoch 00401: val_accuracy did not improve from 0.93596\n","Epoch 402/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 0.6889 - val_accuracy: 0.8670\n","\n","Epoch 00402: val_accuracy did not improve from 0.93596\n","Epoch 403/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.9089\n","\n","Epoch 00403: val_accuracy did not improve from 0.93596\n","Epoch 404/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5001 - val_accuracy: 0.8916\n","\n","Epoch 00404: val_accuracy did not improve from 0.93596\n","Epoch 405/500\n","52/52 [==============================] - 69s 1s/step - loss: 7.2522e-04 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.9163\n","\n","Epoch 00405: val_accuracy did not improve from 0.93596\n","Epoch 406/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4428 - val_accuracy: 0.9187\n","\n","Epoch 00406: val_accuracy did not improve from 0.93596\n","Epoch 407/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4728 - val_accuracy: 0.9212\n","\n","Epoch 00407: val_accuracy did not improve from 0.93596\n","Epoch 408/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5048 - val_accuracy: 0.9039\n","\n","Epoch 00408: val_accuracy did not improve from 0.93596\n","Epoch 409/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.7167 - val_accuracy: 0.9089\n","\n","Epoch 00409: val_accuracy did not improve from 0.93596\n","Epoch 410/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.5257 - val_accuracy: 0.9113\n","\n","Epoch 00410: val_accuracy did not improve from 0.93596\n","Epoch 411/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4077 - val_accuracy: 0.9212\n","\n","Epoch 00411: val_accuracy did not improve from 0.93596\n","Epoch 412/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.9335\n","\n","Epoch 00412: val_accuracy did not improve from 0.93596\n","Epoch 413/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4858 - val_accuracy: 0.9089\n","\n","Epoch 00413: val_accuracy did not improve from 0.93596\n","Epoch 414/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.6744 - val_accuracy: 0.8374\n","\n","Epoch 00414: val_accuracy did not improve from 0.93596\n","Epoch 415/500\n","52/52 [==============================] - 69s 1s/step - loss: 9.7431e-04 - accuracy: 1.0000 - val_loss: 0.5594 - val_accuracy: 0.8768\n","\n","Epoch 00415: val_accuracy did not improve from 0.93596\n","Epoch 416/500\n","52/52 [==============================] - 69s 1s/step - loss: 7.9005e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9261\n","\n","Epoch 00416: val_accuracy did not improve from 0.93596\n","Epoch 417/500\n","52/52 [==============================] - 69s 1s/step - loss: 9.4664e-04 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.9163\n","\n","Epoch 00417: val_accuracy did not improve from 0.93596\n","Epoch 418/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.5480 - val_accuracy: 0.9163\n","\n","Epoch 00418: val_accuracy did not improve from 0.93596\n","Epoch 419/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5204 - val_accuracy: 0.9039\n","\n","Epoch 00419: val_accuracy did not improve from 0.93596\n","Epoch 420/500\n","52/52 [==============================] - 69s 1s/step - loss: 6.2088e-04 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9384\n","\n","Epoch 00420: val_accuracy improved from 0.93596 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 421/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9310\n","\n","Epoch 00421: val_accuracy did not improve from 0.93842\n","Epoch 422/500\n","52/52 [==============================] - 69s 1s/step - loss: 5.8289e-04 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.9236\n","\n","Epoch 00422: val_accuracy did not improve from 0.93842\n","Epoch 423/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.4340 - val_accuracy: 0.9138\n","\n","Epoch 00423: val_accuracy did not improve from 0.93842\n","Epoch 424/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 1.3498 - val_accuracy: 0.7685\n","\n","Epoch 00424: val_accuracy did not improve from 0.93842\n","Epoch 425/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0810 - accuracy: 0.9793 - val_loss: 1.5173 - val_accuracy: 0.7635\n","\n","Epoch 00425: val_accuracy did not improve from 0.93842\n","Epoch 426/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0675 - accuracy: 0.9848 - val_loss: 1.4124 - val_accuracy: 0.7709\n","\n","Epoch 00426: val_accuracy did not improve from 0.93842\n","Epoch 427/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0558 - accuracy: 0.9866 - val_loss: 1.2030 - val_accuracy: 0.8054\n","\n","Epoch 00427: val_accuracy did not improve from 0.93842\n","Epoch 428/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0676 - accuracy: 0.9829 - val_loss: 0.5896 - val_accuracy: 0.8670\n","\n","Epoch 00428: val_accuracy did not improve from 0.93842\n","Epoch 429/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.5784 - val_accuracy: 0.8793\n","\n","Epoch 00429: val_accuracy did not improve from 0.93842\n","Epoch 430/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.4761 - val_accuracy: 0.8990\n","\n","Epoch 00430: val_accuracy did not improve from 0.93842\n","Epoch 431/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9138\n","\n","Epoch 00431: val_accuracy did not improve from 0.93842\n","Epoch 432/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.9163\n","\n","Epoch 00432: val_accuracy did not improve from 0.93842\n","Epoch 433/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 0.9261\n","\n","Epoch 00433: val_accuracy did not improve from 0.93842\n","Epoch 434/500\n","52/52 [==============================] - 69s 1s/step - loss: 5.3881e-04 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9236\n","\n","Epoch 00434: val_accuracy did not improve from 0.93842\n","Epoch 435/500\n","52/52 [==============================] - 69s 1s/step - loss: 5.7498e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9286\n","\n","Epoch 00435: val_accuracy did not improve from 0.93842\n","Epoch 436/500\n","52/52 [==============================] - 69s 1s/step - loss: 7.1610e-04 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.9261\n","\n","Epoch 00436: val_accuracy did not improve from 0.93842\n","Epoch 437/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.8072 - val_accuracy: 0.8621\n","\n","Epoch 00437: val_accuracy did not improve from 0.93842\n","Epoch 438/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0608 - accuracy: 0.9829 - val_loss: 0.7782 - val_accuracy: 0.8645\n","\n","Epoch 00438: val_accuracy did not improve from 0.93842\n","Epoch 439/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.5140 - val_accuracy: 0.9015\n","\n","Epoch 00439: val_accuracy did not improve from 0.93842\n","Epoch 440/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0347 - accuracy: 0.9866 - val_loss: 0.6773 - val_accuracy: 0.8547\n","\n","Epoch 00440: val_accuracy did not improve from 0.93842\n","Epoch 441/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.5737 - val_accuracy: 0.9089\n","\n","Epoch 00441: val_accuracy did not improve from 0.93842\n","Epoch 442/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.5733 - val_accuracy: 0.9039\n","\n","Epoch 00442: val_accuracy did not improve from 0.93842\n","Epoch 443/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5497 - val_accuracy: 0.9064\n","\n","Epoch 00443: val_accuracy did not improve from 0.93842\n","Epoch 444/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5369 - val_accuracy: 0.9039\n","\n","Epoch 00444: val_accuracy did not improve from 0.93842\n","Epoch 445/500\n","52/52 [==============================] - 69s 1s/step - loss: 9.2612e-04 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.9113\n","\n","Epoch 00445: val_accuracy did not improve from 0.93842\n","Epoch 446/500\n","52/52 [==============================] - 69s 1s/step - loss: 9.1280e-04 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.9163\n","\n","Epoch 00446: val_accuracy did not improve from 0.93842\n","Epoch 447/500\n","52/52 [==============================] - 69s 1s/step - loss: 8.4703e-04 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9236\n","\n","Epoch 00447: val_accuracy did not improve from 0.93842\n","Epoch 448/500\n","52/52 [==============================] - 70s 1s/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.5264 - val_accuracy: 0.9113\n","\n","Epoch 00448: val_accuracy did not improve from 0.93842\n","Epoch 449/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4351 - val_accuracy: 0.9236\n","\n","Epoch 00449: val_accuracy did not improve from 0.93842\n","Epoch 450/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4104 - val_accuracy: 0.9261\n","\n","Epoch 00450: val_accuracy did not improve from 0.93842\n","Epoch 451/500\n","52/52 [==============================] - 69s 1s/step - loss: 3.5752e-04 - accuracy: 1.0000 - val_loss: 0.4161 - val_accuracy: 0.9236\n","\n","Epoch 00451: val_accuracy did not improve from 0.93842\n","Epoch 452/500\n","52/52 [==============================] - 69s 1s/step - loss: 7.5360e-04 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.9335\n","\n","Epoch 00452: val_accuracy did not improve from 0.93842\n","Epoch 453/500\n","52/52 [==============================] - 69s 1s/step - loss: 8.8057e-04 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.9360\n","\n","Epoch 00453: val_accuracy did not improve from 0.93842\n","Epoch 454/500\n","52/52 [==============================] - 69s 1s/step - loss: 7.0463e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9236\n","\n","Epoch 00454: val_accuracy did not improve from 0.93842\n","Epoch 455/500\n","52/52 [==============================] - 69s 1s/step - loss: 3.7361e-04 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.9163\n","\n","Epoch 00455: val_accuracy did not improve from 0.93842\n","Epoch 456/500\n","52/52 [==============================] - 68s 1s/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4179 - val_accuracy: 0.9261\n","\n","Epoch 00456: val_accuracy did not improve from 0.93842\n","Epoch 457/500\n","52/52 [==============================] - 69s 1s/step - loss: 6.3742e-04 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9138\n","\n","Epoch 00457: val_accuracy did not improve from 0.93842\n","Epoch 458/500\n","52/52 [==============================] - 69s 1s/step - loss: 4.6916e-04 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 0.9286\n","\n","Epoch 00458: val_accuracy did not improve from 0.93842\n","Epoch 459/500\n","52/52 [==============================] - 69s 1s/step - loss: 5.9388e-04 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.9236\n","\n","Epoch 00459: val_accuracy did not improve from 0.93842\n","Epoch 460/500\n","52/52 [==============================] - 69s 1s/step - loss: 6.9426e-04 - accuracy: 1.0000 - val_loss: 0.3977 - val_accuracy: 0.9138\n","\n","Epoch 00460: val_accuracy did not improve from 0.93842\n","Epoch 461/500\n","52/52 [==============================] - 69s 1s/step - loss: 6.7572e-04 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.9261\n","\n","Epoch 00461: val_accuracy did not improve from 0.93842\n","Epoch 462/500\n","52/52 [==============================] - 69s 1s/step - loss: 2.8843e-04 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9261\n","\n","Epoch 00462: val_accuracy did not improve from 0.93842\n","Epoch 463/500\n","52/52 [==============================] - 69s 1s/step - loss: 2.7689e-04 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9286\n","\n","Epoch 00463: val_accuracy did not improve from 0.93842\n","Epoch 464/500\n","52/52 [==============================] - 69s 1s/step - loss: 1.8647e-04 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.9286\n","\n","Epoch 00464: val_accuracy did not improve from 0.93842\n","Epoch 465/500\n","52/52 [==============================] - 69s 1s/step - loss: 2.6849e-04 - accuracy: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.9335\n","\n","Epoch 00465: val_accuracy did not improve from 0.93842\n","Epoch 466/500\n","52/52 [==============================] - 69s 1s/step - loss: 1.4589e-04 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.9310\n","\n","Epoch 00466: val_accuracy did not improve from 0.93842\n","Epoch 467/500\n","52/52 [==============================] - 70s 1s/step - loss: 1.6878e-04 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.9286\n","\n","Epoch 00467: val_accuracy did not improve from 0.93842\n","Epoch 468/500\n","52/52 [==============================] - 69s 1s/step - loss: 1.1783e-04 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.9286\n","\n","Epoch 00468: val_accuracy did not improve from 0.93842\n","Epoch 469/500\n","52/52 [==============================] - 69s 1s/step - loss: 3.9516e-04 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.9335\n","\n","Epoch 00469: val_accuracy did not improve from 0.93842\n","Epoch 470/500\n","52/52 [==============================] - 69s 1s/step - loss: 1.9444e-04 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.9384\n","\n","Epoch 00470: val_accuracy did not improve from 0.93842\n","Epoch 471/500\n","52/52 [==============================] - 69s 1s/step - loss: 2.0918e-04 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.9360\n","\n","Epoch 00471: val_accuracy did not improve from 0.93842\n","Epoch 472/500\n","52/52 [==============================] - 69s 1s/step - loss: 1.5185e-04 - accuracy: 1.0000 - val_loss: 0.4153 - val_accuracy: 0.9409\n","\n","Epoch 00472: val_accuracy improved from 0.93842 to 0.94089, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5\n","Epoch 473/500\n","52/52 [==============================] - 69s 1s/step - loss: 1.1377e-04 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9335\n","\n","Epoch 00473: val_accuracy did not improve from 0.94089\n","Epoch 474/500\n","52/52 [==============================] - 69s 1s/step - loss: 1.0420e-04 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.9384\n","\n","Epoch 00474: val_accuracy did not improve from 0.94089\n","Epoch 475/500\n","52/52 [==============================] - 69s 1s/step - loss: 1.0976e-04 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9310\n","\n","Epoch 00475: val_accuracy did not improve from 0.94089\n","Epoch 476/500\n","52/52 [==============================] - 69s 1s/step - loss: 6.8272e-04 - accuracy: 0.9994 - val_loss: 0.4317 - val_accuracy: 0.9236\n","\n","Epoch 00476: val_accuracy did not improve from 0.94089\n","Epoch 477/500\n","52/52 [==============================] - 69s 1s/step - loss: 5.5903e-04 - accuracy: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.9163\n","\n","Epoch 00477: val_accuracy did not improve from 0.94089\n","Epoch 478/500\n","52/52 [==============================] - 69s 1s/step - loss: 7.3319e-04 - accuracy: 0.9994 - val_loss: 0.4075 - val_accuracy: 0.9261\n","\n","Epoch 00478: val_accuracy did not improve from 0.94089\n","Epoch 479/500\n","52/52 [==============================] - 69s 1s/step - loss: 4.3148e-04 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.9089\n","\n","Epoch 00479: val_accuracy did not improve from 0.94089\n","Epoch 480/500\n","52/52 [==============================] - 69s 1s/step - loss: 2.4154e-04 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.9236\n","\n","Epoch 00480: val_accuracy did not improve from 0.94089\n","Epoch 481/500\n","52/52 [==============================] - 69s 1s/step - loss: 2.4057e-04 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.9236\n","\n","Epoch 00481: val_accuracy did not improve from 0.94089\n","Epoch 482/500\n","52/52 [==============================] - 69s 1s/step - loss: 1.6300e-04 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9236\n","\n","Epoch 00482: val_accuracy did not improve from 0.94089\n","Epoch 483/500\n","52/52 [==============================] - 69s 1s/step - loss: 9.6254e-05 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.9212\n","\n","Epoch 00483: val_accuracy did not improve from 0.94089\n","Epoch 484/500\n","52/52 [==============================] - 69s 1s/step - loss: 3.2652e-04 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.9286\n","\n","Epoch 00484: val_accuracy did not improve from 0.94089\n","Epoch 485/500\n","52/52 [==============================] - 69s 1s/step - loss: 5.0758e-04 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.9335\n","\n","Epoch 00485: val_accuracy did not improve from 0.94089\n","Epoch 486/500\n","52/52 [==============================] - 69s 1s/step - loss: 2.2114e-04 - accuracy: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.9310\n","\n","Epoch 00486: val_accuracy did not improve from 0.94089\n","Epoch 487/500\n","52/52 [==============================] - 69s 1s/step - loss: 4.2967e-04 - accuracy: 1.0000 - val_loss: 0.4551 - val_accuracy: 0.9286\n","\n","Epoch 00487: val_accuracy did not improve from 0.94089\n","Epoch 488/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.8765 - val_accuracy: 0.8695\n","\n","Epoch 00488: val_accuracy did not improve from 0.94089\n","Epoch 489/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0672 - accuracy: 0.9829 - val_loss: 1.4675 - val_accuracy: 0.8153\n","\n","Epoch 00489: val_accuracy did not improve from 0.94089\n","Epoch 490/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.1152 - accuracy: 0.9635 - val_loss: 1.6079 - val_accuracy: 0.8005\n","\n","Epoch 00490: val_accuracy did not improve from 0.94089\n","Epoch 491/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0661 - accuracy: 0.9811 - val_loss: 1.0102 - val_accuracy: 0.8350\n","\n","Epoch 00491: val_accuracy did not improve from 0.94089\n","Epoch 492/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 1.4039 - val_accuracy: 0.7463\n","\n","Epoch 00492: val_accuracy did not improve from 0.94089\n","Epoch 493/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 1.1746 - val_accuracy: 0.7635\n","\n","Epoch 00493: val_accuracy did not improve from 0.94089\n","Epoch 494/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.8744\n","\n","Epoch 00494: val_accuracy did not improve from 0.94089\n","Epoch 495/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.9138\n","\n","Epoch 00495: val_accuracy did not improve from 0.94089\n","Epoch 496/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0026 - accuracy: 0.9982 - val_loss: 0.4263 - val_accuracy: 0.9064\n","\n","Epoch 00496: val_accuracy did not improve from 0.94089\n","Epoch 497/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4226 - val_accuracy: 0.9187\n","\n","Epoch 00497: val_accuracy did not improve from 0.94089\n","Epoch 498/500\n","52/52 [==============================] - 70s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.9187\n","\n","Epoch 00498: val_accuracy did not improve from 0.94089\n","Epoch 499/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.9236\n","\n","Epoch 00499: val_accuracy did not improve from 0.94089\n","Epoch 500/500\n","52/52 [==============================] - 69s 1s/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5354 - val_accuracy: 0.8645\n","\n","Epoch 00500: val_accuracy did not improve from 0.94089\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f179a971ad0>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1631304836866,"user_tz":-540,"elapsed":35,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"07551da4-7d27-4cb9-811e-10d9a2a4d3ee"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1631304873866,"user_tz":-540,"elapsed":37023,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_2_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1631304874530,"user_tz":-540,"elapsed":676,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631304874922,"user_tz":-540,"elapsed":396,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d3ed6e4f-5666-42ee-9288-869d210c2988"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(299,299), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631305099063,"user_tz":-540,"elapsed":224145,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"95186ccc-0fab-42d9-c649-747a7b8ec7f6"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1631305099597,"user_tz":-540,"elapsed":552,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1631305099598,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1631305101080,"user_tz":-540,"elapsed":1486,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1631305101081,"user_tz":-540,"elapsed":4,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1631305117188,"user_tz":-540,"elapsed":16110,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1631305117191,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"21a09bed-050e-4a00-d92a-47cf569ab9f4"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1631305117703,"user_tz":-540,"elapsed":521,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"89fbca2e-f587-4c96-ba9a-c3bf69c6bbc1"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_299_2_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_299_2_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_65eaad61-4f9a-44cb-b298-322cd25e9fb6\", \"ImageSize_299_2_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}