{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"InceptionV3_1_(public-, private-).ipynb","provenance":[{"file_id":"1M_c2tK-OSq0Sf0EkgPYrIVj_UFxyDhLa","timestamp":1632722288709},{"file_id":"1Ks4BnsIQVSo6nrDm_GCFLP-tUWbMF7fV","timestamp":1632675649149},{"file_id":"1CqtLKNQRRuC325QEoXZHskfQDXw-hybx","timestamp":1632675617704},{"file_id":"12JaYWavZfXc3mxowUEN1hmoDHEhLE9kD","timestamp":1632669857913},{"file_id":"1mRQmgFDcxuga37ytSbeksdBDV8lXPuP_","timestamp":1632669810228},{"file_id":"1hSseuq321IM3Xw9iARWzPOzaWFGuSYps","timestamp":1632659933103},{"file_id":"1i84kOIoNMg1SDAOmCAl-iREVAA8REpRl","timestamp":1632659111522},{"file_id":"1aWKemyOVH_XXsufg6PEqpNJHCIODEQDQ","timestamp":1632658287256},{"file_id":"1ZUL9g9uU5gE9mjrGyZ_ZE6_ZMwE69CPb","timestamp":1632657078244},{"file_id":"1Xq9yUa0JgnqQUKKTfy3z54fip8tHOUVO","timestamp":1632649657584},{"file_id":"1g107jAyKQClzEQj_DMR2xU4rZ9qbJH5e","timestamp":1632649536640},{"file_id":"1Z6kuupfDyi8FoEAzxFaCF1zxYVFMOZLV","timestamp":1632555432723},{"file_id":"1EbR-z2BYoOKWzYoeQoCF6HChJXoczWOg","timestamp":1632529654720},{"file_id":"19UhJoIWtCbGyO-f3O4Ejh3cQm9HsELdp","timestamp":1632508748323},{"file_id":"1P94NU6OoLRtS_ewl8Rb7NPZqKyl6ScPt","timestamp":1632508239637},{"file_id":"1oYHEjU-CSdxlLxyB6mhRRnSPmxfEbe9-","timestamp":1632483693856},{"file_id":"1tY8RF_0awL36zd9hQqUN3JK-9i7JjSCs","timestamp":1632483672985},{"file_id":"1hfaa8YJTlfEKZL9us0XaxbDFzEg6QlrT","timestamp":1632483587193},{"file_id":"1ar0JVhm118hpsiDCU0yS0Ty83Lr95cSu","timestamp":1632438063611},{"file_id":"1ISSiU2DrdSTDMVmbAxc8Ql72Bwult8wi","timestamp":1632382754243},{"file_id":"1cmBIBf0Y6KY5nFGyXFWuz9pe-V3QXe84","timestamp":1632382703200},{"file_id":"1NmDQbVBw3bmj4dkYxCWjOgHGEPxn2knZ","timestamp":1632382649241},{"file_id":"1h-FhrHH66IwjTlqiffpUdtWJZ47_06LZ","timestamp":1632332735991},{"file_id":"174isfXxsoXsuFjV-4wlPn8FyvhQelSZa","timestamp":1632264352072},{"file_id":"1rvvO3AZYRa3O0L25N-Kx2tXg3SO3ZLMb","timestamp":1632207962186},{"file_id":"10a77ENeqwaxgwFA_yCVpQBXkA9Fdts6t","timestamp":1632177040567},{"file_id":"1FLQ4OWmjzgDT_6nR4k61mlxJ0RbQfLbW","timestamp":1632127337902},{"file_id":"1L21WYacshipXDSgj75p87xRajwZ-yYEf","timestamp":1632125266824},{"file_id":"1gXw-oagzF1c49Ds2rFNXBNA-Jjj0YTGM","timestamp":1632125231955},{"file_id":"1odc6VzTolz3PuXSezCpAr8zqRhjlzJFc","timestamp":1632032770915},{"file_id":"1MLPQlf1Ig6rev94yP2Zy_hjHPEwnJWKr","timestamp":1631962707157},{"file_id":"1RFXq_y4na26GX1TMhOCKZvjIKxWZgQei","timestamp":1631894145495},{"file_id":"1j4_hnK2KjlLPPPkDR5LUdjrgcl7E5VJ2","timestamp":1631892272403},{"file_id":"1p_d4XYROzKVVUxBHxjuVx1gTinsguwp8","timestamp":1631892211512},{"file_id":"1qviqzhy3AgjpFc3P2QLjjqfHnbk3izT5","timestamp":1631892086873},{"file_id":"1rE8G1jItkQTqd3bvVGDHTrM9ONajBm2k","timestamp":1631891790249},{"file_id":"https://github.com/d9249/DACON/blob/main/CVLC_05_No_Data_Argmentation(public_0_81862_private_0_76593).ipynb","timestamp":1627056180265}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g0yI4jO4W5lx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632737216292,"user_tz":-540,"elapsed":775,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"26265415-5534-45be-d009-478bf4c31150"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Sep 27 10:06:59 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632737239750,"user_tz":-540,"elapsed":23463,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ef1eb57b-9839-4502-d524-fe09f21f129d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1632737246701,"user_tz":-540,"elapsed":6959,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1632737247825,"user_tz":-540,"elapsed":1128,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1632737250024,"user_tz":-540,"elapsed":2202,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1632737266891,"user_tz":-540,"elapsed":16870,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTkw3fo6icZm","executionInfo":{"status":"ok","timestamp":1632737266898,"user_tz":-540,"elapsed":15,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["model_save = 'InceptionV3_1'\n","Target_model = 'InceptionV3_model'\n","Target_predict = 'InceptionV3_predict'\n","Target_acc = 'InceptionV3_acc'\n","Target_val = 'InceptionV3_val'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1632737273467,"user_tz":-540,"elapsed":6582,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","Target_model =  tf.keras.applications.InceptionV3(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","executionInfo":{"status":"ok","timestamp":1632737273467,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632737273468,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"99bc27eb-a6a2-4fbf-abe3-24591a58e93e"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator (\n","    rescale = 1./255, \n","    validation_split = 0.075,\n","    rotation_range = 15,\n","    width_shift_range = 0.00,\n","    height_shift_range = 0.05 )\n","\n","batch_size = 8\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1900 images belonging to 10 classes.\n","Found 148 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1632737273469,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632745705827,"user_tz":-540,"elapsed":8432364,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"82f06504-b226-436d-f7ba-bf1f6888f9f8"},"source":["Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","238/238 [==============================] - 40s 72ms/step - loss: 2.1607 - accuracy: 0.2779 - val_loss: 5.3383 - val_accuracy: 0.0946\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_1.h5\n","Epoch 2/500\n","238/238 [==============================] - 16s 68ms/step - loss: 1.2967 - accuracy: 0.5716 - val_loss: 6.6153 - val_accuracy: 0.1149\n","\n","Epoch 00002: val_accuracy improved from 0.09459 to 0.11486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_1.h5\n","Epoch 3/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.9714 - accuracy: 0.6963 - val_loss: 0.7238 - val_accuracy: 0.7230\n","\n","Epoch 00003: val_accuracy improved from 0.11486 to 0.72297, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_1.h5\n","Epoch 4/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.7325 - accuracy: 0.7695 - val_loss: 0.5268 - val_accuracy: 0.7905\n","\n","Epoch 00004: val_accuracy improved from 0.72297 to 0.79054, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_1.h5\n","Epoch 5/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.7195 - accuracy: 0.7716 - val_loss: 0.7394 - val_accuracy: 0.7905\n","\n","Epoch 00005: val_accuracy did not improve from 0.79054\n","Epoch 6/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.5874 - accuracy: 0.8074 - val_loss: 0.6425 - val_accuracy: 0.7770\n","\n","Epoch 00006: val_accuracy did not improve from 0.79054\n","Epoch 7/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.5948 - accuracy: 0.7989 - val_loss: 1.5215 - val_accuracy: 0.6757\n","\n","Epoch 00007: val_accuracy did not improve from 0.79054\n","Epoch 8/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.5418 - accuracy: 0.8163 - val_loss: 0.5621 - val_accuracy: 0.8041\n","\n","Epoch 00008: val_accuracy improved from 0.79054 to 0.80405, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_1.h5\n","Epoch 9/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.4893 - accuracy: 0.8400 - val_loss: 0.8785 - val_accuracy: 0.7162\n","\n","Epoch 00009: val_accuracy did not improve from 0.80405\n","Epoch 10/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.4485 - accuracy: 0.8437 - val_loss: 0.7520 - val_accuracy: 0.7973\n","\n","Epoch 00010: val_accuracy did not improve from 0.80405\n","Epoch 11/500\n","238/238 [==============================] - 15s 65ms/step - loss: 0.3926 - accuracy: 0.8626 - val_loss: 0.4206 - val_accuracy: 0.8581\n","\n","Epoch 00011: val_accuracy improved from 0.80405 to 0.85811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_1.h5\n","Epoch 12/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.4063 - accuracy: 0.8689 - val_loss: 2.1514 - val_accuracy: 0.4932\n","\n","Epoch 00012: val_accuracy did not improve from 0.85811\n","Epoch 13/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.3963 - accuracy: 0.8753 - val_loss: 0.9043 - val_accuracy: 0.7838\n","\n","Epoch 00013: val_accuracy did not improve from 0.85811\n","Epoch 14/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.3997 - accuracy: 0.8695 - val_loss: 0.4467 - val_accuracy: 0.8446\n","\n","Epoch 00014: val_accuracy did not improve from 0.85811\n","Epoch 15/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.3481 - accuracy: 0.8863 - val_loss: 0.4827 - val_accuracy: 0.8041\n","\n","Epoch 00015: val_accuracy did not improve from 0.85811\n","Epoch 16/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.3486 - accuracy: 0.8868 - val_loss: 0.3414 - val_accuracy: 0.8986\n","\n","Epoch 00016: val_accuracy improved from 0.85811 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_1.h5\n","Epoch 17/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.3483 - accuracy: 0.8937 - val_loss: 0.2382 - val_accuracy: 0.9324\n","\n","Epoch 00017: val_accuracy improved from 0.89865 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_1.h5\n","Epoch 18/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.2939 - accuracy: 0.9068 - val_loss: 0.5249 - val_accuracy: 0.8581\n","\n","Epoch 00018: val_accuracy did not improve from 0.93243\n","Epoch 19/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.2972 - accuracy: 0.9032 - val_loss: 0.5054 - val_accuracy: 0.8446\n","\n","Epoch 00019: val_accuracy did not improve from 0.93243\n","Epoch 20/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.2723 - accuracy: 0.9116 - val_loss: 0.8213 - val_accuracy: 0.7905\n","\n","Epoch 00020: val_accuracy did not improve from 0.93243\n","Epoch 21/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.3053 - accuracy: 0.9063 - val_loss: 0.5489 - val_accuracy: 0.8108\n","\n","Epoch 00021: val_accuracy did not improve from 0.93243\n","Epoch 22/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.3084 - accuracy: 0.8963 - val_loss: 0.5229 - val_accuracy: 0.8919\n","\n","Epoch 00022: val_accuracy did not improve from 0.93243\n","Epoch 23/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.2088 - accuracy: 0.9295 - val_loss: 0.3501 - val_accuracy: 0.8784\n","\n","Epoch 00023: val_accuracy did not improve from 0.93243\n","Epoch 24/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.2901 - accuracy: 0.9116 - val_loss: 0.6784 - val_accuracy: 0.8581\n","\n","Epoch 00024: val_accuracy did not improve from 0.93243\n","Epoch 25/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.2518 - accuracy: 0.9153 - val_loss: 0.3108 - val_accuracy: 0.8784\n","\n","Epoch 00025: val_accuracy did not improve from 0.93243\n","Epoch 26/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.1907 - accuracy: 0.9389 - val_loss: 0.4407 - val_accuracy: 0.8649\n","\n","Epoch 00026: val_accuracy did not improve from 0.93243\n","Epoch 27/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.2004 - accuracy: 0.9247 - val_loss: 0.4547 - val_accuracy: 0.8446\n","\n","Epoch 00027: val_accuracy did not improve from 0.93243\n","Epoch 28/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.2024 - accuracy: 0.9353 - val_loss: 0.2868 - val_accuracy: 0.9122\n","\n","Epoch 00028: val_accuracy did not improve from 0.93243\n","Epoch 29/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1763 - accuracy: 0.9453 - val_loss: 1.1612 - val_accuracy: 0.7500\n","\n","Epoch 00029: val_accuracy did not improve from 0.93243\n","Epoch 30/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.1850 - accuracy: 0.9442 - val_loss: 0.5521 - val_accuracy: 0.8649\n","\n","Epoch 00030: val_accuracy did not improve from 0.93243\n","Epoch 31/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.2362 - accuracy: 0.9284 - val_loss: 0.4594 - val_accuracy: 0.8649\n","\n","Epoch 00031: val_accuracy did not improve from 0.93243\n","Epoch 32/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1634 - accuracy: 0.9484 - val_loss: 0.3521 - val_accuracy: 0.9054\n","\n","Epoch 00032: val_accuracy did not improve from 0.93243\n","Epoch 33/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.1843 - accuracy: 0.9384 - val_loss: 4.8368 - val_accuracy: 0.4257\n","\n","Epoch 00033: val_accuracy did not improve from 0.93243\n","Epoch 34/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.1788 - accuracy: 0.9426 - val_loss: 0.6035 - val_accuracy: 0.8176\n","\n","Epoch 00034: val_accuracy did not improve from 0.93243\n","Epoch 35/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.1936 - accuracy: 0.9311 - val_loss: 0.4977 - val_accuracy: 0.8716\n","\n","Epoch 00035: val_accuracy did not improve from 0.93243\n","Epoch 36/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1569 - accuracy: 0.9453 - val_loss: 0.4656 - val_accuracy: 0.8784\n","\n","Epoch 00036: val_accuracy did not improve from 0.93243\n","Epoch 37/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1179 - accuracy: 0.9632 - val_loss: 0.2991 - val_accuracy: 0.9122\n","\n","Epoch 00037: val_accuracy did not improve from 0.93243\n","Epoch 38/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.1343 - accuracy: 0.9521 - val_loss: 0.3233 - val_accuracy: 0.8919\n","\n","Epoch 00038: val_accuracy did not improve from 0.93243\n","Epoch 39/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.1823 - accuracy: 0.9453 - val_loss: 0.4826 - val_accuracy: 0.8446\n","\n","Epoch 00039: val_accuracy did not improve from 0.93243\n","Epoch 40/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1274 - accuracy: 0.9537 - val_loss: 0.6933 - val_accuracy: 0.8581\n","\n","Epoch 00040: val_accuracy did not improve from 0.93243\n","Epoch 41/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.1649 - accuracy: 0.9432 - val_loss: 0.4560 - val_accuracy: 0.8784\n","\n","Epoch 00041: val_accuracy did not improve from 0.93243\n","Epoch 42/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1433 - accuracy: 0.9547 - val_loss: 0.3750 - val_accuracy: 0.8784\n","\n","Epoch 00042: val_accuracy did not improve from 0.93243\n","Epoch 43/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0748 - accuracy: 0.9742 - val_loss: 0.3927 - val_accuracy: 0.8716\n","\n","Epoch 00043: val_accuracy did not improve from 0.93243\n","Epoch 44/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1333 - accuracy: 0.9584 - val_loss: 0.7870 - val_accuracy: 0.8311\n","\n","Epoch 00044: val_accuracy did not improve from 0.93243\n","Epoch 45/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1231 - accuracy: 0.9605 - val_loss: 0.4518 - val_accuracy: 0.8649\n","\n","Epoch 00045: val_accuracy did not improve from 0.93243\n","Epoch 46/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.1318 - accuracy: 0.9532 - val_loss: 0.3753 - val_accuracy: 0.8919\n","\n","Epoch 00046: val_accuracy did not improve from 0.93243\n","Epoch 47/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0999 - accuracy: 0.9679 - val_loss: 0.4707 - val_accuracy: 0.8716\n","\n","Epoch 00047: val_accuracy did not improve from 0.93243\n","Epoch 48/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1552 - accuracy: 0.9511 - val_loss: 0.9369 - val_accuracy: 0.7905\n","\n","Epoch 00048: val_accuracy did not improve from 0.93243\n","Epoch 49/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.1102 - accuracy: 0.9621 - val_loss: 0.3155 - val_accuracy: 0.8986\n","\n","Epoch 00049: val_accuracy did not improve from 0.93243\n","Epoch 50/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0867 - accuracy: 0.9726 - val_loss: 0.4167 - val_accuracy: 0.8851\n","\n","Epoch 00050: val_accuracy did not improve from 0.93243\n","Epoch 51/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0961 - accuracy: 0.9663 - val_loss: 0.5692 - val_accuracy: 0.8581\n","\n","Epoch 00051: val_accuracy did not improve from 0.93243\n","Epoch 52/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0713 - accuracy: 0.9768 - val_loss: 0.5387 - val_accuracy: 0.8446\n","\n","Epoch 00052: val_accuracy did not improve from 0.93243\n","Epoch 53/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1453 - accuracy: 0.9547 - val_loss: 0.6614 - val_accuracy: 0.8311\n","\n","Epoch 00053: val_accuracy did not improve from 0.93243\n","Epoch 54/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0855 - accuracy: 0.9716 - val_loss: 0.6323 - val_accuracy: 0.8446\n","\n","Epoch 00054: val_accuracy did not improve from 0.93243\n","Epoch 55/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1384 - accuracy: 0.9568 - val_loss: 0.5255 - val_accuracy: 0.8446\n","\n","Epoch 00055: val_accuracy did not improve from 0.93243\n","Epoch 56/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1048 - accuracy: 0.9621 - val_loss: 0.2895 - val_accuracy: 0.8986\n","\n","Epoch 00056: val_accuracy did not improve from 0.93243\n","Epoch 57/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0304 - accuracy: 0.9879 - val_loss: 0.3371 - val_accuracy: 0.9054\n","\n","Epoch 00057: val_accuracy did not improve from 0.93243\n","Epoch 58/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1201 - accuracy: 0.9637 - val_loss: 0.3305 - val_accuracy: 0.9459\n","\n","Epoch 00058: val_accuracy improved from 0.93243 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_1.h5\n","Epoch 59/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0607 - accuracy: 0.9816 - val_loss: 0.4070 - val_accuracy: 0.8986\n","\n","Epoch 00059: val_accuracy did not improve from 0.94595\n","Epoch 60/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0643 - accuracy: 0.9784 - val_loss: 0.4060 - val_accuracy: 0.8986\n","\n","Epoch 00060: val_accuracy did not improve from 0.94595\n","Epoch 61/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0937 - accuracy: 0.9742 - val_loss: 0.3790 - val_accuracy: 0.9122\n","\n","Epoch 00061: val_accuracy did not improve from 0.94595\n","Epoch 62/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0733 - accuracy: 0.9711 - val_loss: 0.4709 - val_accuracy: 0.9122\n","\n","Epoch 00062: val_accuracy did not improve from 0.94595\n","Epoch 63/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0703 - accuracy: 0.9763 - val_loss: 0.5365 - val_accuracy: 0.8581\n","\n","Epoch 00063: val_accuracy did not improve from 0.94595\n","Epoch 64/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.1202 - accuracy: 0.9605 - val_loss: 0.3965 - val_accuracy: 0.8919\n","\n","Epoch 00064: val_accuracy did not improve from 0.94595\n","Epoch 65/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0921 - accuracy: 0.9689 - val_loss: 0.4524 - val_accuracy: 0.8851\n","\n","Epoch 00065: val_accuracy did not improve from 0.94595\n","Epoch 66/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: 0.4533 - val_accuracy: 0.8514\n","\n","Epoch 00066: val_accuracy did not improve from 0.94595\n","Epoch 67/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0597 - accuracy: 0.9837 - val_loss: 0.4260 - val_accuracy: 0.8851\n","\n","Epoch 00067: val_accuracy did not improve from 0.94595\n","Epoch 68/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0660 - accuracy: 0.9753 - val_loss: 0.5186 - val_accuracy: 0.8851\n","\n","Epoch 00068: val_accuracy did not improve from 0.94595\n","Epoch 69/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.1074 - accuracy: 0.9674 - val_loss: 0.3963 - val_accuracy: 0.9054\n","\n","Epoch 00069: val_accuracy did not improve from 0.94595\n","Epoch 70/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0476 - accuracy: 0.9863 - val_loss: 0.3637 - val_accuracy: 0.8919\n","\n","Epoch 00070: val_accuracy did not improve from 0.94595\n","Epoch 71/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0673 - accuracy: 0.9737 - val_loss: 0.6680 - val_accuracy: 0.8514\n","\n","Epoch 00071: val_accuracy did not improve from 0.94595\n","Epoch 72/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0496 - accuracy: 0.9858 - val_loss: 0.7236 - val_accuracy: 0.8446\n","\n","Epoch 00072: val_accuracy did not improve from 0.94595\n","Epoch 73/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0439 - accuracy: 0.9847 - val_loss: 0.7369 - val_accuracy: 0.8851\n","\n","Epoch 00073: val_accuracy did not improve from 0.94595\n","Epoch 74/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0756 - accuracy: 0.9732 - val_loss: 0.5081 - val_accuracy: 0.8784\n","\n","Epoch 00074: val_accuracy did not improve from 0.94595\n","Epoch 75/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0473 - accuracy: 0.9832 - val_loss: 0.4466 - val_accuracy: 0.8716\n","\n","Epoch 00075: val_accuracy did not improve from 0.94595\n","Epoch 76/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0693 - accuracy: 0.9795 - val_loss: 0.4766 - val_accuracy: 0.8716\n","\n","Epoch 00076: val_accuracy did not improve from 0.94595\n","Epoch 77/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0381 - accuracy: 0.9863 - val_loss: 0.3887 - val_accuracy: 0.8919\n","\n","Epoch 00077: val_accuracy did not improve from 0.94595\n","Epoch 78/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0489 - accuracy: 0.9811 - val_loss: 0.5034 - val_accuracy: 0.8784\n","\n","Epoch 00078: val_accuracy did not improve from 0.94595\n","Epoch 79/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0830 - accuracy: 0.9753 - val_loss: 0.3761 - val_accuracy: 0.8784\n","\n","Epoch 00079: val_accuracy did not improve from 0.94595\n","Epoch 80/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0752 - accuracy: 0.9758 - val_loss: 0.2577 - val_accuracy: 0.9189\n","\n","Epoch 00080: val_accuracy did not improve from 0.94595\n","Epoch 81/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0475 - accuracy: 0.9816 - val_loss: 0.4000 - val_accuracy: 0.8919\n","\n","Epoch 00081: val_accuracy did not improve from 0.94595\n","Epoch 82/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0390 - accuracy: 0.9863 - val_loss: 0.3187 - val_accuracy: 0.9189\n","\n","Epoch 00082: val_accuracy did not improve from 0.94595\n","Epoch 83/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0379 - accuracy: 0.9879 - val_loss: 0.4381 - val_accuracy: 0.8919\n","\n","Epoch 00083: val_accuracy did not improve from 0.94595\n","Epoch 84/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0683 - accuracy: 0.9763 - val_loss: 0.8959 - val_accuracy: 0.8446\n","\n","Epoch 00084: val_accuracy did not improve from 0.94595\n","Epoch 85/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0494 - accuracy: 0.9847 - val_loss: 0.4458 - val_accuracy: 0.8851\n","\n","Epoch 00085: val_accuracy did not improve from 0.94595\n","Epoch 86/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0561 - accuracy: 0.9837 - val_loss: 0.3719 - val_accuracy: 0.9122\n","\n","Epoch 00086: val_accuracy did not improve from 0.94595\n","Epoch 87/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0401 - accuracy: 0.9889 - val_loss: 0.4080 - val_accuracy: 0.9054\n","\n","Epoch 00087: val_accuracy did not improve from 0.94595\n","Epoch 88/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0369 - accuracy: 0.9911 - val_loss: 0.6637 - val_accuracy: 0.8784\n","\n","Epoch 00088: val_accuracy did not improve from 0.94595\n","Epoch 89/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.4127 - val_accuracy: 0.8851\n","\n","Epoch 00089: val_accuracy did not improve from 0.94595\n","Epoch 90/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 0.6324 - val_accuracy: 0.8581\n","\n","Epoch 00090: val_accuracy did not improve from 0.94595\n","Epoch 91/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0597 - accuracy: 0.9800 - val_loss: 0.3514 - val_accuracy: 0.8919\n","\n","Epoch 00091: val_accuracy did not improve from 0.94595\n","Epoch 92/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0676 - accuracy: 0.9768 - val_loss: 0.4239 - val_accuracy: 0.8986\n","\n","Epoch 00092: val_accuracy did not improve from 0.94595\n","Epoch 93/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.3633 - val_accuracy: 0.8986\n","\n","Epoch 00093: val_accuracy did not improve from 0.94595\n","Epoch 94/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0267 - accuracy: 0.9905 - val_loss: 0.4660 - val_accuracy: 0.8986\n","\n","Epoch 00094: val_accuracy did not improve from 0.94595\n","Epoch 95/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0647 - accuracy: 0.9763 - val_loss: 0.9203 - val_accuracy: 0.8041\n","\n","Epoch 00095: val_accuracy did not improve from 0.94595\n","Epoch 96/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0417 - accuracy: 0.9868 - val_loss: 0.6035 - val_accuracy: 0.8716\n","\n","Epoch 00096: val_accuracy did not improve from 0.94595\n","Epoch 97/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0491 - accuracy: 0.9858 - val_loss: 0.5712 - val_accuracy: 0.8514\n","\n","Epoch 00097: val_accuracy did not improve from 0.94595\n","Epoch 98/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0607 - accuracy: 0.9789 - val_loss: 0.3368 - val_accuracy: 0.9054\n","\n","Epoch 00098: val_accuracy did not improve from 0.94595\n","Epoch 99/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0346 - accuracy: 0.9889 - val_loss: 0.3538 - val_accuracy: 0.9392\n","\n","Epoch 00099: val_accuracy did not improve from 0.94595\n","Epoch 100/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.3535 - val_accuracy: 0.9122\n","\n","Epoch 00100: val_accuracy did not improve from 0.94595\n","Epoch 101/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0350 - accuracy: 0.9895 - val_loss: 0.3533 - val_accuracy: 0.9054\n","\n","Epoch 00101: val_accuracy did not improve from 0.94595\n","Epoch 102/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0389 - accuracy: 0.9895 - val_loss: 0.3123 - val_accuracy: 0.9054\n","\n","Epoch 00102: val_accuracy did not improve from 0.94595\n","Epoch 103/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.3643 - val_accuracy: 0.9122\n","\n","Epoch 00103: val_accuracy did not improve from 0.94595\n","Epoch 104/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0258 - accuracy: 0.9932 - val_loss: 0.4849 - val_accuracy: 0.9122\n","\n","Epoch 00104: val_accuracy did not improve from 0.94595\n","Epoch 105/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0675 - accuracy: 0.9805 - val_loss: 0.4552 - val_accuracy: 0.8919\n","\n","Epoch 00105: val_accuracy did not improve from 0.94595\n","Epoch 106/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0382 - accuracy: 0.9863 - val_loss: 0.3841 - val_accuracy: 0.8986\n","\n","Epoch 00106: val_accuracy did not improve from 0.94595\n","Epoch 107/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0580 - accuracy: 0.9858 - val_loss: 0.7928 - val_accuracy: 0.8581\n","\n","Epoch 00107: val_accuracy did not improve from 0.94595\n","Epoch 108/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0526 - accuracy: 0.9795 - val_loss: 0.4499 - val_accuracy: 0.8649\n","\n","Epoch 00108: val_accuracy did not improve from 0.94595\n","Epoch 109/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0143 - accuracy: 0.9942 - val_loss: 0.3760 - val_accuracy: 0.9122\n","\n","Epoch 00109: val_accuracy did not improve from 0.94595\n","Epoch 110/500\n","238/238 [==============================] - 16s 65ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.4055 - val_accuracy: 0.9054\n","\n","Epoch 00110: val_accuracy did not improve from 0.94595\n","Epoch 111/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0473 - accuracy: 0.9868 - val_loss: 0.4519 - val_accuracy: 0.8986\n","\n","Epoch 00111: val_accuracy did not improve from 0.94595\n","Epoch 112/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0689 - accuracy: 0.9779 - val_loss: 0.4196 - val_accuracy: 0.8851\n","\n","Epoch 00112: val_accuracy did not improve from 0.94595\n","Epoch 113/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0301 - accuracy: 0.9863 - val_loss: 0.2154 - val_accuracy: 0.9257\n","\n","Epoch 00113: val_accuracy did not improve from 0.94595\n","Epoch 114/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0409 - accuracy: 0.9842 - val_loss: 0.3792 - val_accuracy: 0.9257\n","\n","Epoch 00114: val_accuracy did not improve from 0.94595\n","Epoch 115/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.2592 - val_accuracy: 0.9257\n","\n","Epoch 00115: val_accuracy did not improve from 0.94595\n","Epoch 116/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.6487 - val_accuracy: 0.8986\n","\n","Epoch 00116: val_accuracy did not improve from 0.94595\n","Epoch 117/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0365 - accuracy: 0.9868 - val_loss: 0.5393 - val_accuracy: 0.8851\n","\n","Epoch 00117: val_accuracy did not improve from 0.94595\n","Epoch 118/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0373 - accuracy: 0.9895 - val_loss: 0.7142 - val_accuracy: 0.8581\n","\n","Epoch 00118: val_accuracy did not improve from 0.94595\n","Epoch 119/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.4515 - val_accuracy: 0.9189\n","\n","Epoch 00119: val_accuracy did not improve from 0.94595\n","Epoch 120/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0497 - accuracy: 0.9837 - val_loss: 0.4677 - val_accuracy: 0.9122\n","\n","Epoch 00120: val_accuracy did not improve from 0.94595\n","Epoch 121/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0443 - accuracy: 0.9853 - val_loss: 0.2948 - val_accuracy: 0.9257\n","\n","Epoch 00121: val_accuracy did not improve from 0.94595\n","Epoch 122/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0582 - accuracy: 0.9832 - val_loss: 0.6835 - val_accuracy: 0.8581\n","\n","Epoch 00122: val_accuracy did not improve from 0.94595\n","Epoch 123/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0436 - accuracy: 0.9832 - val_loss: 0.5347 - val_accuracy: 0.9054\n","\n","Epoch 00123: val_accuracy did not improve from 0.94595\n","Epoch 124/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.5274 - val_accuracy: 0.8919\n","\n","Epoch 00124: val_accuracy did not improve from 0.94595\n","Epoch 125/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0304 - accuracy: 0.9895 - val_loss: 0.4605 - val_accuracy: 0.8851\n","\n","Epoch 00125: val_accuracy did not improve from 0.94595\n","Epoch 126/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0170 - accuracy: 0.9932 - val_loss: 0.4301 - val_accuracy: 0.8986\n","\n","Epoch 00126: val_accuracy did not improve from 0.94595\n","Epoch 127/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0174 - accuracy: 0.9932 - val_loss: 0.6479 - val_accuracy: 0.8919\n","\n","Epoch 00127: val_accuracy did not improve from 0.94595\n","Epoch 128/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0630 - accuracy: 0.9795 - val_loss: 0.7279 - val_accuracy: 0.8649\n","\n","Epoch 00128: val_accuracy did not improve from 0.94595\n","Epoch 129/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 0.5255 - val_accuracy: 0.9054\n","\n","Epoch 00129: val_accuracy did not improve from 0.94595\n","Epoch 130/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.8202 - val_accuracy: 0.8716\n","\n","Epoch 00130: val_accuracy did not improve from 0.94595\n","Epoch 131/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.3531 - val_accuracy: 0.9122\n","\n","Epoch 00131: val_accuracy did not improve from 0.94595\n","Epoch 132/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 0.4357 - val_accuracy: 0.9054\n","\n","Epoch 00132: val_accuracy did not improve from 0.94595\n","Epoch 133/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0245 - accuracy: 0.9942 - val_loss: 0.6323 - val_accuracy: 0.8514\n","\n","Epoch 00133: val_accuracy did not improve from 0.94595\n","Epoch 134/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0350 - accuracy: 0.9868 - val_loss: 0.6696 - val_accuracy: 0.8649\n","\n","Epoch 00134: val_accuracy did not improve from 0.94595\n","Epoch 135/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.4255 - val_accuracy: 0.9324\n","\n","Epoch 00135: val_accuracy did not improve from 0.94595\n","Epoch 136/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0238 - accuracy: 0.9900 - val_loss: 0.5128 - val_accuracy: 0.9054\n","\n","Epoch 00136: val_accuracy did not improve from 0.94595\n","Epoch 137/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.5793 - val_accuracy: 0.8716\n","\n","Epoch 00137: val_accuracy did not improve from 0.94595\n","Epoch 138/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0278 - accuracy: 0.9921 - val_loss: 0.5119 - val_accuracy: 0.8851\n","\n","Epoch 00138: val_accuracy did not improve from 0.94595\n","Epoch 139/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0403 - accuracy: 0.9868 - val_loss: 0.4072 - val_accuracy: 0.9122\n","\n","Epoch 00139: val_accuracy did not improve from 0.94595\n","Epoch 140/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0158 - accuracy: 0.9932 - val_loss: 0.4822 - val_accuracy: 0.9054\n","\n","Epoch 00140: val_accuracy did not improve from 0.94595\n","Epoch 141/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0467 - accuracy: 0.9874 - val_loss: 0.4429 - val_accuracy: 0.8919\n","\n","Epoch 00141: val_accuracy did not improve from 0.94595\n","Epoch 142/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0134 - accuracy: 0.9942 - val_loss: 0.4228 - val_accuracy: 0.9122\n","\n","Epoch 00142: val_accuracy did not improve from 0.94595\n","Epoch 143/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.4774 - val_accuracy: 0.9054\n","\n","Epoch 00143: val_accuracy did not improve from 0.94595\n","Epoch 144/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 0.4871 - val_accuracy: 0.9122\n","\n","Epoch 00144: val_accuracy did not improve from 0.94595\n","Epoch 145/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.5409 - val_accuracy: 0.8919\n","\n","Epoch 00145: val_accuracy did not improve from 0.94595\n","Epoch 146/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0366 - accuracy: 0.9905 - val_loss: 0.5311 - val_accuracy: 0.8986\n","\n","Epoch 00146: val_accuracy did not improve from 0.94595\n","Epoch 147/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0547 - accuracy: 0.9847 - val_loss: 0.4239 - val_accuracy: 0.8919\n","\n","Epoch 00147: val_accuracy did not improve from 0.94595\n","Epoch 148/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 0.4034 - val_accuracy: 0.9122\n","\n","Epoch 00148: val_accuracy did not improve from 0.94595\n","Epoch 149/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.3055 - val_accuracy: 0.9392\n","\n","Epoch 00149: val_accuracy did not improve from 0.94595\n","Epoch 150/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.3282 - val_accuracy: 0.9122\n","\n","Epoch 00150: val_accuracy did not improve from 0.94595\n","Epoch 151/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0504 - accuracy: 0.9863 - val_loss: 0.4615 - val_accuracy: 0.8986\n","\n","Epoch 00151: val_accuracy did not improve from 0.94595\n","Epoch 152/500\n","238/238 [==============================] - 16s 66ms/step - loss: 0.0319 - accuracy: 0.9884 - val_loss: 0.5140 - val_accuracy: 0.9054\n","\n","Epoch 00152: val_accuracy did not improve from 0.94595\n","Epoch 153/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 0.5330 - val_accuracy: 0.9122\n","\n","Epoch 00153: val_accuracy did not improve from 0.94595\n","Epoch 154/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0237 - accuracy: 0.9958 - val_loss: 0.4761 - val_accuracy: 0.9054\n","\n","Epoch 00154: val_accuracy did not improve from 0.94595\n","Epoch 155/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0130 - accuracy: 0.9942 - val_loss: 0.4053 - val_accuracy: 0.8986\n","\n","Epoch 00155: val_accuracy did not improve from 0.94595\n","Epoch 156/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0116 - accuracy: 0.9979 - val_loss: 0.6729 - val_accuracy: 0.8716\n","\n","Epoch 00156: val_accuracy did not improve from 0.94595\n","Epoch 157/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.8247 - val_accuracy: 0.8446\n","\n","Epoch 00157: val_accuracy did not improve from 0.94595\n","Epoch 158/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0383 - accuracy: 0.9900 - val_loss: 0.5178 - val_accuracy: 0.9054\n","\n","Epoch 00158: val_accuracy did not improve from 0.94595\n","Epoch 159/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.4352 - val_accuracy: 0.8986\n","\n","Epoch 00159: val_accuracy did not improve from 0.94595\n","Epoch 160/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0275 - accuracy: 0.9889 - val_loss: 0.4891 - val_accuracy: 0.9324\n","\n","Epoch 00160: val_accuracy did not improve from 0.94595\n","Epoch 161/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.4196 - val_accuracy: 0.9189\n","\n","Epoch 00161: val_accuracy did not improve from 0.94595\n","Epoch 162/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.4530 - val_accuracy: 0.9122\n","\n","Epoch 00162: val_accuracy did not improve from 0.94595\n","Epoch 163/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.5681 - val_accuracy: 0.9122\n","\n","Epoch 00163: val_accuracy did not improve from 0.94595\n","Epoch 164/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0431 - accuracy: 0.9889 - val_loss: 0.5313 - val_accuracy: 0.9189\n","\n","Epoch 00164: val_accuracy did not improve from 0.94595\n","Epoch 165/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0373 - accuracy: 0.9847 - val_loss: 0.5883 - val_accuracy: 0.8919\n","\n","Epoch 00165: val_accuracy did not improve from 0.94595\n","Epoch 166/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0287 - accuracy: 0.9895 - val_loss: 0.4045 - val_accuracy: 0.9054\n","\n","Epoch 00166: val_accuracy did not improve from 0.94595\n","Epoch 167/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.4489 - val_accuracy: 0.9122\n","\n","Epoch 00167: val_accuracy did not improve from 0.94595\n","Epoch 168/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0303 - accuracy: 0.9900 - val_loss: 0.3767 - val_accuracy: 0.9324\n","\n","Epoch 00168: val_accuracy did not improve from 0.94595\n","Epoch 169/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 0.3383 - val_accuracy: 0.9122\n","\n","Epoch 00169: val_accuracy did not improve from 0.94595\n","Epoch 170/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.4587 - val_accuracy: 0.8986\n","\n","Epoch 00170: val_accuracy did not improve from 0.94595\n","Epoch 171/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.5059 - val_accuracy: 0.8986\n","\n","Epoch 00171: val_accuracy did not improve from 0.94595\n","Epoch 172/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.5398 - val_accuracy: 0.8919\n","\n","Epoch 00172: val_accuracy did not improve from 0.94595\n","Epoch 173/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0119 - accuracy: 0.9947 - val_loss: 0.5783 - val_accuracy: 0.8919\n","\n","Epoch 00173: val_accuracy did not improve from 0.94595\n","Epoch 174/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0485 - accuracy: 0.9874 - val_loss: 0.5402 - val_accuracy: 0.8716\n","\n","Epoch 00174: val_accuracy did not improve from 0.94595\n","Epoch 175/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0521 - accuracy: 0.9826 - val_loss: 0.4600 - val_accuracy: 0.8851\n","\n","Epoch 00175: val_accuracy did not improve from 0.94595\n","Epoch 176/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.3581 - val_accuracy: 0.8919\n","\n","Epoch 00176: val_accuracy did not improve from 0.94595\n","Epoch 177/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.4260 - val_accuracy: 0.9189\n","\n","Epoch 00177: val_accuracy did not improve from 0.94595\n","Epoch 178/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.4248 - val_accuracy: 0.8851\n","\n","Epoch 00178: val_accuracy did not improve from 0.94595\n","Epoch 179/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0198 - accuracy: 0.9947 - val_loss: 0.3341 - val_accuracy: 0.9054\n","\n","Epoch 00179: val_accuracy did not improve from 0.94595\n","Epoch 180/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.3649 - val_accuracy: 0.9189\n","\n","Epoch 00180: val_accuracy did not improve from 0.94595\n","Epoch 181/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0068 - accuracy: 0.9963 - val_loss: 0.4931 - val_accuracy: 0.9054\n","\n","Epoch 00181: val_accuracy did not improve from 0.94595\n","Epoch 182/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.5035 - val_accuracy: 0.8851\n","\n","Epoch 00182: val_accuracy did not improve from 0.94595\n","Epoch 183/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0449 - accuracy: 0.9884 - val_loss: 0.6089 - val_accuracy: 0.8851\n","\n","Epoch 00183: val_accuracy did not improve from 0.94595\n","Epoch 184/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0194 - accuracy: 0.9963 - val_loss: 0.4137 - val_accuracy: 0.9324\n","\n","Epoch 00184: val_accuracy did not improve from 0.94595\n","Epoch 185/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.6483 - val_accuracy: 0.8784\n","\n","Epoch 00185: val_accuracy did not improve from 0.94595\n","Epoch 186/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.5558 - val_accuracy: 0.8919\n","\n","Epoch 00186: val_accuracy did not improve from 0.94595\n","Epoch 187/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.4507 - val_accuracy: 0.8919\n","\n","Epoch 00187: val_accuracy did not improve from 0.94595\n","Epoch 188/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0298 - accuracy: 0.9926 - val_loss: 0.9619 - val_accuracy: 0.8176\n","\n","Epoch 00188: val_accuracy did not improve from 0.94595\n","Epoch 189/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 0.6719 - val_accuracy: 0.8986\n","\n","Epoch 00189: val_accuracy did not improve from 0.94595\n","Epoch 190/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.4223 - val_accuracy: 0.9392\n","\n","Epoch 00190: val_accuracy did not improve from 0.94595\n","Epoch 191/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 0.5306 - val_accuracy: 0.9122\n","\n","Epoch 00191: val_accuracy did not improve from 0.94595\n","Epoch 192/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.4779 - val_accuracy: 0.9189\n","\n","Epoch 00192: val_accuracy did not improve from 0.94595\n","Epoch 193/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.4747 - val_accuracy: 0.8986\n","\n","Epoch 00193: val_accuracy did not improve from 0.94595\n","Epoch 194/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.4116 - val_accuracy: 0.9054\n","\n","Epoch 00194: val_accuracy did not improve from 0.94595\n","Epoch 195/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0191 - accuracy: 0.9963 - val_loss: 0.4838 - val_accuracy: 0.9189\n","\n","Epoch 00195: val_accuracy did not improve from 0.94595\n","Epoch 196/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.4387 - val_accuracy: 0.9189\n","\n","Epoch 00196: val_accuracy did not improve from 0.94595\n","Epoch 197/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.4669 - val_accuracy: 0.9189\n","\n","Epoch 00197: val_accuracy did not improve from 0.94595\n","Epoch 198/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.5497 - val_accuracy: 0.8919\n","\n","Epoch 00198: val_accuracy did not improve from 0.94595\n","Epoch 199/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0330 - accuracy: 0.9884 - val_loss: 0.4843 - val_accuracy: 0.8986\n","\n","Epoch 00199: val_accuracy did not improve from 0.94595\n","Epoch 200/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0487 - accuracy: 0.9868 - val_loss: 0.4791 - val_accuracy: 0.8784\n","\n","Epoch 00200: val_accuracy did not improve from 0.94595\n","Epoch 201/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 0.4978 - val_accuracy: 0.8716\n","\n","Epoch 00201: val_accuracy did not improve from 0.94595\n","Epoch 202/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0178 - accuracy: 0.9958 - val_loss: 0.4657 - val_accuracy: 0.8851\n","\n","Epoch 00202: val_accuracy did not improve from 0.94595\n","Epoch 203/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.7388 - val_accuracy: 0.8649\n","\n","Epoch 00203: val_accuracy did not improve from 0.94595\n","Epoch 204/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0065 - accuracy: 0.9968 - val_loss: 0.4285 - val_accuracy: 0.8784\n","\n","Epoch 00204: val_accuracy did not improve from 0.94595\n","Epoch 205/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.7232 - val_accuracy: 0.8716\n","\n","Epoch 00205: val_accuracy did not improve from 0.94595\n","Epoch 206/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.6151 - val_accuracy: 0.8311\n","\n","Epoch 00206: val_accuracy did not improve from 0.94595\n","Epoch 207/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.4333 - val_accuracy: 0.9189\n","\n","Epoch 00207: val_accuracy did not improve from 0.94595\n","Epoch 208/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.5902 - val_accuracy: 0.8986\n","\n","Epoch 00208: val_accuracy did not improve from 0.94595\n","Epoch 209/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.4396 - val_accuracy: 0.9189\n","\n","Epoch 00209: val_accuracy did not improve from 0.94595\n","Epoch 210/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0417 - accuracy: 0.9842 - val_loss: 0.4029 - val_accuracy: 0.8986\n","\n","Epoch 00210: val_accuracy did not improve from 0.94595\n","Epoch 211/500\n","238/238 [==============================] - 16s 67ms/step - loss: 0.0102 - accuracy: 0.9953 - val_loss: 0.3613 - val_accuracy: 0.9189\n","\n","Epoch 00211: val_accuracy did not improve from 0.94595\n","Epoch 212/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.5086 - val_accuracy: 0.8986\n","\n","Epoch 00212: val_accuracy did not improve from 0.94595\n","Epoch 213/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.4920 - val_accuracy: 0.9054\n","\n","Epoch 00213: val_accuracy did not improve from 0.94595\n","Epoch 214/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.5418 - val_accuracy: 0.8986\n","\n","Epoch 00214: val_accuracy did not improve from 0.94595\n","Epoch 215/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.9189\n","\n","Epoch 00215: val_accuracy did not improve from 0.94595\n","Epoch 216/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.5085 - val_accuracy: 0.9054\n","\n","Epoch 00216: val_accuracy did not improve from 0.94595\n","Epoch 217/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0334 - accuracy: 0.9879 - val_loss: 0.6160 - val_accuracy: 0.8919\n","\n","Epoch 00217: val_accuracy did not improve from 0.94595\n","Epoch 218/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0440 - accuracy: 0.9895 - val_loss: 0.5010 - val_accuracy: 0.9054\n","\n","Epoch 00218: val_accuracy did not improve from 0.94595\n","Epoch 219/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.2783 - val_accuracy: 0.9257\n","\n","Epoch 00219: val_accuracy did not improve from 0.94595\n","Epoch 220/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0304 - accuracy: 0.9926 - val_loss: 0.4665 - val_accuracy: 0.8986\n","\n","Epoch 00220: val_accuracy did not improve from 0.94595\n","Epoch 221/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0062 - accuracy: 0.9963 - val_loss: 0.3606 - val_accuracy: 0.8919\n","\n","Epoch 00221: val_accuracy did not improve from 0.94595\n","Epoch 222/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.3836 - val_accuracy: 0.9257\n","\n","Epoch 00222: val_accuracy did not improve from 0.94595\n","Epoch 223/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.5271 - val_accuracy: 0.8986\n","\n","Epoch 00223: val_accuracy did not improve from 0.94595\n","Epoch 224/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.4006 - val_accuracy: 0.9324\n","\n","Epoch 00224: val_accuracy did not improve from 0.94595\n","Epoch 225/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.5490 - val_accuracy: 0.8784\n","\n","Epoch 00225: val_accuracy did not improve from 0.94595\n","Epoch 226/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.5344 - val_accuracy: 0.8986\n","\n","Epoch 00226: val_accuracy did not improve from 0.94595\n","Epoch 227/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0124 - accuracy: 0.9984 - val_loss: 0.6618 - val_accuracy: 0.8716\n","\n","Epoch 00227: val_accuracy did not improve from 0.94595\n","Epoch 228/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.4183 - val_accuracy: 0.8986\n","\n","Epoch 00228: val_accuracy did not improve from 0.94595\n","Epoch 229/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.4314 - val_accuracy: 0.9257\n","\n","Epoch 00229: val_accuracy did not improve from 0.94595\n","Epoch 230/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.3225 - val_accuracy: 0.9189\n","\n","Epoch 00230: val_accuracy did not improve from 0.94595\n","Epoch 231/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.5042 - val_accuracy: 0.8784\n","\n","Epoch 00231: val_accuracy did not improve from 0.94595\n","Epoch 232/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0225 - accuracy: 0.9947 - val_loss: 0.5273 - val_accuracy: 0.8986\n","\n","Epoch 00232: val_accuracy did not improve from 0.94595\n","Epoch 233/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0152 - accuracy: 0.9937 - val_loss: 0.4674 - val_accuracy: 0.9054\n","\n","Epoch 00233: val_accuracy did not improve from 0.94595\n","Epoch 234/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0231 - accuracy: 0.9916 - val_loss: 0.4807 - val_accuracy: 0.8986\n","\n","Epoch 00234: val_accuracy did not improve from 0.94595\n","Epoch 235/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0122 - accuracy: 0.9947 - val_loss: 0.5755 - val_accuracy: 0.9122\n","\n","Epoch 00235: val_accuracy did not improve from 0.94595\n","Epoch 236/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.4135 - val_accuracy: 0.9257\n","\n","Epoch 00236: val_accuracy did not improve from 0.94595\n","Epoch 237/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0171 - accuracy: 0.9932 - val_loss: 0.3948 - val_accuracy: 0.9324\n","\n","Epoch 00237: val_accuracy did not improve from 0.94595\n","Epoch 238/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.5345 - val_accuracy: 0.8851\n","\n","Epoch 00238: val_accuracy did not improve from 0.94595\n","Epoch 239/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.2993 - val_accuracy: 0.8986\n","\n","Epoch 00239: val_accuracy did not improve from 0.94595\n","Epoch 240/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.4120 - val_accuracy: 0.9122\n","\n","Epoch 00240: val_accuracy did not improve from 0.94595\n","Epoch 241/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.5784 - val_accuracy: 0.8919\n","\n","Epoch 00241: val_accuracy did not improve from 0.94595\n","Epoch 242/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.7472 - val_accuracy: 0.8716\n","\n","Epoch 00242: val_accuracy did not improve from 0.94595\n","Epoch 243/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.5904 - val_accuracy: 0.8851\n","\n","Epoch 00243: val_accuracy did not improve from 0.94595\n","Epoch 244/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.3461 - val_accuracy: 0.9189\n","\n","Epoch 00244: val_accuracy did not improve from 0.94595\n","Epoch 245/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.4267 - val_accuracy: 0.8986\n","\n","Epoch 00245: val_accuracy did not improve from 0.94595\n","Epoch 246/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.5155 - val_accuracy: 0.8919\n","\n","Epoch 00246: val_accuracy did not improve from 0.94595\n","Epoch 247/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5190 - val_accuracy: 0.8784\n","\n","Epoch 00247: val_accuracy did not improve from 0.94595\n","Epoch 248/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 0.4706 - val_accuracy: 0.8919\n","\n","Epoch 00248: val_accuracy did not improve from 0.94595\n","Epoch 249/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0582 - accuracy: 0.9863 - val_loss: 0.5548 - val_accuracy: 0.8851\n","\n","Epoch 00249: val_accuracy did not improve from 0.94595\n","Epoch 250/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 0.6809 - val_accuracy: 0.9054\n","\n","Epoch 00250: val_accuracy did not improve from 0.94595\n","Epoch 251/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.7575 - val_accuracy: 0.8784\n","\n","Epoch 00251: val_accuracy did not improve from 0.94595\n","Epoch 252/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 0.4862 - val_accuracy: 0.8919\n","\n","Epoch 00252: val_accuracy did not improve from 0.94595\n","Epoch 253/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.4894 - val_accuracy: 0.9122\n","\n","Epoch 00253: val_accuracy did not improve from 0.94595\n","Epoch 254/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4777 - val_accuracy: 0.8986\n","\n","Epoch 00254: val_accuracy did not improve from 0.94595\n","Epoch 255/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.5917 - val_accuracy: 0.8649\n","\n","Epoch 00255: val_accuracy did not improve from 0.94595\n","Epoch 256/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.8252 - val_accuracy: 0.8514\n","\n","Epoch 00256: val_accuracy did not improve from 0.94595\n","Epoch 257/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.5618 - val_accuracy: 0.8919\n","\n","Epoch 00257: val_accuracy did not improve from 0.94595\n","Epoch 258/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 0.4642 - val_accuracy: 0.8919\n","\n","Epoch 00258: val_accuracy did not improve from 0.94595\n","Epoch 259/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.3846 - val_accuracy: 0.8919\n","\n","Epoch 00259: val_accuracy did not improve from 0.94595\n","Epoch 260/500\n","238/238 [==============================] - 16s 68ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.4240 - val_accuracy: 0.8986\n","\n","Epoch 00260: val_accuracy did not improve from 0.94595\n","Epoch 261/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.4023 - val_accuracy: 0.8919\n","\n","Epoch 00261: val_accuracy did not improve from 0.94595\n","Epoch 262/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0049 - accuracy: 0.9974 - val_loss: 0.5067 - val_accuracy: 0.8919\n","\n","Epoch 00262: val_accuracy did not improve from 0.94595\n","Epoch 263/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.4627 - val_accuracy: 0.9257\n","\n","Epoch 00263: val_accuracy did not improve from 0.94595\n","Epoch 264/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.4436 - val_accuracy: 0.9122\n","\n","Epoch 00264: val_accuracy did not improve from 0.94595\n","Epoch 265/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0331 - accuracy: 0.9911 - val_loss: 0.6209 - val_accuracy: 0.8784\n","\n","Epoch 00265: val_accuracy did not improve from 0.94595\n","Epoch 266/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.5429 - val_accuracy: 0.9054\n","\n","Epoch 00266: val_accuracy did not improve from 0.94595\n","Epoch 267/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0281 - accuracy: 0.9932 - val_loss: 0.5666 - val_accuracy: 0.8986\n","\n","Epoch 00267: val_accuracy did not improve from 0.94595\n","Epoch 268/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.4658 - val_accuracy: 0.8986\n","\n","Epoch 00268: val_accuracy did not improve from 0.94595\n","Epoch 269/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.6680 - val_accuracy: 0.8851\n","\n","Epoch 00269: val_accuracy did not improve from 0.94595\n","Epoch 270/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.6095 - val_accuracy: 0.8919\n","\n","Epoch 00270: val_accuracy did not improve from 0.94595\n","Epoch 271/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0362 - accuracy: 0.9900 - val_loss: 0.3982 - val_accuracy: 0.9054\n","\n","Epoch 00271: val_accuracy did not improve from 0.94595\n","Epoch 272/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.3367 - val_accuracy: 0.9324\n","\n","Epoch 00272: val_accuracy did not improve from 0.94595\n","Epoch 273/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4207 - val_accuracy: 0.9054\n","\n","Epoch 00273: val_accuracy did not improve from 0.94595\n","Epoch 274/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.4184 - val_accuracy: 0.9189\n","\n","Epoch 00274: val_accuracy did not improve from 0.94595\n","Epoch 275/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.5863 - val_accuracy: 0.8919\n","\n","Epoch 00275: val_accuracy did not improve from 0.94595\n","Epoch 276/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.3975 - val_accuracy: 0.9054\n","\n","Epoch 00276: val_accuracy did not improve from 0.94595\n","Epoch 277/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.5991 - val_accuracy: 0.8716\n","\n","Epoch 00277: val_accuracy did not improve from 0.94595\n","Epoch 278/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.6868 - val_accuracy: 0.8851\n","\n","Epoch 00278: val_accuracy did not improve from 0.94595\n","Epoch 279/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0113 - accuracy: 0.9942 - val_loss: 0.7469 - val_accuracy: 0.8514\n","\n","Epoch 00279: val_accuracy did not improve from 0.94595\n","Epoch 280/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0083 - accuracy: 0.9989 - val_loss: 0.5674 - val_accuracy: 0.9257\n","\n","Epoch 00280: val_accuracy did not improve from 0.94595\n","Epoch 281/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 0.6220 - val_accuracy: 0.9054\n","\n","Epoch 00281: val_accuracy did not improve from 0.94595\n","Epoch 282/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.8986\n","\n","Epoch 00282: val_accuracy did not improve from 0.94595\n","Epoch 283/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0080 - accuracy: 0.9963 - val_loss: 0.4981 - val_accuracy: 0.9324\n","\n","Epoch 00283: val_accuracy did not improve from 0.94595\n","Epoch 284/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.4989 - val_accuracy: 0.9324\n","\n","Epoch 00284: val_accuracy did not improve from 0.94595\n","Epoch 285/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.6834 - val_accuracy: 0.8311\n","\n","Epoch 00285: val_accuracy did not improve from 0.94595\n","Epoch 286/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0095 - accuracy: 0.9953 - val_loss: 0.3934 - val_accuracy: 0.9122\n","\n","Epoch 00286: val_accuracy did not improve from 0.94595\n","Epoch 287/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0186 - accuracy: 0.9953 - val_loss: 0.4457 - val_accuracy: 0.9122\n","\n","Epoch 00287: val_accuracy did not improve from 0.94595\n","Epoch 288/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.4739 - val_accuracy: 0.8851\n","\n","Epoch 00288: val_accuracy did not improve from 0.94595\n","Epoch 289/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.6404 - val_accuracy: 0.8919\n","\n","Epoch 00289: val_accuracy did not improve from 0.94595\n","Epoch 290/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0099 - accuracy: 0.9953 - val_loss: 0.4521 - val_accuracy: 0.9189\n","\n","Epoch 00290: val_accuracy did not improve from 0.94595\n","Epoch 291/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.3931 - val_accuracy: 0.9324\n","\n","Epoch 00291: val_accuracy did not improve from 0.94595\n","Epoch 292/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.4269 - val_accuracy: 0.9189\n","\n","Epoch 00292: val_accuracy did not improve from 0.94595\n","Epoch 293/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0100 - accuracy: 0.9958 - val_loss: 0.3124 - val_accuracy: 0.9324\n","\n","Epoch 00293: val_accuracy did not improve from 0.94595\n","Epoch 294/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0169 - accuracy: 0.9937 - val_loss: 0.4883 - val_accuracy: 0.8986\n","\n","Epoch 00294: val_accuracy did not improve from 0.94595\n","Epoch 295/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.6550 - val_accuracy: 0.8986\n","\n","Epoch 00295: val_accuracy did not improve from 0.94595\n","Epoch 296/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.4622 - val_accuracy: 0.9054\n","\n","Epoch 00296: val_accuracy did not improve from 0.94595\n","Epoch 297/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.4833 - val_accuracy: 0.9122\n","\n","Epoch 00297: val_accuracy did not improve from 0.94595\n","Epoch 298/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.5585 - val_accuracy: 0.8919\n","\n","Epoch 00298: val_accuracy did not improve from 0.94595\n","Epoch 299/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.4593 - val_accuracy: 0.9122\n","\n","Epoch 00299: val_accuracy did not improve from 0.94595\n","Epoch 300/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.6579 - val_accuracy: 0.8986\n","\n","Epoch 00300: val_accuracy did not improve from 0.94595\n","Epoch 301/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.6226 - val_accuracy: 0.9054\n","\n","Epoch 00301: val_accuracy did not improve from 0.94595\n","Epoch 302/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.6895 - val_accuracy: 0.8986\n","\n","Epoch 00302: val_accuracy did not improve from 0.94595\n","Epoch 303/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.5644 - val_accuracy: 0.8986\n","\n","Epoch 00303: val_accuracy did not improve from 0.94595\n","Epoch 304/500\n","238/238 [==============================] - 17s 72ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.6707 - val_accuracy: 0.8851\n","\n","Epoch 00304: val_accuracy did not improve from 0.94595\n","Epoch 305/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4676 - val_accuracy: 0.9054\n","\n","Epoch 00305: val_accuracy did not improve from 0.94595\n","Epoch 306/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.5437 - val_accuracy: 0.9122\n","\n","Epoch 00306: val_accuracy did not improve from 0.94595\n","Epoch 307/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.5115 - val_accuracy: 0.9324\n","\n","Epoch 00307: val_accuracy did not improve from 0.94595\n","Epoch 308/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0283 - accuracy: 0.9895 - val_loss: 0.4265 - val_accuracy: 0.9324\n","\n","Epoch 00308: val_accuracy did not improve from 0.94595\n","Epoch 309/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.3665 - val_accuracy: 0.9257\n","\n","Epoch 00309: val_accuracy did not improve from 0.94595\n","Epoch 310/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.3829 - val_accuracy: 0.9122\n","\n","Epoch 00310: val_accuracy did not improve from 0.94595\n","Epoch 311/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.5917 - val_accuracy: 0.8919\n","\n","Epoch 00311: val_accuracy did not improve from 0.94595\n","Epoch 312/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.5908 - val_accuracy: 0.8919\n","\n","Epoch 00312: val_accuracy did not improve from 0.94595\n","Epoch 313/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0294 - accuracy: 0.9921 - val_loss: 0.5828 - val_accuracy: 0.8919\n","\n","Epoch 00313: val_accuracy did not improve from 0.94595\n","Epoch 314/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.5817 - val_accuracy: 0.8851\n","\n","Epoch 00314: val_accuracy did not improve from 0.94595\n","Epoch 315/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.4715 - val_accuracy: 0.9054\n","\n","Epoch 00315: val_accuracy did not improve from 0.94595\n","Epoch 316/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.4354 - val_accuracy: 0.8919\n","\n","Epoch 00316: val_accuracy did not improve from 0.94595\n","Epoch 317/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.5560 - val_accuracy: 0.8986\n","\n","Epoch 00317: val_accuracy did not improve from 0.94595\n","Epoch 318/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.4374 - val_accuracy: 0.9257\n","\n","Epoch 00318: val_accuracy did not improve from 0.94595\n","Epoch 319/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.5075 - val_accuracy: 0.8919\n","\n","Epoch 00319: val_accuracy did not improve from 0.94595\n","Epoch 320/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.4004 - val_accuracy: 0.9054\n","\n","Epoch 00320: val_accuracy did not improve from 0.94595\n","Epoch 321/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.9324\n","\n","Epoch 00321: val_accuracy did not improve from 0.94595\n","Epoch 322/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4728 - val_accuracy: 0.9257\n","\n","Epoch 00322: val_accuracy did not improve from 0.94595\n","Epoch 323/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.5432 - val_accuracy: 0.9054\n","\n","Epoch 00323: val_accuracy did not improve from 0.94595\n","Epoch 324/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9189\n","\n","Epoch 00324: val_accuracy did not improve from 0.94595\n","Epoch 325/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0205 - accuracy: 0.9968 - val_loss: 0.6595 - val_accuracy: 0.8851\n","\n","Epoch 00325: val_accuracy did not improve from 0.94595\n","Epoch 326/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0486 - accuracy: 0.9842 - val_loss: 0.6029 - val_accuracy: 0.8986\n","\n","Epoch 00326: val_accuracy did not improve from 0.94595\n","Epoch 327/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.5502 - val_accuracy: 0.8784\n","\n","Epoch 00327: val_accuracy did not improve from 0.94595\n","Epoch 328/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.4814 - val_accuracy: 0.9257\n","\n","Epoch 00328: val_accuracy did not improve from 0.94595\n","Epoch 329/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.6140 - val_accuracy: 0.8581\n","\n","Epoch 00329: val_accuracy did not improve from 0.94595\n","Epoch 330/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0044 - accuracy: 0.9974 - val_loss: 0.6611 - val_accuracy: 0.8919\n","\n","Epoch 00330: val_accuracy did not improve from 0.94595\n","Epoch 331/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.4954 - val_accuracy: 0.9054\n","\n","Epoch 00331: val_accuracy did not improve from 0.94595\n","Epoch 332/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.6328 - val_accuracy: 0.8581\n","\n","Epoch 00332: val_accuracy did not improve from 0.94595\n","Epoch 333/500\n","238/238 [==============================] - 16s 69ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5886 - val_accuracy: 0.9054\n","\n","Epoch 00333: val_accuracy did not improve from 0.94595\n","Epoch 334/500\n","238/238 [==============================] - 17s 70ms/step - loss: 4.3744e-04 - accuracy: 1.0000 - val_loss: 0.6054 - val_accuracy: 0.9189\n","\n","Epoch 00334: val_accuracy did not improve from 0.94595\n","Epoch 335/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.6230 - val_accuracy: 0.8851\n","\n","Epoch 00335: val_accuracy did not improve from 0.94595\n","Epoch 336/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.6472 - val_accuracy: 0.9054\n","\n","Epoch 00336: val_accuracy did not improve from 0.94595\n","Epoch 337/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0247 - accuracy: 0.9942 - val_loss: 0.5882 - val_accuracy: 0.8919\n","\n","Epoch 00337: val_accuracy did not improve from 0.94595\n","Epoch 338/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.4805 - val_accuracy: 0.8919\n","\n","Epoch 00338: val_accuracy did not improve from 0.94595\n","Epoch 339/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.4677 - val_accuracy: 0.8986\n","\n","Epoch 00339: val_accuracy did not improve from 0.94595\n","Epoch 340/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0206 - accuracy: 0.9953 - val_loss: 0.4827 - val_accuracy: 0.9054\n","\n","Epoch 00340: val_accuracy did not improve from 0.94595\n","Epoch 341/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.4021 - val_accuracy: 0.9054\n","\n","Epoch 00341: val_accuracy did not improve from 0.94595\n","Epoch 342/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.4296 - val_accuracy: 0.8851\n","\n","Epoch 00342: val_accuracy did not improve from 0.94595\n","Epoch 343/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.4384 - val_accuracy: 0.8986\n","\n","Epoch 00343: val_accuracy did not improve from 0.94595\n","Epoch 344/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.4333 - val_accuracy: 0.8986\n","\n","Epoch 00344: val_accuracy did not improve from 0.94595\n","Epoch 345/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.5348 - val_accuracy: 0.8919\n","\n","Epoch 00345: val_accuracy did not improve from 0.94595\n","Epoch 346/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.5414 - val_accuracy: 0.8919\n","\n","Epoch 00346: val_accuracy did not improve from 0.94595\n","Epoch 347/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0047 - accuracy: 0.9974 - val_loss: 0.5837 - val_accuracy: 0.8784\n","\n","Epoch 00347: val_accuracy did not improve from 0.94595\n","Epoch 348/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.4667 - val_accuracy: 0.8851\n","\n","Epoch 00348: val_accuracy did not improve from 0.94595\n","Epoch 349/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0094 - accuracy: 0.9953 - val_loss: 0.4164 - val_accuracy: 0.9189\n","\n","Epoch 00349: val_accuracy did not improve from 0.94595\n","Epoch 350/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.5177 - val_accuracy: 0.8986\n","\n","Epoch 00350: val_accuracy did not improve from 0.94595\n","Epoch 351/500\n","238/238 [==============================] - 17s 69ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.4457 - val_accuracy: 0.8986\n","\n","Epoch 00351: val_accuracy did not improve from 0.94595\n","Epoch 352/500\n","238/238 [==============================] - 17s 69ms/step - loss: 8.8364e-04 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.8919\n","\n","Epoch 00352: val_accuracy did not improve from 0.94595\n","Epoch 353/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0017 - accuracy: 0.9989 - val_loss: 0.5484 - val_accuracy: 0.9122\n","\n","Epoch 00353: val_accuracy did not improve from 0.94595\n","Epoch 354/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.6447 - val_accuracy: 0.8986\n","\n","Epoch 00354: val_accuracy did not improve from 0.94595\n","Epoch 355/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0128 - accuracy: 0.9942 - val_loss: 0.7886 - val_accuracy: 0.8649\n","\n","Epoch 00355: val_accuracy did not improve from 0.94595\n","Epoch 356/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.6604 - val_accuracy: 0.8919\n","\n","Epoch 00356: val_accuracy did not improve from 0.94595\n","Epoch 357/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.6595 - val_accuracy: 0.8784\n","\n","Epoch 00357: val_accuracy did not improve from 0.94595\n","Epoch 358/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.5398 - val_accuracy: 0.8986\n","\n","Epoch 00358: val_accuracy did not improve from 0.94595\n","Epoch 359/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.5641 - val_accuracy: 0.9324\n","\n","Epoch 00359: val_accuracy did not improve from 0.94595\n","Epoch 360/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.2812 - val_accuracy: 0.9662\n","\n","Epoch 00360: val_accuracy improved from 0.94595 to 0.96622, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_1.h5\n","Epoch 361/500\n","238/238 [==============================] - 18s 74ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.3940 - val_accuracy: 0.9189\n","\n","Epoch 00361: val_accuracy did not improve from 0.96622\n","Epoch 362/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.5461 - val_accuracy: 0.9189\n","\n","Epoch 00362: val_accuracy did not improve from 0.96622\n","Epoch 363/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.8578 - val_accuracy: 0.9054\n","\n","Epoch 00363: val_accuracy did not improve from 0.96622\n","Epoch 364/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.5540 - val_accuracy: 0.9189\n","\n","Epoch 00364: val_accuracy did not improve from 0.96622\n","Epoch 365/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.7112 - val_accuracy: 0.8986\n","\n","Epoch 00365: val_accuracy did not improve from 0.96622\n","Epoch 366/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.4189 - val_accuracy: 0.9189\n","\n","Epoch 00366: val_accuracy did not improve from 0.96622\n","Epoch 367/500\n","238/238 [==============================] - 17s 70ms/step - loss: 7.6478e-04 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9392\n","\n","Epoch 00367: val_accuracy did not improve from 0.96622\n","Epoch 368/500\n","238/238 [==============================] - 17s 70ms/step - loss: 2.5693e-04 - accuracy: 1.0000 - val_loss: 0.3974 - val_accuracy: 0.9257\n","\n","Epoch 00368: val_accuracy did not improve from 0.96622\n","Epoch 369/500\n","238/238 [==============================] - 17s 70ms/step - loss: 8.8103e-04 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.8986\n","\n","Epoch 00369: val_accuracy did not improve from 0.96622\n","Epoch 370/500\n","238/238 [==============================] - 17s 71ms/step - loss: 8.5309e-04 - accuracy: 0.9995 - val_loss: 0.4725 - val_accuracy: 0.8986\n","\n","Epoch 00370: val_accuracy did not improve from 0.96622\n","Epoch 371/500\n","238/238 [==============================] - 17s 70ms/step - loss: 3.8625e-04 - accuracy: 1.0000 - val_loss: 0.4409 - val_accuracy: 0.8986\n","\n","Epoch 00371: val_accuracy did not improve from 0.96622\n","Epoch 372/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.7625 - val_accuracy: 0.8784\n","\n","Epoch 00372: val_accuracy did not improve from 0.96622\n","Epoch 373/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0398 - accuracy: 0.9905 - val_loss: 0.4534 - val_accuracy: 0.9189\n","\n","Epoch 00373: val_accuracy did not improve from 0.96622\n","Epoch 374/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.9164 - val_accuracy: 0.8919\n","\n","Epoch 00374: val_accuracy did not improve from 0.96622\n","Epoch 375/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.5307 - val_accuracy: 0.9054\n","\n","Epoch 00375: val_accuracy did not improve from 0.96622\n","Epoch 376/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.5887 - val_accuracy: 0.9189\n","\n","Epoch 00376: val_accuracy did not improve from 0.96622\n","Epoch 377/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.4950 - val_accuracy: 0.9054\n","\n","Epoch 00377: val_accuracy did not improve from 0.96622\n","Epoch 378/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.5363 - val_accuracy: 0.9054\n","\n","Epoch 00378: val_accuracy did not improve from 0.96622\n","Epoch 379/500\n","238/238 [==============================] - 17s 70ms/step - loss: 3.8364e-04 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 0.8919\n","\n","Epoch 00379: val_accuracy did not improve from 0.96622\n","Epoch 380/500\n","238/238 [==============================] - 17s 70ms/step - loss: 9.7701e-04 - accuracy: 1.0000 - val_loss: 0.6041 - val_accuracy: 0.8986\n","\n","Epoch 00380: val_accuracy did not improve from 0.96622\n","Epoch 381/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.6261 - val_accuracy: 0.8919\n","\n","Epoch 00381: val_accuracy did not improve from 0.96622\n","Epoch 382/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.7119 - val_accuracy: 0.9257\n","\n","Epoch 00382: val_accuracy did not improve from 0.96622\n","Epoch 383/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0403 - accuracy: 0.9911 - val_loss: 0.3324 - val_accuracy: 0.9122\n","\n","Epoch 00383: val_accuracy did not improve from 0.96622\n","Epoch 384/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.5667 - val_accuracy: 0.8919\n","\n","Epoch 00384: val_accuracy did not improve from 0.96622\n","Epoch 385/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.5608 - val_accuracy: 0.9054\n","\n","Epoch 00385: val_accuracy did not improve from 0.96622\n","Epoch 386/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.6954 - val_accuracy: 0.8919\n","\n","Epoch 00386: val_accuracy did not improve from 0.96622\n","Epoch 387/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0105 - accuracy: 0.9953 - val_loss: 0.6490 - val_accuracy: 0.8919\n","\n","Epoch 00387: val_accuracy did not improve from 0.96622\n","Epoch 388/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.4786 - val_accuracy: 0.9054\n","\n","Epoch 00388: val_accuracy did not improve from 0.96622\n","Epoch 389/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3829 - val_accuracy: 0.9392\n","\n","Epoch 00389: val_accuracy did not improve from 0.96622\n","Epoch 390/500\n","238/238 [==============================] - 17s 70ms/step - loss: 5.3883e-04 - accuracy: 1.0000 - val_loss: 0.5158 - val_accuracy: 0.9122\n","\n","Epoch 00390: val_accuracy did not improve from 0.96622\n","Epoch 391/500\n","238/238 [==============================] - 17s 70ms/step - loss: 7.0742e-04 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.9392\n","\n","Epoch 00391: val_accuracy did not improve from 0.96622\n","Epoch 392/500\n","238/238 [==============================] - 17s 70ms/step - loss: 4.3301e-04 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 0.8986\n","\n","Epoch 00392: val_accuracy did not improve from 0.96622\n","Epoch 393/500\n","238/238 [==============================] - 17s 70ms/step - loss: 4.2732e-04 - accuracy: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.9122\n","\n","Epoch 00393: val_accuracy did not improve from 0.96622\n","Epoch 394/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.5944 - val_accuracy: 0.9257\n","\n","Epoch 00394: val_accuracy did not improve from 0.96622\n","Epoch 395/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0396 - accuracy: 0.9900 - val_loss: 0.8566 - val_accuracy: 0.8649\n","\n","Epoch 00395: val_accuracy did not improve from 0.96622\n","Epoch 396/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0093 - accuracy: 0.9958 - val_loss: 0.5538 - val_accuracy: 0.8919\n","\n","Epoch 00396: val_accuracy did not improve from 0.96622\n","Epoch 397/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.4252 - val_accuracy: 0.8986\n","\n","Epoch 00397: val_accuracy did not improve from 0.96622\n","Epoch 398/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5634 - val_accuracy: 0.8986\n","\n","Epoch 00398: val_accuracy did not improve from 0.96622\n","Epoch 399/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0232 - accuracy: 0.9963 - val_loss: 0.5469 - val_accuracy: 0.9054\n","\n","Epoch 00399: val_accuracy did not improve from 0.96622\n","Epoch 400/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0087 - accuracy: 0.9984 - val_loss: 0.4935 - val_accuracy: 0.9122\n","\n","Epoch 00400: val_accuracy did not improve from 0.96622\n","Epoch 401/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.5213 - val_accuracy: 0.9122\n","\n","Epoch 00401: val_accuracy did not improve from 0.96622\n","Epoch 402/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.5700 - val_accuracy: 0.8784\n","\n","Epoch 00402: val_accuracy did not improve from 0.96622\n","Epoch 403/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.4359 - val_accuracy: 0.9324\n","\n","Epoch 00403: val_accuracy did not improve from 0.96622\n","Epoch 404/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.6289 - val_accuracy: 0.8851\n","\n","Epoch 00404: val_accuracy did not improve from 0.96622\n","Epoch 405/500\n","238/238 [==============================] - 17s 70ms/step - loss: 8.4192e-04 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.9324\n","\n","Epoch 00405: val_accuracy did not improve from 0.96622\n","Epoch 406/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.7110 - val_accuracy: 0.9122\n","\n","Epoch 00406: val_accuracy did not improve from 0.96622\n","Epoch 407/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.5701 - val_accuracy: 0.9122\n","\n","Epoch 00407: val_accuracy did not improve from 0.96622\n","Epoch 408/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0318 - accuracy: 0.9911 - val_loss: 0.6360 - val_accuracy: 0.8851\n","\n","Epoch 00408: val_accuracy did not improve from 0.96622\n","Epoch 409/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.5553 - val_accuracy: 0.8986\n","\n","Epoch 00409: val_accuracy did not improve from 0.96622\n","Epoch 410/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.6279 - val_accuracy: 0.8649\n","\n","Epoch 00410: val_accuracy did not improve from 0.96622\n","Epoch 411/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.7253 - val_accuracy: 0.9054\n","\n","Epoch 00411: val_accuracy did not improve from 0.96622\n","Epoch 412/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.5456 - val_accuracy: 0.9054\n","\n","Epoch 00412: val_accuracy did not improve from 0.96622\n","Epoch 413/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.5775 - val_accuracy: 0.8986\n","\n","Epoch 00413: val_accuracy did not improve from 0.96622\n","Epoch 414/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.4083 - val_accuracy: 0.9189\n","\n","Epoch 00414: val_accuracy did not improve from 0.96622\n","Epoch 415/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0098 - accuracy: 0.9953 - val_loss: 0.5111 - val_accuracy: 0.9189\n","\n","Epoch 00415: val_accuracy did not improve from 0.96622\n","Epoch 416/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.7152 - val_accuracy: 0.8784\n","\n","Epoch 00416: val_accuracy did not improve from 0.96622\n","Epoch 417/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.3088 - val_accuracy: 0.9392\n","\n","Epoch 00417: val_accuracy did not improve from 0.96622\n","Epoch 418/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.3131 - val_accuracy: 0.9392\n","\n","Epoch 00418: val_accuracy did not improve from 0.96622\n","Epoch 419/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 0.4720 - val_accuracy: 0.9054\n","\n","Epoch 00419: val_accuracy did not improve from 0.96622\n","Epoch 420/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.4629 - val_accuracy: 0.9257\n","\n","Epoch 00420: val_accuracy did not improve from 0.96622\n","Epoch 421/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0117 - accuracy: 0.9984 - val_loss: 0.4348 - val_accuracy: 0.9054\n","\n","Epoch 00421: val_accuracy did not improve from 0.96622\n","Epoch 422/500\n","238/238 [==============================] - 17s 70ms/step - loss: 9.9564e-04 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.9459\n","\n","Epoch 00422: val_accuracy did not improve from 0.96622\n","Epoch 423/500\n","238/238 [==============================] - 17s 71ms/step - loss: 6.3114e-04 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9257\n","\n","Epoch 00423: val_accuracy did not improve from 0.96622\n","Epoch 424/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.4826 - val_accuracy: 0.9392\n","\n","Epoch 00424: val_accuracy did not improve from 0.96622\n","Epoch 425/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.6655 - val_accuracy: 0.9054\n","\n","Epoch 00425: val_accuracy did not improve from 0.96622\n","Epoch 426/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.7336 - val_accuracy: 0.8986\n","\n","Epoch 00426: val_accuracy did not improve from 0.96622\n","Epoch 427/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0120 - accuracy: 0.9984 - val_loss: 0.8765 - val_accuracy: 0.8919\n","\n","Epoch 00427: val_accuracy did not improve from 0.96622\n","Epoch 428/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.4445 - val_accuracy: 0.9189\n","\n","Epoch 00428: val_accuracy did not improve from 0.96622\n","Epoch 429/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0053 - accuracy: 0.9968 - val_loss: 0.4807 - val_accuracy: 0.9189\n","\n","Epoch 00429: val_accuracy did not improve from 0.96622\n","Epoch 430/500\n","238/238 [==============================] - 17s 71ms/step - loss: 4.0631e-04 - accuracy: 1.0000 - val_loss: 0.8032 - val_accuracy: 0.9189\n","\n","Epoch 00430: val_accuracy did not improve from 0.96622\n","Epoch 431/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 0.6642 - val_accuracy: 0.9054\n","\n","Epoch 00431: val_accuracy did not improve from 0.96622\n","Epoch 432/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0186 - accuracy: 0.9963 - val_loss: 0.7943 - val_accuracy: 0.8784\n","\n","Epoch 00432: val_accuracy did not improve from 0.96622\n","Epoch 433/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.5281 - val_accuracy: 0.9189\n","\n","Epoch 00433: val_accuracy did not improve from 0.96622\n","Epoch 434/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.5670 - val_accuracy: 0.9122\n","\n","Epoch 00434: val_accuracy did not improve from 0.96622\n","Epoch 435/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0017 - accuracy: 0.9989 - val_loss: 0.4964 - val_accuracy: 0.9122\n","\n","Epoch 00435: val_accuracy did not improve from 0.96622\n","Epoch 436/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.5882 - val_accuracy: 0.8919\n","\n","Epoch 00436: val_accuracy did not improve from 0.96622\n","Epoch 437/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.5301 - val_accuracy: 0.8919\n","\n","Epoch 00437: val_accuracy did not improve from 0.96622\n","Epoch 438/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.6693 - val_accuracy: 0.8919\n","\n","Epoch 00438: val_accuracy did not improve from 0.96622\n","Epoch 439/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.6843 - val_accuracy: 0.8716\n","\n","Epoch 00439: val_accuracy did not improve from 0.96622\n","Epoch 440/500\n","238/238 [==============================] - 17s 72ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.5113 - val_accuracy: 0.9122\n","\n","Epoch 00440: val_accuracy did not improve from 0.96622\n","Epoch 441/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.9122\n","\n","Epoch 00441: val_accuracy did not improve from 0.96622\n","Epoch 442/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.7481 - val_accuracy: 0.8986\n","\n","Epoch 00442: val_accuracy did not improve from 0.96622\n","Epoch 443/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.6956 - val_accuracy: 0.8851\n","\n","Epoch 00443: val_accuracy did not improve from 0.96622\n","Epoch 444/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0144 - accuracy: 0.9968 - val_loss: 0.6340 - val_accuracy: 0.8986\n","\n","Epoch 00444: val_accuracy did not improve from 0.96622\n","Epoch 445/500\n","238/238 [==============================] - 17s 72ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.6144 - val_accuracy: 0.8919\n","\n","Epoch 00445: val_accuracy did not improve from 0.96622\n","Epoch 446/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.4548 - val_accuracy: 0.9189\n","\n","Epoch 00446: val_accuracy did not improve from 0.96622\n","Epoch 447/500\n","238/238 [==============================] - 17s 72ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.6603 - val_accuracy: 0.9054\n","\n","Epoch 00447: val_accuracy did not improve from 0.96622\n","Epoch 448/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.5896 - val_accuracy: 0.8986\n","\n","Epoch 00448: val_accuracy did not improve from 0.96622\n","Epoch 449/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.5856 - val_accuracy: 0.8986\n","\n","Epoch 00449: val_accuracy did not improve from 0.96622\n","Epoch 450/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.5922 - val_accuracy: 0.9054\n","\n","Epoch 00450: val_accuracy did not improve from 0.96622\n","Epoch 451/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0038 - accuracy: 0.9979 - val_loss: 0.6928 - val_accuracy: 0.9054\n","\n","Epoch 00451: val_accuracy did not improve from 0.96622\n","Epoch 452/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.7022 - val_accuracy: 0.9054\n","\n","Epoch 00452: val_accuracy did not improve from 0.96622\n","Epoch 453/500\n","238/238 [==============================] - 17s 72ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.7298 - val_accuracy: 0.8716\n","\n","Epoch 00453: val_accuracy did not improve from 0.96622\n","Epoch 454/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.4012 - val_accuracy: 0.8919\n","\n","Epoch 00454: val_accuracy did not improve from 0.96622\n","Epoch 455/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.6400 - val_accuracy: 0.9054\n","\n","Epoch 00455: val_accuracy did not improve from 0.96622\n","Epoch 456/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.6263 - val_accuracy: 0.8986\n","\n","Epoch 00456: val_accuracy did not improve from 0.96622\n","Epoch 457/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.7087 - val_accuracy: 0.8986\n","\n","Epoch 00457: val_accuracy did not improve from 0.96622\n","Epoch 458/500\n","238/238 [==============================] - 17s 72ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.6424 - val_accuracy: 0.8986\n","\n","Epoch 00458: val_accuracy did not improve from 0.96622\n","Epoch 459/500\n","238/238 [==============================] - 17s 72ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.5216 - val_accuracy: 0.8649\n","\n","Epoch 00459: val_accuracy did not improve from 0.96622\n","Epoch 460/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.8919\n","\n","Epoch 00460: val_accuracy did not improve from 0.96622\n","Epoch 461/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.3996 - val_accuracy: 0.8986\n","\n","Epoch 00461: val_accuracy did not improve from 0.96622\n","Epoch 462/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0053 - accuracy: 0.9974 - val_loss: 0.4173 - val_accuracy: 0.9257\n","\n","Epoch 00462: val_accuracy did not improve from 0.96622\n","Epoch 463/500\n","238/238 [==============================] - 17s 72ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.5242 - val_accuracy: 0.9122\n","\n","Epoch 00463: val_accuracy did not improve from 0.96622\n","Epoch 464/500\n","238/238 [==============================] - 17s 71ms/step - loss: 9.0052e-04 - accuracy: 1.0000 - val_loss: 0.5473 - val_accuracy: 0.9054\n","\n","Epoch 00464: val_accuracy did not improve from 0.96622\n","Epoch 465/500\n","238/238 [==============================] - 17s 71ms/step - loss: 1.5889e-04 - accuracy: 1.0000 - val_loss: 0.6458 - val_accuracy: 0.8986\n","\n","Epoch 00465: val_accuracy did not improve from 0.96622\n","Epoch 466/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.4954 - val_accuracy: 0.9257\n","\n","Epoch 00466: val_accuracy did not improve from 0.96622\n","Epoch 467/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.5932 - val_accuracy: 0.8986\n","\n","Epoch 00467: val_accuracy did not improve from 0.96622\n","Epoch 468/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.6420 - val_accuracy: 0.9189\n","\n","Epoch 00468: val_accuracy did not improve from 0.96622\n","Epoch 469/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.4819 - val_accuracy: 0.9122\n","\n","Epoch 00469: val_accuracy did not improve from 0.96622\n","Epoch 470/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.7034 - val_accuracy: 0.8784\n","\n","Epoch 00470: val_accuracy did not improve from 0.96622\n","Epoch 471/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.5560 - val_accuracy: 0.8986\n","\n","Epoch 00471: val_accuracy did not improve from 0.96622\n","Epoch 472/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.5937 - val_accuracy: 0.9054\n","\n","Epoch 00472: val_accuracy did not improve from 0.96622\n","Epoch 473/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.9189\n","\n","Epoch 00473: val_accuracy did not improve from 0.96622\n","Epoch 474/500\n","238/238 [==============================] - 17s 72ms/step - loss: 7.7123e-04 - accuracy: 1.0000 - val_loss: 0.4703 - val_accuracy: 0.9054\n","\n","Epoch 00474: val_accuracy did not improve from 0.96622\n","Epoch 475/500\n","238/238 [==============================] - 17s 71ms/step - loss: 1.5657e-04 - accuracy: 1.0000 - val_loss: 0.5351 - val_accuracy: 0.9189\n","\n","Epoch 00475: val_accuracy did not improve from 0.96622\n","Epoch 476/500\n","238/238 [==============================] - 17s 71ms/step - loss: 8.6400e-04 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.8851\n","\n","Epoch 00476: val_accuracy did not improve from 0.96622\n","Epoch 477/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.6837 - val_accuracy: 0.8649\n","\n","Epoch 00477: val_accuracy did not improve from 0.96622\n","Epoch 478/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.6300 - val_accuracy: 0.8919\n","\n","Epoch 00478: val_accuracy did not improve from 0.96622\n","Epoch 479/500\n","238/238 [==============================] - 17s 70ms/step - loss: 8.9111e-04 - accuracy: 1.0000 - val_loss: 0.5581 - val_accuracy: 0.9122\n","\n","Epoch 00479: val_accuracy did not improve from 0.96622\n","Epoch 480/500\n","238/238 [==============================] - 17s 70ms/step - loss: 7.5545e-04 - accuracy: 1.0000 - val_loss: 0.5163 - val_accuracy: 0.9054\n","\n","Epoch 00480: val_accuracy did not improve from 0.96622\n","Epoch 481/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.6076 - val_accuracy: 0.8784\n","\n","Epoch 00481: val_accuracy did not improve from 0.96622\n","Epoch 482/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.5225 - val_accuracy: 0.9054\n","\n","Epoch 00482: val_accuracy did not improve from 0.96622\n","Epoch 483/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 0.3843 - val_accuracy: 0.9324\n","\n","Epoch 00483: val_accuracy did not improve from 0.96622\n","Epoch 484/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.3579 - val_accuracy: 0.9257\n","\n","Epoch 00484: val_accuracy did not improve from 0.96622\n","Epoch 485/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.5538 - val_accuracy: 0.9054\n","\n","Epoch 00485: val_accuracy did not improve from 0.96622\n","Epoch 486/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.4577 - val_accuracy: 0.9257\n","\n","Epoch 00486: val_accuracy did not improve from 0.96622\n","Epoch 487/500\n","238/238 [==============================] - 17s 71ms/step - loss: 5.4630e-04 - accuracy: 1.0000 - val_loss: 0.5039 - val_accuracy: 0.9054\n","\n","Epoch 00487: val_accuracy did not improve from 0.96622\n","Epoch 488/500\n","238/238 [==============================] - 17s 70ms/step - loss: 5.5432e-04 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.8986\n","\n","Epoch 00488: val_accuracy did not improve from 0.96622\n","Epoch 489/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.5629 - val_accuracy: 0.9122\n","\n","Epoch 00489: val_accuracy did not improve from 0.96622\n","Epoch 490/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0122 - accuracy: 0.9984 - val_loss: 0.5070 - val_accuracy: 0.9189\n","\n","Epoch 00490: val_accuracy did not improve from 0.96622\n","Epoch 491/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.8246 - val_accuracy: 0.8514\n","\n","Epoch 00491: val_accuracy did not improve from 0.96622\n","Epoch 492/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.5406 - val_accuracy: 0.9054\n","\n","Epoch 00492: val_accuracy did not improve from 0.96622\n","Epoch 493/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9054\n","\n","Epoch 00493: val_accuracy did not improve from 0.96622\n","Epoch 494/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.4158 - val_accuracy: 0.9324\n","\n","Epoch 00494: val_accuracy did not improve from 0.96622\n","Epoch 495/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.6100 - val_accuracy: 0.9054\n","\n","Epoch 00495: val_accuracy did not improve from 0.96622\n","Epoch 496/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0191 - accuracy: 0.9953 - val_loss: 0.6338 - val_accuracy: 0.8851\n","\n","Epoch 00496: val_accuracy did not improve from 0.96622\n","Epoch 497/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.5509 - val_accuracy: 0.9054\n","\n","Epoch 00497: val_accuracy did not improve from 0.96622\n","Epoch 498/500\n","238/238 [==============================] - 17s 70ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.5312 - val_accuracy: 0.8986\n","\n","Epoch 00498: val_accuracy did not improve from 0.96622\n","Epoch 499/500\n","238/238 [==============================] - 17s 71ms/step - loss: 6.7148e-04 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.9122\n","\n","Epoch 00499: val_accuracy did not improve from 0.96622\n","Epoch 500/500\n","238/238 [==============================] - 17s 71ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.5321 - val_accuracy: 0.8986\n","\n","Epoch 00500: val_accuracy did not improve from 0.96622\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc34ddcf810>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1632745705830,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"5c27d787-2f98-4ded-e67a-56f020c1ce46"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n","plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n","\n","plt.legend()\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1632745711064,"user_tz":-540,"elapsed":5245,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1632745712140,"user_tz":-540,"elapsed":543,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632745713071,"user_tz":-540,"elapsed":933,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"af29a75a-a023-46d2-e9d4-f1452f449d6a"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632745738677,"user_tz":-540,"elapsed":25613,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"9c0e4547-9109-4734-f815-abb97e33a2bf"},"source":["Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1632745739908,"user_tz":-540,"elapsed":1233,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1632745739909,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1632745741094,"user_tz":-540,"elapsed":1189,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1632745741095,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"model_predict\"] = Target_predict"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1632745752474,"user_tz":-540,"elapsed":11382,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['model_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","executionInfo":{"status":"ok","timestamp":1632745752475,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = submission[['id', 'digit']]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":16},"executionInfo":{"status":"ok","timestamp":1632745752476,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"bfd55f01-ce2e-44e3-d06e-6238dd0f4a00"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_bfdf4bf4-528f-4862-9774-b95617baeac2\", \"InceptionV3_1.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"lmZ06MWjdN2l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632745756016,"user_tz":-540,"elapsed":3548,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"9d386367-af94-4083-a727-7a792d93ef7f"},"source":["!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n","Installing collected packages: dacon-submit-api\n","Successfully installed dacon-submit-api-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"oVdKDp3mdOZA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632745770931,"user_tz":-540,"elapsed":14919,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"398f7aa2-dcc2-4bdf-951e-de0a756c7bbe"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","    # 파일경로\n","    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n","    # d9249@kyonggi.ac.kr\n","    # 대회 ID\n","    '235626',\n","    # d9249@kyonggi.ac.kr 팀이릉\n","    # 'iDeal9',\n","    # dodo9249@gmail.com 팀이름\n","    # 'iDeal96',\n","    # d9249.acc001@gmail.com\n","    'iDeal01',\n","    # meanideal96@gamil.com\n","    # 'iDeal02',\n","    # dodo402298@gmail.com\n","    # 'mean01',\n","    # d9249.acc002@gmail.com\n","    # 'mean02',\n","    # memo\n","    'd9249_kyonggi_ac_kr' )"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{'isSubmitted': True, 'detail': 'Success'}\n"]}]}]}