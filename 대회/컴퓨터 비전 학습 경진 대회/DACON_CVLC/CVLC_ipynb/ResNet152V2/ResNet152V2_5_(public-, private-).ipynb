{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet152V2_5_(public-, private-).ipynb","provenance":[{"file_id":"1Ks4BnsIQVSo6nrDm_GCFLP-tUWbMF7fV","timestamp":1632675649149},{"file_id":"1CqtLKNQRRuC325QEoXZHskfQDXw-hybx","timestamp":1632675617704},{"file_id":"12JaYWavZfXc3mxowUEN1hmoDHEhLE9kD","timestamp":1632669857913},{"file_id":"1mRQmgFDcxuga37ytSbeksdBDV8lXPuP_","timestamp":1632669810228},{"file_id":"1hSseuq321IM3Xw9iARWzPOzaWFGuSYps","timestamp":1632659933103},{"file_id":"1i84kOIoNMg1SDAOmCAl-iREVAA8REpRl","timestamp":1632659111522},{"file_id":"1aWKemyOVH_XXsufg6PEqpNJHCIODEQDQ","timestamp":1632658287256},{"file_id":"1ZUL9g9uU5gE9mjrGyZ_ZE6_ZMwE69CPb","timestamp":1632657078244},{"file_id":"1Xq9yUa0JgnqQUKKTfy3z54fip8tHOUVO","timestamp":1632649657584},{"file_id":"1g107jAyKQClzEQj_DMR2xU4rZ9qbJH5e","timestamp":1632649536640},{"file_id":"1Z6kuupfDyi8FoEAzxFaCF1zxYVFMOZLV","timestamp":1632555432723},{"file_id":"1EbR-z2BYoOKWzYoeQoCF6HChJXoczWOg","timestamp":1632529654720},{"file_id":"19UhJoIWtCbGyO-f3O4Ejh3cQm9HsELdp","timestamp":1632508748323},{"file_id":"1P94NU6OoLRtS_ewl8Rb7NPZqKyl6ScPt","timestamp":1632508239637},{"file_id":"1oYHEjU-CSdxlLxyB6mhRRnSPmxfEbe9-","timestamp":1632483693856},{"file_id":"1tY8RF_0awL36zd9hQqUN3JK-9i7JjSCs","timestamp":1632483672985},{"file_id":"1hfaa8YJTlfEKZL9us0XaxbDFzEg6QlrT","timestamp":1632483587193},{"file_id":"1ar0JVhm118hpsiDCU0yS0Ty83Lr95cSu","timestamp":1632438063611},{"file_id":"1ISSiU2DrdSTDMVmbAxc8Ql72Bwult8wi","timestamp":1632382754243},{"file_id":"1cmBIBf0Y6KY5nFGyXFWuz9pe-V3QXe84","timestamp":1632382703200},{"file_id":"1NmDQbVBw3bmj4dkYxCWjOgHGEPxn2knZ","timestamp":1632382649241},{"file_id":"1h-FhrHH66IwjTlqiffpUdtWJZ47_06LZ","timestamp":1632332735991},{"file_id":"174isfXxsoXsuFjV-4wlPn8FyvhQelSZa","timestamp":1632264352072},{"file_id":"1rvvO3AZYRa3O0L25N-Kx2tXg3SO3ZLMb","timestamp":1632207962186},{"file_id":"10a77ENeqwaxgwFA_yCVpQBXkA9Fdts6t","timestamp":1632177040567},{"file_id":"1FLQ4OWmjzgDT_6nR4k61mlxJ0RbQfLbW","timestamp":1632127337902},{"file_id":"1L21WYacshipXDSgj75p87xRajwZ-yYEf","timestamp":1632125266824},{"file_id":"1gXw-oagzF1c49Ds2rFNXBNA-Jjj0YTGM","timestamp":1632125231955},{"file_id":"1odc6VzTolz3PuXSezCpAr8zqRhjlzJFc","timestamp":1632032770915},{"file_id":"1MLPQlf1Ig6rev94yP2Zy_hjHPEwnJWKr","timestamp":1631962707157},{"file_id":"1RFXq_y4na26GX1TMhOCKZvjIKxWZgQei","timestamp":1631894145495},{"file_id":"1j4_hnK2KjlLPPPkDR5LUdjrgcl7E5VJ2","timestamp":1631892272403},{"file_id":"1p_d4XYROzKVVUxBHxjuVx1gTinsguwp8","timestamp":1631892211512},{"file_id":"1qviqzhy3AgjpFc3P2QLjjqfHnbk3izT5","timestamp":1631892086873},{"file_id":"1rE8G1jItkQTqd3bvVGDHTrM9ONajBm2k","timestamp":1631891790249},{"file_id":"https://github.com/d9249/DACON/blob/main/CVLC_05_No_Data_Argmentation(public_0_81862_private_0_76593).ipynb","timestamp":1627056180265}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g0yI4jO4W5lx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632737205430,"user_tz":-540,"elapsed":476,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"56de6b00-dcaf-4c1b-c931-8ee10f95ca4b"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Sep 27 10:06:49 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632737227490,"user_tz":-540,"elapsed":22066,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"117c1f0a-bed5-4daa-ae9e-1898dbe7a934"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj"},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo"},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg"},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc"},"source":["for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTkw3fo6icZm"},"source":["model_save = 'ResNet152V2_5'\n","Target_model = 'ResNet152V2_model'\n","Target_predict = 'ResNet152V2_predict'\n","Target_acc = 'ResNet152V2_acc'\n","Target_val = 'ResNet152V2_val'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK"},"source":["import tensorflow as tf\n","Target_model =  tf.keras.applications.ResNet152V2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ"},"source":["Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632737259528,"user_tz":-540,"elapsed":23,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"f9ffc50a-913d-4853-a739-3bf39f481ccc"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator (\n","    rescale = 1./255, \n","    validation_split = 0.075,\n","    rotation_range = 15,\n","    width_shift_range = 0.00,\n","    height_shift_range = 0.05 )\n","\n","batch_size = 8\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1900 images belonging to 10 classes.\n","Found 148 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY"},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632756658004,"user_tz":-540,"elapsed":1126902,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"8e2f77d1-d25b-4104-8178-9674c98a91e8"},"source":["Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":12,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/500\n","238/238 [==============================] - 70s 168ms/step - loss: 2.0631 - accuracy: 0.3116 - val_loss: 7.9232 - val_accuracy: 0.1149\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.11486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_5.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/500\n","238/238 [==============================] - 38s 161ms/step - loss: 1.4700 - accuracy: 0.5032 - val_loss: 2.5536 - val_accuracy: 0.3986\n","\n","Epoch 00002: val_accuracy improved from 0.11486 to 0.39865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_5.h5\n","Epoch 3/500\n","238/238 [==============================] - 38s 161ms/step - loss: 1.1266 - accuracy: 0.6295 - val_loss: 1.0159 - val_accuracy: 0.6959\n","\n","Epoch 00003: val_accuracy improved from 0.39865 to 0.69595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_5.h5\n","Epoch 4/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.9503 - accuracy: 0.6884 - val_loss: 6.8621 - val_accuracy: 0.1757\n","\n","Epoch 00004: val_accuracy did not improve from 0.69595\n","Epoch 5/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.8085 - accuracy: 0.7342 - val_loss: 1.1107 - val_accuracy: 0.6689\n","\n","Epoch 00005: val_accuracy did not improve from 0.69595\n","Epoch 6/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.7635 - accuracy: 0.7411 - val_loss: 0.5990 - val_accuracy: 0.7838\n","\n","Epoch 00006: val_accuracy improved from 0.69595 to 0.78378, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_5.h5\n","Epoch 7/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.7735 - accuracy: 0.7453 - val_loss: 0.9387 - val_accuracy: 0.7162\n","\n","Epoch 00007: val_accuracy did not improve from 0.78378\n","Epoch 8/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.6552 - accuracy: 0.7795 - val_loss: 2.8850 - val_accuracy: 0.4459\n","\n","Epoch 00008: val_accuracy did not improve from 0.78378\n","Epoch 9/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.6834 - accuracy: 0.7763 - val_loss: 12.5822 - val_accuracy: 0.0946\n","\n","Epoch 00009: val_accuracy did not improve from 0.78378\n","Epoch 10/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.6169 - accuracy: 0.7974 - val_loss: 0.8313 - val_accuracy: 0.7500\n","\n","Epoch 00010: val_accuracy did not improve from 0.78378\n","Epoch 11/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.5111 - accuracy: 0.8316 - val_loss: 0.6707 - val_accuracy: 0.7838\n","\n","Epoch 00011: val_accuracy did not improve from 0.78378\n","Epoch 12/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.5437 - accuracy: 0.8263 - val_loss: 0.5986 - val_accuracy: 0.8311\n","\n","Epoch 00012: val_accuracy improved from 0.78378 to 0.83108, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_5.h5\n","Epoch 13/500\n","238/238 [==============================] - 38s 162ms/step - loss: 0.5499 - accuracy: 0.8279 - val_loss: 0.9043 - val_accuracy: 0.7162\n","\n","Epoch 00013: val_accuracy did not improve from 0.83108\n","Epoch 14/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.4859 - accuracy: 0.8363 - val_loss: 0.5146 - val_accuracy: 0.8311\n","\n","Epoch 00014: val_accuracy did not improve from 0.83108\n","Epoch 15/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.4763 - accuracy: 0.8389 - val_loss: 0.5316 - val_accuracy: 0.8311\n","\n","Epoch 00015: val_accuracy did not improve from 0.83108\n","Epoch 16/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.4431 - accuracy: 0.8589 - val_loss: 0.6368 - val_accuracy: 0.8041\n","\n","Epoch 00016: val_accuracy did not improve from 0.83108\n","Epoch 17/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.4446 - accuracy: 0.8505 - val_loss: 0.6541 - val_accuracy: 0.8243\n","\n","Epoch 00017: val_accuracy did not improve from 0.83108\n","Epoch 18/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.4037 - accuracy: 0.8674 - val_loss: 0.3674 - val_accuracy: 0.8851\n","\n","Epoch 00018: val_accuracy improved from 0.83108 to 0.88514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_5.h5\n","Epoch 19/500\n","238/238 [==============================] - 38s 162ms/step - loss: 0.4143 - accuracy: 0.8589 - val_loss: 0.4417 - val_accuracy: 0.8649\n","\n","Epoch 00019: val_accuracy did not improve from 0.88514\n","Epoch 20/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.3216 - accuracy: 0.8911 - val_loss: 0.7941 - val_accuracy: 0.7230\n","\n","Epoch 00020: val_accuracy did not improve from 0.88514\n","Epoch 21/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.3896 - accuracy: 0.8763 - val_loss: 0.7334 - val_accuracy: 0.7703\n","\n","Epoch 00021: val_accuracy did not improve from 0.88514\n","Epoch 22/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.3577 - accuracy: 0.8795 - val_loss: 0.4666 - val_accuracy: 0.8514\n","\n","Epoch 00022: val_accuracy did not improve from 0.88514\n","Epoch 23/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.3650 - accuracy: 0.8732 - val_loss: 0.9855 - val_accuracy: 0.7027\n","\n","Epoch 00023: val_accuracy did not improve from 0.88514\n","Epoch 24/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.3163 - accuracy: 0.8932 - val_loss: 0.6822 - val_accuracy: 0.7838\n","\n","Epoch 00024: val_accuracy did not improve from 0.88514\n","Epoch 25/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.3606 - accuracy: 0.8805 - val_loss: 0.3513 - val_accuracy: 0.8716\n","\n","Epoch 00025: val_accuracy did not improve from 0.88514\n","Epoch 26/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.2986 - accuracy: 0.9011 - val_loss: 0.6095 - val_accuracy: 0.8041\n","\n","Epoch 00026: val_accuracy did not improve from 0.88514\n","Epoch 27/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.3022 - accuracy: 0.9053 - val_loss: 0.4273 - val_accuracy: 0.8581\n","\n","Epoch 00027: val_accuracy did not improve from 0.88514\n","Epoch 28/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.2782 - accuracy: 0.9074 - val_loss: 0.7396 - val_accuracy: 0.8176\n","\n","Epoch 00028: val_accuracy did not improve from 0.88514\n","Epoch 29/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.2817 - accuracy: 0.9126 - val_loss: 0.3653 - val_accuracy: 0.8716\n","\n","Epoch 00029: val_accuracy did not improve from 0.88514\n","Epoch 30/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.2826 - accuracy: 0.9016 - val_loss: 0.3487 - val_accuracy: 0.8784\n","\n","Epoch 00030: val_accuracy did not improve from 0.88514\n","Epoch 31/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.2152 - accuracy: 0.9258 - val_loss: 0.6309 - val_accuracy: 0.8378\n","\n","Epoch 00031: val_accuracy did not improve from 0.88514\n","Epoch 32/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.2801 - accuracy: 0.9042 - val_loss: 0.4752 - val_accuracy: 0.8514\n","\n","Epoch 00032: val_accuracy did not improve from 0.88514\n","Epoch 33/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.2601 - accuracy: 0.9158 - val_loss: 0.6787 - val_accuracy: 0.8176\n","\n","Epoch 00033: val_accuracy did not improve from 0.88514\n","Epoch 34/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.2104 - accuracy: 0.9247 - val_loss: 0.6187 - val_accuracy: 0.8311\n","\n","Epoch 00034: val_accuracy did not improve from 0.88514\n","Epoch 35/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.2633 - accuracy: 0.9132 - val_loss: 4.5368 - val_accuracy: 0.2905\n","\n","Epoch 00035: val_accuracy did not improve from 0.88514\n","Epoch 36/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1992 - accuracy: 0.9284 - val_loss: 0.4489 - val_accuracy: 0.8446\n","\n","Epoch 00036: val_accuracy did not improve from 0.88514\n","Epoch 37/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.2015 - accuracy: 0.9326 - val_loss: 0.4553 - val_accuracy: 0.8378\n","\n","Epoch 00037: val_accuracy did not improve from 0.88514\n","Epoch 38/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.1996 - accuracy: 0.9305 - val_loss: 0.5167 - val_accuracy: 0.8446\n","\n","Epoch 00038: val_accuracy did not improve from 0.88514\n","Epoch 39/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.2147 - accuracy: 0.9284 - val_loss: 0.6651 - val_accuracy: 0.8108\n","\n","Epoch 00039: val_accuracy did not improve from 0.88514\n","Epoch 40/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1686 - accuracy: 0.9453 - val_loss: 0.4150 - val_accuracy: 0.8851\n","\n","Epoch 00040: val_accuracy did not improve from 0.88514\n","Epoch 41/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.1731 - accuracy: 0.9411 - val_loss: 0.5819 - val_accuracy: 0.8378\n","\n","Epoch 00041: val_accuracy did not improve from 0.88514\n","Epoch 42/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1731 - accuracy: 0.9374 - val_loss: 0.4470 - val_accuracy: 0.8446\n","\n","Epoch 00042: val_accuracy did not improve from 0.88514\n","Epoch 43/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1975 - accuracy: 0.9295 - val_loss: 0.5347 - val_accuracy: 0.8649\n","\n","Epoch 00043: val_accuracy did not improve from 0.88514\n","Epoch 44/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1336 - accuracy: 0.9532 - val_loss: 0.4267 - val_accuracy: 0.8649\n","\n","Epoch 00044: val_accuracy did not improve from 0.88514\n","Epoch 45/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.2140 - accuracy: 0.9274 - val_loss: 0.7832 - val_accuracy: 0.7838\n","\n","Epoch 00045: val_accuracy did not improve from 0.88514\n","Epoch 46/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1641 - accuracy: 0.9468 - val_loss: 0.5001 - val_accuracy: 0.8716\n","\n","Epoch 00046: val_accuracy did not improve from 0.88514\n","Epoch 47/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.1118 - accuracy: 0.9600 - val_loss: 0.6808 - val_accuracy: 0.8243\n","\n","Epoch 00047: val_accuracy did not improve from 0.88514\n","Epoch 48/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1753 - accuracy: 0.9405 - val_loss: 0.4722 - val_accuracy: 0.8716\n","\n","Epoch 00048: val_accuracy did not improve from 0.88514\n","Epoch 49/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1841 - accuracy: 0.9432 - val_loss: 0.6208 - val_accuracy: 0.7973\n","\n","Epoch 00049: val_accuracy did not improve from 0.88514\n","Epoch 50/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1319 - accuracy: 0.9547 - val_loss: 0.2667 - val_accuracy: 0.8986\n","\n","Epoch 00050: val_accuracy improved from 0.88514 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_5.h5\n","Epoch 51/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.1406 - accuracy: 0.9495 - val_loss: 0.3645 - val_accuracy: 0.8851\n","\n","Epoch 00051: val_accuracy did not improve from 0.89865\n","Epoch 52/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1488 - accuracy: 0.9511 - val_loss: 0.3526 - val_accuracy: 0.8716\n","\n","Epoch 00052: val_accuracy did not improve from 0.89865\n","Epoch 53/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1110 - accuracy: 0.9595 - val_loss: 0.4213 - val_accuracy: 0.8514\n","\n","Epoch 00053: val_accuracy did not improve from 0.89865\n","Epoch 54/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1076 - accuracy: 0.9605 - val_loss: 0.3820 - val_accuracy: 0.8514\n","\n","Epoch 00054: val_accuracy did not improve from 0.89865\n","Epoch 55/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1022 - accuracy: 0.9626 - val_loss: 0.3201 - val_accuracy: 0.8986\n","\n","Epoch 00055: val_accuracy did not improve from 0.89865\n","Epoch 56/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1258 - accuracy: 0.9616 - val_loss: 0.5790 - val_accuracy: 0.8378\n","\n","Epoch 00056: val_accuracy did not improve from 0.89865\n","Epoch 57/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1034 - accuracy: 0.9647 - val_loss: 0.4296 - val_accuracy: 0.8378\n","\n","Epoch 00057: val_accuracy did not improve from 0.89865\n","Epoch 58/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0666 - accuracy: 0.9779 - val_loss: 0.4814 - val_accuracy: 0.8378\n","\n","Epoch 00058: val_accuracy did not improve from 0.89865\n","Epoch 59/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1583 - accuracy: 0.9511 - val_loss: 1.0402 - val_accuracy: 0.7973\n","\n","Epoch 00059: val_accuracy did not improve from 0.89865\n","Epoch 60/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1130 - accuracy: 0.9584 - val_loss: 0.6731 - val_accuracy: 0.8243\n","\n","Epoch 00060: val_accuracy did not improve from 0.89865\n","Epoch 61/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0950 - accuracy: 0.9653 - val_loss: 0.4069 - val_accuracy: 0.8716\n","\n","Epoch 00061: val_accuracy did not improve from 0.89865\n","Epoch 62/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0713 - accuracy: 0.9753 - val_loss: 0.5229 - val_accuracy: 0.8649\n","\n","Epoch 00062: val_accuracy did not improve from 0.89865\n","Epoch 63/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0816 - accuracy: 0.9711 - val_loss: 0.4831 - val_accuracy: 0.8581\n","\n","Epoch 00063: val_accuracy did not improve from 0.89865\n","Epoch 64/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0772 - accuracy: 0.9705 - val_loss: 0.9795 - val_accuracy: 0.7838\n","\n","Epoch 00064: val_accuracy did not improve from 0.89865\n","Epoch 65/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.1039 - accuracy: 0.9642 - val_loss: 0.5425 - val_accuracy: 0.8378\n","\n","Epoch 00065: val_accuracy did not improve from 0.89865\n","Epoch 66/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1025 - accuracy: 0.9684 - val_loss: 0.4690 - val_accuracy: 0.8581\n","\n","Epoch 00066: val_accuracy did not improve from 0.89865\n","Epoch 67/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.1130 - accuracy: 0.9642 - val_loss: 0.3258 - val_accuracy: 0.8716\n","\n","Epoch 00067: val_accuracy did not improve from 0.89865\n","Epoch 68/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0901 - accuracy: 0.9721 - val_loss: 0.6285 - val_accuracy: 0.8649\n","\n","Epoch 00068: val_accuracy did not improve from 0.89865\n","Epoch 69/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1146 - accuracy: 0.9647 - val_loss: 0.4952 - val_accuracy: 0.8919\n","\n","Epoch 00069: val_accuracy did not improve from 0.89865\n","Epoch 70/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0609 - accuracy: 0.9821 - val_loss: 1.3003 - val_accuracy: 0.6824\n","\n","Epoch 00070: val_accuracy did not improve from 0.89865\n","Epoch 71/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0878 - accuracy: 0.9737 - val_loss: 0.5051 - val_accuracy: 0.8919\n","\n","Epoch 00071: val_accuracy did not improve from 0.89865\n","Epoch 72/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0890 - accuracy: 0.9674 - val_loss: 0.8000 - val_accuracy: 0.8311\n","\n","Epoch 00072: val_accuracy did not improve from 0.89865\n","Epoch 73/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.1028 - accuracy: 0.9621 - val_loss: 0.5082 - val_accuracy: 0.8716\n","\n","Epoch 00073: val_accuracy did not improve from 0.89865\n","Epoch 74/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0411 - accuracy: 0.9889 - val_loss: 1.5856 - val_accuracy: 0.7095\n","\n","Epoch 00074: val_accuracy did not improve from 0.89865\n","Epoch 75/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0828 - accuracy: 0.9684 - val_loss: 0.5584 - val_accuracy: 0.8311\n","\n","Epoch 00075: val_accuracy did not improve from 0.89865\n","Epoch 76/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0934 - accuracy: 0.9721 - val_loss: 0.4098 - val_accuracy: 0.8784\n","\n","Epoch 00076: val_accuracy did not improve from 0.89865\n","Epoch 77/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0956 - accuracy: 0.9621 - val_loss: 0.4744 - val_accuracy: 0.8919\n","\n","Epoch 00077: val_accuracy did not improve from 0.89865\n","Epoch 78/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0868 - accuracy: 0.9684 - val_loss: 0.2501 - val_accuracy: 0.9189\n","\n","Epoch 00078: val_accuracy improved from 0.89865 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_5.h5\n","Epoch 79/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0565 - accuracy: 0.9853 - val_loss: 0.6757 - val_accuracy: 0.8919\n","\n","Epoch 00079: val_accuracy did not improve from 0.91892\n","Epoch 80/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0549 - accuracy: 0.9811 - val_loss: 0.2851 - val_accuracy: 0.9054\n","\n","Epoch 00080: val_accuracy did not improve from 0.91892\n","Epoch 81/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0350 - accuracy: 0.9905 - val_loss: 0.5687 - val_accuracy: 0.8919\n","\n","Epoch 00081: val_accuracy did not improve from 0.91892\n","Epoch 82/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0535 - accuracy: 0.9884 - val_loss: 0.5071 - val_accuracy: 0.8919\n","\n","Epoch 00082: val_accuracy did not improve from 0.91892\n","Epoch 83/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0446 - accuracy: 0.9853 - val_loss: 0.5232 - val_accuracy: 0.8581\n","\n","Epoch 00083: val_accuracy did not improve from 0.91892\n","Epoch 84/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0884 - accuracy: 0.9705 - val_loss: 0.8054 - val_accuracy: 0.8649\n","\n","Epoch 00084: val_accuracy did not improve from 0.91892\n","Epoch 85/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0891 - accuracy: 0.9700 - val_loss: 0.5376 - val_accuracy: 0.8378\n","\n","Epoch 00085: val_accuracy did not improve from 0.91892\n","Epoch 86/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0563 - accuracy: 0.9811 - val_loss: 0.4221 - val_accuracy: 0.8919\n","\n","Epoch 00086: val_accuracy did not improve from 0.91892\n","Epoch 87/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0541 - accuracy: 0.9805 - val_loss: 1.0307 - val_accuracy: 0.7973\n","\n","Epoch 00087: val_accuracy did not improve from 0.91892\n","Epoch 88/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 5.2692 - val_accuracy: 0.4257\n","\n","Epoch 00088: val_accuracy did not improve from 0.91892\n","Epoch 89/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0691 - accuracy: 0.9726 - val_loss: 0.6589 - val_accuracy: 0.8378\n","\n","Epoch 00089: val_accuracy did not improve from 0.91892\n","Epoch 90/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0750 - accuracy: 0.9784 - val_loss: 0.6434 - val_accuracy: 0.8514\n","\n","Epoch 00090: val_accuracy did not improve from 0.91892\n","Epoch 91/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 0.3594 - val_accuracy: 0.8986\n","\n","Epoch 00091: val_accuracy did not improve from 0.91892\n","Epoch 92/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0432 - accuracy: 0.9853 - val_loss: 0.6002 - val_accuracy: 0.8649\n","\n","Epoch 00092: val_accuracy did not improve from 0.91892\n","Epoch 93/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0665 - accuracy: 0.9774 - val_loss: 0.7048 - val_accuracy: 0.8446\n","\n","Epoch 00093: val_accuracy did not improve from 0.91892\n","Epoch 94/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0552 - accuracy: 0.9811 - val_loss: 0.4570 - val_accuracy: 0.8986\n","\n","Epoch 00094: val_accuracy did not improve from 0.91892\n","Epoch 95/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0487 - accuracy: 0.9837 - val_loss: 0.6054 - val_accuracy: 0.8716\n","\n","Epoch 00095: val_accuracy did not improve from 0.91892\n","Epoch 96/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0664 - accuracy: 0.9774 - val_loss: 0.3915 - val_accuracy: 0.9122\n","\n","Epoch 00096: val_accuracy did not improve from 0.91892\n","Epoch 97/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0290 - accuracy: 0.9874 - val_loss: 0.5173 - val_accuracy: 0.8851\n","\n","Epoch 00097: val_accuracy did not improve from 0.91892\n","Epoch 98/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0374 - accuracy: 0.9868 - val_loss: 0.4753 - val_accuracy: 0.9122\n","\n","Epoch 00098: val_accuracy did not improve from 0.91892\n","Epoch 99/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0500 - accuracy: 0.9837 - val_loss: 0.5614 - val_accuracy: 0.8784\n","\n","Epoch 00099: val_accuracy did not improve from 0.91892\n","Epoch 100/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0481 - accuracy: 0.9826 - val_loss: 0.4634 - val_accuracy: 0.8716\n","\n","Epoch 00100: val_accuracy did not improve from 0.91892\n","Epoch 101/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0582 - accuracy: 0.9805 - val_loss: 0.7486 - val_accuracy: 0.8649\n","\n","Epoch 00101: val_accuracy did not improve from 0.91892\n","Epoch 102/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 2.2466 - val_accuracy: 0.5676\n","\n","Epoch 00102: val_accuracy did not improve from 0.91892\n","Epoch 103/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0265 - accuracy: 0.9932 - val_loss: 0.7115 - val_accuracy: 0.8311\n","\n","Epoch 00103: val_accuracy did not improve from 0.91892\n","Epoch 104/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0269 - accuracy: 0.9911 - val_loss: 0.5162 - val_accuracy: 0.8919\n","\n","Epoch 00104: val_accuracy did not improve from 0.91892\n","Epoch 105/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0667 - accuracy: 0.9768 - val_loss: 0.5024 - val_accuracy: 0.8581\n","\n","Epoch 00105: val_accuracy did not improve from 0.91892\n","Epoch 106/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0599 - accuracy: 0.9816 - val_loss: 0.4763 - val_accuracy: 0.8716\n","\n","Epoch 00106: val_accuracy did not improve from 0.91892\n","Epoch 107/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0342 - accuracy: 0.9879 - val_loss: 0.6260 - val_accuracy: 0.8581\n","\n","Epoch 00107: val_accuracy did not improve from 0.91892\n","Epoch 108/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0361 - accuracy: 0.9858 - val_loss: 0.4619 - val_accuracy: 0.8784\n","\n","Epoch 00108: val_accuracy did not improve from 0.91892\n","Epoch 109/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0406 - accuracy: 0.9832 - val_loss: 0.7233 - val_accuracy: 0.8311\n","\n","Epoch 00109: val_accuracy did not improve from 0.91892\n","Epoch 110/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0340 - accuracy: 0.9874 - val_loss: 0.3980 - val_accuracy: 0.9122\n","\n","Epoch 00110: val_accuracy did not improve from 0.91892\n","Epoch 111/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0357 - accuracy: 0.9868 - val_loss: 0.5706 - val_accuracy: 0.8514\n","\n","Epoch 00111: val_accuracy did not improve from 0.91892\n","Epoch 112/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0639 - accuracy: 0.9774 - val_loss: 0.9523 - val_accuracy: 0.7703\n","\n","Epoch 00112: val_accuracy did not improve from 0.91892\n","Epoch 113/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0507 - accuracy: 0.9805 - val_loss: 0.3131 - val_accuracy: 0.9122\n","\n","Epoch 00113: val_accuracy did not improve from 0.91892\n","Epoch 114/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.3346 - val_accuracy: 0.9122\n","\n","Epoch 00114: val_accuracy did not improve from 0.91892\n","Epoch 115/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0405 - accuracy: 0.9863 - val_loss: 0.3588 - val_accuracy: 0.8851\n","\n","Epoch 00115: val_accuracy did not improve from 0.91892\n","Epoch 116/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0478 - accuracy: 0.9826 - val_loss: 0.5342 - val_accuracy: 0.8649\n","\n","Epoch 00116: val_accuracy did not improve from 0.91892\n","Epoch 117/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0189 - accuracy: 0.9932 - val_loss: 0.5184 - val_accuracy: 0.8851\n","\n","Epoch 00117: val_accuracy did not improve from 0.91892\n","Epoch 118/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0394 - accuracy: 0.9900 - val_loss: 0.3705 - val_accuracy: 0.9054\n","\n","Epoch 00118: val_accuracy did not improve from 0.91892\n","Epoch 119/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.5123 - val_accuracy: 0.8649\n","\n","Epoch 00119: val_accuracy did not improve from 0.91892\n","Epoch 120/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0168 - accuracy: 0.9958 - val_loss: 0.3267 - val_accuracy: 0.9054\n","\n","Epoch 00120: val_accuracy did not improve from 0.91892\n","Epoch 121/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0600 - accuracy: 0.9811 - val_loss: 0.5396 - val_accuracy: 0.8649\n","\n","Epoch 00121: val_accuracy did not improve from 0.91892\n","Epoch 122/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0347 - accuracy: 0.9879 - val_loss: 0.6262 - val_accuracy: 0.8919\n","\n","Epoch 00122: val_accuracy did not improve from 0.91892\n","Epoch 123/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0301 - accuracy: 0.9895 - val_loss: 0.4319 - val_accuracy: 0.9054\n","\n","Epoch 00123: val_accuracy did not improve from 0.91892\n","Epoch 124/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0287 - accuracy: 0.9911 - val_loss: 0.6824 - val_accuracy: 0.8446\n","\n","Epoch 00124: val_accuracy did not improve from 0.91892\n","Epoch 125/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 0.5979 - val_accuracy: 0.8716\n","\n","Epoch 00125: val_accuracy did not improve from 0.91892\n","Epoch 126/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0543 - accuracy: 0.9826 - val_loss: 0.5168 - val_accuracy: 0.8581\n","\n","Epoch 00126: val_accuracy did not improve from 0.91892\n","Epoch 127/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.6351 - val_accuracy: 0.8514\n","\n","Epoch 00127: val_accuracy did not improve from 0.91892\n","Epoch 128/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0403 - accuracy: 0.9863 - val_loss: 0.6583 - val_accuracy: 0.8649\n","\n","Epoch 00128: val_accuracy did not improve from 0.91892\n","Epoch 129/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0387 - accuracy: 0.9847 - val_loss: 0.5196 - val_accuracy: 0.9054\n","\n","Epoch 00129: val_accuracy did not improve from 0.91892\n","Epoch 130/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.5579 - val_accuracy: 0.8784\n","\n","Epoch 00130: val_accuracy did not improve from 0.91892\n","Epoch 131/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0340 - accuracy: 0.9884 - val_loss: 0.5831 - val_accuracy: 0.8649\n","\n","Epoch 00131: val_accuracy did not improve from 0.91892\n","Epoch 132/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0762 - accuracy: 0.9742 - val_loss: 0.5488 - val_accuracy: 0.8649\n","\n","Epoch 00132: val_accuracy did not improve from 0.91892\n","Epoch 133/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0616 - accuracy: 0.9768 - val_loss: 0.4760 - val_accuracy: 0.8716\n","\n","Epoch 00133: val_accuracy did not improve from 0.91892\n","Epoch 134/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.6458 - val_accuracy: 0.8784\n","\n","Epoch 00134: val_accuracy did not improve from 0.91892\n","Epoch 135/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0192 - accuracy: 0.9926 - val_loss: 0.3740 - val_accuracy: 0.8851\n","\n","Epoch 00135: val_accuracy did not improve from 0.91892\n","Epoch 136/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.5670 - val_accuracy: 0.8311\n","\n","Epoch 00136: val_accuracy did not improve from 0.91892\n","Epoch 137/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0536 - accuracy: 0.9842 - val_loss: 0.5650 - val_accuracy: 0.8784\n","\n","Epoch 00137: val_accuracy did not improve from 0.91892\n","Epoch 138/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.4255 - val_accuracy: 0.8851\n","\n","Epoch 00138: val_accuracy did not improve from 0.91892\n","Epoch 139/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0184 - accuracy: 0.9958 - val_loss: 0.4425 - val_accuracy: 0.8784\n","\n","Epoch 00139: val_accuracy did not improve from 0.91892\n","Epoch 140/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0352 - accuracy: 0.9889 - val_loss: 0.5331 - val_accuracy: 0.8716\n","\n","Epoch 00140: val_accuracy did not improve from 0.91892\n","Epoch 141/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.6339 - val_accuracy: 0.8446\n","\n","Epoch 00141: val_accuracy did not improve from 0.91892\n","Epoch 142/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.4990 - val_accuracy: 0.8716\n","\n","Epoch 00142: val_accuracy did not improve from 0.91892\n","Epoch 143/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.5007 - val_accuracy: 0.8851\n","\n","Epoch 00143: val_accuracy did not improve from 0.91892\n","Epoch 144/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0341 - accuracy: 0.9879 - val_loss: 0.6621 - val_accuracy: 0.8514\n","\n","Epoch 00144: val_accuracy did not improve from 0.91892\n","Epoch 145/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0660 - accuracy: 0.9784 - val_loss: 0.7827 - val_accuracy: 0.8446\n","\n","Epoch 00145: val_accuracy did not improve from 0.91892\n","Epoch 146/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.6122 - val_accuracy: 0.8514\n","\n","Epoch 00146: val_accuracy did not improve from 0.91892\n","Epoch 147/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0394 - accuracy: 0.9868 - val_loss: 0.7442 - val_accuracy: 0.8514\n","\n","Epoch 00147: val_accuracy did not improve from 0.91892\n","Epoch 148/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.4210 - val_accuracy: 0.8919\n","\n","Epoch 00148: val_accuracy did not improve from 0.91892\n","Epoch 149/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0260 - accuracy: 0.9905 - val_loss: 0.6101 - val_accuracy: 0.8919\n","\n","Epoch 00149: val_accuracy did not improve from 0.91892\n","Epoch 150/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.5903 - val_accuracy: 0.8851\n","\n","Epoch 00150: val_accuracy did not improve from 0.91892\n","Epoch 151/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.5037 - val_accuracy: 0.8986\n","\n","Epoch 00151: val_accuracy did not improve from 0.91892\n","Epoch 152/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 0.5986 - val_accuracy: 0.8716\n","\n","Epoch 00152: val_accuracy did not improve from 0.91892\n","Epoch 153/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0460 - accuracy: 0.9863 - val_loss: 0.7088 - val_accuracy: 0.8919\n","\n","Epoch 00153: val_accuracy did not improve from 0.91892\n","Epoch 154/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0364 - accuracy: 0.9868 - val_loss: 0.6257 - val_accuracy: 0.8919\n","\n","Epoch 00154: val_accuracy did not improve from 0.91892\n","Epoch 155/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0185 - accuracy: 0.9958 - val_loss: 0.4722 - val_accuracy: 0.8716\n","\n","Epoch 00155: val_accuracy did not improve from 0.91892\n","Epoch 156/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0170 - accuracy: 0.9974 - val_loss: 0.4150 - val_accuracy: 0.8919\n","\n","Epoch 00156: val_accuracy did not improve from 0.91892\n","Epoch 157/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0303 - accuracy: 0.9900 - val_loss: 0.5404 - val_accuracy: 0.8784\n","\n","Epoch 00157: val_accuracy did not improve from 0.91892\n","Epoch 158/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0494 - accuracy: 0.9842 - val_loss: 0.6746 - val_accuracy: 0.8784\n","\n","Epoch 00158: val_accuracy did not improve from 0.91892\n","Epoch 159/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.4551 - val_accuracy: 0.8986\n","\n","Epoch 00159: val_accuracy did not improve from 0.91892\n","Epoch 160/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.5314 - val_accuracy: 0.8446\n","\n","Epoch 00160: val_accuracy did not improve from 0.91892\n","Epoch 161/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.4673 - val_accuracy: 0.8919\n","\n","Epoch 00161: val_accuracy did not improve from 0.91892\n","Epoch 162/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0339 - accuracy: 0.9895 - val_loss: 0.3455 - val_accuracy: 0.9189\n","\n","Epoch 00162: val_accuracy did not improve from 0.91892\n","Epoch 163/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.8105 - val_accuracy: 0.8716\n","\n","Epoch 00163: val_accuracy did not improve from 0.91892\n","Epoch 164/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0127 - accuracy: 0.9947 - val_loss: 0.8144 - val_accuracy: 0.8581\n","\n","Epoch 00164: val_accuracy did not improve from 0.91892\n","Epoch 165/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.4946 - val_accuracy: 0.8851\n","\n","Epoch 00165: val_accuracy did not improve from 0.91892\n","Epoch 166/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0391 - accuracy: 0.9842 - val_loss: 0.6073 - val_accuracy: 0.8784\n","\n","Epoch 00166: val_accuracy did not improve from 0.91892\n","Epoch 167/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.4690 - val_accuracy: 0.8986\n","\n","Epoch 00167: val_accuracy did not improve from 0.91892\n","Epoch 168/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.7353 - val_accuracy: 0.8581\n","\n","Epoch 00168: val_accuracy did not improve from 0.91892\n","Epoch 169/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.5858 - val_accuracy: 0.8986\n","\n","Epoch 00169: val_accuracy did not improve from 0.91892\n","Epoch 170/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.6101 - val_accuracy: 0.8514\n","\n","Epoch 00170: val_accuracy did not improve from 0.91892\n","Epoch 171/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0244 - accuracy: 0.9900 - val_loss: 0.6524 - val_accuracy: 0.8716\n","\n","Epoch 00171: val_accuracy did not improve from 0.91892\n","Epoch 172/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0293 - accuracy: 0.9889 - val_loss: 0.6000 - val_accuracy: 0.8649\n","\n","Epoch 00172: val_accuracy did not improve from 0.91892\n","Epoch 173/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0256 - accuracy: 0.9905 - val_loss: 0.5488 - val_accuracy: 0.8716\n","\n","Epoch 00173: val_accuracy did not improve from 0.91892\n","Epoch 174/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0376 - accuracy: 0.9868 - val_loss: 0.7100 - val_accuracy: 0.8581\n","\n","Epoch 00174: val_accuracy did not improve from 0.91892\n","Epoch 175/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.6825 - val_accuracy: 0.8716\n","\n","Epoch 00175: val_accuracy did not improve from 0.91892\n","Epoch 176/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0254 - accuracy: 0.9937 - val_loss: 0.4525 - val_accuracy: 0.8919\n","\n","Epoch 00176: val_accuracy did not improve from 0.91892\n","Epoch 177/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0440 - accuracy: 0.9868 - val_loss: 0.6131 - val_accuracy: 0.8514\n","\n","Epoch 00177: val_accuracy did not improve from 0.91892\n","Epoch 178/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.6053 - val_accuracy: 0.8716\n","\n","Epoch 00178: val_accuracy did not improve from 0.91892\n","Epoch 179/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.7133 - val_accuracy: 0.8649\n","\n","Epoch 00179: val_accuracy did not improve from 0.91892\n","Epoch 180/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.6282 - val_accuracy: 0.8581\n","\n","Epoch 00180: val_accuracy did not improve from 0.91892\n","Epoch 181/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.4921 - val_accuracy: 0.8716\n","\n","Epoch 00181: val_accuracy did not improve from 0.91892\n","Epoch 182/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.5368 - val_accuracy: 0.9054\n","\n","Epoch 00182: val_accuracy did not improve from 0.91892\n","Epoch 183/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0389 - accuracy: 0.9868 - val_loss: 0.9074 - val_accuracy: 0.8514\n","\n","Epoch 00183: val_accuracy did not improve from 0.91892\n","Epoch 184/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0311 - accuracy: 0.9884 - val_loss: 0.6726 - val_accuracy: 0.8581\n","\n","Epoch 00184: val_accuracy did not improve from 0.91892\n","Epoch 185/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0152 - accuracy: 0.9937 - val_loss: 0.5097 - val_accuracy: 0.8919\n","\n","Epoch 00185: val_accuracy did not improve from 0.91892\n","Epoch 186/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.4150 - val_accuracy: 0.9189\n","\n","Epoch 00186: val_accuracy did not improve from 0.91892\n","Epoch 187/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0243 - accuracy: 0.9884 - val_loss: 0.6642 - val_accuracy: 0.8784\n","\n","Epoch 00187: val_accuracy did not improve from 0.91892\n","Epoch 188/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.5174 - val_accuracy: 0.8649\n","\n","Epoch 00188: val_accuracy did not improve from 0.91892\n","Epoch 189/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.6022 - val_accuracy: 0.9054\n","\n","Epoch 00189: val_accuracy did not improve from 0.91892\n","Epoch 190/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 5.7339 - val_accuracy: 0.3581\n","\n","Epoch 00190: val_accuracy did not improve from 0.91892\n","Epoch 191/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0411 - accuracy: 0.9889 - val_loss: 0.7731 - val_accuracy: 0.8649\n","\n","Epoch 00191: val_accuracy did not improve from 0.91892\n","Epoch 192/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.5650 - val_accuracy: 0.8986\n","\n","Epoch 00192: val_accuracy did not improve from 0.91892\n","Epoch 193/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0274 - accuracy: 0.9932 - val_loss: 0.4692 - val_accuracy: 0.8986\n","\n","Epoch 00193: val_accuracy did not improve from 0.91892\n","Epoch 194/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0325 - accuracy: 0.9868 - val_loss: 0.6397 - val_accuracy: 0.8716\n","\n","Epoch 00194: val_accuracy did not improve from 0.91892\n","Epoch 195/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.4208 - val_accuracy: 0.9054\n","\n","Epoch 00195: val_accuracy did not improve from 0.91892\n","Epoch 196/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.3943 - val_accuracy: 0.8919\n","\n","Epoch 00196: val_accuracy did not improve from 0.91892\n","Epoch 197/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0236 - accuracy: 0.9905 - val_loss: 0.5047 - val_accuracy: 0.9054\n","\n","Epoch 00197: val_accuracy did not improve from 0.91892\n","Epoch 198/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0104 - accuracy: 0.9958 - val_loss: 0.7601 - val_accuracy: 0.8784\n","\n","Epoch 00198: val_accuracy did not improve from 0.91892\n","Epoch 199/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.5088 - val_accuracy: 0.9122\n","\n","Epoch 00199: val_accuracy did not improve from 0.91892\n","Epoch 200/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.4176 - val_accuracy: 0.9054\n","\n","Epoch 00200: val_accuracy did not improve from 0.91892\n","Epoch 201/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.4151 - val_accuracy: 0.9122\n","\n","Epoch 00201: val_accuracy did not improve from 0.91892\n","Epoch 202/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.4855 - val_accuracy: 0.8851\n","\n","Epoch 00202: val_accuracy did not improve from 0.91892\n","Epoch 203/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.5466 - val_accuracy: 0.9054\n","\n","Epoch 00203: val_accuracy did not improve from 0.91892\n","Epoch 204/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.4229 - val_accuracy: 0.8986\n","\n","Epoch 00204: val_accuracy did not improve from 0.91892\n","Epoch 205/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5247 - val_accuracy: 0.9054\n","\n","Epoch 00205: val_accuracy did not improve from 0.91892\n","Epoch 206/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0225 - accuracy: 0.9947 - val_loss: 0.5561 - val_accuracy: 0.8986\n","\n","Epoch 00206: val_accuracy did not improve from 0.91892\n","Epoch 207/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0403 - accuracy: 0.9853 - val_loss: 0.8644 - val_accuracy: 0.8176\n","\n","Epoch 00207: val_accuracy did not improve from 0.91892\n","Epoch 208/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.8470 - val_accuracy: 0.8581\n","\n","Epoch 00208: val_accuracy did not improve from 0.91892\n","Epoch 209/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0132 - accuracy: 0.9942 - val_loss: 0.6626 - val_accuracy: 0.8716\n","\n","Epoch 00209: val_accuracy did not improve from 0.91892\n","Epoch 210/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.7965 - val_accuracy: 0.8514\n","\n","Epoch 00210: val_accuracy did not improve from 0.91892\n","Epoch 211/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0761 - accuracy: 0.9784 - val_loss: 0.6296 - val_accuracy: 0.8851\n","\n","Epoch 00211: val_accuracy did not improve from 0.91892\n","Epoch 212/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.4995 - val_accuracy: 0.9122\n","\n","Epoch 00212: val_accuracy did not improve from 0.91892\n","Epoch 213/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.4334 - val_accuracy: 0.9189\n","\n","Epoch 00213: val_accuracy did not improve from 0.91892\n","Epoch 214/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.4304 - val_accuracy: 0.8919\n","\n","Epoch 00214: val_accuracy did not improve from 0.91892\n","Epoch 215/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0126 - accuracy: 0.9942 - val_loss: 0.3998 - val_accuracy: 0.9054\n","\n","Epoch 00215: val_accuracy did not improve from 0.91892\n","Epoch 216/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.3482 - val_accuracy: 0.9122\n","\n","Epoch 00216: val_accuracy did not improve from 0.91892\n","Epoch 217/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.5447 - val_accuracy: 0.9054\n","\n","Epoch 00217: val_accuracy did not improve from 0.91892\n","Epoch 218/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.3184 - val_accuracy: 0.9189\n","\n","Epoch 00218: val_accuracy did not improve from 0.91892\n","Epoch 219/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.6434 - val_accuracy: 0.8851\n","\n","Epoch 00219: val_accuracy did not improve from 0.91892\n","Epoch 220/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.8259 - val_accuracy: 0.8446\n","\n","Epoch 00220: val_accuracy did not improve from 0.91892\n","Epoch 221/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0363 - accuracy: 0.9895 - val_loss: 0.4513 - val_accuracy: 0.8784\n","\n","Epoch 00221: val_accuracy did not improve from 0.91892\n","Epoch 222/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0406 - accuracy: 0.9847 - val_loss: 0.4226 - val_accuracy: 0.9054\n","\n","Epoch 00222: val_accuracy did not improve from 0.91892\n","Epoch 223/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0234 - accuracy: 0.9942 - val_loss: 0.5675 - val_accuracy: 0.8986\n","\n","Epoch 00223: val_accuracy did not improve from 0.91892\n","Epoch 224/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0277 - accuracy: 0.9900 - val_loss: 0.3859 - val_accuracy: 0.8919\n","\n","Epoch 00224: val_accuracy did not improve from 0.91892\n","Epoch 225/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.4180 - val_accuracy: 0.9392\n","\n","Epoch 00225: val_accuracy improved from 0.91892 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_5.h5\n","Epoch 226/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.6887 - val_accuracy: 0.8581\n","\n","Epoch 00226: val_accuracy did not improve from 0.93919\n","Epoch 227/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.4977 - val_accuracy: 0.9054\n","\n","Epoch 00227: val_accuracy did not improve from 0.93919\n","Epoch 228/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0097 - accuracy: 0.9958 - val_loss: 0.4091 - val_accuracy: 0.9189\n","\n","Epoch 00228: val_accuracy did not improve from 0.93919\n","Epoch 229/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.4027 - val_accuracy: 0.9324\n","\n","Epoch 00229: val_accuracy did not improve from 0.93919\n","Epoch 230/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0056 - accuracy: 0.9974 - val_loss: 0.2920 - val_accuracy: 0.9324\n","\n","Epoch 00230: val_accuracy did not improve from 0.93919\n","Epoch 231/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.4314 - val_accuracy: 0.9257\n","\n","Epoch 00231: val_accuracy did not improve from 0.93919\n","Epoch 232/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0322 - accuracy: 0.9905 - val_loss: 0.5560 - val_accuracy: 0.8784\n","\n","Epoch 00232: val_accuracy did not improve from 0.93919\n","Epoch 233/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.4069 - val_accuracy: 0.9122\n","\n","Epoch 00233: val_accuracy did not improve from 0.93919\n","Epoch 234/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.7167 - val_accuracy: 0.8784\n","\n","Epoch 00234: val_accuracy did not improve from 0.93919\n","Epoch 235/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0412 - accuracy: 0.9874 - val_loss: 0.5656 - val_accuracy: 0.8851\n","\n","Epoch 00235: val_accuracy did not improve from 0.93919\n","Epoch 236/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.4503 - val_accuracy: 0.8716\n","\n","Epoch 00236: val_accuracy did not improve from 0.93919\n","Epoch 237/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.4542 - val_accuracy: 0.9054\n","\n","Epoch 00237: val_accuracy did not improve from 0.93919\n","Epoch 238/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.3432 - val_accuracy: 0.9257\n","\n","Epoch 00238: val_accuracy did not improve from 0.93919\n","Epoch 239/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.5504 - val_accuracy: 0.8851\n","\n","Epoch 00239: val_accuracy did not improve from 0.93919\n","Epoch 240/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0207 - accuracy: 0.9905 - val_loss: 0.8709 - val_accuracy: 0.8514\n","\n","Epoch 00240: val_accuracy did not improve from 0.93919\n","Epoch 241/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 0.4940 - val_accuracy: 0.8851\n","\n","Epoch 00241: val_accuracy did not improve from 0.93919\n","Epoch 242/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0169 - accuracy: 0.9932 - val_loss: 0.4725 - val_accuracy: 0.9054\n","\n","Epoch 00242: val_accuracy did not improve from 0.93919\n","Epoch 243/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.9253 - val_accuracy: 0.8514\n","\n","Epoch 00243: val_accuracy did not improve from 0.93919\n","Epoch 244/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.6467 - val_accuracy: 0.8919\n","\n","Epoch 00244: val_accuracy did not improve from 0.93919\n","Epoch 245/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 0.6051 - val_accuracy: 0.8784\n","\n","Epoch 00245: val_accuracy did not improve from 0.93919\n","Epoch 246/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0359 - accuracy: 0.9905 - val_loss: 0.7896 - val_accuracy: 0.8919\n","\n","Epoch 00246: val_accuracy did not improve from 0.93919\n","Epoch 247/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.5280 - val_accuracy: 0.9122\n","\n","Epoch 00247: val_accuracy did not improve from 0.93919\n","Epoch 248/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.4120 - val_accuracy: 0.9054\n","\n","Epoch 00248: val_accuracy did not improve from 0.93919\n","Epoch 249/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.4459 - val_accuracy: 0.9189\n","\n","Epoch 00249: val_accuracy did not improve from 0.93919\n","Epoch 250/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5574 - val_accuracy: 0.8919\n","\n","Epoch 00250: val_accuracy did not improve from 0.93919\n","Epoch 251/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4426 - val_accuracy: 0.8919\n","\n","Epoch 00251: val_accuracy did not improve from 0.93919\n","Epoch 252/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.5447 - val_accuracy: 0.8986\n","\n","Epoch 00252: val_accuracy did not improve from 0.93919\n","Epoch 253/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0353 - accuracy: 0.9921 - val_loss: 0.9026 - val_accuracy: 0.8649\n","\n","Epoch 00253: val_accuracy did not improve from 0.93919\n","Epoch 254/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.5405 - val_accuracy: 0.8851\n","\n","Epoch 00254: val_accuracy did not improve from 0.93919\n","Epoch 255/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.4370 - val_accuracy: 0.8851\n","\n","Epoch 00255: val_accuracy did not improve from 0.93919\n","Epoch 256/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.5507 - val_accuracy: 0.9054\n","\n","Epoch 00256: val_accuracy did not improve from 0.93919\n","Epoch 257/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.4958 - val_accuracy: 0.9054\n","\n","Epoch 00257: val_accuracy did not improve from 0.93919\n","Epoch 258/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0264 - accuracy: 0.9953 - val_loss: 0.5213 - val_accuracy: 0.8919\n","\n","Epoch 00258: val_accuracy did not improve from 0.93919\n","Epoch 259/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.3830 - val_accuracy: 0.9392\n","\n","Epoch 00259: val_accuracy did not improve from 0.93919\n","Epoch 260/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.4849 - val_accuracy: 0.9122\n","\n","Epoch 00260: val_accuracy did not improve from 0.93919\n","Epoch 261/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.3845 - val_accuracy: 0.9459\n","\n","Epoch 00261: val_accuracy improved from 0.93919 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_5.h5\n","Epoch 262/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.4345 - val_accuracy: 0.9189\n","\n","Epoch 00262: val_accuracy did not improve from 0.94595\n","Epoch 263/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.4186 - val_accuracy: 0.9189\n","\n","Epoch 00263: val_accuracy did not improve from 0.94595\n","Epoch 264/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.4578 - val_accuracy: 0.9122\n","\n","Epoch 00264: val_accuracy did not improve from 0.94595\n","Epoch 265/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.5018 - val_accuracy: 0.9189\n","\n","Epoch 00265: val_accuracy did not improve from 0.94595\n","Epoch 266/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3711 - val_accuracy: 0.9257\n","\n","Epoch 00266: val_accuracy did not improve from 0.94595\n","Epoch 267/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3816 - val_accuracy: 0.9122\n","\n","Epoch 00267: val_accuracy did not improve from 0.94595\n","Epoch 268/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4559 - val_accuracy: 0.9122\n","\n","Epoch 00268: val_accuracy did not improve from 0.94595\n","Epoch 269/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.4578 - val_accuracy: 0.9122\n","\n","Epoch 00269: val_accuracy did not improve from 0.94595\n","Epoch 270/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.4555 - val_accuracy: 0.9054\n","\n","Epoch 00270: val_accuracy did not improve from 0.94595\n","Epoch 271/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.5925 - val_accuracy: 0.9189\n","\n","Epoch 00271: val_accuracy did not improve from 0.94595\n","Epoch 272/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0447 - accuracy: 0.9842 - val_loss: 0.4988 - val_accuracy: 0.8851\n","\n","Epoch 00272: val_accuracy did not improve from 0.94595\n","Epoch 273/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.7623 - val_accuracy: 0.8649\n","\n","Epoch 00273: val_accuracy did not improve from 0.94595\n","Epoch 274/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.0213 - accuracy: 0.9947 - val_loss: 0.8279 - val_accuracy: 0.8446\n","\n","Epoch 00274: val_accuracy did not improve from 0.94595\n","Epoch 275/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0134 - accuracy: 0.9932 - val_loss: 0.8199 - val_accuracy: 0.8041\n","\n","Epoch 00275: val_accuracy did not improve from 0.94595\n","Epoch 276/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.5787 - val_accuracy: 0.8784\n","\n","Epoch 00276: val_accuracy did not improve from 0.94595\n","Epoch 277/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.5548 - val_accuracy: 0.8986\n","\n","Epoch 00277: val_accuracy did not improve from 0.94595\n","Epoch 278/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.5600 - val_accuracy: 0.8986\n","\n","Epoch 00278: val_accuracy did not improve from 0.94595\n","Epoch 279/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.8326 - val_accuracy: 0.8919\n","\n","Epoch 00279: val_accuracy did not improve from 0.94595\n","Epoch 280/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.6389 - val_accuracy: 0.8716\n","\n","Epoch 00280: val_accuracy did not improve from 0.94595\n","Epoch 281/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.6686 - val_accuracy: 0.8716\n","\n","Epoch 00281: val_accuracy did not improve from 0.94595\n","Epoch 282/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 1.3148 - val_accuracy: 0.8378\n","\n","Epoch 00282: val_accuracy did not improve from 0.94595\n","Epoch 283/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0644 - accuracy: 0.9832 - val_loss: 0.6353 - val_accuracy: 0.8851\n","\n","Epoch 00283: val_accuracy did not improve from 0.94595\n","Epoch 284/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.5351 - val_accuracy: 0.8378\n","\n","Epoch 00284: val_accuracy did not improve from 0.94595\n","Epoch 285/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.6376 - val_accuracy: 0.8649\n","\n","Epoch 00285: val_accuracy did not improve from 0.94595\n","Epoch 286/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.5143 - val_accuracy: 0.8784\n","\n","Epoch 00286: val_accuracy did not improve from 0.94595\n","Epoch 287/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4670 - val_accuracy: 0.8851\n","\n","Epoch 00287: val_accuracy did not improve from 0.94595\n","Epoch 288/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9122\n","\n","Epoch 00288: val_accuracy did not improve from 0.94595\n","Epoch 289/500\n","238/238 [==============================] - 38s 159ms/step - loss: 5.0441e-04 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.9189\n","\n","Epoch 00289: val_accuracy did not improve from 0.94595\n","Epoch 290/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.5336 - val_accuracy: 0.9122\n","\n","Epoch 00290: val_accuracy did not improve from 0.94595\n","Epoch 291/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.4856 - val_accuracy: 0.8851\n","\n","Epoch 00291: val_accuracy did not improve from 0.94595\n","Epoch 292/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.6144 - val_accuracy: 0.8919\n","\n","Epoch 00292: val_accuracy did not improve from 0.94595\n","Epoch 293/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0217 - accuracy: 0.9921 - val_loss: 0.5950 - val_accuracy: 0.8581\n","\n","Epoch 00293: val_accuracy did not improve from 0.94595\n","Epoch 294/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5054 - val_accuracy: 0.8784\n","\n","Epoch 00294: val_accuracy did not improve from 0.94595\n","Epoch 295/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.3968 - val_accuracy: 0.8784\n","\n","Epoch 00295: val_accuracy did not improve from 0.94595\n","Epoch 296/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.5333 - val_accuracy: 0.8581\n","\n","Epoch 00296: val_accuracy did not improve from 0.94595\n","Epoch 297/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.5418 - val_accuracy: 0.8716\n","\n","Epoch 00297: val_accuracy did not improve from 0.94595\n","Epoch 298/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.5273 - val_accuracy: 0.9054\n","\n","Epoch 00298: val_accuracy did not improve from 0.94595\n","Epoch 299/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0059 - accuracy: 0.9968 - val_loss: 0.6929 - val_accuracy: 0.8716\n","\n","Epoch 00299: val_accuracy did not improve from 0.94595\n","Epoch 300/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0327 - accuracy: 0.9895 - val_loss: 0.4644 - val_accuracy: 0.8784\n","\n","Epoch 00300: val_accuracy did not improve from 0.94595\n","Epoch 301/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0134 - accuracy: 0.9968 - val_loss: 0.4801 - val_accuracy: 0.8986\n","\n","Epoch 00301: val_accuracy did not improve from 0.94595\n","Epoch 302/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.8087 - val_accuracy: 0.8716\n","\n","Epoch 00302: val_accuracy did not improve from 0.94595\n","Epoch 303/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.5594 - val_accuracy: 0.8986\n","\n","Epoch 00303: val_accuracy did not improve from 0.94595\n","Epoch 304/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.4358 - val_accuracy: 0.9054\n","\n","Epoch 00304: val_accuracy did not improve from 0.94595\n","Epoch 305/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.5257 - val_accuracy: 0.8851\n","\n","Epoch 00305: val_accuracy did not improve from 0.94595\n","Epoch 306/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0181 - accuracy: 0.9958 - val_loss: 0.4925 - val_accuracy: 0.8851\n","\n","Epoch 00306: val_accuracy did not improve from 0.94595\n","Epoch 307/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.4496 - val_accuracy: 0.8919\n","\n","Epoch 00307: val_accuracy did not improve from 0.94595\n","Epoch 308/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.3169 - val_accuracy: 0.9189\n","\n","Epoch 00308: val_accuracy did not improve from 0.94595\n","Epoch 309/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4729 - val_accuracy: 0.9122\n","\n","Epoch 00309: val_accuracy did not improve from 0.94595\n","Epoch 310/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.4802 - val_accuracy: 0.9122\n","\n","Epoch 00310: val_accuracy did not improve from 0.94595\n","Epoch 311/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.8807 - val_accuracy: 0.8311\n","\n","Epoch 00311: val_accuracy did not improve from 0.94595\n","Epoch 312/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0250 - accuracy: 0.9937 - val_loss: 0.6672 - val_accuracy: 0.8716\n","\n","Epoch 00312: val_accuracy did not improve from 0.94595\n","Epoch 313/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.5105 - val_accuracy: 0.8919\n","\n","Epoch 00313: val_accuracy did not improve from 0.94595\n","Epoch 314/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.5514 - val_accuracy: 0.8716\n","\n","Epoch 00314: val_accuracy did not improve from 0.94595\n","Epoch 315/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.6574 - val_accuracy: 0.8649\n","\n","Epoch 00315: val_accuracy did not improve from 0.94595\n","Epoch 316/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.8986\n","\n","Epoch 00316: val_accuracy did not improve from 0.94595\n","Epoch 317/500\n","238/238 [==============================] - 38s 160ms/step - loss: 8.7344e-04 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.8851\n","\n","Epoch 00317: val_accuracy did not improve from 0.94595\n","Epoch 318/500\n","238/238 [==============================] - 38s 160ms/step - loss: 8.8928e-04 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.8851\n","\n","Epoch 00318: val_accuracy did not improve from 0.94595\n","Epoch 319/500\n","238/238 [==============================] - 38s 160ms/step - loss: 7.1828e-04 - accuracy: 1.0000 - val_loss: 0.5185 - val_accuracy: 0.8986\n","\n","Epoch 00319: val_accuracy did not improve from 0.94595\n","Epoch 320/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4476 - val_accuracy: 0.8851\n","\n","Epoch 00320: val_accuracy did not improve from 0.94595\n","Epoch 321/500\n","238/238 [==============================] - 38s 160ms/step - loss: 5.8906e-04 - accuracy: 1.0000 - val_loss: 0.5839 - val_accuracy: 0.8851\n","\n","Epoch 00321: val_accuracy did not improve from 0.94595\n","Epoch 322/500\n","238/238 [==============================] - 38s 160ms/step - loss: 8.7262e-04 - accuracy: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.8851\n","\n","Epoch 00322: val_accuracy did not improve from 0.94595\n","Epoch 323/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0174 - accuracy: 0.9932 - val_loss: 1.5694 - val_accuracy: 0.7770\n","\n","Epoch 00323: val_accuracy did not improve from 0.94595\n","Epoch 324/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0648 - accuracy: 0.9837 - val_loss: 0.6860 - val_accuracy: 0.8919\n","\n","Epoch 00324: val_accuracy did not improve from 0.94595\n","Epoch 325/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0246 - accuracy: 0.9911 - val_loss: 0.5412 - val_accuracy: 0.8851\n","\n","Epoch 00325: val_accuracy did not improve from 0.94595\n","Epoch 326/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.4397 - val_accuracy: 0.8649\n","\n","Epoch 00326: val_accuracy did not improve from 0.94595\n","Epoch 327/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.4413 - val_accuracy: 0.8851\n","\n","Epoch 00327: val_accuracy did not improve from 0.94595\n","Epoch 328/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.4440 - val_accuracy: 0.8919\n","\n","Epoch 00328: val_accuracy did not improve from 0.94595\n","Epoch 329/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.8986\n","\n","Epoch 00329: val_accuracy did not improve from 0.94595\n","Epoch 330/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.5643 - val_accuracy: 0.9054\n","\n","Epoch 00330: val_accuracy did not improve from 0.94595\n","Epoch 331/500\n","238/238 [==============================] - 39s 162ms/step - loss: 0.0224 - accuracy: 0.9916 - val_loss: 0.4736 - val_accuracy: 0.8851\n","\n","Epoch 00331: val_accuracy did not improve from 0.94595\n","Epoch 332/500\n","238/238 [==============================] - 38s 162ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.4711 - val_accuracy: 0.8986\n","\n","Epoch 00332: val_accuracy did not improve from 0.94595\n","Epoch 333/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4645 - val_accuracy: 0.8851\n","\n","Epoch 00333: val_accuracy did not improve from 0.94595\n","Epoch 334/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.5649 - val_accuracy: 0.8784\n","\n","Epoch 00334: val_accuracy did not improve from 0.94595\n","Epoch 335/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.9054\n","\n","Epoch 00335: val_accuracy did not improve from 0.94595\n","Epoch 336/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.4653 - val_accuracy: 0.8919\n","\n","Epoch 00336: val_accuracy did not improve from 0.94595\n","Epoch 337/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.7456 - val_accuracy: 0.8581\n","\n","Epoch 00337: val_accuracy did not improve from 0.94595\n","Epoch 338/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0330 - accuracy: 0.9905 - val_loss: 0.5982 - val_accuracy: 0.8851\n","\n","Epoch 00338: val_accuracy did not improve from 0.94595\n","Epoch 339/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.7250 - val_accuracy: 0.8716\n","\n","Epoch 00339: val_accuracy did not improve from 0.94595\n","Epoch 340/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.6003 - val_accuracy: 0.8851\n","\n","Epoch 00340: val_accuracy did not improve from 0.94595\n","Epoch 341/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.4732 - val_accuracy: 0.8919\n","\n","Epoch 00341: val_accuracy did not improve from 0.94595\n","Epoch 342/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.4874 - val_accuracy: 0.8514\n","\n","Epoch 00342: val_accuracy did not improve from 0.94595\n","Epoch 343/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 0.6766 - val_accuracy: 0.8851\n","\n","Epoch 00343: val_accuracy did not improve from 0.94595\n","Epoch 344/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0223 - accuracy: 0.9953 - val_loss: 0.5761 - val_accuracy: 0.8919\n","\n","Epoch 00344: val_accuracy did not improve from 0.94595\n","Epoch 345/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.5751 - val_accuracy: 0.8581\n","\n","Epoch 00345: val_accuracy did not improve from 0.94595\n","Epoch 346/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.4999 - val_accuracy: 0.9257\n","\n","Epoch 00346: val_accuracy did not improve from 0.94595\n","Epoch 347/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.4213 - val_accuracy: 0.9189\n","\n","Epoch 00347: val_accuracy did not improve from 0.94595\n","Epoch 348/500\n","238/238 [==============================] - 38s 160ms/step - loss: 4.9953e-04 - accuracy: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.9122\n","\n","Epoch 00348: val_accuracy did not improve from 0.94595\n","Epoch 349/500\n","238/238 [==============================] - 38s 160ms/step - loss: 6.4328e-04 - accuracy: 1.0000 - val_loss: 0.4090 - val_accuracy: 0.8986\n","\n","Epoch 00349: val_accuracy did not improve from 0.94595\n","Epoch 350/500\n","238/238 [==============================] - 38s 160ms/step - loss: 6.5590e-04 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.8919\n","\n","Epoch 00350: val_accuracy did not improve from 0.94595\n","Epoch 351/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.5559 - val_accuracy: 0.8919\n","\n","Epoch 00351: val_accuracy did not improve from 0.94595\n","Epoch 352/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 1.3153 - val_accuracy: 0.8581\n","\n","Epoch 00352: val_accuracy did not improve from 0.94595\n","Epoch 353/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0468 - accuracy: 0.9868 - val_loss: 0.9540 - val_accuracy: 0.8243\n","\n","Epoch 00353: val_accuracy did not improve from 0.94595\n","Epoch 354/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.6208 - val_accuracy: 0.8784\n","\n","Epoch 00354: val_accuracy did not improve from 0.94595\n","Epoch 355/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.5005 - val_accuracy: 0.8919\n","\n","Epoch 00355: val_accuracy did not improve from 0.94595\n","Epoch 356/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.6201 - val_accuracy: 0.8649\n","\n","Epoch 00356: val_accuracy did not improve from 0.94595\n","Epoch 357/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0079 - accuracy: 0.9968 - val_loss: 0.8196 - val_accuracy: 0.8514\n","\n","Epoch 00357: val_accuracy did not improve from 0.94595\n","Epoch 358/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.8784\n","\n","Epoch 00358: val_accuracy did not improve from 0.94595\n","Epoch 359/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.5019 - val_accuracy: 0.9122\n","\n","Epoch 00359: val_accuracy did not improve from 0.94595\n","Epoch 360/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.6880 - val_accuracy: 0.8919\n","\n","Epoch 00360: val_accuracy did not improve from 0.94595\n","Epoch 361/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.7954 - val_accuracy: 0.8851\n","\n","Epoch 00361: val_accuracy did not improve from 0.94595\n","Epoch 362/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.7073 - val_accuracy: 0.8919\n","\n","Epoch 00362: val_accuracy did not improve from 0.94595\n","Epoch 363/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.9222 - val_accuracy: 0.8243\n","\n","Epoch 00363: val_accuracy did not improve from 0.94595\n","Epoch 364/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.5138 - val_accuracy: 0.8986\n","\n","Epoch 00364: val_accuracy did not improve from 0.94595\n","Epoch 365/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0071 - accuracy: 0.9968 - val_loss: 0.7919 - val_accuracy: 0.8851\n","\n","Epoch 00365: val_accuracy did not improve from 0.94595\n","Epoch 366/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0112 - accuracy: 0.9953 - val_loss: 0.5714 - val_accuracy: 0.8784\n","\n","Epoch 00366: val_accuracy did not improve from 0.94595\n","Epoch 367/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.5708 - val_accuracy: 0.8919\n","\n","Epoch 00367: val_accuracy did not improve from 0.94595\n","Epoch 368/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.8667 - val_accuracy: 0.8649\n","\n","Epoch 00368: val_accuracy did not improve from 0.94595\n","Epoch 369/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.3287 - val_accuracy: 0.9189\n","\n","Epoch 00369: val_accuracy did not improve from 0.94595\n","Epoch 370/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.7958 - val_accuracy: 0.8446\n","\n","Epoch 00370: val_accuracy did not improve from 0.94595\n","Epoch 371/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.6967 - val_accuracy: 0.8919\n","\n","Epoch 00371: val_accuracy did not improve from 0.94595\n","Epoch 372/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.5335 - val_accuracy: 0.8851\n","\n","Epoch 00372: val_accuracy did not improve from 0.94595\n","Epoch 373/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.6496 - val_accuracy: 0.9054\n","\n","Epoch 00373: val_accuracy did not improve from 0.94595\n","Epoch 374/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.8874 - val_accuracy: 0.8514\n","\n","Epoch 00374: val_accuracy did not improve from 0.94595\n","Epoch 375/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.5241 - val_accuracy: 0.9054\n","\n","Epoch 00375: val_accuracy did not improve from 0.94595\n","Epoch 376/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 0.5668 - val_accuracy: 0.8784\n","\n","Epoch 00376: val_accuracy did not improve from 0.94595\n","Epoch 377/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.4982 - val_accuracy: 0.8851\n","\n","Epoch 00377: val_accuracy did not improve from 0.94595\n","Epoch 378/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.6069 - val_accuracy: 0.8986\n","\n","Epoch 00378: val_accuracy did not improve from 0.94595\n","Epoch 379/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0175 - accuracy: 0.9958 - val_loss: 0.7325 - val_accuracy: 0.8919\n","\n","Epoch 00379: val_accuracy did not improve from 0.94595\n","Epoch 380/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.6218 - val_accuracy: 0.8716\n","\n","Epoch 00380: val_accuracy did not improve from 0.94595\n","Epoch 381/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.8851\n","\n","Epoch 00381: val_accuracy did not improve from 0.94595\n","Epoch 382/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0027 - accuracy: 0.9984 - val_loss: 0.6454 - val_accuracy: 0.8784\n","\n","Epoch 00382: val_accuracy did not improve from 0.94595\n","Epoch 383/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.8167 - val_accuracy: 0.8716\n","\n","Epoch 00383: val_accuracy did not improve from 0.94595\n","Epoch 384/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.6457 - val_accuracy: 0.8784\n","\n","Epoch 00384: val_accuracy did not improve from 0.94595\n","Epoch 385/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.6226 - val_accuracy: 0.8851\n","\n","Epoch 00385: val_accuracy did not improve from 0.94595\n","Epoch 386/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.5724 - val_accuracy: 0.8919\n","\n","Epoch 00386: val_accuracy did not improve from 0.94595\n","Epoch 387/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0250 - accuracy: 0.9937 - val_loss: 1.1184 - val_accuracy: 0.8514\n","\n","Epoch 00387: val_accuracy did not improve from 0.94595\n","Epoch 388/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0091 - accuracy: 0.9995 - val_loss: 0.6763 - val_accuracy: 0.8919\n","\n","Epoch 00388: val_accuracy did not improve from 0.94595\n","Epoch 389/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.9003 - val_accuracy: 0.8243\n","\n","Epoch 00389: val_accuracy did not improve from 0.94595\n","Epoch 390/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0518 - accuracy: 0.9884 - val_loss: 0.8527 - val_accuracy: 0.8716\n","\n","Epoch 00390: val_accuracy did not improve from 0.94595\n","Epoch 391/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.7353 - val_accuracy: 0.8784\n","\n","Epoch 00391: val_accuracy did not improve from 0.94595\n","Epoch 392/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.6023 - val_accuracy: 0.8986\n","\n","Epoch 00392: val_accuracy did not improve from 0.94595\n","Epoch 393/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.5867 - val_accuracy: 0.8851\n","\n","Epoch 00393: val_accuracy did not improve from 0.94595\n","Epoch 394/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.6070 - val_accuracy: 0.8851\n","\n","Epoch 00394: val_accuracy did not improve from 0.94595\n","Epoch 395/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.6929 - val_accuracy: 0.8581\n","\n","Epoch 00395: val_accuracy did not improve from 0.94595\n","Epoch 396/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.5637 - val_accuracy: 0.9054\n","\n","Epoch 00396: val_accuracy did not improve from 0.94595\n","Epoch 397/500\n","238/238 [==============================] - 38s 161ms/step - loss: 5.6608e-04 - accuracy: 1.0000 - val_loss: 0.6053 - val_accuracy: 0.8919\n","\n","Epoch 00397: val_accuracy did not improve from 0.94595\n","Epoch 398/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.8275 - val_accuracy: 0.8716\n","\n","Epoch 00398: val_accuracy did not improve from 0.94595\n","Epoch 399/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.6817 - val_accuracy: 0.8716\n","\n","Epoch 00399: val_accuracy did not improve from 0.94595\n","Epoch 400/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.8816 - val_accuracy: 0.8716\n","\n","Epoch 00400: val_accuracy did not improve from 0.94595\n","Epoch 401/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0415 - accuracy: 0.9889 - val_loss: 0.8686 - val_accuracy: 0.8446\n","\n","Epoch 00401: val_accuracy did not improve from 0.94595\n","Epoch 402/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0228 - accuracy: 0.9911 - val_loss: 0.9193 - val_accuracy: 0.8446\n","\n","Epoch 00402: val_accuracy did not improve from 0.94595\n","Epoch 403/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0141 - accuracy: 0.9968 - val_loss: 0.6808 - val_accuracy: 0.8919\n","\n","Epoch 00403: val_accuracy did not improve from 0.94595\n","Epoch 404/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.7616 - val_accuracy: 0.8514\n","\n","Epoch 00404: val_accuracy did not improve from 0.94595\n","Epoch 405/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0071 - accuracy: 0.9968 - val_loss: 0.5152 - val_accuracy: 0.8986\n","\n","Epoch 00405: val_accuracy did not improve from 0.94595\n","Epoch 406/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.5019 - val_accuracy: 0.9189\n","\n","Epoch 00406: val_accuracy did not improve from 0.94595\n","Epoch 407/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5036 - val_accuracy: 0.9122\n","\n","Epoch 00407: val_accuracy did not improve from 0.94595\n","Epoch 408/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9122\n","\n","Epoch 00408: val_accuracy did not improve from 0.94595\n","Epoch 409/500\n","238/238 [==============================] - 38s 161ms/step - loss: 8.6898e-04 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.9054\n","\n","Epoch 00409: val_accuracy did not improve from 0.94595\n","Epoch 410/500\n","238/238 [==============================] - 38s 161ms/step - loss: 1.9595e-04 - accuracy: 1.0000 - val_loss: 0.4891 - val_accuracy: 0.9189\n","\n","Epoch 00410: val_accuracy did not improve from 0.94595\n","Epoch 411/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5571 - val_accuracy: 0.9054\n","\n","Epoch 00411: val_accuracy did not improve from 0.94595\n","Epoch 412/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6392 - val_accuracy: 0.9189\n","\n","Epoch 00412: val_accuracy did not improve from 0.94595\n","Epoch 413/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0127 - accuracy: 0.9989 - val_loss: 0.7038 - val_accuracy: 0.8986\n","\n","Epoch 00413: val_accuracy did not improve from 0.94595\n","Epoch 414/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.9033 - val_accuracy: 0.8919\n","\n","Epoch 00414: val_accuracy did not improve from 0.94595\n","Epoch 415/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.6949 - val_accuracy: 0.8784\n","\n","Epoch 00415: val_accuracy did not improve from 0.94595\n","Epoch 416/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.5400 - val_accuracy: 0.8919\n","\n","Epoch 00416: val_accuracy did not improve from 0.94595\n","Epoch 417/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.8091 - val_accuracy: 0.8851\n","\n","Epoch 00417: val_accuracy did not improve from 0.94595\n","Epoch 418/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.8540 - val_accuracy: 0.8716\n","\n","Epoch 00418: val_accuracy did not improve from 0.94595\n","Epoch 419/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.4716 - val_accuracy: 0.8986\n","\n","Epoch 00419: val_accuracy did not improve from 0.94595\n","Epoch 420/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.8115 - val_accuracy: 0.8851\n","\n","Epoch 00420: val_accuracy did not improve from 0.94595\n","Epoch 421/500\n","238/238 [==============================] - 38s 161ms/step - loss: 9.3046e-04 - accuracy: 1.0000 - val_loss: 0.5457 - val_accuracy: 0.9122\n","\n","Epoch 00421: val_accuracy did not improve from 0.94595\n","Epoch 422/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.5588 - val_accuracy: 0.8986\n","\n","Epoch 00422: val_accuracy did not improve from 0.94595\n","Epoch 423/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.6058 - val_accuracy: 0.8919\n","\n","Epoch 00423: val_accuracy did not improve from 0.94595\n","Epoch 424/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.7168 - val_accuracy: 0.8851\n","\n","Epoch 00424: val_accuracy did not improve from 0.94595\n","Epoch 425/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.5712 - val_accuracy: 0.8784\n","\n","Epoch 00425: val_accuracy did not improve from 0.94595\n","Epoch 426/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.9122\n","\n","Epoch 00426: val_accuracy did not improve from 0.94595\n","Epoch 427/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.5453 - val_accuracy: 0.8784\n","\n","Epoch 00427: val_accuracy did not improve from 0.94595\n","Epoch 428/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.4798 - val_accuracy: 0.8986\n","\n","Epoch 00428: val_accuracy did not improve from 0.94595\n","Epoch 429/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0166 - accuracy: 0.9979 - val_loss: 0.4788 - val_accuracy: 0.9054\n","\n","Epoch 00429: val_accuracy did not improve from 0.94595\n","Epoch 430/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.4922 - val_accuracy: 0.9122\n","\n","Epoch 00430: val_accuracy did not improve from 0.94595\n","Epoch 431/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.5302 - val_accuracy: 0.8919\n","\n","Epoch 00431: val_accuracy did not improve from 0.94595\n","Epoch 432/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.5246 - val_accuracy: 0.8986\n","\n","Epoch 00432: val_accuracy did not improve from 0.94595\n","Epoch 433/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0088 - accuracy: 0.9958 - val_loss: 0.4694 - val_accuracy: 0.9324\n","\n","Epoch 00433: val_accuracy did not improve from 0.94595\n","Epoch 434/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.6260 - val_accuracy: 0.9189\n","\n","Epoch 00434: val_accuracy did not improve from 0.94595\n","Epoch 435/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 0.4410 - val_accuracy: 0.8986\n","\n","Epoch 00435: val_accuracy did not improve from 0.94595\n","Epoch 436/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0067 - accuracy: 0.9968 - val_loss: 0.6720 - val_accuracy: 0.8311\n","\n","Epoch 00436: val_accuracy did not improve from 0.94595\n","Epoch 437/500\n","238/238 [==============================] - 38s 160ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.6284 - val_accuracy: 0.8649\n","\n","Epoch 00437: val_accuracy did not improve from 0.94595\n","Epoch 438/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.6865 - val_accuracy: 0.8784\n","\n","Epoch 00438: val_accuracy did not improve from 0.94595\n","Epoch 439/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.6100 - val_accuracy: 0.8851\n","\n","Epoch 00439: val_accuracy did not improve from 0.94595\n","Epoch 440/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.6211 - val_accuracy: 0.8851\n","\n","Epoch 00440: val_accuracy did not improve from 0.94595\n","Epoch 441/500\n","238/238 [==============================] - 38s 161ms/step - loss: 9.5106e-04 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.9054\n","\n","Epoch 00441: val_accuracy did not improve from 0.94595\n","Epoch 442/500\n","238/238 [==============================] - 38s 161ms/step - loss: 7.5057e-04 - accuracy: 1.0000 - val_loss: 0.5805 - val_accuracy: 0.8784\n","\n","Epoch 00442: val_accuracy did not improve from 0.94595\n","Epoch 443/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0159 - accuracy: 0.9926 - val_loss: 0.5277 - val_accuracy: 0.9189\n","\n","Epoch 00443: val_accuracy did not improve from 0.94595\n","Epoch 444/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.6348 - val_accuracy: 0.8851\n","\n","Epoch 00444: val_accuracy did not improve from 0.94595\n","Epoch 445/500\n","238/238 [==============================] - 39s 162ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.6576 - val_accuracy: 0.9122\n","\n","Epoch 00445: val_accuracy did not improve from 0.94595\n","Epoch 446/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0182 - accuracy: 0.9974 - val_loss: 0.6047 - val_accuracy: 0.8986\n","\n","Epoch 00446: val_accuracy did not improve from 0.94595\n","Epoch 447/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.6545 - val_accuracy: 0.8514\n","\n","Epoch 00447: val_accuracy did not improve from 0.94595\n","Epoch 448/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.6244 - val_accuracy: 0.8784\n","\n","Epoch 00448: val_accuracy did not improve from 0.94595\n","Epoch 449/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.6712 - val_accuracy: 0.8919\n","\n","Epoch 00449: val_accuracy did not improve from 0.94595\n","Epoch 450/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.7606 - val_accuracy: 0.8649\n","\n","Epoch 00450: val_accuracy did not improve from 0.94595\n","Epoch 451/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.4330 - val_accuracy: 0.9054\n","\n","Epoch 00451: val_accuracy did not improve from 0.94595\n","Epoch 452/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.6821 - val_accuracy: 0.8784\n","\n","Epoch 00452: val_accuracy did not improve from 0.94595\n","Epoch 453/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.4931 - val_accuracy: 0.9054\n","\n","Epoch 00453: val_accuracy did not improve from 0.94595\n","Epoch 454/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5838 - val_accuracy: 0.8986\n","\n","Epoch 00454: val_accuracy did not improve from 0.94595\n","Epoch 455/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.5932 - val_accuracy: 0.8851\n","\n","Epoch 00455: val_accuracy did not improve from 0.94595\n","Epoch 456/500\n","238/238 [==============================] - 38s 162ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.3014 - val_accuracy: 0.9257\n","\n","Epoch 00456: val_accuracy did not improve from 0.94595\n","Epoch 457/500\n","238/238 [==============================] - 39s 162ms/step - loss: 2.6550e-04 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9122\n","\n","Epoch 00457: val_accuracy did not improve from 0.94595\n","Epoch 458/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.5589 - val_accuracy: 0.9122\n","\n","Epoch 00458: val_accuracy did not improve from 0.94595\n","Epoch 459/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 0.9189\n","\n","Epoch 00459: val_accuracy did not improve from 0.94595\n","Epoch 460/500\n","238/238 [==============================] - 38s 161ms/step - loss: 4.6875e-04 - accuracy: 1.0000 - val_loss: 0.5445 - val_accuracy: 0.8784\n","\n","Epoch 00460: val_accuracy did not improve from 0.94595\n","Epoch 461/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.5316 - val_accuracy: 0.9122\n","\n","Epoch 00461: val_accuracy did not improve from 0.94595\n","Epoch 462/500\n","238/238 [==============================] - 38s 162ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.8986\n","\n","Epoch 00462: val_accuracy did not improve from 0.94595\n","Epoch 463/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0097 - accuracy: 0.9958 - val_loss: 0.4662 - val_accuracy: 0.9189\n","\n","Epoch 00463: val_accuracy did not improve from 0.94595\n","Epoch 464/500\n","238/238 [==============================] - 39s 162ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.4921 - val_accuracy: 0.9054\n","\n","Epoch 00464: val_accuracy did not improve from 0.94595\n","Epoch 465/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0062 - accuracy: 0.9968 - val_loss: 0.5377 - val_accuracy: 0.9054\n","\n","Epoch 00465: val_accuracy did not improve from 0.94595\n","Epoch 466/500\n","238/238 [==============================] - 39s 162ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.6462 - val_accuracy: 0.8851\n","\n","Epoch 00466: val_accuracy did not improve from 0.94595\n","Epoch 467/500\n","238/238 [==============================] - 39s 162ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.7239 - val_accuracy: 0.8649\n","\n","Epoch 00467: val_accuracy did not improve from 0.94595\n","Epoch 468/500\n","238/238 [==============================] - 39s 162ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.5111 - val_accuracy: 0.8784\n","\n","Epoch 00468: val_accuracy did not improve from 0.94595\n","Epoch 469/500\n","238/238 [==============================] - 39s 162ms/step - loss: 0.0069 - accuracy: 0.9968 - val_loss: 0.8235 - val_accuracy: 0.8784\n","\n","Epoch 00469: val_accuracy did not improve from 0.94595\n","Epoch 470/500\n","238/238 [==============================] - 38s 161ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.8402 - val_accuracy: 0.8919\n","\n","Epoch 00470: val_accuracy did not improve from 0.94595\n","Epoch 471/500\n","238/238 [==============================] - 39s 162ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.5921 - val_accuracy: 0.9054\n","\n","Epoch 00471: val_accuracy did not improve from 0.94595\n","Epoch 472/500\n","238/238 [==============================] - 39s 162ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.6553 - val_accuracy: 0.8649\n","\n","Epoch 00472: val_accuracy did not improve from 0.94595\n","Epoch 473/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.7577 - val_accuracy: 0.8649\n","\n","Epoch 00473: val_accuracy did not improve from 0.94595\n","Epoch 474/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.6586 - val_accuracy: 0.8784\n","\n","Epoch 00474: val_accuracy did not improve from 0.94595\n","Epoch 475/500\n","238/238 [==============================] - 39s 162ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.7804 - val_accuracy: 0.8851\n","\n","Epoch 00475: val_accuracy did not improve from 0.94595\n","Epoch 476/500\n","238/238 [==============================] - 39s 162ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.6099 - val_accuracy: 0.8919\n","\n","Epoch 00476: val_accuracy did not improve from 0.94595\n","Epoch 477/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.7808 - val_accuracy: 0.9054\n","\n","Epoch 00477: val_accuracy did not improve from 0.94595\n","Epoch 478/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0047 - accuracy: 0.9974 - val_loss: 0.5369 - val_accuracy: 0.9122\n","\n","Epoch 00478: val_accuracy did not improve from 0.94595\n","Epoch 479/500\n","238/238 [==============================] - 39s 162ms/step - loss: 0.0089 - accuracy: 0.9953 - val_loss: 0.4844 - val_accuracy: 0.9054\n","\n","Epoch 00479: val_accuracy did not improve from 0.94595\n","Epoch 480/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0039 - accuracy: 0.9979 - val_loss: 0.5194 - val_accuracy: 0.9054\n","\n","Epoch 00480: val_accuracy did not improve from 0.94595\n","Epoch 481/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5508 - val_accuracy: 0.9189\n","\n","Epoch 00481: val_accuracy did not improve from 0.94595\n","Epoch 482/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.7569 - val_accuracy: 0.8919\n","\n","Epoch 00482: val_accuracy did not improve from 0.94595\n","Epoch 483/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.6792 - val_accuracy: 0.9054\n","\n","Epoch 00483: val_accuracy did not improve from 0.94595\n","Epoch 484/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.6299 - val_accuracy: 0.8986\n","\n","Epoch 00484: val_accuracy did not improve from 0.94595\n","Epoch 485/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0086 - accuracy: 0.9958 - val_loss: 0.5717 - val_accuracy: 0.8784\n","\n","Epoch 00485: val_accuracy did not improve from 0.94595\n","Epoch 486/500\n","238/238 [==============================] - 39s 164ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.7045 - val_accuracy: 0.8649\n","\n","Epoch 00486: val_accuracy did not improve from 0.94595\n","Epoch 487/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.5719 - val_accuracy: 0.8784\n","\n","Epoch 00487: val_accuracy did not improve from 0.94595\n","Epoch 488/500\n","238/238 [==============================] - 39s 163ms/step - loss: 7.6952e-04 - accuracy: 1.0000 - val_loss: 0.5324 - val_accuracy: 0.8784\n","\n","Epoch 00488: val_accuracy did not improve from 0.94595\n","Epoch 489/500\n","238/238 [==============================] - 39s 164ms/step - loss: 7.8185e-04 - accuracy: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.8919\n","\n","Epoch 00489: val_accuracy did not improve from 0.94595\n","Epoch 490/500\n","238/238 [==============================] - 39s 164ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.5054 - val_accuracy: 0.9122\n","\n","Epoch 00490: val_accuracy did not improve from 0.94595\n","Epoch 491/500\n","238/238 [==============================] - 39s 164ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.5639 - val_accuracy: 0.8919\n","\n","Epoch 00491: val_accuracy did not improve from 0.94595\n","Epoch 492/500\n","238/238 [==============================] - 39s 164ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.5537 - val_accuracy: 0.9054\n","\n","Epoch 00492: val_accuracy did not improve from 0.94595\n","Epoch 493/500\n","238/238 [==============================] - 39s 164ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.8919\n","\n","Epoch 00493: val_accuracy did not improve from 0.94595\n","Epoch 494/500\n","238/238 [==============================] - 39s 164ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.9634 - val_accuracy: 0.8581\n","\n","Epoch 00494: val_accuracy did not improve from 0.94595\n","Epoch 495/500\n","238/238 [==============================] - 39s 164ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.5634 - val_accuracy: 0.8649\n","\n","Epoch 00495: val_accuracy did not improve from 0.94595\n","Epoch 496/500\n","238/238 [==============================] - 39s 164ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.6012 - val_accuracy: 0.8919\n","\n","Epoch 00496: val_accuracy did not improve from 0.94595\n","Epoch 497/500\n","238/238 [==============================] - 39s 164ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.8926 - val_accuracy: 0.8716\n","\n","Epoch 00497: val_accuracy did not improve from 0.94595\n","Epoch 498/500\n","238/238 [==============================] - 39s 164ms/step - loss: 0.0326 - accuracy: 0.9911 - val_loss: 1.1234 - val_accuracy: 0.8108\n","\n","Epoch 00498: val_accuracy did not improve from 0.94595\n","Epoch 499/500\n","238/238 [==============================] - 39s 163ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.5290 - val_accuracy: 0.8986\n","\n","Epoch 00499: val_accuracy did not improve from 0.94595\n","Epoch 500/500\n","238/238 [==============================] - 39s 164ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7547 - val_accuracy: 0.8986\n","\n","Epoch 00500: val_accuracy did not improve from 0.94595\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f62e422fc50>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1632756658007,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c9de1f31-8104-4458-e7cb-49ad1c44b514"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n","plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n","\n","plt.legend()\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1632756728597,"user_tz":-540,"elapsed":70596,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-"},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632756806851,"user_tz":-540,"elapsed":77246,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"10f7a9ab-8b0b-4cb6-ab01-a8a923cbced9"},"source":["Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD"},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz"},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK"},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1632756808422,"user_tz":-540,"elapsed":2,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"model_predict\"] = Target_predict"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1632756819799,"user_tz":-540,"elapsed":11378,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['model_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS"},"source":["submission = submission[['id', 'digit']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1632756819806,"user_tz":-540,"elapsed":4,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"6ac8b740-fec9-4b3d-8378-8defd382c37d"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_dcc975b1-424f-4d26-a857-903730733632\", \"ResNet152V2_5.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"lmZ06MWjdN2l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632756823448,"user_tz":-540,"elapsed":3644,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"6f73d46a-ec3f-44df-d8ba-c8997c4d5614"},"source":["!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n","Installing collected packages: dacon-submit-api\n","Successfully installed dacon-submit-api-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"oVdKDp3mdOZA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632756842096,"user_tz":-540,"elapsed":36,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"83d38572-d452-46fa-9c39-4d608d6d64ed"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","    # 파일경로\n","    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n","    # d9249@kyonggi.ac.kr\n","    # 'c2ecc8b05a9867f71ebb86f632ae73326696cb7f6e21be07ab43a7b400ef1f11',\n","    # dodo9249@gmail.com\n","    # 'abc9927563b1882b2480ac943a313a002631fb00c5a0daea43b12720ed34114e',\n","    # d9249.acc001@gmail.com\n","    'b27d6929e0eedade68e6a882d4006ec463f061c75a81aa27561c2c606dde8ad7',\n","    # meanideal96@gamil.com\n","    # '895306aa742a46bd095afaf319bd0b9519e1e6e74f4bf98a32c2e4c15aee5026',\n","    # dodo402298@gmail.com\n","    # '384b4c250944611e49156214ca31fd554bbc64d22ec31a2726302c22f1a05271',\n","    # d9249.acc002@gmail.com\n","    # 'b28b29dd8d3ed4701f3b4e5b4d95549078e543dbd4a12abd92a3dd9a09d85616',\n","    # 대회 ID\n","    '235626',\n","    # d9249@kyonggi.ac.kr 팀이릉\n","    # 'iDeal9',\n","    # dodo9249@gmail.com 팀이름\n","    # 'iDeal96',\n","    # d9249.acc001@gmail.com\n","    'iDeal01',\n","    # meanideal96@gamil.com\n","    # 'iDeal02',\n","    # dodo402298@gmail.com\n","    # 'mean01',\n","    # d9249.acc002@gmail.com\n","    # 'mean02',\n","    # memo\n","    'd9249_kyonggi_ac_kr' )"],"execution_count":26,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["{'isSubmitted': True, 'detail': 'Success'}\n"]}]}]}