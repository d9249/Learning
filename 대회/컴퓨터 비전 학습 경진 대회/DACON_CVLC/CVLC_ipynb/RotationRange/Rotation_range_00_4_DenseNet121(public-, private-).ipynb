{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Rotation_range_00_4_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyMsRUDEB6lTSxfP0nsyLqAo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629807315969,"user_tz":-540,"elapsed":29,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"8e9cfe1a-04e4-41a9-ab07-5b2d6511bd5e"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Aug 24 12:15:17 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629807332084,"user_tz":-540,"elapsed":16122,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"862dc0d5-b033-4a38-995a-3d45dee15f69"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1629807335796,"user_tz":-540,"elapsed":3719,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1629807337082,"user_tz":-540,"elapsed":1290,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1629807338997,"user_tz":-540,"elapsed":1919,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1629807356124,"user_tz":-540,"elapsed":17131,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1629807363015,"user_tz":-540,"elapsed":6897,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629807363023,"user_tz":-540,"elapsed":16,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0c510a81-9b09-4aa3-9d0d-845d3068db11"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629807363024,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"53fb56b7-070b-45d4-8217-4ca9842b27b9"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=0,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1629807363026,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629817664450,"user_tz":-540,"elapsed":10301436,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"8c7c0c0c-2835-4be9-9393-84b8fd35a78c"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 53s 471ms/step - loss: 1.8573 - accuracy: 0.3447 - val_loss: 3.1838 - val_accuracy: 0.1084\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.10837, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 19s 368ms/step - loss: 1.1328 - accuracy: 0.6114 - val_loss: 6.4339 - val_accuracy: 0.0985\n","\n","Epoch 00002: val_accuracy did not improve from 0.10837\n","Epoch 3/500\n","52/52 [==============================] - 19s 371ms/step - loss: 0.9014 - accuracy: 0.7040 - val_loss: 5.0359 - val_accuracy: 0.1158\n","\n","Epoch 00003: val_accuracy improved from 0.10837 to 0.11576, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 4/500\n","52/52 [==============================] - 20s 373ms/step - loss: 0.8588 - accuracy: 0.7186 - val_loss: 6.3555 - val_accuracy: 0.1034\n","\n","Epoch 00004: val_accuracy did not improve from 0.11576\n","Epoch 5/500\n","52/52 [==============================] - 20s 375ms/step - loss: 0.6522 - accuracy: 0.7881 - val_loss: 9.5211 - val_accuracy: 0.1626\n","\n","Epoch 00005: val_accuracy improved from 0.11576 to 0.16256, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 20s 374ms/step - loss: 0.5946 - accuracy: 0.8063 - val_loss: 3.8448 - val_accuracy: 0.2537\n","\n","Epoch 00006: val_accuracy improved from 0.16256 to 0.25369, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 20s 377ms/step - loss: 0.5490 - accuracy: 0.8155 - val_loss: 6.3634 - val_accuracy: 0.2709\n","\n","Epoch 00007: val_accuracy improved from 0.25369 to 0.27094, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.4735 - accuracy: 0.8410 - val_loss: 6.1667 - val_accuracy: 0.2414\n","\n","Epoch 00008: val_accuracy did not improve from 0.27094\n","Epoch 9/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.4707 - accuracy: 0.8459 - val_loss: 2.0798 - val_accuracy: 0.5591\n","\n","Epoch 00009: val_accuracy improved from 0.27094 to 0.55911, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.3757 - accuracy: 0.8703 - val_loss: 1.0619 - val_accuracy: 0.6897\n","\n","Epoch 00010: val_accuracy improved from 0.55911 to 0.68966, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.4112 - accuracy: 0.8648 - val_loss: 5.1958 - val_accuracy: 0.3547\n","\n","Epoch 00011: val_accuracy did not improve from 0.68966\n","Epoch 12/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.3576 - accuracy: 0.8739 - val_loss: 2.0594 - val_accuracy: 0.5493\n","\n","Epoch 00012: val_accuracy did not improve from 0.68966\n","Epoch 13/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3560 - accuracy: 0.8800 - val_loss: 0.8238 - val_accuracy: 0.7340\n","\n","Epoch 00013: val_accuracy improved from 0.68966 to 0.73399, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 14/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.2928 - accuracy: 0.9062 - val_loss: 0.5873 - val_accuracy: 0.8202\n","\n","Epoch 00014: val_accuracy improved from 0.73399 to 0.82020, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 15/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.2839 - accuracy: 0.9001 - val_loss: 4.8377 - val_accuracy: 0.3621\n","\n","Epoch 00015: val_accuracy did not improve from 0.82020\n","Epoch 16/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.3256 - accuracy: 0.8806 - val_loss: 1.5081 - val_accuracy: 0.6650\n","\n","Epoch 00016: val_accuracy did not improve from 0.82020\n","Epoch 17/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.2664 - accuracy: 0.9117 - val_loss: 0.8917 - val_accuracy: 0.7685\n","\n","Epoch 00017: val_accuracy did not improve from 0.82020\n","Epoch 18/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.2178 - accuracy: 0.9269 - val_loss: 0.6290 - val_accuracy: 0.8251\n","\n","Epoch 00018: val_accuracy improved from 0.82020 to 0.82512, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 19/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.2328 - accuracy: 0.9178 - val_loss: 0.9480 - val_accuracy: 0.7463\n","\n","Epoch 00019: val_accuracy did not improve from 0.82512\n","Epoch 20/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.2308 - accuracy: 0.9141 - val_loss: 0.7397 - val_accuracy: 0.7906\n","\n","Epoch 00020: val_accuracy did not improve from 0.82512\n","Epoch 21/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1865 - accuracy: 0.9409 - val_loss: 0.7828 - val_accuracy: 0.8153\n","\n","Epoch 00021: val_accuracy did not improve from 0.82512\n","Epoch 22/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.2196 - accuracy: 0.9324 - val_loss: 1.0959 - val_accuracy: 0.7365\n","\n","Epoch 00022: val_accuracy did not improve from 0.82512\n","Epoch 23/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.2473 - accuracy: 0.9153 - val_loss: 1.3569 - val_accuracy: 0.7192\n","\n","Epoch 00023: val_accuracy did not improve from 0.82512\n","Epoch 24/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1713 - accuracy: 0.9379 - val_loss: 0.6162 - val_accuracy: 0.8325\n","\n","Epoch 00024: val_accuracy improved from 0.82512 to 0.83251, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 25/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1509 - accuracy: 0.9537 - val_loss: 0.9563 - val_accuracy: 0.7414\n","\n","Epoch 00025: val_accuracy did not improve from 0.83251\n","Epoch 26/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1582 - accuracy: 0.9446 - val_loss: 0.6128 - val_accuracy: 0.8350\n","\n","Epoch 00026: val_accuracy improved from 0.83251 to 0.83498, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 27/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1689 - accuracy: 0.9440 - val_loss: 0.4731 - val_accuracy: 0.8596\n","\n","Epoch 00027: val_accuracy improved from 0.83498 to 0.85961, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 28/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1287 - accuracy: 0.9537 - val_loss: 0.5971 - val_accuracy: 0.8522\n","\n","Epoch 00028: val_accuracy did not improve from 0.85961\n","Epoch 29/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1025 - accuracy: 0.9647 - val_loss: 0.6765 - val_accuracy: 0.8374\n","\n","Epoch 00029: val_accuracy did not improve from 0.85961\n","Epoch 30/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1140 - accuracy: 0.9598 - val_loss: 0.7125 - val_accuracy: 0.8079\n","\n","Epoch 00030: val_accuracy did not improve from 0.85961\n","Epoch 31/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1647 - accuracy: 0.9458 - val_loss: 0.4272 - val_accuracy: 0.8818\n","\n","Epoch 00031: val_accuracy improved from 0.85961 to 0.88177, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 32/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1624 - accuracy: 0.9409 - val_loss: 5.3309 - val_accuracy: 0.3916\n","\n","Epoch 00032: val_accuracy did not improve from 0.88177\n","Epoch 33/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1576 - accuracy: 0.9428 - val_loss: 2.0925 - val_accuracy: 0.6552\n","\n","Epoch 00033: val_accuracy did not improve from 0.88177\n","Epoch 34/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1391 - accuracy: 0.9543 - val_loss: 0.8205 - val_accuracy: 0.7906\n","\n","Epoch 00034: val_accuracy did not improve from 0.88177\n","Epoch 35/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1169 - accuracy: 0.9622 - val_loss: 0.4439 - val_accuracy: 0.8744\n","\n","Epoch 00035: val_accuracy did not improve from 0.88177\n","Epoch 36/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1006 - accuracy: 0.9653 - val_loss: 0.8356 - val_accuracy: 0.7980\n","\n","Epoch 00036: val_accuracy did not improve from 0.88177\n","Epoch 37/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1098 - accuracy: 0.9653 - val_loss: 1.6527 - val_accuracy: 0.6773\n","\n","Epoch 00037: val_accuracy did not improve from 0.88177\n","Epoch 38/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0845 - accuracy: 0.9726 - val_loss: 0.4477 - val_accuracy: 0.8842\n","\n","Epoch 00038: val_accuracy improved from 0.88177 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 39/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0603 - accuracy: 0.9787 - val_loss: 0.4827 - val_accuracy: 0.8719\n","\n","Epoch 00039: val_accuracy did not improve from 0.88424\n","Epoch 40/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0744 - accuracy: 0.9769 - val_loss: 0.4978 - val_accuracy: 0.8596\n","\n","Epoch 00040: val_accuracy did not improve from 0.88424\n","Epoch 41/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0820 - accuracy: 0.9726 - val_loss: 0.5572 - val_accuracy: 0.8571\n","\n","Epoch 00041: val_accuracy did not improve from 0.88424\n","Epoch 42/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0524 - accuracy: 0.9842 - val_loss: 0.5109 - val_accuracy: 0.8768\n","\n","Epoch 00042: val_accuracy did not improve from 0.88424\n","Epoch 43/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0764 - accuracy: 0.9756 - val_loss: 0.7344 - val_accuracy: 0.8103\n","\n","Epoch 00043: val_accuracy did not improve from 0.88424\n","Epoch 44/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0833 - accuracy: 0.9702 - val_loss: 0.6366 - val_accuracy: 0.8522\n","\n","Epoch 00044: val_accuracy did not improve from 0.88424\n","Epoch 45/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0921 - accuracy: 0.9689 - val_loss: 0.6317 - val_accuracy: 0.8571\n","\n","Epoch 00045: val_accuracy did not improve from 0.88424\n","Epoch 46/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0988 - accuracy: 0.9683 - val_loss: 0.7444 - val_accuracy: 0.8399\n","\n","Epoch 00046: val_accuracy did not improve from 0.88424\n","Epoch 47/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0627 - accuracy: 0.9793 - val_loss: 0.7866 - val_accuracy: 0.8054\n","\n","Epoch 00047: val_accuracy did not improve from 0.88424\n","Epoch 48/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0580 - accuracy: 0.9805 - val_loss: 0.5417 - val_accuracy: 0.8645\n","\n","Epoch 00048: val_accuracy did not improve from 0.88424\n","Epoch 49/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0637 - accuracy: 0.9823 - val_loss: 0.4908 - val_accuracy: 0.8670\n","\n","Epoch 00049: val_accuracy did not improve from 0.88424\n","Epoch 50/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 0.4363 - val_accuracy: 0.8793\n","\n","Epoch 00050: val_accuracy did not improve from 0.88424\n","Epoch 51/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0779 - accuracy: 0.9720 - val_loss: 1.3087 - val_accuracy: 0.7611\n","\n","Epoch 00051: val_accuracy did not improve from 0.88424\n","Epoch 52/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0730 - accuracy: 0.9726 - val_loss: 0.5457 - val_accuracy: 0.8596\n","\n","Epoch 00052: val_accuracy did not improve from 0.88424\n","Epoch 53/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0903 - accuracy: 0.9689 - val_loss: 0.5192 - val_accuracy: 0.8695\n","\n","Epoch 00053: val_accuracy did not improve from 0.88424\n","Epoch 54/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0592 - accuracy: 0.9811 - val_loss: 1.5821 - val_accuracy: 0.7562\n","\n","Epoch 00054: val_accuracy did not improve from 0.88424\n","Epoch 55/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0488 - accuracy: 0.9842 - val_loss: 0.6523 - val_accuracy: 0.8350\n","\n","Epoch 00055: val_accuracy did not improve from 0.88424\n","Epoch 56/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0848 - accuracy: 0.9695 - val_loss: 0.4127 - val_accuracy: 0.8892\n","\n","Epoch 00056: val_accuracy improved from 0.88424 to 0.88916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 57/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0781 - accuracy: 0.9714 - val_loss: 0.8651 - val_accuracy: 0.8300\n","\n","Epoch 00057: val_accuracy did not improve from 0.88916\n","Epoch 58/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1874 - accuracy: 0.9361 - val_loss: 13.1334 - val_accuracy: 0.2069\n","\n","Epoch 00058: val_accuracy did not improve from 0.88916\n","Epoch 59/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.1238 - accuracy: 0.9598 - val_loss: 0.9879 - val_accuracy: 0.7931\n","\n","Epoch 00059: val_accuracy did not improve from 0.88916\n","Epoch 60/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0571 - accuracy: 0.9823 - val_loss: 0.5363 - val_accuracy: 0.8744\n","\n","Epoch 00060: val_accuracy did not improve from 0.88916\n","Epoch 61/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.3958 - val_accuracy: 0.8892\n","\n","Epoch 00061: val_accuracy did not improve from 0.88916\n","Epoch 62/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0338 - accuracy: 0.9872 - val_loss: 0.4281 - val_accuracy: 0.8892\n","\n","Epoch 00062: val_accuracy did not improve from 0.88916\n","Epoch 63/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0802 - accuracy: 0.9726 - val_loss: 0.8262 - val_accuracy: 0.8448\n","\n","Epoch 00063: val_accuracy did not improve from 0.88916\n","Epoch 64/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0625 - accuracy: 0.9799 - val_loss: 0.3329 - val_accuracy: 0.9212\n","\n","Epoch 00064: val_accuracy improved from 0.88916 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 65/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0385 - accuracy: 0.9872 - val_loss: 0.5625 - val_accuracy: 0.8842\n","\n","Epoch 00065: val_accuracy did not improve from 0.92118\n","Epoch 66/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0318 - accuracy: 0.9903 - val_loss: 0.5046 - val_accuracy: 0.8842\n","\n","Epoch 00066: val_accuracy did not improve from 0.92118\n","Epoch 67/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0333 - accuracy: 0.9933 - val_loss: 0.8879 - val_accuracy: 0.7980\n","\n","Epoch 00067: val_accuracy did not improve from 0.92118\n","Epoch 68/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 0.4687 - val_accuracy: 0.8867\n","\n","Epoch 00068: val_accuracy did not improve from 0.92118\n","Epoch 69/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0432 - accuracy: 0.9860 - val_loss: 1.2655 - val_accuracy: 0.8005\n","\n","Epoch 00069: val_accuracy did not improve from 0.92118\n","Epoch 70/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0946 - accuracy: 0.9689 - val_loss: 0.5924 - val_accuracy: 0.8768\n","\n","Epoch 00070: val_accuracy did not improve from 0.92118\n","Epoch 71/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1194 - accuracy: 0.9665 - val_loss: 1.3967 - val_accuracy: 0.7611\n","\n","Epoch 00071: val_accuracy did not improve from 0.92118\n","Epoch 72/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1505 - accuracy: 0.9464 - val_loss: 1.1092 - val_accuracy: 0.7759\n","\n","Epoch 00072: val_accuracy did not improve from 0.92118\n","Epoch 73/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1203 - accuracy: 0.9592 - val_loss: 1.5063 - val_accuracy: 0.7389\n","\n","Epoch 00073: val_accuracy did not improve from 0.92118\n","Epoch 74/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0464 - accuracy: 0.9854 - val_loss: 1.1309 - val_accuracy: 0.8202\n","\n","Epoch 00074: val_accuracy did not improve from 0.92118\n","Epoch 75/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 0.5215 - val_accuracy: 0.8695\n","\n","Epoch 00075: val_accuracy did not improve from 0.92118\n","Epoch 76/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0266 - accuracy: 0.9903 - val_loss: 0.4378 - val_accuracy: 0.8818\n","\n","Epoch 00076: val_accuracy did not improve from 0.92118\n","Epoch 77/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0285 - accuracy: 0.9903 - val_loss: 0.4830 - val_accuracy: 0.8966\n","\n","Epoch 00077: val_accuracy did not improve from 0.92118\n","Epoch 78/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0308 - accuracy: 0.9903 - val_loss: 0.5396 - val_accuracy: 0.8842\n","\n","Epoch 00078: val_accuracy did not improve from 0.92118\n","Epoch 79/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.4593 - val_accuracy: 0.9039\n","\n","Epoch 00079: val_accuracy did not improve from 0.92118\n","Epoch 80/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.3376 - val_accuracy: 0.9212\n","\n","Epoch 00080: val_accuracy did not improve from 0.92118\n","Epoch 81/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0278 - accuracy: 0.9884 - val_loss: 0.8321 - val_accuracy: 0.8276\n","\n","Epoch 00081: val_accuracy did not improve from 0.92118\n","Epoch 82/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0948 - accuracy: 0.9714 - val_loss: 0.8424 - val_accuracy: 0.8030\n","\n","Epoch 00082: val_accuracy did not improve from 0.92118\n","Epoch 83/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0412 - accuracy: 0.9872 - val_loss: 0.6379 - val_accuracy: 0.8571\n","\n","Epoch 00083: val_accuracy did not improve from 0.92118\n","Epoch 84/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0363 - accuracy: 0.9896 - val_loss: 0.6211 - val_accuracy: 0.8719\n","\n","Epoch 00084: val_accuracy did not improve from 0.92118\n","Epoch 85/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0262 - accuracy: 0.9890 - val_loss: 0.5281 - val_accuracy: 0.8744\n","\n","Epoch 00085: val_accuracy did not improve from 0.92118\n","Epoch 86/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0401 - accuracy: 0.9848 - val_loss: 0.7077 - val_accuracy: 0.8374\n","\n","Epoch 00086: val_accuracy did not improve from 0.92118\n","Epoch 87/500\n","52/52 [==============================] - 20s 394ms/step - loss: 0.0592 - accuracy: 0.9817 - val_loss: 0.6987 - val_accuracy: 0.8645\n","\n","Epoch 00087: val_accuracy did not improve from 0.92118\n","Epoch 88/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0565 - accuracy: 0.9793 - val_loss: 0.4226 - val_accuracy: 0.9039\n","\n","Epoch 00088: val_accuracy did not improve from 0.92118\n","Epoch 89/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0625 - accuracy: 0.9769 - val_loss: 0.8007 - val_accuracy: 0.7980\n","\n","Epoch 00089: val_accuracy did not improve from 0.92118\n","Epoch 90/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0790 - accuracy: 0.9726 - val_loss: 1.4387 - val_accuracy: 0.7167\n","\n","Epoch 00090: val_accuracy did not improve from 0.92118\n","Epoch 91/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1033 - accuracy: 0.9732 - val_loss: 0.7653 - val_accuracy: 0.8424\n","\n","Epoch 00091: val_accuracy did not improve from 0.92118\n","Epoch 92/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0463 - accuracy: 0.9884 - val_loss: 0.7299 - val_accuracy: 0.8424\n","\n","Epoch 00092: val_accuracy did not improve from 0.92118\n","Epoch 93/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0715 - accuracy: 0.9781 - val_loss: 0.7137 - val_accuracy: 0.8571\n","\n","Epoch 00093: val_accuracy did not improve from 0.92118\n","Epoch 94/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0286 - accuracy: 0.9903 - val_loss: 0.5303 - val_accuracy: 0.8916\n","\n","Epoch 00094: val_accuracy did not improve from 0.92118\n","Epoch 95/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.3811 - val_accuracy: 0.9187\n","\n","Epoch 00095: val_accuracy did not improve from 0.92118\n","Epoch 96/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.5649 - val_accuracy: 0.8867\n","\n","Epoch 00096: val_accuracy did not improve from 0.92118\n","Epoch 97/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9236\n","\n","Epoch 00097: val_accuracy improved from 0.92118 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 98/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.3053 - val_accuracy: 0.9261\n","\n","Epoch 00098: val_accuracy improved from 0.92365 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 99/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.3183 - val_accuracy: 0.9261\n","\n","Epoch 00099: val_accuracy did not improve from 0.92611\n","Epoch 100/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0321 - accuracy: 0.9921 - val_loss: 0.7402 - val_accuracy: 0.8202\n","\n","Epoch 00100: val_accuracy did not improve from 0.92611\n","Epoch 101/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0326 - accuracy: 0.9903 - val_loss: 0.8275 - val_accuracy: 0.8399\n","\n","Epoch 00101: val_accuracy did not improve from 0.92611\n","Epoch 102/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.6569 - val_accuracy: 0.8744\n","\n","Epoch 00102: val_accuracy did not improve from 0.92611\n","Epoch 103/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.4432 - val_accuracy: 0.8941\n","\n","Epoch 00103: val_accuracy did not improve from 0.92611\n","Epoch 104/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0083 - accuracy: 0.9957 - val_loss: 0.6301 - val_accuracy: 0.8744\n","\n","Epoch 00104: val_accuracy did not improve from 0.92611\n","Epoch 105/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0542 - accuracy: 0.9842 - val_loss: 0.8290 - val_accuracy: 0.8227\n","\n","Epoch 00105: val_accuracy did not improve from 0.92611\n","Epoch 106/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0414 - accuracy: 0.9860 - val_loss: 1.0370 - val_accuracy: 0.8227\n","\n","Epoch 00106: val_accuracy did not improve from 0.92611\n","Epoch 107/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0278 - accuracy: 0.9903 - val_loss: 0.7060 - val_accuracy: 0.8571\n","\n","Epoch 00107: val_accuracy did not improve from 0.92611\n","Epoch 108/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.4089 - val_accuracy: 0.9039\n","\n","Epoch 00108: val_accuracy did not improve from 0.92611\n","Epoch 109/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0291 - accuracy: 0.9909 - val_loss: 0.6970 - val_accuracy: 0.8670\n","\n","Epoch 00109: val_accuracy did not improve from 0.92611\n","Epoch 110/500\n","52/52 [==============================] - 21s 404ms/step - loss: 0.0447 - accuracy: 0.9884 - val_loss: 0.5830 - val_accuracy: 0.9015\n","\n","Epoch 00110: val_accuracy did not improve from 0.92611\n","Epoch 111/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0122 - accuracy: 0.9976 - val_loss: 0.4139 - val_accuracy: 0.9138\n","\n","Epoch 00111: val_accuracy did not improve from 0.92611\n","Epoch 112/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.3200 - val_accuracy: 0.9483\n","\n","Epoch 00112: val_accuracy improved from 0.92611 to 0.94828, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5\n","Epoch 113/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9360\n","\n","Epoch 00113: val_accuracy did not improve from 0.94828\n","Epoch 114/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9212\n","\n","Epoch 00114: val_accuracy did not improve from 0.94828\n","Epoch 115/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3193 - val_accuracy: 0.9286\n","\n","Epoch 00115: val_accuracy did not improve from 0.94828\n","Epoch 116/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.4188 - val_accuracy: 0.9212\n","\n","Epoch 00116: val_accuracy did not improve from 0.94828\n","Epoch 117/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0270 - accuracy: 0.9896 - val_loss: 0.8926 - val_accuracy: 0.8276\n","\n","Epoch 00117: val_accuracy did not improve from 0.94828\n","Epoch 118/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0572 - accuracy: 0.9793 - val_loss: 0.6354 - val_accuracy: 0.8645\n","\n","Epoch 00118: val_accuracy did not improve from 0.94828\n","Epoch 119/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0452 - accuracy: 0.9866 - val_loss: 0.5102 - val_accuracy: 0.9015\n","\n","Epoch 00119: val_accuracy did not improve from 0.94828\n","Epoch 120/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.6037 - val_accuracy: 0.8793\n","\n","Epoch 00120: val_accuracy did not improve from 0.94828\n","Epoch 121/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0427 - accuracy: 0.9921 - val_loss: 0.6467 - val_accuracy: 0.8768\n","\n","Epoch 00121: val_accuracy did not improve from 0.94828\n","Epoch 122/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0416 - accuracy: 0.9854 - val_loss: 0.4470 - val_accuracy: 0.8990\n","\n","Epoch 00122: val_accuracy did not improve from 0.94828\n","Epoch 123/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0263 - accuracy: 0.9896 - val_loss: 0.6037 - val_accuracy: 0.8941\n","\n","Epoch 00123: val_accuracy did not improve from 0.94828\n","Epoch 124/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0202 - accuracy: 0.9927 - val_loss: 0.5552 - val_accuracy: 0.8695\n","\n","Epoch 00124: val_accuracy did not improve from 0.94828\n","Epoch 125/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0293 - accuracy: 0.9890 - val_loss: 0.5776 - val_accuracy: 0.8867\n","\n","Epoch 00125: val_accuracy did not improve from 0.94828\n","Epoch 126/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0363 - accuracy: 0.9860 - val_loss: 1.0423 - val_accuracy: 0.8498\n","\n","Epoch 00126: val_accuracy did not improve from 0.94828\n","Epoch 127/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0975 - accuracy: 0.9702 - val_loss: 1.2321 - val_accuracy: 0.7956\n","\n","Epoch 00127: val_accuracy did not improve from 0.94828\n","Epoch 128/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.2067 - accuracy: 0.9342 - val_loss: 4.4783 - val_accuracy: 0.5172\n","\n","Epoch 00128: val_accuracy did not improve from 0.94828\n","Epoch 129/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0794 - accuracy: 0.9726 - val_loss: 0.7200 - val_accuracy: 0.8793\n","\n","Epoch 00129: val_accuracy did not improve from 0.94828\n","Epoch 130/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0656 - accuracy: 0.9775 - val_loss: 0.5124 - val_accuracy: 0.8867\n","\n","Epoch 00130: val_accuracy did not improve from 0.94828\n","Epoch 131/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0265 - accuracy: 0.9890 - val_loss: 0.4257 - val_accuracy: 0.9064\n","\n","Epoch 00131: val_accuracy did not improve from 0.94828\n","Epoch 132/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0132 - accuracy: 0.9945 - val_loss: 0.4808 - val_accuracy: 0.8842\n","\n","Epoch 00132: val_accuracy did not improve from 0.94828\n","Epoch 133/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0153 - accuracy: 0.9939 - val_loss: 0.5069 - val_accuracy: 0.8867\n","\n","Epoch 00133: val_accuracy did not improve from 0.94828\n","Epoch 134/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.5723 - val_accuracy: 0.8842\n","\n","Epoch 00134: val_accuracy did not improve from 0.94828\n","Epoch 135/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.4709 - val_accuracy: 0.8916\n","\n","Epoch 00135: val_accuracy did not improve from 0.94828\n","Epoch 136/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.5522 - val_accuracy: 0.8793\n","\n","Epoch 00136: val_accuracy did not improve from 0.94828\n","Epoch 137/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.6507 - val_accuracy: 0.8719\n","\n","Epoch 00137: val_accuracy did not improve from 0.94828\n","Epoch 138/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.3749 - val_accuracy: 0.8892\n","\n","Epoch 00138: val_accuracy did not improve from 0.94828\n","Epoch 139/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4877 - val_accuracy: 0.8892\n","\n","Epoch 00139: val_accuracy did not improve from 0.94828\n","Epoch 140/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.4182 - val_accuracy: 0.8990\n","\n","Epoch 00140: val_accuracy did not improve from 0.94828\n","Epoch 141/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.3655 - val_accuracy: 0.9187\n","\n","Epoch 00141: val_accuracy did not improve from 0.94828\n","Epoch 142/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.5169 - val_accuracy: 0.9015\n","\n","Epoch 00142: val_accuracy did not improve from 0.94828\n","Epoch 143/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0380 - accuracy: 0.9848 - val_loss: 0.5351 - val_accuracy: 0.8941\n","\n","Epoch 00143: val_accuracy did not improve from 0.94828\n","Epoch 144/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0226 - accuracy: 0.9903 - val_loss: 0.5328 - val_accuracy: 0.8941\n","\n","Epoch 00144: val_accuracy did not improve from 0.94828\n","Epoch 145/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0259 - accuracy: 0.9903 - val_loss: 0.5486 - val_accuracy: 0.8670\n","\n","Epoch 00145: val_accuracy did not improve from 0.94828\n","Epoch 146/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 0.7964 - val_accuracy: 0.8473\n","\n","Epoch 00146: val_accuracy did not improve from 0.94828\n","Epoch 147/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0239 - accuracy: 0.9945 - val_loss: 0.5274 - val_accuracy: 0.8842\n","\n","Epoch 00147: val_accuracy did not improve from 0.94828\n","Epoch 148/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0828 - accuracy: 0.9787 - val_loss: 0.5463 - val_accuracy: 0.8867\n","\n","Epoch 00148: val_accuracy did not improve from 0.94828\n","Epoch 149/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0322 - accuracy: 0.9896 - val_loss: 0.4635 - val_accuracy: 0.8990\n","\n","Epoch 00149: val_accuracy did not improve from 0.94828\n","Epoch 150/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.3830 - val_accuracy: 0.9113\n","\n","Epoch 00150: val_accuracy did not improve from 0.94828\n","Epoch 151/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.5537 - val_accuracy: 0.8867\n","\n","Epoch 00151: val_accuracy did not improve from 0.94828\n","Epoch 152/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.9113\n","\n","Epoch 00152: val_accuracy did not improve from 0.94828\n","Epoch 153/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.5091 - val_accuracy: 0.8941\n","\n","Epoch 00153: val_accuracy did not improve from 0.94828\n","Epoch 154/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9335\n","\n","Epoch 00154: val_accuracy did not improve from 0.94828\n","Epoch 155/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 1.3944 - val_accuracy: 0.7192\n","\n","Epoch 00155: val_accuracy did not improve from 0.94828\n","Epoch 156/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0217 - accuracy: 0.9945 - val_loss: 0.8293 - val_accuracy: 0.8719\n","\n","Epoch 00156: val_accuracy did not improve from 0.94828\n","Epoch 157/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.4397 - val_accuracy: 0.8941\n","\n","Epoch 00157: val_accuracy did not improve from 0.94828\n","Epoch 158/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0278 - accuracy: 0.9896 - val_loss: 0.6271 - val_accuracy: 0.8941\n","\n","Epoch 00158: val_accuracy did not improve from 0.94828\n","Epoch 159/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.5306 - val_accuracy: 0.8842\n","\n","Epoch 00159: val_accuracy did not improve from 0.94828\n","Epoch 160/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1011 - accuracy: 0.9708 - val_loss: 1.5466 - val_accuracy: 0.8005\n","\n","Epoch 00160: val_accuracy did not improve from 0.94828\n","Epoch 161/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0589 - accuracy: 0.9793 - val_loss: 0.5740 - val_accuracy: 0.8892\n","\n","Epoch 00161: val_accuracy did not improve from 0.94828\n","Epoch 162/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0411 - accuracy: 0.9860 - val_loss: 0.6160 - val_accuracy: 0.8719\n","\n","Epoch 00162: val_accuracy did not improve from 0.94828\n","Epoch 163/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.5631 - val_accuracy: 0.8941\n","\n","Epoch 00163: val_accuracy did not improve from 0.94828\n","Epoch 164/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.4109 - val_accuracy: 0.9015\n","\n","Epoch 00164: val_accuracy did not improve from 0.94828\n","Epoch 165/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.3880 - val_accuracy: 0.9187\n","\n","Epoch 00165: val_accuracy did not improve from 0.94828\n","Epoch 166/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3150 - val_accuracy: 0.9335\n","\n","Epoch 00166: val_accuracy did not improve from 0.94828\n","Epoch 167/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.4116 - val_accuracy: 0.9089\n","\n","Epoch 00167: val_accuracy did not improve from 0.94828\n","Epoch 168/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.4434 - val_accuracy: 0.9138\n","\n","Epoch 00168: val_accuracy did not improve from 0.94828\n","Epoch 169/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4497 - val_accuracy: 0.9113\n","\n","Epoch 00169: val_accuracy did not improve from 0.94828\n","Epoch 170/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.3952 - val_accuracy: 0.9113\n","\n","Epoch 00170: val_accuracy did not improve from 0.94828\n","Epoch 171/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.4262 - val_accuracy: 0.9113\n","\n","Epoch 00171: val_accuracy did not improve from 0.94828\n","Epoch 172/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.3761 - val_accuracy: 0.9089\n","\n","Epoch 00172: val_accuracy did not improve from 0.94828\n","Epoch 173/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.3312 - val_accuracy: 0.9261\n","\n","Epoch 00173: val_accuracy did not improve from 0.94828\n","Epoch 174/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9310\n","\n","Epoch 00174: val_accuracy did not improve from 0.94828\n","Epoch 175/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.3002 - val_accuracy: 0.9335\n","\n","Epoch 00175: val_accuracy did not improve from 0.94828\n","Epoch 176/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.4557 - val_accuracy: 0.9089\n","\n","Epoch 00176: val_accuracy did not improve from 0.94828\n","Epoch 177/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.3905 - val_accuracy: 0.9187\n","\n","Epoch 00177: val_accuracy did not improve from 0.94828\n","Epoch 178/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9236\n","\n","Epoch 00178: val_accuracy did not improve from 0.94828\n","Epoch 179/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.3606 - val_accuracy: 0.9360\n","\n","Epoch 00179: val_accuracy did not improve from 0.94828\n","Epoch 180/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.3816 - val_accuracy: 0.9286\n","\n","Epoch 00180: val_accuracy did not improve from 0.94828\n","Epoch 181/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.3632 - val_accuracy: 0.9236\n","\n","Epoch 00181: val_accuracy did not improve from 0.94828\n","Epoch 182/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.9236\n","\n","Epoch 00182: val_accuracy did not improve from 0.94828\n","Epoch 183/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.6372 - val_accuracy: 0.8768\n","\n","Epoch 00183: val_accuracy did not improve from 0.94828\n","Epoch 184/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.4535 - val_accuracy: 0.8990\n","\n","Epoch 00184: val_accuracy did not improve from 0.94828\n","Epoch 185/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0487 - accuracy: 0.9836 - val_loss: 0.7227 - val_accuracy: 0.8670\n","\n","Epoch 00185: val_accuracy did not improve from 0.94828\n","Epoch 186/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0495 - accuracy: 0.9829 - val_loss: 0.8736 - val_accuracy: 0.8079\n","\n","Epoch 00186: val_accuracy did not improve from 0.94828\n","Epoch 187/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0744 - accuracy: 0.9756 - val_loss: 0.7705 - val_accuracy: 0.8448\n","\n","Epoch 00187: val_accuracy did not improve from 0.94828\n","Epoch 188/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0347 - accuracy: 0.9860 - val_loss: 0.4962 - val_accuracy: 0.8916\n","\n","Epoch 00188: val_accuracy did not improve from 0.94828\n","Epoch 189/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0327 - accuracy: 0.9866 - val_loss: 0.5443 - val_accuracy: 0.9064\n","\n","Epoch 00189: val_accuracy did not improve from 0.94828\n","Epoch 190/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0861 - accuracy: 0.9744 - val_loss: 1.6018 - val_accuracy: 0.7438\n","\n","Epoch 00190: val_accuracy did not improve from 0.94828\n","Epoch 191/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 0.6927 - val_accuracy: 0.8473\n","\n","Epoch 00191: val_accuracy did not improve from 0.94828\n","Epoch 192/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.5960 - val_accuracy: 0.8670\n","\n","Epoch 00192: val_accuracy did not improve from 0.94828\n","Epoch 193/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.4379 - val_accuracy: 0.9163\n","\n","Epoch 00193: val_accuracy did not improve from 0.94828\n","Epoch 194/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.4536 - val_accuracy: 0.9163\n","\n","Epoch 00194: val_accuracy did not improve from 0.94828\n","Epoch 195/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4017 - val_accuracy: 0.9113\n","\n","Epoch 00195: val_accuracy did not improve from 0.94828\n","Epoch 196/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9261\n","\n","Epoch 00196: val_accuracy did not improve from 0.94828\n","Epoch 197/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9261\n","\n","Epoch 00197: val_accuracy did not improve from 0.94828\n","Epoch 198/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.3317 - val_accuracy: 0.9286\n","\n","Epoch 00198: val_accuracy did not improve from 0.94828\n","Epoch 199/500\n","52/52 [==============================] - 20s 387ms/step - loss: 6.1599e-04 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.9236\n","\n","Epoch 00199: val_accuracy did not improve from 0.94828\n","Epoch 200/500\n","52/52 [==============================] - 20s 386ms/step - loss: 5.1290e-04 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9212\n","\n","Epoch 00200: val_accuracy did not improve from 0.94828\n","Epoch 201/500\n","52/52 [==============================] - 20s 389ms/step - loss: 4.6514e-04 - accuracy: 1.0000 - val_loss: 0.3740 - val_accuracy: 0.9236\n","\n","Epoch 00201: val_accuracy did not improve from 0.94828\n","Epoch 202/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5707 - val_accuracy: 0.8916\n","\n","Epoch 00202: val_accuracy did not improve from 0.94828\n","Epoch 203/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9187\n","\n","Epoch 00203: val_accuracy did not improve from 0.94828\n","Epoch 204/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.9138\n","\n","Epoch 00204: val_accuracy did not improve from 0.94828\n","Epoch 205/500\n","52/52 [==============================] - 20s 386ms/step - loss: 5.7919e-04 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9310\n","\n","Epoch 00205: val_accuracy did not improve from 0.94828\n","Epoch 206/500\n","52/52 [==============================] - 20s 387ms/step - loss: 9.7359e-04 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9236\n","\n","Epoch 00206: val_accuracy did not improve from 0.94828\n","Epoch 207/500\n","52/52 [==============================] - 20s 388ms/step - loss: 6.1993e-04 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9261\n","\n","Epoch 00207: val_accuracy did not improve from 0.94828\n","Epoch 208/500\n","52/52 [==============================] - 20s 387ms/step - loss: 3.6099e-04 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9409\n","\n","Epoch 00208: val_accuracy did not improve from 0.94828\n","Epoch 209/500\n","52/52 [==============================] - 20s 387ms/step - loss: 3.3572e-04 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9261\n","\n","Epoch 00209: val_accuracy did not improve from 0.94828\n","Epoch 210/500\n","52/52 [==============================] - 20s 387ms/step - loss: 8.8891e-04 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9310\n","\n","Epoch 00210: val_accuracy did not improve from 0.94828\n","Epoch 211/500\n","52/52 [==============================] - 20s 387ms/step - loss: 9.7814e-04 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.9360\n","\n","Epoch 00211: val_accuracy did not improve from 0.94828\n","Epoch 212/500\n","52/52 [==============================] - 20s 388ms/step - loss: 7.5196e-04 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9360\n","\n","Epoch 00212: val_accuracy did not improve from 0.94828\n","Epoch 213/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.2047 - accuracy: 0.9421 - val_loss: 1.6248 - val_accuracy: 0.7734\n","\n","Epoch 00213: val_accuracy did not improve from 0.94828\n","Epoch 214/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0932 - accuracy: 0.9677 - val_loss: 1.0469 - val_accuracy: 0.8005\n","\n","Epoch 00214: val_accuracy did not improve from 0.94828\n","Epoch 215/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0458 - accuracy: 0.9860 - val_loss: 0.8070 - val_accuracy: 0.8448\n","\n","Epoch 00215: val_accuracy did not improve from 0.94828\n","Epoch 216/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1299 - accuracy: 0.9610 - val_loss: 1.0349 - val_accuracy: 0.8202\n","\n","Epoch 00216: val_accuracy did not improve from 0.94828\n","Epoch 217/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 0.8882 - val_accuracy: 0.8522\n","\n","Epoch 00217: val_accuracy did not improve from 0.94828\n","Epoch 218/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.4446 - val_accuracy: 0.8990\n","\n","Epoch 00218: val_accuracy did not improve from 0.94828\n","Epoch 219/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.5041 - val_accuracy: 0.8916\n","\n","Epoch 00219: val_accuracy did not improve from 0.94828\n","Epoch 220/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.4506 - val_accuracy: 0.9064\n","\n","Epoch 00220: val_accuracy did not improve from 0.94828\n","Epoch 221/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.3561 - val_accuracy: 0.9261\n","\n","Epoch 00221: val_accuracy did not improve from 0.94828\n","Epoch 222/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.9236\n","\n","Epoch 00222: val_accuracy did not improve from 0.94828\n","Epoch 223/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4294 - val_accuracy: 0.9286\n","\n","Epoch 00223: val_accuracy did not improve from 0.94828\n","Epoch 224/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4265 - val_accuracy: 0.9064\n","\n","Epoch 00224: val_accuracy did not improve from 0.94828\n","Epoch 225/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4135 - val_accuracy: 0.9261\n","\n","Epoch 00225: val_accuracy did not improve from 0.94828\n","Epoch 226/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.3727 - val_accuracy: 0.9089\n","\n","Epoch 00226: val_accuracy did not improve from 0.94828\n","Epoch 227/500\n","52/52 [==============================] - 20s 388ms/step - loss: 9.2961e-04 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9187\n","\n","Epoch 00227: val_accuracy did not improve from 0.94828\n","Epoch 228/500\n","52/52 [==============================] - 20s 386ms/step - loss: 8.3482e-04 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.9138\n","\n","Epoch 00228: val_accuracy did not improve from 0.94828\n","Epoch 229/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9335\n","\n","Epoch 00229: val_accuracy did not improve from 0.94828\n","Epoch 230/500\n","52/52 [==============================] - 20s 387ms/step - loss: 6.3460e-04 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.9212\n","\n","Epoch 00230: val_accuracy did not improve from 0.94828\n","Epoch 231/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.8734e-04 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 0.9310\n","\n","Epoch 00231: val_accuracy did not improve from 0.94828\n","Epoch 232/500\n","52/52 [==============================] - 20s 387ms/step - loss: 8.3067e-04 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9286\n","\n","Epoch 00232: val_accuracy did not improve from 0.94828\n","Epoch 233/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.3742 - val_accuracy: 0.9261\n","\n","Epoch 00233: val_accuracy did not improve from 0.94828\n","Epoch 234/500\n","52/52 [==============================] - 20s 388ms/step - loss: 7.0247e-04 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9286\n","\n","Epoch 00234: val_accuracy did not improve from 0.94828\n","Epoch 235/500\n","52/52 [==============================] - 20s 389ms/step - loss: 3.0608e-04 - accuracy: 1.0000 - val_loss: 0.3582 - val_accuracy: 0.9261\n","\n","Epoch 00235: val_accuracy did not improve from 0.94828\n","Epoch 236/500\n","52/52 [==============================] - 20s 387ms/step - loss: 8.5199e-04 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9409\n","\n","Epoch 00236: val_accuracy did not improve from 0.94828\n","Epoch 237/500\n","52/52 [==============================] - 20s 387ms/step - loss: 5.2840e-04 - accuracy: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9360\n","\n","Epoch 00237: val_accuracy did not improve from 0.94828\n","Epoch 238/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3751 - val_accuracy: 0.9261\n","\n","Epoch 00238: val_accuracy did not improve from 0.94828\n","Epoch 239/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4480 - val_accuracy: 0.9261\n","\n","Epoch 00239: val_accuracy did not improve from 0.94828\n","Epoch 240/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4418 - val_accuracy: 0.9212\n","\n","Epoch 00240: val_accuracy did not improve from 0.94828\n","Epoch 241/500\n","52/52 [==============================] - 20s 387ms/step - loss: 6.9222e-04 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9187\n","\n","Epoch 00241: val_accuracy did not improve from 0.94828\n","Epoch 242/500\n","52/52 [==============================] - 20s 387ms/step - loss: 5.8474e-04 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.9212\n","\n","Epoch 00242: val_accuracy did not improve from 0.94828\n","Epoch 243/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.9769e-04 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9360\n","\n","Epoch 00243: val_accuracy did not improve from 0.94828\n","Epoch 244/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.3446e-04 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9236\n","\n","Epoch 00244: val_accuracy did not improve from 0.94828\n","Epoch 245/500\n","52/52 [==============================] - 20s 386ms/step - loss: 2.1925e-04 - accuracy: 1.0000 - val_loss: 0.3959 - val_accuracy: 0.9212\n","\n","Epoch 00245: val_accuracy did not improve from 0.94828\n","Epoch 246/500\n","52/52 [==============================] - 20s 387ms/step - loss: 6.0211e-04 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9261\n","\n","Epoch 00246: val_accuracy did not improve from 0.94828\n","Epoch 247/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.8434e-04 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.9261\n","\n","Epoch 00247: val_accuracy did not improve from 0.94828\n","Epoch 248/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.5393 - val_accuracy: 0.9138\n","\n","Epoch 00248: val_accuracy did not improve from 0.94828\n","Epoch 249/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.8688 - val_accuracy: 0.8374\n","\n","Epoch 00249: val_accuracy did not improve from 0.94828\n","Epoch 250/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0797 - accuracy: 0.9811 - val_loss: 1.3355 - val_accuracy: 0.7980\n","\n","Epoch 00250: val_accuracy did not improve from 0.94828\n","Epoch 251/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1320 - accuracy: 0.9598 - val_loss: 5.2386 - val_accuracy: 0.4852\n","\n","Epoch 00251: val_accuracy did not improve from 0.94828\n","Epoch 252/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0569 - accuracy: 0.9793 - val_loss: 0.5649 - val_accuracy: 0.8941\n","\n","Epoch 00252: val_accuracy did not improve from 0.94828\n","Epoch 253/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.6206 - val_accuracy: 0.8941\n","\n","Epoch 00253: val_accuracy did not improve from 0.94828\n","Epoch 254/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.3566 - val_accuracy: 0.9236\n","\n","Epoch 00254: val_accuracy did not improve from 0.94828\n","Epoch 255/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0158 - accuracy: 0.9933 - val_loss: 0.4764 - val_accuracy: 0.8867\n","\n","Epoch 00255: val_accuracy did not improve from 0.94828\n","Epoch 256/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.4431 - val_accuracy: 0.9236\n","\n","Epoch 00256: val_accuracy did not improve from 0.94828\n","Epoch 257/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.6280 - val_accuracy: 0.8916\n","\n","Epoch 00257: val_accuracy did not improve from 0.94828\n","Epoch 258/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4520 - val_accuracy: 0.8966\n","\n","Epoch 00258: val_accuracy did not improve from 0.94828\n","Epoch 259/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.6299 - val_accuracy: 0.8941\n","\n","Epoch 00259: val_accuracy did not improve from 0.94828\n","Epoch 260/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.4948 - val_accuracy: 0.9039\n","\n","Epoch 00260: val_accuracy did not improve from 0.94828\n","Epoch 261/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4312 - val_accuracy: 0.9064\n","\n","Epoch 00261: val_accuracy did not improve from 0.94828\n","Epoch 262/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0330 - accuracy: 0.9915 - val_loss: 0.9032 - val_accuracy: 0.8621\n","\n","Epoch 00262: val_accuracy did not improve from 0.94828\n","Epoch 263/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.7065 - val_accuracy: 0.8596\n","\n","Epoch 00263: val_accuracy did not improve from 0.94828\n","Epoch 264/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.6166 - val_accuracy: 0.8744\n","\n","Epoch 00264: val_accuracy did not improve from 0.94828\n","Epoch 265/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.4582 - val_accuracy: 0.8966\n","\n","Epoch 00265: val_accuracy did not improve from 0.94828\n","Epoch 266/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.3048 - val_accuracy: 0.9310\n","\n","Epoch 00266: val_accuracy did not improve from 0.94828\n","Epoch 267/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.3531 - val_accuracy: 0.9187\n","\n","Epoch 00267: val_accuracy did not improve from 0.94828\n","Epoch 268/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.3986 - val_accuracy: 0.9064\n","\n","Epoch 00268: val_accuracy did not improve from 0.94828\n","Epoch 269/500\n","52/52 [==============================] - 20s 388ms/step - loss: 7.1145e-04 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.9113\n","\n","Epoch 00269: val_accuracy did not improve from 0.94828\n","Epoch 270/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4490 - val_accuracy: 0.9138\n","\n","Epoch 00270: val_accuracy did not improve from 0.94828\n","Epoch 271/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.3885 - val_accuracy: 0.9163\n","\n","Epoch 00271: val_accuracy did not improve from 0.94828\n","Epoch 272/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4044 - val_accuracy: 0.9187\n","\n","Epoch 00272: val_accuracy did not improve from 0.94828\n","Epoch 273/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.9113\n","\n","Epoch 00273: val_accuracy did not improve from 0.94828\n","Epoch 274/500\n","52/52 [==============================] - 20s 391ms/step - loss: 5.8911e-04 - accuracy: 1.0000 - val_loss: 0.3771 - val_accuracy: 0.9236\n","\n","Epoch 00274: val_accuracy did not improve from 0.94828\n","Epoch 275/500\n","52/52 [==============================] - 20s 387ms/step - loss: 8.7054e-04 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.9163\n","\n","Epoch 00275: val_accuracy did not improve from 0.94828\n","Epoch 276/500\n","52/52 [==============================] - 20s 386ms/step - loss: 4.7047e-04 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.9089\n","\n","Epoch 00276: val_accuracy did not improve from 0.94828\n","Epoch 277/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.5728 - val_accuracy: 0.8916\n","\n","Epoch 00277: val_accuracy did not improve from 0.94828\n","Epoch 278/500\n","52/52 [==============================] - 20s 390ms/step - loss: 7.0181e-04 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9286\n","\n","Epoch 00278: val_accuracy did not improve from 0.94828\n","Epoch 279/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4542 - val_accuracy: 0.9039\n","\n","Epoch 00279: val_accuracy did not improve from 0.94828\n","Epoch 280/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.6495 - val_accuracy: 0.8621\n","\n","Epoch 00280: val_accuracy did not improve from 0.94828\n","Epoch 281/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.5598 - val_accuracy: 0.8966\n","\n","Epoch 00281: val_accuracy did not improve from 0.94828\n","Epoch 282/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.9492 - val_accuracy: 0.8251\n","\n","Epoch 00282: val_accuracy did not improve from 0.94828\n","Epoch 283/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0531 - accuracy: 0.9823 - val_loss: 2.3230 - val_accuracy: 0.6256\n","\n","Epoch 00283: val_accuracy did not improve from 0.94828\n","Epoch 284/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0922 - accuracy: 0.9720 - val_loss: 1.7302 - val_accuracy: 0.8153\n","\n","Epoch 00284: val_accuracy did not improve from 0.94828\n","Epoch 285/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0425 - accuracy: 0.9829 - val_loss: 1.3642 - val_accuracy: 0.8325\n","\n","Epoch 00285: val_accuracy did not improve from 0.94828\n","Epoch 286/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0185 - accuracy: 0.9927 - val_loss: 0.6637 - val_accuracy: 0.8399\n","\n","Epoch 00286: val_accuracy did not improve from 0.94828\n","Epoch 287/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0413 - accuracy: 0.9903 - val_loss: 0.3584 - val_accuracy: 0.9064\n","\n","Epoch 00287: val_accuracy did not improve from 0.94828\n","Epoch 288/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.4706 - val_accuracy: 0.8818\n","\n","Epoch 00288: val_accuracy did not improve from 0.94828\n","Epoch 289/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4050 - val_accuracy: 0.9236\n","\n","Epoch 00289: val_accuracy did not improve from 0.94828\n","Epoch 290/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.9335\n","\n","Epoch 00290: val_accuracy did not improve from 0.94828\n","Epoch 291/500\n","52/52 [==============================] - 20s 388ms/step - loss: 8.5488e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9286\n","\n","Epoch 00291: val_accuracy did not improve from 0.94828\n","Epoch 292/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0346 - accuracy: 0.9915 - val_loss: 0.6180 - val_accuracy: 0.8818\n","\n","Epoch 00292: val_accuracy did not improve from 0.94828\n","Epoch 293/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 0.8057 - val_accuracy: 0.8547\n","\n","Epoch 00293: val_accuracy did not improve from 0.94828\n","Epoch 294/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.5208 - val_accuracy: 0.8719\n","\n","Epoch 00294: val_accuracy did not improve from 0.94828\n","Epoch 295/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.4797 - val_accuracy: 0.8892\n","\n","Epoch 00295: val_accuracy did not improve from 0.94828\n","Epoch 296/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.3872 - val_accuracy: 0.9064\n","\n","Epoch 00296: val_accuracy did not improve from 0.94828\n","Epoch 297/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.3636 - val_accuracy: 0.9187\n","\n","Epoch 00297: val_accuracy did not improve from 0.94828\n","Epoch 298/500\n","52/52 [==============================] - 20s 387ms/step - loss: 8.2825e-04 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.8990\n","\n","Epoch 00298: val_accuracy did not improve from 0.94828\n","Epoch 299/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.5222 - val_accuracy: 0.8695\n","\n","Epoch 00299: val_accuracy did not improve from 0.94828\n","Epoch 300/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4778 - val_accuracy: 0.8892\n","\n","Epoch 00300: val_accuracy did not improve from 0.94828\n","Epoch 301/500\n","52/52 [==============================] - 20s 386ms/step - loss: 9.7648e-04 - accuracy: 1.0000 - val_loss: 0.3844 - val_accuracy: 0.9064\n","\n","Epoch 00301: val_accuracy did not improve from 0.94828\n","Epoch 302/500\n","52/52 [==============================] - 20s 387ms/step - loss: 5.5735e-04 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.9163\n","\n","Epoch 00302: val_accuracy did not improve from 0.94828\n","Epoch 303/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.3115 - val_accuracy: 0.9310\n","\n","Epoch 00303: val_accuracy did not improve from 0.94828\n","Epoch 304/500\n","52/52 [==============================] - 20s 386ms/step - loss: 5.5283e-04 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9335\n","\n","Epoch 00304: val_accuracy did not improve from 0.94828\n","Epoch 305/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.3881e-04 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9360\n","\n","Epoch 00305: val_accuracy did not improve from 0.94828\n","Epoch 306/500\n","52/52 [==============================] - 20s 386ms/step - loss: 6.6325e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9433\n","\n","Epoch 00306: val_accuracy did not improve from 0.94828\n","Epoch 307/500\n","52/52 [==============================] - 20s 386ms/step - loss: 3.4717e-04 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9360\n","\n","Epoch 00307: val_accuracy did not improve from 0.94828\n","Epoch 308/500\n","52/52 [==============================] - 20s 388ms/step - loss: 5.9694e-04 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.9360\n","\n","Epoch 00308: val_accuracy did not improve from 0.94828\n","Epoch 309/500\n","52/52 [==============================] - 20s 386ms/step - loss: 2.3491e-04 - accuracy: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.9384\n","\n","Epoch 00309: val_accuracy did not improve from 0.94828\n","Epoch 310/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.4167 - val_accuracy: 0.9212\n","\n","Epoch 00310: val_accuracy did not improve from 0.94828\n","Epoch 311/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.9187\n","\n","Epoch 00311: val_accuracy did not improve from 0.94828\n","Epoch 312/500\n","52/52 [==============================] - 20s 387ms/step - loss: 4.5730e-04 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.9335\n","\n","Epoch 00312: val_accuracy did not improve from 0.94828\n","Epoch 313/500\n","52/52 [==============================] - 20s 386ms/step - loss: 9.8356e-04 - accuracy: 0.9994 - val_loss: 0.4771 - val_accuracy: 0.9163\n","\n","Epoch 00313: val_accuracy did not improve from 0.94828\n","Epoch 314/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.0184e-04 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.9236\n","\n","Epoch 00314: val_accuracy did not improve from 0.94828\n","Epoch 315/500\n","52/52 [==============================] - 20s 388ms/step - loss: 6.9232e-04 - accuracy: 1.0000 - val_loss: 0.4479 - val_accuracy: 0.9261\n","\n","Epoch 00315: val_accuracy did not improve from 0.94828\n","Epoch 316/500\n","52/52 [==============================] - 20s 386ms/step - loss: 3.4644e-04 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.9236\n","\n","Epoch 00316: val_accuracy did not improve from 0.94828\n","Epoch 317/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.8379e-04 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.9212\n","\n","Epoch 00317: val_accuracy did not improve from 0.94828\n","Epoch 318/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.6132 - val_accuracy: 0.8818\n","\n","Epoch 00318: val_accuracy did not improve from 0.94828\n","Epoch 319/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.7842 - val_accuracy: 0.8399\n","\n","Epoch 00319: val_accuracy did not improve from 0.94828\n","Epoch 320/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1637 - accuracy: 0.9495 - val_loss: 2.0986 - val_accuracy: 0.7660\n","\n","Epoch 00320: val_accuracy did not improve from 0.94828\n","Epoch 321/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0979 - accuracy: 0.9732 - val_loss: 1.9556 - val_accuracy: 0.7389\n","\n","Epoch 00321: val_accuracy did not improve from 0.94828\n","Epoch 322/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0241 - accuracy: 0.9939 - val_loss: 0.7683 - val_accuracy: 0.8621\n","\n","Epoch 00322: val_accuracy did not improve from 0.94828\n","Epoch 323/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.4867 - val_accuracy: 0.8867\n","\n","Epoch 00323: val_accuracy did not improve from 0.94828\n","Epoch 324/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4710 - val_accuracy: 0.9064\n","\n","Epoch 00324: val_accuracy did not improve from 0.94828\n","Epoch 325/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.3845 - val_accuracy: 0.9039\n","\n","Epoch 00325: val_accuracy did not improve from 0.94828\n","Epoch 326/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.2637 - val_accuracy: 0.9261\n","\n","Epoch 00326: val_accuracy did not improve from 0.94828\n","Epoch 327/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9261\n","\n","Epoch 00327: val_accuracy did not improve from 0.94828\n","Epoch 328/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.9236\n","\n","Epoch 00328: val_accuracy did not improve from 0.94828\n","Epoch 329/500\n","52/52 [==============================] - 20s 389ms/step - loss: 8.9990e-04 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9335\n","\n","Epoch 00329: val_accuracy did not improve from 0.94828\n","Epoch 330/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.2895 - val_accuracy: 0.9261\n","\n","Epoch 00330: val_accuracy did not improve from 0.94828\n","Epoch 331/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.3684 - val_accuracy: 0.9163\n","\n","Epoch 00331: val_accuracy did not improve from 0.94828\n","Epoch 332/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9310\n","\n","Epoch 00332: val_accuracy did not improve from 0.94828\n","Epoch 333/500\n","52/52 [==============================] - 20s 386ms/step - loss: 4.5152e-04 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.9286\n","\n","Epoch 00333: val_accuracy did not improve from 0.94828\n","Epoch 334/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.4014e-04 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 0.9236\n","\n","Epoch 00334: val_accuracy did not improve from 0.94828\n","Epoch 335/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.4836e-04 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9409\n","\n","Epoch 00335: val_accuracy did not improve from 0.94828\n","Epoch 336/500\n","52/52 [==============================] - 20s 387ms/step - loss: 3.7990e-04 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9310\n","\n","Epoch 00336: val_accuracy did not improve from 0.94828\n","Epoch 337/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.3095 - val_accuracy: 0.9360\n","\n","Epoch 00337: val_accuracy did not improve from 0.94828\n","Epoch 338/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3278 - val_accuracy: 0.9335\n","\n","Epoch 00338: val_accuracy did not improve from 0.94828\n","Epoch 339/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9113\n","\n","Epoch 00339: val_accuracy did not improve from 0.94828\n","Epoch 340/500\n","52/52 [==============================] - 20s 387ms/step - loss: 9.4225e-04 - accuracy: 1.0000 - val_loss: 0.3272 - val_accuracy: 0.9335\n","\n","Epoch 00340: val_accuracy did not improve from 0.94828\n","Epoch 341/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.5807e-04 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9310\n","\n","Epoch 00341: val_accuracy did not improve from 0.94828\n","Epoch 342/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.1645e-04 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9384\n","\n","Epoch 00342: val_accuracy did not improve from 0.94828\n","Epoch 343/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.4513e-04 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.9335\n","\n","Epoch 00343: val_accuracy did not improve from 0.94828\n","Epoch 344/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.6259e-04 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9310\n","\n","Epoch 00344: val_accuracy did not improve from 0.94828\n","Epoch 345/500\n","52/52 [==============================] - 20s 387ms/step - loss: 3.3246e-04 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9310\n","\n","Epoch 00345: val_accuracy did not improve from 0.94828\n","Epoch 346/500\n","52/52 [==============================] - 20s 386ms/step - loss: 3.4555e-04 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.9360\n","\n","Epoch 00346: val_accuracy did not improve from 0.94828\n","Epoch 347/500\n","52/52 [==============================] - 20s 387ms/step - loss: 1.7344e-04 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9360\n","\n","Epoch 00347: val_accuracy did not improve from 0.94828\n","Epoch 348/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.9371e-04 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9360\n","\n","Epoch 00348: val_accuracy did not improve from 0.94828\n","Epoch 349/500\n","52/52 [==============================] - 20s 387ms/step - loss: 3.1447e-04 - accuracy: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.9261\n","\n","Epoch 00349: val_accuracy did not improve from 0.94828\n","Epoch 350/500\n","52/52 [==============================] - 20s 387ms/step - loss: 3.3595e-04 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9433\n","\n","Epoch 00350: val_accuracy did not improve from 0.94828\n","Epoch 351/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.4305e-04 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9310\n","\n","Epoch 00351: val_accuracy did not improve from 0.94828\n","Epoch 352/500\n","52/52 [==============================] - 20s 388ms/step - loss: 1.5832e-04 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9261\n","\n","Epoch 00352: val_accuracy did not improve from 0.94828\n","Epoch 353/500\n","52/52 [==============================] - 20s 388ms/step - loss: 1.8765e-04 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 0.9384\n","\n","Epoch 00353: val_accuracy did not improve from 0.94828\n","Epoch 354/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.5446e-04 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9409\n","\n","Epoch 00354: val_accuracy did not improve from 0.94828\n","Epoch 355/500\n","52/52 [==============================] - 20s 388ms/step - loss: 1.7791e-04 - accuracy: 1.0000 - val_loss: 0.3480 - val_accuracy: 0.9360\n","\n","Epoch 00355: val_accuracy did not improve from 0.94828\n","Epoch 356/500\n","52/52 [==============================] - 20s 389ms/step - loss: 4.1198e-04 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9286\n","\n","Epoch 00356: val_accuracy did not improve from 0.94828\n","Epoch 357/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4131 - val_accuracy: 0.9089\n","\n","Epoch 00357: val_accuracy did not improve from 0.94828\n","Epoch 358/500\n","52/52 [==============================] - 20s 387ms/step - loss: 4.1600e-04 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9236\n","\n","Epoch 00358: val_accuracy did not improve from 0.94828\n","Epoch 359/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.8078 - val_accuracy: 0.8621\n","\n","Epoch 00359: val_accuracy did not improve from 0.94828\n","Epoch 360/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0948 - accuracy: 0.9677 - val_loss: 1.4416 - val_accuracy: 0.7833\n","\n","Epoch 00360: val_accuracy did not improve from 0.94828\n","Epoch 361/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1140 - accuracy: 0.9598 - val_loss: 0.8895 - val_accuracy: 0.8153\n","\n","Epoch 00361: val_accuracy did not improve from 0.94828\n","Epoch 362/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0254 - accuracy: 0.9909 - val_loss: 0.6069 - val_accuracy: 0.8990\n","\n","Epoch 00362: val_accuracy did not improve from 0.94828\n","Epoch 363/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0455 - accuracy: 0.9854 - val_loss: 0.5413 - val_accuracy: 0.8892\n","\n","Epoch 00363: val_accuracy did not improve from 0.94828\n","Epoch 364/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0417 - accuracy: 0.9866 - val_loss: 0.6876 - val_accuracy: 0.8768\n","\n","Epoch 00364: val_accuracy did not improve from 0.94828\n","Epoch 365/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0243 - accuracy: 0.9903 - val_loss: 0.4524 - val_accuracy: 0.9113\n","\n","Epoch 00365: val_accuracy did not improve from 0.94828\n","Epoch 366/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0148 - accuracy: 0.9939 - val_loss: 0.5090 - val_accuracy: 0.8916\n","\n","Epoch 00366: val_accuracy did not improve from 0.94828\n","Epoch 367/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.8990\n","\n","Epoch 00367: val_accuracy did not improve from 0.94828\n","Epoch 368/500\n","52/52 [==============================] - 20s 387ms/step - loss: 8.3962e-04 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9261\n","\n","Epoch 00368: val_accuracy did not improve from 0.94828\n","Epoch 369/500\n","52/52 [==============================] - 20s 387ms/step - loss: 6.0565e-04 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9384\n","\n","Epoch 00369: val_accuracy did not improve from 0.94828\n","Epoch 370/500\n","52/52 [==============================] - 20s 388ms/step - loss: 8.6512e-04 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.9310\n","\n","Epoch 00370: val_accuracy did not improve from 0.94828\n","Epoch 371/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.3234 - val_accuracy: 0.9286\n","\n","Epoch 00371: val_accuracy did not improve from 0.94828\n","Epoch 372/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9360\n","\n","Epoch 00372: val_accuracy did not improve from 0.94828\n","Epoch 373/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9310\n","\n","Epoch 00373: val_accuracy did not improve from 0.94828\n","Epoch 374/500\n","52/52 [==============================] - 20s 387ms/step - loss: 6.3834e-04 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9286\n","\n","Epoch 00374: val_accuracy did not improve from 0.94828\n","Epoch 375/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.3757 - val_accuracy: 0.9236\n","\n","Epoch 00375: val_accuracy did not improve from 0.94828\n","Epoch 376/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.9187\n","\n","Epoch 00376: val_accuracy did not improve from 0.94828\n","Epoch 377/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.7713e-04 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 0.9310\n","\n","Epoch 00377: val_accuracy did not improve from 0.94828\n","Epoch 378/500\n","52/52 [==============================] - 20s 391ms/step - loss: 4.7436e-04 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.9310\n","\n","Epoch 00378: val_accuracy did not improve from 0.94828\n","Epoch 379/500\n","52/52 [==============================] - 20s 387ms/step - loss: 7.0506e-04 - accuracy: 0.9994 - val_loss: 0.3178 - val_accuracy: 0.9335\n","\n","Epoch 00379: val_accuracy did not improve from 0.94828\n","Epoch 380/500\n","52/52 [==============================] - 20s 387ms/step - loss: 5.6751e-04 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.9384\n","\n","Epoch 00380: val_accuracy did not improve from 0.94828\n","Epoch 381/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.8584e-04 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9335\n","\n","Epoch 00381: val_accuracy did not improve from 0.94828\n","Epoch 382/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.1582e-04 - accuracy: 1.0000 - val_loss: 0.3377 - val_accuracy: 0.9384\n","\n","Epoch 00382: val_accuracy did not improve from 0.94828\n","Epoch 383/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.4696e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9286\n","\n","Epoch 00383: val_accuracy did not improve from 0.94828\n","Epoch 384/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.5127e-04 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9310\n","\n","Epoch 00384: val_accuracy did not improve from 0.94828\n","Epoch 385/500\n","52/52 [==============================] - 20s 389ms/step - loss: 2.9277e-04 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9261\n","\n","Epoch 00385: val_accuracy did not improve from 0.94828\n","Epoch 386/500\n","52/52 [==============================] - 20s 387ms/step - loss: 1.9682e-04 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9335\n","\n","Epoch 00386: val_accuracy did not improve from 0.94828\n","Epoch 387/500\n","52/52 [==============================] - 20s 389ms/step - loss: 1.2708e-04 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.9384\n","\n","Epoch 00387: val_accuracy did not improve from 0.94828\n","Epoch 388/500\n","52/52 [==============================] - 20s 388ms/step - loss: 1.6790e-04 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.9335\n","\n","Epoch 00388: val_accuracy did not improve from 0.94828\n","Epoch 389/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4202 - val_accuracy: 0.9113\n","\n","Epoch 00389: val_accuracy did not improve from 0.94828\n","Epoch 390/500\n","52/52 [==============================] - 20s 386ms/step - loss: 5.4929e-04 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9335\n","\n","Epoch 00390: val_accuracy did not improve from 0.94828\n","Epoch 391/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9163\n","\n","Epoch 00391: val_accuracy did not improve from 0.94828\n","Epoch 392/500\n","52/52 [==============================] - 20s 387ms/step - loss: 6.3427e-04 - accuracy: 1.0000 - val_loss: 0.3525 - val_accuracy: 0.9409\n","\n","Epoch 00392: val_accuracy did not improve from 0.94828\n","Epoch 393/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.4909 - val_accuracy: 0.8744\n","\n","Epoch 00393: val_accuracy did not improve from 0.94828\n","Epoch 394/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4520 - val_accuracy: 0.8916\n","\n","Epoch 00394: val_accuracy did not improve from 0.94828\n","Epoch 395/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.3735 - val_accuracy: 0.9261\n","\n","Epoch 00395: val_accuracy did not improve from 0.94828\n","Epoch 396/500\n","52/52 [==============================] - 20s 386ms/step - loss: 6.6092e-04 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9187\n","\n","Epoch 00396: val_accuracy did not improve from 0.94828\n","Epoch 397/500\n","52/52 [==============================] - 20s 387ms/step - loss: 3.6924e-04 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9335\n","\n","Epoch 00397: val_accuracy did not improve from 0.94828\n","Epoch 398/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.5347e-04 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9286\n","\n","Epoch 00398: val_accuracy did not improve from 0.94828\n","Epoch 399/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5564 - val_accuracy: 0.8793\n","\n","Epoch 00399: val_accuracy did not improve from 0.94828\n","Epoch 400/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.8610 - val_accuracy: 0.8596\n","\n","Epoch 00400: val_accuracy did not improve from 0.94828\n","Epoch 401/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0943 - accuracy: 0.9738 - val_loss: 2.1328 - val_accuracy: 0.7438\n","\n","Epoch 00401: val_accuracy did not improve from 0.94828\n","Epoch 402/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0745 - accuracy: 0.9793 - val_loss: 1.5819 - val_accuracy: 0.8079\n","\n","Epoch 00402: val_accuracy did not improve from 0.94828\n","Epoch 403/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.6156 - val_accuracy: 0.8966\n","\n","Epoch 00403: val_accuracy did not improve from 0.94828\n","Epoch 404/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.5479 - val_accuracy: 0.9064\n","\n","Epoch 00404: val_accuracy did not improve from 0.94828\n","Epoch 405/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4671 - val_accuracy: 0.8966\n","\n","Epoch 00405: val_accuracy did not improve from 0.94828\n","Epoch 406/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.4870 - val_accuracy: 0.8842\n","\n","Epoch 00406: val_accuracy did not improve from 0.94828\n","Epoch 407/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4845 - val_accuracy: 0.8867\n","\n","Epoch 00407: val_accuracy did not improve from 0.94828\n","Epoch 408/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5955 - val_accuracy: 0.8547\n","\n","Epoch 00408: val_accuracy did not improve from 0.94828\n","Epoch 409/500\n","52/52 [==============================] - 20s 387ms/step - loss: 8.7658e-04 - accuracy: 1.0000 - val_loss: 0.4713 - val_accuracy: 0.8941\n","\n","Epoch 00409: val_accuracy did not improve from 0.94828\n","Epoch 410/500\n","52/52 [==============================] - 20s 387ms/step - loss: 4.4163e-04 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.9089\n","\n","Epoch 00410: val_accuracy did not improve from 0.94828\n","Epoch 411/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.7752e-04 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.9138\n","\n","Epoch 00411: val_accuracy did not improve from 0.94828\n","Epoch 412/500\n","52/52 [==============================] - 20s 387ms/step - loss: 5.5327e-04 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.9138\n","\n","Epoch 00412: val_accuracy did not improve from 0.94828\n","Epoch 413/500\n","52/52 [==============================] - 20s 388ms/step - loss: 5.8687e-04 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9163\n","\n","Epoch 00413: val_accuracy did not improve from 0.94828\n","Epoch 414/500\n","52/52 [==============================] - 20s 387ms/step - loss: 4.7311e-04 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.9261\n","\n","Epoch 00414: val_accuracy did not improve from 0.94828\n","Epoch 415/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4133 - val_accuracy: 0.9187\n","\n","Epoch 00415: val_accuracy did not improve from 0.94828\n","Epoch 416/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.3831 - val_accuracy: 0.9360\n","\n","Epoch 00416: val_accuracy did not improve from 0.94828\n","Epoch 417/500\n","52/52 [==============================] - 20s 388ms/step - loss: 9.0100e-04 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9286\n","\n","Epoch 00417: val_accuracy did not improve from 0.94828\n","Epoch 418/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.3933 - val_accuracy: 0.9212\n","\n","Epoch 00418: val_accuracy did not improve from 0.94828\n","Epoch 419/500\n","52/52 [==============================] - 20s 387ms/step - loss: 4.3953e-04 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.9187\n","\n","Epoch 00419: val_accuracy did not improve from 0.94828\n","Epoch 420/500\n","52/52 [==============================] - 20s 389ms/step - loss: 3.0066e-04 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.9310\n","\n","Epoch 00420: val_accuracy did not improve from 0.94828\n","Epoch 421/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.2122e-04 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.9261\n","\n","Epoch 00421: val_accuracy did not improve from 0.94828\n","Epoch 422/500\n","52/52 [==============================] - 20s 387ms/step - loss: 6.3943e-04 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9310\n","\n","Epoch 00422: val_accuracy did not improve from 0.94828\n","Epoch 423/500\n","52/52 [==============================] - 20s 387ms/step - loss: 3.6185e-04 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.9236\n","\n","Epoch 00423: val_accuracy did not improve from 0.94828\n","Epoch 424/500\n","52/52 [==============================] - 20s 386ms/step - loss: 1.5148e-04 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9286\n","\n","Epoch 00424: val_accuracy did not improve from 0.94828\n","Epoch 425/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0558 - accuracy: 0.9884 - val_loss: 1.5675 - val_accuracy: 0.7611\n","\n","Epoch 00425: val_accuracy did not improve from 0.94828\n","Epoch 426/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0746 - accuracy: 0.9762 - val_loss: 1.0151 - val_accuracy: 0.8498\n","\n","Epoch 00426: val_accuracy did not improve from 0.94828\n","Epoch 427/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0362 - accuracy: 0.9915 - val_loss: 0.6457 - val_accuracy: 0.8768\n","\n","Epoch 00427: val_accuracy did not improve from 0.94828\n","Epoch 428/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.5019 - val_accuracy: 0.9212\n","\n","Epoch 00428: val_accuracy did not improve from 0.94828\n","Epoch 429/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.3424 - val_accuracy: 0.9335\n","\n","Epoch 00429: val_accuracy did not improve from 0.94828\n","Epoch 430/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.4698 - val_accuracy: 0.9039\n","\n","Epoch 00430: val_accuracy did not improve from 0.94828\n","Epoch 431/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.4333 - val_accuracy: 0.8892\n","\n","Epoch 00431: val_accuracy did not improve from 0.94828\n","Epoch 432/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0142 - accuracy: 0.9945 - val_loss: 0.6795 - val_accuracy: 0.8768\n","\n","Epoch 00432: val_accuracy did not improve from 0.94828\n","Epoch 433/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4758 - val_accuracy: 0.9015\n","\n","Epoch 00433: val_accuracy did not improve from 0.94828\n","Epoch 434/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.4712 - val_accuracy: 0.8990\n","\n","Epoch 00434: val_accuracy did not improve from 0.94828\n","Epoch 435/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0060 - accuracy: 0.9963 - val_loss: 0.6108 - val_accuracy: 0.8842\n","\n","Epoch 00435: val_accuracy did not improve from 0.94828\n","Epoch 436/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.3877 - val_accuracy: 0.9261\n","\n","Epoch 00436: val_accuracy did not improve from 0.94828\n","Epoch 437/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0114 - accuracy: 0.9982 - val_loss: 1.2235 - val_accuracy: 0.7956\n","\n","Epoch 00437: val_accuracy did not improve from 0.94828\n","Epoch 438/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0439 - accuracy: 0.9915 - val_loss: 0.9708 - val_accuracy: 0.8498\n","\n","Epoch 00438: val_accuracy did not improve from 0.94828\n","Epoch 439/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0101 - accuracy: 0.9957 - val_loss: 0.7050 - val_accuracy: 0.8695\n","\n","Epoch 00439: val_accuracy did not improve from 0.94828\n","Epoch 440/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.5932 - val_accuracy: 0.9089\n","\n","Epoch 00440: val_accuracy did not improve from 0.94828\n","Epoch 441/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.5436 - val_accuracy: 0.8990\n","\n","Epoch 00441: val_accuracy did not improve from 0.94828\n","Epoch 442/500\n","52/52 [==============================] - 20s 388ms/step - loss: 6.5329e-04 - accuracy: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.9187\n","\n","Epoch 00442: val_accuracy did not improve from 0.94828\n","Epoch 443/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.2363e-04 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9064\n","\n","Epoch 00443: val_accuracy did not improve from 0.94828\n","Epoch 444/500\n","52/52 [==============================] - 20s 385ms/step - loss: 7.0331e-04 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.9286\n","\n","Epoch 00444: val_accuracy did not improve from 0.94828\n","Epoch 445/500\n","52/52 [==============================] - 20s 386ms/step - loss: 6.3276e-04 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.9187\n","\n","Epoch 00445: val_accuracy did not improve from 0.94828\n","Epoch 446/500\n","52/52 [==============================] - 20s 386ms/step - loss: 6.9487e-04 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9335\n","\n","Epoch 00446: val_accuracy did not improve from 0.94828\n","Epoch 447/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.3688 - val_accuracy: 0.9335\n","\n","Epoch 00447: val_accuracy did not improve from 0.94828\n","Epoch 448/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.3329 - val_accuracy: 0.9310\n","\n","Epoch 00448: val_accuracy did not improve from 0.94828\n","Epoch 449/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9236\n","\n","Epoch 00449: val_accuracy did not improve from 0.94828\n","Epoch 450/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.9113\n","\n","Epoch 00450: val_accuracy did not improve from 0.94828\n","Epoch 451/500\n","52/52 [==============================] - 20s 386ms/step - loss: 6.5297e-04 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9261\n","\n","Epoch 00451: val_accuracy did not improve from 0.94828\n","Epoch 452/500\n","52/52 [==============================] - 20s 385ms/step - loss: 2.0548e-04 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9384\n","\n","Epoch 00452: val_accuracy did not improve from 0.94828\n","Epoch 453/500\n","52/52 [==============================] - 20s 386ms/step - loss: 6.4570e-04 - accuracy: 1.0000 - val_loss: 0.5045 - val_accuracy: 0.8966\n","\n","Epoch 00453: val_accuracy did not improve from 0.94828\n","Epoch 454/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5547 - val_accuracy: 0.8842\n","\n","Epoch 00454: val_accuracy did not improve from 0.94828\n","Epoch 455/500\n","52/52 [==============================] - 20s 386ms/step - loss: 4.0990e-04 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.9064\n","\n","Epoch 00455: val_accuracy did not improve from 0.94828\n","Epoch 456/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.2246e-04 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9138\n","\n","Epoch 00456: val_accuracy did not improve from 0.94828\n","Epoch 457/500\n","52/52 [==============================] - 20s 387ms/step - loss: 4.0771e-04 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9163\n","\n","Epoch 00457: val_accuracy did not improve from 0.94828\n","Epoch 458/500\n","52/52 [==============================] - 20s 386ms/step - loss: 5.2921e-04 - accuracy: 1.0000 - val_loss: 0.4402 - val_accuracy: 0.9236\n","\n","Epoch 00458: val_accuracy did not improve from 0.94828\n","Epoch 459/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.9212\n","\n","Epoch 00459: val_accuracy did not improve from 0.94828\n","Epoch 460/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0252 - accuracy: 0.9927 - val_loss: 0.5743 - val_accuracy: 0.9064\n","\n","Epoch 00460: val_accuracy did not improve from 0.94828\n","Epoch 461/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0359 - accuracy: 0.9854 - val_loss: 0.6248 - val_accuracy: 0.8768\n","\n","Epoch 00461: val_accuracy did not improve from 0.94828\n","Epoch 462/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0439 - accuracy: 0.9842 - val_loss: 0.8385 - val_accuracy: 0.8448\n","\n","Epoch 00462: val_accuracy did not improve from 0.94828\n","Epoch 463/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.8163 - val_accuracy: 0.8177\n","\n","Epoch 00463: val_accuracy did not improve from 0.94828\n","Epoch 464/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0178 - accuracy: 0.9933 - val_loss: 1.1028 - val_accuracy: 0.8128\n","\n","Epoch 00464: val_accuracy did not improve from 0.94828\n","Epoch 465/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.4395 - val_accuracy: 0.9113\n","\n","Epoch 00465: val_accuracy did not improve from 0.94828\n","Epoch 466/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.8990\n","\n","Epoch 00466: val_accuracy did not improve from 0.94828\n","Epoch 467/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4580 - val_accuracy: 0.8990\n","\n","Epoch 00467: val_accuracy did not improve from 0.94828\n","Epoch 468/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.9039\n","\n","Epoch 00468: val_accuracy did not improve from 0.94828\n","Epoch 469/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4903 - val_accuracy: 0.8867\n","\n","Epoch 00469: val_accuracy did not improve from 0.94828\n","Epoch 470/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4774 - val_accuracy: 0.8990\n","\n","Epoch 00470: val_accuracy did not improve from 0.94828\n","Epoch 471/500\n","52/52 [==============================] - 20s 387ms/step - loss: 7.9255e-04 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9212\n","\n","Epoch 00471: val_accuracy did not improve from 0.94828\n","Epoch 472/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.3644e-04 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9310\n","\n","Epoch 00472: val_accuracy did not improve from 0.94828\n","Epoch 473/500\n","52/52 [==============================] - 20s 387ms/step - loss: 3.0564e-04 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9310\n","\n","Epoch 00473: val_accuracy did not improve from 0.94828\n","Epoch 474/500\n","52/52 [==============================] - 20s 387ms/step - loss: 4.0389e-04 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 0.9310\n","\n","Epoch 00474: val_accuracy did not improve from 0.94828\n","Epoch 475/500\n","52/52 [==============================] - 20s 386ms/step - loss: 9.2857e-04 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 0.9335\n","\n","Epoch 00475: val_accuracy did not improve from 0.94828\n","Epoch 476/500\n","52/52 [==============================] - 20s 387ms/step - loss: 1.6766e-04 - accuracy: 1.0000 - val_loss: 0.3707 - val_accuracy: 0.9384\n","\n","Epoch 00476: val_accuracy did not improve from 0.94828\n","Epoch 477/500\n","52/52 [==============================] - 20s 389ms/step - loss: 1.0589e-04 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9409\n","\n","Epoch 00477: val_accuracy did not improve from 0.94828\n","Epoch 478/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.3413e-04 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9212\n","\n","Epoch 00478: val_accuracy did not improve from 0.94828\n","Epoch 479/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.0124e-04 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9286\n","\n","Epoch 00479: val_accuracy did not improve from 0.94828\n","Epoch 480/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.0438e-04 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.9335\n","\n","Epoch 00480: val_accuracy did not improve from 0.94828\n","Epoch 481/500\n","52/52 [==============================] - 20s 387ms/step - loss: 1.6216e-04 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9409\n","\n","Epoch 00481: val_accuracy did not improve from 0.94828\n","Epoch 482/500\n","52/52 [==============================] - 20s 390ms/step - loss: 1.4174e-04 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.9236\n","\n","Epoch 00482: val_accuracy did not improve from 0.94828\n","Epoch 483/500\n","52/52 [==============================] - 20s 389ms/step - loss: 9.3861e-05 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.9310\n","\n","Epoch 00483: val_accuracy did not improve from 0.94828\n","Epoch 484/500\n","52/52 [==============================] - 20s 388ms/step - loss: 1.4374e-04 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.9360\n","\n","Epoch 00484: val_accuracy did not improve from 0.94828\n","Epoch 485/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.2609e-04 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.9335\n","\n","Epoch 00485: val_accuracy did not improve from 0.94828\n","Epoch 486/500\n","52/52 [==============================] - 20s 388ms/step - loss: 1.2451e-04 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9310\n","\n","Epoch 00486: val_accuracy did not improve from 0.94828\n","Epoch 487/500\n","52/52 [==============================] - 20s 387ms/step - loss: 6.7671e-05 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.9310\n","\n","Epoch 00487: val_accuracy did not improve from 0.94828\n","Epoch 488/500\n","52/52 [==============================] - 20s 387ms/step - loss: 1.1198e-04 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9261\n","\n","Epoch 00488: val_accuracy did not improve from 0.94828\n","Epoch 489/500\n","52/52 [==============================] - 20s 387ms/step - loss: 1.0331e-04 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.9384\n","\n","Epoch 00489: val_accuracy did not improve from 0.94828\n","Epoch 490/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.7939e-04 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.9360\n","\n","Epoch 00490: val_accuracy did not improve from 0.94828\n","Epoch 491/500\n","52/52 [==============================] - 20s 389ms/step - loss: 1.7299e-04 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9286\n","\n","Epoch 00491: val_accuracy did not improve from 0.94828\n","Epoch 492/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.6065e-04 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9261\n","\n","Epoch 00492: val_accuracy did not improve from 0.94828\n","Epoch 493/500\n","52/52 [==============================] - 20s 387ms/step - loss: 9.3511e-05 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 0.9335\n","\n","Epoch 00493: val_accuracy did not improve from 0.94828\n","Epoch 494/500\n","52/52 [==============================] - 20s 387ms/step - loss: 9.0790e-05 - accuracy: 1.0000 - val_loss: 0.3387 - val_accuracy: 0.9384\n","\n","Epoch 00494: val_accuracy did not improve from 0.94828\n","Epoch 495/500\n","52/52 [==============================] - 20s 389ms/step - loss: 2.4377e-04 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9360\n","\n","Epoch 00495: val_accuracy did not improve from 0.94828\n","Epoch 496/500\n","52/52 [==============================] - 20s 386ms/step - loss: 8.8295e-05 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.9335\n","\n","Epoch 00496: val_accuracy did not improve from 0.94828\n","Epoch 497/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4996 - val_accuracy: 0.9236\n","\n","Epoch 00497: val_accuracy did not improve from 0.94828\n","Epoch 498/500\n","52/52 [==============================] - 20s 388ms/step - loss: 5.9899e-04 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9089\n","\n","Epoch 00498: val_accuracy did not improve from 0.94828\n","Epoch 499/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0166 - accuracy: 0.9982 - val_loss: 0.7259 - val_accuracy: 0.9039\n","\n","Epoch 00499: val_accuracy did not improve from 0.94828\n","Epoch 500/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0161 - accuracy: 0.9939 - val_loss: 0.6498 - val_accuracy: 0.8842\n","\n","Epoch 00500: val_accuracy did not improve from 0.94828\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fcfb6b15610>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1629817664451,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"2957e2eb-8cbd-4aa0-bf76-9d4cd9f9295d"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1629817684737,"user_tz":-540,"elapsed":20297,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_4_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1629817685404,"user_tz":-540,"elapsed":686,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629817686058,"user_tz":-540,"elapsed":658,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"095e4bf7-1440-4dd8-b513-29024d44d698"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Found 20480 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629817741174,"user_tz":-540,"elapsed":55118,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"43b4738a-eb9d-406d-82eb-0973f14048f6"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1629817741563,"user_tz":-540,"elapsed":391,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1629817741564,"user_tz":-540,"elapsed":4,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1629817742551,"user_tz":-540,"elapsed":990,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1629817742555,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1629817753723,"user_tz":-540,"elapsed":11173,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1629817753730,"user_tz":-540,"elapsed":16,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"e1c46cef-9ced-4ba1-e668-78e047ec5d79"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1629817754603,"user_tz":-540,"elapsed":882,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"8903b263-e97a-4aa6-d963-251668f8486e"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_00_4_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_00_4_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_dc935aa4-001a-4fe9-9162-1fe8e2a88aaf\", \"Rotation_range_00_4_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}