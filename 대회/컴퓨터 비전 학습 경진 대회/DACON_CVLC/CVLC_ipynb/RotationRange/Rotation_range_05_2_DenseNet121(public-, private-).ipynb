{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Rotation_range_05_2_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyPg+Z55+m3QHEaV5W+pYrlX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629817972124,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d8d872a2-9446-4707-dc29-f80cfb1a5141"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tue Aug 24 15:12:51 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629817993588,"user_tz":-540,"elapsed":21468,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c20e1f2e-e9cd-4077-c3ad-b8c437fc71e4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj"},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo"},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg"},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc"},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK"},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629818025586,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"58e23ac9-0e42-4e96-866c-a14c9f9362c6"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629818025588,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"7e7e5502-ab64-4a6e-ac05-e387b90ddb83"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=5,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY"},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629824583843,"user_tz":-540,"elapsed":1253542,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"a8310799-44cf-459b-ee01-cc5111b4eeaa"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 39s 274ms/step - loss: 1.7951 - accuracy: 0.3703 - val_loss: 37.9927 - val_accuracy: 0.1010\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 12s 225ms/step - loss: 1.1650 - accuracy: 0.5981 - val_loss: 10.8886 - val_accuracy: 0.1010\n","\n","Epoch 00002: val_accuracy did not improve from 0.10099\n","Epoch 3/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.9029 - accuracy: 0.6931 - val_loss: 19.9777 - val_accuracy: 0.1010\n","\n","Epoch 00003: val_accuracy did not improve from 0.10099\n","Epoch 4/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.7920 - accuracy: 0.7418 - val_loss: 14.6127 - val_accuracy: 0.1084\n","\n","Epoch 00004: val_accuracy improved from 0.10099 to 0.10837, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 5/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.6878 - accuracy: 0.7686 - val_loss: 15.0788 - val_accuracy: 0.1084\n","\n","Epoch 00005: val_accuracy did not improve from 0.10837\n","Epoch 6/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.5934 - accuracy: 0.8027 - val_loss: 6.8686 - val_accuracy: 0.2365\n","\n","Epoch 00006: val_accuracy improved from 0.10837 to 0.23645, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.5319 - accuracy: 0.8228 - val_loss: 6.9868 - val_accuracy: 0.1823\n","\n","Epoch 00007: val_accuracy did not improve from 0.23645\n","Epoch 8/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.5066 - accuracy: 0.8283 - val_loss: 3.7705 - val_accuracy: 0.3719\n","\n","Epoch 00008: val_accuracy improved from 0.23645 to 0.37192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.4779 - accuracy: 0.8410 - val_loss: 3.8107 - val_accuracy: 0.4113\n","\n","Epoch 00009: val_accuracy improved from 0.37192 to 0.41133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.3986 - accuracy: 0.8672 - val_loss: 0.8608 - val_accuracy: 0.7118\n","\n","Epoch 00010: val_accuracy improved from 0.41133 to 0.71182, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.4011 - accuracy: 0.8557 - val_loss: 0.7369 - val_accuracy: 0.7783\n","\n","Epoch 00011: val_accuracy improved from 0.71182 to 0.77833, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.3993 - accuracy: 0.8593 - val_loss: 0.8470 - val_accuracy: 0.7685\n","\n","Epoch 00012: val_accuracy did not improve from 0.77833\n","Epoch 13/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.3525 - accuracy: 0.8812 - val_loss: 3.2372 - val_accuracy: 0.4409\n","\n","Epoch 00013: val_accuracy did not improve from 0.77833\n","Epoch 14/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3502 - accuracy: 0.8800 - val_loss: 4.8516 - val_accuracy: 0.3498\n","\n","Epoch 00014: val_accuracy did not improve from 0.77833\n","Epoch 15/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3758 - accuracy: 0.8745 - val_loss: 2.3789 - val_accuracy: 0.5591\n","\n","Epoch 00015: val_accuracy did not improve from 0.77833\n","Epoch 16/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.3196 - accuracy: 0.8910 - val_loss: 2.8257 - val_accuracy: 0.5419\n","\n","Epoch 00016: val_accuracy did not improve from 0.77833\n","Epoch 17/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3085 - accuracy: 0.8922 - val_loss: 1.5384 - val_accuracy: 0.6798\n","\n","Epoch 00017: val_accuracy did not improve from 0.77833\n","Epoch 18/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2299 - accuracy: 0.9208 - val_loss: 0.6113 - val_accuracy: 0.8177\n","\n","Epoch 00018: val_accuracy improved from 0.77833 to 0.81773, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 19/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.2837 - accuracy: 0.8959 - val_loss: 0.8929 - val_accuracy: 0.8030\n","\n","Epoch 00019: val_accuracy did not improve from 0.81773\n","Epoch 20/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1989 - accuracy: 0.9348 - val_loss: 0.9025 - val_accuracy: 0.7537\n","\n","Epoch 00020: val_accuracy did not improve from 0.81773\n","Epoch 21/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2174 - accuracy: 0.9178 - val_loss: 0.5078 - val_accuracy: 0.8448\n","\n","Epoch 00021: val_accuracy improved from 0.81773 to 0.84483, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 22/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1671 - accuracy: 0.9440 - val_loss: 0.6054 - val_accuracy: 0.8424\n","\n","Epoch 00022: val_accuracy did not improve from 0.84483\n","Epoch 23/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.2020 - accuracy: 0.9281 - val_loss: 0.7657 - val_accuracy: 0.7857\n","\n","Epoch 00023: val_accuracy did not improve from 0.84483\n","Epoch 24/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1799 - accuracy: 0.9409 - val_loss: 0.9941 - val_accuracy: 0.7438\n","\n","Epoch 00024: val_accuracy did not improve from 0.84483\n","Epoch 25/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.1585 - accuracy: 0.9428 - val_loss: 0.6089 - val_accuracy: 0.8399\n","\n","Epoch 00025: val_accuracy did not improve from 0.84483\n","Epoch 26/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.2094 - accuracy: 0.9281 - val_loss: 1.6753 - val_accuracy: 0.6601\n","\n","Epoch 00026: val_accuracy did not improve from 0.84483\n","Epoch 27/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.1729 - accuracy: 0.9379 - val_loss: 0.6000 - val_accuracy: 0.8300\n","\n","Epoch 00027: val_accuracy did not improve from 0.84483\n","Epoch 28/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1540 - accuracy: 0.9476 - val_loss: 0.8247 - val_accuracy: 0.8030\n","\n","Epoch 00028: val_accuracy did not improve from 0.84483\n","Epoch 29/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1664 - accuracy: 0.9452 - val_loss: 0.4731 - val_accuracy: 0.8596\n","\n","Epoch 00029: val_accuracy improved from 0.84483 to 0.85961, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 30/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.2041 - accuracy: 0.9300 - val_loss: 1.0128 - val_accuracy: 0.7586\n","\n","Epoch 00030: val_accuracy did not improve from 0.85961\n","Epoch 31/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1382 - accuracy: 0.9574 - val_loss: 0.5197 - val_accuracy: 0.8621\n","\n","Epoch 00031: val_accuracy improved from 0.85961 to 0.86207, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 32/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.1129 - accuracy: 0.9574 - val_loss: 0.6455 - val_accuracy: 0.8300\n","\n","Epoch 00032: val_accuracy did not improve from 0.86207\n","Epoch 33/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1020 - accuracy: 0.9683 - val_loss: 0.4937 - val_accuracy: 0.8571\n","\n","Epoch 00033: val_accuracy did not improve from 0.86207\n","Epoch 34/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0903 - accuracy: 0.9683 - val_loss: 0.5125 - val_accuracy: 0.8571\n","\n","Epoch 00034: val_accuracy did not improve from 0.86207\n","Epoch 35/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0800 - accuracy: 0.9750 - val_loss: 0.5733 - val_accuracy: 0.8547\n","\n","Epoch 00035: val_accuracy did not improve from 0.86207\n","Epoch 36/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1189 - accuracy: 0.9555 - val_loss: 0.6963 - val_accuracy: 0.8473\n","\n","Epoch 00036: val_accuracy did not improve from 0.86207\n","Epoch 37/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1635 - accuracy: 0.9440 - val_loss: 1.0537 - val_accuracy: 0.8103\n","\n","Epoch 00037: val_accuracy did not improve from 0.86207\n","Epoch 38/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1385 - accuracy: 0.9495 - val_loss: 0.6167 - val_accuracy: 0.8424\n","\n","Epoch 00038: val_accuracy did not improve from 0.86207\n","Epoch 39/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1106 - accuracy: 0.9653 - val_loss: 0.5616 - val_accuracy: 0.8571\n","\n","Epoch 00039: val_accuracy did not improve from 0.86207\n","Epoch 40/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0816 - accuracy: 0.9732 - val_loss: 0.6535 - val_accuracy: 0.8350\n","\n","Epoch 00040: val_accuracy did not improve from 0.86207\n","Epoch 41/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0973 - accuracy: 0.9702 - val_loss: 0.4689 - val_accuracy: 0.8571\n","\n","Epoch 00041: val_accuracy did not improve from 0.86207\n","Epoch 42/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0930 - accuracy: 0.9653 - val_loss: 0.4477 - val_accuracy: 0.8966\n","\n","Epoch 00042: val_accuracy improved from 0.86207 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 43/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0775 - accuracy: 0.9750 - val_loss: 0.8108 - val_accuracy: 0.8153\n","\n","Epoch 00043: val_accuracy did not improve from 0.89655\n","Epoch 44/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1186 - accuracy: 0.9629 - val_loss: 0.9190 - val_accuracy: 0.8399\n","\n","Epoch 00044: val_accuracy did not improve from 0.89655\n","Epoch 45/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0972 - accuracy: 0.9665 - val_loss: 0.5905 - val_accuracy: 0.8571\n","\n","Epoch 00045: val_accuracy did not improve from 0.89655\n","Epoch 46/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0969 - accuracy: 0.9653 - val_loss: 0.5620 - val_accuracy: 0.8744\n","\n","Epoch 00046: val_accuracy did not improve from 0.89655\n","Epoch 47/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0790 - accuracy: 0.9714 - val_loss: 0.4476 - val_accuracy: 0.8818\n","\n","Epoch 00047: val_accuracy did not improve from 0.89655\n","Epoch 48/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0581 - accuracy: 0.9811 - val_loss: 0.5075 - val_accuracy: 0.8744\n","\n","Epoch 00048: val_accuracy did not improve from 0.89655\n","Epoch 49/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0522 - accuracy: 0.9823 - val_loss: 0.5246 - val_accuracy: 0.8695\n","\n","Epoch 00049: val_accuracy did not improve from 0.89655\n","Epoch 50/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0606 - accuracy: 0.9781 - val_loss: 0.8383 - val_accuracy: 0.8325\n","\n","Epoch 00050: val_accuracy did not improve from 0.89655\n","Epoch 51/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0527 - accuracy: 0.9829 - val_loss: 0.5128 - val_accuracy: 0.8571\n","\n","Epoch 00051: val_accuracy did not improve from 0.89655\n","Epoch 52/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0354 - accuracy: 0.9909 - val_loss: 0.4660 - val_accuracy: 0.8867\n","\n","Epoch 00052: val_accuracy did not improve from 0.89655\n","Epoch 53/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0335 - accuracy: 0.9872 - val_loss: 0.7412 - val_accuracy: 0.8374\n","\n","Epoch 00053: val_accuracy did not improve from 0.89655\n","Epoch 54/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1588 - accuracy: 0.9513 - val_loss: 1.9866 - val_accuracy: 0.6724\n","\n","Epoch 00054: val_accuracy did not improve from 0.89655\n","Epoch 55/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1306 - accuracy: 0.9574 - val_loss: 1.2077 - val_accuracy: 0.7734\n","\n","Epoch 00055: val_accuracy did not improve from 0.89655\n","Epoch 56/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0718 - accuracy: 0.9769 - val_loss: 0.4884 - val_accuracy: 0.8744\n","\n","Epoch 00056: val_accuracy did not improve from 0.89655\n","Epoch 57/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0678 - accuracy: 0.9781 - val_loss: 0.8311 - val_accuracy: 0.8054\n","\n","Epoch 00057: val_accuracy did not improve from 0.89655\n","Epoch 58/500\n","52/52 [==============================] - 12s 239ms/step - loss: 0.0504 - accuracy: 0.9866 - val_loss: 0.4895 - val_accuracy: 0.8793\n","\n","Epoch 00058: val_accuracy did not improve from 0.89655\n","Epoch 59/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0563 - accuracy: 0.9823 - val_loss: 0.5710 - val_accuracy: 0.8522\n","\n","Epoch 00059: val_accuracy did not improve from 0.89655\n","Epoch 60/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0380 - accuracy: 0.9896 - val_loss: 0.5383 - val_accuracy: 0.8818\n","\n","Epoch 00060: val_accuracy did not improve from 0.89655\n","Epoch 61/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0621 - accuracy: 0.9756 - val_loss: 0.6075 - val_accuracy: 0.8571\n","\n","Epoch 00061: val_accuracy did not improve from 0.89655\n","Epoch 62/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1135 - accuracy: 0.9629 - val_loss: 0.8243 - val_accuracy: 0.8202\n","\n","Epoch 00062: val_accuracy did not improve from 0.89655\n","Epoch 63/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0663 - accuracy: 0.9775 - val_loss: 0.6947 - val_accuracy: 0.8473\n","\n","Epoch 00063: val_accuracy did not improve from 0.89655\n","Epoch 64/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0740 - accuracy: 0.9732 - val_loss: 0.5492 - val_accuracy: 0.8793\n","\n","Epoch 00064: val_accuracy did not improve from 0.89655\n","Epoch 65/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0805 - accuracy: 0.9726 - val_loss: 0.4127 - val_accuracy: 0.8892\n","\n","Epoch 00065: val_accuracy did not improve from 0.89655\n","Epoch 66/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0688 - accuracy: 0.9738 - val_loss: 0.6665 - val_accuracy: 0.8448\n","\n","Epoch 00066: val_accuracy did not improve from 0.89655\n","Epoch 67/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0437 - accuracy: 0.9811 - val_loss: 0.6195 - val_accuracy: 0.8695\n","\n","Epoch 00067: val_accuracy did not improve from 0.89655\n","Epoch 68/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0628 - accuracy: 0.9811 - val_loss: 0.6044 - val_accuracy: 0.8670\n","\n","Epoch 00068: val_accuracy did not improve from 0.89655\n","Epoch 69/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0571 - accuracy: 0.9817 - val_loss: 0.6414 - val_accuracy: 0.8744\n","\n","Epoch 00069: val_accuracy did not improve from 0.89655\n","Epoch 70/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0405 - accuracy: 0.9860 - val_loss: 0.4491 - val_accuracy: 0.8941\n","\n","Epoch 00070: val_accuracy did not improve from 0.89655\n","Epoch 71/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.4246 - val_accuracy: 0.8990\n","\n","Epoch 00071: val_accuracy improved from 0.89655 to 0.89901, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 72/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.4332 - val_accuracy: 0.8941\n","\n","Epoch 00072: val_accuracy did not improve from 0.89901\n","Epoch 73/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0703 - accuracy: 0.9799 - val_loss: 0.7289 - val_accuracy: 0.8202\n","\n","Epoch 00073: val_accuracy did not improve from 0.89901\n","Epoch 74/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0238 - accuracy: 0.9939 - val_loss: 0.4480 - val_accuracy: 0.9039\n","\n","Epoch 00074: val_accuracy improved from 0.89901 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 75/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0338 - accuracy: 0.9854 - val_loss: 0.4920 - val_accuracy: 0.8892\n","\n","Epoch 00075: val_accuracy did not improve from 0.90394\n","Epoch 76/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0735 - accuracy: 0.9762 - val_loss: 0.8260 - val_accuracy: 0.8547\n","\n","Epoch 00076: val_accuracy did not improve from 0.90394\n","Epoch 77/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0825 - accuracy: 0.9677 - val_loss: 1.2386 - val_accuracy: 0.7488\n","\n","Epoch 00077: val_accuracy did not improve from 0.90394\n","Epoch 78/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0911 - accuracy: 0.9702 - val_loss: 0.6742 - val_accuracy: 0.8670\n","\n","Epoch 00078: val_accuracy did not improve from 0.90394\n","Epoch 79/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0661 - accuracy: 0.9769 - val_loss: 1.1225 - val_accuracy: 0.7759\n","\n","Epoch 00079: val_accuracy did not improve from 0.90394\n","Epoch 80/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1465 - accuracy: 0.9531 - val_loss: 1.4022 - val_accuracy: 0.7463\n","\n","Epoch 00080: val_accuracy did not improve from 0.90394\n","Epoch 81/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0778 - accuracy: 0.9769 - val_loss: 0.9596 - val_accuracy: 0.7857\n","\n","Epoch 00081: val_accuracy did not improve from 0.90394\n","Epoch 82/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0310 - accuracy: 0.9903 - val_loss: 0.4195 - val_accuracy: 0.8916\n","\n","Epoch 00082: val_accuracy did not improve from 0.90394\n","Epoch 83/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0209 - accuracy: 0.9903 - val_loss: 0.3997 - val_accuracy: 0.9039\n","\n","Epoch 00083: val_accuracy did not improve from 0.90394\n","Epoch 84/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.5726 - val_accuracy: 0.8941\n","\n","Epoch 00084: val_accuracy did not improve from 0.90394\n","Epoch 85/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.4377 - val_accuracy: 0.9015\n","\n","Epoch 00085: val_accuracy did not improve from 0.90394\n","Epoch 86/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0445 - accuracy: 0.9866 - val_loss: 0.9897 - val_accuracy: 0.8005\n","\n","Epoch 00086: val_accuracy did not improve from 0.90394\n","Epoch 87/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0912 - accuracy: 0.9653 - val_loss: 1.1390 - val_accuracy: 0.7833\n","\n","Epoch 00087: val_accuracy did not improve from 0.90394\n","Epoch 88/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0445 - accuracy: 0.9866 - val_loss: 0.6567 - val_accuracy: 0.8695\n","\n","Epoch 00088: val_accuracy did not improve from 0.90394\n","Epoch 89/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.4456 - val_accuracy: 0.8990\n","\n","Epoch 00089: val_accuracy did not improve from 0.90394\n","Epoch 90/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.5114 - val_accuracy: 0.8916\n","\n","Epoch 00090: val_accuracy did not improve from 0.90394\n","Epoch 91/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 0.4392 - val_accuracy: 0.9064\n","\n","Epoch 00091: val_accuracy improved from 0.90394 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 92/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0149 - accuracy: 0.9939 - val_loss: 0.4644 - val_accuracy: 0.8966\n","\n","Epoch 00092: val_accuracy did not improve from 0.90640\n","Epoch 93/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.5196 - val_accuracy: 0.8842\n","\n","Epoch 00093: val_accuracy did not improve from 0.90640\n","Epoch 94/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9236\n","\n","Epoch 00094: val_accuracy improved from 0.90640 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 95/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.4221 - val_accuracy: 0.9015\n","\n","Epoch 00095: val_accuracy did not improve from 0.92365\n","Epoch 96/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0274 - accuracy: 0.9890 - val_loss: 0.8445 - val_accuracy: 0.8547\n","\n","Epoch 00096: val_accuracy did not improve from 0.92365\n","Epoch 97/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0692 - accuracy: 0.9769 - val_loss: 0.9795 - val_accuracy: 0.8276\n","\n","Epoch 00097: val_accuracy did not improve from 0.92365\n","Epoch 98/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1085 - accuracy: 0.9653 - val_loss: 1.0720 - val_accuracy: 0.8103\n","\n","Epoch 00098: val_accuracy did not improve from 0.92365\n","Epoch 99/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0965 - accuracy: 0.9756 - val_loss: 0.7591 - val_accuracy: 0.8571\n","\n","Epoch 00099: val_accuracy did not improve from 0.92365\n","Epoch 100/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0816 - accuracy: 0.9732 - val_loss: 0.5382 - val_accuracy: 0.8571\n","\n","Epoch 00100: val_accuracy did not improve from 0.92365\n","Epoch 101/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0605 - accuracy: 0.9799 - val_loss: 0.7348 - val_accuracy: 0.8522\n","\n","Epoch 00101: val_accuracy did not improve from 0.92365\n","Epoch 102/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.4472 - val_accuracy: 0.8867\n","\n","Epoch 00102: val_accuracy did not improve from 0.92365\n","Epoch 103/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 0.4398 - val_accuracy: 0.9064\n","\n","Epoch 00103: val_accuracy did not improve from 0.92365\n","Epoch 104/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0759 - accuracy: 0.9811 - val_loss: 2.2205 - val_accuracy: 0.7118\n","\n","Epoch 00104: val_accuracy did not improve from 0.92365\n","Epoch 105/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0396 - accuracy: 0.9872 - val_loss: 0.7078 - val_accuracy: 0.8621\n","\n","Epoch 00105: val_accuracy did not improve from 0.92365\n","Epoch 106/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.5640 - val_accuracy: 0.8768\n","\n","Epoch 00106: val_accuracy did not improve from 0.92365\n","Epoch 107/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.4327 - val_accuracy: 0.8892\n","\n","Epoch 00107: val_accuracy did not improve from 0.92365\n","Epoch 108/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0500 - accuracy: 0.9903 - val_loss: 1.3552 - val_accuracy: 0.7611\n","\n","Epoch 00108: val_accuracy did not improve from 0.92365\n","Epoch 109/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0795 - accuracy: 0.9726 - val_loss: 0.7280 - val_accuracy: 0.8719\n","\n","Epoch 00109: val_accuracy did not improve from 0.92365\n","Epoch 110/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0322 - accuracy: 0.9866 - val_loss: 0.5266 - val_accuracy: 0.8719\n","\n","Epoch 00110: val_accuracy did not improve from 0.92365\n","Epoch 111/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.4656 - val_accuracy: 0.8966\n","\n","Epoch 00111: val_accuracy did not improve from 0.92365\n","Epoch 112/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.8990\n","\n","Epoch 00112: val_accuracy did not improve from 0.92365\n","Epoch 113/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.3697 - val_accuracy: 0.8990\n","\n","Epoch 00113: val_accuracy did not improve from 0.92365\n","Epoch 114/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4140 - val_accuracy: 0.9113\n","\n","Epoch 00114: val_accuracy did not improve from 0.92365\n","Epoch 115/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.4366 - val_accuracy: 0.8818\n","\n","Epoch 00115: val_accuracy did not improve from 0.92365\n","Epoch 116/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.5523 - val_accuracy: 0.8990\n","\n","Epoch 00116: val_accuracy did not improve from 0.92365\n","Epoch 117/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 0.5244 - val_accuracy: 0.8892\n","\n","Epoch 00117: val_accuracy did not improve from 0.92365\n","Epoch 118/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.5948 - val_accuracy: 0.8793\n","\n","Epoch 00118: val_accuracy did not improve from 0.92365\n","Epoch 119/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 1.1932 - val_accuracy: 0.7857\n","\n","Epoch 00119: val_accuracy did not improve from 0.92365\n","Epoch 120/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0883 - accuracy: 0.9702 - val_loss: 1.0068 - val_accuracy: 0.8276\n","\n","Epoch 00120: val_accuracy did not improve from 0.92365\n","Epoch 121/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0950 - accuracy: 0.9671 - val_loss: 0.6832 - val_accuracy: 0.8867\n","\n","Epoch 00121: val_accuracy did not improve from 0.92365\n","Epoch 122/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0595 - accuracy: 0.9775 - val_loss: 0.6277 - val_accuracy: 0.8768\n","\n","Epoch 00122: val_accuracy did not improve from 0.92365\n","Epoch 123/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.4874 - val_accuracy: 0.8867\n","\n","Epoch 00123: val_accuracy did not improve from 0.92365\n","Epoch 124/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0366 - accuracy: 0.9884 - val_loss: 0.6180 - val_accuracy: 0.8670\n","\n","Epoch 00124: val_accuracy did not improve from 0.92365\n","Epoch 125/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0280 - accuracy: 0.9903 - val_loss: 0.4660 - val_accuracy: 0.9089\n","\n","Epoch 00125: val_accuracy did not improve from 0.92365\n","Epoch 126/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.4894 - val_accuracy: 0.9015\n","\n","Epoch 00126: val_accuracy did not improve from 0.92365\n","Epoch 127/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.4534 - val_accuracy: 0.8916\n","\n","Epoch 00127: val_accuracy did not improve from 0.92365\n","Epoch 128/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.4297 - val_accuracy: 0.9089\n","\n","Epoch 00128: val_accuracy did not improve from 0.92365\n","Epoch 129/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4345 - val_accuracy: 0.9039\n","\n","Epoch 00129: val_accuracy did not improve from 0.92365\n","Epoch 130/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4737 - val_accuracy: 0.9015\n","\n","Epoch 00130: val_accuracy did not improve from 0.92365\n","Epoch 131/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.4183 - val_accuracy: 0.8941\n","\n","Epoch 00131: val_accuracy did not improve from 0.92365\n","Epoch 132/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.5514 - val_accuracy: 0.8916\n","\n","Epoch 00132: val_accuracy did not improve from 0.92365\n","Epoch 133/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.6574 - val_accuracy: 0.8719\n","\n","Epoch 00133: val_accuracy did not improve from 0.92365\n","Epoch 134/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0351 - accuracy: 0.9884 - val_loss: 0.6574 - val_accuracy: 0.8719\n","\n","Epoch 00134: val_accuracy did not improve from 0.92365\n","Epoch 135/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0524 - accuracy: 0.9823 - val_loss: 0.8582 - val_accuracy: 0.8473\n","\n","Epoch 00135: val_accuracy did not improve from 0.92365\n","Epoch 136/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0505 - accuracy: 0.9829 - val_loss: 0.6141 - val_accuracy: 0.8966\n","\n","Epoch 00136: val_accuracy did not improve from 0.92365\n","Epoch 137/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0249 - accuracy: 0.9896 - val_loss: 0.6674 - val_accuracy: 0.8670\n","\n","Epoch 00137: val_accuracy did not improve from 0.92365\n","Epoch 138/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0650 - accuracy: 0.9836 - val_loss: 0.9315 - val_accuracy: 0.8300\n","\n","Epoch 00138: val_accuracy did not improve from 0.92365\n","Epoch 139/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0819 - accuracy: 0.9787 - val_loss: 0.9433 - val_accuracy: 0.8251\n","\n","Epoch 00139: val_accuracy did not improve from 0.92365\n","Epoch 140/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0985 - accuracy: 0.9683 - val_loss: 0.6997 - val_accuracy: 0.8719\n","\n","Epoch 00140: val_accuracy did not improve from 0.92365\n","Epoch 141/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.5432 - val_accuracy: 0.8892\n","\n","Epoch 00141: val_accuracy did not improve from 0.92365\n","Epoch 142/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0215 - accuracy: 0.9896 - val_loss: 0.4798 - val_accuracy: 0.9015\n","\n","Epoch 00142: val_accuracy did not improve from 0.92365\n","Epoch 143/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.4283 - val_accuracy: 0.9064\n","\n","Epoch 00143: val_accuracy did not improve from 0.92365\n","Epoch 144/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.5691 - val_accuracy: 0.8941\n","\n","Epoch 00144: val_accuracy did not improve from 0.92365\n","Epoch 145/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.4752 - val_accuracy: 0.9015\n","\n","Epoch 00145: val_accuracy did not improve from 0.92365\n","Epoch 146/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0357 - accuracy: 0.9903 - val_loss: 0.6556 - val_accuracy: 0.8793\n","\n","Epoch 00146: val_accuracy did not improve from 0.92365\n","Epoch 147/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0372 - accuracy: 0.9890 - val_loss: 0.7810 - val_accuracy: 0.8473\n","\n","Epoch 00147: val_accuracy did not improve from 0.92365\n","Epoch 148/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.5726 - val_accuracy: 0.8941\n","\n","Epoch 00148: val_accuracy did not improve from 0.92365\n","Epoch 149/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0229 - accuracy: 0.9945 - val_loss: 0.4275 - val_accuracy: 0.8892\n","\n","Epoch 00149: val_accuracy did not improve from 0.92365\n","Epoch 150/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.6109 - val_accuracy: 0.8793\n","\n","Epoch 00150: val_accuracy did not improve from 0.92365\n","Epoch 151/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.4890 - val_accuracy: 0.9064\n","\n","Epoch 00151: val_accuracy did not improve from 0.92365\n","Epoch 152/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4582 - val_accuracy: 0.8966\n","\n","Epoch 00152: val_accuracy did not improve from 0.92365\n","Epoch 153/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4105 - val_accuracy: 0.8966\n","\n","Epoch 00153: val_accuracy did not improve from 0.92365\n","Epoch 154/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.9138\n","\n","Epoch 00154: val_accuracy did not improve from 0.92365\n","Epoch 155/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4330 - val_accuracy: 0.9039\n","\n","Epoch 00155: val_accuracy did not improve from 0.92365\n","Epoch 156/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4388 - val_accuracy: 0.9113\n","\n","Epoch 00156: val_accuracy did not improve from 0.92365\n","Epoch 157/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.3926 - val_accuracy: 0.8990\n","\n","Epoch 00157: val_accuracy did not improve from 0.92365\n","Epoch 158/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.4832 - val_accuracy: 0.9089\n","\n","Epoch 00158: val_accuracy did not improve from 0.92365\n","Epoch 159/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.6486 - val_accuracy: 0.8793\n","\n","Epoch 00159: val_accuracy did not improve from 0.92365\n","Epoch 160/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.8769 - val_accuracy: 0.8571\n","\n","Epoch 00160: val_accuracy did not improve from 0.92365\n","Epoch 161/500\n","52/52 [==============================] - 12s 239ms/step - loss: 0.0413 - accuracy: 0.9854 - val_loss: 0.9263 - val_accuracy: 0.8522\n","\n","Epoch 00161: val_accuracy did not improve from 0.92365\n","Epoch 162/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0516 - accuracy: 0.9854 - val_loss: 0.9103 - val_accuracy: 0.8571\n","\n","Epoch 00162: val_accuracy did not improve from 0.92365\n","Epoch 163/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0825 - accuracy: 0.9769 - val_loss: 0.9098 - val_accuracy: 0.8645\n","\n","Epoch 00163: val_accuracy did not improve from 0.92365\n","Epoch 164/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0552 - accuracy: 0.9854 - val_loss: 0.9543 - val_accuracy: 0.8498\n","\n","Epoch 00164: val_accuracy did not improve from 0.92365\n","Epoch 165/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0412 - accuracy: 0.9817 - val_loss: 1.1470 - val_accuracy: 0.8227\n","\n","Epoch 00165: val_accuracy did not improve from 0.92365\n","Epoch 166/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0231 - accuracy: 0.9909 - val_loss: 0.5358 - val_accuracy: 0.8892\n","\n","Epoch 00166: val_accuracy did not improve from 0.92365\n","Epoch 167/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0268 - accuracy: 0.9903 - val_loss: 0.5220 - val_accuracy: 0.9089\n","\n","Epoch 00167: val_accuracy did not improve from 0.92365\n","Epoch 168/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0326 - accuracy: 0.9915 - val_loss: 0.6290 - val_accuracy: 0.9015\n","\n","Epoch 00168: val_accuracy did not improve from 0.92365\n","Epoch 169/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0315 - accuracy: 0.9909 - val_loss: 0.4319 - val_accuracy: 0.8892\n","\n","Epoch 00169: val_accuracy did not improve from 0.92365\n","Epoch 170/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0158 - accuracy: 0.9970 - val_loss: 0.4667 - val_accuracy: 0.9039\n","\n","Epoch 00170: val_accuracy did not improve from 0.92365\n","Epoch 171/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.4043 - val_accuracy: 0.9138\n","\n","Epoch 00171: val_accuracy did not improve from 0.92365\n","Epoch 172/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.4337 - val_accuracy: 0.9089\n","\n","Epoch 00172: val_accuracy did not improve from 0.92365\n","Epoch 173/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.4735 - val_accuracy: 0.9015\n","\n","Epoch 00173: val_accuracy did not improve from 0.92365\n","Epoch 174/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4071 - val_accuracy: 0.9089\n","\n","Epoch 00174: val_accuracy did not improve from 0.92365\n","Epoch 175/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.8966\n","\n","Epoch 00175: val_accuracy did not improve from 0.92365\n","Epoch 176/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.3661 - val_accuracy: 0.9261\n","\n","Epoch 00176: val_accuracy improved from 0.92365 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 177/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.3871 - val_accuracy: 0.9310\n","\n","Epoch 00177: val_accuracy improved from 0.92611 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 178/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4053 - val_accuracy: 0.9163\n","\n","Epoch 00178: val_accuracy did not improve from 0.93103\n","Epoch 179/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4588 - val_accuracy: 0.8842\n","\n","Epoch 00179: val_accuracy did not improve from 0.93103\n","Epoch 180/500\n","52/52 [==============================] - 12s 225ms/step - loss: 8.9312e-04 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9089\n","\n","Epoch 00180: val_accuracy did not improve from 0.93103\n","Epoch 181/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4064 - val_accuracy: 0.9039\n","\n","Epoch 00181: val_accuracy did not improve from 0.93103\n","Epoch 182/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.6661 - val_accuracy: 0.8768\n","\n","Epoch 00182: val_accuracy did not improve from 0.93103\n","Epoch 183/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0157 - accuracy: 0.9933 - val_loss: 0.6760 - val_accuracy: 0.8670\n","\n","Epoch 00183: val_accuracy did not improve from 0.93103\n","Epoch 184/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.6812 - val_accuracy: 0.8695\n","\n","Epoch 00184: val_accuracy did not improve from 0.93103\n","Epoch 185/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0223 - accuracy: 0.9909 - val_loss: 0.6131 - val_accuracy: 0.8768\n","\n","Epoch 00185: val_accuracy did not improve from 0.93103\n","Epoch 186/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0534 - accuracy: 0.9848 - val_loss: 0.9215 - val_accuracy: 0.8522\n","\n","Epoch 00186: val_accuracy did not improve from 0.93103\n","Epoch 187/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.1247 - accuracy: 0.9671 - val_loss: 1.5341 - val_accuracy: 0.7562\n","\n","Epoch 00187: val_accuracy did not improve from 0.93103\n","Epoch 188/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0653 - accuracy: 0.9836 - val_loss: 0.6934 - val_accuracy: 0.8522\n","\n","Epoch 00188: val_accuracy did not improve from 0.93103\n","Epoch 189/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0204 - accuracy: 0.9951 - val_loss: 0.4832 - val_accuracy: 0.8966\n","\n","Epoch 00189: val_accuracy did not improve from 0.93103\n","Epoch 190/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.4811 - val_accuracy: 0.9138\n","\n","Epoch 00190: val_accuracy did not improve from 0.93103\n","Epoch 191/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0110 - accuracy: 0.9945 - val_loss: 0.4389 - val_accuracy: 0.9138\n","\n","Epoch 00191: val_accuracy did not improve from 0.93103\n","Epoch 192/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.4586 - val_accuracy: 0.8990\n","\n","Epoch 00192: val_accuracy did not improve from 0.93103\n","Epoch 193/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.3707 - val_accuracy: 0.9163\n","\n","Epoch 00193: val_accuracy did not improve from 0.93103\n","Epoch 194/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3363 - val_accuracy: 0.9236\n","\n","Epoch 00194: val_accuracy did not improve from 0.93103\n","Epoch 195/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9187\n","\n","Epoch 00195: val_accuracy did not improve from 0.93103\n","Epoch 196/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.9531 - val_accuracy: 0.8695\n","\n","Epoch 00196: val_accuracy did not improve from 0.93103\n","Epoch 197/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0261 - accuracy: 0.9903 - val_loss: 0.7783 - val_accuracy: 0.8498\n","\n","Epoch 00197: val_accuracy did not improve from 0.93103\n","Epoch 198/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.7012 - val_accuracy: 0.8768\n","\n","Epoch 00198: val_accuracy did not improve from 0.93103\n","Epoch 199/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0383 - accuracy: 0.9860 - val_loss: 0.9473 - val_accuracy: 0.8448\n","\n","Epoch 00199: val_accuracy did not improve from 0.93103\n","Epoch 200/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0466 - accuracy: 0.9860 - val_loss: 0.8816 - val_accuracy: 0.8498\n","\n","Epoch 00200: val_accuracy did not improve from 0.93103\n","Epoch 201/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 0.6325 - val_accuracy: 0.8596\n","\n","Epoch 00201: val_accuracy did not improve from 0.93103\n","Epoch 202/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0331 - accuracy: 0.9878 - val_loss: 1.3917 - val_accuracy: 0.7956\n","\n","Epoch 00202: val_accuracy did not improve from 0.93103\n","Epoch 203/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0551 - accuracy: 0.9793 - val_loss: 0.9661 - val_accuracy: 0.8522\n","\n","Epoch 00203: val_accuracy did not improve from 0.93103\n","Epoch 204/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0398 - accuracy: 0.9848 - val_loss: 0.7207 - val_accuracy: 0.8695\n","\n","Epoch 00204: val_accuracy did not improve from 0.93103\n","Epoch 205/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.5201 - val_accuracy: 0.8990\n","\n","Epoch 00205: val_accuracy did not improve from 0.93103\n","Epoch 206/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.5592 - val_accuracy: 0.8892\n","\n","Epoch 00206: val_accuracy did not improve from 0.93103\n","Epoch 207/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0599 - accuracy: 0.9848 - val_loss: 0.9912 - val_accuracy: 0.8153\n","\n","Epoch 00207: val_accuracy did not improve from 0.93103\n","Epoch 208/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.9760 - val_accuracy: 0.8547\n","\n","Epoch 00208: val_accuracy did not improve from 0.93103\n","Epoch 209/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0174 - accuracy: 0.9933 - val_loss: 0.6469 - val_accuracy: 0.8892\n","\n","Epoch 00209: val_accuracy did not improve from 0.93103\n","Epoch 210/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0100 - accuracy: 0.9957 - val_loss: 0.6402 - val_accuracy: 0.8842\n","\n","Epoch 00210: val_accuracy did not improve from 0.93103\n","Epoch 211/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6376 - val_accuracy: 0.8842\n","\n","Epoch 00211: val_accuracy did not improve from 0.93103\n","Epoch 212/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0379 - accuracy: 0.9896 - val_loss: 0.5871 - val_accuracy: 0.8916\n","\n","Epoch 00212: val_accuracy did not improve from 0.93103\n","Epoch 213/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.5450 - val_accuracy: 0.9039\n","\n","Epoch 00213: val_accuracy did not improve from 0.93103\n","Epoch 214/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.5102 - val_accuracy: 0.8941\n","\n","Epoch 00214: val_accuracy did not improve from 0.93103\n","Epoch 215/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.6253 - val_accuracy: 0.8916\n","\n","Epoch 00215: val_accuracy did not improve from 0.93103\n","Epoch 216/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.6440 - val_accuracy: 0.8818\n","\n","Epoch 00216: val_accuracy did not improve from 0.93103\n","Epoch 217/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.6604 - val_accuracy: 0.8916\n","\n","Epoch 00217: val_accuracy did not improve from 0.93103\n","Epoch 218/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5468 - val_accuracy: 0.8818\n","\n","Epoch 00218: val_accuracy did not improve from 0.93103\n","Epoch 219/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5088 - val_accuracy: 0.9039\n","\n","Epoch 00219: val_accuracy did not improve from 0.93103\n","Epoch 220/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.8966\n","\n","Epoch 00220: val_accuracy did not improve from 0.93103\n","Epoch 221/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4731 - val_accuracy: 0.9039\n","\n","Epoch 00221: val_accuracy did not improve from 0.93103\n","Epoch 222/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.9039\n","\n","Epoch 00222: val_accuracy did not improve from 0.93103\n","Epoch 223/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5515 - val_accuracy: 0.8941\n","\n","Epoch 00223: val_accuracy did not improve from 0.93103\n","Epoch 224/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5228 - val_accuracy: 0.9015\n","\n","Epoch 00224: val_accuracy did not improve from 0.93103\n","Epoch 225/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.8990\n","\n","Epoch 00225: val_accuracy did not improve from 0.93103\n","Epoch 226/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.6301 - val_accuracy: 0.8916\n","\n","Epoch 00226: val_accuracy did not improve from 0.93103\n","Epoch 227/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.1016 - accuracy: 0.9744 - val_loss: 0.6239 - val_accuracy: 0.8325\n","\n","Epoch 00227: val_accuracy did not improve from 0.93103\n","Epoch 228/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0525 - accuracy: 0.9829 - val_loss: 0.7381 - val_accuracy: 0.8645\n","\n","Epoch 00228: val_accuracy did not improve from 0.93103\n","Epoch 229/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0268 - accuracy: 0.9927 - val_loss: 0.8836 - val_accuracy: 0.8744\n","\n","Epoch 00229: val_accuracy did not improve from 0.93103\n","Epoch 230/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0418 - accuracy: 0.9854 - val_loss: 1.4200 - val_accuracy: 0.7882\n","\n","Epoch 00230: val_accuracy did not improve from 0.93103\n","Epoch 231/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0507 - accuracy: 0.9836 - val_loss: 1.0528 - val_accuracy: 0.8325\n","\n","Epoch 00231: val_accuracy did not improve from 0.93103\n","Epoch 232/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0685 - accuracy: 0.9775 - val_loss: 0.8436 - val_accuracy: 0.8350\n","\n","Epoch 00232: val_accuracy did not improve from 0.93103\n","Epoch 233/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.4686 - val_accuracy: 0.8966\n","\n","Epoch 00233: val_accuracy did not improve from 0.93103\n","Epoch 234/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.4414 - val_accuracy: 0.9039\n","\n","Epoch 00234: val_accuracy did not improve from 0.93103\n","Epoch 235/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.4830 - val_accuracy: 0.8990\n","\n","Epoch 00235: val_accuracy did not improve from 0.93103\n","Epoch 236/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.3995 - val_accuracy: 0.9187\n","\n","Epoch 00236: val_accuracy did not improve from 0.93103\n","Epoch 237/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9187\n","\n","Epoch 00237: val_accuracy did not improve from 0.93103\n","Epoch 238/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9286\n","\n","Epoch 00238: val_accuracy did not improve from 0.93103\n","Epoch 239/500\n","52/52 [==============================] - 12s 224ms/step - loss: 7.2080e-04 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9187\n","\n","Epoch 00239: val_accuracy did not improve from 0.93103\n","Epoch 240/500\n","52/52 [==============================] - 12s 226ms/step - loss: 5.5359e-04 - accuracy: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.9236\n","\n","Epoch 00240: val_accuracy did not improve from 0.93103\n","Epoch 241/500\n","52/52 [==============================] - 12s 225ms/step - loss: 8.4400e-04 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.9163\n","\n","Epoch 00241: val_accuracy did not improve from 0.93103\n","Epoch 242/500\n","52/52 [==============================] - 12s 224ms/step - loss: 6.2678e-04 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9212\n","\n","Epoch 00242: val_accuracy did not improve from 0.93103\n","Epoch 243/500\n","52/52 [==============================] - 12s 224ms/step - loss: 8.4205e-04 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9187\n","\n","Epoch 00243: val_accuracy did not improve from 0.93103\n","Epoch 244/500\n","52/52 [==============================] - 12s 225ms/step - loss: 2.7852e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9261\n","\n","Epoch 00244: val_accuracy did not improve from 0.93103\n","Epoch 245/500\n","52/52 [==============================] - 12s 224ms/step - loss: 6.0938e-04 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.9310\n","\n","Epoch 00245: val_accuracy did not improve from 0.93103\n","Epoch 246/500\n","52/52 [==============================] - 12s 226ms/step - loss: 4.2691e-04 - accuracy: 1.0000 - val_loss: 0.3690 - val_accuracy: 0.9310\n","\n","Epoch 00246: val_accuracy did not improve from 0.93103\n","Epoch 247/500\n","52/52 [==============================] - 12s 225ms/step - loss: 5.1800e-04 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9310\n","\n","Epoch 00247: val_accuracy did not improve from 0.93103\n","Epoch 248/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0149 - accuracy: 0.9976 - val_loss: 0.4369 - val_accuracy: 0.9212\n","\n","Epoch 00248: val_accuracy did not improve from 0.93103\n","Epoch 249/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0365 - accuracy: 0.9872 - val_loss: 2.1021 - val_accuracy: 0.6970\n","\n","Epoch 00249: val_accuracy did not improve from 0.93103\n","Epoch 250/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0587 - accuracy: 0.9793 - val_loss: 1.1745 - val_accuracy: 0.8153\n","\n","Epoch 00250: val_accuracy did not improve from 0.93103\n","Epoch 251/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0490 - accuracy: 0.9842 - val_loss: 0.6309 - val_accuracy: 0.8916\n","\n","Epoch 00251: val_accuracy did not improve from 0.93103\n","Epoch 252/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.5199 - val_accuracy: 0.9064\n","\n","Epoch 00252: val_accuracy did not improve from 0.93103\n","Epoch 253/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.4864 - val_accuracy: 0.9015\n","\n","Epoch 00253: val_accuracy did not improve from 0.93103\n","Epoch 254/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4153 - val_accuracy: 0.9089\n","\n","Epoch 00254: val_accuracy did not improve from 0.93103\n","Epoch 255/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4046 - val_accuracy: 0.9212\n","\n","Epoch 00255: val_accuracy did not improve from 0.93103\n","Epoch 256/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.9138\n","\n","Epoch 00256: val_accuracy did not improve from 0.93103\n","Epoch 257/500\n","52/52 [==============================] - 12s 225ms/step - loss: 7.0484e-04 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.9187\n","\n","Epoch 00257: val_accuracy did not improve from 0.93103\n","Epoch 258/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.9138\n","\n","Epoch 00258: val_accuracy did not improve from 0.93103\n","Epoch 259/500\n","52/52 [==============================] - 12s 224ms/step - loss: 4.6069e-04 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.9113\n","\n","Epoch 00259: val_accuracy did not improve from 0.93103\n","Epoch 260/500\n","52/52 [==============================] - 12s 222ms/step - loss: 7.8092e-04 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.9138\n","\n","Epoch 00260: val_accuracy did not improve from 0.93103\n","Epoch 261/500\n","52/52 [==============================] - 12s 221ms/step - loss: 5.1198e-04 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.9039\n","\n","Epoch 00261: val_accuracy did not improve from 0.93103\n","Epoch 262/500\n","52/52 [==============================] - 12s 224ms/step - loss: 4.3781e-04 - accuracy: 1.0000 - val_loss: 0.3892 - val_accuracy: 0.9187\n","\n","Epoch 00262: val_accuracy did not improve from 0.93103\n","Epoch 263/500\n","52/52 [==============================] - 12s 223ms/step - loss: 6.8888e-04 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9138\n","\n","Epoch 00263: val_accuracy did not improve from 0.93103\n","Epoch 264/500\n","52/52 [==============================] - 12s 222ms/step - loss: 8.1032e-04 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9163\n","\n","Epoch 00264: val_accuracy did not improve from 0.93103\n","Epoch 265/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.4179 - val_accuracy: 0.9236\n","\n","Epoch 00265: val_accuracy did not improve from 0.93103\n","Epoch 266/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0586 - accuracy: 0.9805 - val_loss: 1.0885 - val_accuracy: 0.8325\n","\n","Epoch 00266: val_accuracy did not improve from 0.93103\n","Epoch 267/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0949 - accuracy: 0.9714 - val_loss: 0.7141 - val_accuracy: 0.8768\n","\n","Epoch 00267: val_accuracy did not improve from 0.93103\n","Epoch 268/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.6414 - val_accuracy: 0.8645\n","\n","Epoch 00268: val_accuracy did not improve from 0.93103\n","Epoch 269/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 0.5870 - val_accuracy: 0.8522\n","\n","Epoch 00269: val_accuracy did not improve from 0.93103\n","Epoch 270/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.4345 - val_accuracy: 0.9113\n","\n","Epoch 00270: val_accuracy did not improve from 0.93103\n","Epoch 271/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.3769 - val_accuracy: 0.9187\n","\n","Epoch 00271: val_accuracy did not improve from 0.93103\n","Epoch 272/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.3996 - val_accuracy: 0.9039\n","\n","Epoch 00272: val_accuracy did not improve from 0.93103\n","Epoch 273/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3864 - val_accuracy: 0.9187\n","\n","Epoch 00273: val_accuracy did not improve from 0.93103\n","Epoch 274/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.4419 - val_accuracy: 0.9138\n","\n","Epoch 00274: val_accuracy did not improve from 0.93103\n","Epoch 275/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.9163\n","\n","Epoch 00275: val_accuracy did not improve from 0.93103\n","Epoch 276/500\n","52/52 [==============================] - 12s 223ms/step - loss: 7.3066e-04 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.9261\n","\n","Epoch 00276: val_accuracy did not improve from 0.93103\n","Epoch 277/500\n","52/52 [==============================] - 12s 223ms/step - loss: 2.6229e-04 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9163\n","\n","Epoch 00277: val_accuracy did not improve from 0.93103\n","Epoch 278/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5253 - val_accuracy: 0.8916\n","\n","Epoch 00278: val_accuracy did not improve from 0.93103\n","Epoch 279/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.5717 - val_accuracy: 0.8719\n","\n","Epoch 00279: val_accuracy did not improve from 0.93103\n","Epoch 280/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9064\n","\n","Epoch 00280: val_accuracy did not improve from 0.93103\n","Epoch 281/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3863 - val_accuracy: 0.8990\n","\n","Epoch 00281: val_accuracy did not improve from 0.93103\n","Epoch 282/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9064\n","\n","Epoch 00282: val_accuracy did not improve from 0.93103\n","Epoch 283/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.8198 - val_accuracy: 0.8325\n","\n","Epoch 00283: val_accuracy did not improve from 0.93103\n","Epoch 284/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0526 - accuracy: 0.9854 - val_loss: 0.8816 - val_accuracy: 0.8645\n","\n","Epoch 00284: val_accuracy did not improve from 0.93103\n","Epoch 285/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 0.9277 - val_accuracy: 0.8473\n","\n","Epoch 00285: val_accuracy did not improve from 0.93103\n","Epoch 286/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 0.6173 - val_accuracy: 0.8966\n","\n","Epoch 00286: val_accuracy did not improve from 0.93103\n","Epoch 287/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.5381 - val_accuracy: 0.8916\n","\n","Epoch 00287: val_accuracy did not improve from 0.93103\n","Epoch 288/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0213 - accuracy: 0.9921 - val_loss: 0.7737 - val_accuracy: 0.8621\n","\n","Epoch 00288: val_accuracy did not improve from 0.93103\n","Epoch 289/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5221 - val_accuracy: 0.8818\n","\n","Epoch 00289: val_accuracy did not improve from 0.93103\n","Epoch 290/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.4133 - val_accuracy: 0.9039\n","\n","Epoch 00290: val_accuracy did not improve from 0.93103\n","Epoch 291/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4079 - val_accuracy: 0.9039\n","\n","Epoch 00291: val_accuracy did not improve from 0.93103\n","Epoch 292/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.5327 - val_accuracy: 0.9015\n","\n","Epoch 00292: val_accuracy did not improve from 0.93103\n","Epoch 293/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.4852 - val_accuracy: 0.9064\n","\n","Epoch 00293: val_accuracy did not improve from 0.93103\n","Epoch 294/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.4793 - val_accuracy: 0.9089\n","\n","Epoch 00294: val_accuracy did not improve from 0.93103\n","Epoch 295/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.5306 - val_accuracy: 0.8966\n","\n","Epoch 00295: val_accuracy did not improve from 0.93103\n","Epoch 296/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.5385 - val_accuracy: 0.8990\n","\n","Epoch 00296: val_accuracy did not improve from 0.93103\n","Epoch 297/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4254 - val_accuracy: 0.9187\n","\n","Epoch 00297: val_accuracy did not improve from 0.93103\n","Epoch 298/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9138\n","\n","Epoch 00298: val_accuracy did not improve from 0.93103\n","Epoch 299/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.3939 - val_accuracy: 0.9212\n","\n","Epoch 00299: val_accuracy did not improve from 0.93103\n","Epoch 300/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.4037 - val_accuracy: 0.9064\n","\n","Epoch 00300: val_accuracy did not improve from 0.93103\n","Epoch 301/500\n","52/52 [==============================] - 12s 224ms/step - loss: 7.1321e-04 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.9187\n","\n","Epoch 00301: val_accuracy did not improve from 0.93103\n","Epoch 302/500\n","52/52 [==============================] - 12s 227ms/step - loss: 4.4941e-04 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.9212\n","\n","Epoch 00302: val_accuracy did not improve from 0.93103\n","Epoch 303/500\n","52/52 [==============================] - 12s 223ms/step - loss: 3.8860e-04 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.9310\n","\n","Epoch 00303: val_accuracy did not improve from 0.93103\n","Epoch 304/500\n","52/52 [==============================] - 12s 224ms/step - loss: 3.5254e-04 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.9335\n","\n","Epoch 00304: val_accuracy improved from 0.93103 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 305/500\n","52/52 [==============================] - 12s 229ms/step - loss: 4.7439e-04 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9261\n","\n","Epoch 00305: val_accuracy did not improve from 0.93350\n","Epoch 306/500\n","52/52 [==============================] - 12s 226ms/step - loss: 7.8309e-04 - accuracy: 0.9994 - val_loss: 0.3843 - val_accuracy: 0.9310\n","\n","Epoch 00306: val_accuracy did not improve from 0.93350\n","Epoch 307/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 0.5064 - val_accuracy: 0.9187\n","\n","Epoch 00307: val_accuracy did not improve from 0.93350\n","Epoch 308/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.6665 - val_accuracy: 0.9138\n","\n","Epoch 00308: val_accuracy did not improve from 0.93350\n","Epoch 309/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0662 - accuracy: 0.9823 - val_loss: 1.5313 - val_accuracy: 0.7463\n","\n","Epoch 00309: val_accuracy did not improve from 0.93350\n","Epoch 310/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0513 - accuracy: 0.9829 - val_loss: 2.2954 - val_accuracy: 0.7069\n","\n","Epoch 00310: val_accuracy did not improve from 0.93350\n","Epoch 311/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 0.6899 - val_accuracy: 0.8744\n","\n","Epoch 00311: val_accuracy did not improve from 0.93350\n","Epoch 312/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0269 - accuracy: 0.9884 - val_loss: 0.8194 - val_accuracy: 0.8645\n","\n","Epoch 00312: val_accuracy did not improve from 0.93350\n","Epoch 313/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 0.8932 - val_accuracy: 0.7980\n","\n","Epoch 00313: val_accuracy did not improve from 0.93350\n","Epoch 314/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0378 - accuracy: 0.9872 - val_loss: 0.5755 - val_accuracy: 0.8867\n","\n","Epoch 00314: val_accuracy did not improve from 0.93350\n","Epoch 315/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0223 - accuracy: 0.9915 - val_loss: 0.6482 - val_accuracy: 0.8744\n","\n","Epoch 00315: val_accuracy did not improve from 0.93350\n","Epoch 316/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.5228 - val_accuracy: 0.9064\n","\n","Epoch 00316: val_accuracy did not improve from 0.93350\n","Epoch 317/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5934 - val_accuracy: 0.8966\n","\n","Epoch 00317: val_accuracy did not improve from 0.93350\n","Epoch 318/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.5514 - val_accuracy: 0.9163\n","\n","Epoch 00318: val_accuracy did not improve from 0.93350\n","Epoch 319/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.9187\n","\n","Epoch 00319: val_accuracy did not improve from 0.93350\n","Epoch 320/500\n","52/52 [==============================] - 12s 225ms/step - loss: 8.2005e-04 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.9089\n","\n","Epoch 00320: val_accuracy did not improve from 0.93350\n","Epoch 321/500\n","52/52 [==============================] - 12s 224ms/step - loss: 5.6887e-04 - accuracy: 1.0000 - val_loss: 0.4740 - val_accuracy: 0.9089\n","\n","Epoch 00321: val_accuracy did not improve from 0.93350\n","Epoch 322/500\n","52/52 [==============================] - 12s 226ms/step - loss: 3.2641e-04 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.9163\n","\n","Epoch 00322: val_accuracy did not improve from 0.93350\n","Epoch 323/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4453 - val_accuracy: 0.9163\n","\n","Epoch 00323: val_accuracy did not improve from 0.93350\n","Epoch 324/500\n","52/52 [==============================] - 12s 226ms/step - loss: 5.2397e-04 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9335\n","\n","Epoch 00324: val_accuracy did not improve from 0.93350\n","Epoch 325/500\n","52/52 [==============================] - 12s 224ms/step - loss: 9.7247e-04 - accuracy: 1.0000 - val_loss: 0.4976 - val_accuracy: 0.9138\n","\n","Epoch 00325: val_accuracy did not improve from 0.93350\n","Epoch 326/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4782 - val_accuracy: 0.9163\n","\n","Epoch 00326: val_accuracy did not improve from 0.93350\n","Epoch 327/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0362 - accuracy: 0.9896 - val_loss: 1.8915 - val_accuracy: 0.7586\n","\n","Epoch 00327: val_accuracy did not improve from 0.93350\n","Epoch 328/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0197 - accuracy: 0.9921 - val_loss: 0.5411 - val_accuracy: 0.8916\n","\n","Epoch 00328: val_accuracy did not improve from 0.93350\n","Epoch 329/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.6059 - val_accuracy: 0.8744\n","\n","Epoch 00329: val_accuracy did not improve from 0.93350\n","Epoch 330/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.5345 - val_accuracy: 0.8990\n","\n","Epoch 00330: val_accuracy did not improve from 0.93350\n","Epoch 331/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.6073 - val_accuracy: 0.8966\n","\n","Epoch 00331: val_accuracy did not improve from 0.93350\n","Epoch 332/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.6267 - val_accuracy: 0.8990\n","\n","Epoch 00332: val_accuracy did not improve from 0.93350\n","Epoch 333/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.4428 - val_accuracy: 0.9212\n","\n","Epoch 00333: val_accuracy did not improve from 0.93350\n","Epoch 334/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.6134 - val_accuracy: 0.8892\n","\n","Epoch 00334: val_accuracy did not improve from 0.93350\n","Epoch 335/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.4464 - val_accuracy: 0.9113\n","\n","Epoch 00335: val_accuracy did not improve from 0.93350\n","Epoch 336/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4437 - val_accuracy: 0.9163\n","\n","Epoch 00336: val_accuracy did not improve from 0.93350\n","Epoch 337/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9015\n","\n","Epoch 00337: val_accuracy did not improve from 0.93350\n","Epoch 338/500\n","52/52 [==============================] - 12s 225ms/step - loss: 6.1688e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9163\n","\n","Epoch 00338: val_accuracy did not improve from 0.93350\n","Epoch 339/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.4605 - val_accuracy: 0.9138\n","\n","Epoch 00339: val_accuracy did not improve from 0.93350\n","Epoch 340/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4071 - val_accuracy: 0.9212\n","\n","Epoch 00340: val_accuracy did not improve from 0.93350\n","Epoch 341/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.4950 - val_accuracy: 0.9039\n","\n","Epoch 00341: val_accuracy did not improve from 0.93350\n","Epoch 342/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4840 - val_accuracy: 0.9015\n","\n","Epoch 00342: val_accuracy did not improve from 0.93350\n","Epoch 343/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4832 - val_accuracy: 0.8966\n","\n","Epoch 00343: val_accuracy did not improve from 0.93350\n","Epoch 344/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.9138\n","\n","Epoch 00344: val_accuracy did not improve from 0.93350\n","Epoch 345/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.6972 - val_accuracy: 0.8867\n","\n","Epoch 00345: val_accuracy did not improve from 0.93350\n","Epoch 346/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0276 - accuracy: 0.9909 - val_loss: 0.8686 - val_accuracy: 0.8547\n","\n","Epoch 00346: val_accuracy did not improve from 0.93350\n","Epoch 347/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0286 - accuracy: 0.9921 - val_loss: 0.8541 - val_accuracy: 0.8498\n","\n","Epoch 00347: val_accuracy did not improve from 0.93350\n","Epoch 348/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0222 - accuracy: 0.9951 - val_loss: 0.5501 - val_accuracy: 0.8842\n","\n","Epoch 00348: val_accuracy did not improve from 0.93350\n","Epoch 349/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.6706 - val_accuracy: 0.8818\n","\n","Epoch 00349: val_accuracy did not improve from 0.93350\n","Epoch 350/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.5440 - val_accuracy: 0.9015\n","\n","Epoch 00350: val_accuracy did not improve from 0.93350\n","Epoch 351/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0320 - accuracy: 0.9927 - val_loss: 0.5803 - val_accuracy: 0.8941\n","\n","Epoch 00351: val_accuracy did not improve from 0.93350\n","Epoch 352/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0117 - accuracy: 0.9951 - val_loss: 0.5544 - val_accuracy: 0.8842\n","\n","Epoch 00352: val_accuracy did not improve from 0.93350\n","Epoch 353/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.4699 - val_accuracy: 0.9015\n","\n","Epoch 00353: val_accuracy did not improve from 0.93350\n","Epoch 354/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.5423 - val_accuracy: 0.8966\n","\n","Epoch 00354: val_accuracy did not improve from 0.93350\n","Epoch 355/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4457 - val_accuracy: 0.9039\n","\n","Epoch 00355: val_accuracy did not improve from 0.93350\n","Epoch 356/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4503 - val_accuracy: 0.9015\n","\n","Epoch 00356: val_accuracy did not improve from 0.93350\n","Epoch 357/500\n","52/52 [==============================] - 12s 225ms/step - loss: 6.3602e-04 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.9089\n","\n","Epoch 00357: val_accuracy did not improve from 0.93350\n","Epoch 358/500\n","52/52 [==============================] - 12s 224ms/step - loss: 6.6563e-04 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9187\n","\n","Epoch 00358: val_accuracy did not improve from 0.93350\n","Epoch 359/500\n","52/52 [==============================] - 12s 226ms/step - loss: 3.5288e-04 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.9163\n","\n","Epoch 00359: val_accuracy did not improve from 0.93350\n","Epoch 360/500\n","52/52 [==============================] - 12s 225ms/step - loss: 3.0437e-04 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.9138\n","\n","Epoch 00360: val_accuracy did not improve from 0.93350\n","Epoch 361/500\n","52/52 [==============================] - 12s 224ms/step - loss: 3.8058e-04 - accuracy: 1.0000 - val_loss: 0.3989 - val_accuracy: 0.9138\n","\n","Epoch 00361: val_accuracy did not improve from 0.93350\n","Epoch 362/500\n","52/52 [==============================] - 12s 222ms/step - loss: 6.9288e-04 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.9064\n","\n","Epoch 00362: val_accuracy did not improve from 0.93350\n","Epoch 363/500\n","52/52 [==============================] - 12s 224ms/step - loss: 2.6714e-04 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.9113\n","\n","Epoch 00363: val_accuracy did not improve from 0.93350\n","Epoch 364/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0152 - accuracy: 0.9933 - val_loss: 0.7175 - val_accuracy: 0.8842\n","\n","Epoch 00364: val_accuracy did not improve from 0.93350\n","Epoch 365/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.6208 - val_accuracy: 0.9015\n","\n","Epoch 00365: val_accuracy did not improve from 0.93350\n","Epoch 366/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5191 - val_accuracy: 0.9113\n","\n","Epoch 00366: val_accuracy did not improve from 0.93350\n","Epoch 367/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5214 - val_accuracy: 0.8990\n","\n","Epoch 00367: val_accuracy did not improve from 0.93350\n","Epoch 368/500\n","52/52 [==============================] - 12s 222ms/step - loss: 5.5641e-04 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9212\n","\n","Epoch 00368: val_accuracy did not improve from 0.93350\n","Epoch 369/500\n","52/52 [==============================] - 12s 224ms/step - loss: 9.1627e-04 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.9039\n","\n","Epoch 00369: val_accuracy did not improve from 0.93350\n","Epoch 370/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4806 - val_accuracy: 0.9138\n","\n","Epoch 00370: val_accuracy did not improve from 0.93350\n","Epoch 371/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.6489 - val_accuracy: 0.8916\n","\n","Epoch 00371: val_accuracy did not improve from 0.93350\n","Epoch 372/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.6493 - val_accuracy: 0.8966\n","\n","Epoch 00372: val_accuracy did not improve from 0.93350\n","Epoch 373/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.6014 - val_accuracy: 0.9039\n","\n","Epoch 00373: val_accuracy did not improve from 0.93350\n","Epoch 374/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.5648 - val_accuracy: 0.9039\n","\n","Epoch 00374: val_accuracy did not improve from 0.93350\n","Epoch 375/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5602 - val_accuracy: 0.8966\n","\n","Epoch 00375: val_accuracy did not improve from 0.93350\n","Epoch 376/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.6708 - val_accuracy: 0.8793\n","\n","Epoch 00376: val_accuracy did not improve from 0.93350\n","Epoch 377/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0263 - accuracy: 0.9896 - val_loss: 0.8822 - val_accuracy: 0.8522\n","\n","Epoch 00377: val_accuracy did not improve from 0.93350\n","Epoch 378/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 1.0921 - val_accuracy: 0.8547\n","\n","Epoch 00378: val_accuracy did not improve from 0.93350\n","Epoch 379/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.1292 - accuracy: 0.9677 - val_loss: 2.1856 - val_accuracy: 0.7931\n","\n","Epoch 00379: val_accuracy did not improve from 0.93350\n","Epoch 380/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0290 - accuracy: 0.9878 - val_loss: 0.5747 - val_accuracy: 0.8941\n","\n","Epoch 00380: val_accuracy did not improve from 0.93350\n","Epoch 381/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.6058 - val_accuracy: 0.8941\n","\n","Epoch 00381: val_accuracy did not improve from 0.93350\n","Epoch 382/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.4953 - val_accuracy: 0.9039\n","\n","Epoch 00382: val_accuracy did not improve from 0.93350\n","Epoch 383/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.5229 - val_accuracy: 0.9015\n","\n","Epoch 00383: val_accuracy did not improve from 0.93350\n","Epoch 384/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.3993 - val_accuracy: 0.9039\n","\n","Epoch 00384: val_accuracy did not improve from 0.93350\n","Epoch 385/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.9138\n","\n","Epoch 00385: val_accuracy did not improve from 0.93350\n","Epoch 386/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4489 - val_accuracy: 0.9113\n","\n","Epoch 00386: val_accuracy did not improve from 0.93350\n","Epoch 387/500\n","52/52 [==============================] - 12s 222ms/step - loss: 9.6614e-04 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9236\n","\n","Epoch 00387: val_accuracy did not improve from 0.93350\n","Epoch 388/500\n","52/52 [==============================] - 12s 224ms/step - loss: 5.7275e-04 - accuracy: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.9064\n","\n","Epoch 00388: val_accuracy did not improve from 0.93350\n","Epoch 389/500\n","52/52 [==============================] - 12s 220ms/step - loss: 5.9514e-04 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.9113\n","\n","Epoch 00389: val_accuracy did not improve from 0.93350\n","Epoch 390/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.4310e-04 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.9261\n","\n","Epoch 00390: val_accuracy did not improve from 0.93350\n","Epoch 391/500\n","52/52 [==============================] - 12s 224ms/step - loss: 3.0211e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.9261\n","\n","Epoch 00391: val_accuracy did not improve from 0.93350\n","Epoch 392/500\n","52/52 [==============================] - 12s 221ms/step - loss: 4.5414e-04 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9261\n","\n","Epoch 00392: val_accuracy did not improve from 0.93350\n","Epoch 393/500\n","52/52 [==============================] - 12s 222ms/step - loss: 2.2764e-04 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.9236\n","\n","Epoch 00393: val_accuracy did not improve from 0.93350\n","Epoch 394/500\n","52/52 [==============================] - 12s 223ms/step - loss: 3.2009e-04 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.9039\n","\n","Epoch 00394: val_accuracy did not improve from 0.93350\n","Epoch 395/500\n","52/52 [==============================] - 12s 220ms/step - loss: 1.9746e-04 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9163\n","\n","Epoch 00395: val_accuracy did not improve from 0.93350\n","Epoch 396/500\n","52/52 [==============================] - 12s 223ms/step - loss: 3.3014e-04 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9138\n","\n","Epoch 00396: val_accuracy did not improve from 0.93350\n","Epoch 397/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.6812 - val_accuracy: 0.8842\n","\n","Epoch 00397: val_accuracy did not improve from 0.93350\n","Epoch 398/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.4593 - val_accuracy: 0.8793\n","\n","Epoch 00398: val_accuracy did not improve from 0.93350\n","Epoch 399/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.6533 - val_accuracy: 0.8916\n","\n","Epoch 00399: val_accuracy did not improve from 0.93350\n","Epoch 400/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0211 - accuracy: 0.9951 - val_loss: 0.5980 - val_accuracy: 0.8867\n","\n","Epoch 00400: val_accuracy did not improve from 0.93350\n","Epoch 401/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.3974 - val_accuracy: 0.9236\n","\n","Epoch 00401: val_accuracy did not improve from 0.93350\n","Epoch 402/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.6608 - val_accuracy: 0.8941\n","\n","Epoch 00402: val_accuracy did not improve from 0.93350\n","Epoch 403/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.7112 - val_accuracy: 0.8892\n","\n","Epoch 00403: val_accuracy did not improve from 0.93350\n","Epoch 404/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0428 - accuracy: 0.9896 - val_loss: 1.5905 - val_accuracy: 0.8054\n","\n","Epoch 00404: val_accuracy did not improve from 0.93350\n","Epoch 405/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0529 - accuracy: 0.9890 - val_loss: 0.8687 - val_accuracy: 0.8719\n","\n","Epoch 00405: val_accuracy did not improve from 0.93350\n","Epoch 406/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0223 - accuracy: 0.9903 - val_loss: 0.6975 - val_accuracy: 0.8719\n","\n","Epoch 00406: val_accuracy did not improve from 0.93350\n","Epoch 407/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.4197 - val_accuracy: 0.9064\n","\n","Epoch 00407: val_accuracy did not improve from 0.93350\n","Epoch 408/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.4415 - val_accuracy: 0.9138\n","\n","Epoch 00408: val_accuracy did not improve from 0.93350\n","Epoch 409/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.5243 - val_accuracy: 0.8916\n","\n","Epoch 00409: val_accuracy did not improve from 0.93350\n","Epoch 410/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.4504 - val_accuracy: 0.9015\n","\n","Epoch 00410: val_accuracy did not improve from 0.93350\n","Epoch 411/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.3123 - val_accuracy: 0.9310\n","\n","Epoch 00411: val_accuracy did not improve from 0.93350\n","Epoch 412/500\n","52/52 [==============================] - 12s 222ms/step - loss: 6.2197e-04 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.9310\n","\n","Epoch 00412: val_accuracy did not improve from 0.93350\n","Epoch 413/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3054 - val_accuracy: 0.9409\n","\n","Epoch 00413: val_accuracy improved from 0.93350 to 0.94089, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5\n","Epoch 414/500\n","52/52 [==============================] - 12s 229ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.5753 - val_accuracy: 0.9089\n","\n","Epoch 00414: val_accuracy did not improve from 0.94089\n","Epoch 415/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.3503 - val_accuracy: 0.9187\n","\n","Epoch 00415: val_accuracy did not improve from 0.94089\n","Epoch 416/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3672 - val_accuracy: 0.9261\n","\n","Epoch 00416: val_accuracy did not improve from 0.94089\n","Epoch 417/500\n","52/52 [==============================] - 12s 224ms/step - loss: 6.2690e-04 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.9335\n","\n","Epoch 00417: val_accuracy did not improve from 0.94089\n","Epoch 418/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.3547 - val_accuracy: 0.9335\n","\n","Epoch 00418: val_accuracy did not improve from 0.94089\n","Epoch 419/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9261\n","\n","Epoch 00419: val_accuracy did not improve from 0.94089\n","Epoch 420/500\n","52/52 [==============================] - 12s 225ms/step - loss: 7.4342e-04 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.9236\n","\n","Epoch 00420: val_accuracy did not improve from 0.94089\n","Epoch 421/500\n","52/52 [==============================] - 12s 223ms/step - loss: 5.9815e-04 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.9089\n","\n","Epoch 00421: val_accuracy did not improve from 0.94089\n","Epoch 422/500\n","52/52 [==============================] - 12s 222ms/step - loss: 9.0309e-04 - accuracy: 1.0000 - val_loss: 0.3740 - val_accuracy: 0.9187\n","\n","Epoch 00422: val_accuracy did not improve from 0.94089\n","Epoch 423/500\n","52/52 [==============================] - 12s 224ms/step - loss: 2.3392e-04 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.9236\n","\n","Epoch 00423: val_accuracy did not improve from 0.94089\n","Epoch 424/500\n","52/52 [==============================] - 12s 228ms/step - loss: 2.9344e-04 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9187\n","\n","Epoch 00424: val_accuracy did not improve from 0.94089\n","Epoch 425/500\n","52/52 [==============================] - 12s 225ms/step - loss: 2.2316e-04 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.9138\n","\n","Epoch 00425: val_accuracy did not improve from 0.94089\n","Epoch 426/500\n","52/52 [==============================] - 12s 224ms/step - loss: 4.2634e-04 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9163\n","\n","Epoch 00426: val_accuracy did not improve from 0.94089\n","Epoch 427/500\n","52/52 [==============================] - 12s 226ms/step - loss: 2.6488e-04 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9212\n","\n","Epoch 00427: val_accuracy did not improve from 0.94089\n","Epoch 428/500\n","52/52 [==============================] - 12s 224ms/step - loss: 2.6001e-04 - accuracy: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.9236\n","\n","Epoch 00428: val_accuracy did not improve from 0.94089\n","Epoch 429/500\n","52/52 [==============================] - 12s 228ms/step - loss: 7.3436e-05 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9335\n","\n","Epoch 00429: val_accuracy did not improve from 0.94089\n","Epoch 430/500\n","52/52 [==============================] - 12s 223ms/step - loss: 3.6771e-04 - accuracy: 1.0000 - val_loss: 0.4609 - val_accuracy: 0.8990\n","\n","Epoch 00430: val_accuracy did not improve from 0.94089\n","Epoch 431/500\n","52/52 [==============================] - 12s 225ms/step - loss: 7.1438e-04 - accuracy: 0.9994 - val_loss: 0.3771 - val_accuracy: 0.9261\n","\n","Epoch 00431: val_accuracy did not improve from 0.94089\n","Epoch 432/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9089\n","\n","Epoch 00432: val_accuracy did not improve from 0.94089\n","Epoch 433/500\n","52/52 [==============================] - 12s 226ms/step - loss: 2.2195e-04 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9039\n","\n","Epoch 00433: val_accuracy did not improve from 0.94089\n","Epoch 434/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.3881 - val_accuracy: 0.9163\n","\n","Epoch 00434: val_accuracy did not improve from 0.94089\n","Epoch 435/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.9138\n","\n","Epoch 00435: val_accuracy did not improve from 0.94089\n","Epoch 436/500\n","52/52 [==============================] - 12s 226ms/step - loss: 7.9608e-04 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.9113\n","\n","Epoch 00436: val_accuracy did not improve from 0.94089\n","Epoch 437/500\n","52/52 [==============================] - 12s 225ms/step - loss: 4.0195e-04 - accuracy: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.9113\n","\n","Epoch 00437: val_accuracy did not improve from 0.94089\n","Epoch 438/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4040 - val_accuracy: 0.9212\n","\n","Epoch 00438: val_accuracy did not improve from 0.94089\n","Epoch 439/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5019 - val_accuracy: 0.9212\n","\n","Epoch 00439: val_accuracy did not improve from 0.94089\n","Epoch 440/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.5430 - val_accuracy: 0.8966\n","\n","Epoch 00440: val_accuracy did not improve from 0.94089\n","Epoch 441/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5538 - val_accuracy: 0.8941\n","\n","Epoch 00441: val_accuracy did not improve from 0.94089\n","Epoch 442/500\n","52/52 [==============================] - 12s 229ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9064\n","\n","Epoch 00442: val_accuracy did not improve from 0.94089\n","Epoch 443/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5210 - val_accuracy: 0.9089\n","\n","Epoch 00443: val_accuracy did not improve from 0.94089\n","Epoch 444/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5571 - val_accuracy: 0.8966\n","\n","Epoch 00444: val_accuracy did not improve from 0.94089\n","Epoch 445/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.9264 - val_accuracy: 0.8571\n","\n","Epoch 00445: val_accuracy did not improve from 0.94089\n","Epoch 446/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 0.8412 - val_accuracy: 0.8498\n","\n","Epoch 00446: val_accuracy did not improve from 0.94089\n","Epoch 447/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.8140 - val_accuracy: 0.8670\n","\n","Epoch 00447: val_accuracy did not improve from 0.94089\n","Epoch 448/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4814 - val_accuracy: 0.8990\n","\n","Epoch 00448: val_accuracy did not improve from 0.94089\n","Epoch 449/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.5053 - val_accuracy: 0.9064\n","\n","Epoch 00449: val_accuracy did not improve from 0.94089\n","Epoch 450/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0132 - accuracy: 0.9939 - val_loss: 0.5907 - val_accuracy: 0.8941\n","\n","Epoch 00450: val_accuracy did not improve from 0.94089\n","Epoch 451/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0548 - accuracy: 0.9805 - val_loss: 1.1309 - val_accuracy: 0.8522\n","\n","Epoch 00451: val_accuracy did not improve from 0.94089\n","Epoch 452/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.6997 - val_accuracy: 0.8916\n","\n","Epoch 00452: val_accuracy did not improve from 0.94089\n","Epoch 453/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.5815 - val_accuracy: 0.8818\n","\n","Epoch 00453: val_accuracy did not improve from 0.94089\n","Epoch 454/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.5766 - val_accuracy: 0.8916\n","\n","Epoch 00454: val_accuracy did not improve from 0.94089\n","Epoch 455/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0132 - accuracy: 0.9945 - val_loss: 0.7314 - val_accuracy: 0.8695\n","\n","Epoch 00455: val_accuracy did not improve from 0.94089\n","Epoch 456/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.6082 - val_accuracy: 0.8892\n","\n","Epoch 00456: val_accuracy did not improve from 0.94089\n","Epoch 457/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.6770 - val_accuracy: 0.8719\n","\n","Epoch 00457: val_accuracy did not improve from 0.94089\n","Epoch 458/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0098 - accuracy: 0.9945 - val_loss: 0.5059 - val_accuracy: 0.8990\n","\n","Epoch 00458: val_accuracy did not improve from 0.94089\n","Epoch 459/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.9015\n","\n","Epoch 00459: val_accuracy did not improve from 0.94089\n","Epoch 460/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4553 - val_accuracy: 0.9187\n","\n","Epoch 00460: val_accuracy did not improve from 0.94089\n","Epoch 461/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4325 - val_accuracy: 0.9187\n","\n","Epoch 00461: val_accuracy did not improve from 0.94089\n","Epoch 462/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.4894 - val_accuracy: 0.8990\n","\n","Epoch 00462: val_accuracy did not improve from 0.94089\n","Epoch 463/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4700 - val_accuracy: 0.9236\n","\n","Epoch 00463: val_accuracy did not improve from 0.94089\n","Epoch 464/500\n","52/52 [==============================] - 12s 224ms/step - loss: 7.8348e-04 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.9138\n","\n","Epoch 00464: val_accuracy did not improve from 0.94089\n","Epoch 465/500\n","52/52 [==============================] - 12s 224ms/step - loss: 8.5829e-04 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.9310\n","\n","Epoch 00465: val_accuracy did not improve from 0.94089\n","Epoch 466/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9138\n","\n","Epoch 00466: val_accuracy did not improve from 0.94089\n","Epoch 467/500\n","52/52 [==============================] - 12s 230ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.6099 - val_accuracy: 0.8695\n","\n","Epoch 00467: val_accuracy did not improve from 0.94089\n","Epoch 468/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.5188 - val_accuracy: 0.9015\n","\n","Epoch 00468: val_accuracy did not improve from 0.94089\n","Epoch 469/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9236\n","\n","Epoch 00469: val_accuracy did not improve from 0.94089\n","Epoch 470/500\n","52/52 [==============================] - 12s 231ms/step - loss: 6.3875e-04 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.9236\n","\n","Epoch 00470: val_accuracy did not improve from 0.94089\n","Epoch 471/500\n","52/52 [==============================] - 12s 231ms/step - loss: 3.1427e-04 - accuracy: 1.0000 - val_loss: 0.4551 - val_accuracy: 0.9187\n","\n","Epoch 00471: val_accuracy did not improve from 0.94089\n","Epoch 472/500\n","52/52 [==============================] - 12s 225ms/step - loss: 1.6704e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9286\n","\n","Epoch 00472: val_accuracy did not improve from 0.94089\n","Epoch 473/500\n","52/52 [==============================] - 12s 228ms/step - loss: 3.7415e-04 - accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.9039\n","\n","Epoch 00473: val_accuracy did not improve from 0.94089\n","Epoch 474/500\n","52/52 [==============================] - 12s 229ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.5037 - val_accuracy: 0.9015\n","\n","Epoch 00474: val_accuracy did not improve from 0.94089\n","Epoch 475/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.5726 - val_accuracy: 0.9039\n","\n","Epoch 00475: val_accuracy did not improve from 0.94089\n","Epoch 476/500\n","52/52 [==============================] - 12s 229ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.6051 - val_accuracy: 0.9015\n","\n","Epoch 00476: val_accuracy did not improve from 0.94089\n","Epoch 477/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.6214 - val_accuracy: 0.8916\n","\n","Epoch 00477: val_accuracy did not improve from 0.94089\n","Epoch 478/500\n","52/52 [==============================] - 12s 231ms/step - loss: 0.0080 - accuracy: 0.9951 - val_loss: 0.5300 - val_accuracy: 0.9138\n","\n","Epoch 00478: val_accuracy did not improve from 0.94089\n","Epoch 479/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.8944 - val_accuracy: 0.8719\n","\n","Epoch 00479: val_accuracy did not improve from 0.94089\n","Epoch 480/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.4674 - val_accuracy: 0.9089\n","\n","Epoch 00480: val_accuracy did not improve from 0.94089\n","Epoch 481/500\n","52/52 [==============================] - 12s 231ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.6133 - val_accuracy: 0.9113\n","\n","Epoch 00481: val_accuracy did not improve from 0.94089\n","Epoch 482/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.9212\n","\n","Epoch 00482: val_accuracy did not improve from 0.94089\n","Epoch 483/500\n","52/52 [==============================] - 12s 231ms/step - loss: 4.5984e-04 - accuracy: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.9286\n","\n","Epoch 00483: val_accuracy did not improve from 0.94089\n","Epoch 484/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5201 - val_accuracy: 0.9113\n","\n","Epoch 00484: val_accuracy did not improve from 0.94089\n","Epoch 485/500\n","52/52 [==============================] - 12s 230ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.9212\n","\n","Epoch 00485: val_accuracy did not improve from 0.94089\n","Epoch 486/500\n","52/52 [==============================] - 12s 229ms/step - loss: 3.8496e-04 - accuracy: 1.0000 - val_loss: 0.4703 - val_accuracy: 0.9163\n","\n","Epoch 00486: val_accuracy did not improve from 0.94089\n","Epoch 487/500\n","52/52 [==============================] - 12s 229ms/step - loss: 4.6096e-04 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9236\n","\n","Epoch 00487: val_accuracy did not improve from 0.94089\n","Epoch 488/500\n","52/52 [==============================] - 12s 226ms/step - loss: 1.7320e-04 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.9236\n","\n","Epoch 00488: val_accuracy did not improve from 0.94089\n","Epoch 489/500\n","52/52 [==============================] - 12s 227ms/step - loss: 3.7642e-04 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9212\n","\n","Epoch 00489: val_accuracy did not improve from 0.94089\n","Epoch 490/500\n","52/52 [==============================] - 12s 225ms/step - loss: 2.5221e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9163\n","\n","Epoch 00490: val_accuracy did not improve from 0.94089\n","Epoch 491/500\n","52/52 [==============================] - 12s 226ms/step - loss: 1.2185e-04 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9187\n","\n","Epoch 00491: val_accuracy did not improve from 0.94089\n","Epoch 492/500\n","52/52 [==============================] - 12s 225ms/step - loss: 9.2703e-05 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.9286\n","\n","Epoch 00492: val_accuracy did not improve from 0.94089\n","Epoch 493/500\n","52/52 [==============================] - 12s 225ms/step - loss: 9.9952e-05 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9236\n","\n","Epoch 00493: val_accuracy did not improve from 0.94089\n","Epoch 494/500\n","52/52 [==============================] - 12s 229ms/step - loss: 1.1788e-04 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.9212\n","\n","Epoch 00494: val_accuracy did not improve from 0.94089\n","Epoch 495/500\n","52/52 [==============================] - 12s 225ms/step - loss: 1.0972e-04 - accuracy: 1.0000 - val_loss: 0.4018 - val_accuracy: 0.9286\n","\n","Epoch 00495: val_accuracy did not improve from 0.94089\n","Epoch 496/500\n","52/52 [==============================] - 12s 225ms/step - loss: 8.7293e-05 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.9261\n","\n","Epoch 00496: val_accuracy did not improve from 0.94089\n","Epoch 497/500\n","52/52 [==============================] - 12s 225ms/step - loss: 3.6146e-05 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9335\n","\n","Epoch 00497: val_accuracy did not improve from 0.94089\n","Epoch 498/500\n","52/52 [==============================] - 12s 226ms/step - loss: 7.6513e-05 - accuracy: 1.0000 - val_loss: 0.4593 - val_accuracy: 0.9236\n","\n","Epoch 00498: val_accuracy did not improve from 0.94089\n","Epoch 499/500\n","52/52 [==============================] - 12s 224ms/step - loss: 8.2521e-05 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9286\n","\n","Epoch 00499: val_accuracy did not improve from 0.94089\n","Epoch 500/500\n","52/52 [==============================] - 12s 224ms/step - loss: 8.5258e-05 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9236\n","\n","Epoch 00500: val_accuracy did not improve from 0.94089\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f676841af10>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1629824583845,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"aeea9e71-ed45-4e31-a165-ee37f8b98354"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1629824615416,"user_tz":-540,"elapsed":31575,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_05_2_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-"},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629824647034,"user_tz":-540,"elapsed":30630,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"9a8df80a-7c09-4dc4-92dd-4105875fe1e3"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD"},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz"},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK"},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1629824648489,"user_tz":-540,"elapsed":2,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1629824660152,"user_tz":-540,"elapsed":11665,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1629824660377,"user_tz":-540,"elapsed":3,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b6c9e616-42ab-476b-c9e0-80bad02f4487"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_05_2_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_05_2_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_067e9383-797c-4f67-82bd-7ed0324fdd0a\", \"Rotation_range_05_2_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_067e9383-797c-4f67-82bd-7ed0324fdd0a\", \"Rotation_range_05_2_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}