{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Rotation_range_15_4_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPVptCDs0e1hRZmVwSZRjNL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629879488488,"user_tz":-540,"elapsed":250,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0b888267-1fc7-4dc1-e25d-7bed5b749ae7"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Wed Aug 25 08:18:08 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629879519164,"user_tz":-540,"elapsed":15823,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"8e6e3f3e-667f-49fb-adb7-7721cca75b13"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1629879522656,"user_tz":-540,"elapsed":3497,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1629879523907,"user_tz":-540,"elapsed":1271,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1629879526602,"user_tz":-540,"elapsed":2697,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1629879546096,"user_tz":-540,"elapsed":19495,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1629879553659,"user_tz":-540,"elapsed":7582,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629879553661,"user_tz":-540,"elapsed":39,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"7f82fa08-4177-4781-9891-f0fdfe38c89e"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629879553979,"user_tz":-540,"elapsed":348,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ef0ba9b2-39ed-4fc5-c61b-6ec4d8ff6388"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=15,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1629879553980,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629885552837,"user_tz":-540,"elapsed":5998862,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"37102a5d-b795-4e58-c2a1-7ecad527815c"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 42s 284ms/step - loss: 1.8392 - accuracy: 0.3557 - val_loss: 7.1904 - val_accuracy: 0.0961\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09606, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 11s 219ms/step - loss: 1.2306 - accuracy: 0.5737 - val_loss: 9.5947 - val_accuracy: 0.0837\n","\n","Epoch 00002: val_accuracy did not improve from 0.09606\n","Epoch 3/500\n","52/52 [==============================] - 11s 219ms/step - loss: 1.0898 - accuracy: 0.6303 - val_loss: 30.3460 - val_accuracy: 0.1034\n","\n","Epoch 00003: val_accuracy improved from 0.09606 to 0.10345, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 4/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.8918 - accuracy: 0.7052 - val_loss: 32.8141 - val_accuracy: 0.1010\n","\n","Epoch 00004: val_accuracy did not improve from 0.10345\n","Epoch 5/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.8064 - accuracy: 0.7363 - val_loss: 11.3921 - val_accuracy: 0.1108\n","\n","Epoch 00005: val_accuracy improved from 0.10345 to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.6743 - accuracy: 0.7753 - val_loss: 6.4927 - val_accuracy: 0.2414\n","\n","Epoch 00006: val_accuracy improved from 0.11084 to 0.24138, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.6164 - accuracy: 0.7966 - val_loss: 4.2347 - val_accuracy: 0.3079\n","\n","Epoch 00007: val_accuracy improved from 0.24138 to 0.30788, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.5695 - accuracy: 0.8082 - val_loss: 3.5309 - val_accuracy: 0.3177\n","\n","Epoch 00008: val_accuracy improved from 0.30788 to 0.31773, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.5242 - accuracy: 0.8283 - val_loss: 5.5113 - val_accuracy: 0.2635\n","\n","Epoch 00009: val_accuracy did not improve from 0.31773\n","Epoch 10/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.5279 - accuracy: 0.8234 - val_loss: 1.2918 - val_accuracy: 0.6158\n","\n","Epoch 00010: val_accuracy improved from 0.31773 to 0.61576, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.5027 - accuracy: 0.8270 - val_loss: 1.0252 - val_accuracy: 0.7118\n","\n","Epoch 00011: val_accuracy improved from 0.61576 to 0.71182, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.4364 - accuracy: 0.8508 - val_loss: 1.2437 - val_accuracy: 0.6823\n","\n","Epoch 00012: val_accuracy did not improve from 0.71182\n","Epoch 13/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3897 - accuracy: 0.8672 - val_loss: 1.5900 - val_accuracy: 0.6158\n","\n","Epoch 00013: val_accuracy did not improve from 0.71182\n","Epoch 14/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3717 - accuracy: 0.8794 - val_loss: 1.5427 - val_accuracy: 0.6281\n","\n","Epoch 00014: val_accuracy did not improve from 0.71182\n","Epoch 15/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3963 - accuracy: 0.8703 - val_loss: 0.9807 - val_accuracy: 0.7660\n","\n","Epoch 00015: val_accuracy improved from 0.71182 to 0.76601, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 16/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.3550 - accuracy: 0.8800 - val_loss: 0.6276 - val_accuracy: 0.8177\n","\n","Epoch 00016: val_accuracy improved from 0.76601 to 0.81773, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 17/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.3091 - accuracy: 0.8952 - val_loss: 1.7752 - val_accuracy: 0.5764\n","\n","Epoch 00017: val_accuracy did not improve from 0.81773\n","Epoch 18/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.2753 - accuracy: 0.9056 - val_loss: 1.2439 - val_accuracy: 0.7094\n","\n","Epoch 00018: val_accuracy did not improve from 0.81773\n","Epoch 19/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3159 - accuracy: 0.8886 - val_loss: 0.5960 - val_accuracy: 0.8202\n","\n","Epoch 00019: val_accuracy improved from 0.81773 to 0.82020, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 20/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.3020 - accuracy: 0.8959 - val_loss: 1.3660 - val_accuracy: 0.6872\n","\n","Epoch 00020: val_accuracy did not improve from 0.82020\n","Epoch 21/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.3205 - accuracy: 0.8855 - val_loss: 0.8504 - val_accuracy: 0.7759\n","\n","Epoch 00021: val_accuracy did not improve from 0.82020\n","Epoch 22/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2711 - accuracy: 0.9062 - val_loss: 0.3882 - val_accuracy: 0.8793\n","\n","Epoch 00022: val_accuracy improved from 0.82020 to 0.87931, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 23/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2199 - accuracy: 0.9269 - val_loss: 0.7514 - val_accuracy: 0.7906\n","\n","Epoch 00023: val_accuracy did not improve from 0.87931\n","Epoch 24/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2419 - accuracy: 0.9123 - val_loss: 1.1037 - val_accuracy: 0.7044\n","\n","Epoch 00024: val_accuracy did not improve from 0.87931\n","Epoch 25/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2295 - accuracy: 0.9245 - val_loss: 0.7251 - val_accuracy: 0.8128\n","\n","Epoch 00025: val_accuracy did not improve from 0.87931\n","Epoch 26/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2045 - accuracy: 0.9281 - val_loss: 0.5815 - val_accuracy: 0.8325\n","\n","Epoch 00026: val_accuracy did not improve from 0.87931\n","Epoch 27/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1884 - accuracy: 0.9336 - val_loss: 0.6357 - val_accuracy: 0.8350\n","\n","Epoch 00027: val_accuracy did not improve from 0.87931\n","Epoch 28/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2006 - accuracy: 0.9287 - val_loss: 0.4775 - val_accuracy: 0.8547\n","\n","Epoch 00028: val_accuracy did not improve from 0.87931\n","Epoch 29/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1992 - accuracy: 0.9342 - val_loss: 0.7299 - val_accuracy: 0.7882\n","\n","Epoch 00029: val_accuracy did not improve from 0.87931\n","Epoch 30/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2069 - accuracy: 0.9281 - val_loss: 0.5416 - val_accuracy: 0.8448\n","\n","Epoch 00030: val_accuracy did not improve from 0.87931\n","Epoch 31/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2160 - accuracy: 0.9233 - val_loss: 0.5078 - val_accuracy: 0.8645\n","\n","Epoch 00031: val_accuracy did not improve from 0.87931\n","Epoch 32/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2054 - accuracy: 0.9281 - val_loss: 0.7522 - val_accuracy: 0.8005\n","\n","Epoch 00032: val_accuracy did not improve from 0.87931\n","Epoch 33/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1499 - accuracy: 0.9464 - val_loss: 0.6039 - val_accuracy: 0.8498\n","\n","Epoch 00033: val_accuracy did not improve from 0.87931\n","Epoch 34/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1515 - accuracy: 0.9452 - val_loss: 0.5685 - val_accuracy: 0.8473\n","\n","Epoch 00034: val_accuracy did not improve from 0.87931\n","Epoch 35/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1497 - accuracy: 0.9525 - val_loss: 0.5617 - val_accuracy: 0.8399\n","\n","Epoch 00035: val_accuracy did not improve from 0.87931\n","Epoch 36/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1784 - accuracy: 0.9421 - val_loss: 0.7657 - val_accuracy: 0.8251\n","\n","Epoch 00036: val_accuracy did not improve from 0.87931\n","Epoch 37/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1288 - accuracy: 0.9543 - val_loss: 0.7953 - val_accuracy: 0.7808\n","\n","Epoch 00037: val_accuracy did not improve from 0.87931\n","Epoch 38/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1408 - accuracy: 0.9525 - val_loss: 0.5668 - val_accuracy: 0.8571\n","\n","Epoch 00038: val_accuracy did not improve from 0.87931\n","Epoch 39/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1355 - accuracy: 0.9562 - val_loss: 0.4725 - val_accuracy: 0.8621\n","\n","Epoch 00039: val_accuracy did not improve from 0.87931\n","Epoch 40/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1394 - accuracy: 0.9519 - val_loss: 0.5198 - val_accuracy: 0.8473\n","\n","Epoch 00040: val_accuracy did not improve from 0.87931\n","Epoch 41/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1820 - accuracy: 0.9428 - val_loss: 2.3671 - val_accuracy: 0.6133\n","\n","Epoch 00041: val_accuracy did not improve from 0.87931\n","Epoch 42/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1514 - accuracy: 0.9458 - val_loss: 1.7146 - val_accuracy: 0.6749\n","\n","Epoch 00042: val_accuracy did not improve from 0.87931\n","Epoch 43/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1630 - accuracy: 0.9476 - val_loss: 0.8580 - val_accuracy: 0.7783\n","\n","Epoch 00043: val_accuracy did not improve from 0.87931\n","Epoch 44/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1745 - accuracy: 0.9348 - val_loss: 0.5290 - val_accuracy: 0.8645\n","\n","Epoch 00044: val_accuracy did not improve from 0.87931\n","Epoch 45/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1107 - accuracy: 0.9635 - val_loss: 0.6220 - val_accuracy: 0.8374\n","\n","Epoch 00045: val_accuracy did not improve from 0.87931\n","Epoch 46/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0829 - accuracy: 0.9750 - val_loss: 0.7124 - val_accuracy: 0.8227\n","\n","Epoch 00046: val_accuracy did not improve from 0.87931\n","Epoch 47/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1155 - accuracy: 0.9622 - val_loss: 0.7864 - val_accuracy: 0.8251\n","\n","Epoch 00047: val_accuracy did not improve from 0.87931\n","Epoch 48/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1209 - accuracy: 0.9574 - val_loss: 0.4425 - val_accuracy: 0.8793\n","\n","Epoch 00048: val_accuracy did not improve from 0.87931\n","Epoch 49/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0827 - accuracy: 0.9738 - val_loss: 0.5018 - val_accuracy: 0.8596\n","\n","Epoch 00049: val_accuracy did not improve from 0.87931\n","Epoch 50/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0794 - accuracy: 0.9738 - val_loss: 0.7655 - val_accuracy: 0.8177\n","\n","Epoch 00050: val_accuracy did not improve from 0.87931\n","Epoch 51/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0991 - accuracy: 0.9659 - val_loss: 0.6170 - val_accuracy: 0.8399\n","\n","Epoch 00051: val_accuracy did not improve from 0.87931\n","Epoch 52/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1340 - accuracy: 0.9488 - val_loss: 0.5438 - val_accuracy: 0.8448\n","\n","Epoch 00052: val_accuracy did not improve from 0.87931\n","Epoch 53/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1081 - accuracy: 0.9647 - val_loss: 0.5835 - val_accuracy: 0.8547\n","\n","Epoch 00053: val_accuracy did not improve from 0.87931\n","Epoch 54/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0930 - accuracy: 0.9677 - val_loss: 0.5539 - val_accuracy: 0.8645\n","\n","Epoch 00054: val_accuracy did not improve from 0.87931\n","Epoch 55/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0725 - accuracy: 0.9738 - val_loss: 0.4236 - val_accuracy: 0.8842\n","\n","Epoch 00055: val_accuracy improved from 0.87931 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 56/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0651 - accuracy: 0.9756 - val_loss: 0.5571 - val_accuracy: 0.8350\n","\n","Epoch 00056: val_accuracy did not improve from 0.88424\n","Epoch 57/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1102 - accuracy: 0.9659 - val_loss: 0.7049 - val_accuracy: 0.8227\n","\n","Epoch 00057: val_accuracy did not improve from 0.88424\n","Epoch 58/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0968 - accuracy: 0.9665 - val_loss: 0.7402 - val_accuracy: 0.8227\n","\n","Epoch 00058: val_accuracy did not improve from 0.88424\n","Epoch 59/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0765 - accuracy: 0.9787 - val_loss: 0.4875 - val_accuracy: 0.8744\n","\n","Epoch 00059: val_accuracy did not improve from 0.88424\n","Epoch 60/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1112 - accuracy: 0.9647 - val_loss: 0.6449 - val_accuracy: 0.8596\n","\n","Epoch 00060: val_accuracy did not improve from 0.88424\n","Epoch 61/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1097 - accuracy: 0.9629 - val_loss: 0.7515 - val_accuracy: 0.8153\n","\n","Epoch 00061: val_accuracy did not improve from 0.88424\n","Epoch 62/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0835 - accuracy: 0.9708 - val_loss: 0.3745 - val_accuracy: 0.8966\n","\n","Epoch 00062: val_accuracy improved from 0.88424 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 63/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1000 - accuracy: 0.9708 - val_loss: 1.2073 - val_accuracy: 0.7734\n","\n","Epoch 00063: val_accuracy did not improve from 0.89655\n","Epoch 64/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0956 - accuracy: 0.9689 - val_loss: 0.7650 - val_accuracy: 0.8473\n","\n","Epoch 00064: val_accuracy did not improve from 0.89655\n","Epoch 65/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0700 - accuracy: 0.9720 - val_loss: 0.8967 - val_accuracy: 0.8424\n","\n","Epoch 00065: val_accuracy did not improve from 0.89655\n","Epoch 66/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0678 - accuracy: 0.9787 - val_loss: 0.4755 - val_accuracy: 0.8768\n","\n","Epoch 00066: val_accuracy did not improve from 0.89655\n","Epoch 67/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0652 - accuracy: 0.9799 - val_loss: 0.4606 - val_accuracy: 0.8571\n","\n","Epoch 00067: val_accuracy did not improve from 0.89655\n","Epoch 68/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0661 - accuracy: 0.9744 - val_loss: 0.8447 - val_accuracy: 0.8374\n","\n","Epoch 00068: val_accuracy did not improve from 0.89655\n","Epoch 69/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0568 - accuracy: 0.9799 - val_loss: 0.5380 - val_accuracy: 0.8916\n","\n","Epoch 00069: val_accuracy did not improve from 0.89655\n","Epoch 70/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0785 - accuracy: 0.9732 - val_loss: 0.7570 - val_accuracy: 0.8350\n","\n","Epoch 00070: val_accuracy did not improve from 0.89655\n","Epoch 71/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0596 - accuracy: 0.9781 - val_loss: 0.5423 - val_accuracy: 0.8892\n","\n","Epoch 00071: val_accuracy did not improve from 0.89655\n","Epoch 72/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0718 - accuracy: 0.9787 - val_loss: 0.5756 - val_accuracy: 0.8670\n","\n","Epoch 00072: val_accuracy did not improve from 0.89655\n","Epoch 73/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0453 - accuracy: 0.9854 - val_loss: 1.2118 - val_accuracy: 0.7660\n","\n","Epoch 00073: val_accuracy did not improve from 0.89655\n","Epoch 74/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0456 - accuracy: 0.9854 - val_loss: 0.5064 - val_accuracy: 0.8744\n","\n","Epoch 00074: val_accuracy did not improve from 0.89655\n","Epoch 75/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.4620 - val_accuracy: 0.9113\n","\n","Epoch 00075: val_accuracy improved from 0.89655 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 76/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0308 - accuracy: 0.9878 - val_loss: 0.4406 - val_accuracy: 0.8990\n","\n","Epoch 00076: val_accuracy did not improve from 0.91133\n","Epoch 77/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0864 - accuracy: 0.9702 - val_loss: 1.4977 - val_accuracy: 0.7414\n","\n","Epoch 00077: val_accuracy did not improve from 0.91133\n","Epoch 78/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0900 - accuracy: 0.9744 - val_loss: 0.6957 - val_accuracy: 0.8300\n","\n","Epoch 00078: val_accuracy did not improve from 0.91133\n","Epoch 79/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1439 - accuracy: 0.9610 - val_loss: 1.0051 - val_accuracy: 0.7783\n","\n","Epoch 00079: val_accuracy did not improve from 0.91133\n","Epoch 80/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1083 - accuracy: 0.9647 - val_loss: 0.6515 - val_accuracy: 0.8547\n","\n","Epoch 00080: val_accuracy did not improve from 0.91133\n","Epoch 81/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0946 - accuracy: 0.9708 - val_loss: 0.8362 - val_accuracy: 0.8103\n","\n","Epoch 00081: val_accuracy did not improve from 0.91133\n","Epoch 82/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0775 - accuracy: 0.9756 - val_loss: 0.5180 - val_accuracy: 0.8744\n","\n","Epoch 00082: val_accuracy did not improve from 0.91133\n","Epoch 83/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0629 - accuracy: 0.9787 - val_loss: 0.4559 - val_accuracy: 0.9064\n","\n","Epoch 00083: val_accuracy did not improve from 0.91133\n","Epoch 84/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0513 - accuracy: 0.9823 - val_loss: 0.6122 - val_accuracy: 0.8547\n","\n","Epoch 00084: val_accuracy did not improve from 0.91133\n","Epoch 85/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.4375 - val_accuracy: 0.8793\n","\n","Epoch 00085: val_accuracy did not improve from 0.91133\n","Epoch 86/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0480 - accuracy: 0.9842 - val_loss: 0.5085 - val_accuracy: 0.8695\n","\n","Epoch 00086: val_accuracy did not improve from 0.91133\n","Epoch 87/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0839 - accuracy: 0.9714 - val_loss: 0.7933 - val_accuracy: 0.8177\n","\n","Epoch 00087: val_accuracy did not improve from 0.91133\n","Epoch 88/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0883 - accuracy: 0.9702 - val_loss: 0.4946 - val_accuracy: 0.8744\n","\n","Epoch 00088: val_accuracy did not improve from 0.91133\n","Epoch 89/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0881 - accuracy: 0.9695 - val_loss: 0.5273 - val_accuracy: 0.8744\n","\n","Epoch 00089: val_accuracy did not improve from 0.91133\n","Epoch 90/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0544 - accuracy: 0.9817 - val_loss: 0.4950 - val_accuracy: 0.8793\n","\n","Epoch 00090: val_accuracy did not improve from 0.91133\n","Epoch 91/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0511 - accuracy: 0.9823 - val_loss: 0.3609 - val_accuracy: 0.8966\n","\n","Epoch 00091: val_accuracy did not improve from 0.91133\n","Epoch 92/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.4569 - val_accuracy: 0.8892\n","\n","Epoch 00092: val_accuracy did not improve from 0.91133\n","Epoch 93/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0239 - accuracy: 0.9909 - val_loss: 0.4466 - val_accuracy: 0.9015\n","\n","Epoch 00093: val_accuracy did not improve from 0.91133\n","Epoch 94/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0307 - accuracy: 0.9866 - val_loss: 0.4956 - val_accuracy: 0.8818\n","\n","Epoch 00094: val_accuracy did not improve from 0.91133\n","Epoch 95/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0465 - accuracy: 0.9878 - val_loss: 0.5579 - val_accuracy: 0.8744\n","\n","Epoch 00095: val_accuracy did not improve from 0.91133\n","Epoch 96/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0308 - accuracy: 0.9903 - val_loss: 0.5433 - val_accuracy: 0.8916\n","\n","Epoch 00096: val_accuracy did not improve from 0.91133\n","Epoch 97/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.4944 - val_accuracy: 0.8990\n","\n","Epoch 00097: val_accuracy did not improve from 0.91133\n","Epoch 98/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.5000 - val_accuracy: 0.8867\n","\n","Epoch 00098: val_accuracy did not improve from 0.91133\n","Epoch 99/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0589 - accuracy: 0.9811 - val_loss: 0.8415 - val_accuracy: 0.8325\n","\n","Epoch 00099: val_accuracy did not improve from 0.91133\n","Epoch 100/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0832 - accuracy: 0.9689 - val_loss: 0.7570 - val_accuracy: 0.8621\n","\n","Epoch 00100: val_accuracy did not improve from 0.91133\n","Epoch 101/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0765 - accuracy: 0.9775 - val_loss: 0.6117 - val_accuracy: 0.8645\n","\n","Epoch 00101: val_accuracy did not improve from 0.91133\n","Epoch 102/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0662 - accuracy: 0.9787 - val_loss: 0.8414 - val_accuracy: 0.8153\n","\n","Epoch 00102: val_accuracy did not improve from 0.91133\n","Epoch 103/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0664 - accuracy: 0.9793 - val_loss: 0.6662 - val_accuracy: 0.8621\n","\n","Epoch 00103: val_accuracy did not improve from 0.91133\n","Epoch 104/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0411 - accuracy: 0.9890 - val_loss: 0.4433 - val_accuracy: 0.8867\n","\n","Epoch 00104: val_accuracy did not improve from 0.91133\n","Epoch 105/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0518 - accuracy: 0.9823 - val_loss: 0.5397 - val_accuracy: 0.8719\n","\n","Epoch 00105: val_accuracy did not improve from 0.91133\n","Epoch 106/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0298 - accuracy: 0.9884 - val_loss: 0.4035 - val_accuracy: 0.8990\n","\n","Epoch 00106: val_accuracy did not improve from 0.91133\n","Epoch 107/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.5034 - val_accuracy: 0.9089\n","\n","Epoch 00107: val_accuracy did not improve from 0.91133\n","Epoch 108/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0215 - accuracy: 0.9909 - val_loss: 0.5521 - val_accuracy: 0.8818\n","\n","Epoch 00108: val_accuracy did not improve from 0.91133\n","Epoch 109/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.4399 - val_accuracy: 0.9089\n","\n","Epoch 00109: val_accuracy did not improve from 0.91133\n","Epoch 110/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 0.4822 - val_accuracy: 0.8867\n","\n","Epoch 00110: val_accuracy did not improve from 0.91133\n","Epoch 111/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0221 - accuracy: 0.9915 - val_loss: 0.5148 - val_accuracy: 0.8842\n","\n","Epoch 00111: val_accuracy did not improve from 0.91133\n","Epoch 112/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.5529 - val_accuracy: 0.8842\n","\n","Epoch 00112: val_accuracy did not improve from 0.91133\n","Epoch 113/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1490 - accuracy: 0.9562 - val_loss: 2.6531 - val_accuracy: 0.6700\n","\n","Epoch 00113: val_accuracy did not improve from 0.91133\n","Epoch 114/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0960 - accuracy: 0.9695 - val_loss: 0.6301 - val_accuracy: 0.8695\n","\n","Epoch 00114: val_accuracy did not improve from 0.91133\n","Epoch 115/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0408 - accuracy: 0.9878 - val_loss: 0.6406 - val_accuracy: 0.8768\n","\n","Epoch 00115: val_accuracy did not improve from 0.91133\n","Epoch 116/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0253 - accuracy: 0.9903 - val_loss: 0.5073 - val_accuracy: 0.8916\n","\n","Epoch 00116: val_accuracy did not improve from 0.91133\n","Epoch 117/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0369 - accuracy: 0.9854 - val_loss: 0.5803 - val_accuracy: 0.8670\n","\n","Epoch 00117: val_accuracy did not improve from 0.91133\n","Epoch 118/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 0.4465 - val_accuracy: 0.8966\n","\n","Epoch 00118: val_accuracy did not improve from 0.91133\n","Epoch 119/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.4329 - val_accuracy: 0.9064\n","\n","Epoch 00119: val_accuracy did not improve from 0.91133\n","Epoch 120/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 0.7533 - val_accuracy: 0.8473\n","\n","Epoch 00120: val_accuracy did not improve from 0.91133\n","Epoch 121/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0552 - accuracy: 0.9872 - val_loss: 0.9099 - val_accuracy: 0.8128\n","\n","Epoch 00121: val_accuracy did not improve from 0.91133\n","Epoch 122/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.5214 - val_accuracy: 0.8867\n","\n","Epoch 00122: val_accuracy did not improve from 0.91133\n","Epoch 123/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.8962 - val_accuracy: 0.8227\n","\n","Epoch 00123: val_accuracy did not improve from 0.91133\n","Epoch 124/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.8152 - val_accuracy: 0.8251\n","\n","Epoch 00124: val_accuracy did not improve from 0.91133\n","Epoch 125/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0344 - accuracy: 0.9878 - val_loss: 0.9821 - val_accuracy: 0.7980\n","\n","Epoch 00125: val_accuracy did not improve from 0.91133\n","Epoch 126/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0216 - accuracy: 0.9909 - val_loss: 0.5173 - val_accuracy: 0.8941\n","\n","Epoch 00126: val_accuracy did not improve from 0.91133\n","Epoch 127/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0107 - accuracy: 0.9988 - val_loss: 0.4425 - val_accuracy: 0.9113\n","\n","Epoch 00127: val_accuracy did not improve from 0.91133\n","Epoch 128/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.5839 - val_accuracy: 0.8621\n","\n","Epoch 00128: val_accuracy did not improve from 0.91133\n","Epoch 129/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.5270 - val_accuracy: 0.8941\n","\n","Epoch 00129: val_accuracy did not improve from 0.91133\n","Epoch 130/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 0.5983 - val_accuracy: 0.8695\n","\n","Epoch 00130: val_accuracy did not improve from 0.91133\n","Epoch 131/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.4741 - val_accuracy: 0.8990\n","\n","Epoch 00131: val_accuracy did not improve from 0.91133\n","Epoch 132/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.6052 - val_accuracy: 0.8867\n","\n","Epoch 00132: val_accuracy did not improve from 0.91133\n","Epoch 133/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0279 - accuracy: 0.9933 - val_loss: 0.6970 - val_accuracy: 0.8670\n","\n","Epoch 00133: val_accuracy did not improve from 0.91133\n","Epoch 134/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1908 - accuracy: 0.9409 - val_loss: 3.2398 - val_accuracy: 0.5394\n","\n","Epoch 00134: val_accuracy did not improve from 0.91133\n","Epoch 135/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1380 - accuracy: 0.9574 - val_loss: 0.6765 - val_accuracy: 0.8695\n","\n","Epoch 00135: val_accuracy did not improve from 0.91133\n","Epoch 136/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 1.6488 - val_accuracy: 0.6921\n","\n","Epoch 00136: val_accuracy did not improve from 0.91133\n","Epoch 137/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0423 - accuracy: 0.9860 - val_loss: 0.5282 - val_accuracy: 0.8670\n","\n","Epoch 00137: val_accuracy did not improve from 0.91133\n","Epoch 138/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.4205 - val_accuracy: 0.9089\n","\n","Epoch 00138: val_accuracy did not improve from 0.91133\n","Epoch 139/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4467 - val_accuracy: 0.9089\n","\n","Epoch 00139: val_accuracy did not improve from 0.91133\n","Epoch 140/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0221 - accuracy: 0.9915 - val_loss: 0.7268 - val_accuracy: 0.8350\n","\n","Epoch 00140: val_accuracy did not improve from 0.91133\n","Epoch 141/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0235 - accuracy: 0.9909 - val_loss: 0.7306 - val_accuracy: 0.8547\n","\n","Epoch 00141: val_accuracy did not improve from 0.91133\n","Epoch 142/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0320 - accuracy: 0.9921 - val_loss: 0.6595 - val_accuracy: 0.8867\n","\n","Epoch 00142: val_accuracy did not improve from 0.91133\n","Epoch 143/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0588 - accuracy: 0.9823 - val_loss: 0.6076 - val_accuracy: 0.8941\n","\n","Epoch 00143: val_accuracy did not improve from 0.91133\n","Epoch 144/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.5024 - val_accuracy: 0.9064\n","\n","Epoch 00144: val_accuracy did not improve from 0.91133\n","Epoch 145/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0168 - accuracy: 0.9933 - val_loss: 0.5140 - val_accuracy: 0.8916\n","\n","Epoch 00145: val_accuracy did not improve from 0.91133\n","Epoch 146/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.6247 - val_accuracy: 0.8818\n","\n","Epoch 00146: val_accuracy did not improve from 0.91133\n","Epoch 147/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0159 - accuracy: 0.9970 - val_loss: 0.5320 - val_accuracy: 0.9039\n","\n","Epoch 00147: val_accuracy did not improve from 0.91133\n","Epoch 148/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0296 - accuracy: 0.9884 - val_loss: 0.7795 - val_accuracy: 0.8473\n","\n","Epoch 00148: val_accuracy did not improve from 0.91133\n","Epoch 149/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 0.4646 - val_accuracy: 0.8941\n","\n","Epoch 00149: val_accuracy did not improve from 0.91133\n","Epoch 150/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0163 - accuracy: 0.9933 - val_loss: 0.6788 - val_accuracy: 0.8448\n","\n","Epoch 00150: val_accuracy did not improve from 0.91133\n","Epoch 151/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.6362 - val_accuracy: 0.8842\n","\n","Epoch 00151: val_accuracy did not improve from 0.91133\n","Epoch 152/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0905 - accuracy: 0.9720 - val_loss: 0.8930 - val_accuracy: 0.8300\n","\n","Epoch 00152: val_accuracy did not improve from 0.91133\n","Epoch 153/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1419 - accuracy: 0.9562 - val_loss: 0.7992 - val_accuracy: 0.8227\n","\n","Epoch 00153: val_accuracy did not improve from 0.91133\n","Epoch 154/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0417 - accuracy: 0.9866 - val_loss: 0.5498 - val_accuracy: 0.8966\n","\n","Epoch 00154: val_accuracy did not improve from 0.91133\n","Epoch 155/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0256 - accuracy: 0.9927 - val_loss: 0.5028 - val_accuracy: 0.8842\n","\n","Epoch 00155: val_accuracy did not improve from 0.91133\n","Epoch 156/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.3998 - val_accuracy: 0.9089\n","\n","Epoch 00156: val_accuracy did not improve from 0.91133\n","Epoch 157/500\n","52/52 [==============================] - 12s 237ms/step - loss: 0.0174 - accuracy: 0.9963 - val_loss: 0.4342 - val_accuracy: 0.9015\n","\n","Epoch 00157: val_accuracy did not improve from 0.91133\n","Epoch 158/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.4538 - val_accuracy: 0.9015\n","\n","Epoch 00158: val_accuracy did not improve from 0.91133\n","Epoch 159/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0111 - accuracy: 0.9951 - val_loss: 0.4769 - val_accuracy: 0.8842\n","\n","Epoch 00159: val_accuracy did not improve from 0.91133\n","Epoch 160/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.4195 - val_accuracy: 0.9163\n","\n","Epoch 00160: val_accuracy improved from 0.91133 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 161/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.5601 - val_accuracy: 0.8744\n","\n","Epoch 00161: val_accuracy did not improve from 0.91626\n","Epoch 162/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4209 - val_accuracy: 0.9163\n","\n","Epoch 00162: val_accuracy did not improve from 0.91626\n","Epoch 163/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4044 - val_accuracy: 0.9138\n","\n","Epoch 00163: val_accuracy did not improve from 0.91626\n","Epoch 164/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.9039\n","\n","Epoch 00164: val_accuracy did not improve from 0.91626\n","Epoch 165/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.4836 - val_accuracy: 0.9039\n","\n","Epoch 00165: val_accuracy did not improve from 0.91626\n","Epoch 166/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.6282 - val_accuracy: 0.8818\n","\n","Epoch 00166: val_accuracy did not improve from 0.91626\n","Epoch 167/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0264 - accuracy: 0.9909 - val_loss: 0.5287 - val_accuracy: 0.8818\n","\n","Epoch 00167: val_accuracy did not improve from 0.91626\n","Epoch 168/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0273 - accuracy: 0.9939 - val_loss: 0.7050 - val_accuracy: 0.8571\n","\n","Epoch 00168: val_accuracy did not improve from 0.91626\n","Epoch 169/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5044 - val_accuracy: 0.9015\n","\n","Epoch 00169: val_accuracy did not improve from 0.91626\n","Epoch 170/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.5645 - val_accuracy: 0.8818\n","\n","Epoch 00170: val_accuracy did not improve from 0.91626\n","Epoch 171/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0471 - accuracy: 0.9829 - val_loss: 0.8545 - val_accuracy: 0.8325\n","\n","Epoch 00171: val_accuracy did not improve from 0.91626\n","Epoch 172/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0705 - accuracy: 0.9769 - val_loss: 0.8365 - val_accuracy: 0.8596\n","\n","Epoch 00172: val_accuracy did not improve from 0.91626\n","Epoch 173/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0550 - accuracy: 0.9787 - val_loss: 0.7661 - val_accuracy: 0.8596\n","\n","Epoch 00173: val_accuracy did not improve from 0.91626\n","Epoch 174/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.6441 - val_accuracy: 0.8892\n","\n","Epoch 00174: val_accuracy did not improve from 0.91626\n","Epoch 175/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0364 - accuracy: 0.9878 - val_loss: 0.6174 - val_accuracy: 0.8916\n","\n","Epoch 00175: val_accuracy did not improve from 0.91626\n","Epoch 176/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0803 - accuracy: 0.9726 - val_loss: 0.8741 - val_accuracy: 0.8300\n","\n","Epoch 00176: val_accuracy did not improve from 0.91626\n","Epoch 177/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0427 - accuracy: 0.9860 - val_loss: 0.5235 - val_accuracy: 0.8966\n","\n","Epoch 00177: val_accuracy did not improve from 0.91626\n","Epoch 178/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0489 - accuracy: 0.9854 - val_loss: 0.5703 - val_accuracy: 0.8768\n","\n","Epoch 00178: val_accuracy did not improve from 0.91626\n","Epoch 179/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 0.5256 - val_accuracy: 0.8892\n","\n","Epoch 00179: val_accuracy did not improve from 0.91626\n","Epoch 180/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0419 - accuracy: 0.9860 - val_loss: 0.5633 - val_accuracy: 0.8695\n","\n","Epoch 00180: val_accuracy did not improve from 0.91626\n","Epoch 181/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0330 - accuracy: 0.9878 - val_loss: 0.6090 - val_accuracy: 0.8793\n","\n","Epoch 00181: val_accuracy did not improve from 0.91626\n","Epoch 182/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.6242 - val_accuracy: 0.8719\n","\n","Epoch 00182: val_accuracy did not improve from 0.91626\n","Epoch 183/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0134 - accuracy: 0.9927 - val_loss: 0.7583 - val_accuracy: 0.8842\n","\n","Epoch 00183: val_accuracy did not improve from 0.91626\n","Epoch 184/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 0.5507 - val_accuracy: 0.8744\n","\n","Epoch 00184: val_accuracy did not improve from 0.91626\n","Epoch 185/500\n","52/52 [==============================] - 11s 222ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.5108 - val_accuracy: 0.8966\n","\n","Epoch 00185: val_accuracy did not improve from 0.91626\n","Epoch 186/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.8916\n","\n","Epoch 00186: val_accuracy did not improve from 0.91626\n","Epoch 187/500\n","52/52 [==============================] - 11s 222ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.4187 - val_accuracy: 0.9039\n","\n","Epoch 00187: val_accuracy did not improve from 0.91626\n","Epoch 188/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4701 - val_accuracy: 0.9113\n","\n","Epoch 00188: val_accuracy did not improve from 0.91626\n","Epoch 189/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.9113\n","\n","Epoch 00189: val_accuracy did not improve from 0.91626\n","Epoch 190/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9113\n","\n","Epoch 00190: val_accuracy did not improve from 0.91626\n","Epoch 191/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.6179 - val_accuracy: 0.8867\n","\n","Epoch 00191: val_accuracy did not improve from 0.91626\n","Epoch 192/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.5384 - val_accuracy: 0.8941\n","\n","Epoch 00192: val_accuracy did not improve from 0.91626\n","Epoch 193/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.4587 - val_accuracy: 0.9187\n","\n","Epoch 00193: val_accuracy improved from 0.91626 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 194/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0205 - accuracy: 0.9915 - val_loss: 0.9605 - val_accuracy: 0.8325\n","\n","Epoch 00194: val_accuracy did not improve from 0.91872\n","Epoch 195/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0470 - accuracy: 0.9842 - val_loss: 0.6379 - val_accuracy: 0.8990\n","\n","Epoch 00195: val_accuracy did not improve from 0.91872\n","Epoch 196/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0391 - accuracy: 0.9896 - val_loss: 0.5583 - val_accuracy: 0.9015\n","\n","Epoch 00196: val_accuracy did not improve from 0.91872\n","Epoch 197/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.5910 - val_accuracy: 0.9015\n","\n","Epoch 00197: val_accuracy did not improve from 0.91872\n","Epoch 198/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.6193 - val_accuracy: 0.8990\n","\n","Epoch 00198: val_accuracy did not improve from 0.91872\n","Epoch 199/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0701 - accuracy: 0.9817 - val_loss: 1.9304 - val_accuracy: 0.6675\n","\n","Epoch 00199: val_accuracy did not improve from 0.91872\n","Epoch 200/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0372 - accuracy: 0.9866 - val_loss: 0.6495 - val_accuracy: 0.8892\n","\n","Epoch 00200: val_accuracy did not improve from 0.91872\n","Epoch 201/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0653 - accuracy: 0.9787 - val_loss: 0.6874 - val_accuracy: 0.8719\n","\n","Epoch 00201: val_accuracy did not improve from 0.91872\n","Epoch 202/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.5510 - val_accuracy: 0.8892\n","\n","Epoch 00202: val_accuracy did not improve from 0.91872\n","Epoch 203/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.4355 - val_accuracy: 0.9113\n","\n","Epoch 00203: val_accuracy did not improve from 0.91872\n","Epoch 204/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.5297 - val_accuracy: 0.9015\n","\n","Epoch 00204: val_accuracy did not improve from 0.91872\n","Epoch 205/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.5631 - val_accuracy: 0.8867\n","\n","Epoch 00205: val_accuracy did not improve from 0.91872\n","Epoch 206/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.9138\n","\n","Epoch 00206: val_accuracy did not improve from 0.91872\n","Epoch 207/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 0.4892 - val_accuracy: 0.9089\n","\n","Epoch 00207: val_accuracy did not improve from 0.91872\n","Epoch 208/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.5611 - val_accuracy: 0.8818\n","\n","Epoch 00208: val_accuracy did not improve from 0.91872\n","Epoch 209/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.5287 - val_accuracy: 0.9039\n","\n","Epoch 00209: val_accuracy did not improve from 0.91872\n","Epoch 210/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 1.4395 - val_accuracy: 0.7217\n","\n","Epoch 00210: val_accuracy did not improve from 0.91872\n","Epoch 211/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0287 - accuracy: 0.9884 - val_loss: 0.9169 - val_accuracy: 0.8350\n","\n","Epoch 00211: val_accuracy did not improve from 0.91872\n","Epoch 212/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0175 - accuracy: 0.9921 - val_loss: 1.0157 - val_accuracy: 0.7931\n","\n","Epoch 00212: val_accuracy did not improve from 0.91872\n","Epoch 213/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 2.8308 - val_accuracy: 0.6749\n","\n","Epoch 00213: val_accuracy did not improve from 0.91872\n","Epoch 214/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0954 - accuracy: 0.9695 - val_loss: 0.8956 - val_accuracy: 0.8621\n","\n","Epoch 00214: val_accuracy did not improve from 0.91872\n","Epoch 215/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 0.7406 - val_accuracy: 0.8645\n","\n","Epoch 00215: val_accuracy did not improve from 0.91872\n","Epoch 216/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0284 - accuracy: 0.9915 - val_loss: 0.5048 - val_accuracy: 0.9187\n","\n","Epoch 00216: val_accuracy did not improve from 0.91872\n","Epoch 217/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0358 - accuracy: 0.9890 - val_loss: 0.6323 - val_accuracy: 0.8867\n","\n","Epoch 00217: val_accuracy did not improve from 0.91872\n","Epoch 218/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0590 - accuracy: 0.9829 - val_loss: 0.9210 - val_accuracy: 0.8522\n","\n","Epoch 00218: val_accuracy did not improve from 0.91872\n","Epoch 219/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0958 - accuracy: 0.9738 - val_loss: 0.8411 - val_accuracy: 0.8424\n","\n","Epoch 00219: val_accuracy did not improve from 0.91872\n","Epoch 220/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.5558 - val_accuracy: 0.8941\n","\n","Epoch 00220: val_accuracy did not improve from 0.91872\n","Epoch 221/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.5764 - val_accuracy: 0.8842\n","\n","Epoch 00221: val_accuracy did not improve from 0.91872\n","Epoch 222/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.4679 - val_accuracy: 0.9163\n","\n","Epoch 00222: val_accuracy did not improve from 0.91872\n","Epoch 223/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.5088 - val_accuracy: 0.8818\n","\n","Epoch 00223: val_accuracy did not improve from 0.91872\n","Epoch 224/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5366 - val_accuracy: 0.9015\n","\n","Epoch 00224: val_accuracy did not improve from 0.91872\n","Epoch 225/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.6776 - val_accuracy: 0.8768\n","\n","Epoch 00225: val_accuracy did not improve from 0.91872\n","Epoch 226/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.5306 - val_accuracy: 0.8818\n","\n","Epoch 00226: val_accuracy did not improve from 0.91872\n","Epoch 227/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.5401 - val_accuracy: 0.8842\n","\n","Epoch 00227: val_accuracy did not improve from 0.91872\n","Epoch 228/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.6677 - val_accuracy: 0.8621\n","\n","Epoch 00228: val_accuracy did not improve from 0.91872\n","Epoch 229/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.5819 - val_accuracy: 0.9039\n","\n","Epoch 00229: val_accuracy did not improve from 0.91872\n","Epoch 230/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4972 - val_accuracy: 0.9064\n","\n","Epoch 00230: val_accuracy did not improve from 0.91872\n","Epoch 231/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6969 - val_accuracy: 0.8744\n","\n","Epoch 00231: val_accuracy did not improve from 0.91872\n","Epoch 232/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 0.9803 - val_accuracy: 0.8103\n","\n","Epoch 00232: val_accuracy did not improve from 0.91872\n","Epoch 233/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0255 - accuracy: 0.9896 - val_loss: 0.6447 - val_accuracy: 0.8793\n","\n","Epoch 00233: val_accuracy did not improve from 0.91872\n","Epoch 234/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0440 - accuracy: 0.9848 - val_loss: 0.6575 - val_accuracy: 0.8892\n","\n","Epoch 00234: val_accuracy did not improve from 0.91872\n","Epoch 235/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.6081 - val_accuracy: 0.8768\n","\n","Epoch 00235: val_accuracy did not improve from 0.91872\n","Epoch 236/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0167 - accuracy: 0.9921 - val_loss: 0.6028 - val_accuracy: 0.8793\n","\n","Epoch 00236: val_accuracy did not improve from 0.91872\n","Epoch 237/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0192 - accuracy: 0.9957 - val_loss: 0.5958 - val_accuracy: 0.8966\n","\n","Epoch 00237: val_accuracy did not improve from 0.91872\n","Epoch 238/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0333 - accuracy: 0.9903 - val_loss: 0.7039 - val_accuracy: 0.8719\n","\n","Epoch 00238: val_accuracy did not improve from 0.91872\n","Epoch 239/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.6821 - val_accuracy: 0.8719\n","\n","Epoch 00239: val_accuracy did not improve from 0.91872\n","Epoch 240/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 2.4364 - val_accuracy: 0.6527\n","\n","Epoch 00240: val_accuracy did not improve from 0.91872\n","Epoch 241/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0914 - accuracy: 0.9689 - val_loss: 1.5525 - val_accuracy: 0.7020\n","\n","Epoch 00241: val_accuracy did not improve from 0.91872\n","Epoch 242/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0370 - accuracy: 0.9890 - val_loss: 0.7444 - val_accuracy: 0.8473\n","\n","Epoch 00242: val_accuracy did not improve from 0.91872\n","Epoch 243/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.4420 - val_accuracy: 0.8892\n","\n","Epoch 00243: val_accuracy did not improve from 0.91872\n","Epoch 244/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.4799 - val_accuracy: 0.9163\n","\n","Epoch 00244: val_accuracy did not improve from 0.91872\n","Epoch 245/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.5108 - val_accuracy: 0.8916\n","\n","Epoch 00245: val_accuracy did not improve from 0.91872\n","Epoch 246/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.4989 - val_accuracy: 0.9163\n","\n","Epoch 00246: val_accuracy did not improve from 0.91872\n","Epoch 247/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.3644 - val_accuracy: 0.9163\n","\n","Epoch 00247: val_accuracy did not improve from 0.91872\n","Epoch 248/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.5288 - val_accuracy: 0.8867\n","\n","Epoch 00248: val_accuracy did not improve from 0.91872\n","Epoch 249/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.4221 - val_accuracy: 0.9286\n","\n","Epoch 00249: val_accuracy improved from 0.91872 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 250/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.4948 - val_accuracy: 0.9039\n","\n","Epoch 00250: val_accuracy did not improve from 0.92857\n","Epoch 251/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.4192 - val_accuracy: 0.8941\n","\n","Epoch 00251: val_accuracy did not improve from 0.92857\n","Epoch 252/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0163 - accuracy: 0.9963 - val_loss: 0.5407 - val_accuracy: 0.9089\n","\n","Epoch 00252: val_accuracy did not improve from 0.92857\n","Epoch 253/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.4671 - val_accuracy: 0.9113\n","\n","Epoch 00253: val_accuracy did not improve from 0.92857\n","Epoch 254/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9138\n","\n","Epoch 00254: val_accuracy did not improve from 0.92857\n","Epoch 255/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9138\n","\n","Epoch 00255: val_accuracy did not improve from 0.92857\n","Epoch 256/500\n","52/52 [==============================] - 11s 217ms/step - loss: 6.7385e-04 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.9261\n","\n","Epoch 00256: val_accuracy did not improve from 0.92857\n","Epoch 257/500\n","52/52 [==============================] - 11s 218ms/step - loss: 5.2933e-04 - accuracy: 1.0000 - val_loss: 0.4143 - val_accuracy: 0.9261\n","\n","Epoch 00257: val_accuracy did not improve from 0.92857\n","Epoch 258/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.9089\n","\n","Epoch 00258: val_accuracy did not improve from 0.92857\n","Epoch 259/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5005 - val_accuracy: 0.9163\n","\n","Epoch 00259: val_accuracy did not improve from 0.92857\n","Epoch 260/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.6824 - val_accuracy: 0.8473\n","\n","Epoch 00260: val_accuracy did not improve from 0.92857\n","Epoch 261/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0250 - accuracy: 0.9939 - val_loss: 0.6984 - val_accuracy: 0.8892\n","\n","Epoch 00261: val_accuracy did not improve from 0.92857\n","Epoch 262/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0316 - accuracy: 0.9884 - val_loss: 2.6136 - val_accuracy: 0.6281\n","\n","Epoch 00262: val_accuracy did not improve from 0.92857\n","Epoch 263/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0456 - accuracy: 0.9842 - val_loss: 0.9345 - val_accuracy: 0.8424\n","\n","Epoch 00263: val_accuracy did not improve from 0.92857\n","Epoch 264/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0442 - accuracy: 0.9848 - val_loss: 1.1060 - val_accuracy: 0.8079\n","\n","Epoch 00264: val_accuracy did not improve from 0.92857\n","Epoch 265/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0398 - accuracy: 0.9860 - val_loss: 0.5890 - val_accuracy: 0.8916\n","\n","Epoch 00265: val_accuracy did not improve from 0.92857\n","Epoch 266/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 0.4604 - val_accuracy: 0.9236\n","\n","Epoch 00266: val_accuracy did not improve from 0.92857\n","Epoch 267/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.7318 - val_accuracy: 0.8744\n","\n","Epoch 00267: val_accuracy did not improve from 0.92857\n","Epoch 268/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0334 - accuracy: 0.9921 - val_loss: 0.8789 - val_accuracy: 0.8202\n","\n","Epoch 00268: val_accuracy did not improve from 0.92857\n","Epoch 269/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.6495 - val_accuracy: 0.8621\n","\n","Epoch 00269: val_accuracy did not improve from 0.92857\n","Epoch 270/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.5439 - val_accuracy: 0.9064\n","\n","Epoch 00270: val_accuracy did not improve from 0.92857\n","Epoch 271/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.4327 - val_accuracy: 0.9163\n","\n","Epoch 00271: val_accuracy did not improve from 0.92857\n","Epoch 272/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.4543 - val_accuracy: 0.9187\n","\n","Epoch 00272: val_accuracy did not improve from 0.92857\n","Epoch 273/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3911 - val_accuracy: 0.9261\n","\n","Epoch 00273: val_accuracy did not improve from 0.92857\n","Epoch 274/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.9187\n","\n","Epoch 00274: val_accuracy did not improve from 0.92857\n","Epoch 275/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5070 - val_accuracy: 0.8818\n","\n","Epoch 00275: val_accuracy did not improve from 0.92857\n","Epoch 276/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5327 - val_accuracy: 0.8990\n","\n","Epoch 00276: val_accuracy did not improve from 0.92857\n","Epoch 277/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.3662 - val_accuracy: 0.9138\n","\n","Epoch 00277: val_accuracy did not improve from 0.92857\n","Epoch 278/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.4735 - val_accuracy: 0.8966\n","\n","Epoch 00278: val_accuracy did not improve from 0.92857\n","Epoch 279/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.4541 - val_accuracy: 0.9163\n","\n","Epoch 00279: val_accuracy did not improve from 0.92857\n","Epoch 280/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.5952 - val_accuracy: 0.8892\n","\n","Epoch 00280: val_accuracy did not improve from 0.92857\n","Epoch 281/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0054 - accuracy: 0.9963 - val_loss: 0.5759 - val_accuracy: 0.8941\n","\n","Epoch 00281: val_accuracy did not improve from 0.92857\n","Epoch 282/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.9310\n","\n","Epoch 00282: val_accuracy improved from 0.92857 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 283/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4402 - val_accuracy: 0.9212\n","\n","Epoch 00283: val_accuracy did not improve from 0.93103\n","Epoch 284/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4624 - val_accuracy: 0.9113\n","\n","Epoch 00284: val_accuracy did not improve from 0.93103\n","Epoch 285/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.9113\n","\n","Epoch 00285: val_accuracy did not improve from 0.93103\n","Epoch 286/500\n","52/52 [==============================] - 11s 218ms/step - loss: 8.1750e-04 - accuracy: 1.0000 - val_loss: 0.3796 - val_accuracy: 0.9335\n","\n","Epoch 00286: val_accuracy improved from 0.93103 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 287/500\n","52/52 [==============================] - 11s 217ms/step - loss: 9.7512e-04 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9138\n","\n","Epoch 00287: val_accuracy did not improve from 0.93350\n","Epoch 288/500\n","52/52 [==============================] - 11s 218ms/step - loss: 7.4758e-04 - accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.9212\n","\n","Epoch 00288: val_accuracy did not improve from 0.93350\n","Epoch 289/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4529 - val_accuracy: 0.9015\n","\n","Epoch 00289: val_accuracy did not improve from 0.93350\n","Epoch 290/500\n","52/52 [==============================] - 11s 219ms/step - loss: 6.2807e-04 - accuracy: 1.0000 - val_loss: 0.3994 - val_accuracy: 0.9286\n","\n","Epoch 00290: val_accuracy did not improve from 0.93350\n","Epoch 291/500\n","52/52 [==============================] - 11s 219ms/step - loss: 3.7472e-04 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.9335\n","\n","Epoch 00291: val_accuracy did not improve from 0.93350\n","Epoch 292/500\n","52/52 [==============================] - 11s 217ms/step - loss: 3.7599e-04 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.9187\n","\n","Epoch 00292: val_accuracy did not improve from 0.93350\n","Epoch 293/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6305 - val_accuracy: 0.8793\n","\n","Epoch 00293: val_accuracy did not improve from 0.93350\n","Epoch 294/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0150 - accuracy: 0.9976 - val_loss: 0.6968 - val_accuracy: 0.8571\n","\n","Epoch 00294: val_accuracy did not improve from 0.93350\n","Epoch 295/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.5999 - val_accuracy: 0.8719\n","\n","Epoch 00295: val_accuracy did not improve from 0.93350\n","Epoch 296/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.6360 - val_accuracy: 0.8941\n","\n","Epoch 00296: val_accuracy did not improve from 0.93350\n","Epoch 297/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.6507 - val_accuracy: 0.9039\n","\n","Epoch 00297: val_accuracy did not improve from 0.93350\n","Epoch 298/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0326 - accuracy: 0.9884 - val_loss: 1.1312 - val_accuracy: 0.8325\n","\n","Epoch 00298: val_accuracy did not improve from 0.93350\n","Epoch 299/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0523 - accuracy: 0.9829 - val_loss: 1.3730 - val_accuracy: 0.8153\n","\n","Epoch 00299: val_accuracy did not improve from 0.93350\n","Epoch 300/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0932 - accuracy: 0.9726 - val_loss: 0.9722 - val_accuracy: 0.8448\n","\n","Epoch 00300: val_accuracy did not improve from 0.93350\n","Epoch 301/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0434 - accuracy: 0.9860 - val_loss: 0.7501 - val_accuracy: 0.8695\n","\n","Epoch 00301: val_accuracy did not improve from 0.93350\n","Epoch 302/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.6362 - val_accuracy: 0.8842\n","\n","Epoch 00302: val_accuracy did not improve from 0.93350\n","Epoch 303/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.8416 - val_accuracy: 0.8571\n","\n","Epoch 00303: val_accuracy did not improve from 0.93350\n","Epoch 304/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0385 - accuracy: 0.9884 - val_loss: 4.4739 - val_accuracy: 0.4975\n","\n","Epoch 00304: val_accuracy did not improve from 0.93350\n","Epoch 305/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0357 - accuracy: 0.9896 - val_loss: 0.6678 - val_accuracy: 0.8892\n","\n","Epoch 00305: val_accuracy did not improve from 0.93350\n","Epoch 306/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9236\n","\n","Epoch 00306: val_accuracy did not improve from 0.93350\n","Epoch 307/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9089\n","\n","Epoch 00307: val_accuracy did not improve from 0.93350\n","Epoch 308/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4695 - val_accuracy: 0.9089\n","\n","Epoch 00308: val_accuracy did not improve from 0.93350\n","Epoch 309/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.4852 - val_accuracy: 0.8867\n","\n","Epoch 00309: val_accuracy did not improve from 0.93350\n","Epoch 310/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.5617 - val_accuracy: 0.8892\n","\n","Epoch 00310: val_accuracy did not improve from 0.93350\n","Epoch 311/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5111 - val_accuracy: 0.9064\n","\n","Epoch 00311: val_accuracy did not improve from 0.93350\n","Epoch 312/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.7566 - val_accuracy: 0.8744\n","\n","Epoch 00312: val_accuracy did not improve from 0.93350\n","Epoch 313/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5713 - val_accuracy: 0.8941\n","\n","Epoch 00313: val_accuracy did not improve from 0.93350\n","Epoch 314/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.9138\n","\n","Epoch 00314: val_accuracy did not improve from 0.93350\n","Epoch 315/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3871 - val_accuracy: 0.9236\n","\n","Epoch 00315: val_accuracy did not improve from 0.93350\n","Epoch 316/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.5758 - val_accuracy: 0.9039\n","\n","Epoch 00316: val_accuracy did not improve from 0.93350\n","Epoch 317/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.5316 - val_accuracy: 0.8941\n","\n","Epoch 00317: val_accuracy did not improve from 0.93350\n","Epoch 318/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.6567 - val_accuracy: 0.8695\n","\n","Epoch 00318: val_accuracy did not improve from 0.93350\n","Epoch 319/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.6496 - val_accuracy: 0.8448\n","\n","Epoch 00319: val_accuracy did not improve from 0.93350\n","Epoch 320/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.5841 - val_accuracy: 0.8966\n","\n","Epoch 00320: val_accuracy did not improve from 0.93350\n","Epoch 321/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.5281 - val_accuracy: 0.9064\n","\n","Epoch 00321: val_accuracy did not improve from 0.93350\n","Epoch 322/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5161 - val_accuracy: 0.8966\n","\n","Epoch 00322: val_accuracy did not improve from 0.93350\n","Epoch 323/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5403 - val_accuracy: 0.9015\n","\n","Epoch 00323: val_accuracy did not improve from 0.93350\n","Epoch 324/500\n","52/52 [==============================] - 11s 218ms/step - loss: 7.8131e-04 - accuracy: 1.0000 - val_loss: 0.5351 - val_accuracy: 0.8990\n","\n","Epoch 00324: val_accuracy did not improve from 0.93350\n","Epoch 325/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.5936 - val_accuracy: 0.9015\n","\n","Epoch 00325: val_accuracy did not improve from 0.93350\n","Epoch 326/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.6794 - val_accuracy: 0.8719\n","\n","Epoch 00326: val_accuracy did not improve from 0.93350\n","Epoch 327/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 1.8878 - val_accuracy: 0.6749\n","\n","Epoch 00327: val_accuracy did not improve from 0.93350\n","Epoch 328/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0160 - accuracy: 0.9933 - val_loss: 0.6400 - val_accuracy: 0.8768\n","\n","Epoch 00328: val_accuracy did not improve from 0.93350\n","Epoch 329/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.5254 - val_accuracy: 0.9187\n","\n","Epoch 00329: val_accuracy did not improve from 0.93350\n","Epoch 330/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0362 - accuracy: 0.9915 - val_loss: 0.7120 - val_accuracy: 0.8842\n","\n","Epoch 00330: val_accuracy did not improve from 0.93350\n","Epoch 331/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0252 - accuracy: 0.9896 - val_loss: 0.6769 - val_accuracy: 0.8818\n","\n","Epoch 00331: val_accuracy did not improve from 0.93350\n","Epoch 332/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 0.9104 - val_accuracy: 0.8596\n","\n","Epoch 00332: val_accuracy did not improve from 0.93350\n","Epoch 333/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0420 - accuracy: 0.9896 - val_loss: 0.7964 - val_accuracy: 0.8621\n","\n","Epoch 00333: val_accuracy did not improve from 0.93350\n","Epoch 334/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0552 - accuracy: 0.9829 - val_loss: 1.0121 - val_accuracy: 0.7734\n","\n","Epoch 00334: val_accuracy did not improve from 0.93350\n","Epoch 335/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.8143 - val_accuracy: 0.8645\n","\n","Epoch 00335: val_accuracy did not improve from 0.93350\n","Epoch 336/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0230 - accuracy: 0.9915 - val_loss: 0.6192 - val_accuracy: 0.8966\n","\n","Epoch 00336: val_accuracy did not improve from 0.93350\n","Epoch 337/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.5222 - val_accuracy: 0.9015\n","\n","Epoch 00337: val_accuracy did not improve from 0.93350\n","Epoch 338/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.5328 - val_accuracy: 0.9015\n","\n","Epoch 00338: val_accuracy did not improve from 0.93350\n","Epoch 339/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9064\n","\n","Epoch 00339: val_accuracy did not improve from 0.93350\n","Epoch 340/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.9138\n","\n","Epoch 00340: val_accuracy did not improve from 0.93350\n","Epoch 341/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5736 - val_accuracy: 0.9015\n","\n","Epoch 00341: val_accuracy did not improve from 0.93350\n","Epoch 342/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0098 - accuracy: 0.9988 - val_loss: 0.5190 - val_accuracy: 0.9113\n","\n","Epoch 00342: val_accuracy did not improve from 0.93350\n","Epoch 343/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5045 - val_accuracy: 0.9015\n","\n","Epoch 00343: val_accuracy did not improve from 0.93350\n","Epoch 344/500\n","52/52 [==============================] - 11s 218ms/step - loss: 9.0519e-04 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.9286\n","\n","Epoch 00344: val_accuracy did not improve from 0.93350\n","Epoch 345/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 0.4461 - val_accuracy: 0.9089\n","\n","Epoch 00345: val_accuracy did not improve from 0.93350\n","Epoch 346/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4442 - val_accuracy: 0.9187\n","\n","Epoch 00346: val_accuracy did not improve from 0.93350\n","Epoch 347/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4406 - val_accuracy: 0.9113\n","\n","Epoch 00347: val_accuracy did not improve from 0.93350\n","Epoch 348/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 1.2268 - val_accuracy: 0.7611\n","\n","Epoch 00348: val_accuracy did not improve from 0.93350\n","Epoch 349/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0512 - accuracy: 0.9842 - val_loss: 2.2534 - val_accuracy: 0.6502\n","\n","Epoch 00349: val_accuracy did not improve from 0.93350\n","Epoch 350/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.6846 - val_accuracy: 0.9039\n","\n","Epoch 00350: val_accuracy did not improve from 0.93350\n","Epoch 351/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0330 - accuracy: 0.9903 - val_loss: 0.7252 - val_accuracy: 0.8744\n","\n","Epoch 00351: val_accuracy did not improve from 0.93350\n","Epoch 352/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0254 - accuracy: 0.9896 - val_loss: 0.7669 - val_accuracy: 0.8670\n","\n","Epoch 00352: val_accuracy did not improve from 0.93350\n","Epoch 353/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.5044 - val_accuracy: 0.8990\n","\n","Epoch 00353: val_accuracy did not improve from 0.93350\n","Epoch 354/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.5337 - val_accuracy: 0.8842\n","\n","Epoch 00354: val_accuracy did not improve from 0.93350\n","Epoch 355/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.5630 - val_accuracy: 0.8941\n","\n","Epoch 00355: val_accuracy did not improve from 0.93350\n","Epoch 356/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.6095 - val_accuracy: 0.9089\n","\n","Epoch 00356: val_accuracy did not improve from 0.93350\n","Epoch 357/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5971 - val_accuracy: 0.8990\n","\n","Epoch 00357: val_accuracy did not improve from 0.93350\n","Epoch 358/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.5046 - val_accuracy: 0.9039\n","\n","Epoch 00358: val_accuracy did not improve from 0.93350\n","Epoch 359/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4815 - val_accuracy: 0.9039\n","\n","Epoch 00359: val_accuracy did not improve from 0.93350\n","Epoch 360/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4258 - val_accuracy: 0.9163\n","\n","Epoch 00360: val_accuracy did not improve from 0.93350\n","Epoch 361/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.4225 - val_accuracy: 0.9236\n","\n","Epoch 00361: val_accuracy did not improve from 0.93350\n","Epoch 362/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 0.5286 - val_accuracy: 0.9163\n","\n","Epoch 00362: val_accuracy did not improve from 0.93350\n","Epoch 363/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.4825 - val_accuracy: 0.9089\n","\n","Epoch 00363: val_accuracy did not improve from 0.93350\n","Epoch 364/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.5044 - val_accuracy: 0.9064\n","\n","Epoch 00364: val_accuracy did not improve from 0.93350\n","Epoch 365/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.7720 - val_accuracy: 0.8350\n","\n","Epoch 00365: val_accuracy did not improve from 0.93350\n","Epoch 366/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.4548 - val_accuracy: 0.9286\n","\n","Epoch 00366: val_accuracy did not improve from 0.93350\n","Epoch 367/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.9236\n","\n","Epoch 00367: val_accuracy did not improve from 0.93350\n","Epoch 368/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.5638 - val_accuracy: 0.8842\n","\n","Epoch 00368: val_accuracy did not improve from 0.93350\n","Epoch 369/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0154 - accuracy: 0.9976 - val_loss: 0.5493 - val_accuracy: 0.8916\n","\n","Epoch 00369: val_accuracy did not improve from 0.93350\n","Epoch 370/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.5770 - val_accuracy: 0.8867\n","\n","Epoch 00370: val_accuracy did not improve from 0.93350\n","Epoch 371/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.6131 - val_accuracy: 0.9138\n","\n","Epoch 00371: val_accuracy did not improve from 0.93350\n","Epoch 372/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 0.6537 - val_accuracy: 0.8793\n","\n","Epoch 00372: val_accuracy did not improve from 0.93350\n","Epoch 373/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0443 - accuracy: 0.9872 - val_loss: 1.6358 - val_accuracy: 0.7340\n","\n","Epoch 00373: val_accuracy did not improve from 0.93350\n","Epoch 374/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.9914 - val_accuracy: 0.8030\n","\n","Epoch 00374: val_accuracy did not improve from 0.93350\n","Epoch 375/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.7292 - val_accuracy: 0.8768\n","\n","Epoch 00375: val_accuracy did not improve from 0.93350\n","Epoch 376/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0077 - accuracy: 0.9963 - val_loss: 0.4751 - val_accuracy: 0.9113\n","\n","Epoch 00376: val_accuracy did not improve from 0.93350\n","Epoch 377/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.5258 - val_accuracy: 0.9039\n","\n","Epoch 00377: val_accuracy did not improve from 0.93350\n","Epoch 378/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5065 - val_accuracy: 0.9138\n","\n","Epoch 00378: val_accuracy did not improve from 0.93350\n","Epoch 379/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.4833 - val_accuracy: 0.9138\n","\n","Epoch 00379: val_accuracy did not improve from 0.93350\n","Epoch 380/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5730 - val_accuracy: 0.8892\n","\n","Epoch 00380: val_accuracy did not improve from 0.93350\n","Epoch 381/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0052 - accuracy: 0.9970 - val_loss: 0.6964 - val_accuracy: 0.8645\n","\n","Epoch 00381: val_accuracy did not improve from 0.93350\n","Epoch 382/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.5767 - val_accuracy: 0.8842\n","\n","Epoch 00382: val_accuracy did not improve from 0.93350\n","Epoch 383/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.5648 - val_accuracy: 0.8768\n","\n","Epoch 00383: val_accuracy did not improve from 0.93350\n","Epoch 384/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.6695 - val_accuracy: 0.8448\n","\n","Epoch 00384: val_accuracy did not improve from 0.93350\n","Epoch 385/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.5089 - val_accuracy: 0.9039\n","\n","Epoch 00385: val_accuracy did not improve from 0.93350\n","Epoch 386/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.6052 - val_accuracy: 0.9039\n","\n","Epoch 00386: val_accuracy did not improve from 0.93350\n","Epoch 387/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.6466 - val_accuracy: 0.8867\n","\n","Epoch 00387: val_accuracy did not improve from 0.93350\n","Epoch 388/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0237 - accuracy: 0.9951 - val_loss: 0.7373 - val_accuracy: 0.8990\n","\n","Epoch 00388: val_accuracy did not improve from 0.93350\n","Epoch 389/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.8007 - val_accuracy: 0.8842\n","\n","Epoch 00389: val_accuracy did not improve from 0.93350\n","Epoch 390/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.6943 - val_accuracy: 0.8941\n","\n","Epoch 00390: val_accuracy did not improve from 0.93350\n","Epoch 391/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.9015\n","\n","Epoch 00391: val_accuracy did not improve from 0.93350\n","Epoch 392/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5924 - val_accuracy: 0.9089\n","\n","Epoch 00392: val_accuracy did not improve from 0.93350\n","Epoch 393/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5764 - val_accuracy: 0.9113\n","\n","Epoch 00393: val_accuracy did not improve from 0.93350\n","Epoch 394/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5854 - val_accuracy: 0.9113\n","\n","Epoch 00394: val_accuracy did not improve from 0.93350\n","Epoch 395/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5297 - val_accuracy: 0.9113\n","\n","Epoch 00395: val_accuracy did not improve from 0.93350\n","Epoch 396/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5614 - val_accuracy: 0.9039\n","\n","Epoch 00396: val_accuracy did not improve from 0.93350\n","Epoch 397/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5244 - val_accuracy: 0.9187\n","\n","Epoch 00397: val_accuracy did not improve from 0.93350\n","Epoch 398/500\n","52/52 [==============================] - 12s 222ms/step - loss: 5.3182e-04 - accuracy: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.9163\n","\n","Epoch 00398: val_accuracy did not improve from 0.93350\n","Epoch 399/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.4798e-04 - accuracy: 1.0000 - val_loss: 0.5421 - val_accuracy: 0.9089\n","\n","Epoch 00399: val_accuracy did not improve from 0.93350\n","Epoch 400/500\n","52/52 [==============================] - 11s 220ms/step - loss: 3.0629e-04 - accuracy: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.9163\n","\n","Epoch 00400: val_accuracy did not improve from 0.93350\n","Epoch 401/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.9187\n","\n","Epoch 00401: val_accuracy did not improve from 0.93350\n","Epoch 402/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.8492e-04 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.9236\n","\n","Epoch 00402: val_accuracy did not improve from 0.93350\n","Epoch 403/500\n","52/52 [==============================] - 11s 218ms/step - loss: 1.5919e-04 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.9212\n","\n","Epoch 00403: val_accuracy did not improve from 0.93350\n","Epoch 404/500\n","52/52 [==============================] - 11s 218ms/step - loss: 2.2271e-04 - accuracy: 1.0000 - val_loss: 0.5497 - val_accuracy: 0.9236\n","\n","Epoch 00404: val_accuracy did not improve from 0.93350\n","Epoch 405/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.4243e-04 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.9286\n","\n","Epoch 00405: val_accuracy did not improve from 0.93350\n","Epoch 406/500\n","52/52 [==============================] - 11s 218ms/step - loss: 2.5788e-04 - accuracy: 1.0000 - val_loss: 0.5200 - val_accuracy: 0.9187\n","\n","Epoch 00406: val_accuracy did not improve from 0.93350\n","Epoch 407/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.6493 - val_accuracy: 0.9015\n","\n","Epoch 00407: val_accuracy did not improve from 0.93350\n","Epoch 408/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.5826 - val_accuracy: 0.9187\n","\n","Epoch 00408: val_accuracy did not improve from 0.93350\n","Epoch 409/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.6050 - val_accuracy: 0.9187\n","\n","Epoch 00409: val_accuracy did not improve from 0.93350\n","Epoch 410/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.8953 - val_accuracy: 0.8818\n","\n","Epoch 00410: val_accuracy did not improve from 0.93350\n","Epoch 411/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0121 - accuracy: 0.9933 - val_loss: 1.2793 - val_accuracy: 0.7315\n","\n","Epoch 00411: val_accuracy did not improve from 0.93350\n","Epoch 412/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.7984 - val_accuracy: 0.8202\n","\n","Epoch 00412: val_accuracy did not improve from 0.93350\n","Epoch 413/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0773 - accuracy: 0.9775 - val_loss: 6.5945 - val_accuracy: 0.4212\n","\n","Epoch 00413: val_accuracy did not improve from 0.93350\n","Epoch 414/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0789 - accuracy: 0.9708 - val_loss: 2.9096 - val_accuracy: 0.5862\n","\n","Epoch 00414: val_accuracy did not improve from 0.93350\n","Epoch 415/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0769 - accuracy: 0.9762 - val_loss: 0.8236 - val_accuracy: 0.8695\n","\n","Epoch 00415: val_accuracy did not improve from 0.93350\n","Epoch 416/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0273 - accuracy: 0.9933 - val_loss: 0.4868 - val_accuracy: 0.8941\n","\n","Epoch 00416: val_accuracy did not improve from 0.93350\n","Epoch 417/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.5618 - val_accuracy: 0.8966\n","\n","Epoch 00417: val_accuracy did not improve from 0.93350\n","Epoch 418/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.5360 - val_accuracy: 0.8966\n","\n","Epoch 00418: val_accuracy did not improve from 0.93350\n","Epoch 419/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6691 - val_accuracy: 0.8990\n","\n","Epoch 00419: val_accuracy did not improve from 0.93350\n","Epoch 420/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5028 - val_accuracy: 0.9089\n","\n","Epoch 00420: val_accuracy did not improve from 0.93350\n","Epoch 421/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4511 - val_accuracy: 0.9236\n","\n","Epoch 00421: val_accuracy did not improve from 0.93350\n","Epoch 422/500\n","52/52 [==============================] - 11s 218ms/step - loss: 4.9031e-04 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.9187\n","\n","Epoch 00422: val_accuracy did not improve from 0.93350\n","Epoch 423/500\n","52/52 [==============================] - 11s 218ms/step - loss: 5.1127e-04 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.9187\n","\n","Epoch 00423: val_accuracy did not improve from 0.93350\n","Epoch 424/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 0.5412 - val_accuracy: 0.8990\n","\n","Epoch 00424: val_accuracy did not improve from 0.93350\n","Epoch 425/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5567 - val_accuracy: 0.9236\n","\n","Epoch 00425: val_accuracy did not improve from 0.93350\n","Epoch 426/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0178 - accuracy: 0.9976 - val_loss: 0.6667 - val_accuracy: 0.8645\n","\n","Epoch 00426: val_accuracy did not improve from 0.93350\n","Epoch 427/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.7603 - val_accuracy: 0.8300\n","\n","Epoch 00427: val_accuracy did not improve from 0.93350\n","Epoch 428/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.7105 - val_accuracy: 0.8645\n","\n","Epoch 00428: val_accuracy did not improve from 0.93350\n","Epoch 429/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.6282 - val_accuracy: 0.8941\n","\n","Epoch 00429: val_accuracy did not improve from 0.93350\n","Epoch 430/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.6507 - val_accuracy: 0.9039\n","\n","Epoch 00430: val_accuracy did not improve from 0.93350\n","Epoch 431/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5474 - val_accuracy: 0.9138\n","\n","Epoch 00431: val_accuracy did not improve from 0.93350\n","Epoch 432/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5119 - val_accuracy: 0.9163\n","\n","Epoch 00432: val_accuracy did not improve from 0.93350\n","Epoch 433/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5214 - val_accuracy: 0.9113\n","\n","Epoch 00433: val_accuracy did not improve from 0.93350\n","Epoch 434/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.4839 - val_accuracy: 0.8941\n","\n","Epoch 00434: val_accuracy did not improve from 0.93350\n","Epoch 435/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.5807 - val_accuracy: 0.8941\n","\n","Epoch 00435: val_accuracy did not improve from 0.93350\n","Epoch 436/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.6518 - val_accuracy: 0.8916\n","\n","Epoch 00436: val_accuracy did not improve from 0.93350\n","Epoch 437/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0355 - accuracy: 0.9872 - val_loss: 0.5979 - val_accuracy: 0.8842\n","\n","Epoch 00437: val_accuracy did not improve from 0.93350\n","Epoch 438/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.5986 - val_accuracy: 0.8793\n","\n","Epoch 00438: val_accuracy did not improve from 0.93350\n","Epoch 439/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.6640 - val_accuracy: 0.8941\n","\n","Epoch 00439: val_accuracy did not improve from 0.93350\n","Epoch 440/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0062 - accuracy: 0.9970 - val_loss: 0.6246 - val_accuracy: 0.8695\n","\n","Epoch 00440: val_accuracy did not improve from 0.93350\n","Epoch 441/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0164 - accuracy: 0.9970 - val_loss: 0.9369 - val_accuracy: 0.7906\n","\n","Epoch 00441: val_accuracy did not improve from 0.93350\n","Epoch 442/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.4623 - val_accuracy: 0.9064\n","\n","Epoch 00442: val_accuracy did not improve from 0.93350\n","Epoch 443/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0549 - accuracy: 0.9878 - val_loss: 0.5698 - val_accuracy: 0.9015\n","\n","Epoch 00443: val_accuracy did not improve from 0.93350\n","Epoch 444/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.6915 - val_accuracy: 0.8768\n","\n","Epoch 00444: val_accuracy did not improve from 0.93350\n","Epoch 445/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6057 - val_accuracy: 0.9015\n","\n","Epoch 00445: val_accuracy did not improve from 0.93350\n","Epoch 446/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.9163\n","\n","Epoch 00446: val_accuracy did not improve from 0.93350\n","Epoch 447/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.5322 - val_accuracy: 0.9089\n","\n","Epoch 00447: val_accuracy did not improve from 0.93350\n","Epoch 448/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.4368 - val_accuracy: 0.9261\n","\n","Epoch 00448: val_accuracy did not improve from 0.93350\n","Epoch 449/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4980 - val_accuracy: 0.9113\n","\n","Epoch 00449: val_accuracy did not improve from 0.93350\n","Epoch 450/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4871 - val_accuracy: 0.9138\n","\n","Epoch 00450: val_accuracy did not improve from 0.93350\n","Epoch 451/500\n","52/52 [==============================] - 12s 220ms/step - loss: 8.6429e-04 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.9138\n","\n","Epoch 00451: val_accuracy did not improve from 0.93350\n","Epoch 452/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9335\n","\n","Epoch 00452: val_accuracy did not improve from 0.93350\n","Epoch 453/500\n","52/52 [==============================] - 11s 218ms/step - loss: 4.7298e-04 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.9236\n","\n","Epoch 00453: val_accuracy did not improve from 0.93350\n","Epoch 454/500\n","52/52 [==============================] - 11s 218ms/step - loss: 5.7334e-04 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9261\n","\n","Epoch 00454: val_accuracy did not improve from 0.93350\n","Epoch 455/500\n","52/52 [==============================] - 11s 218ms/step - loss: 3.8795e-04 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 0.9409\n","\n","Epoch 00455: val_accuracy improved from 0.93350 to 0.94089, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5\n","Epoch 456/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.1296e-04 - accuracy: 1.0000 - val_loss: 0.3892 - val_accuracy: 0.9335\n","\n","Epoch 00456: val_accuracy did not improve from 0.94089\n","Epoch 457/500\n","52/52 [==============================] - 11s 219ms/step - loss: 3.1872e-04 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.9138\n","\n","Epoch 00457: val_accuracy did not improve from 0.94089\n","Epoch 458/500\n","52/52 [==============================] - 12s 220ms/step - loss: 3.2719e-04 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9286\n","\n","Epoch 00458: val_accuracy did not improve from 0.94089\n","Epoch 459/500\n","52/52 [==============================] - 11s 218ms/step - loss: 4.7109e-04 - accuracy: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.9286\n","\n","Epoch 00459: val_accuracy did not improve from 0.94089\n","Epoch 460/500\n","52/52 [==============================] - 11s 218ms/step - loss: 2.8730e-04 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9187\n","\n","Epoch 00460: val_accuracy did not improve from 0.94089\n","Epoch 461/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.7185e-04 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9286\n","\n","Epoch 00461: val_accuracy did not improve from 0.94089\n","Epoch 462/500\n","52/52 [==============================] - 11s 218ms/step - loss: 2.3198e-04 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.9212\n","\n","Epoch 00462: val_accuracy did not improve from 0.94089\n","Epoch 463/500\n","52/52 [==============================] - 11s 219ms/step - loss: 3.3917e-04 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.9261\n","\n","Epoch 00463: val_accuracy did not improve from 0.94089\n","Epoch 464/500\n","52/52 [==============================] - 11s 218ms/step - loss: 1.9482e-04 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 0.9286\n","\n","Epoch 00464: val_accuracy did not improve from 0.94089\n","Epoch 465/500\n","52/52 [==============================] - 11s 218ms/step - loss: 1.2563e-04 - accuracy: 1.0000 - val_loss: 0.4259 - val_accuracy: 0.9310\n","\n","Epoch 00465: val_accuracy did not improve from 0.94089\n","Epoch 466/500\n","52/52 [==============================] - 11s 218ms/step - loss: 3.2451e-04 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9335\n","\n","Epoch 00466: val_accuracy did not improve from 0.94089\n","Epoch 467/500\n","52/52 [==============================] - 11s 217ms/step - loss: 1.4526e-04 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.9286\n","\n","Epoch 00467: val_accuracy did not improve from 0.94089\n","Epoch 468/500\n","52/52 [==============================] - 11s 219ms/step - loss: 6.4443e-05 - accuracy: 1.0000 - val_loss: 0.3649 - val_accuracy: 0.9310\n","\n","Epoch 00468: val_accuracy did not improve from 0.94089\n","Epoch 469/500\n","52/52 [==============================] - 11s 218ms/step - loss: 4.5988e-04 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9335\n","\n","Epoch 00469: val_accuracy did not improve from 0.94089\n","Epoch 470/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.6168e-04 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9335\n","\n","Epoch 00470: val_accuracy did not improve from 0.94089\n","Epoch 471/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4526 - val_accuracy: 0.9138\n","\n","Epoch 00471: val_accuracy did not improve from 0.94089\n","Epoch 472/500\n","52/52 [==============================] - 12s 220ms/step - loss: 9.5466e-04 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.9310\n","\n","Epoch 00472: val_accuracy did not improve from 0.94089\n","Epoch 473/500\n","52/52 [==============================] - 11s 218ms/step - loss: 7.8302e-04 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.9360\n","\n","Epoch 00473: val_accuracy did not improve from 0.94089\n","Epoch 474/500\n","52/52 [==============================] - 11s 218ms/step - loss: 5.3619e-04 - accuracy: 1.0000 - val_loss: 0.5852 - val_accuracy: 0.9039\n","\n","Epoch 00474: val_accuracy did not improve from 0.94089\n","Epoch 475/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0313 - accuracy: 0.9896 - val_loss: 3.6388 - val_accuracy: 0.5640\n","\n","Epoch 00475: val_accuracy did not improve from 0.94089\n","Epoch 476/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0864 - accuracy: 0.9781 - val_loss: 0.8055 - val_accuracy: 0.8645\n","\n","Epoch 00476: val_accuracy did not improve from 0.94089\n","Epoch 477/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0724 - accuracy: 0.9799 - val_loss: 1.0195 - val_accuracy: 0.8621\n","\n","Epoch 00477: val_accuracy did not improve from 0.94089\n","Epoch 478/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0261 - accuracy: 0.9927 - val_loss: 0.5688 - val_accuracy: 0.8892\n","\n","Epoch 00478: val_accuracy did not improve from 0.94089\n","Epoch 479/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0328 - accuracy: 0.9890 - val_loss: 0.3977 - val_accuracy: 0.9089\n","\n","Epoch 00479: val_accuracy did not improve from 0.94089\n","Epoch 480/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4574 - val_accuracy: 0.9113\n","\n","Epoch 00480: val_accuracy did not improve from 0.94089\n","Epoch 481/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.9163\n","\n","Epoch 00481: val_accuracy did not improve from 0.94089\n","Epoch 482/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.3959 - val_accuracy: 0.9163\n","\n","Epoch 00482: val_accuracy did not improve from 0.94089\n","Epoch 483/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3765 - val_accuracy: 0.9212\n","\n","Epoch 00483: val_accuracy did not improve from 0.94089\n","Epoch 484/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4204 - val_accuracy: 0.9039\n","\n","Epoch 00484: val_accuracy did not improve from 0.94089\n","Epoch 485/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9187\n","\n","Epoch 00485: val_accuracy did not improve from 0.94089\n","Epoch 486/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.9212\n","\n","Epoch 00486: val_accuracy did not improve from 0.94089\n","Epoch 487/500\n","52/52 [==============================] - 11s 218ms/step - loss: 6.5130e-04 - accuracy: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.9212\n","\n","Epoch 00487: val_accuracy did not improve from 0.94089\n","Epoch 488/500\n","52/52 [==============================] - 11s 219ms/step - loss: 9.3869e-04 - accuracy: 1.0000 - val_loss: 0.4522 - val_accuracy: 0.9113\n","\n","Epoch 00488: val_accuracy did not improve from 0.94089\n","Epoch 489/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4005 - val_accuracy: 0.9212\n","\n","Epoch 00489: val_accuracy did not improve from 0.94089\n","Epoch 490/500\n","52/52 [==============================] - 11s 218ms/step - loss: 7.6706e-04 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9409\n","\n","Epoch 00490: val_accuracy did not improve from 0.94089\n","Epoch 491/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3618 - val_accuracy: 0.9286\n","\n","Epoch 00491: val_accuracy did not improve from 0.94089\n","Epoch 492/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9163\n","\n","Epoch 00492: val_accuracy did not improve from 0.94089\n","Epoch 493/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4017 - val_accuracy: 0.9310\n","\n","Epoch 00493: val_accuracy did not improve from 0.94089\n","Epoch 494/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.4428 - val_accuracy: 0.9163\n","\n","Epoch 00494: val_accuracy did not improve from 0.94089\n","Epoch 495/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.5115 - val_accuracy: 0.8867\n","\n","Epoch 00495: val_accuracy did not improve from 0.94089\n","Epoch 496/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.4915 - val_accuracy: 0.8892\n","\n","Epoch 00496: val_accuracy did not improve from 0.94089\n","Epoch 497/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0467 - accuracy: 0.9884 - val_loss: 0.8844 - val_accuracy: 0.8251\n","\n","Epoch 00497: val_accuracy did not improve from 0.94089\n","Epoch 498/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 1.3362 - val_accuracy: 0.7512\n","\n","Epoch 00498: val_accuracy did not improve from 0.94089\n","Epoch 499/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0197 - accuracy: 0.9951 - val_loss: 0.4928 - val_accuracy: 0.8941\n","\n","Epoch 00499: val_accuracy did not improve from 0.94089\n","Epoch 500/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.5665 - val_accuracy: 0.9015\n","\n","Epoch 00500: val_accuracy did not improve from 0.94089\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2fee2948d0>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1629885552841,"user_tz":-540,"elapsed":53,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"a1cd5630-07b5-42b7-fbf0-69d7257be5e1"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1629885564289,"user_tz":-540,"elapsed":11484,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_4_DN121.h5', compile=False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1629885565119,"user_tz":-540,"elapsed":838,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629885565693,"user_tz":-540,"elapsed":576,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"2303ddbb-cf69-4643-c1ea-db0635906091"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Found 20480 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629885597636,"user_tz":-540,"elapsed":31948,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ecbb131d-9386-492b-9276-1ec4f048e0f9"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1629885597638,"user_tz":-540,"elapsed":13,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1629885597639,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1629885599358,"user_tz":-540,"elapsed":1729,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1629885599359,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1629885614131,"user_tz":-540,"elapsed":14777,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1629885614140,"user_tz":-540,"elapsed":18,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"e908526b-e8e3-4b34-b11d-890dacafd0ab"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1629885615940,"user_tz":-540,"elapsed":1811,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"149a8534-6374-4b1a-c3dd-951c91056329"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_15_4_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_15_4_DenseNet121_model.csv')"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_d342ad39-8d38-4730-b7d5-6376ab64e878\", \"Rotation_range_15_4_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}