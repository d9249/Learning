{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Rotation_range_25_4_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyMm/nWqXJkxpmuSTc7UpEAQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629904034974,"user_tz":-540,"elapsed":424,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"68c4fd98-3d70-4678-b43a-cd984e2e5f90"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Wed Aug 25 15:07:14 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629904053754,"user_tz":-540,"elapsed":18784,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"e2bb77aa-ee7d-48d1-b00c-4df0871cde35"},"source":["3from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1629904057596,"user_tz":-540,"elapsed":3416,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1629904058716,"user_tz":-540,"elapsed":1127,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1629904061060,"user_tz":-540,"elapsed":2347,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1629904078365,"user_tz":-540,"elapsed":17308,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1629904085059,"user_tz":-540,"elapsed":6697,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629904085060,"user_tz":-540,"elapsed":27,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"400fb5ac-0fe0-451c-d5f0-5a9405314cd0"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629904085061,"user_tz":-540,"elapsed":23,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"5e3cfa39-02d4-4404-a1b0-92b4a6969b4d"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=25,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1629904085061,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629914325726,"user_tz":-540,"elapsed":10240683,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"1a9b2fef-400d-423c-c1dd-6fdab1b100e2"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 53s 472ms/step - loss: 1.9542 - accuracy: 0.3094 - val_loss: 10.1452 - val_accuracy: 0.0936\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09360, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 19s 369ms/step - loss: 1.3744 - accuracy: 0.5286 - val_loss: 7.2927 - val_accuracy: 0.0665\n","\n","Epoch 00002: val_accuracy did not improve from 0.09360\n","Epoch 3/500\n","52/52 [==============================] - 19s 370ms/step - loss: 1.1492 - accuracy: 0.6054 - val_loss: 23.9303 - val_accuracy: 0.1010\n","\n","Epoch 00003: val_accuracy improved from 0.09360 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 4/500\n","52/52 [==============================] - 20s 373ms/step - loss: 0.9774 - accuracy: 0.6693 - val_loss: 11.3123 - val_accuracy: 0.1010\n","\n","Epoch 00004: val_accuracy did not improve from 0.10099\n","Epoch 5/500\n","52/52 [==============================] - 19s 373ms/step - loss: 0.8677 - accuracy: 0.7144 - val_loss: 16.2797 - val_accuracy: 0.1010\n","\n","Epoch 00005: val_accuracy did not improve from 0.10099\n","Epoch 6/500\n","52/52 [==============================] - 20s 374ms/step - loss: 0.7477 - accuracy: 0.7643 - val_loss: 6.6159 - val_accuracy: 0.1724\n","\n","Epoch 00006: val_accuracy improved from 0.10099 to 0.17241, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 20s 377ms/step - loss: 0.7369 - accuracy: 0.7527 - val_loss: 5.1860 - val_accuracy: 0.2118\n","\n","Epoch 00007: val_accuracy improved from 0.17241 to 0.21182, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.6691 - accuracy: 0.7808 - val_loss: 2.9652 - val_accuracy: 0.3522\n","\n","Epoch 00008: val_accuracy improved from 0.21182 to 0.35222, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.6032 - accuracy: 0.7954 - val_loss: 10.5754 - val_accuracy: 0.1453\n","\n","Epoch 00009: val_accuracy did not improve from 0.35222\n","Epoch 10/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.5664 - accuracy: 0.8112 - val_loss: 1.2025 - val_accuracy: 0.6897\n","\n","Epoch 00010: val_accuracy improved from 0.35222 to 0.68966, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.5076 - accuracy: 0.8289 - val_loss: 0.8443 - val_accuracy: 0.7315\n","\n","Epoch 00011: val_accuracy improved from 0.68966 to 0.73153, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.4803 - accuracy: 0.8404 - val_loss: 2.1497 - val_accuracy: 0.5025\n","\n","Epoch 00012: val_accuracy did not improve from 0.73153\n","Epoch 13/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.4912 - accuracy: 0.8362 - val_loss: 1.1334 - val_accuracy: 0.7241\n","\n","Epoch 00013: val_accuracy did not improve from 0.73153\n","Epoch 14/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.4657 - accuracy: 0.8459 - val_loss: 1.0907 - val_accuracy: 0.7069\n","\n","Epoch 00014: val_accuracy did not improve from 0.73153\n","Epoch 15/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.4131 - accuracy: 0.8581 - val_loss: 1.0794 - val_accuracy: 0.6872\n","\n","Epoch 00015: val_accuracy did not improve from 0.73153\n","Epoch 16/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3973 - accuracy: 0.8557 - val_loss: 0.8328 - val_accuracy: 0.7438\n","\n","Epoch 00016: val_accuracy improved from 0.73153 to 0.74384, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 17/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.3826 - accuracy: 0.8800 - val_loss: 0.6045 - val_accuracy: 0.8202\n","\n","Epoch 00017: val_accuracy improved from 0.74384 to 0.82020, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 18/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.3830 - accuracy: 0.8691 - val_loss: 1.1520 - val_accuracy: 0.6429\n","\n","Epoch 00018: val_accuracy did not improve from 0.82020\n","Epoch 19/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3156 - accuracy: 0.8892 - val_loss: 0.6839 - val_accuracy: 0.7882\n","\n","Epoch 00019: val_accuracy did not improve from 0.82020\n","Epoch 20/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.3370 - accuracy: 0.8886 - val_loss: 0.8923 - val_accuracy: 0.7414\n","\n","Epoch 00020: val_accuracy did not improve from 0.82020\n","Epoch 21/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.3108 - accuracy: 0.8879 - val_loss: 0.7155 - val_accuracy: 0.7833\n","\n","Epoch 00021: val_accuracy did not improve from 0.82020\n","Epoch 22/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3231 - accuracy: 0.8849 - val_loss: 0.5995 - val_accuracy: 0.8005\n","\n","Epoch 00022: val_accuracy did not improve from 0.82020\n","Epoch 23/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3517 - accuracy: 0.8745 - val_loss: 0.9495 - val_accuracy: 0.7759\n","\n","Epoch 00023: val_accuracy did not improve from 0.82020\n","Epoch 24/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.2650 - accuracy: 0.9068 - val_loss: 0.7348 - val_accuracy: 0.7660\n","\n","Epoch 00024: val_accuracy did not improve from 0.82020\n","Epoch 25/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3080 - accuracy: 0.8952 - val_loss: 0.8423 - val_accuracy: 0.7734\n","\n","Epoch 00025: val_accuracy did not improve from 0.82020\n","Epoch 26/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.3003 - accuracy: 0.8922 - val_loss: 0.9239 - val_accuracy: 0.7488\n","\n","Epoch 00026: val_accuracy did not improve from 0.82020\n","Epoch 27/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2628 - accuracy: 0.9135 - val_loss: 0.5056 - val_accuracy: 0.8596\n","\n","Epoch 00027: val_accuracy improved from 0.82020 to 0.85961, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 28/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2974 - accuracy: 0.9013 - val_loss: 0.7422 - val_accuracy: 0.7562\n","\n","Epoch 00028: val_accuracy did not improve from 0.85961\n","Epoch 29/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.2885 - accuracy: 0.9038 - val_loss: 1.0733 - val_accuracy: 0.7241\n","\n","Epoch 00029: val_accuracy did not improve from 0.85961\n","Epoch 30/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.2562 - accuracy: 0.9074 - val_loss: 0.7645 - val_accuracy: 0.7488\n","\n","Epoch 00030: val_accuracy did not improve from 0.85961\n","Epoch 31/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.2117 - accuracy: 0.9196 - val_loss: 0.5745 - val_accuracy: 0.8473\n","\n","Epoch 00031: val_accuracy did not improve from 0.85961\n","Epoch 32/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.2260 - accuracy: 0.9184 - val_loss: 0.7078 - val_accuracy: 0.8251\n","\n","Epoch 00032: val_accuracy did not improve from 0.85961\n","Epoch 33/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1750 - accuracy: 0.9434 - val_loss: 0.7077 - val_accuracy: 0.8054\n","\n","Epoch 00033: val_accuracy did not improve from 0.85961\n","Epoch 34/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1962 - accuracy: 0.9300 - val_loss: 0.9458 - val_accuracy: 0.7660\n","\n","Epoch 00034: val_accuracy did not improve from 0.85961\n","Epoch 35/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1686 - accuracy: 0.9391 - val_loss: 0.6393 - val_accuracy: 0.8153\n","\n","Epoch 00035: val_accuracy did not improve from 0.85961\n","Epoch 36/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1795 - accuracy: 0.9385 - val_loss: 0.6400 - val_accuracy: 0.8300\n","\n","Epoch 00036: val_accuracy did not improve from 0.85961\n","Epoch 37/500\n","52/52 [==============================] - 21s 398ms/step - loss: 0.2061 - accuracy: 0.9312 - val_loss: 0.7518 - val_accuracy: 0.8030\n","\n","Epoch 00037: val_accuracy did not improve from 0.85961\n","Epoch 38/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1705 - accuracy: 0.9482 - val_loss: 0.5314 - val_accuracy: 0.8571\n","\n","Epoch 00038: val_accuracy did not improve from 0.85961\n","Epoch 39/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.2655 - accuracy: 0.9172 - val_loss: 0.5326 - val_accuracy: 0.8424\n","\n","Epoch 00039: val_accuracy did not improve from 0.85961\n","Epoch 40/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1244 - accuracy: 0.9647 - val_loss: 0.4258 - val_accuracy: 0.8571\n","\n","Epoch 00040: val_accuracy did not improve from 0.85961\n","Epoch 41/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1409 - accuracy: 0.9519 - val_loss: 0.7734 - val_accuracy: 0.8103\n","\n","Epoch 00041: val_accuracy did not improve from 0.85961\n","Epoch 42/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1434 - accuracy: 0.9555 - val_loss: 0.4922 - val_accuracy: 0.8867\n","\n","Epoch 00042: val_accuracy improved from 0.85961 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 43/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.2248 - accuracy: 0.9294 - val_loss: 3.7386 - val_accuracy: 0.4729\n","\n","Epoch 00043: val_accuracy did not improve from 0.88670\n","Epoch 44/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.2952 - accuracy: 0.9032 - val_loss: 1.1849 - val_accuracy: 0.6478\n","\n","Epoch 00044: val_accuracy did not improve from 0.88670\n","Epoch 45/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2033 - accuracy: 0.9220 - val_loss: 0.6227 - val_accuracy: 0.8030\n","\n","Epoch 00045: val_accuracy did not improve from 0.88670\n","Epoch 46/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.1183 - accuracy: 0.9610 - val_loss: 0.6759 - val_accuracy: 0.7956\n","\n","Epoch 00046: val_accuracy did not improve from 0.88670\n","Epoch 47/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1204 - accuracy: 0.9568 - val_loss: 0.5440 - val_accuracy: 0.8547\n","\n","Epoch 00047: val_accuracy did not improve from 0.88670\n","Epoch 48/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1398 - accuracy: 0.9543 - val_loss: 0.4985 - val_accuracy: 0.8719\n","\n","Epoch 00048: val_accuracy did not improve from 0.88670\n","Epoch 49/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1304 - accuracy: 0.9531 - val_loss: 0.5711 - val_accuracy: 0.8473\n","\n","Epoch 00049: val_accuracy did not improve from 0.88670\n","Epoch 50/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1184 - accuracy: 0.9555 - val_loss: 0.4641 - val_accuracy: 0.8768\n","\n","Epoch 00050: val_accuracy did not improve from 0.88670\n","Epoch 51/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1435 - accuracy: 0.9495 - val_loss: 0.5926 - val_accuracy: 0.8448\n","\n","Epoch 00051: val_accuracy did not improve from 0.88670\n","Epoch 52/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0896 - accuracy: 0.9683 - val_loss: 0.6208 - val_accuracy: 0.8325\n","\n","Epoch 00052: val_accuracy did not improve from 0.88670\n","Epoch 53/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1119 - accuracy: 0.9653 - val_loss: 0.7346 - val_accuracy: 0.7882\n","\n","Epoch 00053: val_accuracy did not improve from 0.88670\n","Epoch 54/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1156 - accuracy: 0.9574 - val_loss: 0.8559 - val_accuracy: 0.7980\n","\n","Epoch 00054: val_accuracy did not improve from 0.88670\n","Epoch 55/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1543 - accuracy: 0.9421 - val_loss: 0.7062 - val_accuracy: 0.8350\n","\n","Epoch 00055: val_accuracy did not improve from 0.88670\n","Epoch 56/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1315 - accuracy: 0.9555 - val_loss: 0.8057 - val_accuracy: 0.8251\n","\n","Epoch 00056: val_accuracy did not improve from 0.88670\n","Epoch 57/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1531 - accuracy: 0.9519 - val_loss: 0.7973 - val_accuracy: 0.8374\n","\n","Epoch 00057: val_accuracy did not improve from 0.88670\n","Epoch 58/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1153 - accuracy: 0.9635 - val_loss: 0.5728 - val_accuracy: 0.8621\n","\n","Epoch 00058: val_accuracy did not improve from 0.88670\n","Epoch 59/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0787 - accuracy: 0.9738 - val_loss: 0.5065 - val_accuracy: 0.8670\n","\n","Epoch 00059: val_accuracy did not improve from 0.88670\n","Epoch 60/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0965 - accuracy: 0.9671 - val_loss: 0.4722 - val_accuracy: 0.8793\n","\n","Epoch 00060: val_accuracy did not improve from 0.88670\n","Epoch 61/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0786 - accuracy: 0.9738 - val_loss: 0.5378 - val_accuracy: 0.8473\n","\n","Epoch 00061: val_accuracy did not improve from 0.88670\n","Epoch 62/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0969 - accuracy: 0.9677 - val_loss: 0.4799 - val_accuracy: 0.8645\n","\n","Epoch 00062: val_accuracy did not improve from 0.88670\n","Epoch 63/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0963 - accuracy: 0.9677 - val_loss: 0.6726 - val_accuracy: 0.8596\n","\n","Epoch 00063: val_accuracy did not improve from 0.88670\n","Epoch 64/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0764 - accuracy: 0.9762 - val_loss: 0.3493 - val_accuracy: 0.9113\n","\n","Epoch 00064: val_accuracy improved from 0.88670 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 65/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0885 - accuracy: 0.9665 - val_loss: 0.7304 - val_accuracy: 0.8522\n","\n","Epoch 00065: val_accuracy did not improve from 0.91133\n","Epoch 66/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0774 - accuracy: 0.9702 - val_loss: 0.5066 - val_accuracy: 0.8916\n","\n","Epoch 00066: val_accuracy did not improve from 0.91133\n","Epoch 67/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1171 - accuracy: 0.9616 - val_loss: 0.8846 - val_accuracy: 0.7980\n","\n","Epoch 00067: val_accuracy did not improve from 0.91133\n","Epoch 68/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0983 - accuracy: 0.9665 - val_loss: 0.6354 - val_accuracy: 0.8547\n","\n","Epoch 00068: val_accuracy did not improve from 0.91133\n","Epoch 69/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1113 - accuracy: 0.9616 - val_loss: 0.5519 - val_accuracy: 0.8522\n","\n","Epoch 00069: val_accuracy did not improve from 0.91133\n","Epoch 70/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0856 - accuracy: 0.9689 - val_loss: 0.6149 - val_accuracy: 0.8374\n","\n","Epoch 00070: val_accuracy did not improve from 0.91133\n","Epoch 71/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0672 - accuracy: 0.9775 - val_loss: 0.4564 - val_accuracy: 0.8842\n","\n","Epoch 00071: val_accuracy did not improve from 0.91133\n","Epoch 72/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0726 - accuracy: 0.9738 - val_loss: 0.5707 - val_accuracy: 0.8596\n","\n","Epoch 00072: val_accuracy did not improve from 0.91133\n","Epoch 73/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0519 - accuracy: 0.9842 - val_loss: 0.7183 - val_accuracy: 0.8202\n","\n","Epoch 00073: val_accuracy did not improve from 0.91133\n","Epoch 74/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0741 - accuracy: 0.9781 - val_loss: 0.6121 - val_accuracy: 0.8153\n","\n","Epoch 00074: val_accuracy did not improve from 0.91133\n","Epoch 75/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.5074 - val_accuracy: 0.8695\n","\n","Epoch 00075: val_accuracy did not improve from 0.91133\n","Epoch 76/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0963 - accuracy: 0.9629 - val_loss: 0.4509 - val_accuracy: 0.8768\n","\n","Epoch 00076: val_accuracy did not improve from 0.91133\n","Epoch 77/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0930 - accuracy: 0.9683 - val_loss: 0.5131 - val_accuracy: 0.8744\n","\n","Epoch 00077: val_accuracy did not improve from 0.91133\n","Epoch 78/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0960 - accuracy: 0.9622 - val_loss: 0.6571 - val_accuracy: 0.8473\n","\n","Epoch 00078: val_accuracy did not improve from 0.91133\n","Epoch 79/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1231 - accuracy: 0.9616 - val_loss: 0.8751 - val_accuracy: 0.8103\n","\n","Epoch 00079: val_accuracy did not improve from 0.91133\n","Epoch 80/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0768 - accuracy: 0.9744 - val_loss: 0.6417 - val_accuracy: 0.8448\n","\n","Epoch 00080: val_accuracy did not improve from 0.91133\n","Epoch 81/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0562 - accuracy: 0.9805 - val_loss: 0.6422 - val_accuracy: 0.8645\n","\n","Epoch 00081: val_accuracy did not improve from 0.91133\n","Epoch 82/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0947 - accuracy: 0.9695 - val_loss: 0.5454 - val_accuracy: 0.8842\n","\n","Epoch 00082: val_accuracy did not improve from 0.91133\n","Epoch 83/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0560 - accuracy: 0.9836 - val_loss: 0.5743 - val_accuracy: 0.8399\n","\n","Epoch 00083: val_accuracy did not improve from 0.91133\n","Epoch 84/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0647 - accuracy: 0.9793 - val_loss: 0.6213 - val_accuracy: 0.8202\n","\n","Epoch 00084: val_accuracy did not improve from 0.91133\n","Epoch 85/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0871 - accuracy: 0.9726 - val_loss: 0.8863 - val_accuracy: 0.8128\n","\n","Epoch 00085: val_accuracy did not improve from 0.91133\n","Epoch 86/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0657 - accuracy: 0.9762 - val_loss: 0.7469 - val_accuracy: 0.8448\n","\n","Epoch 00086: val_accuracy did not improve from 0.91133\n","Epoch 87/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0958 - accuracy: 0.9616 - val_loss: 0.7123 - val_accuracy: 0.8621\n","\n","Epoch 00087: val_accuracy did not improve from 0.91133\n","Epoch 88/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0515 - accuracy: 0.9805 - val_loss: 0.6338 - val_accuracy: 0.8744\n","\n","Epoch 00088: val_accuracy did not improve from 0.91133\n","Epoch 89/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0473 - accuracy: 0.9823 - val_loss: 0.6593 - val_accuracy: 0.8448\n","\n","Epoch 00089: val_accuracy did not improve from 0.91133\n","Epoch 90/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0369 - accuracy: 0.9842 - val_loss: 0.7504 - val_accuracy: 0.8128\n","\n","Epoch 00090: val_accuracy did not improve from 0.91133\n","Epoch 91/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0577 - accuracy: 0.9817 - val_loss: 0.8033 - val_accuracy: 0.8374\n","\n","Epoch 00091: val_accuracy did not improve from 0.91133\n","Epoch 92/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0508 - accuracy: 0.9829 - val_loss: 0.8667 - val_accuracy: 0.8300\n","\n","Epoch 00092: val_accuracy did not improve from 0.91133\n","Epoch 93/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0575 - accuracy: 0.9811 - val_loss: 0.5778 - val_accuracy: 0.8645\n","\n","Epoch 00093: val_accuracy did not improve from 0.91133\n","Epoch 94/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0572 - accuracy: 0.9793 - val_loss: 1.6147 - val_accuracy: 0.6404\n","\n","Epoch 00094: val_accuracy did not improve from 0.91133\n","Epoch 95/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0554 - accuracy: 0.9775 - val_loss: 0.6816 - val_accuracy: 0.8719\n","\n","Epoch 00095: val_accuracy did not improve from 0.91133\n","Epoch 96/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0397 - accuracy: 0.9854 - val_loss: 0.5547 - val_accuracy: 0.8818\n","\n","Epoch 00096: val_accuracy did not improve from 0.91133\n","Epoch 97/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0389 - accuracy: 0.9872 - val_loss: 0.6560 - val_accuracy: 0.8473\n","\n","Epoch 00097: val_accuracy did not improve from 0.91133\n","Epoch 98/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1133 - accuracy: 0.9653 - val_loss: 2.0509 - val_accuracy: 0.6823\n","\n","Epoch 00098: val_accuracy did not improve from 0.91133\n","Epoch 99/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0801 - accuracy: 0.9756 - val_loss: 0.8062 - val_accuracy: 0.8473\n","\n","Epoch 00099: val_accuracy did not improve from 0.91133\n","Epoch 100/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0667 - accuracy: 0.9805 - val_loss: 0.6249 - val_accuracy: 0.8941\n","\n","Epoch 00100: val_accuracy did not improve from 0.91133\n","Epoch 101/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0570 - accuracy: 0.9781 - val_loss: 0.7867 - val_accuracy: 0.8448\n","\n","Epoch 00101: val_accuracy did not improve from 0.91133\n","Epoch 102/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0759 - accuracy: 0.9744 - val_loss: 1.0594 - val_accuracy: 0.7488\n","\n","Epoch 00102: val_accuracy did not improve from 0.91133\n","Epoch 103/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0651 - accuracy: 0.9769 - val_loss: 0.7519 - val_accuracy: 0.8325\n","\n","Epoch 00103: val_accuracy did not improve from 0.91133\n","Epoch 104/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0754 - accuracy: 0.9769 - val_loss: 0.7746 - val_accuracy: 0.8350\n","\n","Epoch 00104: val_accuracy did not improve from 0.91133\n","Epoch 105/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0699 - accuracy: 0.9726 - val_loss: 1.0161 - val_accuracy: 0.7660\n","\n","Epoch 00105: val_accuracy did not improve from 0.91133\n","Epoch 106/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0431 - accuracy: 0.9823 - val_loss: 0.5021 - val_accuracy: 0.8793\n","\n","Epoch 00106: val_accuracy did not improve from 0.91133\n","Epoch 107/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0468 - accuracy: 0.9872 - val_loss: 0.6672 - val_accuracy: 0.8325\n","\n","Epoch 00107: val_accuracy did not improve from 0.91133\n","Epoch 108/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0556 - accuracy: 0.9811 - val_loss: 0.4657 - val_accuracy: 0.8966\n","\n","Epoch 00108: val_accuracy did not improve from 0.91133\n","Epoch 109/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0414 - accuracy: 0.9854 - val_loss: 0.5035 - val_accuracy: 0.8990\n","\n","Epoch 00109: val_accuracy did not improve from 0.91133\n","Epoch 110/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 0.6286 - val_accuracy: 0.8621\n","\n","Epoch 00110: val_accuracy did not improve from 0.91133\n","Epoch 111/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0498 - accuracy: 0.9823 - val_loss: 0.5380 - val_accuracy: 0.8867\n","\n","Epoch 00111: val_accuracy did not improve from 0.91133\n","Epoch 112/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.6666 - val_accuracy: 0.8695\n","\n","Epoch 00112: val_accuracy did not improve from 0.91133\n","Epoch 113/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0427 - accuracy: 0.9872 - val_loss: 0.7040 - val_accuracy: 0.8350\n","\n","Epoch 00113: val_accuracy did not improve from 0.91133\n","Epoch 114/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0410 - accuracy: 0.9878 - val_loss: 0.6520 - val_accuracy: 0.8596\n","\n","Epoch 00114: val_accuracy did not improve from 0.91133\n","Epoch 115/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.7030 - val_accuracy: 0.8695\n","\n","Epoch 00115: val_accuracy did not improve from 0.91133\n","Epoch 116/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0295 - accuracy: 0.9921 - val_loss: 0.5257 - val_accuracy: 0.8916\n","\n","Epoch 00116: val_accuracy did not improve from 0.91133\n","Epoch 117/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.5596 - val_accuracy: 0.8842\n","\n","Epoch 00117: val_accuracy did not improve from 0.91133\n","Epoch 118/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.6464 - val_accuracy: 0.8621\n","\n","Epoch 00118: val_accuracy did not improve from 0.91133\n","Epoch 119/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0394 - accuracy: 0.9860 - val_loss: 0.6119 - val_accuracy: 0.8719\n","\n","Epoch 00119: val_accuracy did not improve from 0.91133\n","Epoch 120/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.4772 - val_accuracy: 0.9089\n","\n","Epoch 00120: val_accuracy did not improve from 0.91133\n","Epoch 121/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.4828 - val_accuracy: 0.8941\n","\n","Epoch 00121: val_accuracy did not improve from 0.91133\n","Epoch 122/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.5569 - val_accuracy: 0.8645\n","\n","Epoch 00122: val_accuracy did not improve from 0.91133\n","Epoch 123/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0531 - accuracy: 0.9836 - val_loss: 1.3280 - val_accuracy: 0.7882\n","\n","Epoch 00123: val_accuracy did not improve from 0.91133\n","Epoch 124/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0449 - accuracy: 0.9829 - val_loss: 0.7256 - val_accuracy: 0.8522\n","\n","Epoch 00124: val_accuracy did not improve from 0.91133\n","Epoch 125/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1030 - accuracy: 0.9677 - val_loss: 0.6029 - val_accuracy: 0.8793\n","\n","Epoch 00125: val_accuracy did not improve from 0.91133\n","Epoch 126/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0528 - accuracy: 0.9787 - val_loss: 1.6847 - val_accuracy: 0.6355\n","\n","Epoch 00126: val_accuracy did not improve from 0.91133\n","Epoch 127/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0420 - accuracy: 0.9854 - val_loss: 0.9228 - val_accuracy: 0.8005\n","\n","Epoch 00127: val_accuracy did not improve from 0.91133\n","Epoch 128/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0615 - accuracy: 0.9805 - val_loss: 0.9433 - val_accuracy: 0.8153\n","\n","Epoch 00128: val_accuracy did not improve from 0.91133\n","Epoch 129/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0535 - accuracy: 0.9872 - val_loss: 0.7383 - val_accuracy: 0.8079\n","\n","Epoch 00129: val_accuracy did not improve from 0.91133\n","Epoch 130/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0376 - accuracy: 0.9878 - val_loss: 0.6696 - val_accuracy: 0.8645\n","\n","Epoch 00130: val_accuracy did not improve from 0.91133\n","Epoch 131/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0269 - accuracy: 0.9903 - val_loss: 0.6123 - val_accuracy: 0.8916\n","\n","Epoch 00131: val_accuracy did not improve from 0.91133\n","Epoch 132/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0358 - accuracy: 0.9866 - val_loss: 0.5940 - val_accuracy: 0.8793\n","\n","Epoch 00132: val_accuracy did not improve from 0.91133\n","Epoch 133/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0700 - accuracy: 0.9762 - val_loss: 0.7122 - val_accuracy: 0.8596\n","\n","Epoch 00133: val_accuracy did not improve from 0.91133\n","Epoch 134/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0750 - accuracy: 0.9726 - val_loss: 0.7804 - val_accuracy: 0.8399\n","\n","Epoch 00134: val_accuracy did not improve from 0.91133\n","Epoch 135/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0696 - accuracy: 0.9793 - val_loss: 1.4665 - val_accuracy: 0.7020\n","\n","Epoch 00135: val_accuracy did not improve from 0.91133\n","Epoch 136/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0790 - accuracy: 0.9756 - val_loss: 0.5708 - val_accuracy: 0.8916\n","\n","Epoch 00136: val_accuracy did not improve from 0.91133\n","Epoch 137/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0574 - accuracy: 0.9860 - val_loss: 0.5141 - val_accuracy: 0.8793\n","\n","Epoch 00137: val_accuracy did not improve from 0.91133\n","Epoch 138/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0563 - accuracy: 0.9836 - val_loss: 0.5020 - val_accuracy: 0.8966\n","\n","Epoch 00138: val_accuracy did not improve from 0.91133\n","Epoch 139/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0207 - accuracy: 0.9915 - val_loss: 0.6058 - val_accuracy: 0.8744\n","\n","Epoch 00139: val_accuracy did not improve from 0.91133\n","Epoch 140/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0216 - accuracy: 0.9909 - val_loss: 0.5099 - val_accuracy: 0.8966\n","\n","Epoch 00140: val_accuracy did not improve from 0.91133\n","Epoch 141/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 0.9586 - val_accuracy: 0.8399\n","\n","Epoch 00141: val_accuracy did not improve from 0.91133\n","Epoch 142/500\n","52/52 [==============================] - 21s 399ms/step - loss: 0.0218 - accuracy: 0.9915 - val_loss: 0.6427 - val_accuracy: 0.8695\n","\n","Epoch 00142: val_accuracy did not improve from 0.91133\n","Epoch 143/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.6010 - val_accuracy: 0.8867\n","\n","Epoch 00143: val_accuracy did not improve from 0.91133\n","Epoch 144/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.5213 - val_accuracy: 0.8941\n","\n","Epoch 00144: val_accuracy did not improve from 0.91133\n","Epoch 145/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.4956 - val_accuracy: 0.9015\n","\n","Epoch 00145: val_accuracy did not improve from 0.91133\n","Epoch 146/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0621 - accuracy: 0.9793 - val_loss: 3.0029 - val_accuracy: 0.6010\n","\n","Epoch 00146: val_accuracy did not improve from 0.91133\n","Epoch 147/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1280 - accuracy: 0.9641 - val_loss: 1.4229 - val_accuracy: 0.7759\n","\n","Epoch 00147: val_accuracy did not improve from 0.91133\n","Epoch 148/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0860 - accuracy: 0.9726 - val_loss: 0.7962 - val_accuracy: 0.8251\n","\n","Epoch 00148: val_accuracy did not improve from 0.91133\n","Epoch 149/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0403 - accuracy: 0.9829 - val_loss: 0.8091 - val_accuracy: 0.7685\n","\n","Epoch 00149: val_accuracy did not improve from 0.91133\n","Epoch 150/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0294 - accuracy: 0.9890 - val_loss: 0.9703 - val_accuracy: 0.7783\n","\n","Epoch 00150: val_accuracy did not improve from 0.91133\n","Epoch 151/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0370 - accuracy: 0.9854 - val_loss: 0.5613 - val_accuracy: 0.8645\n","\n","Epoch 00151: val_accuracy did not improve from 0.91133\n","Epoch 152/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.5556 - val_accuracy: 0.8892\n","\n","Epoch 00152: val_accuracy did not improve from 0.91133\n","Epoch 153/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0266 - accuracy: 0.9927 - val_loss: 0.6284 - val_accuracy: 0.8719\n","\n","Epoch 00153: val_accuracy did not improve from 0.91133\n","Epoch 154/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 0.3961 - val_accuracy: 0.9212\n","\n","Epoch 00154: val_accuracy improved from 0.91133 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 155/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0104 - accuracy: 0.9957 - val_loss: 0.5984 - val_accuracy: 0.8916\n","\n","Epoch 00155: val_accuracy did not improve from 0.92118\n","Epoch 156/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0227 - accuracy: 0.9945 - val_loss: 0.5853 - val_accuracy: 0.8571\n","\n","Epoch 00156: val_accuracy did not improve from 0.92118\n","Epoch 157/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 0.6811 - val_accuracy: 0.8719\n","\n","Epoch 00157: val_accuracy did not improve from 0.92118\n","Epoch 158/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0320 - accuracy: 0.9915 - val_loss: 0.7932 - val_accuracy: 0.7931\n","\n","Epoch 00158: val_accuracy did not improve from 0.92118\n","Epoch 159/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0714 - accuracy: 0.9744 - val_loss: 1.4870 - val_accuracy: 0.7709\n","\n","Epoch 00159: val_accuracy did not improve from 0.92118\n","Epoch 160/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0557 - accuracy: 0.9787 - val_loss: 0.6331 - val_accuracy: 0.8670\n","\n","Epoch 00160: val_accuracy did not improve from 0.92118\n","Epoch 161/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0299 - accuracy: 0.9896 - val_loss: 0.6996 - val_accuracy: 0.8818\n","\n","Epoch 00161: val_accuracy did not improve from 0.92118\n","Epoch 162/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0432 - accuracy: 0.9878 - val_loss: 0.6184 - val_accuracy: 0.8768\n","\n","Epoch 00162: val_accuracy did not improve from 0.92118\n","Epoch 163/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.5488 - val_accuracy: 0.8892\n","\n","Epoch 00163: val_accuracy did not improve from 0.92118\n","Epoch 164/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.7581 - val_accuracy: 0.8054\n","\n","Epoch 00164: val_accuracy did not improve from 0.92118\n","Epoch 165/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.9815 - val_accuracy: 0.7709\n","\n","Epoch 00165: val_accuracy did not improve from 0.92118\n","Epoch 166/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0410 - accuracy: 0.9872 - val_loss: 0.7393 - val_accuracy: 0.8005\n","\n","Epoch 00166: val_accuracy did not improve from 0.92118\n","Epoch 167/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 0.6180 - val_accuracy: 0.8695\n","\n","Epoch 00167: val_accuracy did not improve from 0.92118\n","Epoch 168/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0328 - accuracy: 0.9890 - val_loss: 0.7774 - val_accuracy: 0.8719\n","\n","Epoch 00168: val_accuracy did not improve from 0.92118\n","Epoch 169/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.6986 - val_accuracy: 0.8374\n","\n","Epoch 00169: val_accuracy did not improve from 0.92118\n","Epoch 170/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0309 - accuracy: 0.9872 - val_loss: 0.7604 - val_accuracy: 0.8325\n","\n","Epoch 00170: val_accuracy did not improve from 0.92118\n","Epoch 171/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.6082 - val_accuracy: 0.8818\n","\n","Epoch 00171: val_accuracy did not improve from 0.92118\n","Epoch 172/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0416 - accuracy: 0.9854 - val_loss: 0.4955 - val_accuracy: 0.8793\n","\n","Epoch 00172: val_accuracy did not improve from 0.92118\n","Epoch 173/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0360 - accuracy: 0.9896 - val_loss: 0.8804 - val_accuracy: 0.8522\n","\n","Epoch 00173: val_accuracy did not improve from 0.92118\n","Epoch 174/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0441 - accuracy: 0.9878 - val_loss: 0.5725 - val_accuracy: 0.8719\n","\n","Epoch 00174: val_accuracy did not improve from 0.92118\n","Epoch 175/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 1.5872 - val_accuracy: 0.6281\n","\n","Epoch 00175: val_accuracy did not improve from 0.92118\n","Epoch 176/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.6723 - val_accuracy: 0.8892\n","\n","Epoch 00176: val_accuracy did not improve from 0.92118\n","Epoch 177/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0244 - accuracy: 0.9903 - val_loss: 1.1094 - val_accuracy: 0.7463\n","\n","Epoch 00177: val_accuracy did not improve from 0.92118\n","Epoch 178/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0311 - accuracy: 0.9866 - val_loss: 0.5814 - val_accuracy: 0.8867\n","\n","Epoch 00178: val_accuracy did not improve from 0.92118\n","Epoch 179/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0238 - accuracy: 0.9939 - val_loss: 0.4751 - val_accuracy: 0.9064\n","\n","Epoch 00179: val_accuracy did not improve from 0.92118\n","Epoch 180/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.4370 - val_accuracy: 0.9039\n","\n","Epoch 00180: val_accuracy did not improve from 0.92118\n","Epoch 181/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.4275 - val_accuracy: 0.9187\n","\n","Epoch 00181: val_accuracy did not improve from 0.92118\n","Epoch 182/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0091 - accuracy: 0.9957 - val_loss: 0.5594 - val_accuracy: 0.8916\n","\n","Epoch 00182: val_accuracy did not improve from 0.92118\n","Epoch 183/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.5282 - val_accuracy: 0.8916\n","\n","Epoch 00183: val_accuracy did not improve from 0.92118\n","Epoch 184/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.7568 - val_accuracy: 0.8670\n","\n","Epoch 00184: val_accuracy did not improve from 0.92118\n","Epoch 185/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0270 - accuracy: 0.9927 - val_loss: 0.8762 - val_accuracy: 0.8498\n","\n","Epoch 00185: val_accuracy did not improve from 0.92118\n","Epoch 186/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0375 - accuracy: 0.9890 - val_loss: 0.7880 - val_accuracy: 0.8596\n","\n","Epoch 00186: val_accuracy did not improve from 0.92118\n","Epoch 187/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0592 - accuracy: 0.9817 - val_loss: 1.1102 - val_accuracy: 0.8054\n","\n","Epoch 00187: val_accuracy did not improve from 0.92118\n","Epoch 188/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0591 - accuracy: 0.9793 - val_loss: 0.7997 - val_accuracy: 0.8522\n","\n","Epoch 00188: val_accuracy did not improve from 0.92118\n","Epoch 189/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0450 - accuracy: 0.9842 - val_loss: 0.7046 - val_accuracy: 0.8621\n","\n","Epoch 00189: val_accuracy did not improve from 0.92118\n","Epoch 190/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0401 - accuracy: 0.9866 - val_loss: 0.6740 - val_accuracy: 0.8498\n","\n","Epoch 00190: val_accuracy did not improve from 0.92118\n","Epoch 191/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0265 - accuracy: 0.9927 - val_loss: 1.8044 - val_accuracy: 0.6182\n","\n","Epoch 00191: val_accuracy did not improve from 0.92118\n","Epoch 192/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 1.1768 - val_accuracy: 0.7365\n","\n","Epoch 00192: val_accuracy did not improve from 0.92118\n","Epoch 193/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.6926 - val_accuracy: 0.8005\n","\n","Epoch 00193: val_accuracy did not improve from 0.92118\n","Epoch 194/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.4296 - val_accuracy: 0.9015\n","\n","Epoch 00194: val_accuracy did not improve from 0.92118\n","Epoch 195/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.9321 - val_accuracy: 0.7759\n","\n","Epoch 00195: val_accuracy did not improve from 0.92118\n","Epoch 196/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0171 - accuracy: 0.9957 - val_loss: 0.6556 - val_accuracy: 0.8768\n","\n","Epoch 00196: val_accuracy did not improve from 0.92118\n","Epoch 197/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0295 - accuracy: 0.9884 - val_loss: 0.8479 - val_accuracy: 0.8424\n","\n","Epoch 00197: val_accuracy did not improve from 0.92118\n","Epoch 198/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.5087 - val_accuracy: 0.8990\n","\n","Epoch 00198: val_accuracy did not improve from 0.92118\n","Epoch 199/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.5178 - val_accuracy: 0.8818\n","\n","Epoch 00199: val_accuracy did not improve from 0.92118\n","Epoch 200/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 0.5752 - val_accuracy: 0.8818\n","\n","Epoch 00200: val_accuracy did not improve from 0.92118\n","Epoch 201/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0339 - accuracy: 0.9903 - val_loss: 0.9933 - val_accuracy: 0.7956\n","\n","Epoch 00201: val_accuracy did not improve from 0.92118\n","Epoch 202/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0820 - accuracy: 0.9781 - val_loss: 0.9232 - val_accuracy: 0.8177\n","\n","Epoch 00202: val_accuracy did not improve from 0.92118\n","Epoch 203/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0716 - accuracy: 0.9769 - val_loss: 1.3691 - val_accuracy: 0.7759\n","\n","Epoch 00203: val_accuracy did not improve from 0.92118\n","Epoch 204/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0527 - accuracy: 0.9823 - val_loss: 0.8522 - val_accuracy: 0.8350\n","\n","Epoch 00204: val_accuracy did not improve from 0.92118\n","Epoch 205/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0536 - accuracy: 0.9817 - val_loss: 1.0329 - val_accuracy: 0.8424\n","\n","Epoch 00205: val_accuracy did not improve from 0.92118\n","Epoch 206/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0174 - accuracy: 0.9963 - val_loss: 0.4483 - val_accuracy: 0.9113\n","\n","Epoch 00206: val_accuracy did not improve from 0.92118\n","Epoch 207/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.4347 - val_accuracy: 0.9089\n","\n","Epoch 00207: val_accuracy did not improve from 0.92118\n","Epoch 208/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0173 - accuracy: 0.9963 - val_loss: 0.6517 - val_accuracy: 0.8990\n","\n","Epoch 00208: val_accuracy did not improve from 0.92118\n","Epoch 209/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.6266 - val_accuracy: 0.8793\n","\n","Epoch 00209: val_accuracy did not improve from 0.92118\n","Epoch 210/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.4299 - val_accuracy: 0.9089\n","\n","Epoch 00210: val_accuracy did not improve from 0.92118\n","Epoch 211/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.4442 - val_accuracy: 0.8793\n","\n","Epoch 00211: val_accuracy did not improve from 0.92118\n","Epoch 212/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0457 - accuracy: 0.9842 - val_loss: 0.9392 - val_accuracy: 0.8325\n","\n","Epoch 00212: val_accuracy did not improve from 0.92118\n","Epoch 213/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0262 - accuracy: 0.9896 - val_loss: 1.5070 - val_accuracy: 0.6478\n","\n","Epoch 00213: val_accuracy did not improve from 0.92118\n","Epoch 214/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.6561 - val_accuracy: 0.8670\n","\n","Epoch 00214: val_accuracy did not improve from 0.92118\n","Epoch 215/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.6182 - val_accuracy: 0.8547\n","\n","Epoch 00215: val_accuracy did not improve from 0.92118\n","Epoch 216/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.4806 - val_accuracy: 0.9089\n","\n","Epoch 00216: val_accuracy did not improve from 0.92118\n","Epoch 217/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0240 - accuracy: 0.9896 - val_loss: 0.4524 - val_accuracy: 0.9089\n","\n","Epoch 00217: val_accuracy did not improve from 0.92118\n","Epoch 218/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.5046 - val_accuracy: 0.8695\n","\n","Epoch 00218: val_accuracy did not improve from 0.92118\n","Epoch 219/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0241 - accuracy: 0.9939 - val_loss: 0.9144 - val_accuracy: 0.8596\n","\n","Epoch 00219: val_accuracy did not improve from 0.92118\n","Epoch 220/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0575 - accuracy: 0.9799 - val_loss: 0.8635 - val_accuracy: 0.8547\n","\n","Epoch 00220: val_accuracy did not improve from 0.92118\n","Epoch 221/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.8806 - val_accuracy: 0.8079\n","\n","Epoch 00221: val_accuracy did not improve from 0.92118\n","Epoch 222/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.4540 - val_accuracy: 0.8966\n","\n","Epoch 00222: val_accuracy did not improve from 0.92118\n","Epoch 223/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.5224 - val_accuracy: 0.8867\n","\n","Epoch 00223: val_accuracy did not improve from 0.92118\n","Epoch 224/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.4571 - val_accuracy: 0.8966\n","\n","Epoch 00224: val_accuracy did not improve from 0.92118\n","Epoch 225/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.5212 - val_accuracy: 0.9212\n","\n","Epoch 00225: val_accuracy did not improve from 0.92118\n","Epoch 226/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5902 - val_accuracy: 0.8892\n","\n","Epoch 00226: val_accuracy did not improve from 0.92118\n","Epoch 227/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.5377 - val_accuracy: 0.8744\n","\n","Epoch 00227: val_accuracy did not improve from 0.92118\n","Epoch 228/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.4915 - val_accuracy: 0.9015\n","\n","Epoch 00228: val_accuracy did not improve from 0.92118\n","Epoch 229/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0081 - accuracy: 0.9994 - val_loss: 0.6201 - val_accuracy: 0.8941\n","\n","Epoch 00229: val_accuracy did not improve from 0.92118\n","Epoch 230/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.5411 - val_accuracy: 0.8916\n","\n","Epoch 00230: val_accuracy did not improve from 0.92118\n","Epoch 231/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0097 - accuracy: 0.9957 - val_loss: 0.7751 - val_accuracy: 0.8374\n","\n","Epoch 00231: val_accuracy did not improve from 0.92118\n","Epoch 232/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.4249 - val_accuracy: 0.9064\n","\n","Epoch 00232: val_accuracy did not improve from 0.92118\n","Epoch 233/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.4980 - val_accuracy: 0.9113\n","\n","Epoch 00233: val_accuracy did not improve from 0.92118\n","Epoch 234/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.7006 - val_accuracy: 0.8916\n","\n","Epoch 00234: val_accuracy did not improve from 0.92118\n","Epoch 235/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0313 - accuracy: 0.9939 - val_loss: 1.5627 - val_accuracy: 0.6527\n","\n","Epoch 00235: val_accuracy did not improve from 0.92118\n","Epoch 236/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0281 - accuracy: 0.9903 - val_loss: 0.9472 - val_accuracy: 0.8227\n","\n","Epoch 00236: val_accuracy did not improve from 0.92118\n","Epoch 237/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 1.0549 - val_accuracy: 0.7389\n","\n","Epoch 00237: val_accuracy did not improve from 0.92118\n","Epoch 238/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.7696 - val_accuracy: 0.8670\n","\n","Epoch 00238: val_accuracy did not improve from 0.92118\n","Epoch 239/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0481 - accuracy: 0.9854 - val_loss: 0.9753 - val_accuracy: 0.8350\n","\n","Epoch 00239: val_accuracy did not improve from 0.92118\n","Epoch 240/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0262 - accuracy: 0.9909 - val_loss: 1.2192 - val_accuracy: 0.8079\n","\n","Epoch 00240: val_accuracy did not improve from 0.92118\n","Epoch 241/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0567 - accuracy: 0.9799 - val_loss: 1.0260 - val_accuracy: 0.8054\n","\n","Epoch 00241: val_accuracy did not improve from 0.92118\n","Epoch 242/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0426 - accuracy: 0.9848 - val_loss: 0.7392 - val_accuracy: 0.8473\n","\n","Epoch 00242: val_accuracy did not improve from 0.92118\n","Epoch 243/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0630 - accuracy: 0.9805 - val_loss: 1.5880 - val_accuracy: 0.6700\n","\n","Epoch 00243: val_accuracy did not improve from 0.92118\n","Epoch 244/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.6613 - val_accuracy: 0.8596\n","\n","Epoch 00244: val_accuracy did not improve from 0.92118\n","Epoch 245/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0227 - accuracy: 0.9921 - val_loss: 0.8188 - val_accuracy: 0.7783\n","\n","Epoch 00245: val_accuracy did not improve from 0.92118\n","Epoch 246/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.5654 - val_accuracy: 0.8744\n","\n","Epoch 00246: val_accuracy did not improve from 0.92118\n","Epoch 247/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.9882 - val_accuracy: 0.7340\n","\n","Epoch 00247: val_accuracy did not improve from 0.92118\n","Epoch 248/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.4935 - val_accuracy: 0.8966\n","\n","Epoch 00248: val_accuracy did not improve from 0.92118\n","Epoch 249/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.4629 - val_accuracy: 0.9089\n","\n","Epoch 00249: val_accuracy did not improve from 0.92118\n","Epoch 250/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.5515 - val_accuracy: 0.8990\n","\n","Epoch 00250: val_accuracy did not improve from 0.92118\n","Epoch 251/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.4866 - val_accuracy: 0.8793\n","\n","Epoch 00251: val_accuracy did not improve from 0.92118\n","Epoch 252/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.7503 - val_accuracy: 0.8030\n","\n","Epoch 00252: val_accuracy did not improve from 0.92118\n","Epoch 253/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6236 - val_accuracy: 0.8719\n","\n","Epoch 00253: val_accuracy did not improve from 0.92118\n","Epoch 254/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.6328 - val_accuracy: 0.8645\n","\n","Epoch 00254: val_accuracy did not improve from 0.92118\n","Epoch 255/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0300 - accuracy: 0.9909 - val_loss: 1.0897 - val_accuracy: 0.6921\n","\n","Epoch 00255: val_accuracy did not improve from 0.92118\n","Epoch 256/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.7167 - val_accuracy: 0.8695\n","\n","Epoch 00256: val_accuracy did not improve from 0.92118\n","Epoch 257/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.5976 - val_accuracy: 0.8793\n","\n","Epoch 00257: val_accuracy did not improve from 0.92118\n","Epoch 258/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0722 - accuracy: 0.9811 - val_loss: 0.7817 - val_accuracy: 0.8645\n","\n","Epoch 00258: val_accuracy did not improve from 0.92118\n","Epoch 259/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0387 - accuracy: 0.9842 - val_loss: 0.8970 - val_accuracy: 0.8621\n","\n","Epoch 00259: val_accuracy did not improve from 0.92118\n","Epoch 260/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0338 - accuracy: 0.9878 - val_loss: 0.7107 - val_accuracy: 0.8818\n","\n","Epoch 00260: val_accuracy did not improve from 0.92118\n","Epoch 261/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0362 - accuracy: 0.9878 - val_loss: 0.7800 - val_accuracy: 0.8695\n","\n","Epoch 00261: val_accuracy did not improve from 0.92118\n","Epoch 262/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.7014 - val_accuracy: 0.8054\n","\n","Epoch 00262: val_accuracy did not improve from 0.92118\n","Epoch 263/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0334 - accuracy: 0.9903 - val_loss: 0.9836 - val_accuracy: 0.8424\n","\n","Epoch 00263: val_accuracy did not improve from 0.92118\n","Epoch 264/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0386 - accuracy: 0.9890 - val_loss: 0.9362 - val_accuracy: 0.8153\n","\n","Epoch 00264: val_accuracy did not improve from 0.92118\n","Epoch 265/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0273 - accuracy: 0.9933 - val_loss: 0.7143 - val_accuracy: 0.8695\n","\n","Epoch 00265: val_accuracy did not improve from 0.92118\n","Epoch 266/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.5052 - val_accuracy: 0.8818\n","\n","Epoch 00266: val_accuracy did not improve from 0.92118\n","Epoch 267/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.4157 - val_accuracy: 0.9015\n","\n","Epoch 00267: val_accuracy did not improve from 0.92118\n","Epoch 268/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.5209 - val_accuracy: 0.8695\n","\n","Epoch 00268: val_accuracy did not improve from 0.92118\n","Epoch 269/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0114 - accuracy: 0.9951 - val_loss: 0.5125 - val_accuracy: 0.9064\n","\n","Epoch 00269: val_accuracy did not improve from 0.92118\n","Epoch 270/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.5304 - val_accuracy: 0.9089\n","\n","Epoch 00270: val_accuracy did not improve from 0.92118\n","Epoch 271/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.6483 - val_accuracy: 0.8424\n","\n","Epoch 00271: val_accuracy did not improve from 0.92118\n","Epoch 272/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.7506 - val_accuracy: 0.8227\n","\n","Epoch 00272: val_accuracy did not improve from 0.92118\n","Epoch 273/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.4402 - val_accuracy: 0.9138\n","\n","Epoch 00273: val_accuracy did not improve from 0.92118\n","Epoch 274/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.4865 - val_accuracy: 0.8941\n","\n","Epoch 00274: val_accuracy did not improve from 0.92118\n","Epoch 275/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.4412 - val_accuracy: 0.8966\n","\n","Epoch 00275: val_accuracy did not improve from 0.92118\n","Epoch 276/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0217 - accuracy: 0.9915 - val_loss: 0.5468 - val_accuracy: 0.8842\n","\n","Epoch 00276: val_accuracy did not improve from 0.92118\n","Epoch 277/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0276 - accuracy: 0.9872 - val_loss: 0.7049 - val_accuracy: 0.8473\n","\n","Epoch 00277: val_accuracy did not improve from 0.92118\n","Epoch 278/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0177 - accuracy: 0.9933 - val_loss: 0.7488 - val_accuracy: 0.8547\n","\n","Epoch 00278: val_accuracy did not improve from 0.92118\n","Epoch 279/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.5672 - val_accuracy: 0.8966\n","\n","Epoch 00279: val_accuracy did not improve from 0.92118\n","Epoch 280/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0104 - accuracy: 0.9957 - val_loss: 0.3928 - val_accuracy: 0.9163\n","\n","Epoch 00280: val_accuracy did not improve from 0.92118\n","Epoch 281/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0160 - accuracy: 0.9933 - val_loss: 0.7739 - val_accuracy: 0.8547\n","\n","Epoch 00281: val_accuracy did not improve from 0.92118\n","Epoch 282/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.9221 - val_accuracy: 0.8596\n","\n","Epoch 00282: val_accuracy did not improve from 0.92118\n","Epoch 283/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0182 - accuracy: 0.9927 - val_loss: 0.5169 - val_accuracy: 0.9039\n","\n","Epoch 00283: val_accuracy did not improve from 0.92118\n","Epoch 284/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0162 - accuracy: 0.9970 - val_loss: 0.5240 - val_accuracy: 0.8916\n","\n","Epoch 00284: val_accuracy did not improve from 0.92118\n","Epoch 285/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.5930 - val_accuracy: 0.8842\n","\n","Epoch 00285: val_accuracy did not improve from 0.92118\n","Epoch 286/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0290 - accuracy: 0.9927 - val_loss: 1.4431 - val_accuracy: 0.6847\n","\n","Epoch 00286: val_accuracy did not improve from 0.92118\n","Epoch 287/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.6365 - val_accuracy: 0.8571\n","\n","Epoch 00287: val_accuracy did not improve from 0.92118\n","Epoch 288/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.4495 - val_accuracy: 0.8990\n","\n","Epoch 00288: val_accuracy did not improve from 0.92118\n","Epoch 289/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.5408 - val_accuracy: 0.8744\n","\n","Epoch 00289: val_accuracy did not improve from 0.92118\n","Epoch 290/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.6676 - val_accuracy: 0.8473\n","\n","Epoch 00290: val_accuracy did not improve from 0.92118\n","Epoch 291/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.5070 - val_accuracy: 0.9015\n","\n","Epoch 00291: val_accuracy did not improve from 0.92118\n","Epoch 292/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.6283 - val_accuracy: 0.8941\n","\n","Epoch 00292: val_accuracy did not improve from 0.92118\n","Epoch 293/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0174 - accuracy: 0.9921 - val_loss: 0.6852 - val_accuracy: 0.8842\n","\n","Epoch 00293: val_accuracy did not improve from 0.92118\n","Epoch 294/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 0.6628 - val_accuracy: 0.8793\n","\n","Epoch 00294: val_accuracy did not improve from 0.92118\n","Epoch 295/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.6298 - val_accuracy: 0.8966\n","\n","Epoch 00295: val_accuracy did not improve from 0.92118\n","Epoch 296/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.9093 - val_accuracy: 0.8399\n","\n","Epoch 00296: val_accuracy did not improve from 0.92118\n","Epoch 297/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0225 - accuracy: 0.9909 - val_loss: 0.6612 - val_accuracy: 0.8498\n","\n","Epoch 00297: val_accuracy did not improve from 0.92118\n","Epoch 298/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.5580 - val_accuracy: 0.8695\n","\n","Epoch 00298: val_accuracy did not improve from 0.92118\n","Epoch 299/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.7386 - val_accuracy: 0.8818\n","\n","Epoch 00299: val_accuracy did not improve from 0.92118\n","Epoch 300/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 1.1240 - val_accuracy: 0.7463\n","\n","Epoch 00300: val_accuracy did not improve from 0.92118\n","Epoch 301/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0332 - accuracy: 0.9878 - val_loss: 0.5074 - val_accuracy: 0.9212\n","\n","Epoch 00301: val_accuracy did not improve from 0.92118\n","Epoch 302/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0194 - accuracy: 0.9909 - val_loss: 0.6413 - val_accuracy: 0.8498\n","\n","Epoch 00302: val_accuracy did not improve from 0.92118\n","Epoch 303/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0617 - accuracy: 0.9781 - val_loss: 0.9551 - val_accuracy: 0.8473\n","\n","Epoch 00303: val_accuracy did not improve from 0.92118\n","Epoch 304/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.7402 - val_accuracy: 0.8719\n","\n","Epoch 00304: val_accuracy did not improve from 0.92118\n","Epoch 305/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.6267 - val_accuracy: 0.8892\n","\n","Epoch 00305: val_accuracy did not improve from 0.92118\n","Epoch 306/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.4077 - val_accuracy: 0.9163\n","\n","Epoch 00306: val_accuracy did not improve from 0.92118\n","Epoch 307/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0173 - accuracy: 0.9927 - val_loss: 0.7609 - val_accuracy: 0.8645\n","\n","Epoch 00307: val_accuracy did not improve from 0.92118\n","Epoch 308/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.5214 - val_accuracy: 0.9163\n","\n","Epoch 00308: val_accuracy did not improve from 0.92118\n","Epoch 309/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.8009 - val_accuracy: 0.8892\n","\n","Epoch 00309: val_accuracy did not improve from 0.92118\n","Epoch 310/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.5825 - val_accuracy: 0.8892\n","\n","Epoch 00310: val_accuracy did not improve from 0.92118\n","Epoch 311/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.5915 - val_accuracy: 0.9089\n","\n","Epoch 00311: val_accuracy did not improve from 0.92118\n","Epoch 312/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.4707 - val_accuracy: 0.9113\n","\n","Epoch 00312: val_accuracy did not improve from 0.92118\n","Epoch 313/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.6853 - val_accuracy: 0.8793\n","\n","Epoch 00313: val_accuracy did not improve from 0.92118\n","Epoch 314/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.5665 - val_accuracy: 0.8966\n","\n","Epoch 00314: val_accuracy did not improve from 0.92118\n","Epoch 315/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.6590 - val_accuracy: 0.8842\n","\n","Epoch 00315: val_accuracy did not improve from 0.92118\n","Epoch 316/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.5670 - val_accuracy: 0.9089\n","\n","Epoch 00316: val_accuracy did not improve from 0.92118\n","Epoch 317/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4933 - val_accuracy: 0.8990\n","\n","Epoch 00317: val_accuracy did not improve from 0.92118\n","Epoch 318/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5203 - val_accuracy: 0.9039\n","\n","Epoch 00318: val_accuracy did not improve from 0.92118\n","Epoch 319/500\n","52/52 [==============================] - 20s 385ms/step - loss: 8.1493e-04 - accuracy: 1.0000 - val_loss: 0.5249 - val_accuracy: 0.8990\n","\n","Epoch 00319: val_accuracy did not improve from 0.92118\n","Epoch 320/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.9039\n","\n","Epoch 00320: val_accuracy did not improve from 0.92118\n","Epoch 321/500\n","52/52 [==============================] - 20s 385ms/step - loss: 9.7158e-04 - accuracy: 1.0000 - val_loss: 0.5311 - val_accuracy: 0.8990\n","\n","Epoch 00321: val_accuracy did not improve from 0.92118\n","Epoch 322/500\n","52/52 [==============================] - 20s 385ms/step - loss: 6.8465e-04 - accuracy: 1.0000 - val_loss: 0.5192 - val_accuracy: 0.9089\n","\n","Epoch 00322: val_accuracy did not improve from 0.92118\n","Epoch 323/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.6347 - val_accuracy: 0.9113\n","\n","Epoch 00323: val_accuracy did not improve from 0.92118\n","Epoch 324/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.7858 - val_accuracy: 0.8276\n","\n","Epoch 00324: val_accuracy did not improve from 0.92118\n","Epoch 325/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5759 - val_accuracy: 0.9015\n","\n","Epoch 00325: val_accuracy did not improve from 0.92118\n","Epoch 326/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.7851 - val_accuracy: 0.8719\n","\n","Epoch 00326: val_accuracy did not improve from 0.92118\n","Epoch 327/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 1.1069 - val_accuracy: 0.7488\n","\n","Epoch 00327: val_accuracy did not improve from 0.92118\n","Epoch 328/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0077 - accuracy: 0.9963 - val_loss: 0.6469 - val_accuracy: 0.8793\n","\n","Epoch 00328: val_accuracy did not improve from 0.92118\n","Epoch 329/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0405 - accuracy: 0.9884 - val_loss: 1.5140 - val_accuracy: 0.6404\n","\n","Epoch 00329: val_accuracy did not improve from 0.92118\n","Epoch 330/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0624 - accuracy: 0.9836 - val_loss: 2.1477 - val_accuracy: 0.7118\n","\n","Epoch 00330: val_accuracy did not improve from 0.92118\n","Epoch 331/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0641 - accuracy: 0.9823 - val_loss: 1.3471 - val_accuracy: 0.8153\n","\n","Epoch 00331: val_accuracy did not improve from 0.92118\n","Epoch 332/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0291 - accuracy: 0.9921 - val_loss: 1.0581 - val_accuracy: 0.8276\n","\n","Epoch 00332: val_accuracy did not improve from 0.92118\n","Epoch 333/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.8328 - val_accuracy: 0.8276\n","\n","Epoch 00333: val_accuracy did not improve from 0.92118\n","Epoch 334/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.7627 - val_accuracy: 0.8670\n","\n","Epoch 00334: val_accuracy did not improve from 0.92118\n","Epoch 335/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.5479 - val_accuracy: 0.8966\n","\n","Epoch 00335: val_accuracy did not improve from 0.92118\n","Epoch 336/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.5491 - val_accuracy: 0.8892\n","\n","Epoch 00336: val_accuracy did not improve from 0.92118\n","Epoch 337/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.5365 - val_accuracy: 0.9064\n","\n","Epoch 00337: val_accuracy did not improve from 0.92118\n","Epoch 338/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.5979 - val_accuracy: 0.8941\n","\n","Epoch 00338: val_accuracy did not improve from 0.92118\n","Epoch 339/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0390 - accuracy: 0.9884 - val_loss: 1.8232 - val_accuracy: 0.6478\n","\n","Epoch 00339: val_accuracy did not improve from 0.92118\n","Epoch 340/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0424 - accuracy: 0.9854 - val_loss: 0.8234 - val_accuracy: 0.8645\n","\n","Epoch 00340: val_accuracy did not improve from 0.92118\n","Epoch 341/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0202 - accuracy: 0.9927 - val_loss: 0.6405 - val_accuracy: 0.8621\n","\n","Epoch 00341: val_accuracy did not improve from 0.92118\n","Epoch 342/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0089 - accuracy: 0.9988 - val_loss: 0.4293 - val_accuracy: 0.9113\n","\n","Epoch 00342: val_accuracy did not improve from 0.92118\n","Epoch 343/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.5090 - val_accuracy: 0.9163\n","\n","Epoch 00343: val_accuracy did not improve from 0.92118\n","Epoch 344/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.6369 - val_accuracy: 0.8744\n","\n","Epoch 00344: val_accuracy did not improve from 0.92118\n","Epoch 345/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0382 - accuracy: 0.9896 - val_loss: 1.1428 - val_accuracy: 0.7709\n","\n","Epoch 00345: val_accuracy did not improve from 0.92118\n","Epoch 346/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.6707 - val_accuracy: 0.8350\n","\n","Epoch 00346: val_accuracy did not improve from 0.92118\n","Epoch 347/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0254 - accuracy: 0.9896 - val_loss: 1.0862 - val_accuracy: 0.7882\n","\n","Epoch 00347: val_accuracy did not improve from 0.92118\n","Epoch 348/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 1.7254 - val_accuracy: 0.6601\n","\n","Epoch 00348: val_accuracy did not improve from 0.92118\n","Epoch 349/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0174 - accuracy: 0.9957 - val_loss: 1.2825 - val_accuracy: 0.7069\n","\n","Epoch 00349: val_accuracy did not improve from 0.92118\n","Epoch 350/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0101 - accuracy: 0.9957 - val_loss: 0.5715 - val_accuracy: 0.8768\n","\n","Epoch 00350: val_accuracy did not improve from 0.92118\n","Epoch 351/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.8677 - val_accuracy: 0.8251\n","\n","Epoch 00351: val_accuracy did not improve from 0.92118\n","Epoch 352/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.6181 - val_accuracy: 0.8571\n","\n","Epoch 00352: val_accuracy did not improve from 0.92118\n","Epoch 353/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.5679 - val_accuracy: 0.8818\n","\n","Epoch 00353: val_accuracy did not improve from 0.92118\n","Epoch 354/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5404 - val_accuracy: 0.8768\n","\n","Epoch 00354: val_accuracy did not improve from 0.92118\n","Epoch 355/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5742 - val_accuracy: 0.8842\n","\n","Epoch 00355: val_accuracy did not improve from 0.92118\n","Epoch 356/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.6620 - val_accuracy: 0.8818\n","\n","Epoch 00356: val_accuracy did not improve from 0.92118\n","Epoch 357/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.5085 - val_accuracy: 0.9064\n","\n","Epoch 00357: val_accuracy did not improve from 0.92118\n","Epoch 358/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9064\n","\n","Epoch 00358: val_accuracy did not improve from 0.92118\n","Epoch 359/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.6067 - val_accuracy: 0.9015\n","\n","Epoch 00359: val_accuracy did not improve from 0.92118\n","Epoch 360/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.6043 - val_accuracy: 0.8916\n","\n","Epoch 00360: val_accuracy did not improve from 0.92118\n","Epoch 361/500\n","52/52 [==============================] - 20s 385ms/step - loss: 8.5363e-04 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.9064\n","\n","Epoch 00361: val_accuracy did not improve from 0.92118\n","Epoch 362/500\n","52/52 [==============================] - 20s 385ms/step - loss: 6.3283e-04 - accuracy: 1.0000 - val_loss: 0.5986 - val_accuracy: 0.8990\n","\n","Epoch 00362: val_accuracy did not improve from 0.92118\n","Epoch 363/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5788 - val_accuracy: 0.9064\n","\n","Epoch 00363: val_accuracy did not improve from 0.92118\n","Epoch 364/500\n","52/52 [==============================] - 20s 384ms/step - loss: 8.7728e-04 - accuracy: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.9113\n","\n","Epoch 00364: val_accuracy did not improve from 0.92118\n","Epoch 365/500\n","52/52 [==============================] - 20s 386ms/step - loss: 3.2367e-04 - accuracy: 1.0000 - val_loss: 0.5517 - val_accuracy: 0.9138\n","\n","Epoch 00365: val_accuracy did not improve from 0.92118\n","Epoch 366/500\n","52/52 [==============================] - 20s 385ms/step - loss: 4.9954e-04 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.9163\n","\n","Epoch 00366: val_accuracy did not improve from 0.92118\n","Epoch 367/500\n","52/52 [==============================] - 20s 385ms/step - loss: 4.6597e-04 - accuracy: 1.0000 - val_loss: 0.5279 - val_accuracy: 0.9015\n","\n","Epoch 00367: val_accuracy did not improve from 0.92118\n","Epoch 368/500\n","52/52 [==============================] - 20s 385ms/step - loss: 4.3465e-04 - accuracy: 1.0000 - val_loss: 0.6348 - val_accuracy: 0.9064\n","\n","Epoch 00368: val_accuracy did not improve from 0.92118\n","Epoch 369/500\n","52/52 [==============================] - 20s 384ms/step - loss: 2.4399e-04 - accuracy: 1.0000 - val_loss: 0.5018 - val_accuracy: 0.9212\n","\n","Epoch 00369: val_accuracy did not improve from 0.92118\n","Epoch 370/500\n","52/52 [==============================] - 20s 386ms/step - loss: 2.4582e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.9236\n","\n","Epoch 00370: val_accuracy improved from 0.92118 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 371/500\n","52/52 [==============================] - 20s 385ms/step - loss: 4.0543e-04 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.9163\n","\n","Epoch 00371: val_accuracy did not improve from 0.92365\n","Epoch 372/500\n","52/52 [==============================] - 20s 385ms/step - loss: 3.4236e-04 - accuracy: 1.0000 - val_loss: 0.5523 - val_accuracy: 0.9138\n","\n","Epoch 00372: val_accuracy did not improve from 0.92365\n","Epoch 373/500\n","52/52 [==============================] - 20s 386ms/step - loss: 3.3176e-04 - accuracy: 1.0000 - val_loss: 0.5929 - val_accuracy: 0.9163\n","\n","Epoch 00373: val_accuracy did not improve from 0.92365\n","Epoch 374/500\n","52/52 [==============================] - 20s 384ms/step - loss: 2.4863e-04 - accuracy: 1.0000 - val_loss: 0.6033 - val_accuracy: 0.9039\n","\n","Epoch 00374: val_accuracy did not improve from 0.92365\n","Epoch 375/500\n","52/52 [==============================] - 20s 383ms/step - loss: 2.1336e-04 - accuracy: 1.0000 - val_loss: 0.5793 - val_accuracy: 0.9039\n","\n","Epoch 00375: val_accuracy did not improve from 0.92365\n","Epoch 376/500\n","52/52 [==============================] - 20s 384ms/step - loss: 3.3776e-04 - accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.9212\n","\n","Epoch 00376: val_accuracy did not improve from 0.92365\n","Epoch 377/500\n","52/52 [==============================] - 20s 385ms/step - loss: 4.4726e-04 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.9113\n","\n","Epoch 00377: val_accuracy did not improve from 0.92365\n","Epoch 378/500\n","52/52 [==============================] - 20s 384ms/step - loss: 3.2821e-04 - accuracy: 1.0000 - val_loss: 0.6534 - val_accuracy: 0.8990\n","\n","Epoch 00378: val_accuracy did not improve from 0.92365\n","Epoch 379/500\n","52/52 [==============================] - 20s 389ms/step - loss: 6.1320e-05 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 0.9064\n","\n","Epoch 00379: val_accuracy did not improve from 0.92365\n","Epoch 380/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.8733e-04 - accuracy: 1.0000 - val_loss: 0.5676 - val_accuracy: 0.9187\n","\n","Epoch 00380: val_accuracy did not improve from 0.92365\n","Epoch 381/500\n","52/52 [==============================] - 20s 386ms/step - loss: 9.0911e-05 - accuracy: 1.0000 - val_loss: 0.5440 - val_accuracy: 0.9089\n","\n","Epoch 00381: val_accuracy did not improve from 0.92365\n","Epoch 382/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6254 - val_accuracy: 0.8793\n","\n","Epoch 00382: val_accuracy did not improve from 0.92365\n","Epoch 383/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.8596\n","\n","Epoch 00383: val_accuracy did not improve from 0.92365\n","Epoch 384/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.6401 - val_accuracy: 0.8596\n","\n","Epoch 00384: val_accuracy did not improve from 0.92365\n","Epoch 385/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0777 - accuracy: 0.9750 - val_loss: 1.9010 - val_accuracy: 0.7414\n","\n","Epoch 00385: val_accuracy did not improve from 0.92365\n","Epoch 386/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2480 - accuracy: 0.9306 - val_loss: 2.5473 - val_accuracy: 0.6527\n","\n","Epoch 00386: val_accuracy did not improve from 0.92365\n","Epoch 387/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1298 - accuracy: 0.9598 - val_loss: 1.5552 - val_accuracy: 0.6946\n","\n","Epoch 00387: val_accuracy did not improve from 0.92365\n","Epoch 388/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0240 - accuracy: 0.9884 - val_loss: 1.1873 - val_accuracy: 0.7389\n","\n","Epoch 00388: val_accuracy did not improve from 0.92365\n","Epoch 389/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.4806 - val_accuracy: 0.8842\n","\n","Epoch 00389: val_accuracy did not improve from 0.92365\n","Epoch 390/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.6030 - val_accuracy: 0.8424\n","\n","Epoch 00390: val_accuracy did not improve from 0.92365\n","Epoch 391/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.4820 - val_accuracy: 0.8916\n","\n","Epoch 00391: val_accuracy did not improve from 0.92365\n","Epoch 392/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.4970 - val_accuracy: 0.8916\n","\n","Epoch 00392: val_accuracy did not improve from 0.92365\n","Epoch 393/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.3773 - val_accuracy: 0.9261\n","\n","Epoch 00393: val_accuracy improved from 0.92365 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 394/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4412 - val_accuracy: 0.9163\n","\n","Epoch 00394: val_accuracy did not improve from 0.92611\n","Epoch 395/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.4801 - val_accuracy: 0.8892\n","\n","Epoch 00395: val_accuracy did not improve from 0.92611\n","Epoch 396/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.5776 - val_accuracy: 0.8941\n","\n","Epoch 00396: val_accuracy did not improve from 0.92611\n","Epoch 397/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.7287 - val_accuracy: 0.8768\n","\n","Epoch 00397: val_accuracy did not improve from 0.92611\n","Epoch 398/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.6264 - val_accuracy: 0.8941\n","\n","Epoch 00398: val_accuracy did not improve from 0.92611\n","Epoch 399/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.7255 - val_accuracy: 0.8695\n","\n","Epoch 00399: val_accuracy did not improve from 0.92611\n","Epoch 400/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.6352 - val_accuracy: 0.8892\n","\n","Epoch 00400: val_accuracy did not improve from 0.92611\n","Epoch 401/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4681 - val_accuracy: 0.9015\n","\n","Epoch 00401: val_accuracy did not improve from 0.92611\n","Epoch 402/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5620 - val_accuracy: 0.9039\n","\n","Epoch 00402: val_accuracy did not improve from 0.92611\n","Epoch 403/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9015\n","\n","Epoch 00403: val_accuracy did not improve from 0.92611\n","Epoch 404/500\n","52/52 [==============================] - 20s 383ms/step - loss: 6.3393e-04 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.9113\n","\n","Epoch 00404: val_accuracy did not improve from 0.92611\n","Epoch 405/500\n","52/52 [==============================] - 20s 386ms/step - loss: 6.6401e-04 - accuracy: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.9187\n","\n","Epoch 00405: val_accuracy did not improve from 0.92611\n","Epoch 406/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5179 - val_accuracy: 0.9064\n","\n","Epoch 00406: val_accuracy did not improve from 0.92611\n","Epoch 407/500\n","52/52 [==============================] - 20s 383ms/step - loss: 7.2690e-04 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9039\n","\n","Epoch 00407: val_accuracy did not improve from 0.92611\n","Epoch 408/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4639 - val_accuracy: 0.9163\n","\n","Epoch 00408: val_accuracy did not improve from 0.92611\n","Epoch 409/500\n","52/52 [==============================] - 20s 384ms/step - loss: 8.3212e-04 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.9138\n","\n","Epoch 00409: val_accuracy did not improve from 0.92611\n","Epoch 410/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.9138\n","\n","Epoch 00410: val_accuracy did not improve from 0.92611\n","Epoch 411/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.9163\n","\n","Epoch 00411: val_accuracy did not improve from 0.92611\n","Epoch 412/500\n","52/52 [==============================] - 20s 385ms/step - loss: 9.3867e-04 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.9089\n","\n","Epoch 00412: val_accuracy did not improve from 0.92611\n","Epoch 413/500\n","52/52 [==============================] - 20s 384ms/step - loss: 6.8206e-04 - accuracy: 1.0000 - val_loss: 0.3845 - val_accuracy: 0.9187\n","\n","Epoch 00413: val_accuracy did not improve from 0.92611\n","Epoch 414/500\n","52/52 [==============================] - 20s 384ms/step - loss: 4.9521e-04 - accuracy: 1.0000 - val_loss: 0.5064 - val_accuracy: 0.9113\n","\n","Epoch 00414: val_accuracy did not improve from 0.92611\n","Epoch 415/500\n","52/52 [==============================] - 20s 386ms/step - loss: 3.6916e-04 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.9064\n","\n","Epoch 00415: val_accuracy did not improve from 0.92611\n","Epoch 416/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4594 - val_accuracy: 0.9163\n","\n","Epoch 00416: val_accuracy did not improve from 0.92611\n","Epoch 417/500\n","52/52 [==============================] - 20s 385ms/step - loss: 9.5912e-04 - accuracy: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.9384\n","\n","Epoch 00417: val_accuracy improved from 0.92611 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5\n","Epoch 418/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.6249 - val_accuracy: 0.8744\n","\n","Epoch 00418: val_accuracy did not improve from 0.93842\n","Epoch 419/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5156 - val_accuracy: 0.9163\n","\n","Epoch 00419: val_accuracy did not improve from 0.93842\n","Epoch 420/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.6783 - val_accuracy: 0.9064\n","\n","Epoch 00420: val_accuracy did not improve from 0.93842\n","Epoch 421/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.5908 - val_accuracy: 0.8793\n","\n","Epoch 00421: val_accuracy did not improve from 0.93842\n","Epoch 422/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.6057 - val_accuracy: 0.9039\n","\n","Epoch 00422: val_accuracy did not improve from 0.93842\n","Epoch 423/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.9194 - val_accuracy: 0.8596\n","\n","Epoch 00423: val_accuracy did not improve from 0.93842\n","Epoch 424/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5241 - val_accuracy: 0.9064\n","\n","Epoch 00424: val_accuracy did not improve from 0.93842\n","Epoch 425/500\n","52/52 [==============================] - 20s 385ms/step - loss: 7.2288e-04 - accuracy: 1.0000 - val_loss: 0.5412 - val_accuracy: 0.9064\n","\n","Epoch 00425: val_accuracy did not improve from 0.93842\n","Epoch 426/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.9089\n","\n","Epoch 00426: val_accuracy did not improve from 0.93842\n","Epoch 427/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5413 - val_accuracy: 0.8990\n","\n","Epoch 00427: val_accuracy did not improve from 0.93842\n","Epoch 428/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.6988 - val_accuracy: 0.8768\n","\n","Epoch 00428: val_accuracy did not improve from 0.93842\n","Epoch 429/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6683 - val_accuracy: 0.8916\n","\n","Epoch 00429: val_accuracy did not improve from 0.93842\n","Epoch 430/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.6032 - val_accuracy: 0.8867\n","\n","Epoch 00430: val_accuracy did not improve from 0.93842\n","Epoch 431/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0252 - accuracy: 0.9909 - val_loss: 1.2981 - val_accuracy: 0.8005\n","\n","Epoch 00431: val_accuracy did not improve from 0.93842\n","Epoch 432/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0567 - accuracy: 0.9854 - val_loss: 1.5838 - val_accuracy: 0.7217\n","\n","Epoch 00432: val_accuracy did not improve from 0.93842\n","Epoch 433/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0292 - accuracy: 0.9915 - val_loss: 0.9501 - val_accuracy: 0.7980\n","\n","Epoch 00433: val_accuracy did not improve from 0.93842\n","Epoch 434/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0343 - accuracy: 0.9890 - val_loss: 0.6403 - val_accuracy: 0.8941\n","\n","Epoch 00434: val_accuracy did not improve from 0.93842\n","Epoch 435/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0324 - accuracy: 0.9884 - val_loss: 0.9056 - val_accuracy: 0.8522\n","\n","Epoch 00435: val_accuracy did not improve from 0.93842\n","Epoch 436/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0325 - accuracy: 0.9890 - val_loss: 0.7671 - val_accuracy: 0.8744\n","\n","Epoch 00436: val_accuracy did not improve from 0.93842\n","Epoch 437/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.6373 - val_accuracy: 0.8596\n","\n","Epoch 00437: val_accuracy did not improve from 0.93842\n","Epoch 438/500\n","52/52 [==============================] - 21s 400ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.4484 - val_accuracy: 0.9064\n","\n","Epoch 00438: val_accuracy did not improve from 0.93842\n","Epoch 439/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.5726 - val_accuracy: 0.8941\n","\n","Epoch 00439: val_accuracy did not improve from 0.93842\n","Epoch 440/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.6334 - val_accuracy: 0.8695\n","\n","Epoch 00440: val_accuracy did not improve from 0.93842\n","Epoch 441/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.8242 - val_accuracy: 0.8276\n","\n","Epoch 00441: val_accuracy did not improve from 0.93842\n","Epoch 442/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0228 - accuracy: 0.9957 - val_loss: 0.6974 - val_accuracy: 0.8768\n","\n","Epoch 00442: val_accuracy did not improve from 0.93842\n","Epoch 443/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 0.6471 - val_accuracy: 0.8596\n","\n","Epoch 00443: val_accuracy did not improve from 0.93842\n","Epoch 444/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 1.0251 - val_accuracy: 0.8547\n","\n","Epoch 00444: val_accuracy did not improve from 0.93842\n","Epoch 445/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.7761 - val_accuracy: 0.8842\n","\n","Epoch 00445: val_accuracy did not improve from 0.93842\n","Epoch 446/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.7953 - val_accuracy: 0.8621\n","\n","Epoch 00446: val_accuracy did not improve from 0.93842\n","Epoch 447/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5336 - val_accuracy: 0.8916\n","\n","Epoch 00447: val_accuracy did not improve from 0.93842\n","Epoch 448/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.5808 - val_accuracy: 0.8941\n","\n","Epoch 00448: val_accuracy did not improve from 0.93842\n","Epoch 449/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.7576 - val_accuracy: 0.8719\n","\n","Epoch 00449: val_accuracy did not improve from 0.93842\n","Epoch 450/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.6806 - val_accuracy: 0.8448\n","\n","Epoch 00450: val_accuracy did not improve from 0.93842\n","Epoch 451/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.5847 - val_accuracy: 0.8547\n","\n","Epoch 00451: val_accuracy did not improve from 0.93842\n","Epoch 452/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 0.6218 - val_accuracy: 0.9039\n","\n","Epoch 00452: val_accuracy did not improve from 0.93842\n","Epoch 453/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7031 - val_accuracy: 0.8892\n","\n","Epoch 00453: val_accuracy did not improve from 0.93842\n","Epoch 454/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5809 - val_accuracy: 0.8793\n","\n","Epoch 00454: val_accuracy did not improve from 0.93842\n","Epoch 455/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0400 - accuracy: 0.9909 - val_loss: 1.4448 - val_accuracy: 0.7734\n","\n","Epoch 00455: val_accuracy did not improve from 0.93842\n","Epoch 456/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0454 - accuracy: 0.9854 - val_loss: 0.7853 - val_accuracy: 0.8498\n","\n","Epoch 00456: val_accuracy did not improve from 0.93842\n","Epoch 457/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0303 - accuracy: 0.9921 - val_loss: 0.8775 - val_accuracy: 0.7882\n","\n","Epoch 00457: val_accuracy did not improve from 0.93842\n","Epoch 458/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.6745 - val_accuracy: 0.8571\n","\n","Epoch 00458: val_accuracy did not improve from 0.93842\n","Epoch 459/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 0.4883 - val_accuracy: 0.9064\n","\n","Epoch 00459: val_accuracy did not improve from 0.93842\n","Epoch 460/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.6611 - val_accuracy: 0.9015\n","\n","Epoch 00460: val_accuracy did not improve from 0.93842\n","Epoch 461/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.8990\n","\n","Epoch 00461: val_accuracy did not improve from 0.93842\n","Epoch 462/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4894 - val_accuracy: 0.8990\n","\n","Epoch 00462: val_accuracy did not improve from 0.93842\n","Epoch 463/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.9039\n","\n","Epoch 00463: val_accuracy did not improve from 0.93842\n","Epoch 464/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5830 - val_accuracy: 0.8916\n","\n","Epoch 00464: val_accuracy did not improve from 0.93842\n","Epoch 465/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5224 - val_accuracy: 0.9212\n","\n","Epoch 00465: val_accuracy did not improve from 0.93842\n","Epoch 466/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.6609 - val_accuracy: 0.8719\n","\n","Epoch 00466: val_accuracy did not improve from 0.93842\n","Epoch 467/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.5916 - val_accuracy: 0.8842\n","\n","Epoch 00467: val_accuracy did not improve from 0.93842\n","Epoch 468/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.7276 - val_accuracy: 0.8424\n","\n","Epoch 00468: val_accuracy did not improve from 0.93842\n","Epoch 469/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0392 - accuracy: 0.9866 - val_loss: 1.6585 - val_accuracy: 0.7833\n","\n","Epoch 00469: val_accuracy did not improve from 0.93842\n","Epoch 470/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0338 - accuracy: 0.9890 - val_loss: 0.9866 - val_accuracy: 0.8399\n","\n","Epoch 00470: val_accuracy did not improve from 0.93842\n","Epoch 471/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.7276 - val_accuracy: 0.8793\n","\n","Epoch 00471: val_accuracy did not improve from 0.93842\n","Epoch 472/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.8923 - val_accuracy: 0.7980\n","\n","Epoch 00472: val_accuracy did not improve from 0.93842\n","Epoch 473/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.9359 - val_accuracy: 0.7980\n","\n","Epoch 00473: val_accuracy did not improve from 0.93842\n","Epoch 474/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0261 - accuracy: 0.9927 - val_loss: 0.7628 - val_accuracy: 0.8818\n","\n","Epoch 00474: val_accuracy did not improve from 0.93842\n","Epoch 475/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.6632 - val_accuracy: 0.8990\n","\n","Epoch 00475: val_accuracy did not improve from 0.93842\n","Epoch 476/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.4405 - val_accuracy: 0.9310\n","\n","Epoch 00476: val_accuracy did not improve from 0.93842\n","Epoch 477/500\n","52/52 [==============================] - 20s 384ms/step - loss: 7.8517e-04 - accuracy: 1.0000 - val_loss: 0.6166 - val_accuracy: 0.9113\n","\n","Epoch 00477: val_accuracy did not improve from 0.93842\n","Epoch 478/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6508 - val_accuracy: 0.9039\n","\n","Epoch 00478: val_accuracy did not improve from 0.93842\n","Epoch 479/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5085 - val_accuracy: 0.9187\n","\n","Epoch 00479: val_accuracy did not improve from 0.93842\n","Epoch 480/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.9089\n","\n","Epoch 00480: val_accuracy did not improve from 0.93842\n","Epoch 481/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5349 - val_accuracy: 0.8966\n","\n","Epoch 00481: val_accuracy did not improve from 0.93842\n","Epoch 482/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.4492 - val_accuracy: 0.9163\n","\n","Epoch 00482: val_accuracy did not improve from 0.93842\n","Epoch 483/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4614 - val_accuracy: 0.9089\n","\n","Epoch 00483: val_accuracy did not improve from 0.93842\n","Epoch 484/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.9138\n","\n","Epoch 00484: val_accuracy did not improve from 0.93842\n","Epoch 485/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5253 - val_accuracy: 0.9064\n","\n","Epoch 00485: val_accuracy did not improve from 0.93842\n","Epoch 486/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.7266 - val_accuracy: 0.8916\n","\n","Epoch 00486: val_accuracy did not improve from 0.93842\n","Epoch 487/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6208 - val_accuracy: 0.9113\n","\n","Epoch 00487: val_accuracy did not improve from 0.93842\n","Epoch 488/500\n","52/52 [==============================] - 20s 385ms/step - loss: 8.3372e-04 - accuracy: 1.0000 - val_loss: 0.5997 - val_accuracy: 0.9039\n","\n","Epoch 00488: val_accuracy did not improve from 0.93842\n","Epoch 489/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.7536 - val_accuracy: 0.8941\n","\n","Epoch 00489: val_accuracy did not improve from 0.93842\n","Epoch 490/500\n","52/52 [==============================] - 20s 386ms/step - loss: 9.1647e-04 - accuracy: 1.0000 - val_loss: 0.6241 - val_accuracy: 0.9089\n","\n","Epoch 00490: val_accuracy did not improve from 0.93842\n","Epoch 491/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5336 - val_accuracy: 0.9113\n","\n","Epoch 00491: val_accuracy did not improve from 0.93842\n","Epoch 492/500\n","52/52 [==============================] - 20s 385ms/step - loss: 6.2825e-04 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.9138\n","\n","Epoch 00492: val_accuracy did not improve from 0.93842\n","Epoch 493/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.6708 - val_accuracy: 0.8300\n","\n","Epoch 00493: val_accuracy did not improve from 0.93842\n","Epoch 494/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0079 - accuracy: 0.9957 - val_loss: 0.5247 - val_accuracy: 0.8990\n","\n","Epoch 00494: val_accuracy did not improve from 0.93842\n","Epoch 495/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 1.3655 - val_accuracy: 0.7143\n","\n","Epoch 00495: val_accuracy did not improve from 0.93842\n","Epoch 496/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0463 - accuracy: 0.9860 - val_loss: 1.0199 - val_accuracy: 0.8079\n","\n","Epoch 00496: val_accuracy did not improve from 0.93842\n","Epoch 497/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 1.0279 - val_accuracy: 0.8424\n","\n","Epoch 00497: val_accuracy did not improve from 0.93842\n","Epoch 498/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0301 - accuracy: 0.9884 - val_loss: 0.8296 - val_accuracy: 0.8571\n","\n","Epoch 00498: val_accuracy did not improve from 0.93842\n","Epoch 499/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.7051 - val_accuracy: 0.8916\n","\n","Epoch 00499: val_accuracy did not improve from 0.93842\n","Epoch 500/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 1.0778 - val_accuracy: 0.7365\n","\n","Epoch 00500: val_accuracy did not improve from 0.93842\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5b59418c50>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1629914325729,"user_tz":-540,"elapsed":21,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ccb77fed-c1be-4fd7-87d0-a72134b322be"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1629914345423,"user_tz":-540,"elapsed":19317,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_4_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1629914346087,"user_tz":-540,"elapsed":681,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629914346524,"user_tz":-540,"elapsed":441,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c51a8760-d604-4d02-8265-bb5c519309d0"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Found 20480 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629914401826,"user_tz":-540,"elapsed":55305,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"78595493-ee3e-4ec3-8332-ca10f8282fac"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1629914402221,"user_tz":-540,"elapsed":398,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1629914402221,"user_tz":-540,"elapsed":3,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1629914403097,"user_tz":-540,"elapsed":878,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1629914403099,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1629914414869,"user_tz":-540,"elapsed":11774,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1629914414878,"user_tz":-540,"elapsed":23,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"64cf54f0-d37a-444d-df5f-eb0e5b3b284b"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1629914414879,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"9e324bd1-f06d-49c6-f3a0-3c2a9d34cee9"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_25_4_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_25_4_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_be87d49d-2a5a-4a6b-80bf-5b0b1aff4b2c\", \"Rotation_range_25_4_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}