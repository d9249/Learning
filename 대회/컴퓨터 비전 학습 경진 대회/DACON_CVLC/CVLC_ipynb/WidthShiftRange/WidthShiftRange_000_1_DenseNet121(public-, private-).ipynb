{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WidthShiftRange_000_1_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyN6o/UGLiBI/RtEhKYXonpf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629921773190,"user_tz":-540,"elapsed":397,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"f94905fd-e914-405f-b254-c9c3ada286ce"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Wed Aug 25 20:02:52 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629921789967,"user_tz":-540,"elapsed":16784,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"3c1a70ec-2371-449f-f289-df5124148633"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1629921794029,"user_tz":-540,"elapsed":3625,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1629921795302,"user_tz":-540,"elapsed":1275,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1629921797785,"user_tz":-540,"elapsed":2485,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1629921814936,"user_tz":-540,"elapsed":17152,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1629921821801,"user_tz":-540,"elapsed":6867,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629921821803,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"a3a8db2c-bc80-4e31-fe39-e843d16ce2aa"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629921821805,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0c97169f-5d0c-4022-be38-e54deb6cd741"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.0,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1629921822296,"user_tz":-540,"elapsed":501,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629932141729,"user_tz":-540,"elapsed":10319438,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"afdab878-c559-48b7-f3b9-802f77a7a83f"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 54s 475ms/step - loss: 1.8187 - accuracy: 0.3727 - val_loss: 5.5214 - val_accuracy: 0.0985\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.1518 - accuracy: 0.6114 - val_loss: 17.8118 - val_accuracy: 0.1010\n","\n","Epoch 00002: val_accuracy improved from 0.09852 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 3/500\n","52/52 [==============================] - 20s 373ms/step - loss: 0.9137 - accuracy: 0.6955 - val_loss: 6.2186 - val_accuracy: 0.1379\n","\n","Epoch 00003: val_accuracy improved from 0.10099 to 0.13793, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 4/500\n","52/52 [==============================] - 20s 375ms/step - loss: 0.8007 - accuracy: 0.7302 - val_loss: 13.9559 - val_accuracy: 0.0961\n","\n","Epoch 00004: val_accuracy did not improve from 0.13793\n","Epoch 5/500\n","52/52 [==============================] - 20s 376ms/step - loss: 0.6830 - accuracy: 0.7783 - val_loss: 7.0252 - val_accuracy: 0.1404\n","\n","Epoch 00005: val_accuracy improved from 0.13793 to 0.14039, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.6782 - accuracy: 0.7777 - val_loss: 11.4047 - val_accuracy: 0.1330\n","\n","Epoch 00006: val_accuracy did not improve from 0.14039\n","Epoch 7/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.5575 - accuracy: 0.8009 - val_loss: 7.5633 - val_accuracy: 0.2143\n","\n","Epoch 00007: val_accuracy improved from 0.14039 to 0.21429, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.5333 - accuracy: 0.8234 - val_loss: 3.6087 - val_accuracy: 0.3670\n","\n","Epoch 00008: val_accuracy improved from 0.21429 to 0.36700, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.4611 - accuracy: 0.8435 - val_loss: 1.5294 - val_accuracy: 0.5936\n","\n","Epoch 00009: val_accuracy improved from 0.36700 to 0.59360, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.5107 - accuracy: 0.8343 - val_loss: 1.0111 - val_accuracy: 0.7315\n","\n","Epoch 00010: val_accuracy improved from 0.59360 to 0.73153, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3859 - accuracy: 0.8654 - val_loss: 1.2163 - val_accuracy: 0.6749\n","\n","Epoch 00011: val_accuracy did not improve from 0.73153\n","Epoch 12/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.3465 - accuracy: 0.8819 - val_loss: 1.0527 - val_accuracy: 0.6823\n","\n","Epoch 00012: val_accuracy did not improve from 0.73153\n","Epoch 13/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.3410 - accuracy: 0.8946 - val_loss: 0.9080 - val_accuracy: 0.7094\n","\n","Epoch 00013: val_accuracy did not improve from 0.73153\n","Epoch 14/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.3554 - accuracy: 0.8672 - val_loss: 0.9173 - val_accuracy: 0.7537\n","\n","Epoch 00014: val_accuracy improved from 0.73153 to 0.75369, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 15/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.3075 - accuracy: 0.8946 - val_loss: 0.6175 - val_accuracy: 0.8177\n","\n","Epoch 00015: val_accuracy improved from 0.75369 to 0.81773, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 16/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.2628 - accuracy: 0.9099 - val_loss: 0.6805 - val_accuracy: 0.8054\n","\n","Epoch 00016: val_accuracy did not improve from 0.81773\n","Epoch 17/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.2726 - accuracy: 0.9135 - val_loss: 0.9779 - val_accuracy: 0.7414\n","\n","Epoch 00017: val_accuracy did not improve from 0.81773\n","Epoch 18/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.2954 - accuracy: 0.9013 - val_loss: 0.7070 - val_accuracy: 0.8153\n","\n","Epoch 00018: val_accuracy did not improve from 0.81773\n","Epoch 19/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.2512 - accuracy: 0.9099 - val_loss: 0.8290 - val_accuracy: 0.7463\n","\n","Epoch 00019: val_accuracy did not improve from 0.81773\n","Epoch 20/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.3225 - accuracy: 0.8879 - val_loss: 1.4007 - val_accuracy: 0.6872\n","\n","Epoch 00020: val_accuracy did not improve from 0.81773\n","Epoch 21/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.2219 - accuracy: 0.9166 - val_loss: 0.7032 - val_accuracy: 0.8128\n","\n","Epoch 00021: val_accuracy did not improve from 0.81773\n","Epoch 22/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.2285 - accuracy: 0.9233 - val_loss: 0.8556 - val_accuracy: 0.7759\n","\n","Epoch 00022: val_accuracy did not improve from 0.81773\n","Epoch 23/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.2104 - accuracy: 0.9281 - val_loss: 0.7795 - val_accuracy: 0.7857\n","\n","Epoch 00023: val_accuracy did not improve from 0.81773\n","Epoch 24/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1870 - accuracy: 0.9361 - val_loss: 0.7047 - val_accuracy: 0.8350\n","\n","Epoch 00024: val_accuracy improved from 0.81773 to 0.83498, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 25/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1784 - accuracy: 0.9361 - val_loss: 0.8551 - val_accuracy: 0.7094\n","\n","Epoch 00025: val_accuracy did not improve from 0.83498\n","Epoch 26/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1804 - accuracy: 0.9379 - val_loss: 0.9641 - val_accuracy: 0.7635\n","\n","Epoch 00026: val_accuracy did not improve from 0.83498\n","Epoch 27/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1759 - accuracy: 0.9409 - val_loss: 0.5846 - val_accuracy: 0.8325\n","\n","Epoch 00027: val_accuracy did not improve from 0.83498\n","Epoch 28/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.1786 - accuracy: 0.9361 - val_loss: 0.5145 - val_accuracy: 0.8695\n","\n","Epoch 00028: val_accuracy improved from 0.83498 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 29/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1186 - accuracy: 0.9580 - val_loss: 0.4983 - val_accuracy: 0.8670\n","\n","Epoch 00029: val_accuracy did not improve from 0.86946\n","Epoch 30/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1512 - accuracy: 0.9440 - val_loss: 0.6827 - val_accuracy: 0.8177\n","\n","Epoch 00030: val_accuracy did not improve from 0.86946\n","Epoch 31/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1144 - accuracy: 0.9635 - val_loss: 0.5630 - val_accuracy: 0.8276\n","\n","Epoch 00031: val_accuracy did not improve from 0.86946\n","Epoch 32/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0784 - accuracy: 0.9750 - val_loss: 0.5217 - val_accuracy: 0.8448\n","\n","Epoch 00032: val_accuracy did not improve from 0.86946\n","Epoch 33/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1198 - accuracy: 0.9610 - val_loss: 0.5065 - val_accuracy: 0.8522\n","\n","Epoch 00033: val_accuracy did not improve from 0.86946\n","Epoch 34/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1426 - accuracy: 0.9452 - val_loss: 0.8422 - val_accuracy: 0.8079\n","\n","Epoch 00034: val_accuracy did not improve from 0.86946\n","Epoch 35/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1510 - accuracy: 0.9476 - val_loss: 0.5758 - val_accuracy: 0.8399\n","\n","Epoch 00035: val_accuracy did not improve from 0.86946\n","Epoch 36/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1258 - accuracy: 0.9555 - val_loss: 0.7602 - val_accuracy: 0.8054\n","\n","Epoch 00036: val_accuracy did not improve from 0.86946\n","Epoch 37/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1262 - accuracy: 0.9610 - val_loss: 0.7111 - val_accuracy: 0.8227\n","\n","Epoch 00037: val_accuracy did not improve from 0.86946\n","Epoch 38/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1075 - accuracy: 0.9610 - val_loss: 0.4473 - val_accuracy: 0.8768\n","\n","Epoch 00038: val_accuracy improved from 0.86946 to 0.87685, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 39/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1007 - accuracy: 0.9665 - val_loss: 0.6867 - val_accuracy: 0.8719\n","\n","Epoch 00039: val_accuracy did not improve from 0.87685\n","Epoch 40/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0937 - accuracy: 0.9653 - val_loss: 0.4955 - val_accuracy: 0.8596\n","\n","Epoch 00040: val_accuracy did not improve from 0.87685\n","Epoch 41/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0739 - accuracy: 0.9787 - val_loss: 0.6955 - val_accuracy: 0.8153\n","\n","Epoch 00041: val_accuracy did not improve from 0.87685\n","Epoch 42/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1328 - accuracy: 0.9562 - val_loss: 1.0265 - val_accuracy: 0.7586\n","\n","Epoch 00042: val_accuracy did not improve from 0.87685\n","Epoch 43/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1453 - accuracy: 0.9464 - val_loss: 0.8943 - val_accuracy: 0.8079\n","\n","Epoch 00043: val_accuracy did not improve from 0.87685\n","Epoch 44/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0856 - accuracy: 0.9689 - val_loss: 0.4840 - val_accuracy: 0.8695\n","\n","Epoch 00044: val_accuracy did not improve from 0.87685\n","Epoch 45/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0747 - accuracy: 0.9750 - val_loss: 0.5949 - val_accuracy: 0.8645\n","\n","Epoch 00045: val_accuracy did not improve from 0.87685\n","Epoch 46/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0583 - accuracy: 0.9799 - val_loss: 0.4087 - val_accuracy: 0.8842\n","\n","Epoch 00046: val_accuracy improved from 0.87685 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 47/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0521 - accuracy: 0.9842 - val_loss: 0.4855 - val_accuracy: 0.8547\n","\n","Epoch 00047: val_accuracy did not improve from 0.88424\n","Epoch 48/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0805 - accuracy: 0.9714 - val_loss: 0.5345 - val_accuracy: 0.8596\n","\n","Epoch 00048: val_accuracy did not improve from 0.88424\n","Epoch 49/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0761 - accuracy: 0.9750 - val_loss: 0.6311 - val_accuracy: 0.8695\n","\n","Epoch 00049: val_accuracy did not improve from 0.88424\n","Epoch 50/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1418 - accuracy: 0.9531 - val_loss: 0.7073 - val_accuracy: 0.8448\n","\n","Epoch 00050: val_accuracy did not improve from 0.88424\n","Epoch 51/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0861 - accuracy: 0.9714 - val_loss: 0.7030 - val_accuracy: 0.8251\n","\n","Epoch 00051: val_accuracy did not improve from 0.88424\n","Epoch 52/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0631 - accuracy: 0.9799 - val_loss: 0.8555 - val_accuracy: 0.8424\n","\n","Epoch 00052: val_accuracy did not improve from 0.88424\n","Epoch 53/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0706 - accuracy: 0.9756 - val_loss: 0.4048 - val_accuracy: 0.8941\n","\n","Epoch 00053: val_accuracy improved from 0.88424 to 0.89409, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 54/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0595 - accuracy: 0.9836 - val_loss: 0.4703 - val_accuracy: 0.8719\n","\n","Epoch 00054: val_accuracy did not improve from 0.89409\n","Epoch 55/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0576 - accuracy: 0.9775 - val_loss: 0.4873 - val_accuracy: 0.8818\n","\n","Epoch 00055: val_accuracy did not improve from 0.89409\n","Epoch 56/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0507 - accuracy: 0.9811 - val_loss: 0.5836 - val_accuracy: 0.8818\n","\n","Epoch 00056: val_accuracy did not improve from 0.89409\n","Epoch 57/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0429 - accuracy: 0.9860 - val_loss: 0.7374 - val_accuracy: 0.8498\n","\n","Epoch 00057: val_accuracy did not improve from 0.89409\n","Epoch 58/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0611 - accuracy: 0.9762 - val_loss: 0.7037 - val_accuracy: 0.8276\n","\n","Epoch 00058: val_accuracy did not improve from 0.89409\n","Epoch 59/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0538 - accuracy: 0.9817 - val_loss: 0.6246 - val_accuracy: 0.8621\n","\n","Epoch 00059: val_accuracy did not improve from 0.89409\n","Epoch 60/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.4287 - val_accuracy: 0.9039\n","\n","Epoch 00060: val_accuracy improved from 0.89409 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 61/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0549 - accuracy: 0.9829 - val_loss: 0.5987 - val_accuracy: 0.8744\n","\n","Epoch 00061: val_accuracy did not improve from 0.90394\n","Epoch 62/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0495 - accuracy: 0.9829 - val_loss: 0.7340 - val_accuracy: 0.8399\n","\n","Epoch 00062: val_accuracy did not improve from 0.90394\n","Epoch 63/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0839 - accuracy: 0.9762 - val_loss: 1.5181 - val_accuracy: 0.7266\n","\n","Epoch 00063: val_accuracy did not improve from 0.90394\n","Epoch 64/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0715 - accuracy: 0.9744 - val_loss: 1.3030 - val_accuracy: 0.7537\n","\n","Epoch 00064: val_accuracy did not improve from 0.90394\n","Epoch 65/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0733 - accuracy: 0.9726 - val_loss: 0.5605 - val_accuracy: 0.8621\n","\n","Epoch 00065: val_accuracy did not improve from 0.90394\n","Epoch 66/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0955 - accuracy: 0.9635 - val_loss: 0.6181 - val_accuracy: 0.8522\n","\n","Epoch 00066: val_accuracy did not improve from 0.90394\n","Epoch 67/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.3409 - accuracy: 0.8952 - val_loss: 8.6664 - val_accuracy: 0.2537\n","\n","Epoch 00067: val_accuracy did not improve from 0.90394\n","Epoch 68/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1153 - accuracy: 0.9622 - val_loss: 0.5176 - val_accuracy: 0.8818\n","\n","Epoch 00068: val_accuracy did not improve from 0.90394\n","Epoch 69/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0927 - accuracy: 0.9665 - val_loss: 0.9213 - val_accuracy: 0.7931\n","\n","Epoch 00069: val_accuracy did not improve from 0.90394\n","Epoch 70/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0627 - accuracy: 0.9787 - val_loss: 0.3563 - val_accuracy: 0.9039\n","\n","Epoch 00070: val_accuracy did not improve from 0.90394\n","Epoch 71/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0347 - accuracy: 0.9890 - val_loss: 0.4361 - val_accuracy: 0.8990\n","\n","Epoch 00071: val_accuracy did not improve from 0.90394\n","Epoch 72/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0189 - accuracy: 0.9970 - val_loss: 0.3570 - val_accuracy: 0.9039\n","\n","Epoch 00072: val_accuracy did not improve from 0.90394\n","Epoch 73/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.4903 - val_accuracy: 0.8645\n","\n","Epoch 00073: val_accuracy did not improve from 0.90394\n","Epoch 74/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0340 - accuracy: 0.9878 - val_loss: 0.6168 - val_accuracy: 0.8645\n","\n","Epoch 00074: val_accuracy did not improve from 0.90394\n","Epoch 75/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.3887 - val_accuracy: 0.8867\n","\n","Epoch 00075: val_accuracy did not improve from 0.90394\n","Epoch 76/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0286 - accuracy: 0.9927 - val_loss: 0.6505 - val_accuracy: 0.8621\n","\n","Epoch 00076: val_accuracy did not improve from 0.90394\n","Epoch 77/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0459 - accuracy: 0.9829 - val_loss: 0.6256 - val_accuracy: 0.8695\n","\n","Epoch 00077: val_accuracy did not improve from 0.90394\n","Epoch 78/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0330 - accuracy: 0.9872 - val_loss: 0.5138 - val_accuracy: 0.8941\n","\n","Epoch 00078: val_accuracy did not improve from 0.90394\n","Epoch 79/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.5936 - val_accuracy: 0.8867\n","\n","Epoch 00079: val_accuracy did not improve from 0.90394\n","Epoch 80/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0284 - accuracy: 0.9903 - val_loss: 0.6443 - val_accuracy: 0.8571\n","\n","Epoch 00080: val_accuracy did not improve from 0.90394\n","Epoch 81/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.4088 - val_accuracy: 0.8842\n","\n","Epoch 00081: val_accuracy did not improve from 0.90394\n","Epoch 82/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.4006 - val_accuracy: 0.9163\n","\n","Epoch 00082: val_accuracy improved from 0.90394 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 83/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0576 - accuracy: 0.9842 - val_loss: 0.4950 - val_accuracy: 0.8793\n","\n","Epoch 00083: val_accuracy did not improve from 0.91626\n","Epoch 84/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.2246 - accuracy: 0.9233 - val_loss: 1.4665 - val_accuracy: 0.7685\n","\n","Epoch 00084: val_accuracy did not improve from 0.91626\n","Epoch 85/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1202 - accuracy: 0.9586 - val_loss: 0.8000 - val_accuracy: 0.8399\n","\n","Epoch 00085: val_accuracy did not improve from 0.91626\n","Epoch 86/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0437 - accuracy: 0.9817 - val_loss: 0.4682 - val_accuracy: 0.8892\n","\n","Epoch 00086: val_accuracy did not improve from 0.91626\n","Epoch 87/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0397 - accuracy: 0.9903 - val_loss: 0.4474 - val_accuracy: 0.8990\n","\n","Epoch 00087: val_accuracy did not improve from 0.91626\n","Epoch 88/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.4142 - val_accuracy: 0.9113\n","\n","Epoch 00088: val_accuracy did not improve from 0.91626\n","Epoch 89/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 0.4265 - val_accuracy: 0.8990\n","\n","Epoch 00089: val_accuracy did not improve from 0.91626\n","Epoch 90/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0395 - accuracy: 0.9890 - val_loss: 0.4593 - val_accuracy: 0.8818\n","\n","Epoch 00090: val_accuracy did not improve from 0.91626\n","Epoch 91/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0494 - accuracy: 0.9817 - val_loss: 0.6577 - val_accuracy: 0.8547\n","\n","Epoch 00091: val_accuracy did not improve from 0.91626\n","Epoch 92/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0331 - accuracy: 0.9903 - val_loss: 0.3254 - val_accuracy: 0.9138\n","\n","Epoch 00092: val_accuracy did not improve from 0.91626\n","Epoch 93/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.3282 - val_accuracy: 0.9335\n","\n","Epoch 00093: val_accuracy improved from 0.91626 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 94/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0205 - accuracy: 0.9915 - val_loss: 0.3715 - val_accuracy: 0.9039\n","\n","Epoch 00094: val_accuracy did not improve from 0.93350\n","Epoch 95/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0277 - accuracy: 0.9890 - val_loss: 0.4200 - val_accuracy: 0.8990\n","\n","Epoch 00095: val_accuracy did not improve from 0.93350\n","Epoch 96/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 0.6069 - val_accuracy: 0.8695\n","\n","Epoch 00096: val_accuracy did not improve from 0.93350\n","Epoch 97/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0356 - accuracy: 0.9872 - val_loss: 0.5250 - val_accuracy: 0.8719\n","\n","Epoch 00097: val_accuracy did not improve from 0.93350\n","Epoch 98/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0354 - accuracy: 0.9860 - val_loss: 0.5128 - val_accuracy: 0.8916\n","\n","Epoch 00098: val_accuracy did not improve from 0.93350\n","Epoch 99/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0291 - accuracy: 0.9890 - val_loss: 0.4656 - val_accuracy: 0.8941\n","\n","Epoch 00099: val_accuracy did not improve from 0.93350\n","Epoch 100/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.6132 - val_accuracy: 0.8719\n","\n","Epoch 00100: val_accuracy did not improve from 0.93350\n","Epoch 101/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0550 - accuracy: 0.9823 - val_loss: 0.6038 - val_accuracy: 0.8621\n","\n","Epoch 00101: val_accuracy did not improve from 0.93350\n","Epoch 102/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0621 - accuracy: 0.9799 - val_loss: 0.5439 - val_accuracy: 0.8522\n","\n","Epoch 00102: val_accuracy did not improve from 0.93350\n","Epoch 103/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0538 - accuracy: 0.9817 - val_loss: 1.0532 - val_accuracy: 0.7857\n","\n","Epoch 00103: val_accuracy did not improve from 0.93350\n","Epoch 104/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0678 - accuracy: 0.9732 - val_loss: 0.7846 - val_accuracy: 0.8424\n","\n","Epoch 00104: val_accuracy did not improve from 0.93350\n","Epoch 105/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0625 - accuracy: 0.9805 - val_loss: 0.5613 - val_accuracy: 0.8744\n","\n","Epoch 00105: val_accuracy did not improve from 0.93350\n","Epoch 106/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0368 - accuracy: 0.9860 - val_loss: 0.6695 - val_accuracy: 0.8670\n","\n","Epoch 00106: val_accuracy did not improve from 0.93350\n","Epoch 107/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.4401 - val_accuracy: 0.9138\n","\n","Epoch 00107: val_accuracy did not improve from 0.93350\n","Epoch 108/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0181 - accuracy: 0.9933 - val_loss: 0.6770 - val_accuracy: 0.8744\n","\n","Epoch 00108: val_accuracy did not improve from 0.93350\n","Epoch 109/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0330 - accuracy: 0.9872 - val_loss: 0.5438 - val_accuracy: 0.8621\n","\n","Epoch 00109: val_accuracy did not improve from 0.93350\n","Epoch 110/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0483 - accuracy: 0.9829 - val_loss: 0.7976 - val_accuracy: 0.8424\n","\n","Epoch 00110: val_accuracy did not improve from 0.93350\n","Epoch 111/500\n","52/52 [==============================] - 21s 404ms/step - loss: 0.0316 - accuracy: 0.9909 - val_loss: 0.6112 - val_accuracy: 0.8793\n","\n","Epoch 00111: val_accuracy did not improve from 0.93350\n","Epoch 112/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0260 - accuracy: 0.9939 - val_loss: 0.5044 - val_accuracy: 0.8966\n","\n","Epoch 00112: val_accuracy did not improve from 0.93350\n","Epoch 113/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.3857 - val_accuracy: 0.9015\n","\n","Epoch 00113: val_accuracy did not improve from 0.93350\n","Epoch 114/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.8941\n","\n","Epoch 00114: val_accuracy did not improve from 0.93350\n","Epoch 115/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.4178 - val_accuracy: 0.9089\n","\n","Epoch 00115: val_accuracy did not improve from 0.93350\n","Epoch 116/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.4691 - val_accuracy: 0.9187\n","\n","Epoch 00116: val_accuracy did not improve from 0.93350\n","Epoch 117/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.6826 - val_accuracy: 0.8768\n","\n","Epoch 00117: val_accuracy did not improve from 0.93350\n","Epoch 118/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0256 - accuracy: 0.9939 - val_loss: 0.4804 - val_accuracy: 0.8966\n","\n","Epoch 00118: val_accuracy did not improve from 0.93350\n","Epoch 119/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0579 - accuracy: 0.9805 - val_loss: 1.8254 - val_accuracy: 0.6749\n","\n","Epoch 00119: val_accuracy did not improve from 0.93350\n","Epoch 120/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0578 - accuracy: 0.9805 - val_loss: 0.5338 - val_accuracy: 0.8892\n","\n","Epoch 00120: val_accuracy did not improve from 0.93350\n","Epoch 121/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.5742 - val_accuracy: 0.8695\n","\n","Epoch 00121: val_accuracy did not improve from 0.93350\n","Epoch 122/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0259 - accuracy: 0.9909 - val_loss: 0.5437 - val_accuracy: 0.8867\n","\n","Epoch 00122: val_accuracy did not improve from 0.93350\n","Epoch 123/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 0.4721 - val_accuracy: 0.9039\n","\n","Epoch 00123: val_accuracy did not improve from 0.93350\n","Epoch 124/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.8908 - val_accuracy: 0.8596\n","\n","Epoch 00124: val_accuracy did not improve from 0.93350\n","Epoch 125/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0330 - accuracy: 0.9884 - val_loss: 0.4840 - val_accuracy: 0.8892\n","\n","Epoch 00125: val_accuracy did not improve from 0.93350\n","Epoch 126/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.4641 - val_accuracy: 0.9039\n","\n","Epoch 00126: val_accuracy did not improve from 0.93350\n","Epoch 127/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.5525 - val_accuracy: 0.8867\n","\n","Epoch 00127: val_accuracy did not improve from 0.93350\n","Epoch 128/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.4184 - val_accuracy: 0.9113\n","\n","Epoch 00128: val_accuracy did not improve from 0.93350\n","Epoch 129/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.4253 - val_accuracy: 0.9064\n","\n","Epoch 00129: val_accuracy did not improve from 0.93350\n","Epoch 130/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0282 - accuracy: 0.9896 - val_loss: 0.6910 - val_accuracy: 0.8571\n","\n","Epoch 00130: val_accuracy did not improve from 0.93350\n","Epoch 131/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0718 - accuracy: 0.9793 - val_loss: 1.7471 - val_accuracy: 0.7365\n","\n","Epoch 00131: val_accuracy did not improve from 0.93350\n","Epoch 132/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0801 - accuracy: 0.9714 - val_loss: 0.8664 - val_accuracy: 0.8498\n","\n","Epoch 00132: val_accuracy did not improve from 0.93350\n","Epoch 133/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0644 - accuracy: 0.9836 - val_loss: 0.9723 - val_accuracy: 0.8448\n","\n","Epoch 00133: val_accuracy did not improve from 0.93350\n","Epoch 134/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0835 - accuracy: 0.9720 - val_loss: 0.6757 - val_accuracy: 0.8621\n","\n","Epoch 00134: val_accuracy did not improve from 0.93350\n","Epoch 135/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0722 - accuracy: 0.9781 - val_loss: 0.5148 - val_accuracy: 0.8768\n","\n","Epoch 00135: val_accuracy did not improve from 0.93350\n","Epoch 136/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0508 - accuracy: 0.9842 - val_loss: 0.5123 - val_accuracy: 0.8695\n","\n","Epoch 00136: val_accuracy did not improve from 0.93350\n","Epoch 137/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.4754 - val_accuracy: 0.9015\n","\n","Epoch 00137: val_accuracy did not improve from 0.93350\n","Epoch 138/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.4698 - val_accuracy: 0.8966\n","\n","Epoch 00138: val_accuracy did not improve from 0.93350\n","Epoch 139/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0151 - accuracy: 0.9921 - val_loss: 0.5573 - val_accuracy: 0.9138\n","\n","Epoch 00139: val_accuracy did not improve from 0.93350\n","Epoch 140/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0302 - accuracy: 0.9890 - val_loss: 0.6215 - val_accuracy: 0.8670\n","\n","Epoch 00140: val_accuracy did not improve from 0.93350\n","Epoch 141/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.5657 - val_accuracy: 0.9015\n","\n","Epoch 00141: val_accuracy did not improve from 0.93350\n","Epoch 142/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0218 - accuracy: 0.9921 - val_loss: 0.5689 - val_accuracy: 0.8818\n","\n","Epoch 00142: val_accuracy did not improve from 0.93350\n","Epoch 143/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0367 - accuracy: 0.9872 - val_loss: 0.4739 - val_accuracy: 0.9064\n","\n","Epoch 00143: val_accuracy did not improve from 0.93350\n","Epoch 144/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.4277 - val_accuracy: 0.8990\n","\n","Epoch 00144: val_accuracy did not improve from 0.93350\n","Epoch 145/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0233 - accuracy: 0.9951 - val_loss: 0.4455 - val_accuracy: 0.9236\n","\n","Epoch 00145: val_accuracy did not improve from 0.93350\n","Epoch 146/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0324 - accuracy: 0.9854 - val_loss: 0.5976 - val_accuracy: 0.8793\n","\n","Epoch 00146: val_accuracy did not improve from 0.93350\n","Epoch 147/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.5455 - val_accuracy: 0.8768\n","\n","Epoch 00147: val_accuracy did not improve from 0.93350\n","Epoch 148/500\n","52/52 [==============================] - 21s 403ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.5535 - val_accuracy: 0.8842\n","\n","Epoch 00148: val_accuracy did not improve from 0.93350\n","Epoch 149/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.4291 - val_accuracy: 0.9138\n","\n","Epoch 00149: val_accuracy did not improve from 0.93350\n","Epoch 150/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.6656 - val_accuracy: 0.8670\n","\n","Epoch 00150: val_accuracy did not improve from 0.93350\n","Epoch 151/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.5552 - val_accuracy: 0.8719\n","\n","Epoch 00151: val_accuracy did not improve from 0.93350\n","Epoch 152/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.4108 - val_accuracy: 0.9163\n","\n","Epoch 00152: val_accuracy did not improve from 0.93350\n","Epoch 153/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.4331 - val_accuracy: 0.9163\n","\n","Epoch 00153: val_accuracy did not improve from 0.93350\n","Epoch 154/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0454 - accuracy: 0.9890 - val_loss: 0.5701 - val_accuracy: 0.8768\n","\n","Epoch 00154: val_accuracy did not improve from 0.93350\n","Epoch 155/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0238 - accuracy: 0.9909 - val_loss: 0.4947 - val_accuracy: 0.9039\n","\n","Epoch 00155: val_accuracy did not improve from 0.93350\n","Epoch 156/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.4190 - val_accuracy: 0.9015\n","\n","Epoch 00156: val_accuracy did not improve from 0.93350\n","Epoch 157/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.6473 - val_accuracy: 0.8719\n","\n","Epoch 00157: val_accuracy did not improve from 0.93350\n","Epoch 158/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.5134 - val_accuracy: 0.8966\n","\n","Epoch 00158: val_accuracy did not improve from 0.93350\n","Epoch 159/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.3896 - val_accuracy: 0.9089\n","\n","Epoch 00159: val_accuracy did not improve from 0.93350\n","Epoch 160/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0062 - accuracy: 0.9970 - val_loss: 0.4009 - val_accuracy: 0.9163\n","\n","Epoch 00160: val_accuracy did not improve from 0.93350\n","Epoch 161/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.5144 - val_accuracy: 0.8966\n","\n","Epoch 00161: val_accuracy did not improve from 0.93350\n","Epoch 162/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.5712 - val_accuracy: 0.8892\n","\n","Epoch 00162: val_accuracy did not improve from 0.93350\n","Epoch 163/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.9163\n","\n","Epoch 00163: val_accuracy did not improve from 0.93350\n","Epoch 164/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9261\n","\n","Epoch 00164: val_accuracy did not improve from 0.93350\n","Epoch 165/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4726 - val_accuracy: 0.9064\n","\n","Epoch 00165: val_accuracy did not improve from 0.93350\n","Epoch 166/500\n","52/52 [==============================] - 20s 389ms/step - loss: 8.4644e-04 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9212\n","\n","Epoch 00166: val_accuracy did not improve from 0.93350\n","Epoch 167/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.5444 - val_accuracy: 0.9015\n","\n","Epoch 00167: val_accuracy did not improve from 0.93350\n","Epoch 168/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0355 - accuracy: 0.9854 - val_loss: 1.2786 - val_accuracy: 0.8227\n","\n","Epoch 00168: val_accuracy did not improve from 0.93350\n","Epoch 169/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0898 - accuracy: 0.9714 - val_loss: 1.0420 - val_accuracy: 0.8079\n","\n","Epoch 00169: val_accuracy did not improve from 0.93350\n","Epoch 170/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0689 - accuracy: 0.9799 - val_loss: 0.7312 - val_accuracy: 0.8768\n","\n","Epoch 00170: val_accuracy did not improve from 0.93350\n","Epoch 171/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0595 - accuracy: 0.9823 - val_loss: 0.6251 - val_accuracy: 0.8916\n","\n","Epoch 00171: val_accuracy did not improve from 0.93350\n","Epoch 172/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0490 - accuracy: 0.9817 - val_loss: 0.6005 - val_accuracy: 0.9039\n","\n","Epoch 00172: val_accuracy did not improve from 0.93350\n","Epoch 173/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.7311 - val_accuracy: 0.8473\n","\n","Epoch 00173: val_accuracy did not improve from 0.93350\n","Epoch 174/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0396 - accuracy: 0.9860 - val_loss: 0.5521 - val_accuracy: 0.8793\n","\n","Epoch 00174: val_accuracy did not improve from 0.93350\n","Epoch 175/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0300 - accuracy: 0.9915 - val_loss: 0.5522 - val_accuracy: 0.8966\n","\n","Epoch 00175: val_accuracy did not improve from 0.93350\n","Epoch 176/500\n","52/52 [==============================] - 21s 403ms/step - loss: 0.0162 - accuracy: 0.9933 - val_loss: 0.5431 - val_accuracy: 0.8916\n","\n","Epoch 00176: val_accuracy did not improve from 0.93350\n","Epoch 177/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.6753 - val_accuracy: 0.8768\n","\n","Epoch 00177: val_accuracy did not improve from 0.93350\n","Epoch 178/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.7908 - val_accuracy: 0.8571\n","\n","Epoch 00178: val_accuracy did not improve from 0.93350\n","Epoch 179/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0363 - accuracy: 0.9878 - val_loss: 0.5220 - val_accuracy: 0.8916\n","\n","Epoch 00179: val_accuracy did not improve from 0.93350\n","Epoch 180/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.5056 - val_accuracy: 0.9039\n","\n","Epoch 00180: val_accuracy did not improve from 0.93350\n","Epoch 181/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.4618 - val_accuracy: 0.9187\n","\n","Epoch 00181: val_accuracy did not improve from 0.93350\n","Epoch 182/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4103 - val_accuracy: 0.9261\n","\n","Epoch 00182: val_accuracy did not improve from 0.93350\n","Epoch 183/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0408 - accuracy: 0.9866 - val_loss: 0.6832 - val_accuracy: 0.8768\n","\n","Epoch 00183: val_accuracy did not improve from 0.93350\n","Epoch 184/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.5330 - val_accuracy: 0.9039\n","\n","Epoch 00184: val_accuracy did not improve from 0.93350\n","Epoch 185/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.4835 - val_accuracy: 0.9138\n","\n","Epoch 00185: val_accuracy did not improve from 0.93350\n","Epoch 186/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.4135 - val_accuracy: 0.9064\n","\n","Epoch 00186: val_accuracy did not improve from 0.93350\n","Epoch 187/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.6766 - val_accuracy: 0.8842\n","\n","Epoch 00187: val_accuracy did not improve from 0.93350\n","Epoch 188/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4754 - val_accuracy: 0.9089\n","\n","Epoch 00188: val_accuracy did not improve from 0.93350\n","Epoch 189/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4832 - val_accuracy: 0.8941\n","\n","Epoch 00189: val_accuracy did not improve from 0.93350\n","Epoch 190/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.3962 - val_accuracy: 0.8966\n","\n","Epoch 00190: val_accuracy did not improve from 0.93350\n","Epoch 191/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.4216 - val_accuracy: 0.9138\n","\n","Epoch 00191: val_accuracy did not improve from 0.93350\n","Epoch 192/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4030 - val_accuracy: 0.9261\n","\n","Epoch 00192: val_accuracy did not improve from 0.93350\n","Epoch 193/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4400 - val_accuracy: 0.9064\n","\n","Epoch 00193: val_accuracy did not improve from 0.93350\n","Epoch 194/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.9212\n","\n","Epoch 00194: val_accuracy did not improve from 0.93350\n","Epoch 195/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4944 - val_accuracy: 0.9212\n","\n","Epoch 00195: val_accuracy did not improve from 0.93350\n","Epoch 196/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3932 - val_accuracy: 0.9261\n","\n","Epoch 00196: val_accuracy did not improve from 0.93350\n","Epoch 197/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4542 - val_accuracy: 0.9163\n","\n","Epoch 00197: val_accuracy did not improve from 0.93350\n","Epoch 198/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.5488 - val_accuracy: 0.8818\n","\n","Epoch 00198: val_accuracy did not improve from 0.93350\n","Epoch 199/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0312 - accuracy: 0.9909 - val_loss: 0.9810 - val_accuracy: 0.8177\n","\n","Epoch 00199: val_accuracy did not improve from 0.93350\n","Epoch 200/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0641 - accuracy: 0.9781 - val_loss: 0.7243 - val_accuracy: 0.8695\n","\n","Epoch 00200: val_accuracy did not improve from 0.93350\n","Epoch 201/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0622 - accuracy: 0.9787 - val_loss: 0.8208 - val_accuracy: 0.8473\n","\n","Epoch 00201: val_accuracy did not improve from 0.93350\n","Epoch 202/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0450 - accuracy: 0.9896 - val_loss: 0.7504 - val_accuracy: 0.8793\n","\n","Epoch 00202: val_accuracy did not improve from 0.93350\n","Epoch 203/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 0.5168 - val_accuracy: 0.8990\n","\n","Epoch 00203: val_accuracy did not improve from 0.93350\n","Epoch 204/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0218 - accuracy: 0.9909 - val_loss: 0.6424 - val_accuracy: 0.8842\n","\n","Epoch 00204: val_accuracy did not improve from 0.93350\n","Epoch 205/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.7725 - val_accuracy: 0.8399\n","\n","Epoch 00205: val_accuracy did not improve from 0.93350\n","Epoch 206/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0129 - accuracy: 0.9982 - val_loss: 0.4003 - val_accuracy: 0.9138\n","\n","Epoch 00206: val_accuracy did not improve from 0.93350\n","Epoch 207/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.4918 - val_accuracy: 0.9113\n","\n","Epoch 00207: val_accuracy did not improve from 0.93350\n","Epoch 208/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5250 - val_accuracy: 0.8990\n","\n","Epoch 00208: val_accuracy did not improve from 0.93350\n","Epoch 209/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.6320 - val_accuracy: 0.8768\n","\n","Epoch 00209: val_accuracy did not improve from 0.93350\n","Epoch 210/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.5037 - val_accuracy: 0.9113\n","\n","Epoch 00210: val_accuracy did not improve from 0.93350\n","Epoch 211/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.6251 - val_accuracy: 0.8966\n","\n","Epoch 00211: val_accuracy did not improve from 0.93350\n","Epoch 212/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0046 - accuracy: 0.9976 - val_loss: 0.5185 - val_accuracy: 0.8842\n","\n","Epoch 00212: val_accuracy did not improve from 0.93350\n","Epoch 213/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0149 - accuracy: 0.9939 - val_loss: 0.5186 - val_accuracy: 0.8990\n","\n","Epoch 00213: val_accuracy did not improve from 0.93350\n","Epoch 214/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0282 - accuracy: 0.9927 - val_loss: 0.6475 - val_accuracy: 0.8596\n","\n","Epoch 00214: val_accuracy did not improve from 0.93350\n","Epoch 215/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 0.7117 - val_accuracy: 0.8645\n","\n","Epoch 00215: val_accuracy did not improve from 0.93350\n","Epoch 216/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.5427 - val_accuracy: 0.8941\n","\n","Epoch 00216: val_accuracy did not improve from 0.93350\n","Epoch 217/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 0.4931 - val_accuracy: 0.9039\n","\n","Epoch 00217: val_accuracy did not improve from 0.93350\n","Epoch 218/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 2.2737 - val_accuracy: 0.6576\n","\n","Epoch 00218: val_accuracy did not improve from 0.93350\n","Epoch 219/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0346 - accuracy: 0.9872 - val_loss: 0.7484 - val_accuracy: 0.8645\n","\n","Epoch 00219: val_accuracy did not improve from 0.93350\n","Epoch 220/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0321 - accuracy: 0.9921 - val_loss: 0.5654 - val_accuracy: 0.9015\n","\n","Epoch 00220: val_accuracy did not improve from 0.93350\n","Epoch 221/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0137 - accuracy: 0.9933 - val_loss: 0.6193 - val_accuracy: 0.8768\n","\n","Epoch 00221: val_accuracy did not improve from 0.93350\n","Epoch 222/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.5758 - val_accuracy: 0.9015\n","\n","Epoch 00222: val_accuracy did not improve from 0.93350\n","Epoch 223/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0124 - accuracy: 0.9933 - val_loss: 0.8762 - val_accuracy: 0.8645\n","\n","Epoch 00223: val_accuracy did not improve from 0.93350\n","Epoch 224/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0739 - accuracy: 0.9811 - val_loss: 1.0639 - val_accuracy: 0.8448\n","\n","Epoch 00224: val_accuracy did not improve from 0.93350\n","Epoch 225/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0325 - accuracy: 0.9878 - val_loss: 0.7612 - val_accuracy: 0.8473\n","\n","Epoch 00225: val_accuracy did not improve from 0.93350\n","Epoch 226/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.5628 - val_accuracy: 0.8768\n","\n","Epoch 00226: val_accuracy did not improve from 0.93350\n","Epoch 227/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.4838 - val_accuracy: 0.9015\n","\n","Epoch 00227: val_accuracy did not improve from 0.93350\n","Epoch 228/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.6048 - val_accuracy: 0.8867\n","\n","Epoch 00228: val_accuracy did not improve from 0.93350\n","Epoch 229/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.5653 - val_accuracy: 0.9015\n","\n","Epoch 00229: val_accuracy did not improve from 0.93350\n","Epoch 230/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.8966\n","\n","Epoch 00230: val_accuracy did not improve from 0.93350\n","Epoch 231/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.5860 - val_accuracy: 0.9039\n","\n","Epoch 00231: val_accuracy did not improve from 0.93350\n","Epoch 232/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.6451 - val_accuracy: 0.8916\n","\n","Epoch 00232: val_accuracy did not improve from 0.93350\n","Epoch 233/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0155 - accuracy: 0.9970 - val_loss: 0.8345 - val_accuracy: 0.8645\n","\n","Epoch 00233: val_accuracy did not improve from 0.93350\n","Epoch 234/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.6772 - val_accuracy: 0.8621\n","\n","Epoch 00234: val_accuracy did not improve from 0.93350\n","Epoch 235/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.6729 - val_accuracy: 0.8695\n","\n","Epoch 00235: val_accuracy did not improve from 0.93350\n","Epoch 236/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0753 - accuracy: 0.9787 - val_loss: 1.9250 - val_accuracy: 0.7611\n","\n","Epoch 00236: val_accuracy did not improve from 0.93350\n","Epoch 237/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0494 - accuracy: 0.9829 - val_loss: 1.0917 - val_accuracy: 0.8177\n","\n","Epoch 00237: val_accuracy did not improve from 0.93350\n","Epoch 238/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0367 - accuracy: 0.9842 - val_loss: 0.7346 - val_accuracy: 0.8670\n","\n","Epoch 00238: val_accuracy did not improve from 0.93350\n","Epoch 239/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 0.8519 - val_accuracy: 0.8448\n","\n","Epoch 00239: val_accuracy did not improve from 0.93350\n","Epoch 240/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.6939 - val_accuracy: 0.8842\n","\n","Epoch 00240: val_accuracy did not improve from 0.93350\n","Epoch 241/500\n","52/52 [==============================] - 21s 403ms/step - loss: 0.0105 - accuracy: 0.9951 - val_loss: 0.5381 - val_accuracy: 0.8941\n","\n","Epoch 00241: val_accuracy did not improve from 0.93350\n","Epoch 242/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.4736 - val_accuracy: 0.9187\n","\n","Epoch 00242: val_accuracy did not improve from 0.93350\n","Epoch 243/500\n","52/52 [==============================] - 21s 402ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.5841 - val_accuracy: 0.8990\n","\n","Epoch 00243: val_accuracy did not improve from 0.93350\n","Epoch 244/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.5752 - val_accuracy: 0.8867\n","\n","Epoch 00244: val_accuracy did not improve from 0.93350\n","Epoch 245/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.5836 - val_accuracy: 0.8916\n","\n","Epoch 00245: val_accuracy did not improve from 0.93350\n","Epoch 246/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5381 - val_accuracy: 0.8966\n","\n","Epoch 00246: val_accuracy did not improve from 0.93350\n","Epoch 247/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5083 - val_accuracy: 0.9089\n","\n","Epoch 00247: val_accuracy did not improve from 0.93350\n","Epoch 248/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.4559 - val_accuracy: 0.9015\n","\n","Epoch 00248: val_accuracy did not improve from 0.93350\n","Epoch 249/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.5093 - val_accuracy: 0.9015\n","\n","Epoch 00249: val_accuracy did not improve from 0.93350\n","Epoch 250/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.5396 - val_accuracy: 0.9015\n","\n","Epoch 00250: val_accuracy did not improve from 0.93350\n","Epoch 251/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.5437 - val_accuracy: 0.8892\n","\n","Epoch 00251: val_accuracy did not improve from 0.93350\n","Epoch 252/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5466 - val_accuracy: 0.8916\n","\n","Epoch 00252: val_accuracy did not improve from 0.93350\n","Epoch 253/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.7156 - val_accuracy: 0.8448\n","\n","Epoch 00253: val_accuracy did not improve from 0.93350\n","Epoch 254/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0165 - accuracy: 0.9927 - val_loss: 0.6113 - val_accuracy: 0.8990\n","\n","Epoch 00254: val_accuracy did not improve from 0.93350\n","Epoch 255/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.5776 - val_accuracy: 0.8941\n","\n","Epoch 00255: val_accuracy did not improve from 0.93350\n","Epoch 256/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.4781 - val_accuracy: 0.9039\n","\n","Epoch 00256: val_accuracy did not improve from 0.93350\n","Epoch 257/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.6089 - val_accuracy: 0.8916\n","\n","Epoch 00257: val_accuracy did not improve from 0.93350\n","Epoch 258/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.5764 - val_accuracy: 0.8966\n","\n","Epoch 00258: val_accuracy did not improve from 0.93350\n","Epoch 259/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.5293 - val_accuracy: 0.8990\n","\n","Epoch 00259: val_accuracy did not improve from 0.93350\n","Epoch 260/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 0.6138 - val_accuracy: 0.8916\n","\n","Epoch 00260: val_accuracy did not improve from 0.93350\n","Epoch 261/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4799 - val_accuracy: 0.8990\n","\n","Epoch 00261: val_accuracy did not improve from 0.93350\n","Epoch 262/500\n","52/52 [==============================] - 20s 389ms/step - loss: 4.0491e-04 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9089\n","\n","Epoch 00262: val_accuracy did not improve from 0.93350\n","Epoch 263/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5277 - val_accuracy: 0.8941\n","\n","Epoch 00263: val_accuracy did not improve from 0.93350\n","Epoch 264/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5076 - val_accuracy: 0.9015\n","\n","Epoch 00264: val_accuracy did not improve from 0.93350\n","Epoch 265/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.5724 - val_accuracy: 0.8867\n","\n","Epoch 00265: val_accuracy did not improve from 0.93350\n","Epoch 266/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.4418 - val_accuracy: 0.8941\n","\n","Epoch 00266: val_accuracy did not improve from 0.93350\n","Epoch 267/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.4530 - val_accuracy: 0.9039\n","\n","Epoch 00267: val_accuracy did not improve from 0.93350\n","Epoch 268/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.9015\n","\n","Epoch 00268: val_accuracy did not improve from 0.93350\n","Epoch 269/500\n","52/52 [==============================] - 20s 388ms/step - loss: 8.2483e-04 - accuracy: 1.0000 - val_loss: 0.5115 - val_accuracy: 0.8990\n","\n","Epoch 00269: val_accuracy did not improve from 0.93350\n","Epoch 270/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.9163\n","\n","Epoch 00270: val_accuracy did not improve from 0.93350\n","Epoch 271/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9187\n","\n","Epoch 00271: val_accuracy did not improve from 0.93350\n","Epoch 272/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.6950e-04 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9163\n","\n","Epoch 00272: val_accuracy did not improve from 0.93350\n","Epoch 273/500\n","52/52 [==============================] - 20s 386ms/step - loss: 2.6897e-04 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.9163\n","\n","Epoch 00273: val_accuracy did not improve from 0.93350\n","Epoch 274/500\n","52/52 [==============================] - 20s 387ms/step - loss: 7.4335e-04 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.8990\n","\n","Epoch 00274: val_accuracy did not improve from 0.93350\n","Epoch 275/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.7138e-04 - accuracy: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.8990\n","\n","Epoch 00275: val_accuracy did not improve from 0.93350\n","Epoch 276/500\n","52/52 [==============================] - 20s 388ms/step - loss: 1.8535e-04 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9089\n","\n","Epoch 00276: val_accuracy did not improve from 0.93350\n","Epoch 277/500\n","52/52 [==============================] - 20s 389ms/step - loss: 2.1725e-04 - accuracy: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.9138\n","\n","Epoch 00277: val_accuracy did not improve from 0.93350\n","Epoch 278/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.8019e-04 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9064\n","\n","Epoch 00278: val_accuracy did not improve from 0.93350\n","Epoch 279/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5723 - val_accuracy: 0.8916\n","\n","Epoch 00279: val_accuracy did not improve from 0.93350\n","Epoch 280/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0098 - accuracy: 0.9957 - val_loss: 0.7370 - val_accuracy: 0.8916\n","\n","Epoch 00280: val_accuracy did not improve from 0.93350\n","Epoch 281/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0877 - accuracy: 0.9762 - val_loss: 1.4653 - val_accuracy: 0.7488\n","\n","Epoch 00281: val_accuracy did not improve from 0.93350\n","Epoch 282/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.2142 - accuracy: 0.9421 - val_loss: 1.2084 - val_accuracy: 0.8276\n","\n","Epoch 00282: val_accuracy did not improve from 0.93350\n","Epoch 283/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0919 - accuracy: 0.9720 - val_loss: 0.9262 - val_accuracy: 0.8276\n","\n","Epoch 00283: val_accuracy did not improve from 0.93350\n","Epoch 284/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0285 - accuracy: 0.9903 - val_loss: 0.7490 - val_accuracy: 0.8571\n","\n","Epoch 00284: val_accuracy did not improve from 0.93350\n","Epoch 285/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0109 - accuracy: 0.9951 - val_loss: 0.5323 - val_accuracy: 0.9039\n","\n","Epoch 00285: val_accuracy did not improve from 0.93350\n","Epoch 286/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.4994 - val_accuracy: 0.9064\n","\n","Epoch 00286: val_accuracy did not improve from 0.93350\n","Epoch 287/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.5962 - val_accuracy: 0.8892\n","\n","Epoch 00287: val_accuracy did not improve from 0.93350\n","Epoch 288/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4930 - val_accuracy: 0.8892\n","\n","Epoch 00288: val_accuracy did not improve from 0.93350\n","Epoch 289/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9187\n","\n","Epoch 00289: val_accuracy did not improve from 0.93350\n","Epoch 290/500\n","52/52 [==============================] - 20s 388ms/step - loss: 7.3874e-04 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.8941\n","\n","Epoch 00290: val_accuracy did not improve from 0.93350\n","Epoch 291/500\n","52/52 [==============================] - 20s 387ms/step - loss: 6.1244e-04 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.9236\n","\n","Epoch 00291: val_accuracy did not improve from 0.93350\n","Epoch 292/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.4515 - val_accuracy: 0.9039\n","\n","Epoch 00292: val_accuracy did not improve from 0.93350\n","Epoch 293/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9089\n","\n","Epoch 00293: val_accuracy did not improve from 0.93350\n","Epoch 294/500\n","52/52 [==============================] - 20s 388ms/step - loss: 9.4551e-04 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.9039\n","\n","Epoch 00294: val_accuracy did not improve from 0.93350\n","Epoch 295/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.3821 - val_accuracy: 0.9138\n","\n","Epoch 00295: val_accuracy did not improve from 0.93350\n","Epoch 296/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9212\n","\n","Epoch 00296: val_accuracy did not improve from 0.93350\n","Epoch 297/500\n","52/52 [==============================] - 20s 388ms/step - loss: 5.4459e-04 - accuracy: 1.0000 - val_loss: 0.3328 - val_accuracy: 0.9286\n","\n","Epoch 00297: val_accuracy did not improve from 0.93350\n","Epoch 298/500\n","52/52 [==============================] - 20s 388ms/step - loss: 7.4393e-04 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.9163\n","\n","Epoch 00298: val_accuracy did not improve from 0.93350\n","Epoch 299/500\n","52/52 [==============================] - 20s 388ms/step - loss: 6.2523e-04 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9113\n","\n","Epoch 00299: val_accuracy did not improve from 0.93350\n","Epoch 300/500\n","52/52 [==============================] - 20s 390ms/step - loss: 6.3702e-04 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9212\n","\n","Epoch 00300: val_accuracy did not improve from 0.93350\n","Epoch 301/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.8683e-04 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9212\n","\n","Epoch 00301: val_accuracy did not improve from 0.93350\n","Epoch 302/500\n","52/52 [==============================] - 20s 387ms/step - loss: 3.9933e-04 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9187\n","\n","Epoch 00302: val_accuracy did not improve from 0.93350\n","Epoch 303/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.0328e-04 - accuracy: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.9236\n","\n","Epoch 00303: val_accuracy did not improve from 0.93350\n","Epoch 304/500\n","52/52 [==============================] - 20s 389ms/step - loss: 4.2493e-04 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.9089\n","\n","Epoch 00304: val_accuracy did not improve from 0.93350\n","Epoch 305/500\n","52/52 [==============================] - 20s 389ms/step - loss: 5.2444e-04 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.9113\n","\n","Epoch 00305: val_accuracy did not improve from 0.93350\n","Epoch 306/500\n","52/52 [==============================] - 20s 390ms/step - loss: 6.8765e-04 - accuracy: 1.0000 - val_loss: 0.3882 - val_accuracy: 0.9163\n","\n","Epoch 00306: val_accuracy did not improve from 0.93350\n","Epoch 307/500\n","52/52 [==============================] - 20s 389ms/step - loss: 3.0085e-04 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.9089\n","\n","Epoch 00307: val_accuracy did not improve from 0.93350\n","Epoch 308/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.0427e-04 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.9212\n","\n","Epoch 00308: val_accuracy did not improve from 0.93350\n","Epoch 309/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.7102 - val_accuracy: 0.8547\n","\n","Epoch 00309: val_accuracy did not improve from 0.93350\n","Epoch 310/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0189 - accuracy: 0.9915 - val_loss: 0.8912 - val_accuracy: 0.8399\n","\n","Epoch 00310: val_accuracy did not improve from 0.93350\n","Epoch 311/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0338 - accuracy: 0.9878 - val_loss: 0.8863 - val_accuracy: 0.8695\n","\n","Epoch 00311: val_accuracy did not improve from 0.93350\n","Epoch 312/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1099 - accuracy: 0.9720 - val_loss: 0.7988 - val_accuracy: 0.8522\n","\n","Epoch 00312: val_accuracy did not improve from 0.93350\n","Epoch 313/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0718 - accuracy: 0.9775 - val_loss: 0.5680 - val_accuracy: 0.9064\n","\n","Epoch 00313: val_accuracy did not improve from 0.93350\n","Epoch 314/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.4787 - val_accuracy: 0.9039\n","\n","Epoch 00314: val_accuracy did not improve from 0.93350\n","Epoch 315/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.4604 - val_accuracy: 0.9015\n","\n","Epoch 00315: val_accuracy did not improve from 0.93350\n","Epoch 316/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4949 - val_accuracy: 0.9138\n","\n","Epoch 00316: val_accuracy did not improve from 0.93350\n","Epoch 317/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4458 - val_accuracy: 0.9236\n","\n","Epoch 00317: val_accuracy did not improve from 0.93350\n","Epoch 318/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4929 - val_accuracy: 0.9039\n","\n","Epoch 00318: val_accuracy did not improve from 0.93350\n","Epoch 319/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4841 - val_accuracy: 0.9039\n","\n","Epoch 00319: val_accuracy did not improve from 0.93350\n","Epoch 320/500\n","52/52 [==============================] - 20s 390ms/step - loss: 7.2312e-04 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.9187\n","\n","Epoch 00320: val_accuracy did not improve from 0.93350\n","Epoch 321/500\n","52/52 [==============================] - 20s 389ms/step - loss: 7.3187e-04 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.9089\n","\n","Epoch 00321: val_accuracy did not improve from 0.93350\n","Epoch 322/500\n","52/52 [==============================] - 20s 390ms/step - loss: 3.4058e-04 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.9163\n","\n","Epoch 00322: val_accuracy did not improve from 0.93350\n","Epoch 323/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.6951e-04 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9187\n","\n","Epoch 00323: val_accuracy did not improve from 0.93350\n","Epoch 324/500\n","52/52 [==============================] - 21s 403ms/step - loss: 5.8952e-04 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.9089\n","\n","Epoch 00324: val_accuracy did not improve from 0.93350\n","Epoch 325/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.3138 - val_accuracy: 0.9335\n","\n","Epoch 00325: val_accuracy did not improve from 0.93350\n","Epoch 326/500\n","52/52 [==============================] - 20s 389ms/step - loss: 5.7512e-04 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9335\n","\n","Epoch 00326: val_accuracy did not improve from 0.93350\n","Epoch 327/500\n","52/52 [==============================] - 20s 387ms/step - loss: 8.1057e-04 - accuracy: 1.0000 - val_loss: 0.3652 - val_accuracy: 0.9360\n","\n","Epoch 00327: val_accuracy improved from 0.93350 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5\n","Epoch 328/500\n","52/52 [==============================] - 20s 389ms/step - loss: 2.5675e-04 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9286\n","\n","Epoch 00328: val_accuracy did not improve from 0.93596\n","Epoch 329/500\n","52/52 [==============================] - 21s 396ms/step - loss: 6.1311e-04 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.9310\n","\n","Epoch 00329: val_accuracy did not improve from 0.93596\n","Epoch 330/500\n","52/52 [==============================] - 20s 390ms/step - loss: 6.5019e-04 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.9310\n","\n","Epoch 00330: val_accuracy did not improve from 0.93596\n","Epoch 331/500\n","52/52 [==============================] - 20s 385ms/step - loss: 2.1370e-04 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9187\n","\n","Epoch 00331: val_accuracy did not improve from 0.93596\n","Epoch 332/500\n","52/52 [==============================] - 20s 387ms/step - loss: 3.5875e-04 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9261\n","\n","Epoch 00332: val_accuracy did not improve from 0.93596\n","Epoch 333/500\n","52/52 [==============================] - 20s 388ms/step - loss: 7.8319e-04 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9286\n","\n","Epoch 00333: val_accuracy did not improve from 0.93596\n","Epoch 334/500\n","52/52 [==============================] - 20s 390ms/step - loss: 4.7192e-04 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.9310\n","\n","Epoch 00334: val_accuracy did not improve from 0.93596\n","Epoch 335/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.5795e-04 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.9236\n","\n","Epoch 00335: val_accuracy did not improve from 0.93596\n","Epoch 336/500\n","52/52 [==============================] - 20s 387ms/step - loss: 4.6433e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9360\n","\n","Epoch 00336: val_accuracy did not improve from 0.93596\n","Epoch 337/500\n","52/52 [==============================] - 20s 389ms/step - loss: 1.9641e-04 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9261\n","\n","Epoch 00337: val_accuracy did not improve from 0.93596\n","Epoch 338/500\n","52/52 [==============================] - 20s 389ms/step - loss: 3.6901e-04 - accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.9261\n","\n","Epoch 00338: val_accuracy did not improve from 0.93596\n","Epoch 339/500\n","52/52 [==============================] - 20s 389ms/step - loss: 1.3572e-04 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.9236\n","\n","Epoch 00339: val_accuracy did not improve from 0.93596\n","Epoch 340/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.1732e-04 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.9236\n","\n","Epoch 00340: val_accuracy did not improve from 0.93596\n","Epoch 341/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.7428 - val_accuracy: 0.8916\n","\n","Epoch 00341: val_accuracy did not improve from 0.93596\n","Epoch 342/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.5143 - val_accuracy: 0.9212\n","\n","Epoch 00342: val_accuracy did not improve from 0.93596\n","Epoch 343/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0070 - accuracy: 0.9963 - val_loss: 0.6279 - val_accuracy: 0.9039\n","\n","Epoch 00343: val_accuracy did not improve from 0.93596\n","Epoch 344/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.5687 - val_accuracy: 0.8842\n","\n","Epoch 00344: val_accuracy did not improve from 0.93596\n","Epoch 345/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0771 - accuracy: 0.9793 - val_loss: 1.1338 - val_accuracy: 0.8227\n","\n","Epoch 00345: val_accuracy did not improve from 0.93596\n","Epoch 346/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0326 - accuracy: 0.9890 - val_loss: 0.8258 - val_accuracy: 0.8793\n","\n","Epoch 00346: val_accuracy did not improve from 0.93596\n","Epoch 347/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0289 - accuracy: 0.9903 - val_loss: 0.6759 - val_accuracy: 0.8793\n","\n","Epoch 00347: val_accuracy did not improve from 0.93596\n","Epoch 348/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0288 - accuracy: 0.9896 - val_loss: 0.8524 - val_accuracy: 0.8695\n","\n","Epoch 00348: val_accuracy did not improve from 0.93596\n","Epoch 349/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.5679 - val_accuracy: 0.8867\n","\n","Epoch 00349: val_accuracy did not improve from 0.93596\n","Epoch 350/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0387 - accuracy: 0.9903 - val_loss: 0.9366 - val_accuracy: 0.8128\n","\n","Epoch 00350: val_accuracy did not improve from 0.93596\n","Epoch 351/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0519 - accuracy: 0.9787 - val_loss: 1.1186 - val_accuracy: 0.8103\n","\n","Epoch 00351: val_accuracy did not improve from 0.93596\n","Epoch 352/500\n","52/52 [==============================] - 21s 403ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.6406 - val_accuracy: 0.8744\n","\n","Epoch 00352: val_accuracy did not improve from 0.93596\n","Epoch 353/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0117 - accuracy: 0.9945 - val_loss: 0.5609 - val_accuracy: 0.8768\n","\n","Epoch 00353: val_accuracy did not improve from 0.93596\n","Epoch 354/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4563 - val_accuracy: 0.9064\n","\n","Epoch 00354: val_accuracy did not improve from 0.93596\n","Epoch 355/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4298 - val_accuracy: 0.9089\n","\n","Epoch 00355: val_accuracy did not improve from 0.93596\n","Epoch 356/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4365 - val_accuracy: 0.9089\n","\n","Epoch 00356: val_accuracy did not improve from 0.93596\n","Epoch 357/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9187\n","\n","Epoch 00357: val_accuracy did not improve from 0.93596\n","Epoch 358/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.9163\n","\n","Epoch 00358: val_accuracy did not improve from 0.93596\n","Epoch 359/500\n","52/52 [==============================] - 20s 389ms/step - loss: 9.3357e-04 - accuracy: 0.9994 - val_loss: 0.4773 - val_accuracy: 0.8966\n","\n","Epoch 00359: val_accuracy did not improve from 0.93596\n","Epoch 360/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.4836e-04 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.9187\n","\n","Epoch 00360: val_accuracy did not improve from 0.93596\n","Epoch 361/500\n","52/52 [==============================] - 20s 388ms/step - loss: 5.0195e-04 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9236\n","\n","Epoch 00361: val_accuracy did not improve from 0.93596\n","Epoch 362/500\n","52/52 [==============================] - 20s 388ms/step - loss: 8.3407e-04 - accuracy: 0.9994 - val_loss: 0.4607 - val_accuracy: 0.9064\n","\n","Epoch 00362: val_accuracy did not improve from 0.93596\n","Epoch 363/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4867 - val_accuracy: 0.8990\n","\n","Epoch 00363: val_accuracy did not improve from 0.93596\n","Epoch 364/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4513 - val_accuracy: 0.9187\n","\n","Epoch 00364: val_accuracy did not improve from 0.93596\n","Epoch 365/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 0.6357 - val_accuracy: 0.8892\n","\n","Epoch 00365: val_accuracy did not improve from 0.93596\n","Epoch 366/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0095 - accuracy: 0.9957 - val_loss: 0.6213 - val_accuracy: 0.8966\n","\n","Epoch 00366: val_accuracy did not improve from 0.93596\n","Epoch 367/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.5687 - val_accuracy: 0.8941\n","\n","Epoch 00367: val_accuracy did not improve from 0.93596\n","Epoch 368/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4596 - val_accuracy: 0.9064\n","\n","Epoch 00368: val_accuracy did not improve from 0.93596\n","Epoch 369/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.3335 - val_accuracy: 0.9286\n","\n","Epoch 00369: val_accuracy did not improve from 0.93596\n","Epoch 370/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9187\n","\n","Epoch 00370: val_accuracy did not improve from 0.93596\n","Epoch 371/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3628 - val_accuracy: 0.9163\n","\n","Epoch 00371: val_accuracy did not improve from 0.93596\n","Epoch 372/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.9138\n","\n","Epoch 00372: val_accuracy did not improve from 0.93596\n","Epoch 373/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4264 - val_accuracy: 0.9089\n","\n","Epoch 00373: val_accuracy did not improve from 0.93596\n","Epoch 374/500\n","52/52 [==============================] - 20s 388ms/step - loss: 5.8239e-04 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9138\n","\n","Epoch 00374: val_accuracy did not improve from 0.93596\n","Epoch 375/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.4012e-04 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.9039\n","\n","Epoch 00375: val_accuracy did not improve from 0.93596\n","Epoch 376/500\n","52/52 [==============================] - 20s 389ms/step - loss: 1.7730e-04 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9113\n","\n","Epoch 00376: val_accuracy did not improve from 0.93596\n","Epoch 377/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.7382e-04 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 0.9138\n","\n","Epoch 00377: val_accuracy did not improve from 0.93596\n","Epoch 378/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.4791 - val_accuracy: 0.8966\n","\n","Epoch 00378: val_accuracy did not improve from 0.93596\n","Epoch 379/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4354 - val_accuracy: 0.9138\n","\n","Epoch 00379: val_accuracy did not improve from 0.93596\n","Epoch 380/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.5757 - val_accuracy: 0.8966\n","\n","Epoch 00380: val_accuracy did not improve from 0.93596\n","Epoch 381/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0573 - accuracy: 0.9811 - val_loss: 1.0126 - val_accuracy: 0.8227\n","\n","Epoch 00381: val_accuracy did not improve from 0.93596\n","Epoch 382/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0493 - accuracy: 0.9805 - val_loss: 0.5649 - val_accuracy: 0.8793\n","\n","Epoch 00382: val_accuracy did not improve from 0.93596\n","Epoch 383/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.4982 - val_accuracy: 0.8990\n","\n","Epoch 00383: val_accuracy did not improve from 0.93596\n","Epoch 384/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.4572 - val_accuracy: 0.9187\n","\n","Epoch 00384: val_accuracy did not improve from 0.93596\n","Epoch 385/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0172 - accuracy: 0.9933 - val_loss: 0.5052 - val_accuracy: 0.8990\n","\n","Epoch 00385: val_accuracy did not improve from 0.93596\n","Epoch 386/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4257 - val_accuracy: 0.9113\n","\n","Epoch 00386: val_accuracy did not improve from 0.93596\n","Epoch 387/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9187\n","\n","Epoch 00387: val_accuracy did not improve from 0.93596\n","Epoch 388/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4179 - val_accuracy: 0.9089\n","\n","Epoch 00388: val_accuracy did not improve from 0.93596\n","Epoch 389/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.5302 - val_accuracy: 0.9064\n","\n","Epoch 00389: val_accuracy did not improve from 0.93596\n","Epoch 390/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.5401 - val_accuracy: 0.9138\n","\n","Epoch 00390: val_accuracy did not improve from 0.93596\n","Epoch 391/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.4273 - val_accuracy: 0.9089\n","\n","Epoch 00391: val_accuracy did not improve from 0.93596\n","Epoch 392/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.5707 - val_accuracy: 0.8966\n","\n","Epoch 00392: val_accuracy did not improve from 0.93596\n","Epoch 393/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 0.4514 - val_accuracy: 0.8990\n","\n","Epoch 00393: val_accuracy did not improve from 0.93596\n","Epoch 394/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5218 - val_accuracy: 0.9015\n","\n","Epoch 00394: val_accuracy did not improve from 0.93596\n","Epoch 395/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.4675 - val_accuracy: 0.9089\n","\n","Epoch 00395: val_accuracy did not improve from 0.93596\n","Epoch 396/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4360 - val_accuracy: 0.9089\n","\n","Epoch 00396: val_accuracy did not improve from 0.93596\n","Epoch 397/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.4743 - val_accuracy: 0.8966\n","\n","Epoch 00397: val_accuracy did not improve from 0.93596\n","Epoch 398/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4428 - val_accuracy: 0.9138\n","\n","Epoch 00398: val_accuracy did not improve from 0.93596\n","Epoch 399/500\n","52/52 [==============================] - 20s 392ms/step - loss: 9.1631e-04 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9187\n","\n","Epoch 00399: val_accuracy did not improve from 0.93596\n","Epoch 400/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.4415e-04 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.9163\n","\n","Epoch 00400: val_accuracy did not improve from 0.93596\n","Epoch 401/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.5275 - val_accuracy: 0.8990\n","\n","Epoch 00401: val_accuracy did not improve from 0.93596\n","Epoch 402/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4475 - val_accuracy: 0.9138\n","\n","Epoch 00402: val_accuracy did not improve from 0.93596\n","Epoch 403/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.9089\n","\n","Epoch 00403: val_accuracy did not improve from 0.93596\n","Epoch 404/500\n","52/52 [==============================] - 20s 387ms/step - loss: 8.9268e-04 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.9187\n","\n","Epoch 00404: val_accuracy did not improve from 0.93596\n","Epoch 405/500\n","52/52 [==============================] - 20s 389ms/step - loss: 2.8434e-04 - accuracy: 1.0000 - val_loss: 0.3896 - val_accuracy: 0.9089\n","\n","Epoch 00405: val_accuracy did not improve from 0.93596\n","Epoch 406/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.1345e-04 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.9212\n","\n","Epoch 00406: val_accuracy did not improve from 0.93596\n","Epoch 407/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.1141e-04 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.9138\n","\n","Epoch 00407: val_accuracy did not improve from 0.93596\n","Epoch 408/500\n","52/52 [==============================] - 20s 388ms/step - loss: 7.9527e-04 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.9212\n","\n","Epoch 00408: val_accuracy did not improve from 0.93596\n","Epoch 409/500\n","52/52 [==============================] - 20s 389ms/step - loss: 3.0638e-04 - accuracy: 1.0000 - val_loss: 0.4116 - val_accuracy: 0.9187\n","\n","Epoch 00409: val_accuracy did not improve from 0.93596\n","Epoch 410/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5156 - val_accuracy: 0.8916\n","\n","Epoch 00410: val_accuracy did not improve from 0.93596\n","Epoch 411/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.8011 - val_accuracy: 0.8645\n","\n","Epoch 00411: val_accuracy did not improve from 0.93596\n","Epoch 412/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0263 - accuracy: 0.9927 - val_loss: 0.8606 - val_accuracy: 0.8768\n","\n","Epoch 00412: val_accuracy did not improve from 0.93596\n","Epoch 413/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0281 - accuracy: 0.9903 - val_loss: 0.7584 - val_accuracy: 0.8522\n","\n","Epoch 00413: val_accuracy did not improve from 0.93596\n","Epoch 414/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0186 - accuracy: 0.9921 - val_loss: 0.7593 - val_accuracy: 0.8596\n","\n","Epoch 00414: val_accuracy did not improve from 0.93596\n","Epoch 415/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.6787 - val_accuracy: 0.9015\n","\n","Epoch 00415: val_accuracy did not improve from 0.93596\n","Epoch 416/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.5680 - val_accuracy: 0.9039\n","\n","Epoch 00416: val_accuracy did not improve from 0.93596\n","Epoch 417/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.6052 - val_accuracy: 0.8719\n","\n","Epoch 00417: val_accuracy did not improve from 0.93596\n","Epoch 418/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.5573 - val_accuracy: 0.8990\n","\n","Epoch 00418: val_accuracy did not improve from 0.93596\n","Epoch 419/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.9187\n","\n","Epoch 00419: val_accuracy did not improve from 0.93596\n","Epoch 420/500\n","52/52 [==============================] - 20s 389ms/step - loss: 7.9273e-04 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.8941\n","\n","Epoch 00420: val_accuracy did not improve from 0.93596\n","Epoch 421/500\n","52/52 [==============================] - 20s 390ms/step - loss: 8.1011e-04 - accuracy: 1.0000 - val_loss: 0.4531 - val_accuracy: 0.9163\n","\n","Epoch 00421: val_accuracy did not improve from 0.93596\n","Epoch 422/500\n","52/52 [==============================] - 20s 387ms/step - loss: 6.5387e-04 - accuracy: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.8966\n","\n","Epoch 00422: val_accuracy did not improve from 0.93596\n","Epoch 423/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4938 - val_accuracy: 0.9089\n","\n","Epoch 00423: val_accuracy did not improve from 0.93596\n","Epoch 424/500\n","52/52 [==============================] - 20s 388ms/step - loss: 9.2692e-04 - accuracy: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.9113\n","\n","Epoch 00424: val_accuracy did not improve from 0.93596\n","Epoch 425/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.8887e-04 - accuracy: 1.0000 - val_loss: 0.4110 - val_accuracy: 0.9138\n","\n","Epoch 00425: val_accuracy did not improve from 0.93596\n","Epoch 426/500\n","52/52 [==============================] - 20s 390ms/step - loss: 3.4778e-04 - accuracy: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.9089\n","\n","Epoch 00426: val_accuracy did not improve from 0.93596\n","Epoch 427/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0362 - accuracy: 0.9890 - val_loss: 0.9857 - val_accuracy: 0.8473\n","\n","Epoch 00427: val_accuracy did not improve from 0.93596\n","Epoch 428/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0203 - accuracy: 0.9921 - val_loss: 1.0726 - val_accuracy: 0.8448\n","\n","Epoch 00428: val_accuracy did not improve from 0.93596\n","Epoch 429/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.5561 - val_accuracy: 0.9138\n","\n","Epoch 00429: val_accuracy did not improve from 0.93596\n","Epoch 430/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.5644 - val_accuracy: 0.8990\n","\n","Epoch 00430: val_accuracy did not improve from 0.93596\n","Epoch 431/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.6180 - val_accuracy: 0.8842\n","\n","Epoch 00431: val_accuracy did not improve from 0.93596\n","Epoch 432/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.8214 - val_accuracy: 0.8571\n","\n","Epoch 00432: val_accuracy did not improve from 0.93596\n","Epoch 433/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 0.6304 - val_accuracy: 0.8867\n","\n","Epoch 00433: val_accuracy did not improve from 0.93596\n","Epoch 434/500\n","52/52 [==============================] - 20s 389ms/step - loss: 9.7778e-04 - accuracy: 1.0000 - val_loss: 0.5854 - val_accuracy: 0.8941\n","\n","Epoch 00434: val_accuracy did not improve from 0.93596\n","Epoch 435/500\n","52/52 [==============================] - 20s 388ms/step - loss: 9.9526e-04 - accuracy: 1.0000 - val_loss: 0.6008 - val_accuracy: 0.9064\n","\n","Epoch 00435: val_accuracy did not improve from 0.93596\n","Epoch 436/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.6229 - val_accuracy: 0.8990\n","\n","Epoch 00436: val_accuracy did not improve from 0.93596\n","Epoch 437/500\n","52/52 [==============================] - 20s 390ms/step - loss: 3.5939e-04 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.9039\n","\n","Epoch 00437: val_accuracy did not improve from 0.93596\n","Epoch 438/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.6056 - val_accuracy: 0.9064\n","\n","Epoch 00438: val_accuracy did not improve from 0.93596\n","Epoch 439/500\n","52/52 [==============================] - 20s 388ms/step - loss: 7.5206e-04 - accuracy: 1.0000 - val_loss: 0.5737 - val_accuracy: 0.9113\n","\n","Epoch 00439: val_accuracy did not improve from 0.93596\n","Epoch 440/500\n","52/52 [==============================] - 20s 387ms/step - loss: 9.0992e-04 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 0.8966\n","\n","Epoch 00440: val_accuracy did not improve from 0.93596\n","Epoch 441/500\n","52/52 [==============================] - 20s 387ms/step - loss: 7.3338e-04 - accuracy: 1.0000 - val_loss: 0.5997 - val_accuracy: 0.9015\n","\n","Epoch 00441: val_accuracy did not improve from 0.93596\n","Epoch 442/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0466 - accuracy: 0.9884 - val_loss: 1.1042 - val_accuracy: 0.8424\n","\n","Epoch 00442: val_accuracy did not improve from 0.93596\n","Epoch 443/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0598 - accuracy: 0.9848 - val_loss: 0.9487 - val_accuracy: 0.8300\n","\n","Epoch 00443: val_accuracy did not improve from 0.93596\n","Epoch 444/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.6081 - val_accuracy: 0.8744\n","\n","Epoch 00444: val_accuracy did not improve from 0.93596\n","Epoch 445/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.7441 - val_accuracy: 0.8744\n","\n","Epoch 00445: val_accuracy did not improve from 0.93596\n","Epoch 446/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.5169 - val_accuracy: 0.9039\n","\n","Epoch 00446: val_accuracy did not improve from 0.93596\n","Epoch 447/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5556 - val_accuracy: 0.8793\n","\n","Epoch 00447: val_accuracy did not improve from 0.93596\n","Epoch 448/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.5223 - val_accuracy: 0.8990\n","\n","Epoch 00448: val_accuracy did not improve from 0.93596\n","Epoch 449/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5311 - val_accuracy: 0.8892\n","\n","Epoch 00449: val_accuracy did not improve from 0.93596\n","Epoch 450/500\n","52/52 [==============================] - 20s 387ms/step - loss: 5.0451e-04 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.9064\n","\n","Epoch 00450: val_accuracy did not improve from 0.93596\n","Epoch 451/500\n","52/52 [==============================] - 20s 387ms/step - loss: 8.2714e-04 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.9064\n","\n","Epoch 00451: val_accuracy did not improve from 0.93596\n","Epoch 452/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.1853e-04 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.9113\n","\n","Epoch 00452: val_accuracy did not improve from 0.93596\n","Epoch 453/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0030 - accuracy: 0.9976 - val_loss: 0.4554 - val_accuracy: 0.9089\n","\n","Epoch 00453: val_accuracy did not improve from 0.93596\n","Epoch 454/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0611 - accuracy: 0.9890 - val_loss: 1.8233 - val_accuracy: 0.7512\n","\n","Epoch 00454: val_accuracy did not improve from 0.93596\n","Epoch 455/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0624 - accuracy: 0.9829 - val_loss: 2.4194 - val_accuracy: 0.7143\n","\n","Epoch 00455: val_accuracy did not improve from 0.93596\n","Epoch 456/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.6619 - val_accuracy: 0.8818\n","\n","Epoch 00456: val_accuracy did not improve from 0.93596\n","Epoch 457/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.8966\n","\n","Epoch 00457: val_accuracy did not improve from 0.93596\n","Epoch 458/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.9064\n","\n","Epoch 00458: val_accuracy did not improve from 0.93596\n","Epoch 459/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.4651 - val_accuracy: 0.8966\n","\n","Epoch 00459: val_accuracy did not improve from 0.93596\n","Epoch 460/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.6250 - val_accuracy: 0.8867\n","\n","Epoch 00460: val_accuracy did not improve from 0.93596\n","Epoch 461/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0309 - accuracy: 0.9945 - val_loss: 0.8011 - val_accuracy: 0.8522\n","\n","Epoch 00461: val_accuracy did not improve from 0.93596\n","Epoch 462/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.5150 - val_accuracy: 0.8941\n","\n","Epoch 00462: val_accuracy did not improve from 0.93596\n","Epoch 463/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4911 - val_accuracy: 0.8842\n","\n","Epoch 00463: val_accuracy did not improve from 0.93596\n","Epoch 464/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.5421 - val_accuracy: 0.8892\n","\n","Epoch 00464: val_accuracy did not improve from 0.93596\n","Epoch 465/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5469 - val_accuracy: 0.8966\n","\n","Epoch 00465: val_accuracy did not improve from 0.93596\n","Epoch 466/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4467 - val_accuracy: 0.9039\n","\n","Epoch 00466: val_accuracy did not improve from 0.93596\n","Epoch 467/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4613 - val_accuracy: 0.9015\n","\n","Epoch 00467: val_accuracy did not improve from 0.93596\n","Epoch 468/500\n","52/52 [==============================] - 20s 389ms/step - loss: 7.0173e-04 - accuracy: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.9089\n","\n","Epoch 00468: val_accuracy did not improve from 0.93596\n","Epoch 469/500\n","52/52 [==============================] - 20s 389ms/step - loss: 3.9356e-04 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.9064\n","\n","Epoch 00469: val_accuracy did not improve from 0.93596\n","Epoch 470/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.4491e-04 - accuracy: 1.0000 - val_loss: 0.4631 - val_accuracy: 0.9261\n","\n","Epoch 00470: val_accuracy did not improve from 0.93596\n","Epoch 471/500\n","52/52 [==============================] - 20s 386ms/step - loss: 7.6316e-04 - accuracy: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.9113\n","\n","Epoch 00471: val_accuracy did not improve from 0.93596\n","Epoch 472/500\n","52/52 [==============================] - 20s 389ms/step - loss: 4.7463e-04 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.9138\n","\n","Epoch 00472: val_accuracy did not improve from 0.93596\n","Epoch 473/500\n","52/52 [==============================] - 20s 388ms/step - loss: 7.4778e-04 - accuracy: 1.0000 - val_loss: 0.5203 - val_accuracy: 0.9064\n","\n","Epoch 00473: val_accuracy did not improve from 0.93596\n","Epoch 474/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.7335e-04 - accuracy: 1.0000 - val_loss: 0.5538 - val_accuracy: 0.8990\n","\n","Epoch 00474: val_accuracy did not improve from 0.93596\n","Epoch 475/500\n","52/52 [==============================] - 20s 387ms/step - loss: 5.1594e-04 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.9261\n","\n","Epoch 00475: val_accuracy did not improve from 0.93596\n","Epoch 476/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9138\n","\n","Epoch 00476: val_accuracy did not improve from 0.93596\n","Epoch 477/500\n","52/52 [==============================] - 20s 389ms/step - loss: 7.1546e-04 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.9163\n","\n","Epoch 00477: val_accuracy did not improve from 0.93596\n","Epoch 478/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.4602e-04 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.9236\n","\n","Epoch 00478: val_accuracy did not improve from 0.93596\n","Epoch 479/500\n","52/52 [==============================] - 20s 388ms/step - loss: 1.3184e-04 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9187\n","\n","Epoch 00479: val_accuracy did not improve from 0.93596\n","Epoch 480/500\n","52/52 [==============================] - 20s 388ms/step - loss: 8.4297e-04 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9163\n","\n","Epoch 00480: val_accuracy did not improve from 0.93596\n","Epoch 481/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.5082 - val_accuracy: 0.9039\n","\n","Epoch 00481: val_accuracy did not improve from 0.93596\n","Epoch 482/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.4303e-04 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.9089\n","\n","Epoch 00482: val_accuracy did not improve from 0.93596\n","Epoch 483/500\n","52/52 [==============================] - 20s 388ms/step - loss: 1.8535e-04 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.9113\n","\n","Epoch 00483: val_accuracy did not improve from 0.93596\n","Epoch 484/500\n","52/52 [==============================] - 20s 389ms/step - loss: 3.3620e-04 - accuracy: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.9187\n","\n","Epoch 00484: val_accuracy did not improve from 0.93596\n","Epoch 485/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.0173e-04 - accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.9163\n","\n","Epoch 00485: val_accuracy did not improve from 0.93596\n","Epoch 486/500\n","52/52 [==============================] - 20s 390ms/step - loss: 2.7866e-04 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.9187\n","\n","Epoch 00486: val_accuracy did not improve from 0.93596\n","Epoch 487/500\n","52/52 [==============================] - 20s 389ms/step - loss: 2.1634e-04 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.9163\n","\n","Epoch 00487: val_accuracy did not improve from 0.93596\n","Epoch 488/500\n","52/52 [==============================] - 20s 390ms/step - loss: 1.8379e-04 - accuracy: 1.0000 - val_loss: 0.5560 - val_accuracy: 0.9015\n","\n","Epoch 00488: val_accuracy did not improve from 0.93596\n","Epoch 489/500\n","52/52 [==============================] - 20s 387ms/step - loss: 8.7070e-05 - accuracy: 1.0000 - val_loss: 0.5064 - val_accuracy: 0.9187\n","\n","Epoch 00489: val_accuracy did not improve from 0.93596\n","Epoch 490/500\n","52/52 [==============================] - 20s 390ms/step - loss: 1.6770e-04 - accuracy: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.9113\n","\n","Epoch 00490: val_accuracy did not improve from 0.93596\n","Epoch 491/500\n","52/52 [==============================] - 20s 388ms/step - loss: 7.6128e-05 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.9064\n","\n","Epoch 00491: val_accuracy did not improve from 0.93596\n","Epoch 492/500\n","52/52 [==============================] - 20s 387ms/step - loss: 1.0690e-04 - accuracy: 1.0000 - val_loss: 0.5751 - val_accuracy: 0.9064\n","\n","Epoch 00492: val_accuracy did not improve from 0.93596\n","Epoch 493/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.9906e-04 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.9212\n","\n","Epoch 00493: val_accuracy did not improve from 0.93596\n","Epoch 494/500\n","52/52 [==============================] - 20s 390ms/step - loss: 3.8338e-04 - accuracy: 1.0000 - val_loss: 0.5251 - val_accuracy: 0.9089\n","\n","Epoch 00494: val_accuracy did not improve from 0.93596\n","Epoch 495/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.0449e-04 - accuracy: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.9138\n","\n","Epoch 00495: val_accuracy did not improve from 0.93596\n","Epoch 496/500\n","52/52 [==============================] - 20s 388ms/step - loss: 8.5391e-05 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.9163\n","\n","Epoch 00496: val_accuracy did not improve from 0.93596\n","Epoch 497/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.3967e-04 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.9089\n","\n","Epoch 00497: val_accuracy did not improve from 0.93596\n","Epoch 498/500\n","52/52 [==============================] - 20s 387ms/step - loss: 3.5216e-04 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.9089\n","\n","Epoch 00498: val_accuracy did not improve from 0.93596\n","Epoch 499/500\n","52/52 [==============================] - 20s 389ms/step - loss: 2.7016e-04 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.9089\n","\n","Epoch 00499: val_accuracy did not improve from 0.93596\n","Epoch 500/500\n","52/52 [==============================] - 20s 388ms/step - loss: 1.0551e-04 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9212\n","\n","Epoch 00500: val_accuracy did not improve from 0.93596\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fab8074d5d0>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1629932141730,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"431fe99d-54cd-44bf-fed0-2c606ecdbb2a"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1629932165016,"user_tz":-540,"elapsed":23292,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_1_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1629932165916,"user_tz":-540,"elapsed":926,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629932166765,"user_tz":-540,"elapsed":852,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"011caedf-b81b-4035-c594-6faa7989a797"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Found 20480 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629932222842,"user_tz":-540,"elapsed":56083,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b0658fa2-36e2-41f6-fdf7-b8eac0da4c14"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1629932223269,"user_tz":-540,"elapsed":434,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1629932223270,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1629932224112,"user_tz":-540,"elapsed":847,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1629932224119,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1629932235744,"user_tz":-540,"elapsed":11633,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1629932235750,"user_tz":-540,"elapsed":30,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"4e1fbc6f-f014-4a2e-9554-0fdd8836aa3a"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1629932235751,"user_tz":-540,"elapsed":15,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"003d491c-dcb4-477d-f994-fb8348e8705c"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_000_1_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_000_1_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_904e8a6f-43e9-4c04-adaf-1f3907a6c926\", \"WidthShiftRange_000_1_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}