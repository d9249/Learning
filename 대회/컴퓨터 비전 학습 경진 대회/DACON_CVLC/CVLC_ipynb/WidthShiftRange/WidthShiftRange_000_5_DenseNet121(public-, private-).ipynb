{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WidthShiftRange_000_5_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPju1R6WAHlWLBFc07KlJCW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629934011109,"user_tz":-540,"elapsed":398,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0932c4a8-7e8b-4db1-c7d6-610519c84c81"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Wed Aug 25 23:26:50 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629934030345,"user_tz":-540,"elapsed":19242,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"be8130cc-bc2e-47ed-d65b-628355b51d20"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1629934033723,"user_tz":-540,"elapsed":2964,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1629934034995,"user_tz":-540,"elapsed":1279,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1629934037722,"user_tz":-540,"elapsed":2459,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1629934057886,"user_tz":-540,"elapsed":20169,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1629934065643,"user_tz":-540,"elapsed":7766,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629934065651,"user_tz":-540,"elapsed":22,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b787e837-528b-4e18-db33-81cbdfd35685"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629934065652,"user_tz":-540,"elapsed":18,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ecc8f5c5-bac4-48f6-f555-3cab8c73c422"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.0,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1629934065653,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629939945317,"user_tz":-540,"elapsed":5879677,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"48ea431d-df1c-4335-d9a5-425fa4e5a7e4"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 42s 282ms/step - loss: 1.8307 - accuracy: 0.3514 - val_loss: 9.2161 - val_accuracy: 0.1108\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 11s 219ms/step - loss: 1.2122 - accuracy: 0.5993 - val_loss: 23.4446 - val_accuracy: 0.0911\n","\n","Epoch 00002: val_accuracy did not improve from 0.11084\n","Epoch 3/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.9643 - accuracy: 0.6839 - val_loss: 16.5244 - val_accuracy: 0.0936\n","\n","Epoch 00003: val_accuracy did not improve from 0.11084\n","Epoch 4/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.7919 - accuracy: 0.7381 - val_loss: 8.1813 - val_accuracy: 0.1330\n","\n","Epoch 00004: val_accuracy improved from 0.11084 to 0.13300, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 5/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.6720 - accuracy: 0.7680 - val_loss: 5.6910 - val_accuracy: 0.1552\n","\n","Epoch 00005: val_accuracy improved from 0.13300 to 0.15517, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.6316 - accuracy: 0.7923 - val_loss: 5.0632 - val_accuracy: 0.2365\n","\n","Epoch 00006: val_accuracy improved from 0.15517 to 0.23645, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.5182 - accuracy: 0.8264 - val_loss: 5.0624 - val_accuracy: 0.2611\n","\n","Epoch 00007: val_accuracy improved from 0.23645 to 0.26108, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.5670 - accuracy: 0.8009 - val_loss: 4.9057 - val_accuracy: 0.2882\n","\n","Epoch 00008: val_accuracy improved from 0.26108 to 0.28818, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.4987 - accuracy: 0.8234 - val_loss: 8.0775 - val_accuracy: 0.2463\n","\n","Epoch 00009: val_accuracy did not improve from 0.28818\n","Epoch 10/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.4756 - accuracy: 0.8429 - val_loss: 1.9963 - val_accuracy: 0.5394\n","\n","Epoch 00010: val_accuracy improved from 0.28818 to 0.53941, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3694 - accuracy: 0.8782 - val_loss: 1.1751 - val_accuracy: 0.7118\n","\n","Epoch 00011: val_accuracy improved from 0.53941 to 0.71182, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3877 - accuracy: 0.8648 - val_loss: 1.3244 - val_accuracy: 0.6798\n","\n","Epoch 00012: val_accuracy did not improve from 0.71182\n","Epoch 13/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3451 - accuracy: 0.8831 - val_loss: 0.6411 - val_accuracy: 0.8079\n","\n","Epoch 00013: val_accuracy improved from 0.71182 to 0.80788, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 14/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2856 - accuracy: 0.9086 - val_loss: 0.9318 - val_accuracy: 0.7365\n","\n","Epoch 00014: val_accuracy did not improve from 0.80788\n","Epoch 15/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.3130 - accuracy: 0.8940 - val_loss: 0.9538 - val_accuracy: 0.7611\n","\n","Epoch 00015: val_accuracy did not improve from 0.80788\n","Epoch 16/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2722 - accuracy: 0.9099 - val_loss: 0.6792 - val_accuracy: 0.7956\n","\n","Epoch 00016: val_accuracy did not improve from 0.80788\n","Epoch 17/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2562 - accuracy: 0.9135 - val_loss: 1.1948 - val_accuracy: 0.6724\n","\n","Epoch 00017: val_accuracy did not improve from 0.80788\n","Epoch 18/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2531 - accuracy: 0.9178 - val_loss: 0.8082 - val_accuracy: 0.7783\n","\n","Epoch 00018: val_accuracy did not improve from 0.80788\n","Epoch 19/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2932 - accuracy: 0.8989 - val_loss: 5.6837 - val_accuracy: 0.2833\n","\n","Epoch 00019: val_accuracy did not improve from 0.80788\n","Epoch 20/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.2671 - accuracy: 0.9093 - val_loss: 0.8659 - val_accuracy: 0.7562\n","\n","Epoch 00020: val_accuracy did not improve from 0.80788\n","Epoch 21/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2302 - accuracy: 0.9294 - val_loss: 0.6374 - val_accuracy: 0.8054\n","\n","Epoch 00021: val_accuracy did not improve from 0.80788\n","Epoch 22/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2260 - accuracy: 0.9172 - val_loss: 0.9662 - val_accuracy: 0.7808\n","\n","Epoch 00022: val_accuracy did not improve from 0.80788\n","Epoch 23/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.2363 - accuracy: 0.9196 - val_loss: 0.6619 - val_accuracy: 0.7833\n","\n","Epoch 00023: val_accuracy did not improve from 0.80788\n","Epoch 24/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1837 - accuracy: 0.9379 - val_loss: 0.7432 - val_accuracy: 0.7931\n","\n","Epoch 00024: val_accuracy did not improve from 0.80788\n","Epoch 25/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1328 - accuracy: 0.9580 - val_loss: 0.6266 - val_accuracy: 0.8325\n","\n","Epoch 00025: val_accuracy improved from 0.80788 to 0.83251, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 26/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1734 - accuracy: 0.9354 - val_loss: 0.6924 - val_accuracy: 0.7882\n","\n","Epoch 00026: val_accuracy did not improve from 0.83251\n","Epoch 27/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1265 - accuracy: 0.9574 - val_loss: 0.5700 - val_accuracy: 0.8522\n","\n","Epoch 00027: val_accuracy improved from 0.83251 to 0.85222, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 28/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1806 - accuracy: 0.9336 - val_loss: 0.7134 - val_accuracy: 0.8128\n","\n","Epoch 00028: val_accuracy did not improve from 0.85222\n","Epoch 29/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1380 - accuracy: 0.9562 - val_loss: 0.6351 - val_accuracy: 0.8276\n","\n","Epoch 00029: val_accuracy did not improve from 0.85222\n","Epoch 30/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1449 - accuracy: 0.9519 - val_loss: 0.4920 - val_accuracy: 0.8621\n","\n","Epoch 00030: val_accuracy improved from 0.85222 to 0.86207, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 31/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1151 - accuracy: 0.9629 - val_loss: 0.7638 - val_accuracy: 0.7980\n","\n","Epoch 00031: val_accuracy did not improve from 0.86207\n","Epoch 32/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1683 - accuracy: 0.9421 - val_loss: 0.4393 - val_accuracy: 0.8744\n","\n","Epoch 00032: val_accuracy improved from 0.86207 to 0.87438, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 33/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1110 - accuracy: 0.9592 - val_loss: 0.4618 - val_accuracy: 0.8744\n","\n","Epoch 00033: val_accuracy did not improve from 0.87438\n","Epoch 34/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0927 - accuracy: 0.9695 - val_loss: 0.4881 - val_accuracy: 0.8547\n","\n","Epoch 00034: val_accuracy did not improve from 0.87438\n","Epoch 35/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0881 - accuracy: 0.9732 - val_loss: 0.3581 - val_accuracy: 0.8916\n","\n","Epoch 00035: val_accuracy improved from 0.87438 to 0.89163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 36/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1012 - accuracy: 0.9677 - val_loss: 0.6182 - val_accuracy: 0.8473\n","\n","Epoch 00036: val_accuracy did not improve from 0.89163\n","Epoch 37/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0998 - accuracy: 0.9683 - val_loss: 0.5988 - val_accuracy: 0.8473\n","\n","Epoch 00037: val_accuracy did not improve from 0.89163\n","Epoch 38/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0813 - accuracy: 0.9781 - val_loss: 0.4413 - val_accuracy: 0.8744\n","\n","Epoch 00038: val_accuracy did not improve from 0.89163\n","Epoch 39/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1614 - accuracy: 0.9379 - val_loss: 0.6498 - val_accuracy: 0.8276\n","\n","Epoch 00039: val_accuracy did not improve from 0.89163\n","Epoch 40/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1636 - accuracy: 0.9482 - val_loss: 0.8462 - val_accuracy: 0.8103\n","\n","Epoch 00040: val_accuracy did not improve from 0.89163\n","Epoch 41/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1072 - accuracy: 0.9641 - val_loss: 0.5846 - val_accuracy: 0.8424\n","\n","Epoch 00041: val_accuracy did not improve from 0.89163\n","Epoch 42/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1755 - accuracy: 0.9428 - val_loss: 0.8681 - val_accuracy: 0.7956\n","\n","Epoch 00042: val_accuracy did not improve from 0.89163\n","Epoch 43/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1269 - accuracy: 0.9568 - val_loss: 0.7720 - val_accuracy: 0.8128\n","\n","Epoch 00043: val_accuracy did not improve from 0.89163\n","Epoch 44/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1080 - accuracy: 0.9635 - val_loss: 0.4581 - val_accuracy: 0.8695\n","\n","Epoch 00044: val_accuracy did not improve from 0.89163\n","Epoch 45/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0674 - accuracy: 0.9793 - val_loss: 0.5004 - val_accuracy: 0.8571\n","\n","Epoch 00045: val_accuracy did not improve from 0.89163\n","Epoch 46/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0526 - accuracy: 0.9811 - val_loss: 0.4978 - val_accuracy: 0.8670\n","\n","Epoch 00046: val_accuracy did not improve from 0.89163\n","Epoch 47/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0615 - accuracy: 0.9781 - val_loss: 0.5877 - val_accuracy: 0.8424\n","\n","Epoch 00047: val_accuracy did not improve from 0.89163\n","Epoch 48/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1111 - accuracy: 0.9659 - val_loss: 0.7263 - val_accuracy: 0.8227\n","\n","Epoch 00048: val_accuracy did not improve from 0.89163\n","Epoch 49/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1264 - accuracy: 0.9555 - val_loss: 0.5832 - val_accuracy: 0.8276\n","\n","Epoch 00049: val_accuracy did not improve from 0.89163\n","Epoch 50/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0464 - accuracy: 0.9854 - val_loss: 0.5039 - val_accuracy: 0.8719\n","\n","Epoch 00050: val_accuracy did not improve from 0.89163\n","Epoch 51/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0365 - accuracy: 0.9884 - val_loss: 0.4634 - val_accuracy: 0.8818\n","\n","Epoch 00051: val_accuracy did not improve from 0.89163\n","Epoch 52/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0362 - accuracy: 0.9872 - val_loss: 0.4879 - val_accuracy: 0.8768\n","\n","Epoch 00052: val_accuracy did not improve from 0.89163\n","Epoch 53/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 0.4358 - val_accuracy: 0.8941\n","\n","Epoch 00053: val_accuracy improved from 0.89163 to 0.89409, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 54/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.6797 - val_accuracy: 0.8596\n","\n","Epoch 00054: val_accuracy did not improve from 0.89409\n","Epoch 55/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1090 - accuracy: 0.9671 - val_loss: 5.8270 - val_accuracy: 0.3325\n","\n","Epoch 00055: val_accuracy did not improve from 0.89409\n","Epoch 56/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1753 - accuracy: 0.9409 - val_loss: 0.9246 - val_accuracy: 0.7931\n","\n","Epoch 00056: val_accuracy did not improve from 0.89409\n","Epoch 57/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0940 - accuracy: 0.9695 - val_loss: 0.6840 - val_accuracy: 0.8153\n","\n","Epoch 00057: val_accuracy did not improve from 0.89409\n","Epoch 58/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0978 - accuracy: 0.9629 - val_loss: 0.9078 - val_accuracy: 0.7783\n","\n","Epoch 00058: val_accuracy did not improve from 0.89409\n","Epoch 59/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0630 - accuracy: 0.9793 - val_loss: 0.4139 - val_accuracy: 0.8916\n","\n","Epoch 00059: val_accuracy did not improve from 0.89409\n","Epoch 60/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0584 - accuracy: 0.9805 - val_loss: 0.6727 - val_accuracy: 0.8300\n","\n","Epoch 00060: val_accuracy did not improve from 0.89409\n","Epoch 61/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0592 - accuracy: 0.9799 - val_loss: 0.6278 - val_accuracy: 0.8719\n","\n","Epoch 00061: val_accuracy did not improve from 0.89409\n","Epoch 62/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.4618 - val_accuracy: 0.8645\n","\n","Epoch 00062: val_accuracy did not improve from 0.89409\n","Epoch 63/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 0.4446 - val_accuracy: 0.8892\n","\n","Epoch 00063: val_accuracy did not improve from 0.89409\n","Epoch 64/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 0.5818 - val_accuracy: 0.8547\n","\n","Epoch 00064: val_accuracy did not improve from 0.89409\n","Epoch 65/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0333 - accuracy: 0.9903 - val_loss: 0.5453 - val_accuracy: 0.8867\n","\n","Epoch 00065: val_accuracy did not improve from 0.89409\n","Epoch 66/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0667 - accuracy: 0.9750 - val_loss: 0.5785 - val_accuracy: 0.8645\n","\n","Epoch 00066: val_accuracy did not improve from 0.89409\n","Epoch 67/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0823 - accuracy: 0.9787 - val_loss: 0.5816 - val_accuracy: 0.8621\n","\n","Epoch 00067: val_accuracy did not improve from 0.89409\n","Epoch 68/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0332 - accuracy: 0.9884 - val_loss: 0.7040 - val_accuracy: 0.8177\n","\n","Epoch 00068: val_accuracy did not improve from 0.89409\n","Epoch 69/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.6123 - val_accuracy: 0.8448\n","\n","Epoch 00069: val_accuracy did not improve from 0.89409\n","Epoch 70/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0544 - accuracy: 0.9823 - val_loss: 0.7589 - val_accuracy: 0.8325\n","\n","Epoch 00070: val_accuracy did not improve from 0.89409\n","Epoch 71/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0364 - accuracy: 0.9890 - val_loss: 0.8390 - val_accuracy: 0.8498\n","\n","Epoch 00071: val_accuracy did not improve from 0.89409\n","Epoch 72/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0335 - accuracy: 0.9896 - val_loss: 0.4684 - val_accuracy: 0.8990\n","\n","Epoch 00072: val_accuracy improved from 0.89409 to 0.89901, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 73/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0425 - accuracy: 0.9860 - val_loss: 0.4317 - val_accuracy: 0.8892\n","\n","Epoch 00073: val_accuracy did not improve from 0.89901\n","Epoch 74/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0441 - accuracy: 0.9836 - val_loss: 0.6556 - val_accuracy: 0.8670\n","\n","Epoch 00074: val_accuracy did not improve from 0.89901\n","Epoch 75/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0577 - accuracy: 0.9817 - val_loss: 0.4901 - val_accuracy: 0.9015\n","\n","Epoch 00075: val_accuracy improved from 0.89901 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 76/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0442 - accuracy: 0.9854 - val_loss: 0.3745 - val_accuracy: 0.9113\n","\n","Epoch 00076: val_accuracy improved from 0.90148 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 77/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0406 - accuracy: 0.9896 - val_loss: 0.6681 - val_accuracy: 0.8498\n","\n","Epoch 00077: val_accuracy did not improve from 0.91133\n","Epoch 78/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 1.0803 - val_accuracy: 0.8054\n","\n","Epoch 00078: val_accuracy did not improve from 0.91133\n","Epoch 79/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0562 - accuracy: 0.9787 - val_loss: 0.7363 - val_accuracy: 0.8424\n","\n","Epoch 00079: val_accuracy did not improve from 0.91133\n","Epoch 80/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1064 - accuracy: 0.9647 - val_loss: 1.1263 - val_accuracy: 0.8103\n","\n","Epoch 00080: val_accuracy did not improve from 0.91133\n","Epoch 81/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0587 - accuracy: 0.9805 - val_loss: 0.8527 - val_accuracy: 0.8399\n","\n","Epoch 00081: val_accuracy did not improve from 0.91133\n","Epoch 82/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.4429 - val_accuracy: 0.9039\n","\n","Epoch 00082: val_accuracy did not improve from 0.91133\n","Epoch 83/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.4541 - val_accuracy: 0.8744\n","\n","Epoch 00083: val_accuracy did not improve from 0.91133\n","Epoch 84/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.4792 - val_accuracy: 0.8990\n","\n","Epoch 00084: val_accuracy did not improve from 0.91133\n","Epoch 85/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.4615 - val_accuracy: 0.8966\n","\n","Epoch 00085: val_accuracy did not improve from 0.91133\n","Epoch 86/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.9532 - val_accuracy: 0.7882\n","\n","Epoch 00086: val_accuracy did not improve from 0.91133\n","Epoch 87/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0835 - accuracy: 0.9683 - val_loss: 1.3422 - val_accuracy: 0.7414\n","\n","Epoch 00087: val_accuracy did not improve from 0.91133\n","Epoch 88/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.1081 - accuracy: 0.9671 - val_loss: 0.9703 - val_accuracy: 0.8374\n","\n","Epoch 00088: val_accuracy did not improve from 0.91133\n","Epoch 89/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0463 - accuracy: 0.9842 - val_loss: 0.5176 - val_accuracy: 0.8818\n","\n","Epoch 00089: val_accuracy did not improve from 0.91133\n","Epoch 90/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0429 - accuracy: 0.9860 - val_loss: 0.6776 - val_accuracy: 0.8670\n","\n","Epoch 00090: val_accuracy did not improve from 0.91133\n","Epoch 91/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 0.6249 - val_accuracy: 0.8695\n","\n","Epoch 00091: val_accuracy did not improve from 0.91133\n","Epoch 92/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0269 - accuracy: 0.9896 - val_loss: 0.6905 - val_accuracy: 0.8744\n","\n","Epoch 00092: val_accuracy did not improve from 0.91133\n","Epoch 93/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0551 - accuracy: 0.9805 - val_loss: 0.6195 - val_accuracy: 0.8645\n","\n","Epoch 00093: val_accuracy did not improve from 0.91133\n","Epoch 94/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0766 - accuracy: 0.9769 - val_loss: 0.5696 - val_accuracy: 0.8571\n","\n","Epoch 00094: val_accuracy did not improve from 0.91133\n","Epoch 95/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0550 - accuracy: 0.9793 - val_loss: 1.0148 - val_accuracy: 0.8251\n","\n","Epoch 00095: val_accuracy did not improve from 0.91133\n","Epoch 96/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0552 - accuracy: 0.9775 - val_loss: 0.8140 - val_accuracy: 0.8153\n","\n","Epoch 00096: val_accuracy did not improve from 0.91133\n","Epoch 97/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.5808 - val_accuracy: 0.8818\n","\n","Epoch 00097: val_accuracy did not improve from 0.91133\n","Epoch 98/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.4831 - val_accuracy: 0.8990\n","\n","Epoch 00098: val_accuracy did not improve from 0.91133\n","Epoch 99/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.6378 - val_accuracy: 0.8645\n","\n","Epoch 00099: val_accuracy did not improve from 0.91133\n","Epoch 100/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0295 - accuracy: 0.9945 - val_loss: 0.5228 - val_accuracy: 0.8842\n","\n","Epoch 00100: val_accuracy did not improve from 0.91133\n","Epoch 101/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.5341 - val_accuracy: 0.8966\n","\n","Epoch 00101: val_accuracy did not improve from 0.91133\n","Epoch 102/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.5201 - val_accuracy: 0.9039\n","\n","Epoch 00102: val_accuracy did not improve from 0.91133\n","Epoch 103/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.4467 - val_accuracy: 0.9187\n","\n","Epoch 00103: val_accuracy improved from 0.91133 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 104/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.3804 - val_accuracy: 0.9187\n","\n","Epoch 00104: val_accuracy did not improve from 0.91872\n","Epoch 105/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.4689 - val_accuracy: 0.8966\n","\n","Epoch 00105: val_accuracy did not improve from 0.91872\n","Epoch 106/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0713 - accuracy: 0.9799 - val_loss: 1.2465 - val_accuracy: 0.8005\n","\n","Epoch 00106: val_accuracy did not improve from 0.91872\n","Epoch 107/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1045 - accuracy: 0.9695 - val_loss: 0.9351 - val_accuracy: 0.8054\n","\n","Epoch 00107: val_accuracy did not improve from 0.91872\n","Epoch 108/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0556 - accuracy: 0.9829 - val_loss: 0.7095 - val_accuracy: 0.8768\n","\n","Epoch 00108: val_accuracy did not improve from 0.91872\n","Epoch 109/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.6139 - val_accuracy: 0.8670\n","\n","Epoch 00109: val_accuracy did not improve from 0.91872\n","Epoch 110/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0374 - accuracy: 0.9872 - val_loss: 0.6043 - val_accuracy: 0.8768\n","\n","Epoch 00110: val_accuracy did not improve from 0.91872\n","Epoch 111/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0325 - accuracy: 0.9878 - val_loss: 0.5211 - val_accuracy: 0.8793\n","\n","Epoch 00111: val_accuracy did not improve from 0.91872\n","Epoch 112/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0325 - accuracy: 0.9890 - val_loss: 0.6872 - val_accuracy: 0.8818\n","\n","Epoch 00112: val_accuracy did not improve from 0.91872\n","Epoch 113/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0351 - accuracy: 0.9884 - val_loss: 0.7804 - val_accuracy: 0.8596\n","\n","Epoch 00113: val_accuracy did not improve from 0.91872\n","Epoch 114/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0311 - accuracy: 0.9884 - val_loss: 0.5835 - val_accuracy: 0.8818\n","\n","Epoch 00114: val_accuracy did not improve from 0.91872\n","Epoch 115/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.5456 - val_accuracy: 0.8892\n","\n","Epoch 00115: val_accuracy did not improve from 0.91872\n","Epoch 116/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0275 - accuracy: 0.9915 - val_loss: 0.5662 - val_accuracy: 0.8818\n","\n","Epoch 00116: val_accuracy did not improve from 0.91872\n","Epoch 117/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0326 - accuracy: 0.9896 - val_loss: 0.6878 - val_accuracy: 0.8448\n","\n","Epoch 00117: val_accuracy did not improve from 0.91872\n","Epoch 118/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0487 - accuracy: 0.9836 - val_loss: 1.1941 - val_accuracy: 0.8251\n","\n","Epoch 00118: val_accuracy did not improve from 0.91872\n","Epoch 119/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0569 - accuracy: 0.9829 - val_loss: 0.5348 - val_accuracy: 0.8990\n","\n","Epoch 00119: val_accuracy did not improve from 0.91872\n","Epoch 120/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 0.5759 - val_accuracy: 0.8916\n","\n","Epoch 00120: val_accuracy did not improve from 0.91872\n","Epoch 121/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0235 - accuracy: 0.9909 - val_loss: 0.6133 - val_accuracy: 0.8719\n","\n","Epoch 00121: val_accuracy did not improve from 0.91872\n","Epoch 122/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.6355 - val_accuracy: 0.8793\n","\n","Epoch 00122: val_accuracy did not improve from 0.91872\n","Epoch 123/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0232 - accuracy: 0.9951 - val_loss: 0.6063 - val_accuracy: 0.8892\n","\n","Epoch 00123: val_accuracy did not improve from 0.91872\n","Epoch 124/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 0.5829 - val_accuracy: 0.8842\n","\n","Epoch 00124: val_accuracy did not improve from 0.91872\n","Epoch 125/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.5507 - val_accuracy: 0.8966\n","\n","Epoch 00125: val_accuracy did not improve from 0.91872\n","Epoch 126/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.5095 - val_accuracy: 0.9064\n","\n","Epoch 00126: val_accuracy did not improve from 0.91872\n","Epoch 127/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.5081 - val_accuracy: 0.9064\n","\n","Epoch 00127: val_accuracy did not improve from 0.91872\n","Epoch 128/500\n","52/52 [==============================] - 11s 214ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4910 - val_accuracy: 0.8966\n","\n","Epoch 00128: val_accuracy did not improve from 0.91872\n","Epoch 129/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.4880 - val_accuracy: 0.9015\n","\n","Epoch 00129: val_accuracy did not improve from 0.91872\n","Epoch 130/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5660 - val_accuracy: 0.8916\n","\n","Epoch 00130: val_accuracy did not improve from 0.91872\n","Epoch 131/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.6073 - val_accuracy: 0.8744\n","\n","Epoch 00131: val_accuracy did not improve from 0.91872\n","Epoch 132/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 0.3567 - val_accuracy: 0.9163\n","\n","Epoch 00132: val_accuracy did not improve from 0.91872\n","Epoch 133/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.8042 - val_accuracy: 0.8424\n","\n","Epoch 00133: val_accuracy did not improve from 0.91872\n","Epoch 134/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1107 - accuracy: 0.9671 - val_loss: 1.1852 - val_accuracy: 0.8227\n","\n","Epoch 00134: val_accuracy did not improve from 0.91872\n","Epoch 135/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1283 - accuracy: 0.9574 - val_loss: 2.6333 - val_accuracy: 0.7020\n","\n","Epoch 00135: val_accuracy did not improve from 0.91872\n","Epoch 136/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0676 - accuracy: 0.9750 - val_loss: 0.8086 - val_accuracy: 0.8374\n","\n","Epoch 00136: val_accuracy did not improve from 0.91872\n","Epoch 137/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0230 - accuracy: 0.9939 - val_loss: 0.4952 - val_accuracy: 0.9113\n","\n","Epoch 00137: val_accuracy did not improve from 0.91872\n","Epoch 138/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0245 - accuracy: 0.9909 - val_loss: 0.7334 - val_accuracy: 0.8276\n","\n","Epoch 00138: val_accuracy did not improve from 0.91872\n","Epoch 139/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0334 - accuracy: 0.9903 - val_loss: 0.5141 - val_accuracy: 0.8941\n","\n","Epoch 00139: val_accuracy did not improve from 0.91872\n","Epoch 140/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0190 - accuracy: 0.9927 - val_loss: 0.4577 - val_accuracy: 0.8842\n","\n","Epoch 00140: val_accuracy did not improve from 0.91872\n","Epoch 141/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0326 - accuracy: 0.9921 - val_loss: 0.3887 - val_accuracy: 0.9015\n","\n","Epoch 00141: val_accuracy did not improve from 0.91872\n","Epoch 142/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.4511 - val_accuracy: 0.9015\n","\n","Epoch 00142: val_accuracy did not improve from 0.91872\n","Epoch 143/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0249 - accuracy: 0.9896 - val_loss: 0.6586 - val_accuracy: 0.8695\n","\n","Epoch 00143: val_accuracy did not improve from 0.91872\n","Epoch 144/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.6267 - val_accuracy: 0.8645\n","\n","Epoch 00144: val_accuracy did not improve from 0.91872\n","Epoch 145/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.5157 - val_accuracy: 0.8916\n","\n","Epoch 00145: val_accuracy did not improve from 0.91872\n","Epoch 146/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.5181 - val_accuracy: 0.8867\n","\n","Epoch 00146: val_accuracy did not improve from 0.91872\n","Epoch 147/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.5555 - val_accuracy: 0.8867\n","\n","Epoch 00147: val_accuracy did not improve from 0.91872\n","Epoch 148/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.4353 - val_accuracy: 0.9089\n","\n","Epoch 00148: val_accuracy did not improve from 0.91872\n","Epoch 149/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3840 - val_accuracy: 0.9335\n","\n","Epoch 00149: val_accuracy improved from 0.91872 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 150/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5964 - val_accuracy: 0.8768\n","\n","Epoch 00150: val_accuracy did not improve from 0.93350\n","Epoch 151/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.4525 - val_accuracy: 0.9064\n","\n","Epoch 00151: val_accuracy did not improve from 0.93350\n","Epoch 152/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.9113\n","\n","Epoch 00152: val_accuracy did not improve from 0.93350\n","Epoch 153/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0541 - accuracy: 0.9878 - val_loss: 0.7696 - val_accuracy: 0.8793\n","\n","Epoch 00153: val_accuracy did not improve from 0.93350\n","Epoch 154/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0471 - accuracy: 0.9811 - val_loss: 0.6935 - val_accuracy: 0.8867\n","\n","Epoch 00154: val_accuracy did not improve from 0.93350\n","Epoch 155/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.4369 - val_accuracy: 0.9015\n","\n","Epoch 00155: val_accuracy did not improve from 0.93350\n","Epoch 156/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0333 - accuracy: 0.9884 - val_loss: 0.7029 - val_accuracy: 0.8744\n","\n","Epoch 00156: val_accuracy did not improve from 0.93350\n","Epoch 157/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0875 - accuracy: 0.9702 - val_loss: 0.9430 - val_accuracy: 0.8448\n","\n","Epoch 00157: val_accuracy did not improve from 0.93350\n","Epoch 158/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0734 - accuracy: 0.9775 - val_loss: 1.1107 - val_accuracy: 0.7833\n","\n","Epoch 00158: val_accuracy did not improve from 0.93350\n","Epoch 159/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.1449 - accuracy: 0.9635 - val_loss: 1.0030 - val_accuracy: 0.8448\n","\n","Epoch 00159: val_accuracy did not improve from 0.93350\n","Epoch 160/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 0.4928 - val_accuracy: 0.8990\n","\n","Epoch 00160: val_accuracy did not improve from 0.93350\n","Epoch 161/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.4932 - val_accuracy: 0.8941\n","\n","Epoch 00161: val_accuracy did not improve from 0.93350\n","Epoch 162/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.4372 - val_accuracy: 0.9138\n","\n","Epoch 00162: val_accuracy did not improve from 0.93350\n","Epoch 163/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.9212\n","\n","Epoch 00163: val_accuracy did not improve from 0.93350\n","Epoch 164/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5923 - val_accuracy: 0.8892\n","\n","Epoch 00164: val_accuracy did not improve from 0.93350\n","Epoch 165/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.4877 - val_accuracy: 0.8941\n","\n","Epoch 00165: val_accuracy did not improve from 0.93350\n","Epoch 166/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.5588 - val_accuracy: 0.8793\n","\n","Epoch 00166: val_accuracy did not improve from 0.93350\n","Epoch 167/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0215 - accuracy: 0.9915 - val_loss: 0.5373 - val_accuracy: 0.8867\n","\n","Epoch 00167: val_accuracy did not improve from 0.93350\n","Epoch 168/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.4495 - val_accuracy: 0.8916\n","\n","Epoch 00168: val_accuracy did not improve from 0.93350\n","Epoch 169/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4189 - val_accuracy: 0.9039\n","\n","Epoch 00169: val_accuracy did not improve from 0.93350\n","Epoch 170/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4792 - val_accuracy: 0.9039\n","\n","Epoch 00170: val_accuracy did not improve from 0.93350\n","Epoch 171/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.4153 - val_accuracy: 0.9138\n","\n","Epoch 00171: val_accuracy did not improve from 0.93350\n","Epoch 172/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9261\n","\n","Epoch 00172: val_accuracy did not improve from 0.93350\n","Epoch 173/500\n","52/52 [==============================] - 11s 217ms/step - loss: 7.7672e-04 - accuracy: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.9212\n","\n","Epoch 00173: val_accuracy did not improve from 0.93350\n","Epoch 174/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.9261\n","\n","Epoch 00174: val_accuracy did not improve from 0.93350\n","Epoch 175/500\n","52/52 [==============================] - 11s 215ms/step - loss: 7.8989e-04 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9212\n","\n","Epoch 00175: val_accuracy did not improve from 0.93350\n","Epoch 176/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4128 - val_accuracy: 0.9138\n","\n","Epoch 00176: val_accuracy did not improve from 0.93350\n","Epoch 177/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9138\n","\n","Epoch 00177: val_accuracy did not improve from 0.93350\n","Epoch 178/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4094 - val_accuracy: 0.9089\n","\n","Epoch 00178: val_accuracy did not improve from 0.93350\n","Epoch 179/500\n","52/52 [==============================] - 11s 217ms/step - loss: 5.4734e-04 - accuracy: 1.0000 - val_loss: 0.3687 - val_accuracy: 0.9163\n","\n","Epoch 00179: val_accuracy did not improve from 0.93350\n","Epoch 180/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4530 - val_accuracy: 0.9187\n","\n","Epoch 00180: val_accuracy did not improve from 0.93350\n","Epoch 181/500\n","52/52 [==============================] - 11s 214ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4203 - val_accuracy: 0.9187\n","\n","Epoch 00181: val_accuracy did not improve from 0.93350\n","Epoch 182/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4563 - val_accuracy: 0.9039\n","\n","Epoch 00182: val_accuracy did not improve from 0.93350\n","Epoch 183/500\n","52/52 [==============================] - 11s 216ms/step - loss: 7.9747e-04 - accuracy: 1.0000 - val_loss: 0.4671 - val_accuracy: 0.9064\n","\n","Epoch 00183: val_accuracy did not improve from 0.93350\n","Epoch 184/500\n","52/52 [==============================] - 11s 215ms/step - loss: 4.3494e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9089\n","\n","Epoch 00184: val_accuracy did not improve from 0.93350\n","Epoch 185/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4560 - val_accuracy: 0.8867\n","\n","Epoch 00185: val_accuracy did not improve from 0.93350\n","Epoch 186/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.4634 - val_accuracy: 0.9089\n","\n","Epoch 00186: val_accuracy did not improve from 0.93350\n","Epoch 187/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.6379 - val_accuracy: 0.8941\n","\n","Epoch 00187: val_accuracy did not improve from 0.93350\n","Epoch 188/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.4515 - val_accuracy: 0.9064\n","\n","Epoch 00188: val_accuracy did not improve from 0.93350\n","Epoch 189/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0367 - accuracy: 0.9915 - val_loss: 2.5004 - val_accuracy: 0.7365\n","\n","Epoch 00189: val_accuracy did not improve from 0.93350\n","Epoch 190/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.2049 - accuracy: 0.9440 - val_loss: 1.4144 - val_accuracy: 0.8079\n","\n","Epoch 00190: val_accuracy did not improve from 0.93350\n","Epoch 191/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1107 - accuracy: 0.9702 - val_loss: 1.1490 - val_accuracy: 0.8350\n","\n","Epoch 00191: val_accuracy did not improve from 0.93350\n","Epoch 192/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0337 - accuracy: 0.9909 - val_loss: 0.7692 - val_accuracy: 0.8547\n","\n","Epoch 00192: val_accuracy did not improve from 0.93350\n","Epoch 193/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0282 - accuracy: 0.9890 - val_loss: 0.4825 - val_accuracy: 0.9015\n","\n","Epoch 00193: val_accuracy did not improve from 0.93350\n","Epoch 194/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.3704 - val_accuracy: 0.9113\n","\n","Epoch 00194: val_accuracy did not improve from 0.93350\n","Epoch 195/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.3871 - val_accuracy: 0.9089\n","\n","Epoch 00195: val_accuracy did not improve from 0.93350\n","Epoch 196/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.4239 - val_accuracy: 0.8941\n","\n","Epoch 00196: val_accuracy did not improve from 0.93350\n","Epoch 197/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.3316 - val_accuracy: 0.9286\n","\n","Epoch 00197: val_accuracy did not improve from 0.93350\n","Epoch 198/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.3788 - val_accuracy: 0.9212\n","\n","Epoch 00198: val_accuracy did not improve from 0.93350\n","Epoch 199/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 0.9039\n","\n","Epoch 00199: val_accuracy did not improve from 0.93350\n","Epoch 200/500\n","52/52 [==============================] - 11s 215ms/step - loss: 7.5279e-04 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9163\n","\n","Epoch 00200: val_accuracy did not improve from 0.93350\n","Epoch 201/500\n","52/52 [==============================] - 11s 217ms/step - loss: 8.3391e-04 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9138\n","\n","Epoch 00201: val_accuracy did not improve from 0.93350\n","Epoch 202/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0319 - accuracy: 0.9933 - val_loss: 0.5361 - val_accuracy: 0.8842\n","\n","Epoch 00202: val_accuracy did not improve from 0.93350\n","Epoch 203/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1508 - accuracy: 0.9580 - val_loss: 0.8900 - val_accuracy: 0.8054\n","\n","Epoch 00203: val_accuracy did not improve from 0.93350\n","Epoch 204/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0524 - accuracy: 0.9854 - val_loss: 0.7897 - val_accuracy: 0.8399\n","\n","Epoch 00204: val_accuracy did not improve from 0.93350\n","Epoch 205/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 1.2419 - val_accuracy: 0.7291\n","\n","Epoch 00205: val_accuracy did not improve from 0.93350\n","Epoch 206/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 0.7289 - val_accuracy: 0.8670\n","\n","Epoch 00206: val_accuracy did not improve from 0.93350\n","Epoch 207/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 0.5291 - val_accuracy: 0.8818\n","\n","Epoch 00207: val_accuracy did not improve from 0.93350\n","Epoch 208/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.5039 - val_accuracy: 0.8768\n","\n","Epoch 00208: val_accuracy did not improve from 0.93350\n","Epoch 209/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.4950 - val_accuracy: 0.8867\n","\n","Epoch 00209: val_accuracy did not improve from 0.93350\n","Epoch 210/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.4812 - val_accuracy: 0.9039\n","\n","Epoch 00210: val_accuracy did not improve from 0.93350\n","Epoch 211/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.4836 - val_accuracy: 0.8990\n","\n","Epoch 00211: val_accuracy did not improve from 0.93350\n","Epoch 212/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.4570 - val_accuracy: 0.8892\n","\n","Epoch 00212: val_accuracy did not improve from 0.93350\n","Epoch 213/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4086 - val_accuracy: 0.9113\n","\n","Epoch 00213: val_accuracy did not improve from 0.93350\n","Epoch 214/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.4359 - val_accuracy: 0.9138\n","\n","Epoch 00214: val_accuracy did not improve from 0.93350\n","Epoch 215/500\n","52/52 [==============================] - 11s 216ms/step - loss: 7.6907e-04 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9187\n","\n","Epoch 00215: val_accuracy did not improve from 0.93350\n","Epoch 216/500\n","52/52 [==============================] - 11s 216ms/step - loss: 8.1703e-04 - accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.9163\n","\n","Epoch 00216: val_accuracy did not improve from 0.93350\n","Epoch 217/500\n","52/52 [==============================] - 11s 216ms/step - loss: 6.8331e-04 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9138\n","\n","Epoch 00217: val_accuracy did not improve from 0.93350\n","Epoch 218/500\n","52/52 [==============================] - 11s 217ms/step - loss: 5.7168e-04 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.9163\n","\n","Epoch 00218: val_accuracy did not improve from 0.93350\n","Epoch 219/500\n","52/52 [==============================] - 11s 216ms/step - loss: 3.7499e-04 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.9163\n","\n","Epoch 00219: val_accuracy did not improve from 0.93350\n","Epoch 220/500\n","52/52 [==============================] - 11s 216ms/step - loss: 7.5001e-04 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 0.9286\n","\n","Epoch 00220: val_accuracy did not improve from 0.93350\n","Epoch 221/500\n","52/52 [==============================] - 11s 217ms/step - loss: 8.7692e-04 - accuracy: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.9039\n","\n","Epoch 00221: val_accuracy did not improve from 0.93350\n","Epoch 222/500\n","52/52 [==============================] - 11s 216ms/step - loss: 4.4601e-04 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.9187\n","\n","Epoch 00222: val_accuracy did not improve from 0.93350\n","Epoch 223/500\n","52/52 [==============================] - 11s 216ms/step - loss: 4.2530e-04 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.9236\n","\n","Epoch 00223: val_accuracy did not improve from 0.93350\n","Epoch 224/500\n","52/52 [==============================] - 11s 219ms/step - loss: 4.2638e-04 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.9138\n","\n","Epoch 00224: val_accuracy did not improve from 0.93350\n","Epoch 225/500\n","52/52 [==============================] - 11s 217ms/step - loss: 3.6916e-04 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9187\n","\n","Epoch 00225: val_accuracy did not improve from 0.93350\n","Epoch 226/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.3594 - val_accuracy: 0.9212\n","\n","Epoch 00226: val_accuracy did not improve from 0.93350\n","Epoch 227/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.3961 - val_accuracy: 0.9138\n","\n","Epoch 00227: val_accuracy did not improve from 0.93350\n","Epoch 228/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.8153 - val_accuracy: 0.8522\n","\n","Epoch 00228: val_accuracy did not improve from 0.93350\n","Epoch 229/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1013 - accuracy: 0.9714 - val_loss: 0.7246 - val_accuracy: 0.8719\n","\n","Epoch 00229: val_accuracy did not improve from 0.93350\n","Epoch 230/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0302 - accuracy: 0.9890 - val_loss: 0.9771 - val_accuracy: 0.8399\n","\n","Epoch 00230: val_accuracy did not improve from 0.93350\n","Epoch 231/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 0.8906 - val_accuracy: 0.8547\n","\n","Epoch 00231: val_accuracy did not improve from 0.93350\n","Epoch 232/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.8057 - val_accuracy: 0.8695\n","\n","Epoch 00232: val_accuracy did not improve from 0.93350\n","Epoch 233/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0398 - accuracy: 0.9903 - val_loss: 1.0461 - val_accuracy: 0.8005\n","\n","Epoch 00233: val_accuracy did not improve from 0.93350\n","Epoch 234/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.5417 - val_accuracy: 0.8768\n","\n","Epoch 00234: val_accuracy did not improve from 0.93350\n","Epoch 235/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.3963 - val_accuracy: 0.9039\n","\n","Epoch 00235: val_accuracy did not improve from 0.93350\n","Epoch 236/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.9138\n","\n","Epoch 00236: val_accuracy did not improve from 0.93350\n","Epoch 237/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3941 - val_accuracy: 0.9138\n","\n","Epoch 00237: val_accuracy did not improve from 0.93350\n","Epoch 238/500\n","52/52 [==============================] - 11s 218ms/step - loss: 7.9696e-04 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9039\n","\n","Epoch 00238: val_accuracy did not improve from 0.93350\n","Epoch 239/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.7790 - val_accuracy: 0.8670\n","\n","Epoch 00239: val_accuracy did not improve from 0.93350\n","Epoch 240/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.3910 - val_accuracy: 0.9236\n","\n","Epoch 00240: val_accuracy did not improve from 0.93350\n","Epoch 241/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.7281 - val_accuracy: 0.8695\n","\n","Epoch 00241: val_accuracy did not improve from 0.93350\n","Epoch 242/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.4994 - val_accuracy: 0.9113\n","\n","Epoch 00242: val_accuracy did not improve from 0.93350\n","Epoch 243/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.5106 - val_accuracy: 0.8966\n","\n","Epoch 00243: val_accuracy did not improve from 0.93350\n","Epoch 244/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4512 - val_accuracy: 0.9089\n","\n","Epoch 00244: val_accuracy did not improve from 0.93350\n","Epoch 245/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.6660 - val_accuracy: 0.8842\n","\n","Epoch 00245: val_accuracy did not improve from 0.93350\n","Epoch 246/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4646 - val_accuracy: 0.9187\n","\n","Epoch 00246: val_accuracy did not improve from 0.93350\n","Epoch 247/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.5169 - val_accuracy: 0.9064\n","\n","Epoch 00247: val_accuracy did not improve from 0.93350\n","Epoch 248/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0134 - accuracy: 0.9945 - val_loss: 0.5238 - val_accuracy: 0.8990\n","\n","Epoch 00248: val_accuracy did not improve from 0.93350\n","Epoch 249/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.5041 - val_accuracy: 0.9064\n","\n","Epoch 00249: val_accuracy did not improve from 0.93350\n","Epoch 250/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.5849 - val_accuracy: 0.8744\n","\n","Epoch 00250: val_accuracy did not improve from 0.93350\n","Epoch 251/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0297 - accuracy: 0.9896 - val_loss: 0.7246 - val_accuracy: 0.8768\n","\n","Epoch 00251: val_accuracy did not improve from 0.93350\n","Epoch 252/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.6641 - val_accuracy: 0.8596\n","\n","Epoch 00252: val_accuracy did not improve from 0.93350\n","Epoch 253/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.7994 - val_accuracy: 0.8522\n","\n","Epoch 00253: val_accuracy did not improve from 0.93350\n","Epoch 254/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0778 - accuracy: 0.9781 - val_loss: 0.9799 - val_accuracy: 0.8300\n","\n","Epoch 00254: val_accuracy did not improve from 0.93350\n","Epoch 255/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0272 - accuracy: 0.9896 - val_loss: 0.7994 - val_accuracy: 0.8399\n","\n","Epoch 00255: val_accuracy did not improve from 0.93350\n","Epoch 256/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0148 - accuracy: 0.9939 - val_loss: 0.6062 - val_accuracy: 0.8892\n","\n","Epoch 00256: val_accuracy did not improve from 0.93350\n","Epoch 257/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0176 - accuracy: 0.9933 - val_loss: 0.7092 - val_accuracy: 0.8621\n","\n","Epoch 00257: val_accuracy did not improve from 0.93350\n","Epoch 258/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0327 - accuracy: 0.9927 - val_loss: 0.6246 - val_accuracy: 0.8842\n","\n","Epoch 00258: val_accuracy did not improve from 0.93350\n","Epoch 259/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.5267 - val_accuracy: 0.9138\n","\n","Epoch 00259: val_accuracy did not improve from 0.93350\n","Epoch 260/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.5228 - val_accuracy: 0.9015\n","\n","Epoch 00260: val_accuracy did not improve from 0.93350\n","Epoch 261/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5507 - val_accuracy: 0.8842\n","\n","Epoch 00261: val_accuracy did not improve from 0.93350\n","Epoch 262/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.4590 - val_accuracy: 0.9187\n","\n","Epoch 00262: val_accuracy did not improve from 0.93350\n","Epoch 263/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0120 - accuracy: 0.9945 - val_loss: 0.4510 - val_accuracy: 0.9015\n","\n","Epoch 00263: val_accuracy did not improve from 0.93350\n","Epoch 264/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.3781 - val_accuracy: 0.9163\n","\n","Epoch 00264: val_accuracy did not improve from 0.93350\n","Epoch 265/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 0.9064\n","\n","Epoch 00265: val_accuracy did not improve from 0.93350\n","Epoch 266/500\n","52/52 [==============================] - 11s 217ms/step - loss: 6.7039e-04 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.9163\n","\n","Epoch 00266: val_accuracy did not improve from 0.93350\n","Epoch 267/500\n","52/52 [==============================] - 11s 218ms/step - loss: 8.9313e-04 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.9138\n","\n","Epoch 00267: val_accuracy did not improve from 0.93350\n","Epoch 268/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.3952 - val_accuracy: 0.9138\n","\n","Epoch 00268: val_accuracy did not improve from 0.93350\n","Epoch 269/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.3689 - val_accuracy: 0.9138\n","\n","Epoch 00269: val_accuracy did not improve from 0.93350\n","Epoch 270/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4496 - val_accuracy: 0.9187\n","\n","Epoch 00270: val_accuracy did not improve from 0.93350\n","Epoch 271/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4680 - val_accuracy: 0.9089\n","\n","Epoch 00271: val_accuracy did not improve from 0.93350\n","Epoch 272/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4903 - val_accuracy: 0.9089\n","\n","Epoch 00272: val_accuracy did not improve from 0.93350\n","Epoch 273/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.4815 - val_accuracy: 0.8966\n","\n","Epoch 00273: val_accuracy did not improve from 0.93350\n","Epoch 274/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.6560 - val_accuracy: 0.8818\n","\n","Epoch 00274: val_accuracy did not improve from 0.93350\n","Epoch 275/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6208 - val_accuracy: 0.8842\n","\n","Epoch 00275: val_accuracy did not improve from 0.93350\n","Epoch 276/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5385 - val_accuracy: 0.9015\n","\n","Epoch 00276: val_accuracy did not improve from 0.93350\n","Epoch 277/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5532 - val_accuracy: 0.9039\n","\n","Epoch 00277: val_accuracy did not improve from 0.93350\n","Epoch 278/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.5320 - val_accuracy: 0.8941\n","\n","Epoch 00278: val_accuracy did not improve from 0.93350\n","Epoch 279/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.5856 - val_accuracy: 0.8990\n","\n","Epoch 00279: val_accuracy did not improve from 0.93350\n","Epoch 280/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.6011 - val_accuracy: 0.8867\n","\n","Epoch 00280: val_accuracy did not improve from 0.93350\n","Epoch 281/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.7549 - val_accuracy: 0.8522\n","\n","Epoch 00281: val_accuracy did not improve from 0.93350\n","Epoch 282/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0463 - accuracy: 0.9872 - val_loss: 0.7940 - val_accuracy: 0.8695\n","\n","Epoch 00282: val_accuracy did not improve from 0.93350\n","Epoch 283/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0971 - accuracy: 0.9732 - val_loss: 0.9726 - val_accuracy: 0.8350\n","\n","Epoch 00283: val_accuracy did not improve from 0.93350\n","Epoch 284/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.4738 - val_accuracy: 0.8990\n","\n","Epoch 00284: val_accuracy did not improve from 0.93350\n","Epoch 285/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0208 - accuracy: 0.9945 - val_loss: 0.9327 - val_accuracy: 0.8399\n","\n","Epoch 00285: val_accuracy did not improve from 0.93350\n","Epoch 286/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.4252 - val_accuracy: 0.9089\n","\n","Epoch 00286: val_accuracy did not improve from 0.93350\n","Epoch 287/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.9089\n","\n","Epoch 00287: val_accuracy did not improve from 0.93350\n","Epoch 288/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9064\n","\n","Epoch 00288: val_accuracy did not improve from 0.93350\n","Epoch 289/500\n","52/52 [==============================] - 11s 215ms/step - loss: 6.8056e-04 - accuracy: 1.0000 - val_loss: 0.3749 - val_accuracy: 0.9138\n","\n","Epoch 00289: val_accuracy did not improve from 0.93350\n","Epoch 290/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.3841 - val_accuracy: 0.9286\n","\n","Epoch 00290: val_accuracy did not improve from 0.93350\n","Epoch 291/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.9039\n","\n","Epoch 00291: val_accuracy did not improve from 0.93350\n","Epoch 292/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 0.4314 - val_accuracy: 0.9015\n","\n","Epoch 00292: val_accuracy did not improve from 0.93350\n","Epoch 293/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.3559 - val_accuracy: 0.9236\n","\n","Epoch 00293: val_accuracy did not improve from 0.93350\n","Epoch 294/500\n","52/52 [==============================] - 11s 216ms/step - loss: 7.6465e-04 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9163\n","\n","Epoch 00294: val_accuracy did not improve from 0.93350\n","Epoch 295/500\n","52/52 [==============================] - 11s 215ms/step - loss: 5.6887e-04 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.9113\n","\n","Epoch 00295: val_accuracy did not improve from 0.93350\n","Epoch 296/500\n","52/52 [==============================] - 11s 215ms/step - loss: 2.5683e-04 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9138\n","\n","Epoch 00296: val_accuracy did not improve from 0.93350\n","Epoch 297/500\n","52/52 [==============================] - 11s 216ms/step - loss: 3.9596e-04 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9089\n","\n","Epoch 00297: val_accuracy did not improve from 0.93350\n","Epoch 298/500\n","52/52 [==============================] - 11s 216ms/step - loss: 4.2613e-04 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9138\n","\n","Epoch 00298: val_accuracy did not improve from 0.93350\n","Epoch 299/500\n","52/52 [==============================] - 11s 216ms/step - loss: 3.5923e-04 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.9089\n","\n","Epoch 00299: val_accuracy did not improve from 0.93350\n","Epoch 300/500\n","52/52 [==============================] - 11s 217ms/step - loss: 3.1142e-04 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.9187\n","\n","Epoch 00300: val_accuracy did not improve from 0.93350\n","Epoch 301/500\n","52/52 [==============================] - 11s 216ms/step - loss: 4.9724e-04 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.9187\n","\n","Epoch 00301: val_accuracy did not improve from 0.93350\n","Epoch 302/500\n","52/52 [==============================] - 11s 219ms/step - loss: 1.3093e-04 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.9064\n","\n","Epoch 00302: val_accuracy did not improve from 0.93350\n","Epoch 303/500\n","52/52 [==============================] - 11s 216ms/step - loss: 1.4488e-04 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9113\n","\n","Epoch 00303: val_accuracy did not improve from 0.93350\n","Epoch 304/500\n","52/52 [==============================] - 11s 217ms/step - loss: 3.6705e-04 - accuracy: 1.0000 - val_loss: 0.4231 - val_accuracy: 0.9163\n","\n","Epoch 00304: val_accuracy did not improve from 0.93350\n","Epoch 305/500\n","52/52 [==============================] - 11s 216ms/step - loss: 4.0134e-04 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.9089\n","\n","Epoch 00305: val_accuracy did not improve from 0.93350\n","Epoch 306/500\n","52/52 [==============================] - 11s 216ms/step - loss: 5.5121e-04 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.9261\n","\n","Epoch 00306: val_accuracy did not improve from 0.93350\n","Epoch 307/500\n","52/52 [==============================] - 11s 218ms/step - loss: 3.6733e-04 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.9236\n","\n","Epoch 00307: val_accuracy did not improve from 0.93350\n","Epoch 308/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4449 - val_accuracy: 0.9039\n","\n","Epoch 00308: val_accuracy did not improve from 0.93350\n","Epoch 309/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.4318 - val_accuracy: 0.9064\n","\n","Epoch 00309: val_accuracy did not improve from 0.93350\n","Epoch 310/500\n","52/52 [==============================] - 11s 216ms/step - loss: 8.6902e-04 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.9163\n","\n","Epoch 00310: val_accuracy did not improve from 0.93350\n","Epoch 311/500\n","52/52 [==============================] - 11s 217ms/step - loss: 2.6123e-04 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.8966\n","\n","Epoch 00311: val_accuracy did not improve from 0.93350\n","Epoch 312/500\n","52/52 [==============================] - 11s 216ms/step - loss: 2.9770e-04 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9064\n","\n","Epoch 00312: val_accuracy did not improve from 0.93350\n","Epoch 313/500\n","52/52 [==============================] - 11s 216ms/step - loss: 3.7991e-04 - accuracy: 1.0000 - val_loss: 0.3839 - val_accuracy: 0.9261\n","\n","Epoch 00313: val_accuracy did not improve from 0.93350\n","Epoch 314/500\n","52/52 [==============================] - 11s 217ms/step - loss: 1.7293e-04 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.9163\n","\n","Epoch 00314: val_accuracy did not improve from 0.93350\n","Epoch 315/500\n","52/52 [==============================] - 11s 216ms/step - loss: 3.0200e-04 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.9261\n","\n","Epoch 00315: val_accuracy did not improve from 0.93350\n","Epoch 316/500\n","52/52 [==============================] - 11s 215ms/step - loss: 3.2907e-04 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 0.9212\n","\n","Epoch 00316: val_accuracy did not improve from 0.93350\n","Epoch 317/500\n","52/52 [==============================] - 11s 217ms/step - loss: 2.2205e-04 - accuracy: 1.0000 - val_loss: 0.3379 - val_accuracy: 0.9384\n","\n","Epoch 00317: val_accuracy improved from 0.93350 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5\n","Epoch 318/500\n","52/52 [==============================] - 11s 216ms/step - loss: 1.7390e-04 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9138\n","\n","Epoch 00318: val_accuracy did not improve from 0.93842\n","Epoch 319/500\n","52/52 [==============================] - 11s 215ms/step - loss: 1.3814e-04 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.9187\n","\n","Epoch 00319: val_accuracy did not improve from 0.93842\n","Epoch 320/500\n","52/52 [==============================] - 11s 216ms/step - loss: 8.3834e-05 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9236\n","\n","Epoch 00320: val_accuracy did not improve from 0.93842\n","Epoch 321/500\n","52/52 [==============================] - 11s 214ms/step - loss: 1.4580e-04 - accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.9113\n","\n","Epoch 00321: val_accuracy did not improve from 0.93842\n","Epoch 322/500\n","52/52 [==============================] - 11s 216ms/step - loss: 1.0744e-04 - accuracy: 1.0000 - val_loss: 0.4586 - val_accuracy: 0.9163\n","\n","Epoch 00322: val_accuracy did not improve from 0.93842\n","Epoch 323/500\n","52/52 [==============================] - 11s 216ms/step - loss: 7.7346e-05 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.9089\n","\n","Epoch 00323: val_accuracy did not improve from 0.93842\n","Epoch 324/500\n","52/52 [==============================] - 11s 214ms/step - loss: 9.3529e-05 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.9163\n","\n","Epoch 00324: val_accuracy did not improve from 0.93842\n","Epoch 325/500\n","52/52 [==============================] - 11s 216ms/step - loss: 1.1479e-04 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.9163\n","\n","Epoch 00325: val_accuracy did not improve from 0.93842\n","Epoch 326/500\n","52/52 [==============================] - 11s 216ms/step - loss: 1.6641e-04 - accuracy: 1.0000 - val_loss: 0.5571 - val_accuracy: 0.9138\n","\n","Epoch 00326: val_accuracy did not improve from 0.93842\n","Epoch 327/500\n","52/52 [==============================] - 11s 215ms/step - loss: 2.9439e-04 - accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.9064\n","\n","Epoch 00327: val_accuracy did not improve from 0.93842\n","Epoch 328/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.6544 - val_accuracy: 0.8793\n","\n","Epoch 00328: val_accuracy did not improve from 0.93842\n","Epoch 329/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2582 - accuracy: 0.9428 - val_loss: 4.1807 - val_accuracy: 0.6379\n","\n","Epoch 00329: val_accuracy did not improve from 0.93842\n","Epoch 330/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0828 - accuracy: 0.9799 - val_loss: 0.9594 - val_accuracy: 0.8276\n","\n","Epoch 00330: val_accuracy did not improve from 0.93842\n","Epoch 331/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.7201 - val_accuracy: 0.8596\n","\n","Epoch 00331: val_accuracy did not improve from 0.93842\n","Epoch 332/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0174 - accuracy: 0.9927 - val_loss: 0.5719 - val_accuracy: 0.8818\n","\n","Epoch 00332: val_accuracy did not improve from 0.93842\n","Epoch 333/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.4188 - val_accuracy: 0.9212\n","\n","Epoch 00333: val_accuracy did not improve from 0.93842\n","Epoch 334/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4431 - val_accuracy: 0.9138\n","\n","Epoch 00334: val_accuracy did not improve from 0.93842\n","Epoch 335/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.4120 - val_accuracy: 0.9064\n","\n","Epoch 00335: val_accuracy did not improve from 0.93842\n","Epoch 336/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4197 - val_accuracy: 0.9113\n","\n","Epoch 00336: val_accuracy did not improve from 0.93842\n","Epoch 337/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4113 - val_accuracy: 0.9089\n","\n","Epoch 00337: val_accuracy did not improve from 0.93842\n","Epoch 338/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4602 - val_accuracy: 0.9064\n","\n","Epoch 00338: val_accuracy did not improve from 0.93842\n","Epoch 339/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5173 - val_accuracy: 0.8941\n","\n","Epoch 00339: val_accuracy did not improve from 0.93842\n","Epoch 340/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4130 - val_accuracy: 0.9015\n","\n","Epoch 00340: val_accuracy did not improve from 0.93842\n","Epoch 341/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4125 - val_accuracy: 0.9089\n","\n","Epoch 00341: val_accuracy did not improve from 0.93842\n","Epoch 342/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3834 - val_accuracy: 0.9113\n","\n","Epoch 00342: val_accuracy did not improve from 0.93842\n","Epoch 343/500\n","52/52 [==============================] - 11s 216ms/step - loss: 5.1714e-04 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9212\n","\n","Epoch 00343: val_accuracy did not improve from 0.93842\n","Epoch 344/500\n","52/52 [==============================] - 11s 217ms/step - loss: 8.1722e-04 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9212\n","\n","Epoch 00344: val_accuracy did not improve from 0.93842\n","Epoch 345/500\n","52/52 [==============================] - 11s 217ms/step - loss: 7.5103e-04 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.9163\n","\n","Epoch 00345: val_accuracy did not improve from 0.93842\n","Epoch 346/500\n","52/52 [==============================] - 11s 217ms/step - loss: 5.9393e-04 - accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 0.9163\n","\n","Epoch 00346: val_accuracy did not improve from 0.93842\n","Epoch 347/500\n","52/52 [==============================] - 11s 216ms/step - loss: 7.4847e-04 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9138\n","\n","Epoch 00347: val_accuracy did not improve from 0.93842\n","Epoch 348/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3684 - val_accuracy: 0.9261\n","\n","Epoch 00348: val_accuracy did not improve from 0.93842\n","Epoch 349/500\n","52/52 [==============================] - 11s 216ms/step - loss: 7.3174e-04 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.9039\n","\n","Epoch 00349: val_accuracy did not improve from 0.93842\n","Epoch 350/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0282 - accuracy: 0.9927 - val_loss: 3.1187 - val_accuracy: 0.5394\n","\n","Epoch 00350: val_accuracy did not improve from 0.93842\n","Epoch 351/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0380 - accuracy: 0.9903 - val_loss: 0.9330 - val_accuracy: 0.8350\n","\n","Epoch 00351: val_accuracy did not improve from 0.93842\n","Epoch 352/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.6231 - val_accuracy: 0.8867\n","\n","Epoch 00352: val_accuracy did not improve from 0.93842\n","Epoch 353/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.5280 - val_accuracy: 0.8916\n","\n","Epoch 00353: val_accuracy did not improve from 0.93842\n","Epoch 354/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 0.4242 - val_accuracy: 0.9039\n","\n","Epoch 00354: val_accuracy did not improve from 0.93842\n","Epoch 355/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.4635 - val_accuracy: 0.9138\n","\n","Epoch 00355: val_accuracy did not improve from 0.93842\n","Epoch 356/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4263 - val_accuracy: 0.8990\n","\n","Epoch 00356: val_accuracy did not improve from 0.93842\n","Epoch 357/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4239 - val_accuracy: 0.9113\n","\n","Epoch 00357: val_accuracy did not improve from 0.93842\n","Epoch 358/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9163\n","\n","Epoch 00358: val_accuracy did not improve from 0.93842\n","Epoch 359/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.9163\n","\n","Epoch 00359: val_accuracy did not improve from 0.93842\n","Epoch 360/500\n","52/52 [==============================] - 11s 215ms/step - loss: 6.2416e-04 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9261\n","\n","Epoch 00360: val_accuracy did not improve from 0.93842\n","Epoch 361/500\n","52/52 [==============================] - 11s 216ms/step - loss: 4.1587e-04 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9212\n","\n","Epoch 00361: val_accuracy did not improve from 0.93842\n","Epoch 362/500\n","52/52 [==============================] - 11s 218ms/step - loss: 4.7542e-04 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.9163\n","\n","Epoch 00362: val_accuracy did not improve from 0.93842\n","Epoch 363/500\n","52/52 [==============================] - 11s 217ms/step - loss: 2.1925e-04 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9261\n","\n","Epoch 00363: val_accuracy did not improve from 0.93842\n","Epoch 364/500\n","52/52 [==============================] - 11s 218ms/step - loss: 2.8724e-04 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.9310\n","\n","Epoch 00364: val_accuracy did not improve from 0.93842\n","Epoch 365/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.4477 - val_accuracy: 0.9163\n","\n","Epoch 00365: val_accuracy did not improve from 0.93842\n","Epoch 366/500\n","52/52 [==============================] - 11s 215ms/step - loss: 9.7450e-04 - accuracy: 0.9994 - val_loss: 0.5441 - val_accuracy: 0.9039\n","\n","Epoch 00366: val_accuracy did not improve from 0.93842\n","Epoch 367/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4953 - val_accuracy: 0.9089\n","\n","Epoch 00367: val_accuracy did not improve from 0.93842\n","Epoch 368/500\n","52/52 [==============================] - 11s 216ms/step - loss: 5.1137e-04 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.9286\n","\n","Epoch 00368: val_accuracy did not improve from 0.93842\n","Epoch 369/500\n","52/52 [==============================] - 11s 216ms/step - loss: 2.5952e-04 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.9089\n","\n","Epoch 00369: val_accuracy did not improve from 0.93842\n","Epoch 370/500\n","52/52 [==============================] - 11s 216ms/step - loss: 1.7901e-04 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.9236\n","\n","Epoch 00370: val_accuracy did not improve from 0.93842\n","Epoch 371/500\n","52/52 [==============================] - 11s 216ms/step - loss: 7.4055e-04 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.8916\n","\n","Epoch 00371: val_accuracy did not improve from 0.93842\n","Epoch 372/500\n","52/52 [==============================] - 11s 215ms/step - loss: 8.9571e-04 - accuracy: 1.0000 - val_loss: 0.4582 - val_accuracy: 0.9138\n","\n","Epoch 00372: val_accuracy did not improve from 0.93842\n","Epoch 373/500\n","52/52 [==============================] - 11s 216ms/step - loss: 1.9827e-04 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.9138\n","\n","Epoch 00373: val_accuracy did not improve from 0.93842\n","Epoch 374/500\n","52/52 [==============================] - 11s 216ms/step - loss: 2.0778e-04 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.9360\n","\n","Epoch 00374: val_accuracy did not improve from 0.93842\n","Epoch 375/500\n","52/52 [==============================] - 11s 218ms/step - loss: 2.3015e-04 - accuracy: 1.0000 - val_loss: 0.4116 - val_accuracy: 0.9261\n","\n","Epoch 00375: val_accuracy did not improve from 0.93842\n","Epoch 376/500\n","52/52 [==============================] - 11s 216ms/step - loss: 1.8567e-04 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.9064\n","\n","Epoch 00376: val_accuracy did not improve from 0.93842\n","Epoch 377/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 0.4283 - val_accuracy: 0.9015\n","\n","Epoch 00377: val_accuracy did not improve from 0.93842\n","Epoch 378/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0300 - accuracy: 0.9921 - val_loss: 0.9099 - val_accuracy: 0.8596\n","\n","Epoch 00378: val_accuracy did not improve from 0.93842\n","Epoch 379/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0782 - accuracy: 0.9744 - val_loss: 1.2238 - val_accuracy: 0.8547\n","\n","Epoch 00379: val_accuracy did not improve from 0.93842\n","Epoch 380/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0604 - accuracy: 0.9817 - val_loss: 1.1542 - val_accuracy: 0.8103\n","\n","Epoch 00380: val_accuracy did not improve from 0.93842\n","Epoch 381/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0280 - accuracy: 0.9896 - val_loss: 1.2047 - val_accuracy: 0.8448\n","\n","Epoch 00381: val_accuracy did not improve from 0.93842\n","Epoch 382/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0690 - accuracy: 0.9836 - val_loss: 0.7397 - val_accuracy: 0.8645\n","\n","Epoch 00382: val_accuracy did not improve from 0.93842\n","Epoch 383/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0128 - accuracy: 0.9939 - val_loss: 0.5791 - val_accuracy: 0.9015\n","\n","Epoch 00383: val_accuracy did not improve from 0.93842\n","Epoch 384/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0151 - accuracy: 0.9939 - val_loss: 0.3932 - val_accuracy: 0.9212\n","\n","Epoch 00384: val_accuracy did not improve from 0.93842\n","Epoch 385/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.4480 - val_accuracy: 0.9064\n","\n","Epoch 00385: val_accuracy did not improve from 0.93842\n","Epoch 386/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.4942 - val_accuracy: 0.8941\n","\n","Epoch 00386: val_accuracy did not improve from 0.93842\n","Epoch 387/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.8941\n","\n","Epoch 00387: val_accuracy did not improve from 0.93842\n","Epoch 388/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.9113\n","\n","Epoch 00388: val_accuracy did not improve from 0.93842\n","Epoch 389/500\n","52/52 [==============================] - 11s 217ms/step - loss: 8.5741e-04 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9286\n","\n","Epoch 00389: val_accuracy did not improve from 0.93842\n","Epoch 390/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3897 - val_accuracy: 0.9310\n","\n","Epoch 00390: val_accuracy did not improve from 0.93842\n","Epoch 391/500\n","52/52 [==============================] - 11s 218ms/step - loss: 9.7862e-04 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9310\n","\n","Epoch 00391: val_accuracy did not improve from 0.93842\n","Epoch 392/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3886 - val_accuracy: 0.9261\n","\n","Epoch 00392: val_accuracy did not improve from 0.93842\n","Epoch 393/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5303 - val_accuracy: 0.9015\n","\n","Epoch 00393: val_accuracy did not improve from 0.93842\n","Epoch 394/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5359 - val_accuracy: 0.9039\n","\n","Epoch 00394: val_accuracy did not improve from 0.93842\n","Epoch 395/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.4483 - val_accuracy: 0.9089\n","\n","Epoch 00395: val_accuracy did not improve from 0.93842\n","Epoch 396/500\n","52/52 [==============================] - 11s 217ms/step - loss: 5.6327e-04 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9187\n","\n","Epoch 00396: val_accuracy did not improve from 0.93842\n","Epoch 397/500\n","52/52 [==============================] - 11s 219ms/step - loss: 5.4366e-04 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9360\n","\n","Epoch 00397: val_accuracy did not improve from 0.93842\n","Epoch 398/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4086 - val_accuracy: 0.8966\n","\n","Epoch 00398: val_accuracy did not improve from 0.93842\n","Epoch 399/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.9212\n","\n","Epoch 00399: val_accuracy did not improve from 0.93842\n","Epoch 400/500\n","52/52 [==============================] - 11s 218ms/step - loss: 4.4670e-04 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9286\n","\n","Epoch 00400: val_accuracy did not improve from 0.93842\n","Epoch 401/500\n","52/52 [==============================] - 11s 216ms/step - loss: 2.2008e-04 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.9261\n","\n","Epoch 00401: val_accuracy did not improve from 0.93842\n","Epoch 402/500\n","52/52 [==============================] - 11s 216ms/step - loss: 5.4049e-04 - accuracy: 1.0000 - val_loss: 0.3829 - val_accuracy: 0.9187\n","\n","Epoch 00402: val_accuracy did not improve from 0.93842\n","Epoch 403/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4470 - val_accuracy: 0.9113\n","\n","Epoch 00403: val_accuracy did not improve from 0.93842\n","Epoch 404/500\n","52/52 [==============================] - 11s 217ms/step - loss: 5.6063e-04 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9384\n","\n","Epoch 00404: val_accuracy did not improve from 0.93842\n","Epoch 405/500\n","52/52 [==============================] - 11s 216ms/step - loss: 2.9566e-04 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9384\n","\n","Epoch 00405: val_accuracy did not improve from 0.93842\n","Epoch 406/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.5541 - val_accuracy: 0.9089\n","\n","Epoch 00406: val_accuracy did not improve from 0.93842\n","Epoch 407/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.5228 - val_accuracy: 0.9039\n","\n","Epoch 00407: val_accuracy did not improve from 0.93842\n","Epoch 408/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 1.0532 - val_accuracy: 0.8498\n","\n","Epoch 00408: val_accuracy did not improve from 0.93842\n","Epoch 409/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0186 - accuracy: 0.9927 - val_loss: 0.7190 - val_accuracy: 0.8768\n","\n","Epoch 00409: val_accuracy did not improve from 0.93842\n","Epoch 410/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.5356 - val_accuracy: 0.8941\n","\n","Epoch 00410: val_accuracy did not improve from 0.93842\n","Epoch 411/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5540 - val_accuracy: 0.9064\n","\n","Epoch 00411: val_accuracy did not improve from 0.93842\n","Epoch 412/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 0.6447 - val_accuracy: 0.8744\n","\n","Epoch 00412: val_accuracy did not improve from 0.93842\n","Epoch 413/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0328 - accuracy: 0.9915 - val_loss: 0.6661 - val_accuracy: 0.8399\n","\n","Epoch 00413: val_accuracy did not improve from 0.93842\n","Epoch 414/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.5613 - val_accuracy: 0.8793\n","\n","Epoch 00414: val_accuracy did not improve from 0.93842\n","Epoch 415/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5434 - val_accuracy: 0.8966\n","\n","Epoch 00415: val_accuracy did not improve from 0.93842\n","Epoch 416/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4914 - val_accuracy: 0.9039\n","\n","Epoch 00416: val_accuracy did not improve from 0.93842\n","Epoch 417/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4311 - val_accuracy: 0.9089\n","\n","Epoch 00417: val_accuracy did not improve from 0.93842\n","Epoch 418/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.8990\n","\n","Epoch 00418: val_accuracy did not improve from 0.93842\n","Epoch 419/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.9089\n","\n","Epoch 00419: val_accuracy did not improve from 0.93842\n","Epoch 420/500\n","52/52 [==============================] - 11s 217ms/step - loss: 6.8810e-04 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9236\n","\n","Epoch 00420: val_accuracy did not improve from 0.93842\n","Epoch 421/500\n","52/52 [==============================] - 11s 215ms/step - loss: 7.3919e-04 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.9138\n","\n","Epoch 00421: val_accuracy did not improve from 0.93842\n","Epoch 422/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.7398 - val_accuracy: 0.8695\n","\n","Epoch 00422: val_accuracy did not improve from 0.93842\n","Epoch 423/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0105 - accuracy: 0.9957 - val_loss: 0.5774 - val_accuracy: 0.8966\n","\n","Epoch 00423: val_accuracy did not improve from 0.93842\n","Epoch 424/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4923 - val_accuracy: 0.9163\n","\n","Epoch 00424: val_accuracy did not improve from 0.93842\n","Epoch 425/500\n","52/52 [==============================] - 11s 217ms/step - loss: 5.7452e-04 - accuracy: 1.0000 - val_loss: 0.4784 - val_accuracy: 0.9113\n","\n","Epoch 00425: val_accuracy did not improve from 0.93842\n","Epoch 426/500\n","52/52 [==============================] - 11s 217ms/step - loss: 7.1883e-04 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.9113\n","\n","Epoch 00426: val_accuracy did not improve from 0.93842\n","Epoch 427/500\n","52/52 [==============================] - 11s 216ms/step - loss: 7.6276e-04 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9212\n","\n","Epoch 00427: val_accuracy did not improve from 0.93842\n","Epoch 428/500\n","52/52 [==============================] - 11s 216ms/step - loss: 4.9327e-04 - accuracy: 1.0000 - val_loss: 0.4222 - val_accuracy: 0.9212\n","\n","Epoch 00428: val_accuracy did not improve from 0.93842\n","Epoch 429/500\n","52/52 [==============================] - 11s 218ms/step - loss: 8.6739e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9261\n","\n","Epoch 00429: val_accuracy did not improve from 0.93842\n","Epoch 430/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9261\n","\n","Epoch 00430: val_accuracy did not improve from 0.93842\n","Epoch 431/500\n","52/52 [==============================] - 11s 219ms/step - loss: 3.5224e-04 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9064\n","\n","Epoch 00431: val_accuracy did not improve from 0.93842\n","Epoch 432/500\n","52/52 [==============================] - 11s 217ms/step - loss: 4.2982e-04 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.9212\n","\n","Epoch 00432: val_accuracy did not improve from 0.93842\n","Epoch 433/500\n","52/52 [==============================] - 11s 217ms/step - loss: 1.6538e-04 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.9163\n","\n","Epoch 00433: val_accuracy did not improve from 0.93842\n","Epoch 434/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5581 - val_accuracy: 0.9089\n","\n","Epoch 00434: val_accuracy did not improve from 0.93842\n","Epoch 435/500\n","52/52 [==============================] - 11s 216ms/step - loss: 3.6231e-04 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.9064\n","\n","Epoch 00435: val_accuracy did not improve from 0.93842\n","Epoch 436/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.4477 - val_accuracy: 0.9310\n","\n","Epoch 00436: val_accuracy did not improve from 0.93842\n","Epoch 437/500\n","52/52 [==============================] - 11s 218ms/step - loss: 5.1187e-04 - accuracy: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.9236\n","\n","Epoch 00437: val_accuracy did not improve from 0.93842\n","Epoch 438/500\n","52/52 [==============================] - 11s 216ms/step - loss: 4.1068e-04 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9138\n","\n","Epoch 00438: val_accuracy did not improve from 0.93842\n","Epoch 439/500\n","52/52 [==============================] - 11s 219ms/step - loss: 1.2472e-04 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9138\n","\n","Epoch 00439: val_accuracy did not improve from 0.93842\n","Epoch 440/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.6394 - val_accuracy: 0.9113\n","\n","Epoch 00440: val_accuracy did not improve from 0.93842\n","Epoch 441/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5199 - val_accuracy: 0.9138\n","\n","Epoch 00441: val_accuracy did not improve from 0.93842\n","Epoch 442/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0171 - accuracy: 0.9957 - val_loss: 0.7263 - val_accuracy: 0.8793\n","\n","Epoch 00442: val_accuracy did not improve from 0.93842\n","Epoch 443/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0727 - accuracy: 0.9811 - val_loss: 1.0318 - val_accuracy: 0.8325\n","\n","Epoch 00443: val_accuracy did not improve from 0.93842\n","Epoch 444/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0493 - accuracy: 0.9811 - val_loss: 0.7421 - val_accuracy: 0.8670\n","\n","Epoch 00444: val_accuracy did not improve from 0.93842\n","Epoch 445/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.5066 - val_accuracy: 0.9015\n","\n","Epoch 00445: val_accuracy did not improve from 0.93842\n","Epoch 446/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.6619 - val_accuracy: 0.8670\n","\n","Epoch 00446: val_accuracy did not improve from 0.93842\n","Epoch 447/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.5883 - val_accuracy: 0.8966\n","\n","Epoch 00447: val_accuracy did not improve from 0.93842\n","Epoch 448/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.6390 - val_accuracy: 0.8768\n","\n","Epoch 00448: val_accuracy did not improve from 0.93842\n","Epoch 449/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5711 - val_accuracy: 0.8941\n","\n","Epoch 00449: val_accuracy did not improve from 0.93842\n","Epoch 450/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.9064\n","\n","Epoch 00450: val_accuracy did not improve from 0.93842\n","Epoch 451/500\n","52/52 [==============================] - 11s 216ms/step - loss: 6.0201e-04 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.9064\n","\n","Epoch 00451: val_accuracy did not improve from 0.93842\n","Epoch 452/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5000 - val_accuracy: 0.9015\n","\n","Epoch 00452: val_accuracy did not improve from 0.93842\n","Epoch 453/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4987 - val_accuracy: 0.9113\n","\n","Epoch 00453: val_accuracy did not improve from 0.93842\n","Epoch 454/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 0.4711 - val_accuracy: 0.8990\n","\n","Epoch 00454: val_accuracy did not improve from 0.93842\n","Epoch 455/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0144 - accuracy: 0.9945 - val_loss: 0.5821 - val_accuracy: 0.8916\n","\n","Epoch 00455: val_accuracy did not improve from 0.93842\n","Epoch 456/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0182 - accuracy: 0.9921 - val_loss: 0.9743 - val_accuracy: 0.8177\n","\n","Epoch 00456: val_accuracy did not improve from 0.93842\n","Epoch 457/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.5724 - val_accuracy: 0.8744\n","\n","Epoch 00457: val_accuracy did not improve from 0.93842\n","Epoch 458/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0320 - accuracy: 0.9927 - val_loss: 1.4215 - val_accuracy: 0.8079\n","\n","Epoch 00458: val_accuracy did not improve from 0.93842\n","Epoch 459/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0669 - accuracy: 0.9811 - val_loss: 0.9654 - val_accuracy: 0.8596\n","\n","Epoch 00459: val_accuracy did not improve from 0.93842\n","Epoch 460/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.6253 - val_accuracy: 0.9039\n","\n","Epoch 00460: val_accuracy did not improve from 0.93842\n","Epoch 461/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.6926 - val_accuracy: 0.8621\n","\n","Epoch 00461: val_accuracy did not improve from 0.93842\n","Epoch 462/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.8011 - val_accuracy: 0.8350\n","\n","Epoch 00462: val_accuracy did not improve from 0.93842\n","Epoch 463/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.6263 - val_accuracy: 0.8966\n","\n","Epoch 00463: val_accuracy did not improve from 0.93842\n","Epoch 464/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4247 - val_accuracy: 0.9064\n","\n","Epoch 00464: val_accuracy did not improve from 0.93842\n","Epoch 465/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9212\n","\n","Epoch 00465: val_accuracy did not improve from 0.93842\n","Epoch 466/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5348 - val_accuracy: 0.9039\n","\n","Epoch 00466: val_accuracy did not improve from 0.93842\n","Epoch 467/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 0.5151 - val_accuracy: 0.9064\n","\n","Epoch 00467: val_accuracy did not improve from 0.93842\n","Epoch 468/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5557 - val_accuracy: 0.9064\n","\n","Epoch 00468: val_accuracy did not improve from 0.93842\n","Epoch 469/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9113\n","\n","Epoch 00469: val_accuracy did not improve from 0.93842\n","Epoch 470/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4769 - val_accuracy: 0.9015\n","\n","Epoch 00470: val_accuracy did not improve from 0.93842\n","Epoch 471/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4676 - val_accuracy: 0.8941\n","\n","Epoch 00471: val_accuracy did not improve from 0.93842\n","Epoch 472/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4710 - val_accuracy: 0.9064\n","\n","Epoch 00472: val_accuracy did not improve from 0.93842\n","Epoch 473/500\n","52/52 [==============================] - 11s 220ms/step - loss: 6.6238e-04 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.9039\n","\n","Epoch 00473: val_accuracy did not improve from 0.93842\n","Epoch 474/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4021 - val_accuracy: 0.9138\n","\n","Epoch 00474: val_accuracy did not improve from 0.93842\n","Epoch 475/500\n","52/52 [==============================] - 11s 219ms/step - loss: 6.0404e-04 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.9039\n","\n","Epoch 00475: val_accuracy did not improve from 0.93842\n","Epoch 476/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.9746 - val_accuracy: 0.7956\n","\n","Epoch 00476: val_accuracy did not improve from 0.93842\n","Epoch 477/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.6491 - val_accuracy: 0.8744\n","\n","Epoch 00477: val_accuracy did not improve from 0.93842\n","Epoch 478/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.5231 - val_accuracy: 0.9064\n","\n","Epoch 00478: val_accuracy did not improve from 0.93842\n","Epoch 479/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0039 - accuracy: 0.9976 - val_loss: 0.6150 - val_accuracy: 0.8744\n","\n","Epoch 00479: val_accuracy did not improve from 0.93842\n","Epoch 480/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4568 - val_accuracy: 0.9064\n","\n","Epoch 00480: val_accuracy did not improve from 0.93842\n","Epoch 481/500\n","52/52 [==============================] - 11s 218ms/step - loss: 5.7807e-04 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.9039\n","\n","Epoch 00481: val_accuracy did not improve from 0.93842\n","Epoch 482/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.6160 - val_accuracy: 0.9015\n","\n","Epoch 00482: val_accuracy did not improve from 0.93842\n","Epoch 483/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.8362 - val_accuracy: 0.8818\n","\n","Epoch 00483: val_accuracy did not improve from 0.93842\n","Epoch 484/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.4785 - val_accuracy: 0.9187\n","\n","Epoch 00484: val_accuracy did not improve from 0.93842\n","Epoch 485/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4593 - val_accuracy: 0.8966\n","\n","Epoch 00485: val_accuracy did not improve from 0.93842\n","Epoch 486/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4715 - val_accuracy: 0.9236\n","\n","Epoch 00486: val_accuracy did not improve from 0.93842\n","Epoch 487/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5125 - val_accuracy: 0.9039\n","\n","Epoch 00487: val_accuracy did not improve from 0.93842\n","Epoch 488/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4045 - val_accuracy: 0.9286\n","\n","Epoch 00488: val_accuracy did not improve from 0.93842\n","Epoch 489/500\n","52/52 [==============================] - 11s 216ms/step - loss: 6.5680e-04 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.9212\n","\n","Epoch 00489: val_accuracy did not improve from 0.93842\n","Epoch 490/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.5670 - val_accuracy: 0.9064\n","\n","Epoch 00490: val_accuracy did not improve from 0.93842\n","Epoch 491/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.6042 - val_accuracy: 0.8818\n","\n","Epoch 00491: val_accuracy did not improve from 0.93842\n","Epoch 492/500\n","52/52 [==============================] - 11s 214ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.6697 - val_accuracy: 0.8941\n","\n","Epoch 00492: val_accuracy did not improve from 0.93842\n","Epoch 493/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.6683 - val_accuracy: 0.8818\n","\n","Epoch 00493: val_accuracy did not improve from 0.93842\n","Epoch 494/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.6061 - val_accuracy: 0.8842\n","\n","Epoch 00494: val_accuracy did not improve from 0.93842\n","Epoch 495/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.6361 - val_accuracy: 0.8670\n","\n","Epoch 00495: val_accuracy did not improve from 0.93842\n","Epoch 496/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0432 - accuracy: 0.9927 - val_loss: 1.0384 - val_accuracy: 0.8374\n","\n","Epoch 00496: val_accuracy did not improve from 0.93842\n","Epoch 497/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.7380 - val_accuracy: 0.8916\n","\n","Epoch 00497: val_accuracy did not improve from 0.93842\n","Epoch 498/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 1.0112 - val_accuracy: 0.8325\n","\n","Epoch 00498: val_accuracy did not improve from 0.93842\n","Epoch 499/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0096 - accuracy: 0.9951 - val_loss: 0.5518 - val_accuracy: 0.8990\n","\n","Epoch 00499: val_accuracy did not improve from 0.93842\n","Epoch 500/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.7176 - val_accuracy: 0.8719\n","\n","Epoch 00500: val_accuracy did not improve from 0.93842\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1b5a605490>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1629939945320,"user_tz":-540,"elapsed":16,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"3f2bc98d-af91-49ba-cbc0-a5dae252b634"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deXwURfr/3zWT+yYHRwgQTiEgl4AgICgooIi6ivd6rIrrvZ7rrj9dz/1663qsirrqurseq6uioqiIeCJEEZD7Ru6QQO5rZur3R3XP9ExmkslkQjKTer9eeWWmu2emurv6U089z1NVQkqJRqPRaCIfW1sXQKPRaDThQQu6RqPRRAla0DUajSZK0IKu0Wg0UYIWdI1Go4kSYtrqh7Ozs2V+fn5b/bxGo9FEJD/++OMBKWWOv31tJuj5+fkUFha21c9rNBpNRCKE2B5on3a5aDQaTZSgBV2j0WiiBC3oGo1GEyVoQddoNJooQQu6RqPRRAlNCroQ4h9CiP1CiF8C7BdCiCeFEJuEECuFECPDX0yNRqPRNEUwFvorwPRG9s8A+ht/c4BnW14sjUaj0TSXJvPQpZRfCSHyGznkVOCfUs3Du0QIkSGE6Cal3BOmMmqA3YeqWbq1hB6ZSRzVq1OD/XUOFzE2gc0mGuyTUvLd5mIcLkmPTon0yUlp8vc27Ctn6dYSDlbW0SUtgdmj8hDC+7t/3H6QzUUVnDa8O/VOFx+s2E1epyTW7CmlosZBrN1GjN2GEKp8Oanx7CmtITc9gWP6ZpObkUCM3dumqHU4eW/5LnYdrCY3I5FzxvR076uodbD7UDVJcXbW7C5j16FqDlbW+S1/1/REJvbPpkdmknvbxn3lLFy3H5uACf1yKMhNo7SqnsUbi0iKtTP5iByW/3qI4T0yiLU3tHUcThdOKamocfD60h1ICXmZiTicagrqfp1TyEyOo6i8loykOJLj7XRLT3Tfg/8W7mTnwSpSEmJIjFOPXlFZTaP3oWt6IvVOF8UVtY0eZ1KQm870IV3d5d1yoJKlW0tIT4wlOyWeX3aVUl5T7/WZuBgbF4/vTUq8KlNZTT1fbShiw95y9zFCCHplJVFZ5/Rb5j45KcwalutV/4orapm/ag9F5bWkJMRgE4JYu406h4vyWgcp8XYqahzu42PsNmaPyqNbeiLbDlSyu7SacX2yWLKlhL1l1ewrq6Wq1kF8rJ0ZQ7pSuP0gO0uq/F6HlIQYdx2Mj7Vx2ojudE5NQEpJdb2TTfsr+HztfrqmJdAzM4nx/bLc9bvW4eSzNfuoc7iorHXQJyeFpVtL6JmZhFNKDlbWERdjIzM5jl5ZyazbU0aX9AQmD8hh9e4ythdXUVReQ7/OqUzon83+shqW/3qIyUfkEB9jp7iilqyU+KDuZ3MJx8Ci7sCvlvc7jW0NBF0IMQdlxdOzZ0/f3VGFlLKBAFo5WFnHQwvWs2jdfl68aBRDuqc3OKaovJYXv9mClPD60h2UG5X/mfNGcvLQbu7jXC7JUfd+xowju/LQmcPc2xet2096Uix/fHslG/dXuLfndUrkb+cMZ1heBmU1DjKT46iqc7ClqJKfdhzk41V7+X5LsVdZ0hJjSI6PYWJ/NUBt9e5SZj/3HS4Jt769skHZhYCmptrPTU9g3rUTyE6JZ39ZDSc/9Q1F5d7CVZCbxtC8DPaX1zDrqW/Z60dMfC+z+bsJsTb+fdnRjOjRiWXbSrjo5aXU1LvU+SRsYkzvLL5Ytw+XcXysXVDvlFwwtidH986ib04KXdMTqKhxcMvbK1i6rYSkWDs2m3Dfi8awCXjsrOGcOjyXuz9YwyvfbfN7XKBq4nv9GqlOXse/eOEojh2QwwUv/cDSrSVN/p6USrALctNYvL6I15fuoNbh8jq2sbKY+w5W1XHJ+N44XZL/LN3BPR+spt7Z9HoL1t/4YMVuHp49jLOf/55ah4uMpFgOVdV7HSslPLxgfaPn48tXGw5wwdiePLRgPVuKKhvsv2JSHwbnpjO+bxZX/+cnlmxpeN2aIj8riW3F3g3MiJ4ZrN5VRp3TxaUTejNlUGd+/9qP/PmkQV7GSrgQwSxwYVjoH0oph/jZ9yHwgJTyG+P9QuCPUspGh4GOGjVKRuJI0R+2FON0SY7pl+3e5nRJPly5G5sQZKfEU9AtjcmPLOKqyf04uk8mQ3LTsdkE2w5UkpuRSFyMjT++vZJ3ftqJ3SaYNrgrT547gs/X7GPB6r3ccUoBaQmxnPXc9yzdpipWflYSD88exm9f+oHTR3TnlmkD2XWwmgFdU1i+4xDnzF0CwBc3TcImBA8vWM9Hq1SbmhBr48Jx+dQ5XKzZU8bSrSWcM7oH+dnJPPDxOsb2yWxQgacP7sq1U/qxfm85N761wr39q1uOo2dWEje+9TMLftnLMf2y+WzNPgAmDcjhlGG5DOqWyuDcdKrqHNQ7JC4pSYi1U1xZS9e0BNbtLWfxhiIeXrCe647vx5F5Gbzw1RaWbithVK9OnDo8l1NHdGfsXxdyxsg8bp52BJe+sozC7Qe5bcZAMhJj6ZaRSPeMBPp1Tm1wj6SUbD1QyUlPfs1Zo3oQa7fx0jdbAfjmj8ex+1AN9364hj2lNZx8ZFdmDc/lxa+38vEve72+Jzc9gap6p1tQumckYrPBryXV3D1rMLOG5bK7tJq0hFgcLsmf/7eKI7qmcnTvTPaU1jBvxW62F1dy9uiePLd4M5dN6M2fThrEhn3l/LTjIAO7pjGyZ0bAhl9KyQ9bS9hTWs1pw7s3aiAA1DtdFNz5CZdN7ENZdT3//mEH547pweQjOtM9I5Gy6np6ZCZ59VoAznj2O37cfhBQjdAZI/P4zcg8ju6d6ba4q+ocbNpfQU5qPF3TErzKIqXk1Ge+pbzGwXtXjefZxZt5bvFmuqYl8PjZwxnbJ5PiyjoE4HBJDlbVkZ+VTEWtg6zkOPd3fbPxAL97ZRl1TtWYmAI5LC+dB84YSnpiLLkZiWwpquAPb/7MWaN6cP7RPRtcFyklJZV1ZCTFUVxZy5MLN/KvJTvok53MlgOVDOiSwoAuqdx32hAq65zcNW+1uw6b1+C+045kSPc0nC7J+z/v5tIJvdlbVoPdJshIVPe7pt7J2j1l5HVKYunWEhZvKGJ8vyxmDOlGZnIcjxjP4MlHduO7zcVuY6R3djL//N2YBvchWIQQP0opR/ndFwZBfx74Ukr5uvF+PTC5KZdLpAn6ntJqzpm7hO1GC/z+1eMZ1iMDgE9X72XOaz+6jz1jZB7v/LTT/f7iY/KZfEQOF7+8jCO7p/Pq78Yw9q8LOWt0HnUOF5+u2ce3fzyeYx74gtLqei4a14tbpg9kyF8WcP2U/px/dE8yk+OIsds467nvAbDbBN9vKXZblSa56QnUOlwUG66Ik4d247wxPRlvaYBm/O1rctMTqHO6+HrjAWwChnRPZ+XOUnpmJjH/+onu7jfApIcXuc/7muP6MW1wV0595hsuHJfP7ScP4qsNRbzw9Rb+evqRQblzTE595lvi7TZ3ozVzaDeePs8TUz/lqW+oqXfilJItRZVM6JfNvy47OujvP/7RL72sseum9OfGEwb4Pba0up6Fa/cxrEcGUx5d7N4eYxNcNbkvA7qmMnNoLg6ni5LKOjqnJTT5+wvX7uPSV1UdnzqoCy9ceFSTotxSht/zKd3SE1m7p4xLJ/TmjpkFTX5m2bYSfvfKMkb27MQ9pw6mV1Zys3/3pW+2cu+Ha8hKjqO4sg6bgOV3nEh6UmyzvufeD9fw0jdbGZOfydPnj+C615dzx8wCBuc27MEGy7JtJcw2nptzx/Tg/34z1Gt/dZ2TRz5dz/s/7+JARR0Du6byyR+ODfn3rLhcEptNsH5vOX9+dxVrdpfxr8uO9us2DZbGBD0cLpd5wDVCiDeAo4HSaPGfSyn5ckMRQ7unM/erLWwvrqKgWxpr9pTx/ZZihvXIoLymnmcWbQLgqsl9+fuXm73EHOCV77bx7x/U9AurdpXy4MfrqHO6OHtUT77dfIBDVTu5/J+FlFbXkxBrY8HqfZwyLBdQQmsVj76dk3l9qcfDNWtYd3pkJpKflUx8jI0r//0TAM9dMJLJR3QmIdbe4Lw6p8azv7wWh0sy+Ygcnj3/KBLj7BysrCMxzt7gM5MH5PDq96r8q3eX4pISmxDceOIAYu02pgzqwpRBXZp9fTslxfKTYRnOGNKVJ84e7r0/OY6vNhSRHGfn0dnDmNrM38hNT3QL+ntXj2dYXmBRSE+M5Tcj8wBYevsUFqzexx3v/UK3jARuPPEI93ExdltQYg643VMAY3p3anUxB0iOi2HtnjLsNsH1U/sH9ZnR+ZkU/r+pxNltIZexX2fVkJuGxIkFXZst5gDHDsjhpW+2MnNYNzqnJvDGnHEhlcfKoG5pfl+bJMbZuWNmASN6ZnDNf5ZjC+N9Mns4R3RN5Z0rj6HO4SIupvWyxZsUdCHE68BkIFsIsRP4CxALIKV8DpgPnARsAqqAS1qrsK3N019sZEj3dCYf0RmAJxdu4vHPN9C/cwo9M5MY0CWF+ddPZMQ9n7KjpIqqOgcnPv4Ve0prmDqoC1cd14+/f7kZgDOPyqOovJYnzx3Bm8t28J8fdvDQmcM4/8UlvFn4K90zEhnSPY3tJUpwvttczOkjujOxfzY3vrWCMw2LYlA3b5eC1cXw3tXjGW70EkBZAzedMICDVfWcWNDVb4AUICc1nrV7yiirqeeYvlkkxikB75Qc5/f4347rxavfbycuxsai9UV8v6WYbhkJpCU0/4G1kpYQS5nhi774mPwGAdJMQxAGd0/njKPymv395oNz58wCr+vUFJ1TE+htWKm5RlAzFKwPbt9m9FxagtmzOrJ7erPuT3xMw4a/OZiCDupeXjGpT0jfM2lADh9cM4Eh3RsKb6ikxMcwsGsq6/aWN2oZj+mdCcDF4/PD9tu+tKaYQ3BZLuc2sV8CV4etRG3A+z/voqi8lkc+3QDAtgdOBuCrjUUAbNxfwY6SKkblq8rQMyuZHcVVrN1Tzp7SGn47thdXH9fPy03xx+kDyUlVkew5x/ZlzrF9AWVxL99xiGE90hFCkNfJ40cblpfOrGG5zFuxmy/XFzF1UBe6Z3gLyuh8T4X0FXubTXDtlKatMtNCh+CEpl/nVDbcN4MnF27k6UWbqKl3NShXKKQmeK6Xv25+ZrK6fl2CtIh9qaxVjUXv7Oa7EEbld+I3I7oHbeUGIjUhhvIaR0hlCIUU45r2DNE/Gyq56Qkkxdkp6JbGXbMGt+i7jmykJxUq718znpo6V6O9hs6pCWy8f4bfDKdIoc2mz20v/LKrlOvf+Nn9PsO44VJKNuwtZ9awXD5YuZtah4scI9WoZ2YSH6zYzTebDgBw+cQ+dE1XovPBNRNIiLW5xdyXfjkqiNnfsLStwti/SyoxdhsvXzwawG/31+pLDNWqspatT05wQhMXYyMrxWPBt9SiA0g1LMi4GBud/VyvTsa96BRC1x3guIGd+WFriZf1GCwJsXYe83EBhcIrl4zmle+2h+SXDoVkw6gI9ZqFihCCR2cPo2fW4W1IgiU+xh5UnY1kMYcOLOhSShau3e9Oz4uz26hzusjrlMiDn6xjXJ8symsdHN0nk81FFazeXeYWwp6Z3tZpXifP+6asC/M7Mg33RnZKHAXd0thcVMHArkrkG/Nj2m2CZ88f6RbDULA2IsEKOsC5Y3qyalcp//tpF4eq/Od/NwfTQs9KjvPrHoo1uqehPmRzJvbh9BHdQ7bww8FRvTI5qlfmYfu9xFh1rTKS/LvPWpMZR3Zr+iBNq9KhBH1LUQVCCFITYli58xCX/VNlIIzJz+St34/juteXM2/Fbn7ZVcazhi98RI9ObCmq9BL0rha/6qBuaQF91f64YlJfquudnGn4hIUQfHjtBCrrHEGLdEsfnKN7Z7lf5zRjgENCrJ17Tx3Csm0l3DJtYIvKAJBmCHpyvP9qWG/kQocq6DabaFMxbwucRlL94bbQNe2DDiXox1vS0ayYwZAMn4dgWF46Bblp7DqUxUvfbCXbEL+uFpGYf92EZpUhPTGWv5zi7WO02USLLO7mYvoR7TbR7KyG5PgYvr71+LCUwzzn5Dj/XeGxfbPgMxUo0wSHOSAoUIBbE910GEF3GIMV/DHAcHWkJ3qL6iQj22Vi/2yuOLYPxxnvu6V7BP1wpKK1BsvvOAFXEGMQWhMziJwU578ajs7PZN290/2mXmr8U2/U87ZwuWjang4j6LsOVQfc198ImvkK+pHGcPyEWDt/OmmQe3s0dOPbgwXncCnxSY4PLNhazJuHOa9MQiunx2naJx3mrm850HD+BtNCNFPKfH25gXJhs9qBGEYDvbNVQzp9iA6mNQuXU/35wcymaQ8NdrNwuaB8b9PHaRqlw1jo2/wI+ntXH8OqXaUNrMBrj+/HUb06uWfK88VmE1wwtidj+2T53a8JjiO6pvLznSdo90BzeX4SVB+EG1c32HXvaYM5eWhXBnRpOMdNq7DiDeg2DDoPavpYK6veVp/pYsSTPr4Vlr0Apz4DIy4Ifzk7CB1C0CtrHQ0EvaBbGv06p3qNvDxjZJ57ciLfUYu+3Hfaka1S1nZD2R54bjz89j3oNrTp40NEi3kI7FsVcFdSXAzHD2z+NAyNIiWsfBP6HAeplu92OuDdK9Tru0oDf76uEgr/AVn94IgZ6nPvXAq2GLjTmNWzaJ36v39teMr7879h0CmQEP5BSu2ZqBf0pVtLOOv574mz2xial868ayawZEux229uJS7Gxtmjo3ta36DZuwqqiqFoffMEXUpYOw/iU6HLEEjp3Lzffe10yB0BU+5s3udemAIDpsOkW5r3ucPNoV/h6dFwyXzo3sjiXnVVsPUr6H8i2Gzquq77CLAEsp0OsLfwEd6zEmKTILtfw32VB2D3cnDWKeEedh506gUbP4XLv4CyXZay1IM9QKbWe1fCmvfV6yu+gjjj2XM54NnxcOSZUG5M/1Sxv/nnUFsBq/4LPY6GLgWqcXj/arXtwveb/30tZcuX8O7v4fffQvLh7cVHvQ+9cLuaya/O6SLf8C+O7ZPVahPMRw2lO9T/uvLAx5TvVYJvZWchvHWhEubnj216UnQrUsLmL+DrR5VYBUtVCewqhEX3wT+mw4YFsO0b5ZcNxBf3w//mBP8b4WLtPHBUw/xbVCNUUeT/uB+ehdfPhi/uVe93/wRvng9vWtwRr50Gy14M/Fu7f1auGV/2rFTXyOWC5yfC00f5//xXD8O/z4SP/6jel/4KX/4f7PoR/j7O+97v83H/FG1Q9UNK2LIYCk6FmARY8abHGgfY9wt8fhcc3KbeV+yjUd69Epa95HlftkfVtQ//AP+7HPasgFKjodnyZeN1oCnqqlR9bg5LnoV/nqoaqFVvhf7bIRK1gl7ncPH4ZxtYu8cjSIdrPo1WoWyPEgDz4QqV2go4uL3p40p3eo4PxKNHwDNjvLf9+oPndfke2LJIievc4+DT/9dE2SyNx6r/gqORVXpcLnjvKvj2SVg617N9x/fwn7PglZNhxeuBP//VQ8qNAEp03rkMtn7dePnK98G/zlTnc3C7akh+Xaa21TWM0fjFFKxdhepv6fPqfX2NEoL/nK0s400L1fati6F4c8OGE2Db1/Dd03BgI2z8XH3OREqYO0n1Bqy4XMbvnAVvNDJNU/VBz3UtNWb33GtZyGT/Gtj0ued9yWbvzz8zGh4fDJVFUHMIeh4DGT3Vd1ndKgnpIGzKWrdeH3/UVcKK/8BHN6rrVbQePr4Fdi5V+/f9ooyIbZb7uLfh4itB8/7V8OKU4HsNC++FT27zvN/wSei/HSJR63J54vMN7pkPQWWsnHd0G7pTastVZkJi8LP+ebFlkUcEpj/Q9PI1gXh1pupG31UKjjqoLYPk7IbHHTIe4roK9Tqjh/f+QI3Cr0sgo5fqWv9tqLKeTIrWw9R7lAvBl5oyOGT5zvd+D4sfhOuW+z/XH55VftLG+PnfMOJ8z/v6amXFJVpm3Cvfp1wFq/6r/vz5gp0OZQE6amDTZ+rPl82LYNDMxssDsNdnrfWvHoZflyqr1RSzh/t69u9ZAU/5uGYu+RhenqFeH9wKTxtTYyd3hjmLID1PnSsoQS1aD1n91XXfsxyqjcVMrILjcqn9WxbD+vnqfKQL+h6vek3DL4Cf/+VdDrMxAijZ4nltNsQuh8cazxkAad2Vm8bacOdPVO6ajQuUuDcm6PvWeF7PvxmWv6ZeD5ypArOL7lfvv33Cc9zcSdB9FJzyBHT1E/eqPqTqlz9fu9moFq1Xz25SFsTEwYLbod8UdW2sfP2I9/s9K83loAKfU5iJOgt93d4ybn17Bc8u9oj58QM78+G1E9s2f/zBfHis6cUGArLXEgjz141ujLLdUGMI1e7l6r+Uyi/6cF//bhHTQl/8IDwxxNONNdnlWdDDbZ06HcrKzZ+gGq6pd3uOGXIG1Fcqi+qTP8EPc72t/7cuhOd8Rt0e3Kr8+L4c2gEL/qz8y1PvgmOug6OMWZu7DYcRv1UC5GvVblkMaz+An/7p2fboAPj3bM/7mrKGv1eyRYnHqv823Jc/Uf1/51LPNfPH5i/g1VNg88KG+7YuDixkLovrKbET3LIZ8karTJDjfXo8VQdU8BG868gzY5S7pqYMPr1DBSNvXAenz1WvASqMlMF/zoIfnoMD69X9O/9tuGENjP29//LlT4TUblBsEXTTfQLK7QGQMxDSuytXzPZvPfvT8+Coi9TrnuNUuc3GyCr8K9+CTyy90/XzPa9H/BbSfQwOYYfx16v/uwobWstOhyrnowPhaZ9epvsYo2H66Z/w2ED44h7Vu/j+aWWouJzKLVNT6v8Zqi7xjjMcBqJO0M974QfeKtyJlNAlTfnJC/xMan9YqS1XD2a9pVu+5FklTMGyx9J1PBSEy8T9uRXw2CDl87T6pZ31sPp/xus69RDVW9brNLvZ7t/c4V1prV3sSsMP/OH1qnvd/wT1ftQlcN5bMPg3MO4atW3Zi7Dk70rY/6+7cltUH1I9EH/4Ct2S5+AXo9wTb4IJN8CJ90KyMT1A3+Pg1KchqVNDN4jVRWBll8VP+kAPJb5Wqg7gl+tXwMUfqjI4auCXd5RoLn5YWf5Wfv6PCnICZBurJvWfBlcvg5EXKZGe9Ecljl2GwODTVUNlpXOB6k3ZY1V638SbYc6XMGgWXPKJshhXv6uO9W30138M/5imxHTGQ5DWDYadDee+ofYf2uERUpNxV4PNroQ4x5KWaH098wmVvbJzqSc33mqt//w6xKep80rLUzEZZ52nIUzKgoEnw1VL4GgjY+anf8L3f4f/y1PX8dCvqmdlNSKqiqFTb7h4PgyYpoK1oAwHgJwj4IR74GY1JbbboDH5/C/wt2EqnlGxVz0PoNxby15U9dJhPA+mL/y7p+DvYz3f8f7V8Ndu8EBP+PAG/OIbW2hlos7lYs6BDWCO9p/Q349L4XAgpaocST6z7VUeUL62T26Diz6A3gGWu6qvhp9eUw/3zqXquK1fKXdH7gj/nzn0q/IhDj9PvV/3kfpftgvutUTc6y2L2VYVw9+GQ0w83LJJ+TTNrAOTd69QDclfDilL9Iv7vM8nJhGWG13yvlM8+wZMU3+OOpWFsm+1d2NRV9HQDTHmCti5TAUCK/Z5cpVryryttAyLC+2oi5QrZPTl6n1cinpYXU4lSqAat/yJULIVyhqxpvet9u5O+7OeL1sInfLV66l3qSyOX5eq3/jlHeXuOfs11c3f/IWKLXTKhzNfVr7eeddCWq5yRcx60vO9g3+jejepXaGyWPWo9q5SDWWvY7zLIISqB2cbroeNR3oCgaZb5dRn1Oc+ukmVIzkHRl7o+Q7T3VZV3DAAaM1asceo+5KcrRqSewy3VXoejPodvH2JspoHnaKur0n5buXyEMLjtis4FVK6qHoaa0y323mQsuKzj1DlNMtStkv1qtzliPdYzj3HQf549brXMfC7BZA3Bo673fv80vLUtXz9XPXd/2+fp+dgsmcl5B0Fr8xUZY4xxqD0GAvZ/VU9WvEf789YYzQ/vuy979RnlOD7Gm07f1TPXu+JtAZRZ6FbR3HeeUoBXdMSGNkz9PX7GrB3lXpogzp2pfL1vf077+1WS+jVU/wHvAAW/VVZsu9cqqyaSUbAxdd6tvLJbSpNzHTRbFoI6X5iBw6LNb7gdvWQ1JYp8SrbrfynVsxeQU0pLH7Ae9/SuZ7A1KWfQYKfHlFMHJz3Jgz5jfd2l7OhYE65E84wsjeslu6Bjd7HpXT1vE7PU9Zqenf13hQKa8NVvkf5cQOlkvUw1iu1XhvfMgDMWQx5Pks69jhaifbOZer9wa1KQEB1zw/tgKRslao48kK44B2YfBsN6DxQiTmocl78oadx7tnEcmyp3VRPsKrYY6F3GwaZfTznNvRsb6EWRmMnpSeg3XkwTPu/ht9/0kMw6VbvGEhsguoVgUe8KouUK6eL4bPOMWbmHHw6nPWaatSSjIbEvF+gRD85W7nizF5RVYknJbFzAZxpyXDJ9FkVqedYVbasvurPJDlLfd/6+ere3pWuGtXx18Mpf1MGjOnCMXuba96DhAyVXnrq097psGc3Ebs56RGV4mmLhR9fVc+TyYvHqzhWKxF1gl5nzGUx59g+zBqWy5I/T2l62acPb1BZDsHw3AQVSQclzA/mw7r5ysfsa2nW1zT4uNpe5f3eatFYMQNKWxcrK8N8oP1lnuwsVGliZtB15Zuw/hPlThg6G2a/ErgMpusFVDrf0z5iZaVin+pCg/JTm7/10z/BHqcEpDESfILCLqenOzz+evUdccnKgjN/z8Sa7gb+g6smcUZGk+l2MYeWp3b1lN+Xiz5Q+6zZIruXNxzIk+tn4YvckUoMDu1QjQYYDaPFTRVnWfyh31SPcDfF5D8pf7dvEM6XVGMKhfLdHkE3A8ADpin3xlEXe39GGNdQupTVmn0EXPUdjLsquLIBxKcDQrnOQDUoiZnqN0HFVEDdk4JZqsc04Q9w2nNQcJrPd6V6/PmgfPmlvyq30lXfwxEne/b5BuoDkZTtfU9Neh+rrkff4z1uFbM3V7Re9QDN95l9VO9uxAWqJxuIoy5W8RybDeJTVIeRe/UAACAASURBVN3556lq3/OTgitvC4gql0udw8WBilpumDqgeUuHmYEk0yoMhG/go3SXenA+uwOK1ULR5E9U1ldMvLJ4fXHWN/Ttml1IX6yVsMcYVUnscQ2Prz6o0qsy+yihANXIfPeU8dmj1cP1yzue7quvv9Rk5Rv+t5uU71VWTlI2zHzck/mw8VNllTRW2UE9sKCstqJ1yqKsLVOW4tS7ld8T1MMQl+KdMla0Vp1/ajePeAXCHLxiXuvqEnDVKzeH1a+Z2MkjfjHxykK0/ubcyep/QoZyewTCmkEx7a+qkfrgOuWTNYkNcTWfhDTl724Kt6DvtQi64e7LHQG3bmn4GVPQdyxRLpCpdwVXpgvnqXsBql4mpHmuT3WJajym3KF6If4GHMXEw3A/aZNxKZ5nCWCbEUA1rXxrIx5sg5iUBcUbG243YwHdhqusHvBcj7JdnobZ5OIP1f8t/qfhBmDctZ7BXuY9OLBBpR3v8ayMRl2VdwMfJqLKQt9XpizirumtMGhISjXIworZejstq/ds+9pjSfoGYkAJjK+F7qxXQdJCHz+cNcPD7OLb4z1pYc56ldv9ohGELNniybSwBi3zjFxk0+cLgXsPJuOv97+9fK86h/gU5Ua5zeL+mRxEjvyI36pg5vg/qPcuh/KNJ6Q1TO9KzvZ0gb96RDVQuSNVKuPvmsjx9bXQzW5valfvRscW47k+oFL/zN+0NuCZvdX/QPEO088PamStGfgstfhQQxX0YEkzBL1st3JV2OMhtom1X00BM3shQ4NoOAD6TIJeFhdQQobFQi/xxI0CjR4NRLzPCO7t36j/OQMaHpuaG9x3JmerMvmSZnw+NgGkUz1P5vVwOQILrj2u4bYkw42XGMC9a1rpJr4xqjARNRb6NxsPcMFLygeYH+z6jU6H6tKZ1JarhyDGzw0r2eKdJeGo9UT1fUc1lu+DbninXZnUV6nW2Yqj1jMgoeBUZaXExHk3CNlHqP8x8UoA512nBneYPlsTa3pjSle48jvPw2X1Ofs2KlcvU4NBQGVdnHAPfPs39T4tzxNErNirXD6mBZyQpqzrhHTvBiMQsQnKR77O8Fm66tV5+ssDjk1S5ZTSM2Iyf7ynIW0M82E0Bd2cyS8111tkbDEqU8JlZDnEJqqMm50/qkwJk4yecPFHyi/qj4Q0Zd1m9lF/Zp2wpnu2tqCbbqrKIiUYKV2azoE2Bcysa4HcUU2R2MljoVeVePuwm4NZr2wxqndRuV+NME3La3hscyz0Oj9uSvPamPeldKfneoDHKPDFnz5c9KFy21gTIC76UI0MXjrXW2dA3Z9Qr1EjRI2F/s5PnqyFPkGsZA/AN4/Bs5bMgf/L8x4I47BY3ht9BpNUFXss8/Ld3vvMAKI/l0tdZcPKZbXwH+rtGVFpFV3TQoyJVz71n15VYh5nuDBMobHmQvcY4x0A7G4Z4u3rcknPU40ZeCyXC95R1vSV38CtWyE2WTVWdRXelf3mDXD9zzQLU1RdTnWd/AlJbKJy71jPydcHHAhTGD69XYmrGWRLyvScJyjhiInznI8ZaPv+Ke8GOaOnOsbfw2wy4QbVIIMne8TqPmiFLrYX5jV11itfvpnK1xhegi4Ci1hTJGZ4XAxVxR6LtbmY9SAt19PjSM7xHy8x3XdN4c9YOO05z2uzF/PkcO9nNi6Ajth9PACZfdUcMlPv8m5Ae0+Ekx5WaaK+tNJUwVEj6NZBQ9kpjTx0VvxdVLOLt3cV3JcDb5yvgpZFa5Xf+CwjRazyQGDft1vQ/VjodRUeoT7tWfXfKuigWnSnw3t7hvFwxsR7cmYBhp2j/rsfXqmsmd7HwnSfTIVe4+B0c6i5j4Uem+ipjKbl02+qsqYTOykhTO2iLPS6Su/Knpzd/FntTCvb7XLx8/mYRNXwmMO3L/3MO1WxMUxh2vWjarTfu9JznlZR9s1WmXKHEpDSnd4Pt68/tSnM4K911GJT7o9wIOzKfXBoh6fONHq8cc9rjEY11FGNpstFSsOHHuLC2KbLJT7dkwkTaHR1sGX1rVtxKd7++5gA9yVQj8rqcplyp5qorDGy/biLWmm1sKgRdGv+eVDLwu0sVIGgQJgpcus+VDnYNaVK2Nx5uwe8hdXKpoVK9Eyh6nmMx3Krs7hczLxia5A0dyQgG2ZWmIEWe7yna5vazZPParWIsvqojI10P93UHsaoON/UPCE86XHmIB1fUroaPvSK0C05E3OEosvRiMslQQm6aaH7pqk1hvVhtHZ3YxLg6CvV9Zr9isoXtpLYSd2rovXeo0abCvb64s+iDCQc4cRmV9esfE9wjZ/VQg/W4vVHohE0ri1T9zQxREE3DYX4FE899PVL37Aarl4a/Hf69v5O+7v3+0ANbTAul5yBTU/n4etamfxnlXnWCkSND72ksg6bgIU3TQ7uAy9OaXy/1U9rptYlWKyGymLvlto64GH/GpUCZroSfvexakDWvG8ERQ0BN604M/g5/QGVnvXEEE/mzdir4EjLzY+J94jxBf/zDCDJOcIz1Wljvlp/+dkmMx5SjU//E/1/NrWLGoDhrGvZww8eQXfWB3a5xCSoczV7Kv6CUYEI1F2OTVTdY38ZHyY5A1WZ9luyYczsofaOsHvm2WmOoEtnCwXdyBYyM4iC7Un5YlrocSke48m3cfBnqDSG1Vi49qeGAhvoeQnG5RITxHQiZmzD/b2t53qLGgu9pLKOkT07NT2jYuUB2L+u8WPAO9fbHqe6kwnpntbZWec9G+CkWz3HgqrcteUeoTIrTV2FYZELzz4zTS4hXQ206DkO1hopUt2Gec+bbbUUYxOh13g1OGLaXz0Vv7FKZloj/tIW7bHKcgiUmZDaTeWF15aHwUK3+NBrSv0PRoo1XC5mT6g5GRMBrasgHkAz3/vHV9T/K78PXaCs+A7Wag1sds/8IWlNpHaCdxCwJYI+cKayzD82noNQA37mdLfxFkFvbu/IF2vd8ufbb66FbjUsgnGj+Za/FYPjUSPoB6vqyAxmHcVnx8Pfj/a8zxnkbQGbmG6QvlNUl7+m1Ohame4c6e1y6ZQPJz+qhoSDOt7ajbWm0dVVqfdmXnmlKeiGxZ7ew2N5+958L0FPUq6Soy5Wv2NW1sYqjNnt9820CYaULqpBqjkUBkE3ekBVxcoaTvOTgmZa6OYEVYEyTPwR6EELxh2X1VcFkM2JzEIVup4+Q/UPh6ALuyc2FMh15nW8VdCDTCbwR94oNbeKmWXVqXdo32Pe6+QcT2/Y5Qh8fDBYLXS/rr1Agh7gObK6XIIxEBp8b+tN4x01gl5cGaSgV/gEQlO7eEehbTHqgTDTuHIGGiPvSjxzN4N6OK1B0cQMGH2ZmlgJoWYD3Pa1R6hMUTi0Q4mYKbr2eM8AIrOypVgeRF9xtnb3fCucGYhqzGqwx6qHvrFBMoGwpokF6o4Gi+lyOWBMnpTpx6LztdCDSVc0EQJu39dwZGqwWCeg8td7CIaLPvDZ0DqBMC9sNk8db7agt9CNZvqSU7qE3jgMMSZyO+52Tz0OsCB20Fjdef4adN/nxbwmsYEsdJ9ecnMRrSe7UeFDd7okByvryAo2u8VKTKISwutXqMUSCl9SCzeAEp2sPspCqD5oCLpRIaSPhZ5gBG5sNvU5M6/ZHOFmivVXRuNh5mzbY71dLuD9IPqKttVC9w2ymSMFG6tkQhgjMJtYGcYf1u5q2ATdCFj6C3jGJKiGZ9mLyjpvbgZGbIISl1AaL6uLJdRztcd4x1YOl4WuXgSXOhhOQTfrb3N93FZi4mGaMa+5NROqJTR1/3yfl7Q8NSBMBmhIrK6/UCz0VqwHUWGh7ymtxuGS9OgUgm8q1rghnfIbrlwel+LddbRa6EjvtEJrpNtlEXpzcIrN7m0pmJU/Jt4zMtG0BJMbsdBNQbfHNVxP0hTFpoQvo0dwcQRfrGVpSfccPA9FkWmh++mimw9adUnzAqJWRlygZnlsLtYc7ub0DHwx61fXoSq7prUxy5qUFVy5vQS9hdNMm3XadJW0lP4nKt/8ifc1fWxjNDbnDzQ0jMwGyd/c+OD9fAVroXe1rMurBb1xdpQof3DPzCYE/UE/omHtPvlW6LgU7+BOgsWHLl3eQdFAedjWz1tbdnPUpj0Od1fcFMxky8LKvv420yLwV5HMmesCrVNpktlb5dU3F2tZwuVDL9miroW/87FuC3Ux5PHXNZxXPBhM91IwudyNccZLyh9/+SLl3mttTAs92MW5rYLe0jx5dw8zTIIelwzn/Nt/Yx9OfM/7uD+rFZ4KZjX92WAt9Is/9ExElhzkvQmBiHe5vPb9NuavUj7DHk0JuhloDISvKMeneA85TszwdrlYu4L+fLUn3uc9aZPVF2g+cF6pj8Zr6wPhW9nMY/wFPs25LZqaJyKzb2jdWGvXNVwuF1d94GwMq+XUnICoL6EIVbfhatrhWU+F/rugFvswF/w4HFgt9GCwWpuiBT0R8BhEoY4SbU2u+Cpwbrzvs9RtGFwb5OLQwWasJKSrxn34eWr5ulYi4gX9jvdV3muMTdAtvYX+LN+h0nEp3pZh70kWIbS4XG771b8FOfIin9+yBMVMQY/xk9NqXU6rgculEQvdTG9sani8tdcw+vLgp0q1+vPDJegQeObEWMv9bO4kT1ZC6U0kZsANq5o+rr3hDugFKTRWC72lwTrznrbUddMaNDats2/dak7dbk69tMd4phRuJSJe0E26d0okxt5IhQy4grx1Rj2fTAtTCM5/R6UqJWV63Bkul1phHgLnyfoGmaxBFneWi9VCNyqHdf6VBi6XRiz0pEz/ixz7Yu1N9D0++BGYYXW5WB6EQILu79qEwuEYct9eMC10W5CPdjgF3TR2QnWPtRW+MaemfO6NfbaNiWgfusPpsa6bDIhWB8h0sFrovhMvmYLcf6pn2lTzBv7wnJoWABq6Ay7/Qg0p973ZVjeH+fCYohWT4H384N9473eXMcH7fyiEKpTWNK6WBkWtAbtAgm4d/BSsQPmjtWc5bE+YbpNgA7lWEW+OkPkjlPEC7YWWutbaCUHdQSHEdCHEeiHEJiFEg3WzhBA9hRCLhBDLhRArhRAnhb+oDTlY5ckmSY63qwmtPrq54Qr1VSUN/efHXKv++0acrQEL3yG74HkArPON+z4I3Y9S2RW+WH3o5qo3ZiPiO4PbGS/CbTsaNgqmGLfEYvWdPjboz1mODafLJZAP3XchkFDpSIJua66gW33oLRR0c175platao9Y11mNYJq8g0IIO/AMMAMoAM4VQhT4HPb/gLeklCOAcwCf2W9ah5JKT9pgrN2mZkpc9gLMu8Zz0OYv1JS0v7zj2XbsrZ6pZH0F/bqf1MKw4MkhDxfmfCDX/uQZXm4Kua/bxmb3nzljPoAtGQ7tLxDbXMI1ORcEDlZZ51dvyex0LenNRBqmKIfkcmlhUPTIM+H6la22AHKrc9pzMOPhti5Fiwjmro8BNkkptwAIId4ATgXWWI6RgBkJSQd8JghvHYorPX7xUb06gTDmX7H6y83h279Y1s101nmP+LQSn+oJdvpbJaUlPrMz/6Hm2fBKZTRdLkEKtFnuUb9r/LjGCIdvuqVWr/V3Aw2xHnSKWrf053+1LHfX7EH5G40abYg29KFDcHOwt1f8LYkXYQRzB7sD1mXmdxrbrNwFXCCE2AnMB67190VCiDlCiEIhRGFRURO50kFgWuiPnz2Mi47J91Ti7d+qlb1LtngWgDDnKAfl6+s1QVmG429o+MXmcP2sfn5OogWVPi4Jsn3WOnW7XIK0lEdfrlbOMafjDYVQXS5WWhoMslqDgRoHISDPXJSjhcPmr/gKLvu86eMiHbPxCsmH3kILXdPmhCscfS7wipTyUSHEOOA1IcQQKb3NKinlXGAuwKhRo1o8scWBcmWJT+yfo+ZA9xWn3cs9lp01IOlyqEySP271/8WznlIph36HMIc5qu12uQTpFohP8ayiHvJvhil7pCVY4w6Nzj1jXJ+W1pZI9OuGQltb6B2Fq5a0fI6ZViCYO7gLsCRGk2dss3Ip8BaAlPJ7IAEI03CxwOwprSEuxkaWOSmX72CZ+HTvVWfMIfUDZzb+xUmZMCDAnODhrvSmq6Wxpc3CTTh86OGkMfeNu3yHYWKraMC0soP1h2tBD43Og6DrkLYuRQOCuYPLgP5CiN5CiDhU0HOezzE7gCkAQohBKEFvuU+lCXYdqqZbeoJnhSLfFYQObfde7XvizSpPuyVBm3DnnZrztxzOwF1LXC7ZR7Q8eOZLYxa62dAdjomtooFmW+hhzHLRtDlN3nUppUMIcQ2wALAD/5BSrhZC3AMUSinnATcBLwghbkCZUhdL2UqL5lnYU1pDbrpFDHwF/aMbPa+PvwPGXB6GXw2zoMcbmSyH82Fqicvlyu8Iu7XcqMvFFHRtoQdFcwcWWdGCHvEEddellPNRwU7rtjstr9cA48NbtKbZc6iasX0toyp9F1s2yeoHx94cnh+1VvqRF3mm+gwV00IPOJK1FWiJy6U1RgFql0v4EM0MilrRQdGIJ2KbZKdLsrfMx0J3BVi0uaXzPFuxdlHjksM3h/RhFXSry6UdjOprrFHRFnrz0BZ6hyZi72BxZS0uCV2sE3L5ulxMwjpZUJh9jmbZzIWfDwdeFno7mHejsbiEGTTWPvTgaO7Qf3+f1UQsESvo+8uURZuTYhmQE0jQQ11CzB9eWQFh8KdHmsvlcOPuTWgLPSiaO1LU32c1EUvE3sGiCkPQU62CHsCHHmhtwFDwEvFwCLrpcjmMFrrVemsPLpfGsOssl+ZhNHwhWegRKwcag4i9g0XGoKLOwQh6WCtqK7lcnIfRQrc2Su09EOYeWKQt9KAwr1MoFnp7rwuaJol4Qc+2ulwCrcITTkH3ytuNUJeLlXY2n3MDtMulmRjXKRR/eHuvC5omiWhBT42PITHOUnEDWuhh/OFwD8QwLfSmRq92VGK0hR4SIfnQtYUe6bSDFIfQOFhVR6dkn4BeoKBouH2Dwmb4dMPQUtjscNP6wFPIdnR02mLzaInLRfvQI56IvYMVNQ5SE3wqrSno1/zoc3S4u5LG94XrAUjtenjncmkv3LgObt7U+DHua6wFPThaEBTVPvSIJ2It9IpaB8nxvoJepyyTbJ9pb8NuoQv13GifY8sItFKRlfhUyOgJU+9q7dJEB9pC79BErKBX1jnonOozoZWr3n9eddiFN8wWuiYwNjv8YVVblyKC0GmLHZmIvYOVtU4/Fnq9/7zqsFdUM5MgYi+fJtrRQdEOScQqUnmNgxSroBdtgB+eC5Dp0lquEe1y0bQzWuRy0fU50olYQa+sdZASb7EoFt6t/juqGx7cWpa0fgA07RUdFO2QRKSgO12S6nofl0tip8AfaC3h1YKuaW/ooGiHJiKDopV1akSol8slqZE87nBXVBkFPvTpD0B9VVuXQtNahDRSVFvokU5kCnqtH0FPyGjkE9qH3oCxV7Z1CTStgrbQOzIReQcrapSge7lcGluTs9VcLhF5+TTRjNRpix2ZiLyDFf4sdOkM/IGwC7rpcolgC10TpejZFjsyESno1fVKvL0m5go00yK0YpZLRF4+TTTTIgtdGyiRTkQqUm29WuwgIdaPoJ/zup9PaJeLpoMRSt3UQdGIJyIVqdahLPT4GEvxnYagHzFD/Y+xLB7dasKrLRpNe8OcxCyEuqkNlIgnIu9gTSALXdg93cabN3j26aCopqMgWxDf0fU54onIO+jXQnc5vANBCWkQl6pe65Gimg5DCyx0HRSNeCJS0ANa6HafibncgqtHimo6GNpC75BE5B2sqfdnoTv9WBitPc2tFnRNO6MlKzvpoGjEE5GCXutQFnqjLhcr4bako2HovyZKaUlQVBsokU5EKlJNvZMYmyDGbhX0+kYEXfvQNR2ElgRFtQ894olIQa91uLz959C4ha7z0DUdhZbEjXR9jngi8g7W1Du93S0QwIdu0GpD/yPy8mmimTNegtGXQe7w5n9W1+eIJyJnWwxsoftZfg50UFTTccjsDSc/GtpndVA04onIJtm/hX4Yg6Lu743Iy6fR+EfX54gnIu9grcNFvK+F7tRBUY2mReigaMQTkYLebB+6DopqNE2j63PEE9QdFEJMF0KsF0JsEkLcFuCYs4QQa4QQq4UQ/wlvMb1RPvRgXC6tHbzUFromitCCHvE0GRQVQtiBZ4ATgJ3AMiHEPCnlGssx/YE/AeOllAeFEJ1bq8AAtfVOMpLivDe2iQ9dC7omitCCHvEEcwfHAJuklFuklHXAG8CpPsdcDjwjpTwIIKXcH95ielPrcDUzKKp96BpNk2hBj3iCuYPdgV8t73ca26wMAAYIIb4VQiwRQkz390VCiDlCiEIhRGFRUVFoJUYJepw/QbfrgUUaTcjooGjEEy5FigH6A5OBc4EXhBAZvgdJKedKKUdJKUfl5OSE/GNOlyTG5iPSbWKha0HXRBG6Pkc8wdzBXUAPy/s8Y5uVncA8KWW9lHIrsAEl8K2C0yWxNUvQW8s1ol0umihCDyyKeIIR9GVAfyFEbyFEHHAOMM/nmPdQ1jlCiGyUC2ZLGMvphUtK7L4irQcWaTQtQ9fniKfJOyildADXAAuAtcBbUsrVQoh7hBCzjMMWAMVCiDXAIuAWKWVxaxXa6ZLYG1jobZGHri10TRRh04Ie6QQ1l4uUcj4w32fbnZbXErjR+Gt1XLK5LhftQ9doNNFPRCqS0+XH5eKsb2RyLu1D12g00U/kCrpfl4u20DUaTcclIhVJSj9Gt8uh53LRaDQdmohUJGezs1xay0Jvna/VaDSaUIhMQffrctFpixqNpmMTkYrUbrJctImu0WjaEREp6H6zXPRcLhqNpoMTcYokpcQl8W+hBxq6rGdb1GgC03tSW5dAEyYibpFol7FmRQMLXboCZ7loH7pGE5gL3gFnXVuXQhMGIk7QnYai23211OUMLLB6YJFGExh7rPrTRDwRZ2K6pBJ0L5eLlIBsZLY4baFrNJroJ+IUyS3oVqtbutR/X4GVrbymqBZ0jUbTjog4RXK7XPwJeqDZ4vSaohqNpgMQcYLucmu3RUxdTvU/oA9dW+gajSb6iThFckrTQrdsdLtcDrMPXQdFNRpNOyLyBN2d5WJ1ubSVha4FXaPRtB8iTtD9Z7kECIqaaEHXaDQdgIgT9MaDonpgkUaj6bhEnCKZgu4dFG0jC1370DUaTTsi4gTdJRux0AMKt7bQNRpN9BNximTO5eKVch4wKGoOLNKCrtFoop+IUyS3y6Vd+NC1y0Wj0bQfIk7Q3S4XPbBIo9FovIg4RWo0y0UPLNJoNB2YiBV0W7sYWBRxl0+j0UQxEadI/rNcmphVUfvQNRpNByDiBN3/0P+mgqJ6pKhGo4l+Ik7Q/Q79dwdFAwms9qFrNJroJ+IE3WkY480Kimofukaj6QBEnCJ5ViyybGwyKKoHFmk0mugn4hTJ5TfLRfvQNRqNJuIE3RnKwCI9l4tGo+kARJwi+R/6b6YtHuah/zooqtFo2hERJ+h+h/5rH7pGo9FEnqA3muViO9wjRbWFrtFo2g9BKZ0QYroQYr0QYpMQ4rZGjjtDCCGFEKPCV0RvPEP/LRv1fOgajUbTtKALIezAM8AMoAA4VwhR4Oe4VOB64IdwF9JKu5ptUfvQNRpNOyIYpRsDbJJSbpFS1gFvAKf6Oe5e4EGgJozla0BIsy3quVw0Gk0HIBhB7w78anm/09jmRggxEughpfyosS8SQswRQhQKIQqLioqaXVgIMPRfz7ao0Wg0LQ+KCiFswGPATU0dK6WcK6UcJaUclZOTE9LveUaKNmNgUav50LWFrtFo2g/BCPouoIflfZ6xzSQVGAJ8KYTYBowF5rVWYNRvlosrQFC0qWl1W4q20DUaTTsiGEVaBvQXQvQWQsQB5wDzzJ1SylIpZbaUMl9KmQ8sAWZJKQtbo8CuULJc9MAijUbTAWhS0KWUDuAaYAGwFnhLSrlaCHGPEGJWaxfQF79D/7UPXaPRaIgJ5iAp5Xxgvs+2OwMcO7nlxQpMo1kuAX3orYT2oWs0mnZExJmY/rNcmnK5aAtdo9FEPxGnSH4tdD2wSKPRaCJX0P1b6Id7YFHEXT6NRhPFRJwimZmIfheJ1i4XjUbTgYk4RXL6XYKuidkW9cAijUbTAQgqy6U9ccn4fM47uieJsRb3SkAfemsPLNKCrtFo2g8RJ+jxMXbiY3x85W3lQ9doNJp2RMS5XPzSVgOLNBqNph0RHUp3uCfnOvKs8H6fRqPRhIHoEPTDnYd++nPw593h/U6NRqNpIdEh6E3NqhhuH7rNDnHJ4f1OjUajaSFRIuhtNduiRqPRtB+iRNCbcLnoIfoajaYDECWC3kRQVGe5aDSaDkB0KF2TQVFtoWs0mugnOgS9qYFF2uWi0Wg6AFEi6NpC12g0msgX9Poa+OI+9fpwr1ik0Wg07YjIF/RdP3pe6+CnRqPpwES+ApZZRmz6ulZ+Mxe6DoWYxMNbJo1Go2kDIm62xQaU7Qq8b9Ap6k+j0Wg6AJFvoZfvaesSaDQaTbsg8gW9MQtdo9FoOhBRIOh61kONRqMBLegajUYTNUS2oDsdULGvrUuh0Wg07YLIFvSKfZ5h/xqNRtPBiey0RdPd0vtYZa1rNBpNBybCBd3IcJn2V+h6ZNuWRaPRaNqYyHa5VBap/yld2rYcGo1G0w6IbEGvr1b/Y/XQfo1Go4lsl4ujRv3Xc7Voopz6+np27txJTU1NWxdFc5hISEggLy+P2NjYoD8T2YJeXw22GLBH9mloNE2xc+dOUlNTyc/PR+j5/aMeKSXFxcXs3LmT3r17B/25yHa5OGohJqGtS6HRtDo1NTVkZWVpMe8gCCHIyspqdo8sKEEXQkwXQqwXQmwSQtzmZ/+NQog1QoiVQoiFQohezSpFqDiqtaBrOgxazDsWodzvJgVdCGEHngFmAAXAuUKIDJSFkAAADnBJREFUAp/DlgOjpJRDgbeBh5pdklCor9EBUY1GozEIxkIfA2ySUm6RUtYBbwCnWg+QUi6SUlYZb5cAeeEtZgC0ha7RaDRughH07sCvlvc7jW2BuBT42N8OIcQcIUShEKKwqKgo+FIGor4GYrWgazStjd1uZ/jw4QwePJhhw4bx6KOP4nIdnmk3XnnlFWw2GytXrnRvGzJkCNu2bWv0c0888QRVVVXu97fffjs9evQgJSXF67jHHnuMgoIChg4dypQpU9i+fbt73/Tp08nIyGDmzJnhOZlWJqzpIUKIC4BRwCR/+6WUc4G5AKNGjZIt/kFHjbbQNR2Ouz9YzZrdZWH9zoLcNP5yyuCA+xMTE/n5558B2L9/P+eddx5lZWXcfffdYS1HIPLy8rj//vt58803g/7ME088wQUXXEBSUhIAp5xyCtdccw39+/f3Om7EiBEUFhaSlJTEs88+y6233ur+nVtuuYWqqiqef/758J1MKxKMhb4L6GF5n2ds80IIMRW4HZglpawNT/GaQAu6RnPY6dy5M3PnzuXpp59GSonT6eSWW25h9OjRDB061C1+X375JZMnT+bMM89k4MCBnH/++Uip7LjbbrvNbRXffPPNABQVFXHGGWcwevRoRo8ezbfffuv+zZkzZ7J69WrWr1/foDyffvop48aNY+TIkcyePZuKigqefPJJdu/ezXHHHcdxxx0HwNixY+nWrVuDzx933HFu0R87diw7d+5075syZQqpqalBXZd77rmH0aNHM2TIEObMmeM+102bNjF16lSGDRvGyJEj2bx5MwAPPvggRx55JMOGDeO22xrkmoSGlLLRP5QVvwXoDcQBK4DBPseMADYD/Zv6PvPvqKOOki3muWOl/NeZLf8ejaads2bNmjb9/eTk5Abb0tPT5d69e+Xzzz8v7733XimllDU1NfKoo46SW7ZskYsWLZJpaWny119/lU6nU44dO1Z+/fXX8sCBA3LAgAHS5XJJKaU8ePCglFLKc889V3799ddSSim3b98uBw4cKKWU8uWXX5ZXX321fPXVV+WFF14opZRy8ODBcuvWrbKoqEhOnDhRVlRUSCmlfOCBB+Tdd98tpZSyV69esqioKKhzMbn66qvd52KyaNEiefLJJzd5jYqLi92vL7jgAjlv3jwppZRjxoyR//vf/6SUUlZXV8vKyko5f/58OW7cOFlZWdngs1b83XegUAbQ1SZdLlJKhxDiGmABYAf+IaVcLYS4x/jiecDDQArwXyPVZoeUclZ4mpxG0Ba6RtPmfPrpp6xcuZK3334bgNLSUjZu3EhcXBxjxowhL0/lSAwfPpxt27YxduxYEhISuPTSS5k5c6bbP/3555+zZs0a9/eWlZVRUVHhfn/eeedx//33s3XrVve2JUuWsGbNGsaPHw9AXV0d48aNC+k8/vWvf1FYWMjixYtD+vyiRYt46KGHqKqqoqSkhMGDBzN58mR27drF6aefDqjRn6DO9ZJLLnH3DDIzM0P6TV+C8qFLKecD83223Wl5PTUspWku9TrLRaNpC7Zs2YLdbqdz585IKXnqqaeYNm2a1zFffvkl8fHx7vd2ux2Hw0FMTAxLly5l4cKFvP322zz99NN88cUXuFwulixZ4hY9X2JiYrjpppt48MEH3duklJxwwgm8/vrrLTqfzz//nPvvv5/Fixd7lTlYampquOqqqygsLKRHjx7cddddbTJNQ4SPFNVZLhrN4aaoqIjf//73XHPNNQghmDZtGs8++yz19fUAbNiwgcrKyoCfr6iooLS0lJNOOonHH3+cFStWAHDiiSfy1FNPuY8zg7BWLr74Yj7//HPMLLmxY8fy7bffsmnTJgAqKyvZsGEDAKmpqZSXlzd5PsuXL+eKK65g3rx5dO7cOcir4I0p3tnZ2VRUVLh7K6mpqeTl5fHee+8BUFtbS1VVFSeccAIvv/yyOwunpKQkpN/1JfIFXU/MpdG0OtXV1e60xalTp3LiiSfyl7/8BYDLLruMgoICRo4cyZAhQ7jiiitwOAIvOFNeXs7MmTMZOnQoEyZM4LHHHgPgySefpLCwkKFDh1JQUMBzzz3X4LNxcXFcd9117N+/H4CcnBxeeeUVzj33XIYOHcq4ceNYt24dAHPmzGH69OnuoOitt95KXl4eVVVV5OXlcddddwEqk6WiooLZs2czfPhwZs3yeIsnTpzI7NmzWbhwIXl5eSxYsMDvOWVkZHD55ZczZMgQpk2bxujRo937XnvtNZ588kmGDh3KMcccw969e5k+fTqzZs1i1KhRDB8+nEceeSTYW9EoQsqWZw+GwqhRo2RhYWHLvuTezjD293DCPeEplEbTTlm7di2DBg1q62JoDjP+7rsQ4kcp5Sh/x0euhe5ygbNWW+gajUZjELnzzlYdUP+TwhMd1mg0mmA4/fTTvTJtQOWU+waF24LIFfSDxvDcjMMzsaNGo9EAvPvuu21dhIBErsvlkCnoPdu2HBqNRtNO0IKu0Wg0UUIEC/oOSMyE+JSmj9VoNJoOQOQKeuUBSO3a1qXQaDSadkPkCnr1QUjs1Nal0Gg6BHo+9PDPhz558mRaPBbHh8jNcqk+CJl92roUGs3h5+PbYO+q8H5n1yNhxgMBd+v50KNnPvT2haMWDmwyLPSMti6NRtPh0POhN+STTz5h9uzZ7vdffvml26q/8sorGTVqFIMHD3ZPl9BaRJ6F/u2TsOg+9TpRDyrSdEAasaQPF3369MHpdLJ//37ef/990tPTWbZsGbW1tYwfP54TTzwRUBNfrV69mtzcXMaPH8+3337LoEGDePfdd1m3bh1CCA4dOgTA9ddfzw033MCECRPYsWMH06ZNY+3atQDYbDZuvfVW/vrXv/Lqq6+6y3HgwAHuu+8+Pv/8c5KTk3nwwQd57LHHuPPOO3nsscdYtGgR2dnZQZ/XSy+9xIwZM5p9PaZOncqcOXOorKwkOTmZN998k3POOQeA+++/n8zMTJxOJ1OmTGHlypUMHTq02b8RDJEn6Jm9Pa+1D12jaXP0fOhqat/p06fzwQcfcOaZZ/LRRx/x0EMPAfDWW28xd+5cHA4He/bsYc2aNVrQ3WT19bzWgq7RtAl6PvSGnHPOOTz99NNkZmYyatQoUlNT2bp1K4888gjLli2jU6dOXHzxxa06T3rk+dA7aQtdo2lL9Hzo/pk0aRI//fQTL7zwgtvdUlZWRnJyMunp6ezbt4+PP/445O8PhsgTdGsg1Op+0Wg0rYaeD73x+dBB9UBmzpzJxx9/7HYjDRs2jBEjRjBw4EDOO+88t2uotYjM+dB/fh1i4mDIGeEtlEbTTtHzoXdMmjsfeuT50AGGn9vWJdBoNJp2R2QKukaj0bQRej50jUbTYqSUCCHauhgdnsM1H3oo7vDIC4pqNB2QhIQEiouLQ3rINZGHlJLi4uKAKZyB0Ba6RhMB5OXlsXPnTne6nib6SUhIcA/KChYt6BpNBBAbG0vv3jpNV9M42uWi0Wg0UYIWdI1Go4kStKBrNBpNlNBmI0WFEEXA9iYP9E82cCCMxYkE9Dl3DPQ5dwxacs69pJQ5/na0maC3BCFEYaChr9GKPueOgT7njkFrnbN2uWg0Gk2UoAVdo9FoooRIFfS5bV2ANkCfc8dAn3PHoFXOOSJ96BqNRqNpSKRa6BqNRqPxQQu6RqPRRAkRJ+hCiOlCiPVCiE1CiNvaujzhQgjxDyHEfiHEL5ZtmUKIz4QQG43/nYztQgjxpHENVgohRrZdyUNHCNFDCLFICLFGCLFaCHG9sT1qz1sIkSCEWCqEWGGc893G9t5CiB+Mc3tTCBFnbI833m8y9ue3ZflDRQhhF0IsF0J8aLyP6vMFEEJsE0KsEkL8LIQoNLa1at2OKEEXQtiBZ4AZQAFwrhCioG1LFTZeAab7bLsNWCil7A8sNN6DOv/+xt8c4NnDVMZw4wBuklIWAGOBq437Gc3nXQscL6UcBgwHpgshxgIPAo9LKfsBB4FLjeMvBQ4a2x83jotErgfWWt5H+/maHCelHG7JOW/dui2ljJg/YBywwPL+T8Cf2rpcYTy/fOAXy/v1QDfjdTdgvfH6eeBcf8dF8h/wPnBCRzlvIAn4CTgaNWowxtjurufAAmCc8TrGOE60ddmbeZ55hngdD3wIiGg+X8t5bwOyfba1at2OKAsd6A78anm/09gWrXSRUu4xXu8Fuhivo+46GF3rEcAPRPl5G+6Hn4H9wGfAZuCQlNJhHGI9L/c5G/tLgazDW+IW8wRwK+Ay3mcR3edrIoFPhRA/CiHmGNtatW7r+dAjBCmlFEJEZY6pECIFeAf4g5SyzLrMWjSet5TSCQwXQmQA7wID27hIrYYQYiawX0r5oxBicluX5zAzQUq5SwjRGfhMCLHOurM16nakWei7gB6W93nGtmhlnxCiG4Dxf7+xPWqugxAiFiXm/5ZS/s/YHPXnDSClPAQsQrkcMoQQpoFlPS/3ORv704Hiw1zUljAemCWE2Aa8gXK7/I3oPV83Uspdxv/9qIZ7DK1ctyNN0JcB/Y0IeRxwDjCvjcvUmswDLjJeX4TyMZvbLzQi42OBUks3LmIQyhR/CVgrpXzMsitqz1sIkWNY5gghElExg7UoYT/TOMz3nM1rcSbwhTScrJGAlPJPUso8KWU+6nn9Qkp5PlF6viZCiGQhRKr5GjgR+IXWrtttHTgIIdBwErAB5Xe8va3LE8bzeh3YA9Sj/GeXonyHC4GNwOdApnGsQGX7bAZWAaPauvwhnvMElJ9xJfCz8XdSNJ83MBRYbpzzL8CdxvY+wFJgE/BfIN7YnmC832Ts79PW59CCc58MfNgRztc4vxXG32pTq1q7buuh/xqNRhMlRJrLRaPRaDQB0IKu0Wg0UYIWdI1Go4kStKBrNBpNlKAFXaPRaKIELegajUYTJWhB12g0mijh/wMkBR3ONCt6xQAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1629939966354,"user_tz":-540,"elapsed":21043,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_000_5_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1629939967175,"user_tz":-540,"elapsed":828,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629939967594,"user_tz":-540,"elapsed":424,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"2f67b168-6726-4990-d67c-a92e04fdcd8a"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Found 20480 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629939999478,"user_tz":-540,"elapsed":31888,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d4a9b2eb-76c2-4185-993a-de8c3c068407"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1629939999483,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1629939999483,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1629940001284,"user_tz":-540,"elapsed":1807,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1629940001285,"user_tz":-540,"elapsed":8,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1629940016385,"user_tz":-540,"elapsed":15107,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1629940016386,"user_tz":-540,"elapsed":26,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"94441939-b089-4f30-c5a6-33e042bec749"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1629940016387,"user_tz":-540,"elapsed":21,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"00cce8e6-176a-4025-c843-a0f4102c0488"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_000_5_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_000_5_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_150a9f88-9b61-4f27-af5b-8267fc3d99bd\", \"WidthShiftRange_000_5_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}