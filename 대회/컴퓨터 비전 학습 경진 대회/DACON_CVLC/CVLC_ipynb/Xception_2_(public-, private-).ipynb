{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1633012659973,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"},"user_tz":-540},"id":"g0yI4jO4W5lx","outputId":"34946376-a1c4-4f2a-9e7d-f4ceffb938a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Sep 30 14:37:46 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18341,"status":"ok","timestamp":1633012678310,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"},"user_tz":-540},"id":"LmEaPJckuX-D","outputId":"de696397-3e57-4ee5-f9f5-d71edd3c8d41"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4014,"status":"ok","timestamp":1633012682710,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"},"user_tz":-540},"id":"88GAtllsufPj"},"outputs":[],"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1136,"status":"ok","timestamp":1633012683837,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"},"user_tz":-540},"id":"8qBWziyZrqBo"},"outputs":[],"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2839,"status":"ok","timestamp":1633012686672,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"},"user_tz":-540},"id":"3fjN8mIDrazg"},"outputs":[],"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":20239,"status":"ok","timestamp":1633012706909,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"},"user_tz":-540},"id":"k4P9AD1gyotc"},"outputs":[],"source":["for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1633012706912,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"},"user_tz":-540},"id":"BTkw3fo6icZm"},"outputs":[],"source":["model_save = 'Xception_2'\n","Target_model = 'Xception_model'\n","Target_predict = 'Xception_predict'\n","Target_acc = 'Xception_acc'\n","Target_val = 'Xception_val'"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6338,"status":"ok","timestamp":1633012713234,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"},"user_tz":-540},"id":"HUJTlJ6GxNmK"},"outputs":[],"source":["import tensorflow as tf\n","Target_model =  tf.keras.applications.Xception(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1633012713236,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"},"user_tz":-540},"id":"KlVMd30ZxUMQ"},"outputs":[],"source":["Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":425,"status":"ok","timestamp":1633012713643,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"},"user_tz":-540},"id":"w1haI0Zjxa74","outputId":"e94880d6-f686-4e82-b49a-6af6a0121cbc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1900 images belonging to 10 classes.\n","Found 148 images belonging to 10 classes.\n"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator (\n","    rescale = 1./255, \n","    validation_split = 0.075,\n","    rotation_range = 15,\n","    width_shift_range = 0.00,\n","    height_shift_range = 0.05 )\n","\n","batch_size = 8\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1633012713644,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"},"user_tz":-540},"id":"SRP2R9hdxsyY"},"outputs":[],"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"DKMJhbFnxotA"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/500\n","238/238 [==============================] - 53s 127ms/step - loss: 1.7685 - accuracy: 0.3989 - val_loss: 2.3680 - val_accuracy: 0.1014\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_2.h5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/500\n","238/238 [==============================] - 29s 122ms/step - loss: 1.0256 - accuracy: 0.6532 - val_loss: 5.5763 - val_accuracy: 0.1419\n","\n","Epoch 00002: val_accuracy improved from 0.10135 to 0.14189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_2.h5\n","Epoch 3/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.8051 - accuracy: 0.7395 - val_loss: 1.7374 - val_accuracy: 0.6486\n","\n","Epoch 00003: val_accuracy improved from 0.14189 to 0.64865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_2.h5\n","Epoch 4/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.7280 - accuracy: 0.7605 - val_loss: 1.3703 - val_accuracy: 0.7162\n","\n","Epoch 00004: val_accuracy improved from 0.64865 to 0.71622, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_2.h5\n","Epoch 5/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.5750 - accuracy: 0.8116 - val_loss: 0.3651 - val_accuracy: 0.8446\n","\n","Epoch 00005: val_accuracy improved from 0.71622 to 0.84459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_2.h5\n","Epoch 6/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.5454 - accuracy: 0.8263 - val_loss: 0.7439 - val_accuracy: 0.7770\n","\n","Epoch 00006: val_accuracy did not improve from 0.84459\n","Epoch 7/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.5351 - accuracy: 0.8179 - val_loss: 1.0489 - val_accuracy: 0.7365\n","\n","Epoch 00007: val_accuracy did not improve from 0.84459\n","Epoch 8/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.4533 - accuracy: 0.8574 - val_loss: 1.3737 - val_accuracy: 0.6081\n","\n","Epoch 00008: val_accuracy did not improve from 0.84459\n","Epoch 9/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.4645 - accuracy: 0.8453 - val_loss: 0.7012 - val_accuracy: 0.8041\n","\n","Epoch 00009: val_accuracy did not improve from 0.84459\n","Epoch 10/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.3933 - accuracy: 0.8742 - val_loss: 0.7194 - val_accuracy: 0.7838\n","\n","Epoch 00010: val_accuracy did not improve from 0.84459\n","Epoch 11/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.4134 - accuracy: 0.8705 - val_loss: 0.7053 - val_accuracy: 0.8176\n","\n","Epoch 00011: val_accuracy did not improve from 0.84459\n","Epoch 12/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.3581 - accuracy: 0.8805 - val_loss: 0.5146 - val_accuracy: 0.8581\n","\n","Epoch 00012: val_accuracy improved from 0.84459 to 0.85811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_2.h5\n","Epoch 13/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.3138 - accuracy: 0.8989 - val_loss: 0.6744 - val_accuracy: 0.8243\n","\n","Epoch 00013: val_accuracy did not improve from 0.85811\n","Epoch 14/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.3129 - accuracy: 0.9005 - val_loss: 1.9112 - val_accuracy: 0.5541\n","\n","Epoch 00014: val_accuracy did not improve from 0.85811\n","Epoch 15/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.3255 - accuracy: 0.9037 - val_loss: 0.4336 - val_accuracy: 0.8581\n","\n","Epoch 00015: val_accuracy did not improve from 0.85811\n","Epoch 16/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.2995 - accuracy: 0.9079 - val_loss: 1.7243 - val_accuracy: 0.5946\n","\n","Epoch 00016: val_accuracy did not improve from 0.85811\n","Epoch 17/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.2726 - accuracy: 0.9100 - val_loss: 0.3313 - val_accuracy: 0.8919\n","\n","Epoch 00017: val_accuracy improved from 0.85811 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_2.h5\n","Epoch 18/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.2282 - accuracy: 0.9300 - val_loss: 0.8416 - val_accuracy: 0.8176\n","\n","Epoch 00018: val_accuracy did not improve from 0.89189\n","Epoch 19/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.2814 - accuracy: 0.9021 - val_loss: 0.6052 - val_accuracy: 0.8649\n","\n","Epoch 00019: val_accuracy did not improve from 0.89189\n","Epoch 20/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.2056 - accuracy: 0.9311 - val_loss: 0.7385 - val_accuracy: 0.8108\n","\n","Epoch 00020: val_accuracy did not improve from 0.89189\n","Epoch 21/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.2053 - accuracy: 0.9311 - val_loss: 0.9293 - val_accuracy: 0.7973\n","\n","Epoch 00021: val_accuracy did not improve from 0.89189\n","Epoch 22/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.2366 - accuracy: 0.9221 - val_loss: 0.2768 - val_accuracy: 0.9189\n","\n","Epoch 00022: val_accuracy improved from 0.89189 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_2.h5\n","Epoch 23/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1870 - accuracy: 0.9374 - val_loss: 2.2381 - val_accuracy: 0.6284\n","\n","Epoch 00023: val_accuracy did not improve from 0.91892\n","Epoch 24/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.2129 - accuracy: 0.9305 - val_loss: 0.5831 - val_accuracy: 0.8446\n","\n","Epoch 00024: val_accuracy did not improve from 0.91892\n","Epoch 25/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.2264 - accuracy: 0.9242 - val_loss: 0.5689 - val_accuracy: 0.8581\n","\n","Epoch 00025: val_accuracy did not improve from 0.91892\n","Epoch 26/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.2205 - accuracy: 0.9300 - val_loss: 0.4800 - val_accuracy: 0.8581\n","\n","Epoch 00026: val_accuracy did not improve from 0.91892\n","Epoch 27/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1355 - accuracy: 0.9537 - val_loss: 0.5420 - val_accuracy: 0.8581\n","\n","Epoch 00027: val_accuracy did not improve from 0.91892\n","Epoch 28/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1684 - accuracy: 0.9426 - val_loss: 0.4951 - val_accuracy: 0.8581\n","\n","Epoch 00028: val_accuracy did not improve from 0.91892\n","Epoch 29/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1519 - accuracy: 0.9468 - val_loss: 0.7951 - val_accuracy: 0.8176\n","\n","Epoch 00029: val_accuracy did not improve from 0.91892\n","Epoch 30/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1647 - accuracy: 0.9468 - val_loss: 0.9135 - val_accuracy: 0.8311\n","\n","Epoch 00030: val_accuracy did not improve from 0.91892\n","Epoch 31/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1268 - accuracy: 0.9579 - val_loss: 1.1370 - val_accuracy: 0.7838\n","\n","Epoch 00031: val_accuracy did not improve from 0.91892\n","Epoch 32/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1409 - accuracy: 0.9521 - val_loss: 0.3425 - val_accuracy: 0.9054\n","\n","Epoch 00032: val_accuracy did not improve from 0.91892\n","Epoch 33/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1237 - accuracy: 0.9563 - val_loss: 0.6565 - val_accuracy: 0.8378\n","\n","Epoch 00033: val_accuracy did not improve from 0.91892\n","Epoch 34/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1036 - accuracy: 0.9663 - val_loss: 0.7323 - val_accuracy: 0.8041\n","\n","Epoch 00034: val_accuracy did not improve from 0.91892\n","Epoch 35/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1566 - accuracy: 0.9500 - val_loss: 0.4815 - val_accuracy: 0.8784\n","\n","Epoch 00035: val_accuracy did not improve from 0.91892\n","Epoch 36/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1105 - accuracy: 0.9642 - val_loss: 0.4832 - val_accuracy: 0.8851\n","\n","Epoch 00036: val_accuracy did not improve from 0.91892\n","Epoch 37/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1221 - accuracy: 0.9563 - val_loss: 0.4762 - val_accuracy: 0.8716\n","\n","Epoch 00037: val_accuracy did not improve from 0.91892\n","Epoch 38/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1114 - accuracy: 0.9674 - val_loss: 0.7087 - val_accuracy: 0.8581\n","\n","Epoch 00038: val_accuracy did not improve from 0.91892\n","Epoch 39/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1012 - accuracy: 0.9626 - val_loss: 0.5572 - val_accuracy: 0.8446\n","\n","Epoch 00039: val_accuracy did not improve from 0.91892\n","Epoch 40/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1074 - accuracy: 0.9658 - val_loss: 0.4122 - val_accuracy: 0.9054\n","\n","Epoch 00040: val_accuracy did not improve from 0.91892\n","Epoch 41/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0753 - accuracy: 0.9763 - val_loss: 0.4617 - val_accuracy: 0.8716\n","\n","Epoch 00041: val_accuracy did not improve from 0.91892\n","Epoch 42/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1147 - accuracy: 0.9626 - val_loss: 0.6548 - val_accuracy: 0.8378\n","\n","Epoch 00042: val_accuracy did not improve from 0.91892\n","Epoch 43/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0982 - accuracy: 0.9711 - val_loss: 0.7231 - val_accuracy: 0.8446\n","\n","Epoch 00043: val_accuracy did not improve from 0.91892\n","Epoch 44/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1036 - accuracy: 0.9658 - val_loss: 0.4030 - val_accuracy: 0.8851\n","\n","Epoch 00044: val_accuracy did not improve from 0.91892\n","Epoch 45/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0940 - accuracy: 0.9674 - val_loss: 0.5312 - val_accuracy: 0.8716\n","\n","Epoch 00045: val_accuracy did not improve from 0.91892\n","Epoch 46/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1009 - accuracy: 0.9658 - val_loss: 0.5743 - val_accuracy: 0.8784\n","\n","Epoch 00046: val_accuracy did not improve from 0.91892\n","Epoch 47/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0643 - accuracy: 0.9732 - val_loss: 0.3910 - val_accuracy: 0.8919\n","\n","Epoch 00047: val_accuracy did not improve from 0.91892\n","Epoch 48/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0947 - accuracy: 0.9653 - val_loss: 0.5130 - val_accuracy: 0.8986\n","\n","Epoch 00048: val_accuracy did not improve from 0.91892\n","Epoch 49/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0919 - accuracy: 0.9700 - val_loss: 0.5461 - val_accuracy: 0.8716\n","\n","Epoch 00049: val_accuracy did not improve from 0.91892\n","Epoch 50/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.1012 - accuracy: 0.9658 - val_loss: 0.9294 - val_accuracy: 0.8176\n","\n","Epoch 00050: val_accuracy did not improve from 0.91892\n","Epoch 51/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0892 - accuracy: 0.9732 - val_loss: 0.3386 - val_accuracy: 0.9054\n","\n","Epoch 00051: val_accuracy did not improve from 0.91892\n","Epoch 52/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0830 - accuracy: 0.9711 - val_loss: 1.2559 - val_accuracy: 0.7568\n","\n","Epoch 00052: val_accuracy did not improve from 0.91892\n","Epoch 53/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0572 - accuracy: 0.9805 - val_loss: 0.6959 - val_accuracy: 0.8716\n","\n","Epoch 00053: val_accuracy did not improve from 0.91892\n","Epoch 54/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0799 - accuracy: 0.9721 - val_loss: 0.3250 - val_accuracy: 0.9054\n","\n","Epoch 00054: val_accuracy did not improve from 0.91892\n","Epoch 55/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0816 - accuracy: 0.9732 - val_loss: 0.3805 - val_accuracy: 0.9257\n","\n","Epoch 00055: val_accuracy improved from 0.91892 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_2.h5\n","Epoch 56/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0699 - accuracy: 0.9763 - val_loss: 0.4140 - val_accuracy: 0.8716\n","\n","Epoch 00056: val_accuracy did not improve from 0.92568\n","Epoch 57/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0506 - accuracy: 0.9837 - val_loss: 0.3110 - val_accuracy: 0.8851\n","\n","Epoch 00057: val_accuracy did not improve from 0.92568\n","Epoch 58/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0669 - accuracy: 0.9763 - val_loss: 0.4329 - val_accuracy: 0.8784\n","\n","Epoch 00058: val_accuracy did not improve from 0.92568\n","Epoch 59/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0482 - accuracy: 0.9784 - val_loss: 0.3688 - val_accuracy: 0.8986\n","\n","Epoch 00059: val_accuracy did not improve from 0.92568\n","Epoch 60/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0542 - accuracy: 0.9811 - val_loss: 0.6706 - val_accuracy: 0.8649\n","\n","Epoch 00060: val_accuracy did not improve from 0.92568\n","Epoch 61/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0849 - accuracy: 0.9711 - val_loss: 0.5458 - val_accuracy: 0.8986\n","\n","Epoch 00061: val_accuracy did not improve from 0.92568\n","Epoch 62/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.3376 - val_accuracy: 0.9122\n","\n","Epoch 00062: val_accuracy did not improve from 0.92568\n","Epoch 63/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0565 - accuracy: 0.9805 - val_loss: 0.4813 - val_accuracy: 0.8716\n","\n","Epoch 00063: val_accuracy did not improve from 0.92568\n","Epoch 64/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0346 - accuracy: 0.9874 - val_loss: 0.4399 - val_accuracy: 0.8919\n","\n","Epoch 00064: val_accuracy did not improve from 0.92568\n","Epoch 65/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0524 - accuracy: 0.9858 - val_loss: 0.2921 - val_accuracy: 0.9054\n","\n","Epoch 00065: val_accuracy did not improve from 0.92568\n","Epoch 66/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0519 - accuracy: 0.9832 - val_loss: 0.8103 - val_accuracy: 0.8176\n","\n","Epoch 00066: val_accuracy did not improve from 0.92568\n","Epoch 67/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0944 - accuracy: 0.9737 - val_loss: 0.4027 - val_accuracy: 0.8986\n","\n","Epoch 00067: val_accuracy did not improve from 0.92568\n","Epoch 68/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0384 - accuracy: 0.9879 - val_loss: 0.4560 - val_accuracy: 0.8919\n","\n","Epoch 00068: val_accuracy did not improve from 0.92568\n","Epoch 69/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0418 - accuracy: 0.9868 - val_loss: 0.4992 - val_accuracy: 0.8851\n","\n","Epoch 00069: val_accuracy did not improve from 0.92568\n","Epoch 70/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0644 - accuracy: 0.9789 - val_loss: 0.5056 - val_accuracy: 0.8919\n","\n","Epoch 00070: val_accuracy did not improve from 0.92568\n","Epoch 71/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0361 - accuracy: 0.9889 - val_loss: 0.4413 - val_accuracy: 0.8851\n","\n","Epoch 00071: val_accuracy did not improve from 0.92568\n","Epoch 72/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0476 - accuracy: 0.9811 - val_loss: 0.9925 - val_accuracy: 0.8378\n","\n","Epoch 00072: val_accuracy did not improve from 0.92568\n","Epoch 73/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0448 - accuracy: 0.9853 - val_loss: 0.5998 - val_accuracy: 0.8851\n","\n","Epoch 00073: val_accuracy did not improve from 0.92568\n","Epoch 74/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0751 - accuracy: 0.9726 - val_loss: 0.6155 - val_accuracy: 0.8514\n","\n","Epoch 00074: val_accuracy did not improve from 0.92568\n","Epoch 75/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0637 - accuracy: 0.9821 - val_loss: 0.4487 - val_accuracy: 0.8851\n","\n","Epoch 00075: val_accuracy did not improve from 0.92568\n","Epoch 76/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.4026 - val_accuracy: 0.9189\n","\n","Epoch 00076: val_accuracy did not improve from 0.92568\n","Epoch 77/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.3384 - val_accuracy: 0.9054\n","\n","Epoch 00077: val_accuracy did not improve from 0.92568\n","Epoch 78/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0494 - accuracy: 0.9858 - val_loss: 0.7735 - val_accuracy: 0.8311\n","\n","Epoch 00078: val_accuracy did not improve from 0.92568\n","Epoch 79/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0661 - accuracy: 0.9811 - val_loss: 0.3117 - val_accuracy: 0.9122\n","\n","Epoch 00079: val_accuracy did not improve from 0.92568\n","Epoch 80/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0413 - accuracy: 0.9874 - val_loss: 0.4028 - val_accuracy: 0.8716\n","\n","Epoch 00080: val_accuracy did not improve from 0.92568\n","Epoch 81/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.6657 - val_accuracy: 0.8851\n","\n","Epoch 00081: val_accuracy did not improve from 0.92568\n","Epoch 82/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0406 - accuracy: 0.9858 - val_loss: 0.4396 - val_accuracy: 0.8919\n","\n","Epoch 00082: val_accuracy did not improve from 0.92568\n","Epoch 83/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0345 - accuracy: 0.9895 - val_loss: 0.3957 - val_accuracy: 0.9189\n","\n","Epoch 00083: val_accuracy did not improve from 0.92568\n","Epoch 84/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.4746 - val_accuracy: 0.8716\n","\n","Epoch 00084: val_accuracy did not improve from 0.92568\n","Epoch 85/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0707 - accuracy: 0.9768 - val_loss: 0.6597 - val_accuracy: 0.8986\n","\n","Epoch 00085: val_accuracy did not improve from 0.92568\n","Epoch 86/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0336 - accuracy: 0.9911 - val_loss: 0.4415 - val_accuracy: 0.8919\n","\n","Epoch 00086: val_accuracy did not improve from 0.92568\n","Epoch 87/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0534 - accuracy: 0.9837 - val_loss: 0.6022 - val_accuracy: 0.8784\n","\n","Epoch 00087: val_accuracy did not improve from 0.92568\n","Epoch 88/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0511 - accuracy: 0.9832 - val_loss: 0.3988 - val_accuracy: 0.9122\n","\n","Epoch 00088: val_accuracy did not improve from 0.92568\n","Epoch 89/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0511 - accuracy: 0.9826 - val_loss: 0.4925 - val_accuracy: 0.9054\n","\n","Epoch 00089: val_accuracy did not improve from 0.92568\n","Epoch 90/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0350 - accuracy: 0.9895 - val_loss: 0.4865 - val_accuracy: 0.8851\n","\n","Epoch 00090: val_accuracy did not improve from 0.92568\n","Epoch 91/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0520 - accuracy: 0.9837 - val_loss: 0.4807 - val_accuracy: 0.8986\n","\n","Epoch 00091: val_accuracy did not improve from 0.92568\n","Epoch 92/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0257 - accuracy: 0.9932 - val_loss: 0.4704 - val_accuracy: 0.8986\n","\n","Epoch 00092: val_accuracy did not improve from 0.92568\n","Epoch 93/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0156 - accuracy: 0.9921 - val_loss: 0.2784 - val_accuracy: 0.9189\n","\n","Epoch 00093: val_accuracy did not improve from 0.92568\n","Epoch 94/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0315 - accuracy: 0.9879 - val_loss: 0.4155 - val_accuracy: 0.9054\n","\n","Epoch 00094: val_accuracy did not improve from 0.92568\n","Epoch 95/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0371 - accuracy: 0.9905 - val_loss: 0.2955 - val_accuracy: 0.9257\n","\n","Epoch 00095: val_accuracy did not improve from 0.92568\n","Epoch 96/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0387 - accuracy: 0.9863 - val_loss: 0.8595 - val_accuracy: 0.8851\n","\n","Epoch 00096: val_accuracy did not improve from 0.92568\n","Epoch 97/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0316 - accuracy: 0.9911 - val_loss: 0.3885 - val_accuracy: 0.8986\n","\n","Epoch 00097: val_accuracy did not improve from 0.92568\n","Epoch 98/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0149 - accuracy: 0.9932 - val_loss: 0.3818 - val_accuracy: 0.8986\n","\n","Epoch 00098: val_accuracy did not improve from 0.92568\n","Epoch 99/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 0.4960 - val_accuracy: 0.8851\n","\n","Epoch 00099: val_accuracy did not improve from 0.92568\n","Epoch 100/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0281 - accuracy: 0.9911 - val_loss: 0.9220 - val_accuracy: 0.8514\n","\n","Epoch 00100: val_accuracy did not improve from 0.92568\n","Epoch 101/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0821 - accuracy: 0.9763 - val_loss: 0.7898 - val_accuracy: 0.8784\n","\n","Epoch 00101: val_accuracy did not improve from 0.92568\n","Epoch 102/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0354 - accuracy: 0.9911 - val_loss: 0.3845 - val_accuracy: 0.9122\n","\n","Epoch 00102: val_accuracy did not improve from 0.92568\n","Epoch 103/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 0.4576 - val_accuracy: 0.9054\n","\n","Epoch 00103: val_accuracy did not improve from 0.92568\n","Epoch 104/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0238 - accuracy: 0.9911 - val_loss: 0.3753 - val_accuracy: 0.9189\n","\n","Epoch 00104: val_accuracy did not improve from 0.92568\n","Epoch 105/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0193 - accuracy: 0.9916 - val_loss: 0.4228 - val_accuracy: 0.9257\n","\n","Epoch 00105: val_accuracy did not improve from 0.92568\n","Epoch 106/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 0.4291 - val_accuracy: 0.9054\n","\n","Epoch 00106: val_accuracy did not improve from 0.92568\n","Epoch 107/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0300 - accuracy: 0.9916 - val_loss: 0.6400 - val_accuracy: 0.8716\n","\n","Epoch 00107: val_accuracy did not improve from 0.92568\n","Epoch 108/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0201 - accuracy: 0.9916 - val_loss: 0.5945 - val_accuracy: 0.8784\n","\n","Epoch 00108: val_accuracy did not improve from 0.92568\n","Epoch 109/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0192 - accuracy: 0.9921 - val_loss: 0.4354 - val_accuracy: 0.9122\n","\n","Epoch 00109: val_accuracy did not improve from 0.92568\n","Epoch 110/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.5862 - val_accuracy: 0.8919\n","\n","Epoch 00110: val_accuracy did not improve from 0.92568\n","Epoch 111/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0517 - accuracy: 0.9816 - val_loss: 0.5655 - val_accuracy: 0.8649\n","\n","Epoch 00111: val_accuracy did not improve from 0.92568\n","Epoch 112/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0520 - accuracy: 0.9847 - val_loss: 0.5878 - val_accuracy: 0.8716\n","\n","Epoch 00112: val_accuracy did not improve from 0.92568\n","Epoch 113/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 0.5424 - val_accuracy: 0.8919\n","\n","Epoch 00113: val_accuracy did not improve from 0.92568\n","Epoch 114/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.4181 - val_accuracy: 0.8986\n","\n","Epoch 00114: val_accuracy did not improve from 0.92568\n","Epoch 115/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0289 - accuracy: 0.9889 - val_loss: 0.3869 - val_accuracy: 0.8919\n","\n","Epoch 00115: val_accuracy did not improve from 0.92568\n","Epoch 116/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0096 - accuracy: 0.9984 - val_loss: 0.3360 - val_accuracy: 0.9257\n","\n","Epoch 00116: val_accuracy did not improve from 0.92568\n","Epoch 117/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.2519 - val_accuracy: 0.9257\n","\n","Epoch 00117: val_accuracy did not improve from 0.92568\n","Epoch 118/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.6693 - val_accuracy: 0.8581\n","\n","Epoch 00118: val_accuracy did not improve from 0.92568\n","Epoch 119/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0337 - accuracy: 0.9863 - val_loss: 1.1391 - val_accuracy: 0.7635\n","\n","Epoch 00119: val_accuracy did not improve from 0.92568\n","Epoch 120/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0295 - accuracy: 0.9911 - val_loss: 0.2843 - val_accuracy: 0.9189\n","\n","Epoch 00120: val_accuracy did not improve from 0.92568\n","Epoch 121/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.3808 - val_accuracy: 0.9189\n","\n","Epoch 00121: val_accuracy did not improve from 0.92568\n","Epoch 122/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.3719 - val_accuracy: 0.9122\n","\n","Epoch 00122: val_accuracy did not improve from 0.92568\n","Epoch 123/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.3501 - val_accuracy: 0.9122\n","\n","Epoch 00123: val_accuracy did not improve from 0.92568\n","Epoch 124/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.4224 - val_accuracy: 0.9189\n","\n","Epoch 00124: val_accuracy did not improve from 0.92568\n","Epoch 125/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0460 - accuracy: 0.9879 - val_loss: 1.3854 - val_accuracy: 0.7973\n","\n","Epoch 00125: val_accuracy did not improve from 0.92568\n","Epoch 126/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0215 - accuracy: 0.9911 - val_loss: 0.6462 - val_accuracy: 0.8581\n","\n","Epoch 00126: val_accuracy did not improve from 0.92568\n","Epoch 127/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0439 - accuracy: 0.9874 - val_loss: 0.8327 - val_accuracy: 0.8851\n","\n","Epoch 00127: val_accuracy did not improve from 0.92568\n","Epoch 128/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.2484 - val_accuracy: 0.9189\n","\n","Epoch 00128: val_accuracy did not improve from 0.92568\n","Epoch 129/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.4182 - val_accuracy: 0.8919\n","\n","Epoch 00129: val_accuracy did not improve from 0.92568\n","Epoch 130/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0229 - accuracy: 0.9953 - val_loss: 0.3082 - val_accuracy: 0.9392\n","\n","Epoch 00130: val_accuracy improved from 0.92568 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_2.h5\n","Epoch 131/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.4182 - val_accuracy: 0.9054\n","\n","Epoch 00131: val_accuracy did not improve from 0.93919\n","Epoch 132/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.3599 - val_accuracy: 0.9324\n","\n","Epoch 00132: val_accuracy did not improve from 0.93919\n","Epoch 133/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0485 - accuracy: 0.9853 - val_loss: 0.4973 - val_accuracy: 0.8986\n","\n","Epoch 00133: val_accuracy did not improve from 0.93919\n","Epoch 134/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.3237 - val_accuracy: 0.9054\n","\n","Epoch 00134: val_accuracy did not improve from 0.93919\n","Epoch 135/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0267 - accuracy: 0.9905 - val_loss: 0.7004 - val_accuracy: 0.8716\n","\n","Epoch 00135: val_accuracy did not improve from 0.93919\n","Epoch 136/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0295 - accuracy: 0.9911 - val_loss: 0.3933 - val_accuracy: 0.8986\n","\n","Epoch 00136: val_accuracy did not improve from 0.93919\n","Epoch 137/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.3819 - val_accuracy: 0.9054\n","\n","Epoch 00137: val_accuracy did not improve from 0.93919\n","Epoch 138/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.2976 - val_accuracy: 0.9257\n","\n","Epoch 00138: val_accuracy did not improve from 0.93919\n","Epoch 139/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.3897 - val_accuracy: 0.9122\n","\n","Epoch 00139: val_accuracy did not improve from 0.93919\n","Epoch 140/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.3214 - val_accuracy: 0.9459\n","\n","Epoch 00140: val_accuracy improved from 0.93919 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_2.h5\n","Epoch 141/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.3236 - val_accuracy: 0.9189\n","\n","Epoch 00141: val_accuracy did not improve from 0.94595\n","Epoch 142/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.6163 - val_accuracy: 0.8919\n","\n","Epoch 00142: val_accuracy did not improve from 0.94595\n","Epoch 143/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 0.4730 - val_accuracy: 0.8851\n","\n","Epoch 00143: val_accuracy did not improve from 0.94595\n","Epoch 144/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0267 - accuracy: 0.9905 - val_loss: 0.4037 - val_accuracy: 0.9122\n","\n","Epoch 00144: val_accuracy did not improve from 0.94595\n","Epoch 145/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.5909 - val_accuracy: 0.8919\n","\n","Epoch 00145: val_accuracy did not improve from 0.94595\n","Epoch 146/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.3852 - val_accuracy: 0.9324\n","\n","Epoch 00146: val_accuracy did not improve from 0.94595\n","Epoch 147/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9324\n","\n","Epoch 00147: val_accuracy did not improve from 0.94595\n","Epoch 148/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.2533 - val_accuracy: 0.9189\n","\n","Epoch 00148: val_accuracy did not improve from 0.94595\n","Epoch 149/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.3148 - val_accuracy: 0.9324\n","\n","Epoch 00149: val_accuracy did not improve from 0.94595\n","Epoch 150/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9459\n","\n","Epoch 00150: val_accuracy did not improve from 0.94595\n","Epoch 151/500\n","238/238 [==============================] - 29s 123ms/step - loss: 5.8173e-04 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9392\n","\n","Epoch 00151: val_accuracy did not improve from 0.94595\n","Epoch 152/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0233 - accuracy: 0.9932 - val_loss: 0.9035 - val_accuracy: 0.8378\n","\n","Epoch 00152: val_accuracy did not improve from 0.94595\n","Epoch 153/500\n","238/238 [==============================] - 30s 125ms/step - loss: 0.0437 - accuracy: 0.9842 - val_loss: 0.4778 - val_accuracy: 0.8851\n","\n","Epoch 00153: val_accuracy did not improve from 0.94595\n","Epoch 154/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0479 - accuracy: 0.9879 - val_loss: 0.4604 - val_accuracy: 0.8851\n","\n","Epoch 00154: val_accuracy did not improve from 0.94595\n","Epoch 155/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.2675 - val_accuracy: 0.9324\n","\n","Epoch 00155: val_accuracy did not improve from 0.94595\n","Epoch 156/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.3456 - val_accuracy: 0.9324\n","\n","Epoch 00156: val_accuracy did not improve from 0.94595\n","Epoch 157/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.5793 - val_accuracy: 0.8986\n","\n","Epoch 00157: val_accuracy did not improve from 0.94595\n","Epoch 158/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 0.8221 - val_accuracy: 0.8243\n","\n","Epoch 00158: val_accuracy did not improve from 0.94595\n","Epoch 159/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0344 - accuracy: 0.9911 - val_loss: 0.5329 - val_accuracy: 0.8784\n","\n","Epoch 00159: val_accuracy did not improve from 0.94595\n","Epoch 160/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0348 - accuracy: 0.9905 - val_loss: 0.4876 - val_accuracy: 0.8851\n","\n","Epoch 00160: val_accuracy did not improve from 0.94595\n","Epoch 161/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.5383 - val_accuracy: 0.9054\n","\n","Epoch 00161: val_accuracy did not improve from 0.94595\n","Epoch 162/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.3584 - val_accuracy: 0.9257\n","\n","Epoch 00162: val_accuracy did not improve from 0.94595\n","Epoch 163/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.3566 - val_accuracy: 0.9054\n","\n","Epoch 00163: val_accuracy did not improve from 0.94595\n","Epoch 164/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.4129 - val_accuracy: 0.9054\n","\n","Epoch 00164: val_accuracy did not improve from 0.94595\n","Epoch 165/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.3963 - val_accuracy: 0.9054\n","\n","Epoch 00165: val_accuracy did not improve from 0.94595\n","Epoch 166/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.2732 - val_accuracy: 0.9459\n","\n","Epoch 00166: val_accuracy did not improve from 0.94595\n","Epoch 167/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0259 - accuracy: 0.9947 - val_loss: 0.3054 - val_accuracy: 0.9257\n","\n","Epoch 00167: val_accuracy did not improve from 0.94595\n","Epoch 168/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.4544 - val_accuracy: 0.9324\n","\n","Epoch 00168: val_accuracy did not improve from 0.94595\n","Epoch 169/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0130 - accuracy: 0.9942 - val_loss: 0.4306 - val_accuracy: 0.9122\n","\n","Epoch 00169: val_accuracy did not improve from 0.94595\n","Epoch 170/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0083 - accuracy: 0.9958 - val_loss: 0.3808 - val_accuracy: 0.8784\n","\n","Epoch 00170: val_accuracy did not improve from 0.94595\n","Epoch 171/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.7243 - val_accuracy: 0.8581\n","\n","Epoch 00171: val_accuracy did not improve from 0.94595\n","Epoch 172/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.5249 - val_accuracy: 0.8986\n","\n","Epoch 00172: val_accuracy did not improve from 0.94595\n","Epoch 173/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.2469 - val_accuracy: 0.9392\n","\n","Epoch 00173: val_accuracy did not improve from 0.94595\n","Epoch 174/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0069 - accuracy: 0.9968 - val_loss: 0.5191 - val_accuracy: 0.8716\n","\n","Epoch 00174: val_accuracy did not improve from 0.94595\n","Epoch 175/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.8716 - val_accuracy: 0.8581\n","\n","Epoch 00175: val_accuracy did not improve from 0.94595\n","Epoch 176/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0395 - accuracy: 0.9884 - val_loss: 0.4058 - val_accuracy: 0.9189\n","\n","Epoch 00176: val_accuracy did not improve from 0.94595\n","Epoch 177/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0194 - accuracy: 0.9916 - val_loss: 0.4081 - val_accuracy: 0.8919\n","\n","Epoch 00177: val_accuracy did not improve from 0.94595\n","Epoch 178/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.1536 - val_accuracy: 0.9730\n","\n","Epoch 00178: val_accuracy improved from 0.94595 to 0.97297, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_2.h5\n","Epoch 179/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.3508 - val_accuracy: 0.9324\n","\n","Epoch 00179: val_accuracy did not improve from 0.97297\n","Epoch 180/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.5184 - val_accuracy: 0.8784\n","\n","Epoch 00180: val_accuracy did not improve from 0.97297\n","Epoch 181/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.5510 - val_accuracy: 0.8716\n","\n","Epoch 00181: val_accuracy did not improve from 0.97297\n","Epoch 182/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.3542 - val_accuracy: 0.9189\n","\n","Epoch 00182: val_accuracy did not improve from 0.97297\n","Epoch 183/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.3601 - val_accuracy: 0.9324\n","\n","Epoch 00183: val_accuracy did not improve from 0.97297\n","Epoch 184/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.5205 - val_accuracy: 0.8919\n","\n","Epoch 00184: val_accuracy did not improve from 0.97297\n","Epoch 185/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0374 - accuracy: 0.9911 - val_loss: 0.3934 - val_accuracy: 0.8986\n","\n","Epoch 00185: val_accuracy did not improve from 0.97297\n","Epoch 186/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.3414 - val_accuracy: 0.8919\n","\n","Epoch 00186: val_accuracy did not improve from 0.97297\n","Epoch 187/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 0.5280 - val_accuracy: 0.8851\n","\n","Epoch 00187: val_accuracy did not improve from 0.97297\n","Epoch 188/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.4430 - val_accuracy: 0.8716\n","\n","Epoch 00188: val_accuracy did not improve from 0.97297\n","Epoch 189/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.9228 - val_accuracy: 0.8649\n","\n","Epoch 00189: val_accuracy did not improve from 0.97297\n","Epoch 190/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0240 - accuracy: 0.9905 - val_loss: 0.5595 - val_accuracy: 0.8784\n","\n","Epoch 00190: val_accuracy did not improve from 0.97297\n","Epoch 191/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0150 - accuracy: 0.9968 - val_loss: 0.5739 - val_accuracy: 0.8986\n","\n","Epoch 00191: val_accuracy did not improve from 0.97297\n","Epoch 192/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.4899 - val_accuracy: 0.9054\n","\n","Epoch 00192: val_accuracy did not improve from 0.97297\n","Epoch 193/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0069 - accuracy: 0.9963 - val_loss: 0.5137 - val_accuracy: 0.9054\n","\n","Epoch 00193: val_accuracy did not improve from 0.97297\n","Epoch 194/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.4908 - val_accuracy: 0.8986\n","\n","Epoch 00194: val_accuracy did not improve from 0.97297\n","Epoch 195/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0381 - accuracy: 0.9905 - val_loss: 0.5906 - val_accuracy: 0.9054\n","\n","Epoch 00195: val_accuracy did not improve from 0.97297\n","Epoch 196/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.3874 - val_accuracy: 0.9054\n","\n","Epoch 00196: val_accuracy did not improve from 0.97297\n","Epoch 197/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0072 - accuracy: 0.9968 - val_loss: 0.5069 - val_accuracy: 0.8851\n","\n","Epoch 00197: val_accuracy did not improve from 0.97297\n","Epoch 198/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.5563 - val_accuracy: 0.8851\n","\n","Epoch 00198: val_accuracy did not improve from 0.97297\n","Epoch 199/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.3688 - val_accuracy: 0.9054\n","\n","Epoch 00199: val_accuracy did not improve from 0.97297\n","Epoch 200/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.4908 - val_accuracy: 0.9189\n","\n","Epoch 00200: val_accuracy did not improve from 0.97297\n","Epoch 201/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9122\n","\n","Epoch 00201: val_accuracy did not improve from 0.97297\n","Epoch 202/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.4560 - val_accuracy: 0.9054\n","\n","Epoch 00202: val_accuracy did not improve from 0.97297\n","Epoch 203/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.3884 - val_accuracy: 0.9189\n","\n","Epoch 00203: val_accuracy did not improve from 0.97297\n","Epoch 204/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0507 - accuracy: 0.9868 - val_loss: 0.9489 - val_accuracy: 0.8716\n","\n","Epoch 00204: val_accuracy did not improve from 0.97297\n","Epoch 205/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.5473 - val_accuracy: 0.8986\n","\n","Epoch 00205: val_accuracy did not improve from 0.97297\n","Epoch 206/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4827 - val_accuracy: 0.8851\n","\n","Epoch 00206: val_accuracy did not improve from 0.97297\n","Epoch 207/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.7977 - val_accuracy: 0.8514\n","\n","Epoch 00207: val_accuracy did not improve from 0.97297\n","Epoch 208/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.4642 - val_accuracy: 0.9324\n","\n","Epoch 00208: val_accuracy did not improve from 0.97297\n","Epoch 209/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0092 - accuracy: 0.9947 - val_loss: 0.7391 - val_accuracy: 0.8986\n","\n","Epoch 00209: val_accuracy did not improve from 0.97297\n","Epoch 210/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0288 - accuracy: 0.9932 - val_loss: 0.5460 - val_accuracy: 0.8851\n","\n","Epoch 00210: val_accuracy did not improve from 0.97297\n","Epoch 211/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0090 - accuracy: 0.9958 - val_loss: 0.4698 - val_accuracy: 0.8919\n","\n","Epoch 00211: val_accuracy did not improve from 0.97297\n","Epoch 212/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0129 - accuracy: 0.9974 - val_loss: 0.3958 - val_accuracy: 0.8784\n","\n","Epoch 00212: val_accuracy did not improve from 0.97297\n","Epoch 213/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.5841 - val_accuracy: 0.8784\n","\n","Epoch 00213: val_accuracy did not improve from 0.97297\n","Epoch 214/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.4625 - val_accuracy: 0.9122\n","\n","Epoch 00214: val_accuracy did not improve from 0.97297\n","Epoch 215/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.3840 - val_accuracy: 0.9122\n","\n","Epoch 00215: val_accuracy did not improve from 0.97297\n","Epoch 216/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 0.4288 - val_accuracy: 0.9392\n","\n","Epoch 00216: val_accuracy did not improve from 0.97297\n","Epoch 217/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0291 - accuracy: 0.9942 - val_loss: 0.5628 - val_accuracy: 0.9054\n","\n","Epoch 00217: val_accuracy did not improve from 0.97297\n","Epoch 218/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.5523 - val_accuracy: 0.8986\n","\n","Epoch 00218: val_accuracy did not improve from 0.97297\n","Epoch 219/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.5543 - val_accuracy: 0.8716\n","\n","Epoch 00219: val_accuracy did not improve from 0.97297\n","Epoch 220/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.3500 - val_accuracy: 0.9189\n","\n","Epoch 00220: val_accuracy did not improve from 0.97297\n","Epoch 221/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.6599 - val_accuracy: 0.8986\n","\n","Epoch 00221: val_accuracy did not improve from 0.97297\n","Epoch 222/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.4535 - val_accuracy: 0.8851\n","\n","Epoch 00222: val_accuracy did not improve from 0.97297\n","Epoch 223/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.6506 - val_accuracy: 0.8784\n","\n","Epoch 00223: val_accuracy did not improve from 0.97297\n","Epoch 224/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.4680 - val_accuracy: 0.9257\n","\n","Epoch 00224: val_accuracy did not improve from 0.97297\n","Epoch 225/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.9189\n","\n","Epoch 00225: val_accuracy did not improve from 0.97297\n","Epoch 226/500\n","238/238 [==============================] - 29s 122ms/step - loss: 8.5060e-04 - accuracy: 1.0000 - val_loss: 0.4930 - val_accuracy: 0.9189\n","\n","Epoch 00226: val_accuracy did not improve from 0.97297\n","Epoch 227/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.7454 - val_accuracy: 0.8446\n","\n","Epoch 00227: val_accuracy did not improve from 0.97297\n","Epoch 228/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.6540 - val_accuracy: 0.9054\n","\n","Epoch 00228: val_accuracy did not improve from 0.97297\n","Epoch 229/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.4288 - val_accuracy: 0.9189\n","\n","Epoch 00229: val_accuracy did not improve from 0.97297\n","Epoch 230/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.5861 - val_accuracy: 0.8851\n","\n","Epoch 00230: val_accuracy did not improve from 0.97297\n","Epoch 231/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.6042 - val_accuracy: 0.9054\n","\n","Epoch 00231: val_accuracy did not improve from 0.97297\n","Epoch 232/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6329 - val_accuracy: 0.8919\n","\n","Epoch 00232: val_accuracy did not improve from 0.97297\n","Epoch 233/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0212 - accuracy: 0.9916 - val_loss: 1.0336 - val_accuracy: 0.8851\n","\n","Epoch 00233: val_accuracy did not improve from 0.97297\n","Epoch 234/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0850 - accuracy: 0.9779 - val_loss: 0.6732 - val_accuracy: 0.8581\n","\n","Epoch 00234: val_accuracy did not improve from 0.97297\n","Epoch 235/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.6019 - val_accuracy: 0.8919\n","\n","Epoch 00235: val_accuracy did not improve from 0.97297\n","Epoch 236/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.5236 - val_accuracy: 0.8919\n","\n","Epoch 00236: val_accuracy did not improve from 0.97297\n","Epoch 237/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4040 - val_accuracy: 0.9122\n","\n","Epoch 00237: val_accuracy did not improve from 0.97297\n","Epoch 238/500\n","238/238 [==============================] - 29s 123ms/step - loss: 9.3891e-04 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.8851\n","\n","Epoch 00238: val_accuracy did not improve from 0.97297\n","Epoch 239/500\n","238/238 [==============================] - 29s 123ms/step - loss: 5.7252e-04 - accuracy: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.8851\n","\n","Epoch 00239: val_accuracy did not improve from 0.97297\n","Epoch 240/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.5384 - val_accuracy: 0.8919\n","\n","Epoch 00240: val_accuracy did not improve from 0.97297\n","Epoch 241/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.5430 - val_accuracy: 0.8581\n","\n","Epoch 00241: val_accuracy did not improve from 0.97297\n","Epoch 242/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.3930 - val_accuracy: 0.9054\n","\n","Epoch 00242: val_accuracy did not improve from 0.97297\n","Epoch 243/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.4521 - val_accuracy: 0.8851\n","\n","Epoch 00243: val_accuracy did not improve from 0.97297\n","Epoch 244/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0367 - accuracy: 0.9863 - val_loss: 0.4706 - val_accuracy: 0.8986\n","\n","Epoch 00244: val_accuracy did not improve from 0.97297\n","Epoch 245/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0235 - accuracy: 0.9916 - val_loss: 0.2483 - val_accuracy: 0.9257\n","\n","Epoch 00245: val_accuracy did not improve from 0.97297\n","Epoch 246/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2972 - val_accuracy: 0.9257\n","\n","Epoch 00246: val_accuracy did not improve from 0.97297\n","Epoch 247/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.3162 - val_accuracy: 0.9392\n","\n","Epoch 00247: val_accuracy did not improve from 0.97297\n","Epoch 248/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.5381 - val_accuracy: 0.9324\n","\n","Epoch 00248: val_accuracy did not improve from 0.97297\n","Epoch 249/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.4351 - val_accuracy: 0.8919\n","\n","Epoch 00249: val_accuracy did not improve from 0.97297\n","Epoch 250/500\n","238/238 [==============================] - 30s 125ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.8986\n","\n","Epoch 00250: val_accuracy did not improve from 0.97297\n","Epoch 251/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.5381 - val_accuracy: 0.8919\n","\n","Epoch 00251: val_accuracy did not improve from 0.97297\n","Epoch 252/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5717 - val_accuracy: 0.9054\n","\n","Epoch 00252: val_accuracy did not improve from 0.97297\n","Epoch 253/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.6829 - val_accuracy: 0.8986\n","\n","Epoch 00253: val_accuracy did not improve from 0.97297\n","Epoch 254/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.5815 - val_accuracy: 0.9054\n","\n","Epoch 00254: val_accuracy did not improve from 0.97297\n","Epoch 255/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0118 - accuracy: 0.9953 - val_loss: 0.4752 - val_accuracy: 0.9054\n","\n","Epoch 00255: val_accuracy did not improve from 0.97297\n","Epoch 256/500\n","238/238 [==============================] - 30s 125ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.6183 - val_accuracy: 0.8649\n","\n","Epoch 00256: val_accuracy did not improve from 0.97297\n","Epoch 257/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.4695 - val_accuracy: 0.9189\n","\n","Epoch 00257: val_accuracy did not improve from 0.97297\n","Epoch 258/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0238 - accuracy: 0.9947 - val_loss: 0.5824 - val_accuracy: 0.9122\n","\n","Epoch 00258: val_accuracy did not improve from 0.97297\n","Epoch 259/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.4369 - val_accuracy: 0.8919\n","\n","Epoch 00259: val_accuracy did not improve from 0.97297\n","Epoch 260/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.5485 - val_accuracy: 0.8716\n","\n","Epoch 00260: val_accuracy did not improve from 0.97297\n","Epoch 261/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.8448 - val_accuracy: 0.8784\n","\n","Epoch 00261: val_accuracy did not improve from 0.97297\n","Epoch 262/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.5014 - val_accuracy: 0.8784\n","\n","Epoch 00262: val_accuracy did not improve from 0.97297\n","Epoch 263/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.5978 - val_accuracy: 0.8986\n","\n","Epoch 00263: val_accuracy did not improve from 0.97297\n","Epoch 264/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.4192 - val_accuracy: 0.9054\n","\n","Epoch 00264: val_accuracy did not improve from 0.97297\n","Epoch 265/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.8185 - val_accuracy: 0.8784\n","\n","Epoch 00265: val_accuracy did not improve from 0.97297\n","Epoch 266/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.4332 - val_accuracy: 0.9054\n","\n","Epoch 00266: val_accuracy did not improve from 0.97297\n","Epoch 267/500\n","238/238 [==============================] - 29s 123ms/step - loss: 7.3887e-04 - accuracy: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.9324\n","\n","Epoch 00267: val_accuracy did not improve from 0.97297\n","Epoch 268/500\n","238/238 [==============================] - 29s 123ms/step - loss: 8.4054e-04 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.9054\n","\n","Epoch 00268: val_accuracy did not improve from 0.97297\n","Epoch 269/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.5550 - val_accuracy: 0.8851\n","\n","Epoch 00269: val_accuracy did not improve from 0.97297\n","Epoch 270/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.6920 - val_accuracy: 0.8986\n","\n","Epoch 00270: val_accuracy did not improve from 0.97297\n","Epoch 271/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.6220 - val_accuracy: 0.8919\n","\n","Epoch 00271: val_accuracy did not improve from 0.97297\n","Epoch 272/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.8591 - val_accuracy: 0.8784\n","\n","Epoch 00272: val_accuracy did not improve from 0.97297\n","Epoch 273/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.4948 - val_accuracy: 0.9189\n","\n","Epoch 00273: val_accuracy did not improve from 0.97297\n","Epoch 274/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.4269 - val_accuracy: 0.9189\n","\n","Epoch 00274: val_accuracy did not improve from 0.97297\n","Epoch 275/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5463 - val_accuracy: 0.8986\n","\n","Epoch 00275: val_accuracy did not improve from 0.97297\n","Epoch 276/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9054\n","\n","Epoch 00276: val_accuracy did not improve from 0.97297\n","Epoch 277/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.3923 - val_accuracy: 0.9122\n","\n","Epoch 00277: val_accuracy did not improve from 0.97297\n","Epoch 278/500\n","238/238 [==============================] - 29s 123ms/step - loss: 2.8169e-04 - accuracy: 1.0000 - val_loss: 0.4769 - val_accuracy: 0.9189\n","\n","Epoch 00278: val_accuracy did not improve from 0.97297\n","Epoch 279/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4797 - val_accuracy: 0.9257\n","\n","Epoch 00279: val_accuracy did not improve from 0.97297\n","Epoch 280/500\n","238/238 [==============================] - 29s 123ms/step - loss: 7.1096e-04 - accuracy: 0.9995 - val_loss: 0.4028 - val_accuracy: 0.9324\n","\n","Epoch 00280: val_accuracy did not improve from 0.97297\n","Epoch 281/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0216 - accuracy: 0.9953 - val_loss: 0.2795 - val_accuracy: 0.9257\n","\n","Epoch 00281: val_accuracy did not improve from 0.97297\n","Epoch 282/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.2191 - val_accuracy: 0.9324\n","\n","Epoch 00282: val_accuracy did not improve from 0.97297\n","Epoch 283/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0359 - accuracy: 0.9874 - val_loss: 0.4895 - val_accuracy: 0.9054\n","\n","Epoch 00283: val_accuracy did not improve from 0.97297\n","Epoch 284/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.4098 - val_accuracy: 0.9122\n","\n","Epoch 00284: val_accuracy did not improve from 0.97297\n","Epoch 285/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.3788 - val_accuracy: 0.9122\n","\n","Epoch 00285: val_accuracy did not improve from 0.97297\n","Epoch 286/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.5414 - val_accuracy: 0.8986\n","\n","Epoch 00286: val_accuracy did not improve from 0.97297\n","Epoch 287/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.9324\n","\n","Epoch 00287: val_accuracy did not improve from 0.97297\n","Epoch 288/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.3435 - val_accuracy: 0.9054\n","\n","Epoch 00288: val_accuracy did not improve from 0.97297\n","Epoch 289/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0085 - accuracy: 0.9958 - val_loss: 0.4967 - val_accuracy: 0.8784\n","\n","Epoch 00289: val_accuracy did not improve from 0.97297\n","Epoch 290/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0305 - accuracy: 0.9921 - val_loss: 1.0446 - val_accuracy: 0.8649\n","\n","Epoch 00290: val_accuracy did not improve from 0.97297\n","Epoch 291/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.3556 - val_accuracy: 0.9324\n","\n","Epoch 00291: val_accuracy did not improve from 0.97297\n","Epoch 292/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0100 - accuracy: 0.9958 - val_loss: 0.4917 - val_accuracy: 0.9189\n","\n","Epoch 00292: val_accuracy did not improve from 0.97297\n","Epoch 293/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.3475 - val_accuracy: 0.9257\n","\n","Epoch 00293: val_accuracy did not improve from 0.97297\n","Epoch 294/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 0.4475 - val_accuracy: 0.8986\n","\n","Epoch 00294: val_accuracy did not improve from 0.97297\n","Epoch 295/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.7426 - val_accuracy: 0.8784\n","\n","Epoch 00295: val_accuracy did not improve from 0.97297\n","Epoch 296/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.4841 - val_accuracy: 0.8986\n","\n","Epoch 00296: val_accuracy did not improve from 0.97297\n","Epoch 297/500\n","238/238 [==============================] - 29s 123ms/step - loss: 5.8829e-04 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.9324\n","\n","Epoch 00297: val_accuracy did not improve from 0.97297\n","Epoch 298/500\n","238/238 [==============================] - 29s 123ms/step - loss: 4.1016e-04 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9527\n","\n","Epoch 00298: val_accuracy did not improve from 0.97297\n","Epoch 299/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.9189\n","\n","Epoch 00299: val_accuracy did not improve from 0.97297\n","Epoch 300/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0048 - accuracy: 0.9974 - val_loss: 0.4962 - val_accuracy: 0.9054\n","\n","Epoch 00300: val_accuracy did not improve from 0.97297\n","Epoch 301/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.9122\n","\n","Epoch 00301: val_accuracy did not improve from 0.97297\n","Epoch 302/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.6534 - val_accuracy: 0.8919\n","\n","Epoch 00302: val_accuracy did not improve from 0.97297\n","Epoch 303/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.3820 - val_accuracy: 0.8986\n","\n","Epoch 00303: val_accuracy did not improve from 0.97297\n","Epoch 304/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.3193 - val_accuracy: 0.9392\n","\n","Epoch 00304: val_accuracy did not improve from 0.97297\n","Epoch 305/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0041 - accuracy: 0.9974 - val_loss: 0.4032 - val_accuracy: 0.9054\n","\n","Epoch 00305: val_accuracy did not improve from 0.97297\n","Epoch 306/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9459\n","\n","Epoch 00306: val_accuracy did not improve from 0.97297\n","Epoch 307/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.3092 - val_accuracy: 0.9257\n","\n","Epoch 00307: val_accuracy did not improve from 0.97297\n","Epoch 308/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.4282 - val_accuracy: 0.8986\n","\n","Epoch 00308: val_accuracy did not improve from 0.97297\n","Epoch 309/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.3179 - val_accuracy: 0.9122\n","\n","Epoch 00309: val_accuracy did not improve from 0.97297\n","Epoch 310/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.4089 - val_accuracy: 0.9054\n","\n","Epoch 00310: val_accuracy did not improve from 0.97297\n","Epoch 311/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.3008 - val_accuracy: 0.9324\n","\n","Epoch 00311: val_accuracy did not improve from 0.97297\n","Epoch 312/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 1.0236 - val_accuracy: 0.8176\n","\n","Epoch 00312: val_accuracy did not improve from 0.97297\n","Epoch 313/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 0.4061 - val_accuracy: 0.9122\n","\n","Epoch 00313: val_accuracy did not improve from 0.97297\n","Epoch 314/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.3545 - val_accuracy: 0.9324\n","\n","Epoch 00314: val_accuracy did not improve from 0.97297\n","Epoch 315/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.5273 - val_accuracy: 0.9189\n","\n","Epoch 00315: val_accuracy did not improve from 0.97297\n","Epoch 316/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 0.6163 - val_accuracy: 0.8851\n","\n","Epoch 00316: val_accuracy did not improve from 0.97297\n","Epoch 317/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.4030 - val_accuracy: 0.9054\n","\n","Epoch 00317: val_accuracy did not improve from 0.97297\n","Epoch 318/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.3123 - val_accuracy: 0.9392\n","\n","Epoch 00318: val_accuracy did not improve from 0.97297\n","Epoch 319/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.3327 - val_accuracy: 0.9189\n","\n","Epoch 00319: val_accuracy did not improve from 0.97297\n","Epoch 320/500\n","238/238 [==============================] - 29s 123ms/step - loss: 7.0999e-04 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.8851\n","\n","Epoch 00320: val_accuracy did not improve from 0.97297\n","Epoch 321/500\n","238/238 [==============================] - 29s 123ms/step - loss: 7.4656e-04 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.9122\n","\n","Epoch 00321: val_accuracy did not improve from 0.97297\n","Epoch 322/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.2942 - val_accuracy: 0.9257\n","\n","Epoch 00322: val_accuracy did not improve from 0.97297\n","Epoch 323/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.3826 - val_accuracy: 0.9189\n","\n","Epoch 00323: val_accuracy did not improve from 0.97297\n","Epoch 324/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.3017 - val_accuracy: 0.9122\n","\n","Epoch 00324: val_accuracy did not improve from 0.97297\n","Epoch 325/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.3140 - val_accuracy: 0.9257\n","\n","Epoch 00325: val_accuracy did not improve from 0.97297\n","Epoch 326/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.5482 - val_accuracy: 0.9054\n","\n","Epoch 00326: val_accuracy did not improve from 0.97297\n","Epoch 327/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9257\n","\n","Epoch 00327: val_accuracy did not improve from 0.97297\n","Epoch 328/500\n","238/238 [==============================] - 29s 122ms/step - loss: 6.4467e-04 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.8986\n","\n","Epoch 00328: val_accuracy did not improve from 0.97297\n","Epoch 329/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0015 - accuracy: 0.9989 - val_loss: 0.3474 - val_accuracy: 0.9257\n","\n","Epoch 00329: val_accuracy did not improve from 0.97297\n","Epoch 330/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.5609 - val_accuracy: 0.8986\n","\n","Epoch 00330: val_accuracy did not improve from 0.97297\n","Epoch 331/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0339 - accuracy: 0.9879 - val_loss: 0.4173 - val_accuracy: 0.9122\n","\n","Epoch 00331: val_accuracy did not improve from 0.97297\n","Epoch 332/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.4362 - val_accuracy: 0.8919\n","\n","Epoch 00332: val_accuracy did not improve from 0.97297\n","Epoch 333/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.4105 - val_accuracy: 0.8986\n","\n","Epoch 00333: val_accuracy did not improve from 0.97297\n","Epoch 334/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.5280 - val_accuracy: 0.8851\n","\n","Epoch 00334: val_accuracy did not improve from 0.97297\n","Epoch 335/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.7978 - val_accuracy: 0.8514\n","\n","Epoch 00335: val_accuracy did not improve from 0.97297\n","Epoch 336/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.5382 - val_accuracy: 0.9122\n","\n","Epoch 00336: val_accuracy did not improve from 0.97297\n","Epoch 337/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.3871 - val_accuracy: 0.9189\n","\n","Epoch 00337: val_accuracy did not improve from 0.97297\n","Epoch 338/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.9324\n","\n","Epoch 00338: val_accuracy did not improve from 0.97297\n","Epoch 339/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3467 - val_accuracy: 0.9054\n","\n","Epoch 00339: val_accuracy did not improve from 0.97297\n","Epoch 340/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.4297 - val_accuracy: 0.9122\n","\n","Epoch 00340: val_accuracy did not improve from 0.97297\n","Epoch 341/500\n","238/238 [==============================] - 29s 123ms/step - loss: 5.9976e-04 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9054\n","\n","Epoch 00341: val_accuracy did not improve from 0.97297\n","Epoch 342/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.4207 - val_accuracy: 0.9054\n","\n","Epoch 00342: val_accuracy did not improve from 0.97297\n","Epoch 343/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.4632 - val_accuracy: 0.8986\n","\n","Epoch 00343: val_accuracy did not improve from 0.97297\n","Epoch 344/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.4371 - val_accuracy: 0.9122\n","\n","Epoch 00344: val_accuracy did not improve from 0.97297\n","Epoch 345/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.9257\n","\n","Epoch 00345: val_accuracy did not improve from 0.97297\n","Epoch 346/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.4949 - val_accuracy: 0.8919\n","\n","Epoch 00346: val_accuracy did not improve from 0.97297\n","Epoch 347/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.4326 - val_accuracy: 0.9189\n","\n","Epoch 00347: val_accuracy did not improve from 0.97297\n","Epoch 348/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0172 - accuracy: 0.9926 - val_loss: 0.4759 - val_accuracy: 0.9054\n","\n","Epoch 00348: val_accuracy did not improve from 0.97297\n","Epoch 349/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.4192 - val_accuracy: 0.9122\n","\n","Epoch 00349: val_accuracy did not improve from 0.97297\n","Epoch 350/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4606 - val_accuracy: 0.9054\n","\n","Epoch 00350: val_accuracy did not improve from 0.97297\n","Epoch 351/500\n","238/238 [==============================] - 29s 123ms/step - loss: 2.4638e-04 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9054\n","\n","Epoch 00351: val_accuracy did not improve from 0.97297\n","Epoch 352/500\n","238/238 [==============================] - 29s 122ms/step - loss: 2.3146e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9189\n","\n","Epoch 00352: val_accuracy did not improve from 0.97297\n","Epoch 353/500\n","238/238 [==============================] - 29s 123ms/step - loss: 2.8578e-04 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9189\n","\n","Epoch 00353: val_accuracy did not improve from 0.97297\n","Epoch 354/500\n","238/238 [==============================] - 29s 122ms/step - loss: 3.5582e-04 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.9122\n","\n","Epoch 00354: val_accuracy did not improve from 0.97297\n","Epoch 355/500\n","238/238 [==============================] - 29s 122ms/step - loss: 3.3996e-04 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.9324\n","\n","Epoch 00355: val_accuracy did not improve from 0.97297\n","Epoch 356/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4749 - val_accuracy: 0.8919\n","\n","Epoch 00356: val_accuracy did not improve from 0.97297\n","Epoch 357/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 0.5801 - val_accuracy: 0.8851\n","\n","Epoch 00357: val_accuracy did not improve from 0.97297\n","Epoch 358/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.3267 - val_accuracy: 0.9122\n","\n","Epoch 00358: val_accuracy did not improve from 0.97297\n","Epoch 359/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.2301 - val_accuracy: 0.9324\n","\n","Epoch 00359: val_accuracy did not improve from 0.97297\n","Epoch 360/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.3623 - val_accuracy: 0.9257\n","\n","Epoch 00360: val_accuracy did not improve from 0.97297\n","Epoch 361/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.4979 - val_accuracy: 0.9122\n","\n","Epoch 00361: val_accuracy did not improve from 0.97297\n","Epoch 362/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.3383 - val_accuracy: 0.9122\n","\n","Epoch 00362: val_accuracy did not improve from 0.97297\n","Epoch 363/500\n","238/238 [==============================] - 29s 122ms/step - loss: 4.4681e-04 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.9122\n","\n","Epoch 00363: val_accuracy did not improve from 0.97297\n","Epoch 364/500\n","238/238 [==============================] - 29s 122ms/step - loss: 3.2680e-04 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.9189\n","\n","Epoch 00364: val_accuracy did not improve from 0.97297\n","Epoch 365/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.5949 - val_accuracy: 0.8851\n","\n","Epoch 00365: val_accuracy did not improve from 0.97297\n","Epoch 366/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.6312 - val_accuracy: 0.8986\n","\n","Epoch 00366: val_accuracy did not improve from 0.97297\n","Epoch 367/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0069 - accuracy: 0.9963 - val_loss: 0.7235 - val_accuracy: 0.8986\n","\n","Epoch 00367: val_accuracy did not improve from 0.97297\n","Epoch 368/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9122\n","\n","Epoch 00368: val_accuracy did not improve from 0.97297\n","Epoch 369/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.3117 - val_accuracy: 0.9257\n","\n","Epoch 00369: val_accuracy did not improve from 0.97297\n","Epoch 370/500\n","238/238 [==============================] - 29s 122ms/step - loss: 4.7293e-04 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.9392\n","\n","Epoch 00370: val_accuracy did not improve from 0.97297\n","Epoch 371/500\n","238/238 [==============================] - 29s 123ms/step - loss: 9.3219e-04 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.8986\n","\n","Epoch 00371: val_accuracy did not improve from 0.97297\n","Epoch 372/500\n","238/238 [==============================] - 29s 122ms/step - loss: 4.0723e-04 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.9324\n","\n","Epoch 00372: val_accuracy did not improve from 0.97297\n","Epoch 373/500\n","238/238 [==============================] - 29s 122ms/step - loss: 6.5515e-04 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.9189\n","\n","Epoch 00373: val_accuracy did not improve from 0.97297\n","Epoch 374/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3731 - val_accuracy: 0.9392\n","\n","Epoch 00374: val_accuracy did not improve from 0.97297\n","Epoch 375/500\n","238/238 [==============================] - 29s 122ms/step - loss: 3.1644e-04 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9392\n","\n","Epoch 00375: val_accuracy did not improve from 0.97297\n","Epoch 376/500\n","238/238 [==============================] - 29s 122ms/step - loss: 2.3040e-04 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9459\n","\n","Epoch 00376: val_accuracy did not improve from 0.97297\n","Epoch 377/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0293 - accuracy: 0.9932 - val_loss: 0.6945 - val_accuracy: 0.8716\n","\n","Epoch 00377: val_accuracy did not improve from 0.97297\n","Epoch 378/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.3566 - val_accuracy: 0.9054\n","\n","Epoch 00378: val_accuracy did not improve from 0.97297\n","Epoch 379/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 0.5603 - val_accuracy: 0.8919\n","\n","Epoch 00379: val_accuracy did not improve from 0.97297\n","Epoch 380/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0132 - accuracy: 0.9942 - val_loss: 0.3139 - val_accuracy: 0.8919\n","\n","Epoch 00380: val_accuracy did not improve from 0.97297\n","Epoch 381/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.3792 - val_accuracy: 0.9257\n","\n","Epoch 00381: val_accuracy did not improve from 0.97297\n","Epoch 382/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.3998 - val_accuracy: 0.9122\n","\n","Epoch 00382: val_accuracy did not improve from 0.97297\n","Epoch 383/500\n","238/238 [==============================] - 29s 123ms/step - loss: 6.5346e-04 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.9189\n","\n","Epoch 00383: val_accuracy did not improve from 0.97297\n","Epoch 384/500\n","238/238 [==============================] - 29s 123ms/step - loss: 7.3531e-04 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9324\n","\n","Epoch 00384: val_accuracy did not improve from 0.97297\n","Epoch 385/500\n","238/238 [==============================] - 29s 123ms/step - loss: 3.0153e-04 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.9324\n","\n","Epoch 00385: val_accuracy did not improve from 0.97297\n","Epoch 386/500\n","238/238 [==============================] - 29s 123ms/step - loss: 8.6280e-04 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9257\n","\n","Epoch 00386: val_accuracy did not improve from 0.97297\n","Epoch 387/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.8637 - val_accuracy: 0.8378\n","\n","Epoch 00387: val_accuracy did not improve from 0.97297\n","Epoch 388/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0183 - accuracy: 0.9932 - val_loss: 0.4260 - val_accuracy: 0.8919\n","\n","Epoch 00388: val_accuracy did not improve from 0.97297\n","Epoch 389/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.3826 - val_accuracy: 0.9122\n","\n","Epoch 00389: val_accuracy did not improve from 0.97297\n","Epoch 390/500\n","238/238 [==============================] - 29s 123ms/step - loss: 7.6676e-04 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.9054\n","\n","Epoch 00390: val_accuracy did not improve from 0.97297\n","Epoch 391/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.5584 - val_accuracy: 0.8851\n","\n","Epoch 00391: val_accuracy did not improve from 0.97297\n","Epoch 392/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.5344 - val_accuracy: 0.9054\n","\n","Epoch 00392: val_accuracy did not improve from 0.97297\n","Epoch 393/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.5168 - val_accuracy: 0.8986\n","\n","Epoch 00393: val_accuracy did not improve from 0.97297\n","Epoch 394/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0181 - accuracy: 0.9968 - val_loss: 0.4980 - val_accuracy: 0.8851\n","\n","Epoch 00394: val_accuracy did not improve from 0.97297\n","Epoch 395/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.5769 - val_accuracy: 0.8716\n","\n","Epoch 00395: val_accuracy did not improve from 0.97297\n","Epoch 396/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.4931 - val_accuracy: 0.8919\n","\n","Epoch 00396: val_accuracy did not improve from 0.97297\n","Epoch 397/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.3343 - val_accuracy: 0.9189\n","\n","Epoch 00397: val_accuracy did not improve from 0.97297\n","Epoch 398/500\n","238/238 [==============================] - 29s 122ms/step - loss: 4.5268e-04 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 0.9392\n","\n","Epoch 00398: val_accuracy did not improve from 0.97297\n","Epoch 399/500\n","238/238 [==============================] - 29s 122ms/step - loss: 4.7745e-04 - accuracy: 1.0000 - val_loss: 0.3393 - val_accuracy: 0.9122\n","\n","Epoch 00399: val_accuracy did not improve from 0.97297\n","Epoch 400/500\n","238/238 [==============================] - 29s 123ms/step - loss: 1.6257e-04 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9459\n","\n","Epoch 00400: val_accuracy did not improve from 0.97297\n","Epoch 401/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.3586 - val_accuracy: 0.9324\n","\n","Epoch 00401: val_accuracy did not improve from 0.97297\n","Epoch 402/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0305 - accuracy: 0.9958 - val_loss: 0.4875 - val_accuracy: 0.8986\n","\n","Epoch 00402: val_accuracy did not improve from 0.97297\n","Epoch 403/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.3635 - val_accuracy: 0.9257\n","\n","Epoch 00403: val_accuracy did not improve from 0.97297\n","Epoch 404/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.5586 - val_accuracy: 0.8784\n","\n","Epoch 00404: val_accuracy did not improve from 0.97297\n","Epoch 405/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.4312 - val_accuracy: 0.8986\n","\n","Epoch 00405: val_accuracy did not improve from 0.97297\n","Epoch 406/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.4052 - val_accuracy: 0.9257\n","\n","Epoch 00406: val_accuracy did not improve from 0.97297\n","Epoch 407/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9189\n","\n","Epoch 00407: val_accuracy did not improve from 0.97297\n","Epoch 408/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.2977 - val_accuracy: 0.9054\n","\n","Epoch 00408: val_accuracy did not improve from 0.97297\n","Epoch 409/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.6415 - val_accuracy: 0.8986\n","\n","Epoch 00409: val_accuracy did not improve from 0.97297\n","Epoch 410/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.4525 - val_accuracy: 0.9054\n","\n","Epoch 00410: val_accuracy did not improve from 0.97297\n","Epoch 411/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.2669 - val_accuracy: 0.9392\n","\n","Epoch 00411: val_accuracy did not improve from 0.97297\n","Epoch 412/500\n","238/238 [==============================] - 29s 122ms/step - loss: 4.6073e-04 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9459\n","\n","Epoch 00412: val_accuracy did not improve from 0.97297\n","Epoch 413/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.3766 - val_accuracy: 0.9257\n","\n","Epoch 00413: val_accuracy did not improve from 0.97297\n","Epoch 414/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.2872 - val_accuracy: 0.9257\n","\n","Epoch 00414: val_accuracy did not improve from 0.97297\n","Epoch 415/500\n","238/238 [==============================] - 29s 123ms/step - loss: 3.0667e-04 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 0.9324\n","\n","Epoch 00415: val_accuracy did not improve from 0.97297\n","Epoch 416/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.4724 - val_accuracy: 0.8919\n","\n","Epoch 00416: val_accuracy did not improve from 0.97297\n","Epoch 417/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.3069 - val_accuracy: 0.9257\n","\n","Epoch 00417: val_accuracy did not improve from 0.97297\n","Epoch 418/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5865 - val_accuracy: 0.8649\n","\n","Epoch 00418: val_accuracy did not improve from 0.97297\n","Epoch 419/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.7631 - val_accuracy: 0.8784\n","\n","Epoch 00419: val_accuracy did not improve from 0.97297\n","Epoch 420/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0153 - accuracy: 0.9937 - val_loss: 0.5338 - val_accuracy: 0.9122\n","\n","Epoch 00420: val_accuracy did not improve from 0.97297\n","Epoch 421/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.4490 - val_accuracy: 0.9392\n","\n","Epoch 00421: val_accuracy did not improve from 0.97297\n","Epoch 422/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4053 - val_accuracy: 0.9189\n","\n","Epoch 00422: val_accuracy did not improve from 0.97297\n","Epoch 423/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.5488 - val_accuracy: 0.8919\n","\n","Epoch 00423: val_accuracy did not improve from 0.97297\n","Epoch 424/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.4869 - val_accuracy: 0.9392\n","\n","Epoch 00424: val_accuracy did not improve from 0.97297\n","Epoch 425/500\n","238/238 [==============================] - 29s 122ms/step - loss: 4.1912e-04 - accuracy: 1.0000 - val_loss: 0.4596 - val_accuracy: 0.9122\n","\n","Epoch 00425: val_accuracy did not improve from 0.97297\n","Epoch 426/500\n","238/238 [==============================] - 29s 123ms/step - loss: 3.7944e-04 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9324\n","\n","Epoch 00426: val_accuracy did not improve from 0.97297\n","Epoch 427/500\n","238/238 [==============================] - 29s 123ms/step - loss: 1.7240e-04 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.9257\n","\n","Epoch 00427: val_accuracy did not improve from 0.97297\n","Epoch 428/500\n","238/238 [==============================] - 29s 122ms/step - loss: 3.6565e-04 - accuracy: 1.0000 - val_loss: 0.3139 - val_accuracy: 0.9189\n","\n","Epoch 00428: val_accuracy did not improve from 0.97297\n","Epoch 429/500\n","238/238 [==============================] - 29s 123ms/step - loss: 3.0754e-04 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9122\n","\n","Epoch 00429: val_accuracy did not improve from 0.97297\n","Epoch 430/500\n","238/238 [==============================] - 29s 123ms/step - loss: 2.3220e-04 - accuracy: 1.0000 - val_loss: 0.3713 - val_accuracy: 0.9324\n","\n","Epoch 00430: val_accuracy did not improve from 0.97297\n","Epoch 431/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.4495 - val_accuracy: 0.9122\n","\n","Epoch 00431: val_accuracy did not improve from 0.97297\n","Epoch 432/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.6135 - val_accuracy: 0.8716\n","\n","Epoch 00432: val_accuracy did not improve from 0.97297\n","Epoch 433/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0170 - accuracy: 0.9974 - val_loss: 0.4053 - val_accuracy: 0.9122\n","\n","Epoch 00433: val_accuracy did not improve from 0.97297\n","Epoch 434/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.3622 - val_accuracy: 0.9257\n","\n","Epoch 00434: val_accuracy did not improve from 0.97297\n","Epoch 435/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3732 - val_accuracy: 0.9324\n","\n","Epoch 00435: val_accuracy did not improve from 0.97297\n","Epoch 436/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.6353 - val_accuracy: 0.9054\n","\n","Epoch 00436: val_accuracy did not improve from 0.97297\n","Epoch 437/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 1.2758 - val_accuracy: 0.7973\n","\n","Epoch 00437: val_accuracy did not improve from 0.97297\n","Epoch 438/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 0.3617 - val_accuracy: 0.9257\n","\n","Epoch 00438: val_accuracy did not improve from 0.97297\n","Epoch 439/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.4526 - val_accuracy: 0.9122\n","\n","Epoch 00439: val_accuracy did not improve from 0.97297\n","Epoch 440/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.3662 - val_accuracy: 0.8986\n","\n","Epoch 00440: val_accuracy did not improve from 0.97297\n","Epoch 441/500\n","238/238 [==============================] - 29s 122ms/step - loss: 5.3634e-04 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9189\n","\n","Epoch 00441: val_accuracy did not improve from 0.97297\n","Epoch 442/500\n","238/238 [==============================] - 29s 122ms/step - loss: 2.3032e-04 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.9324\n","\n","Epoch 00442: val_accuracy did not improve from 0.97297\n","Epoch 443/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.5615 - val_accuracy: 0.8986\n","\n","Epoch 00443: val_accuracy did not improve from 0.97297\n","Epoch 444/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4240 - val_accuracy: 0.9189\n","\n","Epoch 00444: val_accuracy did not improve from 0.97297\n","Epoch 445/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.4739 - val_accuracy: 0.9189\n","\n","Epoch 00445: val_accuracy did not improve from 0.97297\n","Epoch 446/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3512 - val_accuracy: 0.9324\n","\n","Epoch 00446: val_accuracy did not improve from 0.97297\n","Epoch 447/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0194 - accuracy: 0.9947 - val_loss: 0.3681 - val_accuracy: 0.9122\n","\n","Epoch 00447: val_accuracy did not improve from 0.97297\n","Epoch 448/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.3631 - val_accuracy: 0.9189\n","\n","Epoch 00448: val_accuracy did not improve from 0.97297\n","Epoch 449/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3098 - val_accuracy: 0.9257\n","\n","Epoch 00449: val_accuracy did not improve from 0.97297\n","Epoch 450/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.5215 - val_accuracy: 0.9324\n","\n","Epoch 00450: val_accuracy did not improve from 0.97297\n","Epoch 451/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.2592 - val_accuracy: 0.9392\n","\n","Epoch 00451: val_accuracy did not improve from 0.97297\n","Epoch 452/500\n","238/238 [==============================] - 29s 123ms/step - loss: 2.9706e-04 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9392\n","\n","Epoch 00452: val_accuracy did not improve from 0.97297\n","Epoch 453/500\n","238/238 [==============================] - 29s 122ms/step - loss: 1.4636e-04 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9054\n","\n","Epoch 00453: val_accuracy did not improve from 0.97297\n","Epoch 454/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.3743 - val_accuracy: 0.9527\n","\n","Epoch 00454: val_accuracy did not improve from 0.97297\n","Epoch 455/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0278 - accuracy: 0.9942 - val_loss: 0.5128 - val_accuracy: 0.8986\n","\n","Epoch 00455: val_accuracy did not improve from 0.97297\n","Epoch 456/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.3390 - val_accuracy: 0.9257\n","\n","Epoch 00456: val_accuracy did not improve from 0.97297\n","Epoch 457/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.2247 - val_accuracy: 0.9527\n","\n","Epoch 00457: val_accuracy did not improve from 0.97297\n","Epoch 458/500\n","238/238 [==============================] - 29s 123ms/step - loss: 5.4006e-04 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9257\n","\n","Epoch 00458: val_accuracy did not improve from 0.97297\n","Epoch 459/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.3174 - val_accuracy: 0.8986\n","\n","Epoch 00459: val_accuracy did not improve from 0.97297\n","Epoch 460/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.4427 - val_accuracy: 0.8986\n","\n","Epoch 00460: val_accuracy did not improve from 0.97297\n","Epoch 461/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.5206 - val_accuracy: 0.8919\n","\n","Epoch 00461: val_accuracy did not improve from 0.97297\n","Epoch 462/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.4135 - val_accuracy: 0.9189\n","\n","Epoch 00462: val_accuracy did not improve from 0.97297\n","Epoch 463/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.3670 - val_accuracy: 0.9122\n","\n","Epoch 00463: val_accuracy did not improve from 0.97297\n","Epoch 464/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.5462 - val_accuracy: 0.8986\n","\n","Epoch 00464: val_accuracy did not improve from 0.97297\n","Epoch 465/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4686 - val_accuracy: 0.8986\n","\n","Epoch 00465: val_accuracy did not improve from 0.97297\n","Epoch 466/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.5362 - val_accuracy: 0.9054\n","\n","Epoch 00466: val_accuracy did not improve from 0.97297\n","Epoch 467/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.5072 - val_accuracy: 0.8986\n","\n","Epoch 00467: val_accuracy did not improve from 0.97297\n","Epoch 468/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.4032 - val_accuracy: 0.9324\n","\n","Epoch 00468: val_accuracy did not improve from 0.97297\n","Epoch 469/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.5530 - val_accuracy: 0.8581\n","\n","Epoch 00469: val_accuracy did not improve from 0.97297\n","Epoch 470/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.4473 - val_accuracy: 0.9122\n","\n","Epoch 00470: val_accuracy did not improve from 0.97297\n","Epoch 471/500\n","238/238 [==============================] - 29s 123ms/step - loss: 6.1917e-04 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9324\n","\n","Epoch 00471: val_accuracy did not improve from 0.97297\n","Epoch 472/500\n","238/238 [==============================] - 29s 123ms/step - loss: 5.3250e-04 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9257\n","\n","Epoch 00472: val_accuracy did not improve from 0.97297\n","Epoch 473/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.4974 - val_accuracy: 0.9324\n","\n","Epoch 00473: val_accuracy did not improve from 0.97297\n","Epoch 474/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9122\n","\n","Epoch 00474: val_accuracy did not improve from 0.97297\n","Epoch 475/500\n","238/238 [==============================] - 29s 123ms/step - loss: 9.7615e-04 - accuracy: 1.0000 - val_loss: 0.4025 - val_accuracy: 0.9189\n","\n","Epoch 00475: val_accuracy did not improve from 0.97297\n","Epoch 476/500\n","238/238 [==============================] - 29s 123ms/step - loss: 1.0690e-04 - accuracy: 1.0000 - val_loss: 0.3216 - val_accuracy: 0.9324\n","\n","Epoch 00476: val_accuracy did not improve from 0.97297\n","Epoch 477/500\n","238/238 [==============================] - 29s 123ms/step - loss: 1.3598e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9189\n","\n","Epoch 00477: val_accuracy did not improve from 0.97297\n","Epoch 478/500\n","238/238 [==============================] - 29s 122ms/step - loss: 5.4217e-05 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9257\n","\n","Epoch 00478: val_accuracy did not improve from 0.97297\n","Epoch 479/500\n","238/238 [==============================] - 29s 123ms/step - loss: 2.5781e-05 - accuracy: 1.0000 - val_loss: 0.3425 - val_accuracy: 0.9189\n","\n","Epoch 00479: val_accuracy did not improve from 0.97297\n","Epoch 480/500\n","238/238 [==============================] - 29s 123ms/step - loss: 5.0240e-05 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9257\n","\n","Epoch 00480: val_accuracy did not improve from 0.97297\n","Epoch 481/500\n","238/238 [==============================] - 29s 123ms/step - loss: 2.2948e-04 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.9189\n","\n","Epoch 00481: val_accuracy did not improve from 0.97297\n","Epoch 482/500\n","238/238 [==============================] - 29s 123ms/step - loss: 4.7070e-05 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9257\n","\n","Epoch 00482: val_accuracy did not improve from 0.97297\n","Epoch 483/500\n","238/238 [==============================] - 29s 123ms/step - loss: 2.4481e-05 - accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 0.9257\n","\n","Epoch 00483: val_accuracy did not improve from 0.97297\n","Epoch 484/500\n","238/238 [==============================] - 29s 123ms/step - loss: 1.8098e-05 - accuracy: 1.0000 - val_loss: 0.4572 - val_accuracy: 0.9054\n","\n","Epoch 00484: val_accuracy did not improve from 0.97297\n","Epoch 485/500\n","238/238 [==============================] - 29s 123ms/step - loss: 2.5253e-05 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.9257\n","\n","Epoch 00485: val_accuracy did not improve from 0.97297\n","Epoch 486/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0198 - accuracy: 0.9953 - val_loss: 0.8297 - val_accuracy: 0.8851\n","\n","Epoch 00486: val_accuracy did not improve from 0.97297\n","Epoch 487/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0521 - accuracy: 0.9905 - val_loss: 0.5773 - val_accuracy: 0.8919\n","\n","Epoch 00487: val_accuracy did not improve from 0.97297\n","Epoch 488/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.7112 - val_accuracy: 0.8784\n","\n","Epoch 00488: val_accuracy did not improve from 0.97297\n","Epoch 489/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.4629 - val_accuracy: 0.9054\n","\n","Epoch 00489: val_accuracy did not improve from 0.97297\n","Epoch 490/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.4313 - val_accuracy: 0.8986\n","\n","Epoch 00490: val_accuracy did not improve from 0.97297\n","Epoch 491/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.5253 - val_accuracy: 0.8919\n","\n","Epoch 00491: val_accuracy did not improve from 0.97297\n","Epoch 492/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.5145 - val_accuracy: 0.9189\n","\n","Epoch 00492: val_accuracy did not improve from 0.97297\n","Epoch 493/500\n","238/238 [==============================] - 29s 123ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.3967 - val_accuracy: 0.9122\n","\n","Epoch 00493: val_accuracy did not improve from 0.97297\n","Epoch 494/500\n","238/238 [==============================] - 29s 123ms/step - loss: 2.2598e-04 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9324\n","\n","Epoch 00494: val_accuracy did not improve from 0.97297\n","Epoch 495/500\n","238/238 [==============================] - 29s 122ms/step - loss: 5.1059e-04 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.9189\n","\n","Epoch 00495: val_accuracy did not improve from 0.97297\n","Epoch 496/500\n","238/238 [==============================] - 29s 122ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.5403 - val_accuracy: 0.8919\n","\n","Epoch 00496: val_accuracy did not improve from 0.97297\n","Epoch 497/500\n","238/238 [==============================] - 29s 123ms/step - loss: 3.3103e-04 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.9054\n","\n","Epoch 00497: val_accuracy did not improve from 0.97297\n","Epoch 498/500\n","238/238 [==============================] - 29s 123ms/step - loss: 1.0235e-04 - accuracy: 1.0000 - val_loss: 0.6151 - val_accuracy: 0.8986\n","\n","Epoch 00498: val_accuracy did not improve from 0.97297\n","Epoch 499/500\n","238/238 [==============================] - 29s 122ms/step - loss: 1.1962e-04 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9324\n","\n","Epoch 00499: val_accuracy did not improve from 0.97297\n","Epoch 500/500\n","238/238 [==============================] - 29s 123ms/step - loss: 8.6375e-05 - accuracy: 1.0000 - val_loss: 0.5330 - val_accuracy: 0.9054\n","\n","Epoch 00500: val_accuracy did not improve from 0.97297\n"]},{"data":{"text/plain":["\u003ckeras.callbacks.History at 0x7f7690400410\u003e"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kHmpkzRJyCrf"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n","plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n","\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qcElIu93yIQU"},"outputs":[],"source":["Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hR4N2pAZyiR-"},"outputs":[],"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rxH98QOgyu1z"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 20480 images belonging to 1 classes.\n"]}],"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nFEcoCR-3DNH"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}],"source":["Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qYhGZuzr1AjD"},"outputs":[],"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VWALVGA1shFz"},"outputs":[],"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7xjLSWZJvuVK"},"outputs":[],"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WNg9gk9z3Noq"},"outputs":[],"source":["submission[\"model_predict\"] = Target_predict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-Smd-xg6deOK"},"outputs":[],"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['model_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Pg9m6Zgk4foS"},"outputs":[],"source":["submission = submission[['id', 'digit']]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"flAHWrtH4flu"},"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_008911a3-26ca-4c1b-af5e-05e63b1eb9fc\", \"Xception_2.csv\", 155898)"],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lmZ06MWjdN2l"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n","Installing collected packages: dacon-submit-api\n","Successfully installed dacon-submit-api-0.0.4\n"]}],"source":["!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"oVdKDp3mdOZA"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"]}],"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","    # 파일경로\n","    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n","    # d9249@kyonggi.ac.kr\n","    # 'c2ecc8b05a9867f71ebb86f632ae73326696cb7f6e21be07ab43a7b400ef1f11',\n","    # dodo9249@gmail.com\n","    # 'abc9927563b1882b2480ac943a313a002631fb00c5a0daea43b12720ed34114e',\n","    # d9249.acc001@gmail.com\n","    # 'b27d6929e0eedade68e6a882d4006ec463f061c75a81aa27561c2c606dde8ad7',\n","    # meanideal96@gamil.com\n","    # '895306aa742a46bd095afaf319bd0b9519e1e6e74f4bf98a32c2e4c15aee5026',\n","    # dodo402298@gmail.com\n","    '384b4c250944611e49156214ca31fd554bbc64d22ec31a2726302c22f1a05271',\n","    # d9249.acc002@gmail.com\n","    # 'b28b29dd8d3ed4701f3b4e5b4d95549078e543dbd4a12abd92a3dd9a09d85616',\n","    # 대회 ID\n","    '235626',\n","    # d9249@kyonggi.ac.kr 팀이릉\n","    # 'iDeal9',\n","    # dodo9249@gmail.com 팀이름\n","    # 'iDeal96',\n","    # d9249.acc001@gmail.com\n","    # 'iDeal01',\n","    # meanideal96@gamil.com\n","    # 'iDeal02',\n","    # dodo402298@gmail.com\n","    'mean01',\n","    # d9249.acc002@gmail.com\n","    # 'mean02',\n","    # memo\n","    'd9249_kyonggi_ac_kr' )"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Xception_2_(public-, private-).ipynb","provenance":[{"file_id":"1OIZKCtwYST5ROVoAH5jE6OyziVLs5YVe","timestamp":1632775577125},{"file_id":"1M8OJEV_AT9MOCy7JGAaVl1j_VfABfzuE","timestamp":1632775493726},{"file_id":"1tLm7xKEM0NUAtTz8MetJXTPqs1Vr30rT","timestamp":1632775476672},{"file_id":"1cQ9_pnDLKsxM2cvx0IWbLgjkO3Cepyu-","timestamp":1632775461739},{"file_id":"1wP4iB5o6DM91rslno_OvktLGjLoIpAes","timestamp":1632775444303},{"file_id":"1dp46txQYj-TzLA1Gc54Q8rt5HLq0q6Ya","timestamp":1632775427818},{"file_id":"1aTR2tEWrt0W_t7v1aT5sEWrY2fB8Vbwk","timestamp":1632775384268},{"file_id":"1OK3Q_uTJHKxOBU9a9LjMw8MZY9-m_qax","timestamp":1632775365110},{"file_id":"12rbPEBCBS4GLkAocXVKMeBFRx23lD26Y","timestamp":1632775350191},{"file_id":"13xRLFQ8Hipz_BgwiFlaogXJZjqYLclRl","timestamp":1632774878702},{"file_id":"1luopodme_2PAosMrjbeJFrjr8TTmUyyi","timestamp":1632774856109},{"file_id":"1_KfZfBkcDbe5bnFU5VAUULs4qEtYpZc2","timestamp":1632773239935},{"file_id":"1ks7cPy6YRHRAmKY092ZBPxiPfOiHr5Dw","timestamp":1632773090135},{"file_id":"1DX-VAkigMOMI4H8Tym6SDeRIC846UJKl","timestamp":1632766435368},{"file_id":"1MiY3-NuosQH2lOSwZs4hXFDVSdCU0ucv","timestamp":1632766287071},{"file_id":"1CQOhgM_f1bTX8impB1c4QEcVlmSxl3Rz","timestamp":1632766225629},{"file_id":"1NxaJdPz5D7xHXti1IodBLxTyurilAYey","timestamp":1632764873900},{"file_id":"18TpM-aeHM3jrQ21NpPhQJXyu9Kkddi1z","timestamp":1632757533244},{"file_id":"1ru3oFw4R5jlAbvt6XFdYZNHbr13fm76L","timestamp":1632757500318},{"file_id":"11bKdbU5uhsA-AQ6rltMfGFGkKz00AQzM","timestamp":1632757434832},{"file_id":"1iT1DpUTybBnG79zJOIqNnn_lqKynaZso","timestamp":1632745793318},{"file_id":"1M_c2tK-OSq0Sf0EkgPYrIVj_UFxyDhLa","timestamp":1632722288709},{"file_id":"1Ks4BnsIQVSo6nrDm_GCFLP-tUWbMF7fV","timestamp":1632675649149},{"file_id":"1CqtLKNQRRuC325QEoXZHskfQDXw-hybx","timestamp":1632675617704},{"file_id":"12JaYWavZfXc3mxowUEN1hmoDHEhLE9kD","timestamp":1632669857913},{"file_id":"1mRQmgFDcxuga37ytSbeksdBDV8lXPuP_","timestamp":1632669810228},{"file_id":"1hSseuq321IM3Xw9iARWzPOzaWFGuSYps","timestamp":1632659933103},{"file_id":"1i84kOIoNMg1SDAOmCAl-iREVAA8REpRl","timestamp":1632659111522},{"file_id":"1aWKemyOVH_XXsufg6PEqpNJHCIODEQDQ","timestamp":1632658287256},{"file_id":"1ZUL9g9uU5gE9mjrGyZ_ZE6_ZMwE69CPb","timestamp":1632657078244},{"file_id":"1Xq9yUa0JgnqQUKKTfy3z54fip8tHOUVO","timestamp":1632649657584},{"file_id":"1g107jAyKQClzEQj_DMR2xU4rZ9qbJH5e","timestamp":1632649536640},{"file_id":"1Z6kuupfDyi8FoEAzxFaCF1zxYVFMOZLV","timestamp":1632555432723},{"file_id":"1EbR-z2BYoOKWzYoeQoCF6HChJXoczWOg","timestamp":1632529654720},{"file_id":"19UhJoIWtCbGyO-f3O4Ejh3cQm9HsELdp","timestamp":1632508748323},{"file_id":"1P94NU6OoLRtS_ewl8Rb7NPZqKyl6ScPt","timestamp":1632508239637},{"file_id":"1oYHEjU-CSdxlLxyB6mhRRnSPmxfEbe9-","timestamp":1632483693856},{"file_id":"1tY8RF_0awL36zd9hQqUN3JK-9i7JjSCs","timestamp":1632483672985},{"file_id":"1hfaa8YJTlfEKZL9us0XaxbDFzEg6QlrT","timestamp":1632483587193},{"file_id":"1ar0JVhm118hpsiDCU0yS0Ty83Lr95cSu","timestamp":1632438063611},{"file_id":"1ISSiU2DrdSTDMVmbAxc8Ql72Bwult8wi","timestamp":1632382754243},{"file_id":"1cmBIBf0Y6KY5nFGyXFWuz9pe-V3QXe84","timestamp":1632382703200},{"file_id":"1NmDQbVBw3bmj4dkYxCWjOgHGEPxn2knZ","timestamp":1632382649241},{"file_id":"1h-FhrHH66IwjTlqiffpUdtWJZ47_06LZ","timestamp":1632332735991},{"file_id":"174isfXxsoXsuFjV-4wlPn8FyvhQelSZa","timestamp":1632264352072},{"file_id":"1rvvO3AZYRa3O0L25N-Kx2tXg3SO3ZLMb","timestamp":1632207962186},{"file_id":"10a77ENeqwaxgwFA_yCVpQBXkA9Fdts6t","timestamp":1632177040567},{"file_id":"1FLQ4OWmjzgDT_6nR4k61mlxJ0RbQfLbW","timestamp":1632127337902},{"file_id":"1L21WYacshipXDSgj75p87xRajwZ-yYEf","timestamp":1632125266824},{"file_id":"1gXw-oagzF1c49Ds2rFNXBNA-Jjj0YTGM","timestamp":1632125231955},{"file_id":"1odc6VzTolz3PuXSezCpAr8zqRhjlzJFc","timestamp":1632032770915},{"file_id":"1MLPQlf1Ig6rev94yP2Zy_hjHPEwnJWKr","timestamp":1631962707157},{"file_id":"1RFXq_y4na26GX1TMhOCKZvjIKxWZgQei","timestamp":1631894145495},{"file_id":"1j4_hnK2KjlLPPPkDR5LUdjrgcl7E5VJ2","timestamp":1631892272403},{"file_id":"1p_d4XYROzKVVUxBHxjuVx1gTinsguwp8","timestamp":1631892211512},{"file_id":"1qviqzhy3AgjpFc3P2QLjjqfHnbk3izT5","timestamp":1631892086873},{"file_id":"1rE8G1jItkQTqd3bvVGDHTrM9ONajBm2k","timestamp":1631891790249},{"file_id":"https://github.com/d9249/DACON/blob/main/CVLC_05_No_Data_Argmentation(public_0_81862_private_0_76593).ipynb","timestamp":1627056180265}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}