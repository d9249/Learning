{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageSize_224_3_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPP1l3W6Kjc4H6BiwOwBVrD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/ImageSize_224_3_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09186eb7-8bcd-4287-b6f9-f297453078b6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep  7 20:40:33 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668d9693-c290-4dc8-cf09-5df2076353a3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61aae486-cc6f-4720-fa5c-07aed30b7528"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2402e4c8-d795-49f1-bf5e-025e1ff088f2"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "617c5f19-3557-4d92-fab9-244e7f2aecf9"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 39s 262ms/step - loss: 1.8286 - accuracy: 0.3496 - val_loss: 10.7671 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11330, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 1.1762 - accuracy: 0.5993 - val_loss: 5.0464 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.11330\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.9508 - accuracy: 0.6784 - val_loss: 30.4434 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.11330\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.8039 - accuracy: 0.7345 - val_loss: 10.7929 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.11330\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.6922 - accuracy: 0.7607 - val_loss: 5.7530 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.11330\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.6499 - accuracy: 0.7893 - val_loss: 5.2539 - val_accuracy: 0.2241\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.11330 to 0.22414, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.5576 - accuracy: 0.8094 - val_loss: 5.4832 - val_accuracy: 0.2734\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.22414 to 0.27340, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.5656 - accuracy: 0.8094 - val_loss: 4.9246 - val_accuracy: 0.2685\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.27340\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.4904 - accuracy: 0.8386 - val_loss: 3.6075 - val_accuracy: 0.3744\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.27340 to 0.37438, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.5117 - accuracy: 0.8289 - val_loss: 1.4853 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.37438 to 0.68473, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.4536 - accuracy: 0.8544 - val_loss: 1.0022 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.68473 to 0.74877, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.4015 - accuracy: 0.8569 - val_loss: 1.2180 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.74877\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.3867 - accuracy: 0.8733 - val_loss: 1.2618 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.74877\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.3430 - accuracy: 0.8849 - val_loss: 1.0902 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.74877\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.2694 - accuracy: 0.9050 - val_loss: 0.7967 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.74877 to 0.77833, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.2971 - accuracy: 0.9013 - val_loss: 0.6826 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.77833 to 0.80296, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.2822 - accuracy: 0.9080 - val_loss: 1.2289 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.80296\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.2676 - accuracy: 0.9147 - val_loss: 0.6891 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.80296\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.2515 - accuracy: 0.9166 - val_loss: 0.7050 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.80296\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.3203 - accuracy: 0.8861 - val_loss: 0.7682 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.80296 to 0.80542, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.2471 - accuracy: 0.9141 - val_loss: 0.6045 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.80542 to 0.83498, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.2228 - accuracy: 0.9220 - val_loss: 1.3309 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.83498\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.2819 - accuracy: 0.9105 - val_loss: 1.0966 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.83498\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.2607 - accuracy: 0.9141 - val_loss: 0.5947 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.83498\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.2151 - accuracy: 0.9227 - val_loss: 0.8859 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.83498\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1701 - accuracy: 0.9446 - val_loss: 0.8268 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.83498\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1752 - accuracy: 0.9403 - val_loss: 0.5539 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.83498 to 0.84975, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1608 - accuracy: 0.9428 - val_loss: 0.5044 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.84975 to 0.85961, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1560 - accuracy: 0.9452 - val_loss: 0.9249 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.85961\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1321 - accuracy: 0.9543 - val_loss: 0.6620 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.85961\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.2219 - accuracy: 0.9294 - val_loss: 0.4830 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.85961\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.2508 - accuracy: 0.9123 - val_loss: 9.9363 - val_accuracy: 0.2217\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.85961\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1775 - accuracy: 0.9361 - val_loss: 1.1534 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.85961\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1716 - accuracy: 0.9409 - val_loss: 1.2600 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.85961\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1286 - accuracy: 0.9549 - val_loss: 0.5892 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.85961\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1342 - accuracy: 0.9519 - val_loss: 0.5250 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.85961\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1408 - accuracy: 0.9543 - val_loss: 0.5893 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.85961\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0903 - accuracy: 0.9714 - val_loss: 0.7784 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.85961\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0846 - accuracy: 0.9714 - val_loss: 0.4704 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.85961 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1140 - accuracy: 0.9562 - val_loss: 0.6079 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.86946\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0794 - accuracy: 0.9744 - val_loss: 0.3853 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.86946 to 0.88916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1606 - accuracy: 0.9428 - val_loss: 0.7217 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.88916\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1759 - accuracy: 0.9421 - val_loss: 0.6480 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.88916\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1078 - accuracy: 0.9665 - val_loss: 0.3943 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.88916\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0726 - accuracy: 0.9762 - val_loss: 0.3538 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.88916 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0644 - accuracy: 0.9793 - val_loss: 0.6641 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89655\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1219 - accuracy: 0.9568 - val_loss: 0.9302 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89655\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1000 - accuracy: 0.9689 - val_loss: 0.5215 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89655\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0729 - accuracy: 0.9756 - val_loss: 0.6204 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89655\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0679 - accuracy: 0.9769 - val_loss: 0.3473 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.89655 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0627 - accuracy: 0.9823 - val_loss: 0.4560 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.90394\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0698 - accuracy: 0.9750 - val_loss: 0.5016 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.90394\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1024 - accuracy: 0.9604 - val_loss: 0.5127 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.90394\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0939 - accuracy: 0.9665 - val_loss: 0.3688 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.90394\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0455 - accuracy: 0.9854 - val_loss: 0.4185 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.90394 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0597 - accuracy: 0.9756 - val_loss: 0.4337 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91379\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1218 - accuracy: 0.9574 - val_loss: 0.7197 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91379\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1124 - accuracy: 0.9629 - val_loss: 0.8796 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91379\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1030 - accuracy: 0.9629 - val_loss: 0.7705 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91379\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1165 - accuracy: 0.9525 - val_loss: 1.0259 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91379\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1121 - accuracy: 0.9653 - val_loss: 0.5779 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91379\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0776 - accuracy: 0.9714 - val_loss: 0.6603 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91379\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0456 - accuracy: 0.9805 - val_loss: 0.5576 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91379\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0725 - accuracy: 0.9781 - val_loss: 0.6151 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91379\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0944 - accuracy: 0.9659 - val_loss: 0.4322 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91379\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0417 - accuracy: 0.9866 - val_loss: 0.3657 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91379\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0730 - accuracy: 0.9738 - val_loss: 0.6223 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91379\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0657 - accuracy: 0.9793 - val_loss: 0.5937 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91379\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0712 - accuracy: 0.9787 - val_loss: 0.8225 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91379\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0776 - accuracy: 0.9769 - val_loss: 0.5289 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91379\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0552 - accuracy: 0.9836 - val_loss: 0.5916 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91379\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0682 - accuracy: 0.9762 - val_loss: 0.7966 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91379\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0384 - accuracy: 0.9848 - val_loss: 0.3908 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91379\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0876 - accuracy: 0.9708 - val_loss: 0.6764 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91379\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0421 - accuracy: 0.9848 - val_loss: 0.6071 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91379\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0356 - accuracy: 0.9903 - val_loss: 0.5883 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91379\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 0.5669 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91379\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 0.3798 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91379\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1224 - accuracy: 0.9622 - val_loss: 0.6897 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91379\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0983 - accuracy: 0.9689 - val_loss: 0.8058 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91379\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0448 - accuracy: 0.9842 - val_loss: 0.4311 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91379\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 0.5483 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91379\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0550 - accuracy: 0.9848 - val_loss: 0.3933 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91379\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0349 - accuracy: 0.9872 - val_loss: 0.4735 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91379\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0743 - accuracy: 0.9787 - val_loss: 0.4660 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91379\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0336 - accuracy: 0.9866 - val_loss: 0.4193 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91379\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0259 - accuracy: 0.9909 - val_loss: 0.6604 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91379\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0217 - accuracy: 0.9921 - val_loss: 0.6080 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91379\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0401 - accuracy: 0.9872 - val_loss: 0.4627 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91379\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0629 - accuracy: 0.9793 - val_loss: 0.5777 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91379\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.6998 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91379\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0514 - accuracy: 0.9836 - val_loss: 0.7312 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91379\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0355 - accuracy: 0.9878 - val_loss: 0.5082 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91379\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0339 - accuracy: 0.9903 - val_loss: 0.5505 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91379\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 0.5285 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91379\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0415 - accuracy: 0.9836 - val_loss: 0.7073 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91379\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0625 - accuracy: 0.9781 - val_loss: 0.5267 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91379\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0321 - accuracy: 0.9884 - val_loss: 0.5731 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91379\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0623 - accuracy: 0.9805 - val_loss: 0.8219 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91379\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0456 - accuracy: 0.9842 - val_loss: 0.7989 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91379\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0280 - accuracy: 0.9890 - val_loss: 0.5416 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91379\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0327 - accuracy: 0.9903 - val_loss: 0.8542 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.91379\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0268 - accuracy: 0.9890 - val_loss: 0.5997 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.91379\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.4588 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.91379\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.3733 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91379\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.3741 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91379\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.4274 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91379\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0265 - accuracy: 0.9903 - val_loss: 0.8689 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91379\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0966 - accuracy: 0.9714 - val_loss: 0.6812 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91379\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0663 - accuracy: 0.9762 - val_loss: 0.8955 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91379\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0810 - accuracy: 0.9695 - val_loss: 1.2430 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91379\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1138 - accuracy: 0.9629 - val_loss: 0.7903 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91379\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0632 - accuracy: 0.9781 - val_loss: 0.5017 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91379\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 0.4325 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91379\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.4058 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91379\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.3901 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91379\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.4031 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91379\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.3863 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91379\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.3997 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91379\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.4955 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91379\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.3509 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91379\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91379\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91379\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00124: val_accuracy improved from 0.91379 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 8.3536e-04 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91872\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4102 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91872\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 1.0359 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91872\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1990 - accuracy: 0.9367 - val_loss: 6.4063 - val_accuracy: 0.4433\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91872\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1478 - accuracy: 0.9495 - val_loss: 2.9023 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91872\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0779 - accuracy: 0.9732 - val_loss: 1.0283 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91872\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0572 - accuracy: 0.9781 - val_loss: 0.5873 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91872\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 0.7002 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91872\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0239 - accuracy: 0.9896 - val_loss: 0.4624 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91872\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 0.4841 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91872\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.4868 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91872\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.4353 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91872\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.4134 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91872\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.4585 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91872\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 12s 231ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4926 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91872\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4669 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91872\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.5120 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.91872\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0207 - accuracy: 0.9921 - val_loss: 0.7586 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.91872\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0897 - accuracy: 0.9769 - val_loss: 0.9434 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.91872\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0523 - accuracy: 0.9842 - val_loss: 0.5827 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.91872\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.6151 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.91872\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.4154 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.91872\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0384 - accuracy: 0.9854 - val_loss: 0.9545 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.91872\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0770 - accuracy: 0.9762 - val_loss: 0.7439 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.91872\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0303 - accuracy: 0.9878 - val_loss: 0.5117 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.91872\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.4826 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.91872\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.5058 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.91872\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.4034 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.91872\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00153: val_accuracy improved from 0.91872 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3384 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92611\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.7170 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92611\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.6421 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92611\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0196 - accuracy: 0.9921 - val_loss: 0.9425 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92611\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.4425 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92611\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.6760 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92611\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0362 - accuracy: 0.9890 - val_loss: 0.8162 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92611\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0464 - accuracy: 0.9836 - val_loss: 0.6113 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92611\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0842 - accuracy: 0.9720 - val_loss: 0.8489 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92611\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0729 - accuracy: 0.9793 - val_loss: 0.6421 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92611\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0310 - accuracy: 0.9915 - val_loss: 0.7263 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92611\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.5699 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92611\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.4790 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92611\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.5362 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92611\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.4794 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92611\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4703 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92611\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92611\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92611\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92611\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4082 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92611\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0145 - accuracy: 0.9915 - val_loss: 0.5162 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92611\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.6166 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92611\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.6451 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92611\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.4323 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92611\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.4022 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92611\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0470 - accuracy: 0.9896 - val_loss: 0.8227 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92611\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0592 - accuracy: 0.9793 - val_loss: 0.8536 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92611\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0452 - accuracy: 0.9823 - val_loss: 0.9975 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92611\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0881 - accuracy: 0.9744 - val_loss: 1.1202 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92611\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0474 - accuracy: 0.9860 - val_loss: 0.6628 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92611\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.4110 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92611\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.4953 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92611\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0135 - accuracy: 0.9945 - val_loss: 0.3490 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92611\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.3372 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92611\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.3746 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92611\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4596 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92611\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.3545 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92611\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.3668 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92611\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.3262 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92611\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.4639 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92611\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.4466 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92611\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.4518 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92611\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.4607 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92611\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0245 - accuracy: 0.9939 - val_loss: 0.9065 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92611\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.8095 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92611\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.5405 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92611\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.4303 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92611\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.5132 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92611\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.3886 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92611\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.4558 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92611\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.5222 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92611\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4103 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92611\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4301 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92611\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0060 - accuracy: 0.9970 - val_loss: 0.5719 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92611\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.8031 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92611\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0447 - accuracy: 0.9866 - val_loss: 2.9513 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92611\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1488 - accuracy: 0.9586 - val_loss: 1.2737 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92611\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1055 - accuracy: 0.9683 - val_loss: 1.3874 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92611\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0497 - accuracy: 0.9848 - val_loss: 0.7990 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92611\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.5218 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92611\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0142 - accuracy: 0.9945 - val_loss: 0.4827 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92611\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.3924 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92611\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.3727 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00216: val_accuracy improved from 0.92611 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4502 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92857\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.3583 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92857\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3490 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92857\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92857\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 8.0647e-04 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00221: val_accuracy improved from 0.92857 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 7.2417e-04 - accuracy: 1.0000 - val_loss: 0.3020 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93103\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 7.4004e-04 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00223: val_accuracy improved from 0.93103 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.3052 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93350\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 4.0026e-04 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93350\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4293 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93350\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 1.1463 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93350\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0625 - accuracy: 0.9787 - val_loss: 1.1135 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93350\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0638 - accuracy: 0.9750 - val_loss: 0.7583 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93350\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0377 - accuracy: 0.9890 - val_loss: 0.7347 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93350\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.5467 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93350\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.4858 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93350\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.4940 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93350\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0093 - accuracy: 0.9957 - val_loss: 0.4053 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93350\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93350\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.3486 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93350\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.6759 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93350\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3786 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93350\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93350\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.3353 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93350\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.3584 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93350\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4003 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93350\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93350\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3850 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93350\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 8.4617e-04 - accuracy: 1.0000 - val_loss: 0.3690 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93350\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0359 - accuracy: 0.9903 - val_loss: 0.7112 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93350\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0845 - accuracy: 0.9769 - val_loss: 0.6956 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93350\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0761 - accuracy: 0.9750 - val_loss: 1.0121 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93350\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0411 - accuracy: 0.9860 - val_loss: 0.5657 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93350\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.4137 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93350\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4647 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93350\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.4205 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93350\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93350\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 6.9454e-04 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93350\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0117 - accuracy: 0.9982 - val_loss: 0.6765 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93350\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0236 - accuracy: 0.9909 - val_loss: 0.9290 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93350\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0347 - accuracy: 0.9890 - val_loss: 0.5118 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93350\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0156 - accuracy: 0.9976 - val_loss: 0.4936 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93350\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0110 - accuracy: 0.9951 - val_loss: 0.5408 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93350\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4363 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93350\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.3090 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93350\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.5068 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93350\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.5661 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93350\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.4833 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93350\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.5114 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93350\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 0.6230 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93350\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4356 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93350\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 7.9264e-04 - accuracy: 1.0000 - val_loss: 0.4871 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93350\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 8.0056e-04 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93350\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 7.0057e-04 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93350\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 7.7822e-04 - accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93350\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 7.7426e-04 - accuracy: 0.9994 - val_loss: 0.3947 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93350\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4451 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93350\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 7.3168e-04 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93350\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 8.7386e-04 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93350\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.5560 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93350\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.8068 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93350\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0822 - accuracy: 0.9793 - val_loss: 0.9464 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93350\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0799 - accuracy: 0.9805 - val_loss: 1.0197 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93350\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.6979 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93350\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0179 - accuracy: 0.9933 - val_loss: 0.4791 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93350\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.5212 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93350\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.4655 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93350\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.4239 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93350\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.5550 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93350\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.5209 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93350\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5545 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93350\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5411 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93350\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93350\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0078 - accuracy: 0.9963 - val_loss: 0.4765 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93350\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.5239 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93350\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4889 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93350\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0776 - accuracy: 0.9756 - val_loss: 0.8605 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93350\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.5846 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93350\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0099 - accuracy: 0.9951 - val_loss: 0.6061 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93350\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 1.8077 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93350\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.5173 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93350\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.5554 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93350\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.4520 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93350\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4215 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93350\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 8.9319e-04 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93350\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93350\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.4035 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93350\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 8.5111e-04 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93350\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 6.6261e-04 - accuracy: 1.0000 - val_loss: 0.3590 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93350\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 7.6879e-04 - accuracy: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93350\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 6.1277e-04 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93350\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.6878e-04 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93350\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 6.1821e-04 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93350\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 1.0280e-04 - accuracy: 1.0000 - val_loss: 0.4176 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93350\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.3729 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93350\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 6.4512e-04 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93350\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 2.1579e-04 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93350\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 5.4961e-04 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93350\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 3.0889e-04 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93350\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.3218e-04 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93350\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 2.1922e-04 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93350\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 2.1297e-04 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93350\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 1.1825e-04 - accuracy: 1.0000 - val_loss: 0.4042 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93350\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 1.6879e-04 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93350\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 1.8304e-04 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93350\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 8.5770e-05 - accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93350\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 8.3564e-05 - accuracy: 1.0000 - val_loss: 0.4050 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93350\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 6.8178e-05 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93350\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 3.0276e-04 - accuracy: 1.0000 - val_loss: 0.5392 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93350\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93350\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 7.4738e-04 - accuracy: 1.0000 - val_loss: 0.5139 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93350\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1534 - accuracy: 0.9635 - val_loss: 5.1967 - val_accuracy: 0.5517\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93350\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1235 - accuracy: 0.9622 - val_loss: 1.4496 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93350\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0657 - accuracy: 0.9750 - val_loss: 0.9015 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93350\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0707 - accuracy: 0.9817 - val_loss: 0.7437 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93350\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0501 - accuracy: 0.9854 - val_loss: 0.7905 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93350\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0208 - accuracy: 0.9945 - val_loss: 0.4280 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93350\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.7156 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93350\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0224 - accuracy: 0.9945 - val_loss: 0.5738 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93350\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 12s 230ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.3741 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93350\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93350\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.4879 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93350\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3765 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93350\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3929 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93350\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4642 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93350\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93350\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 6.3488e-04 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93350\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93350\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 6.0612e-04 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93350\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 6.9969e-04 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93350\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4064 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93350\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 7.2850e-04 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93350\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.3515 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93350\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4635 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93350\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93350\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.3872 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93350\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 3.0137e-04 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93350\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 5.6987e-04 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00354: val_accuracy improved from 0.93350 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 3.5139e-04 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93596\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 9.9908e-04 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93596\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 5.9661e-04 - accuracy: 1.0000 - val_loss: 0.4470 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93596\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 3.7416e-04 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93596\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3348 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93596\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4288 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93596\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.4656 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93596\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.5405 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93596\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.3965 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93596\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4906 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93596\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93596\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4353 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93596\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4991 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93596\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.7266 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93596\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.6720 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93596\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.6205 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93596\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.6615 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93596\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0150 - accuracy: 0.9927 - val_loss: 0.6634 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93596\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0076 - accuracy: 0.9963 - val_loss: 0.5612 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93596\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4405 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93596\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93596\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4467 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93596\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.5380 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93596\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.6076 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93596\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.6952 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93596\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0210 - accuracy: 0.9921 - val_loss: 0.5509 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93596\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.6007 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93596\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0699 - accuracy: 0.9811 - val_loss: 0.7515 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93596\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.5171 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93596\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.5079 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93596\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4270 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93596\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3714 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93596\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4653 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93596\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5715 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93596\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.6228 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93596\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.5106 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93596\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.5196 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93596\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4905 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93596\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 8.9370e-04 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93596\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 6.1338e-04 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93596\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.3872 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93596\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.3233 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93596\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5184 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93596\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.5007 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93596\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.5279 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93596\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0453 - accuracy: 0.9842 - val_loss: 0.8537 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93596\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 0.7730 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93596\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0249 - accuracy: 0.9909 - val_loss: 0.8166 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93596\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.7695 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93596\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.5552 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93596\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.5940 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93596\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.5727 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93596\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4826 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93596\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.5015 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93596\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93596\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 5.1547e-04 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.93596\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.0889e-04 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.93596\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 2.3382e-04 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.93596\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 5.9239e-04 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.93596\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 3.4459e-04 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.93596\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 4.8870e-04 - accuracy: 1.0000 - val_loss: 0.6028 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.93596\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.4763 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93596\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 7.3768e-04 - accuracy: 1.0000 - val_loss: 0.5426 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93596\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 6.4803e-04 - accuracy: 1.0000 - val_loss: 0.4855 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93596\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.0676e-04 - accuracy: 1.0000 - val_loss: 0.4775 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93596\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 7.4448e-04 - accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.93596\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.7534e-04 - accuracy: 1.0000 - val_loss: 0.4154 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.93596\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.0762e-04 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93596\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 2.8791e-04 - accuracy: 1.0000 - val_loss: 0.5081 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93596\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 2.6731e-04 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93596\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 1.9934e-04 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93596\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 7.8257e-04 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93596\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 3.4791e-04 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93596\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 1.0593e-04 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93596\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 1.2936e-04 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.93596\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 6.4508e-05 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.93596\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 1.3303e-04 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.93596\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 1.0178e-04 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.93596\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 1.2395e-04 - accuracy: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00433: val_accuracy improved from 0.93596 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 1.5703e-04 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.93842\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 9.5268e-05 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.93842\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 8.5778e-05 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.93842\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 8.3062e-05 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.93842\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 1.5380e-04 - accuracy: 1.0000 - val_loss: 0.4050 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.93842\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 1.4681e-04 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.93842\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 1.7592e-04 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.93842\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.2603e-04 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.93842\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.9049e-05 - accuracy: 1.0000 - val_loss: 0.4946 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.93842\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 6.6707e-04 - accuracy: 0.9994 - val_loss: 0.4681 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.93842\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 1.0821 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.93842\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1462 - accuracy: 0.9610 - val_loss: 2.3809 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.93842\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0759 - accuracy: 0.9775 - val_loss: 1.5060 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.93842\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0714 - accuracy: 0.9787 - val_loss: 0.7704 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.93842\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0229 - accuracy: 0.9963 - val_loss: 0.4568 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.93842\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.4560 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.93842\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.4381 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.93842\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0130 - accuracy: 0.9945 - val_loss: 0.4707 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.93842\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.4444 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.93842\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.3902 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.93842\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.3717 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.93842\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 5.9953e-04 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.93842\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 9.9309e-04 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.93842\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.93842\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 6.4164e-04 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.93842\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 6.9876e-04 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.93842\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 6.2260e-04 - accuracy: 1.0000 - val_loss: 0.4514 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.93842\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4607 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.93842\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4842 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.93842\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 3.4806e-04 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.93842\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 3.0652e-04 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.93842\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 1.7775e-04 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.93842\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 4.2574e-04 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.93842\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 4.5641e-04 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.93842\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.5913e-04 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.93842\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 2.7715e-04 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.93842\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 3.5693e-04 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.93842\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 2.5348e-04 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.93842\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 5.4110e-04 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.93842\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.5809e-04 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.93842\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 2.7895e-04 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.93842\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.5922e-04 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.93842\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.5958e-04 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.93842\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.3035e-04 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.93842\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 1.5658e-04 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.93842\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 4.0760e-04 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.93842\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.4684e-04 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.93842\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 2.5963e-04 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.93842\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.4784e-04 - accuracy: 1.0000 - val_loss: 0.4560 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.93842\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 2.0190e-04 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.93842\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 3.0955e-04 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.93842\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 1.3720e-04 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.93842\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 1.0869e-04 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.93842\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 1.0481e-04 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.93842\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 8.0154e-05 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.93842\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.5502 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.93842\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 1.6236 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.93842\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0467 - accuracy: 0.9842 - val_loss: 1.5101 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.93842\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.6551 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.93842\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0700 - accuracy: 0.9805 - val_loss: 0.7569 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.93842\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0420 - accuracy: 0.9878 - val_loss: 0.8198 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.93842\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.5412 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.93842\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.5795 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.93842\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0111 - accuracy: 0.9951 - val_loss: 0.5556 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.93842\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.4881 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.93842\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4025 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.93842\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5000 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.93842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58a0174bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "165cd32a-e7ae-4f6e-9b44-67c60c91d577"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_224_3_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d852992e-568e-4faf-cda9-48ff88b02ff5"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f46fa49-459c-4216-e69c-f2714dfee6de"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "87e36b56-4b8c-494d-8a4e-463a5f20fcd1"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "569fcd0f-47ce-4dd4-987b-94a7a7fe92cc"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_224_3_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_224_3_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f398d356-3048-4e89-9b52-322849cc3c7e\", \"ImageSize_224_3_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}