{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet101V2_2_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/ResNet101V2_2_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfbbaae3-221d-490b-92ff-ed1f21bf974c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 26 11:51:07 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10218f8-0bf9-4fe3-c68e-775286454801"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "model_save = 'ResNet101V2_2'\n",
        "Target_model = 'ResNet101V2_model'\n",
        "Target_predict = 'ResNet101V2_predict'\n",
        "Target_acc = 'ResNet101V2_acc'\n",
        "Target_val = 'ResNet101V2_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.ResNet101V2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76348c3e-28f4-4500-84ab-7ffa59df1f4a"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c63d4c3-d271-4ce1-bf6c-da518aa44c5f"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 57s 119ms/step - loss: 2.0200 - accuracy: 0.3079 - val_loss: 10.3747 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 1.3399 - accuracy: 0.5500 - val_loss: 4.0260 - val_accuracy: 0.3108\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.10135 to 0.31081, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 1.1472 - accuracy: 0.6158 - val_loss: 1.7915 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.31081 to 0.50000, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.9632 - accuracy: 0.6800 - val_loss: 1.0691 - val_accuracy: 0.6554\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.50000 to 0.65541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.8617 - accuracy: 0.7153 - val_loss: 1.1816 - val_accuracy: 0.6689\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.65541 to 0.66892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7806 - accuracy: 0.7495 - val_loss: 1.6957 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.66892\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7383 - accuracy: 0.7547 - val_loss: 1.1969 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.66892\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.6392 - accuracy: 0.7958 - val_loss: 0.5996 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.66892 to 0.76351, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.6142 - accuracy: 0.7979 - val_loss: 0.5761 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.76351 to 0.81757, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.5922 - accuracy: 0.8079 - val_loss: 0.6441 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.81757\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.5274 - accuracy: 0.8200 - val_loss: 0.4560 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.81757 to 0.82432, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.5345 - accuracy: 0.8253 - val_loss: 0.6709 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.82432\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.4954 - accuracy: 0.8358 - val_loss: 0.8028 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.82432\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.4891 - accuracy: 0.8268 - val_loss: 1.0978 - val_accuracy: 0.6554\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.82432\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.4621 - accuracy: 0.8495 - val_loss: 3.2346 - val_accuracy: 0.4257\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.82432\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.4369 - accuracy: 0.8463 - val_loss: 0.2893 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.82432 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.4515 - accuracy: 0.8468 - val_loss: 0.5537 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.87162\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.4106 - accuracy: 0.8574 - val_loss: 0.7219 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.87162\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.4109 - accuracy: 0.8689 - val_loss: 0.4397 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.87162\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.3900 - accuracy: 0.8658 - val_loss: 0.9470 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.87162\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.3557 - accuracy: 0.8853 - val_loss: 0.8271 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.87162\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.3567 - accuracy: 0.8832 - val_loss: 0.4397 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.87162\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.3383 - accuracy: 0.8879 - val_loss: 0.6576 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.87162\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.3291 - accuracy: 0.8863 - val_loss: 0.4139 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.87162\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.3418 - accuracy: 0.8853 - val_loss: 0.5430 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.87162\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.2664 - accuracy: 0.9021 - val_loss: 0.4012 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.87162\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.3040 - accuracy: 0.9016 - val_loss: 0.6880 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.87162\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.2585 - accuracy: 0.9142 - val_loss: 0.3411 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.87162\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.2649 - accuracy: 0.9047 - val_loss: 0.4981 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.87162\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.2661 - accuracy: 0.9016 - val_loss: 0.6646 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.87162\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.2547 - accuracy: 0.9205 - val_loss: 0.5454 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.87162\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.2306 - accuracy: 0.9211 - val_loss: 0.5559 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.87162\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.2221 - accuracy: 0.9247 - val_loss: 1.0896 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.87162\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.2650 - accuracy: 0.9121 - val_loss: 0.4005 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.87162\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.2465 - accuracy: 0.9205 - val_loss: 0.5352 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.87162\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1997 - accuracy: 0.9363 - val_loss: 0.4595 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.87162\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1831 - accuracy: 0.9342 - val_loss: 0.8121 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.87162\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.2225 - accuracy: 0.9263 - val_loss: 0.5894 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.87162\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.2074 - accuracy: 0.9211 - val_loss: 0.4983 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.87162\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1653 - accuracy: 0.9432 - val_loss: 0.6786 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.87162\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.1819 - accuracy: 0.9389 - val_loss: 0.4215 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.87162 to 0.88514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.1401 - accuracy: 0.9521 - val_loss: 0.4468 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.88514 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.1499 - accuracy: 0.9495 - val_loss: 0.7307 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89189\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1580 - accuracy: 0.9437 - val_loss: 0.7423 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89189\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.1734 - accuracy: 0.9379 - val_loss: 0.4347 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89189\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.1651 - accuracy: 0.9447 - val_loss: 0.5859 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89189\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1273 - accuracy: 0.9511 - val_loss: 0.6581 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89189\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1118 - accuracy: 0.9605 - val_loss: 0.3278 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.89189 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.1557 - accuracy: 0.9442 - val_loss: 0.7552 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.90541\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1427 - accuracy: 0.9521 - val_loss: 0.6041 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.90541\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1295 - accuracy: 0.9563 - val_loss: 0.3213 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.90541\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.1316 - accuracy: 0.9542 - val_loss: 0.5209 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.90541\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1357 - accuracy: 0.9595 - val_loss: 0.5690 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.90541\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0983 - accuracy: 0.9674 - val_loss: 0.4545 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.90541\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1228 - accuracy: 0.9568 - val_loss: 0.4826 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.90541\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0969 - accuracy: 0.9647 - val_loss: 0.4252 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.90541\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1252 - accuracy: 0.9563 - val_loss: 0.4209 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.90541\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.1153 - accuracy: 0.9611 - val_loss: 0.4919 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.90541\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1124 - accuracy: 0.9647 - val_loss: 0.4134 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.90541\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1373 - accuracy: 0.9516 - val_loss: 0.9451 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.90541\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1138 - accuracy: 0.9600 - val_loss: 13.1121 - val_accuracy: 0.1419\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.90541\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1220 - accuracy: 0.9616 - val_loss: 0.6842 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.90541\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0841 - accuracy: 0.9742 - val_loss: 0.5583 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.90541\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1208 - accuracy: 0.9579 - val_loss: 0.4049 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.90541\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1005 - accuracy: 0.9616 - val_loss: 0.7363 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.90541\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0862 - accuracy: 0.9747 - val_loss: 0.3815 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.90541 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0902 - accuracy: 0.9700 - val_loss: 0.6673 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.92568\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0658 - accuracy: 0.9800 - val_loss: 0.4666 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.92568\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0647 - accuracy: 0.9763 - val_loss: 0.2544 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.92568\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0915 - accuracy: 0.9663 - val_loss: 0.4203 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.92568\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.1011 - accuracy: 0.9658 - val_loss: 0.5028 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.92568\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0743 - accuracy: 0.9758 - val_loss: 0.3632 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.92568\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0791 - accuracy: 0.9721 - val_loss: 0.5511 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.92568\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.1122 - accuracy: 0.9589 - val_loss: 1.0871 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.92568\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0846 - accuracy: 0.9674 - val_loss: 0.5318 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.92568\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0388 - accuracy: 0.9879 - val_loss: 0.3621 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.92568\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0440 - accuracy: 0.9832 - val_loss: 0.5315 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.92568\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0896 - accuracy: 0.9732 - val_loss: 0.3931 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.92568\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0698 - accuracy: 0.9800 - val_loss: 5.3952 - val_accuracy: 0.4257\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.92568\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0653 - accuracy: 0.9789 - val_loss: 0.5120 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.92568\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0722 - accuracy: 0.9774 - val_loss: 0.5320 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.92568\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0353 - accuracy: 0.9858 - val_loss: 0.3122 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.92568\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0457 - accuracy: 0.9879 - val_loss: 0.4618 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.92568\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0915 - accuracy: 0.9679 - val_loss: 0.6150 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.92568\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0816 - accuracy: 0.9716 - val_loss: 0.3902 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.92568\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0873 - accuracy: 0.9689 - val_loss: 0.7351 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.92568\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0530 - accuracy: 0.9800 - val_loss: 0.7719 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.92568\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0552 - accuracy: 0.9816 - val_loss: 0.5251 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.92568\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0763 - accuracy: 0.9753 - val_loss: 0.5879 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.92568\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0573 - accuracy: 0.9795 - val_loss: 0.5560 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.92568\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0338 - accuracy: 0.9868 - val_loss: 0.3550 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00091: val_accuracy improved from 0.92568 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0474 - accuracy: 0.9842 - val_loss: 0.4531 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.93243\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0598 - accuracy: 0.9800 - val_loss: 0.4666 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.93243\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0764 - accuracy: 0.9747 - val_loss: 0.7518 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.93243\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0396 - accuracy: 0.9868 - val_loss: 0.3721 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.93243\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0269 - accuracy: 0.9900 - val_loss: 0.4243 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.93243\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.2980 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00097: val_accuracy improved from 0.93243 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.3158 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.93919\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0572 - accuracy: 0.9832 - val_loss: 0.6724 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.93919\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0751 - accuracy: 0.9758 - val_loss: 0.5310 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.93919\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0723 - accuracy: 0.9747 - val_loss: 0.4523 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.93919\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0653 - accuracy: 0.9779 - val_loss: 0.4873 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.93919\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0347 - accuracy: 0.9863 - val_loss: 0.3769 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.93919\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0536 - accuracy: 0.9826 - val_loss: 0.4241 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.93919\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0583 - accuracy: 0.9805 - val_loss: 0.7467 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.93919\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0625 - accuracy: 0.9805 - val_loss: 0.5136 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.93919\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.4563 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.93919\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.3789 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.93919\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0688 - accuracy: 0.9805 - val_loss: 0.6711 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.93919\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0798 - accuracy: 0.9742 - val_loss: 0.5022 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.93919\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0578 - accuracy: 0.9858 - val_loss: 0.5501 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.93919\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0416 - accuracy: 0.9858 - val_loss: 0.4934 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.93919\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0105 - accuracy: 0.9984 - val_loss: 0.3930 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.93919\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0311 - accuracy: 0.9874 - val_loss: 0.5313 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.93919\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0277 - accuracy: 0.9937 - val_loss: 0.3859 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.93919\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0390 - accuracy: 0.9895 - val_loss: 0.3499 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.93919\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0432 - accuracy: 0.9853 - val_loss: 0.6634 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.93919\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0317 - accuracy: 0.9889 - val_loss: 0.4984 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.93919\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0534 - accuracy: 0.9826 - val_loss: 0.5576 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.93919\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0458 - accuracy: 0.9858 - val_loss: 0.4085 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.93919\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0330 - accuracy: 0.9879 - val_loss: 0.3522 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.93919\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 0.5140 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.93919\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0409 - accuracy: 0.9868 - val_loss: 0.4518 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.93919\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0484 - accuracy: 0.9832 - val_loss: 0.5531 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.93919\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0590 - accuracy: 0.9816 - val_loss: 0.5649 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.93919\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0396 - accuracy: 0.9858 - val_loss: 0.5786 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.93919\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.4607 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.93919\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0298 - accuracy: 0.9884 - val_loss: 0.5942 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.93919\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.3705 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.93919\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.0500 - accuracy: 0.9816 - val_loss: 0.5608 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.93919\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0663 - accuracy: 0.9832 - val_loss: 0.4360 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.93919\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.0405 - accuracy: 0.9874 - val_loss: 0.4024 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.93919\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.3988 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.93919\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.4537 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.93919\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.5866 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.93919\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0490 - accuracy: 0.9842 - val_loss: 2.0706 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.93919\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0523 - accuracy: 0.9837 - val_loss: 0.5840 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.93919\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0225 - accuracy: 0.9916 - val_loss: 0.3298 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.93919\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.4820 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.93919\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0279 - accuracy: 0.9916 - val_loss: 0.5104 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.93919\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.3991 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.93919\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0153 - accuracy: 0.9937 - val_loss: 0.3789 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.93919\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.0358 - accuracy: 0.9858 - val_loss: 0.4351 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.93919\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0663 - accuracy: 0.9805 - val_loss: 0.5210 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93919\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0278 - accuracy: 0.9900 - val_loss: 0.6019 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93919\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0340 - accuracy: 0.9895 - val_loss: 0.6214 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93919\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0326 - accuracy: 0.9874 - val_loss: 0.6386 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93919\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0334 - accuracy: 0.9889 - val_loss: 0.6783 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93919\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 0.4361 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93919\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.6763 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93919\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.5432 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93919\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.5267 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93919\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0923 - accuracy: 0.9742 - val_loss: 0.5606 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93919\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.4893 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.93919\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.5071 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93919\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 0.5536 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93919\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0284 - accuracy: 0.9889 - val_loss: 0.5369 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93919\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0329 - accuracy: 0.9905 - val_loss: 0.9343 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.93919\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.6215 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.93919\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0154 - accuracy: 0.9937 - val_loss: 0.5693 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.93919\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.4584 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.93919\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.4926 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.93919\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.4689 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.93919\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.5907 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.93919\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 0.6052 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.93919\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0386 - accuracy: 0.9853 - val_loss: 0.7453 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.93919\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0783 - accuracy: 0.9753 - val_loss: 0.6724 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.93919\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 0.7226 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.93919\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0314 - accuracy: 0.9911 - val_loss: 0.4341 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.93919\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.4279 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.93919\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.5091 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.93919\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0355 - accuracy: 0.9900 - val_loss: 0.5561 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.93919\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0306 - accuracy: 0.9874 - val_loss: 0.4232 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.93919\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.5664 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.93919\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.3514 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.93919\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.4925 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.93919\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0421 - accuracy: 0.9879 - val_loss: 0.5570 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.93919\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0403 - accuracy: 0.9837 - val_loss: 0.6079 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.93919\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0361 - accuracy: 0.9889 - val_loss: 0.6254 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93919\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.5211 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93919\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.5593 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93919\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0163 - accuracy: 0.9926 - val_loss: 0.4097 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93919\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.2976 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93919\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0088 - accuracy: 0.9953 - val_loss: 0.5042 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93919\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0479 - accuracy: 0.9874 - val_loss: 0.6236 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93919\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0327 - accuracy: 0.9895 - val_loss: 0.4710 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93919\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.3612 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93919\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0354 - accuracy: 0.9889 - val_loss: 0.4026 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93919\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0171 - accuracy: 0.9932 - val_loss: 0.3425 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93919\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.4270 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93919\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.5734 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93919\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.7950 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93919\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0361 - accuracy: 0.9858 - val_loss: 0.5287 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93919\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0136 - accuracy: 0.9979 - val_loss: 0.4076 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93919\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0367 - accuracy: 0.9879 - val_loss: 0.4929 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93919\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 0.4741 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93919\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.5557 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93919\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0272 - accuracy: 0.9884 - val_loss: 0.6569 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93919\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0273 - accuracy: 0.9926 - val_loss: 0.5329 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93919\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.6490 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93919\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.6577 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93919\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0192 - accuracy: 0.9921 - val_loss: 0.7209 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93919\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0510 - accuracy: 0.9863 - val_loss: 0.4659 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93919\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0130 - accuracy: 0.9947 - val_loss: 0.5343 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93919\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.5630 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93919\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.5300 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93919\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.4540 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93919\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.4562 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93919\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0245 - accuracy: 0.9911 - val_loss: 0.7014 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93919\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.4213 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93919\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 0.5061 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93919\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.3850 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93919\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.4180 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93919\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.4515 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93919\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.7191 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93919\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0148 - accuracy: 0.9974 - val_loss: 0.4428 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93919\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.4013 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93919\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4081 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93919\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93919\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0211 - accuracy: 0.9953 - val_loss: 0.8446 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93919\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0370 - accuracy: 0.9905 - val_loss: 0.4941 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93919\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0658 - accuracy: 0.9805 - val_loss: 0.7352 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93919\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0140 - accuracy: 0.9937 - val_loss: 0.5527 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93919\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.5718 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93919\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.5425 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93919\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0074 - accuracy: 0.9968 - val_loss: 0.6416 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93919\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0302 - accuracy: 0.9932 - val_loss: 0.6798 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93919\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.4369 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93919\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.5511 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93919\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.5908 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93919\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.5539 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93919\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0332 - accuracy: 0.9895 - val_loss: 0.7350 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93919\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0506 - accuracy: 0.9863 - val_loss: 0.5253 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93919\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.4900 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93919\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.4005 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93919\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0101 - accuracy: 0.9947 - val_loss: 0.4117 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93919\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.3753 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93919\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.5658 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93919\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.4727 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93919\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.6097 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93919\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0171 - accuracy: 0.9937 - val_loss: 0.7939 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93919\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.6121 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93919\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.6945 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93919\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.5099 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93919\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.3325 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93919\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.6407 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93919\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0272 - accuracy: 0.9889 - val_loss: 0.5237 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93919\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.5081 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93919\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.3625 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93919\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.4715 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93919\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.5244 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93919\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0139 - accuracy: 0.9932 - val_loss: 0.4982 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93919\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0108 - accuracy: 0.9984 - val_loss: 0.3815 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00253: val_accuracy improved from 0.93919 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0457 - accuracy: 0.9826 - val_loss: 0.8962 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.94595\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.4933 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.94595\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 0.4109 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.94595\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.5376 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.94595\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 0.4388 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.94595\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.3678 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.94595\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0072 - accuracy: 0.9958 - val_loss: 0.4541 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.94595\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.4866 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.94595\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.4781 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.94595\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.5674 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.94595\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.5539 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.94595\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.5632 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.94595\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.7307 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.94595\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0339 - accuracy: 0.9858 - val_loss: 0.5660 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.94595\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.5931 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.94595\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.5406 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.94595\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.7254 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.94595\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.4396 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.94595\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3959 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.94595\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.4971 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.94595\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0283 - accuracy: 0.9942 - val_loss: 0.6572 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.94595\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.3537 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.94595\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.94595\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4151 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.94595\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0110 - accuracy: 0.9947 - val_loss: 0.5923 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.94595\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0310 - accuracy: 0.9879 - val_loss: 0.6117 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.94595\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0409 - accuracy: 0.9884 - val_loss: 0.4567 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.94595\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0112 - accuracy: 0.9953 - val_loss: 0.4726 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.94595\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.4318 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.94595\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.94595\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.94595\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.5093 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.94595\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.4821 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.94595\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 8.6997e-04 - accuracy: 1.0000 - val_loss: 0.5198 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.94595\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.3538 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.94595\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0596 - accuracy: 0.9832 - val_loss: 0.6864 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.94595\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0373 - accuracy: 0.9863 - val_loss: 0.4013 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.94595\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.4593 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.94595\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.4324 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.94595\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.94595\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.94595\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0016 - accuracy: 0.9989 - val_loss: 0.3331 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.94595\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.4336 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.94595\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0401 - accuracy: 0.9863 - val_loss: 0.5113 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.94595\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.4998 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.94595\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0258 - accuracy: 0.9937 - val_loss: 0.3831 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.94595\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.5103 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.94595\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0193 - accuracy: 0.9953 - val_loss: 0.4819 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.94595\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.3873 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.94595\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.5102 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.94595\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0256 - accuracy: 0.9905 - val_loss: 0.5539 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.94595\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0131 - accuracy: 0.9979 - val_loss: 0.4585 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.94595\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.4951 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.94595\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.4531 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.94595\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.3820 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.94595\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.3494 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.94595\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.4520 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.94595\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0229 - accuracy: 0.9953 - val_loss: 0.6189 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.94595\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.5367 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.94595\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.5691 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.94595\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0246 - accuracy: 0.9942 - val_loss: 0.4561 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.94595\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.3953 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.94595\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.2596 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.94595\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.3293 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.94595\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.94595\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3667 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.94595\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0126 - accuracy: 0.9942 - val_loss: 0.5543 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.94595\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0189 - accuracy: 0.9926 - val_loss: 0.7496 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.94595\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.6164 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.94595\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.7743 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.94595\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.4574 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.94595\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4655 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.94595\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.5537 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.94595\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.5838 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.94595\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.9226 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.94595\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.3704 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.94595\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.3706 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.94595\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.6019 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.94595\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.3772 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.94595\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0066 - accuracy: 0.9968 - val_loss: 0.4310 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.94595\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.3482 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.94595\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.5539 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.94595\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.6733 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.94595\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0189 - accuracy: 0.9926 - val_loss: 0.6323 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.94595\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0147 - accuracy: 0.9942 - val_loss: 0.4232 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.94595\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0185 - accuracy: 0.9911 - val_loss: 0.4912 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.94595\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.6077 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.94595\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.4323 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.94595\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.7343 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.94595\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.5012 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.94595\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.94595\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 7.8924e-04 - accuracy: 1.0000 - val_loss: 0.4404 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.94595\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 9.3624e-04 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.94595\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 4.4901e-04 - accuracy: 1.0000 - val_loss: 0.6726 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.94595\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.6773 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.94595\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0425 - accuracy: 0.9868 - val_loss: 0.4803 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.94595\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.5199 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.94595\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 0.6327 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.94595\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.94595\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5533 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.94595\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.8038 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.94595\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0135 - accuracy: 0.9942 - val_loss: 1.0040 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.94595\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 0.5709 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.94595\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.5517 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.94595\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.7880 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.94595\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.3815 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.94595\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 9.6244e-04 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.94595\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.5693 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.94595\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.5614 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.94595\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.5695 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.94595\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.5120 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.94595\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.4382 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.94595\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.6272 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.94595\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.4350 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.94595\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0420 - accuracy: 0.9905 - val_loss: 0.6277 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.94595\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0347 - accuracy: 0.9900 - val_loss: 0.4789 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.94595\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.4062 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.94595\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.5746 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.94595\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.4782 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.94595\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.3786 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.94595\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4945 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.94595\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.94595\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.3848 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.94595\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3493 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.94595\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.6989 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.94595\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.3542 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.94595\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.4429 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.94595\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.4866 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.94595\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.8928 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.94595\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0182 - accuracy: 0.9926 - val_loss: 0.4712 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.94595\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.3766 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.94595\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.94595\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.4918 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94595\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.3781 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94595\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.4429 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94595\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 0.7806 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94595\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.4842 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94595\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.5918 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94595\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.4946 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94595\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 0.5956 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94595\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0262 - accuracy: 0.9947 - val_loss: 0.4864 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94595\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.4052 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94595\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.4875 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94595\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.4092 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94595\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.4405 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94595\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.5221 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.94595\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.5163 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94595\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.5690 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94595\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.4543 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94595\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94595\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 7.9499e-04 - accuracy: 1.0000 - val_loss: 0.5187 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94595\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.5952 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94595\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0384 - accuracy: 0.9916 - val_loss: 0.5374 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94595\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.5755 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94595\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 0.6198 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94595\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.5396 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94595\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.6083 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94595\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.4494 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94595\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3649 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94595\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.3771 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94595\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4142 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94595\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0040 - accuracy: 0.9979 - val_loss: 0.4753 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94595\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.4966 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94595\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0348 - accuracy: 0.9911 - val_loss: 0.6576 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94595\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.5498 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94595\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.8642 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94595\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 0.4876 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94595\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 9.9323e-04 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94595\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.4459 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94595\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.5356 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94595\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.4960 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94595\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4437 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94595\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6699 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94595\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.5081 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94595\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.4794 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94595\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0395 - accuracy: 0.9884 - val_loss: 0.4994 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94595\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.5412 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94595\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 0.5131 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94595\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.5096 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94595\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.5228 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94595\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0114 - accuracy: 0.9947 - val_loss: 0.6559 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94595\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.3818 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94595\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.4649 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94595\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 9.4558e-04 - accuracy: 1.0000 - val_loss: 0.4806 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94595\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4225 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94595\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.4801 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94595\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.5701 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94595\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.7424 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94595\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.8079 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94595\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.5472 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94595\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.4811 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94595\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.4206 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94595\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.6944 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94595\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.5666 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94595\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.6042 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94595\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.4411 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94595\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.7291 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94595\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.4402 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94595\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.5176 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94595\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.3827 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94595\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.4443 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94595\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 6.2435e-04 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94595\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.5422 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94595\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.6225 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94595\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.7956 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94595\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.5137 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94595\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.5929 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94595\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5243 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94595\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 9.3064e-04 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94595\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94595\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.3136 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94595\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3290 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00465: val_accuracy improved from 0.94595 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_2.h5\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.6790 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95270\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.4952 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95270\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.4998 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95270\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0157 - accuracy: 0.9937 - val_loss: 0.5040 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95270\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.5520 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95270\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.4522 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95270\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0158 - accuracy: 0.9968 - val_loss: 0.6321 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95270\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0099 - accuracy: 0.9958 - val_loss: 0.8079 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95270\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.6292 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95270\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 9.2914e-04 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95270\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.6413 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95270\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.4884 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95270\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.6770 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95270\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.5421 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95270\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.4980 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95270\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0250 - accuracy: 0.9932 - val_loss: 0.3696 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95270\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0055 - accuracy: 0.9968 - val_loss: 0.5304 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95270\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4999 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95270\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95270\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.4196 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95270\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.6708 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95270\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.5577 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95270\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4465 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95270\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.5762 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95270\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5881 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95270\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.7023 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95270\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.6636 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95270\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.6580 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95270\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.4932 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95270\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0100 - accuracy: 0.9947 - val_loss: 0.4269 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95270\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 7.9598e-04 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95270\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95270\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 4.7498e-04 - accuracy: 1.0000 - val_loss: 0.4362 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95270\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4704 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95270\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.6487 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2f5272f190>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b837a860-1579-4714-f1a0-7a5a3ab63d3d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce13b338-ea07-4a70-a73a-0e8b31e63361"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZ06MWjdN2l"
      },
      "source": [
        "!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKDp3mdOZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e34a8f-25ea-4350-b5f4-31e692c3030a"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    # \n",
        "    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n",
        "    # d9249@kyonggi.ac.kr\n",
        "    #  ID\n",
        "    '235626',\n",
        "    # d9249@kyonggi.ac.kr \n",
        "    # 'iDeal9',\n",
        "    # dodo9249@gmail.com \n",
        "    'iDeal96',\n",
        "    # d9249.acc001@gmail.com\n",
        "    # 'iDeal01',\n",
        "    # memo\n",
        "    'd9249_kyonggi_ac_kr' )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'isSubmitted': True, 'detail': 'Success'}\n"
          ]
        }
      ]
    }
  ]
}