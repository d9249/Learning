{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HeightShiftRange_010_1_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPLqNsOG5SzmyEZRkXtl74j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/HeightShiftRange_010_1_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a07a5b4-320e-4255-f2b7-10de78a52f8e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep  1 15:25:37 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e33014-efcf-46b9-eb31-cfc38f8ed366"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1fe91eb-ee91-47ac-f7bb-4367726bc405"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ad60d8-69e3-4ba5-9ce8-17001e878ad1"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea38ece3-1056-43a8-8df1-84ecfdf74e86"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 39s 264ms/step - loss: 1.8258 - accuracy: 0.3825 - val_loss: 3.6343 - val_accuracy: 0.1108\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 1.1534 - accuracy: 0.6066 - val_loss: 5.1492 - val_accuracy: 0.0591\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.11084\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.9201 - accuracy: 0.7010 - val_loss: 7.4739 - val_accuracy: 0.0665\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.11084\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.7736 - accuracy: 0.7412 - val_loss: 7.2816 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.11084\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.7131 - accuracy: 0.7704 - val_loss: 4.4956 - val_accuracy: 0.1034\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.11084\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.5730 - accuracy: 0.8057 - val_loss: 3.0946 - val_accuracy: 0.1847\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.11084 to 0.18473, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.5944 - accuracy: 0.8033 - val_loss: 3.5420 - val_accuracy: 0.3202\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.18473 to 0.32020, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.5011 - accuracy: 0.8252 - val_loss: 7.2586 - val_accuracy: 0.1749\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.32020\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.5127 - accuracy: 0.8076 - val_loss: 2.1643 - val_accuracy: 0.5468\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.32020 to 0.54680, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.4620 - accuracy: 0.8441 - val_loss: 1.3459 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.54680 to 0.67488, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.4443 - accuracy: 0.8465 - val_loss: 2.9597 - val_accuracy: 0.4754\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.67488\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.4271 - accuracy: 0.8569 - val_loss: 0.6380 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.67488 to 0.80542, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.3252 - accuracy: 0.8946 - val_loss: 1.1435 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.80542\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.3500 - accuracy: 0.8806 - val_loss: 0.8849 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.80542\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.2791 - accuracy: 0.9056 - val_loss: 0.7134 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.80542\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.3141 - accuracy: 0.8916 - val_loss: 0.6779 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.80542\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.3127 - accuracy: 0.9001 - val_loss: 0.7251 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.80542\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.3053 - accuracy: 0.8873 - val_loss: 0.9003 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.80542\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.2708 - accuracy: 0.9050 - val_loss: 0.5449 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.80542 to 0.83498, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.2203 - accuracy: 0.9281 - val_loss: 0.9015 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.83498\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.2926 - accuracy: 0.9019 - val_loss: 3.4682 - val_accuracy: 0.4901\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.83498\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.2560 - accuracy: 0.9117 - val_loss: 0.6544 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.83498\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.2455 - accuracy: 0.9214 - val_loss: 0.9684 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.83498\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1927 - accuracy: 0.9324 - val_loss: 0.6482 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.83498\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1801 - accuracy: 0.9421 - val_loss: 0.7903 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.83498\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1838 - accuracy: 0.9361 - val_loss: 0.5279 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.83498\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1915 - accuracy: 0.9354 - val_loss: 0.6423 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.83498\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.2011 - accuracy: 0.9324 - val_loss: 0.7892 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.83498\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1854 - accuracy: 0.9373 - val_loss: 0.5718 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.83498 to 0.84236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1509 - accuracy: 0.9470 - val_loss: 0.7086 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.84236\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1446 - accuracy: 0.9501 - val_loss: 0.9906 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.84236\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1537 - accuracy: 0.9446 - val_loss: 0.5726 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.84236\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1691 - accuracy: 0.9385 - val_loss: 0.6161 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.84236\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1115 - accuracy: 0.9616 - val_loss: 0.6157 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.84236\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1535 - accuracy: 0.9476 - val_loss: 1.0209 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.84236\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1325 - accuracy: 0.9507 - val_loss: 0.7375 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.84236\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1283 - accuracy: 0.9513 - val_loss: 1.1577 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.84236\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1212 - accuracy: 0.9598 - val_loss: 0.9683 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.84236\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1387 - accuracy: 0.9543 - val_loss: 0.8994 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.84236\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1356 - accuracy: 0.9562 - val_loss: 0.7138 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.84236\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1156 - accuracy: 0.9622 - val_loss: 0.4300 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.84236 to 0.89163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0811 - accuracy: 0.9714 - val_loss: 0.8358 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89163\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1717 - accuracy: 0.9446 - val_loss: 0.6675 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89163\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1417 - accuracy: 0.9495 - val_loss: 0.4869 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89163\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0807 - accuracy: 0.9756 - val_loss: 0.4513 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89163\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0861 - accuracy: 0.9720 - val_loss: 0.4744 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89163\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0935 - accuracy: 0.9726 - val_loss: 0.3885 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89163\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0765 - accuracy: 0.9732 - val_loss: 0.4304 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89163\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0992 - accuracy: 0.9659 - val_loss: 0.8130 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89163\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.1191 - accuracy: 0.9598 - val_loss: 0.6518 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89163\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0920 - accuracy: 0.9689 - val_loss: 0.4940 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89163\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1150 - accuracy: 0.9592 - val_loss: 0.3271 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.89163 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0857 - accuracy: 0.9641 - val_loss: 1.6962 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.90640\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0888 - accuracy: 0.9689 - val_loss: 0.6001 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.90640\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0750 - accuracy: 0.9762 - val_loss: 0.5120 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.90640\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0609 - accuracy: 0.9817 - val_loss: 0.4154 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.90640\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0770 - accuracy: 0.9762 - val_loss: 0.4783 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.90640\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0945 - accuracy: 0.9659 - val_loss: 0.5031 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.90640\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0757 - accuracy: 0.9787 - val_loss: 0.4933 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.90640\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0476 - accuracy: 0.9817 - val_loss: 0.7245 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.90640\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0429 - accuracy: 0.9860 - val_loss: 0.5471 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.90640\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1268 - accuracy: 0.9568 - val_loss: 0.9930 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.90640\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1170 - accuracy: 0.9555 - val_loss: 0.8819 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.90640\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1289 - accuracy: 0.9647 - val_loss: 0.5808 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.90640\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1170 - accuracy: 0.9549 - val_loss: 0.8348 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.90640\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0799 - accuracy: 0.9726 - val_loss: 0.5458 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.90640\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0786 - accuracy: 0.9799 - val_loss: 0.6387 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.90640\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0569 - accuracy: 0.9787 - val_loss: 0.4280 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.90640\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.3987 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.90640\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0184 - accuracy: 0.9957 - val_loss: 0.4252 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.90640\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0491 - accuracy: 0.9872 - val_loss: 0.5149 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.90640\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0506 - accuracy: 0.9811 - val_loss: 0.4425 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.90640\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0576 - accuracy: 0.9805 - val_loss: 0.5799 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90640\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 0.5769 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.90640\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0379 - accuracy: 0.9896 - val_loss: 0.9965 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.90640\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.2089 - accuracy: 0.9373 - val_loss: 1.9639 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.90640\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0851 - accuracy: 0.9695 - val_loss: 0.6208 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.90640\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1025 - accuracy: 0.9647 - val_loss: 0.3818 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.90640 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0417 - accuracy: 0.9872 - val_loss: 0.4775 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.90887\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0643 - accuracy: 0.9781 - val_loss: 0.6464 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.90887\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0853 - accuracy: 0.9732 - val_loss: 0.6374 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.90887\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0584 - accuracy: 0.9805 - val_loss: 0.7674 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.90887\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0302 - accuracy: 0.9903 - val_loss: 0.4733 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.90887\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.5044 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.90887\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0721 - accuracy: 0.9726 - val_loss: 0.4978 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.90887\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 0.4044 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.90887\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.4094 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.90887\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.4564 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.90887\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0172 - accuracy: 0.9970 - val_loss: 0.5144 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.90887\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0302 - accuracy: 0.9915 - val_loss: 0.6399 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.90887\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0415 - accuracy: 0.9866 - val_loss: 0.7416 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.90887\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0224 - accuracy: 0.9915 - val_loss: 0.4549 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.90887\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0282 - accuracy: 0.9896 - val_loss: 0.6546 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.90887\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0849 - accuracy: 0.9769 - val_loss: 1.3011 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.90887\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0960 - accuracy: 0.9641 - val_loss: 1.1415 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.90887\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.1029 - accuracy: 0.9677 - val_loss: 0.6206 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.90887\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0572 - accuracy: 0.9805 - val_loss: 0.5901 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.90887\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0469 - accuracy: 0.9817 - val_loss: 0.8032 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.90887\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0545 - accuracy: 0.9860 - val_loss: 1.1657 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.90887\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0575 - accuracy: 0.9829 - val_loss: 1.1889 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.90887\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0368 - accuracy: 0.9866 - val_loss: 0.5518 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.90887\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.4073 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.90887\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.5547 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.90887\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.3596 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00104: val_accuracy improved from 0.90887 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4322 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91133\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.3727 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91133\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.4209 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91133\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00108: val_accuracy improved from 0.91133 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.5372 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91872\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.6015 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91872\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0207 - accuracy: 0.9921 - val_loss: 0.5367 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91872\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.5758 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91872\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0621 - accuracy: 0.9805 - val_loss: 0.8317 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91872\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0510 - accuracy: 0.9805 - val_loss: 0.6809 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91872\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0770 - accuracy: 0.9756 - val_loss: 0.7399 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91872\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1639 - accuracy: 0.9488 - val_loss: 2.4467 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91872\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1299 - accuracy: 0.9488 - val_loss: 1.2540 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91872\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0636 - accuracy: 0.9799 - val_loss: 1.1392 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91872\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0439 - accuracy: 0.9836 - val_loss: 0.5122 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91872\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0379 - accuracy: 0.9884 - val_loss: 0.4452 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91872\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.4942 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91872\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0892 - accuracy: 0.9726 - val_loss: 0.6309 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91872\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0536 - accuracy: 0.9854 - val_loss: 0.4950 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91872\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0279 - accuracy: 0.9890 - val_loss: 0.3581 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91872\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0352 - accuracy: 0.9866 - val_loss: 0.5458 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91872\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0402 - accuracy: 0.9903 - val_loss: 0.5264 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91872\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.5091 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91872\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.5929 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91872\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0180 - accuracy: 0.9933 - val_loss: 0.4272 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91872\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.3941 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00130: val_accuracy improved from 0.91872 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.3881 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.92611\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.4275 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.92611\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3814 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.92611\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.92611\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.92611\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00136: val_accuracy improved from 0.92611 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9507\n",
            "\n",
            "Epoch 00137: val_accuracy improved from 0.93350 to 0.95074, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 8.1288e-04 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.95074\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.3881 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.95074\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.95074\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0073 - accuracy: 0.9994 - val_loss: 0.4114 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.95074\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5861 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.95074\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.9521 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.95074\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0422 - accuracy: 0.9842 - val_loss: 0.4877 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.95074\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0470 - accuracy: 0.9829 - val_loss: 1.2124 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.95074\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0488 - accuracy: 0.9836 - val_loss: 0.7607 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.95074\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0454 - accuracy: 0.9817 - val_loss: 0.5180 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.95074\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0493 - accuracy: 0.9829 - val_loss: 0.8754 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.95074\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0848 - accuracy: 0.9762 - val_loss: 0.7839 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.95074\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0556 - accuracy: 0.9787 - val_loss: 0.6668 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.95074\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.6064 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.95074\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 0.4806 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.95074\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.5139 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.95074\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0542 - accuracy: 0.9811 - val_loss: 0.5917 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.95074\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0850 - accuracy: 0.9689 - val_loss: 1.0331 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.95074\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0543 - accuracy: 0.9799 - val_loss: 0.9051 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.95074\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0340 - accuracy: 0.9903 - val_loss: 0.6124 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.95074\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0152 - accuracy: 0.9939 - val_loss: 0.4660 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.95074\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0480 - accuracy: 0.9848 - val_loss: 0.8713 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.95074\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0549 - accuracy: 0.9805 - val_loss: 0.6748 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.95074\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0149 - accuracy: 0.9939 - val_loss: 0.4397 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.95074\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.4754 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.95074\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 1.0195 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.95074\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.8245 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.95074\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.4486 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.95074\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.4613 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.95074\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.5114 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.95074\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.5138 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.95074\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.4667 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.95074\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.3673 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.95074\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0064 - accuracy: 0.9970 - val_loss: 0.3685 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.95074\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.3995 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.95074\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4559 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.95074\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.5042 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.95074\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.4704 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.95074\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.6811 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.95074\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.5279 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.95074\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.7199 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.95074\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.7038 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.95074\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.4774 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.95074\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0554 - accuracy: 0.9811 - val_loss: 0.8956 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.95074\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0710 - accuracy: 0.9775 - val_loss: 1.3401 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.95074\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0548 - accuracy: 0.9793 - val_loss: 0.8239 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.95074\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0609 - accuracy: 0.9769 - val_loss: 1.2231 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.95074\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0522 - accuracy: 0.9848 - val_loss: 0.5421 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.95074\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0419 - accuracy: 0.9848 - val_loss: 0.5219 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.95074\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.5065 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.95074\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.4363 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.95074\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.3981 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.95074\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.3938 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.95074\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.6076 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.95074\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0838 - accuracy: 0.9787 - val_loss: 0.6062 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.95074\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 0.6136 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.95074\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.4793 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.95074\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0106 - accuracy: 0.9945 - val_loss: 0.5671 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.95074\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.6471 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.95074\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5867 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.95074\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5768 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.95074\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.95074\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.4366 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.95074\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4145 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.95074\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.95074\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 8.0793e-04 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.95074\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.95074\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 8.3323e-04 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.95074\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4894 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.95074\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3980 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.95074\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 9.8684e-04 - accuracy: 1.0000 - val_loss: 0.3932 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.95074\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4774 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.95074\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.95074\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 7.1790e-04 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.95074\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 8.8682e-04 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.95074\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 9.8553e-04 - accuracy: 0.9994 - val_loss: 0.4687 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.95074\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.6499 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.95074\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4618 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.95074\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.5263 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.95074\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 1.1426 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.95074\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0753 - accuracy: 0.9769 - val_loss: 1.5901 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.95074\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.1624 - accuracy: 0.9507 - val_loss: 3.2758 - val_accuracy: 0.5862\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.95074\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.1050 - accuracy: 0.9647 - val_loss: 1.1400 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.95074\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0869 - accuracy: 0.9726 - val_loss: 0.9018 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.95074\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 0.8120 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.95074\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.6461 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.95074\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0192 - accuracy: 0.9915 - val_loss: 0.6961 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.95074\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0096 - accuracy: 0.9957 - val_loss: 0.5628 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.95074\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.5220 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.95074\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.5132 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.95074\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.4533 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.95074\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.4656 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.95074\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.95074\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4046 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.95074\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.95074\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.3845 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.95074\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4192 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.95074\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0134 - accuracy: 0.9939 - val_loss: 0.6988 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.95074\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.5473 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.95074\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.7093 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.95074\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.5905 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.95074\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0181 - accuracy: 0.9933 - val_loss: 0.9897 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.95074\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.6189 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.95074\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.5505 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.95074\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.5030 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.95074\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.4167 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.95074\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.4096 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.95074\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4753 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.95074\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.7821 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.95074\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0463 - accuracy: 0.9854 - val_loss: 0.8624 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.95074\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0376 - accuracy: 0.9866 - val_loss: 1.0155 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.95074\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.5403 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.95074\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.5815 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.95074\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.5669 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.95074\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.4335 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.95074\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.4400 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.95074\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0823 - accuracy: 0.9756 - val_loss: 1.5623 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.95074\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.1324 - accuracy: 0.9598 - val_loss: 1.1954 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.95074\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0795 - accuracy: 0.9738 - val_loss: 0.8711 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.95074\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0162 - accuracy: 0.9933 - val_loss: 0.5429 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.95074\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.4469 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.95074\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4301 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.95074\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.4178 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.95074\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0077 - accuracy: 0.9957 - val_loss: 0.4309 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.95074\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4129 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.95074\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.95074\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.95074\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 7.8766e-04 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.95074\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.95074\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 9.2208e-04 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.95074\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 4.4520e-04 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.95074\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.95074\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 6.5346e-04 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.95074\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 2.9685e-04 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.95074\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.95074\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 5.0637e-04 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.95074\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 3.7680e-04 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.95074\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 4.2758e-04 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.95074\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 3.0857e-04 - accuracy: 1.0000 - val_loss: 0.3590 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.95074\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 5.2656e-04 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.95074\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 2.3126e-04 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.95074\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 2.4507e-04 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.95074\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 3.9247e-04 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.95074\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 4.8260e-04 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.95074\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0427 - accuracy: 0.9866 - val_loss: 1.1825 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.95074\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0883 - accuracy: 0.9781 - val_loss: 0.8282 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.95074\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0391 - accuracy: 0.9878 - val_loss: 0.7560 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.95074\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0259 - accuracy: 0.9884 - val_loss: 0.6773 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.95074\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.7357 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.95074\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.4007 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.95074\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.5065 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.95074\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.4429 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.95074\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5159 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.95074\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4526 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.95074\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.5275 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.95074\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0284 - accuracy: 0.9903 - val_loss: 0.5986 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.95074\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0274 - accuracy: 0.9933 - val_loss: 0.4477 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.95074\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.4582 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.95074\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.6062 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.95074\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.4203 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.95074\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4899 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.95074\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.4788 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.95074\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.6516 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.95074\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4766 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.95074\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4335 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.95074\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 1.1018 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.95074\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.8224 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.95074\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0225 - accuracy: 0.9909 - val_loss: 0.6174 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.95074\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.95074\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0310 - accuracy: 0.9909 - val_loss: 0.6447 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.95074\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0387 - accuracy: 0.9872 - val_loss: 0.5525 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.95074\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0400 - accuracy: 0.9866 - val_loss: 0.7055 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.95074\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.6868 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.95074\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.7601 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.95074\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5799 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.95074\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.3932 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.95074\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.4943 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.95074\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.5909 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.95074\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0208 - accuracy: 0.9915 - val_loss: 0.7314 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.95074\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.5560 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.95074\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.3781 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.95074\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.4896 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.95074\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.95074\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.95074\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 7.3872e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.95074\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 4.2494e-04 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.95074\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 5.5567e-04 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.95074\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 3.1938e-04 - accuracy: 1.0000 - val_loss: 0.4623 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.95074\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 4.1602e-04 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.95074\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 3.0252e-04 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.95074\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 1.9172e-04 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.95074\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 2.4017e-04 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.95074\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 3.7048e-04 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.95074\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 3.1266e-04 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.95074\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.4499 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.95074\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 6.6161e-04 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.95074\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 6.5921e-04 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.95074\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 4.6022e-04 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.95074\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 2.5213e-04 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.95074\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 3.3474e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.95074\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 7.0574e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.95074\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 1.0797 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.95074\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0528 - accuracy: 0.9866 - val_loss: 0.9983 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.95074\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.8120 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95074\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.5298 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95074\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.6311 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95074\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.8768 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95074\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95074\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.4969 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95074\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0597 - accuracy: 0.9793 - val_loss: 0.8039 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95074\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0343 - accuracy: 0.9915 - val_loss: 0.6202 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95074\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0289 - accuracy: 0.9939 - val_loss: 0.4710 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95074\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.4614 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95074\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.5660 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95074\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 0.5097 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95074\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.5013 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95074\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95074\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 9.5868e-04 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95074\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.6640 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95074\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.5859 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95074\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0056 - accuracy: 0.9970 - val_loss: 0.4141 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95074\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.4603 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95074\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5227 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95074\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.5817 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95074\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.5104 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95074\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5313 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95074\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0238 - accuracy: 0.9945 - val_loss: 0.6387 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95074\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.5706 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95074\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0347 - accuracy: 0.9909 - val_loss: 0.6873 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95074\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.5979 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95074\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5309 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95074\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.5697 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95074\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.6941 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95074\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.6306 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95074\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0062 - accuracy: 0.9970 - val_loss: 0.5126 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95074\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4482 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95074\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5448 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95074\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 5.6661e-04 - accuracy: 1.0000 - val_loss: 0.5150 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95074\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 7.9087e-04 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95074\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 3.4028e-04 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95074\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 3.7889e-04 - accuracy: 1.0000 - val_loss: 0.4567 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95074\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 3.5034e-04 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95074\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0050 - accuracy: 0.9970 - val_loss: 0.4910 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95074\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 0.4825 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95074\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.3785 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95074\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95074\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 9.5424e-04 - accuracy: 1.0000 - val_loss: 0.4189 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95074\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4343 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95074\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.4304 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95074\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0240 - accuracy: 0.9945 - val_loss: 0.7239 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95074\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0398 - accuracy: 0.9866 - val_loss: 0.8372 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95074\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0462 - accuracy: 0.9860 - val_loss: 0.6921 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95074\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0348 - accuracy: 0.9890 - val_loss: 0.6230 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95074\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 0.6874 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95074\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.5481 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95074\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.4560 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95074\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.4872 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95074\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.3811 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95074\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0175 - accuracy: 0.9970 - val_loss: 0.4741 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95074\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.3860 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95074\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95074\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 7.5846e-04 - accuracy: 1.0000 - val_loss: 0.3512 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95074\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 6.6987e-04 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95074\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 5.9020e-04 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95074\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 6.6517e-04 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95074\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 6.2754e-04 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95074\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 3.9745e-04 - accuracy: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95074\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 2.7258e-04 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95074\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 12s 232ms/step - loss: 2.1721e-04 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95074\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 11s 213ms/step - loss: 3.4455e-04 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95074\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 8.8412e-04 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95074\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 5.7323e-04 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95074\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 6.7186e-04 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95074\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 2.4193e-04 - accuracy: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95074\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 5.0239e-04 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95074\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 4.4966e-04 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95074\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 2.4166e-04 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95074\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 2.0303e-04 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95074\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 2.1432e-04 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95074\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 1.2115e-04 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95074\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 1.6457e-04 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95074\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 1.0701e-04 - accuracy: 1.0000 - val_loss: 0.4197 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95074\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 1.2525e-04 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95074\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 1.7816e-04 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95074\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 1.0063e-04 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95074\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 6.8926e-05 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95074\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 1.5992e-04 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95074\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 1.0215e-04 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95074\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 2.3357e-04 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95074\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 5.3180e-04 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95074\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 2.2088e-04 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95074\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.7573 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95074\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0553 - accuracy: 0.9811 - val_loss: 2.6091 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95074\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.1897 - accuracy: 0.9513 - val_loss: 3.6182 - val_accuracy: 0.5764\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95074\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0555 - accuracy: 0.9842 - val_loss: 1.0087 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95074\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 0.5176 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95074\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5281 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95074\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.4847 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95074\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3819 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95074\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4186 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95074\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4396 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95074\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.5088 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95074\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.6173 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95074\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0094 - accuracy: 0.9988 - val_loss: 0.5214 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95074\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4185 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95074\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4830 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95074\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95074\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.5270 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95074\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4845 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95074\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4511 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95074\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95074\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 4.5273e-04 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95074\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95074\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4231 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95074\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 6.1852e-04 - accuracy: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95074\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 2.7902e-04 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95074\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.6321 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95074\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0110 - accuracy: 0.9982 - val_loss: 0.5061 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95074\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.6609 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95074\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.7631 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95074\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.4977 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95074\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.6074 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95074\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.8984 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95074\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0384 - accuracy: 0.9860 - val_loss: 1.7971 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95074\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0269 - accuracy: 0.9945 - val_loss: 1.0374 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95074\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.5097 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95074\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.4691 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95074\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4112 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95074\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.5477 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95074\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95074\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 8.5764e-04 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95074\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.6353 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95074\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0093 - accuracy: 0.9945 - val_loss: 0.6858 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95074\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.4817 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95074\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.8381 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95074\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0215 - accuracy: 0.9945 - val_loss: 0.6118 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95074\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0103 - accuracy: 0.9957 - val_loss: 0.5665 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95074\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.5113 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95074\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5318 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95074\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0344 - accuracy: 0.9927 - val_loss: 0.7334 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95074\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.5562 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95074\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95074\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4006 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95074\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4140 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95074\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4787 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95074\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 8.7404e-04 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95074\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95074\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 7.3411e-04 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95074\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 2.8008e-04 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95074\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 2.6347e-04 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95074\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5796 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95074\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.4341 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95074\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 3.7213e-04 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95074\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 4.5814e-04 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95074\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6015 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95074\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5022 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95074\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.4139 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95074\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 5.0613e-04 - accuracy: 1.0000 - val_loss: 0.3989 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95074\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.6703 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95074\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6011 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95074\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 6.4480e-04 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95074\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 4.3094e-04 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95074\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 2.1602e-04 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95074\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f055217dfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b325cd0d-2510-4f76-c556-18c5e2e78350"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_1_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb347256-ee6a-4feb-b26e-d1a6a05d45c8"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50137d99-e930-497d-f999-96a85f62b16b"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "670ad0a6-3690-438e-cba6-4a949dd87a82"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "37674a52-6500-4d2b-ae1c-be69a85f7159"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_010_1_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_010_1_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3616f84e-1159-466a-ac06-ed3aa9057c26\", \"HeightShiftRange_010_1_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}