{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HeightShiftRange_010_5_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNbiyjdyUAmhEai6hZvEHL8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/HeightShiftRange_010_5_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce53855e-cee8-4692-b785-a15c0eb29fbc"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep  1 19:19:33 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd4b63b-5839-439f-b774-0af023253a9f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c831ef-2ac2-4724-9077-90526b3b0eb7"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425aafd8-72ca-4150-e97f-dd96e7e856f2"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f2e28f-df22-46f9-fe43-60f40c9d4b54"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 42s 284ms/step - loss: 1.8604 - accuracy: 0.3374 - val_loss: 7.4583 - val_accuracy: 0.1059\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10591, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 1.2218 - accuracy: 0.5798 - val_loss: 17.5511 - val_accuracy: 0.1108\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.10591 to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.9077 - accuracy: 0.6876 - val_loss: 7.2299 - val_accuracy: 0.1034\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.11084\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.8037 - accuracy: 0.7406 - val_loss: 7.2991 - val_accuracy: 0.0690\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.11084\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.7179 - accuracy: 0.7600 - val_loss: 4.3021 - val_accuracy: 0.1773\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.11084 to 0.17734, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.6180 - accuracy: 0.7978 - val_loss: 5.0941 - val_accuracy: 0.1626\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.17734\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.6021 - accuracy: 0.7966 - val_loss: 2.9365 - val_accuracy: 0.3153\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.17734 to 0.31527, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.5618 - accuracy: 0.8076 - val_loss: 3.4719 - val_accuracy: 0.3424\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.31527 to 0.34236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.4680 - accuracy: 0.8453 - val_loss: 2.5239 - val_accuracy: 0.4754\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.34236 to 0.47537, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.4242 - accuracy: 0.8605 - val_loss: 1.5089 - val_accuracy: 0.5887\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.47537 to 0.58867, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.4211 - accuracy: 0.8520 - val_loss: 0.9395 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.58867 to 0.71921, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.4427 - accuracy: 0.8538 - val_loss: 1.0453 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.71921\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.3533 - accuracy: 0.8703 - val_loss: 1.5730 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.71921\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.3241 - accuracy: 0.8916 - val_loss: 0.7877 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.71921 to 0.79064, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.3231 - accuracy: 0.8965 - val_loss: 0.9439 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.79064\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.3304 - accuracy: 0.8855 - val_loss: 0.8244 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.79064\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.2758 - accuracy: 0.9050 - val_loss: 3.9046 - val_accuracy: 0.3867\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.79064\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.2756 - accuracy: 0.9105 - val_loss: 0.7822 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.79064\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.2452 - accuracy: 0.9184 - val_loss: 1.1368 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.79064\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.2348 - accuracy: 0.9129 - val_loss: 1.0257 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.79064\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.2370 - accuracy: 0.9184 - val_loss: 0.8141 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.79064\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.2135 - accuracy: 0.9263 - val_loss: 0.9450 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.79064\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.2200 - accuracy: 0.9184 - val_loss: 1.4491 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.79064\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.1980 - accuracy: 0.9342 - val_loss: 0.7666 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.79064\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.1936 - accuracy: 0.9287 - val_loss: 0.7755 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.79064\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.2020 - accuracy: 0.9373 - val_loss: 0.4679 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.79064 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.2066 - accuracy: 0.9251 - val_loss: 0.7712 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.86946\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.1828 - accuracy: 0.9385 - val_loss: 0.5816 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.86946\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 12s 219ms/step - loss: 0.1386 - accuracy: 0.9537 - val_loss: 0.4846 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.86946 to 0.87438, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.1471 - accuracy: 0.9470 - val_loss: 0.5687 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.87438\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.1657 - accuracy: 0.9452 - val_loss: 0.6791 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.87438\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 12s 223ms/step - loss: 0.1419 - accuracy: 0.9531 - val_loss: 0.7086 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.87438\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.1308 - accuracy: 0.9513 - val_loss: 0.6206 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.87438\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.1257 - accuracy: 0.9598 - val_loss: 0.6728 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.87438\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.1088 - accuracy: 0.9635 - val_loss: 0.7024 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.87438\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.1417 - accuracy: 0.9488 - val_loss: 0.9114 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.87438\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.2544 - accuracy: 0.9190 - val_loss: 2.1608 - val_accuracy: 0.5961\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.87438\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.1512 - accuracy: 0.9507 - val_loss: 0.6165 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.87438\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.1166 - accuracy: 0.9592 - val_loss: 0.5462 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.87438\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0839 - accuracy: 0.9732 - val_loss: 0.3741 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.87438 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0680 - accuracy: 0.9781 - val_loss: 0.3493 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.88670 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0979 - accuracy: 0.9659 - val_loss: 0.6674 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.90148\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.1198 - accuracy: 0.9568 - val_loss: 0.4590 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.90148\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.1542 - accuracy: 0.9507 - val_loss: 0.7271 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.90148\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0991 - accuracy: 0.9635 - val_loss: 0.6696 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.90148\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.1274 - accuracy: 0.9531 - val_loss: 0.5058 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.90148\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0947 - accuracy: 0.9689 - val_loss: 0.5014 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.90148\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.1139 - accuracy: 0.9653 - val_loss: 0.5275 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.90148\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0707 - accuracy: 0.9756 - val_loss: 0.5556 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.90148\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0939 - accuracy: 0.9702 - val_loss: 1.0941 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.90148\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 12s 223ms/step - loss: 0.0569 - accuracy: 0.9787 - val_loss: 0.3652 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.90148 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0287 - accuracy: 0.9933 - val_loss: 0.3248 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.90640\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0513 - accuracy: 0.9842 - val_loss: 0.4553 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.90640\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0543 - accuracy: 0.9854 - val_loss: 0.7878 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.90640\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 12s 219ms/step - loss: 0.0999 - accuracy: 0.9695 - val_loss: 0.6344 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.90640\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0920 - accuracy: 0.9689 - val_loss: 0.5567 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.90640\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.1278 - accuracy: 0.9598 - val_loss: 0.8165 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.90640\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 12s 219ms/step - loss: 0.1152 - accuracy: 0.9616 - val_loss: 0.8452 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.90640\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0473 - accuracy: 0.9872 - val_loss: 0.4507 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.90640\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0513 - accuracy: 0.9805 - val_loss: 0.9883 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.90640\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0948 - accuracy: 0.9689 - val_loss: 0.9660 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.90640\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.1474 - accuracy: 0.9470 - val_loss: 1.4990 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.90640\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.1163 - accuracy: 0.9629 - val_loss: 0.7064 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.90640\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.1253 - accuracy: 0.9568 - val_loss: 0.9799 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.90640\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0697 - accuracy: 0.9750 - val_loss: 0.6295 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.90640\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0411 - accuracy: 0.9890 - val_loss: 0.5390 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.90640\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0421 - accuracy: 0.9848 - val_loss: 0.3844 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.90640\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.3922 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.90640\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.4143 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.90640\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.6837 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.90640\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0596 - accuracy: 0.9799 - val_loss: 0.6162 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.90640\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0574 - accuracy: 0.9805 - val_loss: 0.6073 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.90640\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0320 - accuracy: 0.9909 - val_loss: 0.4422 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90640\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.3671 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.90640\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.4443 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.90640\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0648 - accuracy: 0.9781 - val_loss: 1.6584 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.90640\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.1020 - accuracy: 0.9647 - val_loss: 0.7541 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.90640\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0481 - accuracy: 0.9842 - val_loss: 0.6271 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.90640\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 12s 219ms/step - loss: 0.0515 - accuracy: 0.9848 - val_loss: 1.0732 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.90640\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.1127 - accuracy: 0.9592 - val_loss: 0.9379 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.90640\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0865 - accuracy: 0.9720 - val_loss: 0.6600 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.90640\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0544 - accuracy: 0.9817 - val_loss: 0.6367 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.90640\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0697 - accuracy: 0.9738 - val_loss: 0.5297 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.90640\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0969 - accuracy: 0.9677 - val_loss: 1.4518 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.90640\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0493 - accuracy: 0.9836 - val_loss: 0.4428 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.90640\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0401 - accuracy: 0.9884 - val_loss: 0.5986 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.90640\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 0.5681 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.90640\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 0.6060 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.90640\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0622 - accuracy: 0.9799 - val_loss: 0.8657 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.90640\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0567 - accuracy: 0.9836 - val_loss: 0.5022 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.90640\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 12s 219ms/step - loss: 0.0395 - accuracy: 0.9848 - val_loss: 0.5615 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.90640\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.5277 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.90640\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0151 - accuracy: 0.9939 - val_loss: 0.3278 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00093: val_accuracy improved from 0.90640 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.4117 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91379\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0519 - accuracy: 0.9842 - val_loss: 0.4558 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91379\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0643 - accuracy: 0.9781 - val_loss: 0.8302 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91379\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0747 - accuracy: 0.9769 - val_loss: 0.5146 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91379\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.1006 - accuracy: 0.9702 - val_loss: 0.7879 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91379\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0813 - accuracy: 0.9720 - val_loss: 0.6820 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91379\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.5941 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91379\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.5032 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91379\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.3579 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00102: val_accuracy improved from 0.91379 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.4073 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.92365\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.5402 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.92365\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 11s 222ms/step - loss: 0.0215 - accuracy: 0.9915 - val_loss: 0.3948 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.92365\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0257 - accuracy: 0.9890 - val_loss: 0.5234 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.92365\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0490 - accuracy: 0.9805 - val_loss: 0.7931 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.92365\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0576 - accuracy: 0.9848 - val_loss: 0.9553 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.92365\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0691 - accuracy: 0.9775 - val_loss: 0.8010 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.92365\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0430 - accuracy: 0.9872 - val_loss: 0.4983 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.92365\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0093 - accuracy: 0.9988 - val_loss: 0.4336 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.92365\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.4452 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.92365\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.7720 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.92365\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0446 - accuracy: 0.9866 - val_loss: 1.0584 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.92365\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0521 - accuracy: 0.9860 - val_loss: 0.7977 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.92365\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0438 - accuracy: 0.9878 - val_loss: 0.7000 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.92365\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0388 - accuracy: 0.9866 - val_loss: 0.8801 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.92365\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0346 - accuracy: 0.9896 - val_loss: 0.6697 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.92365\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.4614 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.92365\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.4204 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.92365\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.5457 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.92365\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4093 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.92365\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.4400 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.92365\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.4319 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.92365\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.4074 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.92365\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0056 - accuracy: 0.9970 - val_loss: 0.4178 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.92365\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.6096 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.92365\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0467 - accuracy: 0.9823 - val_loss: 5.1264 - val_accuracy: 0.5222\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.92365\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.1189 - accuracy: 0.9659 - val_loss: 1.0932 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.92365\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.1015 - accuracy: 0.9629 - val_loss: 1.5824 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.92365\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0627 - accuracy: 0.9781 - val_loss: 0.8358 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.92365\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0470 - accuracy: 0.9836 - val_loss: 0.5103 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.92365\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0261 - accuracy: 0.9909 - val_loss: 0.6984 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.92365\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.5583 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.92365\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0239 - accuracy: 0.9909 - val_loss: 0.6923 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.92365\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.6126 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.92365\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.6389 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.92365\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.6624 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.92365\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.5250 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.92365\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.4137 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.92365\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4126 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.92365\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.4137 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.92365\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.4737 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.92365\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.4143 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.92365\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4849 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.92365\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0137 - accuracy: 0.9939 - val_loss: 0.8181 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.92365\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.8319 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.92365\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0759 - accuracy: 0.9805 - val_loss: 0.7950 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.92365\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0663 - accuracy: 0.9793 - val_loss: 1.0812 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.92365\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0765 - accuracy: 0.9738 - val_loss: 0.8785 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.92365\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0404 - accuracy: 0.9842 - val_loss: 1.0097 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.92365\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0763 - accuracy: 0.9781 - val_loss: 0.8565 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.92365\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0581 - accuracy: 0.9805 - val_loss: 0.8691 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.92365\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0823 - accuracy: 0.9769 - val_loss: 0.6163 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92365\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0520 - accuracy: 0.9866 - val_loss: 0.7301 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92365\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 0.5107 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92365\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.4145 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92365\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.5537 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92365\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.5470 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92365\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.4100 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92365\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.4239 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92365\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0089 - accuracy: 0.9957 - val_loss: 0.4284 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92365\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0193 - accuracy: 0.9915 - val_loss: 0.5922 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92365\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.4471 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92365\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.4114 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92365\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.4278 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92365\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92365\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00168: val_accuracy improved from 0.92365 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.3764 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92611\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.6171 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92611\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0102 - accuracy: 0.9951 - val_loss: 0.5270 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92611\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.4429 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92611\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.4759 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92611\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.5425 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92611\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0183 - accuracy: 0.9970 - val_loss: 0.6001 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92611\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0250 - accuracy: 0.9890 - val_loss: 0.8835 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92611\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0380 - accuracy: 0.9896 - val_loss: 1.1792 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92611\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0473 - accuracy: 0.9848 - val_loss: 0.8226 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92611\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0500 - accuracy: 0.9829 - val_loss: 1.1373 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92611\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0672 - accuracy: 0.9787 - val_loss: 1.1781 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92611\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0788 - accuracy: 0.9775 - val_loss: 0.9821 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92611\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0522 - accuracy: 0.9817 - val_loss: 0.7361 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92611\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0290 - accuracy: 0.9933 - val_loss: 0.7588 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92611\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0449 - accuracy: 0.9842 - val_loss: 0.5653 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92611\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0193 - accuracy: 0.9927 - val_loss: 0.5163 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92611\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.5012 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92611\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0159 - accuracy: 0.9970 - val_loss: 0.5280 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92611\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.6623 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92611\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.6328 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92611\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0285 - accuracy: 0.9903 - val_loss: 0.6171 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92611\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0326 - accuracy: 0.9903 - val_loss: 0.4910 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92611\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0183 - accuracy: 0.9963 - val_loss: 0.5435 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92611\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0069 - accuracy: 0.9957 - val_loss: 0.4706 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92611\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.3989 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92611\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5099 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92611\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4071 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92611\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.3822 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92611\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.5530 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92611\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4867 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92611\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5006 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92611\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4596 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92611\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92611\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.3619 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92611\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.4889 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92611\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.4244 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92611\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.6220 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92611\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4689 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92611\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4174 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92611\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4415 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92611\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4747 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92611\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92611\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4160 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92611\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92611\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92611\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92611\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 6.7639e-04 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.92611\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4645 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92611\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.5367 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92611\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.5204 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92611\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.5643 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92611\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0284 - accuracy: 0.9903 - val_loss: 0.8666 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.92611\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 11s 222ms/step - loss: 0.0677 - accuracy: 0.9793 - val_loss: 1.8685 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.92611\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0778 - accuracy: 0.9762 - val_loss: 1.6023 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.92611\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 12s 219ms/step - loss: 0.1540 - accuracy: 0.9604 - val_loss: 4.3957 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.92611\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0593 - accuracy: 0.9769 - val_loss: 1.2329 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.92611\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 12s 219ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.4073 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.92611\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 11s 221ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.4639 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92611\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.3983 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92611\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0055 - accuracy: 0.9970 - val_loss: 0.3419 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92611\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0443 - accuracy: 0.9878 - val_loss: 1.0352 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92611\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0320 - accuracy: 0.9884 - val_loss: 0.9016 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92611\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0384 - accuracy: 0.9903 - val_loss: 0.5120 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92611\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.9437 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92611\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.5014 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92611\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.4776 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92611\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.3877 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92611\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92611\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92611\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3664 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92611\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.3631 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92611\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.3059 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00241: val_accuracy improved from 0.92611 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93103\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4104 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93103\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.3093 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00244: val_accuracy improved from 0.93103 to 0.94335, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.94335\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4124 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.94335\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.94335\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4197 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.94335\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.94335\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 7.0666e-04 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.94335\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0397 - accuracy: 0.9921 - val_loss: 0.7733 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.94335\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0488 - accuracy: 0.9848 - val_loss: 2.2367 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.94335\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0560 - accuracy: 0.9793 - val_loss: 0.6027 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.94335\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0596 - accuracy: 0.9829 - val_loss: 0.5202 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.94335\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.5700 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.94335\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.4470 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.94335\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.3867 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.94335\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.4344 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.94335\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.4191 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.94335\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.3893 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.94335\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 12s 223ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3887 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.94335\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0222 - accuracy: 0.9951 - val_loss: 0.5449 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.94335\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 1.3017 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.94335\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0433 - accuracy: 0.9890 - val_loss: 0.6413 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.94335\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0430 - accuracy: 0.9896 - val_loss: 0.7613 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.94335\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0289 - accuracy: 0.9896 - val_loss: 1.3431 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.94335\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0358 - accuracy: 0.9921 - val_loss: 0.8163 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.94335\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0421 - accuracy: 0.9854 - val_loss: 0.8227 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.94335\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.6324 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.94335\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.6349 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.94335\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.7370 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.94335\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5391 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.94335\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 0.7976 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.94335\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.94335\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 11s 222ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.5552 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.94335\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4988 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.94335\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4738 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.94335\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.94335\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 5.3687e-04 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.94335\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 4.3711e-04 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.94335\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 4.4980e-04 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.94335\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.6460 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.94335\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.8497 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.94335\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4745 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.94335\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0617 - accuracy: 0.9866 - val_loss: 1.2601 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.94335\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.5930 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.94335\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.9356 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.94335\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0290 - accuracy: 0.9890 - val_loss: 0.5940 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.94335\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0289 - accuracy: 0.9866 - val_loss: 0.9180 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.94335\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.5141 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.94335\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4855 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.94335\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4584 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.94335\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 8.3629e-04 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.94335\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 0.4836 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.94335\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.94335\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.94335\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3802 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.94335\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 8.1908e-04 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.94335\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 3.5817e-04 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.94335\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 7.1267e-04 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.94335\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 3.5126e-04 - accuracy: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.94335\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 3.7791e-04 - accuracy: 1.0000 - val_loss: 0.3821 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.94335\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 12s 219ms/step - loss: 2.4518e-04 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.94335\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 3.0327e-04 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.94335\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 7.7327e-04 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.94335\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 4.4734e-04 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.94335\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 5.1742e-04 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.94335\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 7.1710e-04 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.94335\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 3.1548e-04 - accuracy: 1.0000 - val_loss: 0.3760 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.94335\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 5.0150e-04 - accuracy: 1.0000 - val_loss: 0.3893 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.94335\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 2.6849e-04 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.94335\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 2.0822e-04 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.94335\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 3.6175e-04 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.94335\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 5.4367e-04 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.94335\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 3.7192 - val_accuracy: 0.5764\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.94335\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0449 - accuracy: 0.9860 - val_loss: 3.8687 - val_accuracy: 0.5049\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.94335\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.1282 - accuracy: 0.9635 - val_loss: 2.4800 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.94335\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.1029 - accuracy: 0.9708 - val_loss: 1.2946 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.94335\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0860 - accuracy: 0.9811 - val_loss: 0.9591 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.94335\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.5591 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.94335\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.4103 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.94335\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.4809 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.94335\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0464 - accuracy: 0.9909 - val_loss: 0.9488 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.94335\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.5882 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.94335\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.5922 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.94335\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.4130 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.94335\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.94335\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 9.0024e-04 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.94335\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 8.6909e-04 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.94335\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 7.6076e-04 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.94335\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.94335\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.94335\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.94335\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.94335\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 3.3988e-04 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.94335\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 6.1569e-04 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.94335\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 5.0449e-04 - accuracy: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.94335\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 5.6936e-04 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.94335\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 3.1065e-04 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.94335\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 4.0274e-04 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.94335\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 3.4002e-04 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.94335\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 2.5798e-04 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.94335\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 2.4626e-04 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.94335\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5298 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.94335\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4300 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.94335\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5733 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.94335\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5019 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.94335\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.5752 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.94335\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.4711 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.94335\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.8528 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.94335\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0372 - accuracy: 0.9915 - val_loss: 0.8761 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.94335\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0751 - accuracy: 0.9769 - val_loss: 1.4541 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.94335\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.8043 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.94335\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0394 - accuracy: 0.9872 - val_loss: 0.7670 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.94335\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0373 - accuracy: 0.9890 - val_loss: 0.5946 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.94335\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.7956 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.94335\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.5459 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.94335\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4467 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.94335\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.94335\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4230 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.94335\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4823 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.94335\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 8.1996e-04 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.94335\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3858 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.94335\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4140 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.94335\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.94335\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0268 - accuracy: 0.9896 - val_loss: 0.7227 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.94335\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0524 - accuracy: 0.9836 - val_loss: 0.8009 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.94335\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0183 - accuracy: 0.9927 - val_loss: 1.3167 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.94335\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0215 - accuracy: 0.9909 - val_loss: 0.9696 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.94335\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.5295 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.94335\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5741 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.94335\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.94335\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.94335\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4714 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.94335\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 8.0168e-04 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.94335\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 6.4999e-04 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.94335\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 11s 221ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.4180 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.94335\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 8.6495e-04 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.94335\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.94335\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5731 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.94335\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 0.7311 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.94335\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.5915 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.94335\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.6882 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.94335\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.5706 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.94335\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 1.3602 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.94335\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 1.0641 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94335\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0195 - accuracy: 0.9957 - val_loss: 0.6737 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94335\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.5823 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94335\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.6048 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94335\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.6620 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94335\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5260 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94335\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94335\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3930 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94335\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4907 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94335\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.5320 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94335\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 12s 219ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4655 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94335\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94335\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94335\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 8.8857e-04 - accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.94335\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.9120 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94335\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0304 - accuracy: 0.9890 - val_loss: 0.6729 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94335\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0299 - accuracy: 0.9890 - val_loss: 0.9919 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94335\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.6232 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94335\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.4982 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94335\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4286 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94335\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94335\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 9.9787e-04 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94335\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.6202 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94335\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.7468 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94335\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0365 - accuracy: 0.9903 - val_loss: 0.7626 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94335\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0408 - accuracy: 0.9860 - val_loss: 0.8815 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94335\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.4678 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94335\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94335\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4544 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94335\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 1.2230 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94335\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.6775 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94335\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.5716 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94335\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.6551 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94335\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94335\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 9.9805e-04 - accuracy: 1.0000 - val_loss: 0.5269 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94335\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 3.7364e-04 - accuracy: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94335\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 12s 219ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4147 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94335\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 5.1825e-04 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94335\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 4.2628e-04 - accuracy: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94335\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 6.7180e-04 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94335\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 5.2604e-04 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94335\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 3.7012e-04 - accuracy: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94335\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 4.0199e-04 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94335\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 1.4617e-04 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94335\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 6.3207e-04 - accuracy: 1.0000 - val_loss: 0.5351 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94335\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.6348 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94335\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0243 - accuracy: 0.9945 - val_loss: 0.9012 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94335\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0286 - accuracy: 0.9921 - val_loss: 0.6882 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94335\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0143 - accuracy: 0.9939 - val_loss: 1.2867 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94335\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 11s 213ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 1.0132 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94335\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 0.9816 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94335\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 1.7428 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94335\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.6934 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94335\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.8075 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94335\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.6293 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94335\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.5601 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94335\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.6613 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94335\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.5485 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94335\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0108 - accuracy: 0.9957 - val_loss: 0.6463 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94335\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.7753 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94335\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.4810 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94335\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.9494 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94335\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5544 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94335\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5180 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94335\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5644 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94335\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.4835 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94335\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.5276 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94335\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94335\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 4.0687e-04 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94335\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4764 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94335\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 1.9824e-04 - accuracy: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94335\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 3.7273e-04 - accuracy: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94335\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 3.9354e-04 - accuracy: 1.0000 - val_loss: 0.4430 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94335\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 6.1176e-04 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94335\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 7.3930e-04 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94335\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4280 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94335\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 4.3335e-04 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94335\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 3.1852e-04 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94335\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 5.0744e-04 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94335\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 4.2804e-04 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94335\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 1.5823e-04 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94335\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 1.4841e-04 - accuracy: 1.0000 - val_loss: 0.4455 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94335\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 9.8665e-04 - accuracy: 0.9994 - val_loss: 0.5323 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94335\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0278 - accuracy: 0.9903 - val_loss: 1.1655 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94335\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 0.9254 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94335\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0147 - accuracy: 0.9939 - val_loss: 0.4827 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94335\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0089 - accuracy: 0.9957 - val_loss: 0.6748 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94335\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.4913 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94335\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.5774 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94335\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.5971 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94335\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.6659 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94335\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4962 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94335\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.4907 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94335\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.8790 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94335\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.8391 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94335\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.0334 - accuracy: 0.9903 - val_loss: 0.8155 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94335\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.9186 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94335\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.8494 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94335\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 9.5921e-04 - accuracy: 1.0000 - val_loss: 0.6289 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94335\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 7.5544e-04 - accuracy: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94335\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5883 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94335\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 5.1149e-04 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94335\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.3963 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94335\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 2.5015 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94335\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 0.9010 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94335\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.6110 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94335\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.5445 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94335\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0117 - accuracy: 0.9988 - val_loss: 0.4694 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94335\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 7.8298e-04 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94335\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5508 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94335\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4654 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94335\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 9.1531e-04 - accuracy: 0.9994 - val_loss: 0.4692 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94335\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0332 - accuracy: 0.9915 - val_loss: 2.9886 - val_accuracy: 0.5887\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94335\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 1.4063 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94335\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0362 - accuracy: 0.9909 - val_loss: 0.7358 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94335\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81c26fb810>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0c5e8841-d9f5-49e6-917f-4c034429465f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_5_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388ddcbe-43c8-4703-f7d3-03d8b5ce9fed"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "48e8da6d-7d15-4071-8ac1-10cb87aefd75"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_010_5_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_010_5_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_417aa5d1-db71-4d46-b88f-11f5b7db1b38\", \"HeightShiftRange_010_5_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    }
  ]
}