{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HeightShiftRange_030_5_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKhZx64NwvkAFCYzRoBdv6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/HeightShiftRange_030_5_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81792b6b-725a-4120-dd1e-1590473fd77f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep  3 13:22:50 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e00177-fa4b-4885-c68f-9c6121a4a7ec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7cca3b0-c2f4-4ee8-996d-e5c02dbc28ab"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f8b31b-5c23-456c-c900-ac5a53c7ad95"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.3)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e958205-bbaf-4a33-dcff-607ca8b00411"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 53s 467ms/step - loss: 2.0121 - accuracy: 0.2826 - val_loss: 6.8619 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09606, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 19s 365ms/step - loss: 1.4585 - accuracy: 0.4842 - val_loss: 15.3134 - val_accuracy: 0.1084\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.09606 to 0.10837, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 1.1237 - accuracy: 0.6181 - val_loss: 3.0844 - val_accuracy: 0.0788\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.10837\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 19s 371ms/step - loss: 0.9893 - accuracy: 0.6510 - val_loss: 14.7067 - val_accuracy: 0.1084\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.10837\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 19s 373ms/step - loss: 0.8612 - accuracy: 0.7132 - val_loss: 12.4936 - val_accuracy: 0.1158\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.10837 to 0.11576, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 20s 375ms/step - loss: 0.7919 - accuracy: 0.7381 - val_loss: 4.8348 - val_accuracy: 0.2537\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.11576 to 0.25369, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 20s 376ms/step - loss: 0.7634 - accuracy: 0.7345 - val_loss: 6.0727 - val_accuracy: 0.2069\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.25369\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 0.6818 - accuracy: 0.7698 - val_loss: 3.2558 - val_accuracy: 0.2980\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.25369 to 0.29803, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 20s 376ms/step - loss: 0.6335 - accuracy: 0.7887 - val_loss: 5.1701 - val_accuracy: 0.3251\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.29803 to 0.32512, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 0.6341 - accuracy: 0.7789 - val_loss: 1.2420 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.32512 to 0.62562, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.5705 - accuracy: 0.8076 - val_loss: 1.0186 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.62562 to 0.70936, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.5237 - accuracy: 0.8149 - val_loss: 0.9356 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.70936\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.4757 - accuracy: 0.8435 - val_loss: 1.1145 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.70936 to 0.71182, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.4677 - accuracy: 0.8453 - val_loss: 1.2212 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.71182\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.4034 - accuracy: 0.8648 - val_loss: 0.8702 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.71182 to 0.72660, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.3882 - accuracy: 0.8648 - val_loss: 1.0635 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.72660\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.3208 - accuracy: 0.8812 - val_loss: 1.1335 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.72660\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.3978 - accuracy: 0.8654 - val_loss: 1.9170 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.72660\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.4129 - accuracy: 0.8551 - val_loss: 1.0714 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.72660\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.3576 - accuracy: 0.8776 - val_loss: 0.6562 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.72660 to 0.82266, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.3437 - accuracy: 0.8825 - val_loss: 3.0683 - val_accuracy: 0.4778\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.82266\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.3407 - accuracy: 0.8800 - val_loss: 0.6774 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.82266\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.3120 - accuracy: 0.8928 - val_loss: 1.0153 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.82266\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.2890 - accuracy: 0.9026 - val_loss: 0.8115 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.82266\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.2883 - accuracy: 0.9050 - val_loss: 0.6795 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.82266\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.2587 - accuracy: 0.9117 - val_loss: 0.7583 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.82266\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.2864 - accuracy: 0.9038 - val_loss: 0.9337 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.82266\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.2628 - accuracy: 0.9080 - val_loss: 0.5483 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.82266 to 0.82759, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.2280 - accuracy: 0.9166 - val_loss: 0.4374 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.82759 to 0.87438, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.2576 - accuracy: 0.9214 - val_loss: 0.8805 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.87438\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.3155 - accuracy: 0.8934 - val_loss: 0.9482 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.87438\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.2518 - accuracy: 0.9086 - val_loss: 0.5338 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.87438\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.2206 - accuracy: 0.9239 - val_loss: 0.5471 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.87438\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.2256 - accuracy: 0.9239 - val_loss: 0.5600 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.87438\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.2004 - accuracy: 0.9312 - val_loss: 0.4881 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.87438\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.2319 - accuracy: 0.9147 - val_loss: 0.6559 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.87438\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.2028 - accuracy: 0.9348 - val_loss: 0.6453 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.87438\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.2206 - accuracy: 0.9233 - val_loss: 0.6462 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.87438\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.2147 - accuracy: 0.9294 - val_loss: 0.8593 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.87438\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1923 - accuracy: 0.9361 - val_loss: 0.5323 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.87438\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1702 - accuracy: 0.9391 - val_loss: 0.4802 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.87438\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1643 - accuracy: 0.9397 - val_loss: 0.6317 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.87438\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.2033 - accuracy: 0.9251 - val_loss: 0.4032 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.87438\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1442 - accuracy: 0.9501 - val_loss: 0.6800 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.87438\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1808 - accuracy: 0.9415 - val_loss: 0.6153 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.87438\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1494 - accuracy: 0.9488 - val_loss: 0.5059 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.87438\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1343 - accuracy: 0.9488 - val_loss: 0.5075 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.87438\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1511 - accuracy: 0.9507 - val_loss: 0.7882 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.87438\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1272 - accuracy: 0.9592 - val_loss: 0.4390 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.87438\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1490 - accuracy: 0.9452 - val_loss: 0.4880 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.87438\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1460 - accuracy: 0.9507 - val_loss: 0.8247 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.87438\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1207 - accuracy: 0.9574 - val_loss: 0.5461 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.87438\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1279 - accuracy: 0.9604 - val_loss: 1.5569 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.87438\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.2033 - accuracy: 0.9324 - val_loss: 1.0100 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.87438\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.1541 - accuracy: 0.9470 - val_loss: 0.7949 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.87438\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1425 - accuracy: 0.9513 - val_loss: 0.8380 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.87438\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1117 - accuracy: 0.9525 - val_loss: 0.6429 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.87438\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0985 - accuracy: 0.9695 - val_loss: 0.3876 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.87438\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.2194 - accuracy: 0.9287 - val_loss: 1.0144 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.87438\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1204 - accuracy: 0.9592 - val_loss: 0.6078 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.87438\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1197 - accuracy: 0.9586 - val_loss: 0.6115 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.87438\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1103 - accuracy: 0.9647 - val_loss: 0.7971 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.87438\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.1086 - accuracy: 0.9629 - val_loss: 0.4575 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.87438\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.1148 - accuracy: 0.9635 - val_loss: 0.6853 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.87438\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.1118 - accuracy: 0.9653 - val_loss: 0.5979 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.87438\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1192 - accuracy: 0.9604 - val_loss: 0.4797 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.87438\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1291 - accuracy: 0.9604 - val_loss: 0.4970 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.87438\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.1074 - accuracy: 0.9592 - val_loss: 0.4615 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.87438\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0841 - accuracy: 0.9677 - val_loss: 0.5938 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.87438\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1205 - accuracy: 0.9622 - val_loss: 0.7143 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.87438\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1398 - accuracy: 0.9482 - val_loss: 0.6691 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.87438\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1398 - accuracy: 0.9476 - val_loss: 0.7927 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.87438\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1045 - accuracy: 0.9647 - val_loss: 0.7208 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.87438\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1075 - accuracy: 0.9647 - val_loss: 0.4992 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.87438\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0667 - accuracy: 0.9787 - val_loss: 0.5667 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.87438\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0875 - accuracy: 0.9695 - val_loss: 0.5614 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.87438\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0742 - accuracy: 0.9762 - val_loss: 0.7588 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.87438\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0723 - accuracy: 0.9769 - val_loss: 0.4531 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.87438\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1039 - accuracy: 0.9629 - val_loss: 0.6387 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.87438\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.2187 - accuracy: 0.9312 - val_loss: 3.0917 - val_accuracy: 0.5837\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.87438\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1916 - accuracy: 0.9385 - val_loss: 1.0299 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.87438\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0956 - accuracy: 0.9702 - val_loss: 0.4712 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.87438\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0691 - accuracy: 0.9750 - val_loss: 0.5729 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.87438\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0677 - accuracy: 0.9769 - val_loss: 0.5087 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.87438\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0758 - accuracy: 0.9769 - val_loss: 0.6122 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.87438\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0603 - accuracy: 0.9775 - val_loss: 0.4503 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.87438 to 0.87931, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0604 - accuracy: 0.9842 - val_loss: 0.5159 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.87931\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0505 - accuracy: 0.9805 - val_loss: 0.4385 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.87931\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0754 - accuracy: 0.9769 - val_loss: 0.7656 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.87931\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0491 - accuracy: 0.9866 - val_loss: 0.5159 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.87931\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0610 - accuracy: 0.9781 - val_loss: 0.6596 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.87931\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0618 - accuracy: 0.9762 - val_loss: 0.5522 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.87931\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0568 - accuracy: 0.9842 - val_loss: 0.5707 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.87931\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0835 - accuracy: 0.9726 - val_loss: 0.7881 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.87931\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0664 - accuracy: 0.9756 - val_loss: 0.6441 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.87931\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0737 - accuracy: 0.9714 - val_loss: 0.7915 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.87931\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0802 - accuracy: 0.9762 - val_loss: 0.8297 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.87931\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0866 - accuracy: 0.9677 - val_loss: 0.6157 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.87931\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0960 - accuracy: 0.9689 - val_loss: 1.0038 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.87931\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0920 - accuracy: 0.9677 - val_loss: 0.7116 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.87931\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0831 - accuracy: 0.9720 - val_loss: 0.7206 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.87931\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0927 - accuracy: 0.9708 - val_loss: 0.4122 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.87931\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0746 - accuracy: 0.9756 - val_loss: 0.6258 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.87931\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0690 - accuracy: 0.9756 - val_loss: 0.6659 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.87931\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0742 - accuracy: 0.9738 - val_loss: 0.7231 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.87931\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0686 - accuracy: 0.9793 - val_loss: 0.6049 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.87931\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1022 - accuracy: 0.9683 - val_loss: 0.6641 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.87931\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 21s 405ms/step - loss: 0.0683 - accuracy: 0.9750 - val_loss: 0.5305 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.87931\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0834 - accuracy: 0.9708 - val_loss: 0.5212 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.87931\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0518 - accuracy: 0.9823 - val_loss: 0.4920 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00110: val_accuracy improved from 0.87931 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0454 - accuracy: 0.9811 - val_loss: 0.4176 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.88670\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0660 - accuracy: 0.9799 - val_loss: 0.7514 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.88670\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0553 - accuracy: 0.9793 - val_loss: 0.7965 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.88670\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0763 - accuracy: 0.9799 - val_loss: 0.6408 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.88670\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0813 - accuracy: 0.9720 - val_loss: 0.5170 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.88670\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0755 - accuracy: 0.9744 - val_loss: 0.8794 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.88670\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0795 - accuracy: 0.9738 - val_loss: 0.4414 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00117: val_accuracy improved from 0.88670 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0647 - accuracy: 0.9726 - val_loss: 0.7319 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.90640\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0757 - accuracy: 0.9756 - val_loss: 0.5260 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.90640\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 0.5742 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.90640\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0457 - accuracy: 0.9829 - val_loss: 0.7018 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.90640\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0989 - accuracy: 0.9732 - val_loss: 0.7839 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.90640\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1047 - accuracy: 0.9677 - val_loss: 0.9358 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.90640\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.1023 - accuracy: 0.9677 - val_loss: 0.6796 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.90640\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0470 - accuracy: 0.9823 - val_loss: 0.6540 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.90640\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0787 - accuracy: 0.9781 - val_loss: 0.7876 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.90640\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0602 - accuracy: 0.9823 - val_loss: 0.7594 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.90640\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0737 - accuracy: 0.9750 - val_loss: 0.6471 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.90640\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0493 - accuracy: 0.9823 - val_loss: 0.5952 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.90640\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0374 - accuracy: 0.9854 - val_loss: 0.4190 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.90640\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 21s 406ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 0.6363 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.90640\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0349 - accuracy: 0.9860 - val_loss: 0.5464 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.90640\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 0.5394 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.90640\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.5454 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.90640\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.4337 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.90640\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0669 - accuracy: 0.9817 - val_loss: 0.8294 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.90640\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1248 - accuracy: 0.9659 - val_loss: 0.8562 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.90640\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0847 - accuracy: 0.9702 - val_loss: 0.7758 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.90640\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0668 - accuracy: 0.9756 - val_loss: 0.5208 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.90640\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0501 - accuracy: 0.9842 - val_loss: 0.5215 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.90640\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0458 - accuracy: 0.9836 - val_loss: 0.5816 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.90640\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0282 - accuracy: 0.9909 - val_loss: 0.5630 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.90640\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0489 - accuracy: 0.9787 - val_loss: 0.5415 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.90640\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0412 - accuracy: 0.9860 - val_loss: 0.6170 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.90640\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0363 - accuracy: 0.9903 - val_loss: 0.6211 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.90640\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 0.4933 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.90640\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 0.5509 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.90640\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0503 - accuracy: 0.9854 - val_loss: 0.8875 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.90640\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.5728 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.90640\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0635 - accuracy: 0.9799 - val_loss: 0.6151 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.90640\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 0.5098 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.90640\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0372 - accuracy: 0.9878 - val_loss: 0.5587 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.90640\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0255 - accuracy: 0.9896 - val_loss: 0.6398 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.90640\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0404 - accuracy: 0.9866 - val_loss: 0.6537 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.90640\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0459 - accuracy: 0.9836 - val_loss: 0.4657 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.90640\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0502 - accuracy: 0.9811 - val_loss: 0.4978 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.90640\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0867 - accuracy: 0.9677 - val_loss: 0.7552 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.90640\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0627 - accuracy: 0.9799 - val_loss: 0.8963 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.90640\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0515 - accuracy: 0.9811 - val_loss: 0.6004 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.90640\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0696 - accuracy: 0.9775 - val_loss: 1.0234 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.90640\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0539 - accuracy: 0.9793 - val_loss: 0.5975 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.90640\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0434 - accuracy: 0.9842 - val_loss: 0.5842 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.90640\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0395 - accuracy: 0.9890 - val_loss: 0.4792 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.90640\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.6748 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.90640\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.5475 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.90640\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0175 - accuracy: 0.9927 - val_loss: 0.4600 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.90640\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0222 - accuracy: 0.9945 - val_loss: 0.4930 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.90640\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 20s 394ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.5242 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.90640\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0290 - accuracy: 0.9890 - val_loss: 0.7178 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.90640\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0547 - accuracy: 0.9823 - val_loss: 0.7976 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.90640\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0548 - accuracy: 0.9805 - val_loss: 0.8185 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.90640\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0583 - accuracy: 0.9842 - val_loss: 0.9782 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.90640\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0702 - accuracy: 0.9756 - val_loss: 0.8307 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.90640\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0603 - accuracy: 0.9781 - val_loss: 0.6947 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.90640\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0536 - accuracy: 0.9799 - val_loss: 0.5858 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.90640\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.7154 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.90640\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0397 - accuracy: 0.9829 - val_loss: 0.6039 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.90640\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0435 - accuracy: 0.9884 - val_loss: 1.0314 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.90640\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.8395 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.90640\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0382 - accuracy: 0.9896 - val_loss: 0.7452 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.90640\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0547 - accuracy: 0.9829 - val_loss: 0.5683 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.90640\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0444 - accuracy: 0.9860 - val_loss: 0.8327 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.90640\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0271 - accuracy: 0.9909 - val_loss: 0.7878 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.90640\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0312 - accuracy: 0.9921 - val_loss: 0.5483 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.90640\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 0.6480 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.90640\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0596 - accuracy: 0.9823 - val_loss: 0.9351 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.90640\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0545 - accuracy: 0.9805 - val_loss: 0.8774 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.90640\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0332 - accuracy: 0.9878 - val_loss: 0.5234 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.90640\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0267 - accuracy: 0.9896 - val_loss: 0.5684 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.90640\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0537 - accuracy: 0.9805 - val_loss: 0.8525 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.90640\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0581 - accuracy: 0.9829 - val_loss: 1.4697 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.90640\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1564 - accuracy: 0.9525 - val_loss: 1.2885 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.90640\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0418 - accuracy: 0.9860 - val_loss: 0.6044 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.90640\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0314 - accuracy: 0.9921 - val_loss: 0.6282 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.90640\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0358 - accuracy: 0.9915 - val_loss: 0.5902 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.90640\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.4888 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.90640\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 0.4883 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.90640\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0155 - accuracy: 0.9970 - val_loss: 0.4770 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.90640\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 0.4164 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.90640\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.5809 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.90640\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0337 - accuracy: 0.9896 - val_loss: 0.4638 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.90640\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.5465 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.90640\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0420 - accuracy: 0.9872 - val_loss: 0.7254 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.90640\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0219 - accuracy: 0.9915 - val_loss: 0.6123 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.90640\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0176 - accuracy: 0.9933 - val_loss: 0.3794 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.90640\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.4279 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.90640\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.5048 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.90640\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 0.7019 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.90640\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0498 - accuracy: 0.9836 - val_loss: 0.6606 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.90640\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0430 - accuracy: 0.9878 - val_loss: 0.5835 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.90640\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.5805 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.90640\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.8368 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.90640\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.5657 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.90640\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0382 - accuracy: 0.9890 - val_loss: 0.8377 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.90640\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0284 - accuracy: 0.9890 - val_loss: 0.6383 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.90640\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.5463 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.90640\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.5543 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.90640\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.7264 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.90640\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0708 - accuracy: 0.9799 - val_loss: 0.8534 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.90640\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0495 - accuracy: 0.9823 - val_loss: 0.5869 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.90640\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0366 - accuracy: 0.9860 - val_loss: 0.5528 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.90640\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0319 - accuracy: 0.9915 - val_loss: 0.5876 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.90640\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.4816 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.90640\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.5181 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.90640\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.4520 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.90640\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.8536 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.90640\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 21s 406ms/step - loss: 0.0234 - accuracy: 0.9939 - val_loss: 0.7000 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.90640\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0187 - accuracy: 0.9921 - val_loss: 0.6874 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.90640\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0264 - accuracy: 0.9884 - val_loss: 0.8792 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.90640\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 21s 405ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.6228 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.90640\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.5667 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.90640\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.5867 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.90640\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.7491 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.90640\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.8295 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.90640\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0347 - accuracy: 0.9896 - val_loss: 0.5447 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.90640\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0508 - accuracy: 0.9866 - val_loss: 0.8349 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.90640\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.6270 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.90640\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.7300 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.90640\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0743 - accuracy: 0.9823 - val_loss: 0.8819 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.90640\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1014 - accuracy: 0.9665 - val_loss: 1.1217 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.90640\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0518 - accuracy: 0.9811 - val_loss: 0.7331 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.90640\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0327 - accuracy: 0.9909 - val_loss: 0.6113 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.90640\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 0.5491 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.90640\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0101 - accuracy: 0.9988 - val_loss: 0.4751 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.90640\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.5784 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.90640\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.6003 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.90640\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0167 - accuracy: 0.9933 - val_loss: 0.6032 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.90640\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.7850 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.90640\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.7325 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.90640\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.5976 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.90640\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0191 - accuracy: 0.9915 - val_loss: 0.5362 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.90640\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.5118 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.90640\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0215 - accuracy: 0.9903 - val_loss: 0.8294 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.90640\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0444 - accuracy: 0.9878 - val_loss: 0.9881 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.90640\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0519 - accuracy: 0.9842 - val_loss: 0.6058 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.90640\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0594 - accuracy: 0.9829 - val_loss: 1.8138 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.90640\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0383 - accuracy: 0.9903 - val_loss: 0.6554 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.90640\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0266 - accuracy: 0.9896 - val_loss: 0.5767 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.90640\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.5732 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.90640\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0614 - accuracy: 0.9805 - val_loss: 0.6862 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.90640\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0314 - accuracy: 0.9903 - val_loss: 0.8571 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.90640\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0298 - accuracy: 0.9915 - val_loss: 0.6044 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.90640\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.4830 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.90640\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.6029 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.90640\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 0.5930 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.90640\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0238 - accuracy: 0.9939 - val_loss: 0.5711 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.90640\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0108 - accuracy: 0.9957 - val_loss: 0.5698 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.90640\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 0.5094 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.90640\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.6220 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.90640\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0354 - accuracy: 0.9896 - val_loss: 0.7148 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.90640\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.6773 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.90640\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0134 - accuracy: 0.9933 - val_loss: 0.6731 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.90640\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.6509 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.90640\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 21s 406ms/step - loss: 0.0148 - accuracy: 0.9945 - val_loss: 0.6008 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.90640\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.5638 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.90640\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.5863 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.90640\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.6591 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.90640\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.5259 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.90640\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0284 - accuracy: 0.9896 - val_loss: 0.7218 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.90640\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 20s 396ms/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 0.6164 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.90640\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.8068 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.90640\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.4942 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.90640\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4666 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.90640\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.6506 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.90640\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 21s 410ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 0.7271 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.90640\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.7112 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.90640\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 20s 395ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 1.1527 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.90640\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0410 - accuracy: 0.9866 - val_loss: 0.5975 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.90640\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0273 - accuracy: 0.9896 - val_loss: 0.6844 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.90640\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0202 - accuracy: 0.9909 - val_loss: 0.6221 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.90640\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0557 - accuracy: 0.9860 - val_loss: 0.7181 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.90640\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0269 - accuracy: 0.9890 - val_loss: 0.7725 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.90640\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0516 - accuracy: 0.9769 - val_loss: 1.0031 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.90640\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0460 - accuracy: 0.9829 - val_loss: 0.7767 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.90640\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.5267 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.90640\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.5046 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.90640\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.5424 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.90640\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0236 - accuracy: 0.9945 - val_loss: 0.5520 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.90640\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.4983 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.90640\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0218 - accuracy: 0.9951 - val_loss: 0.6585 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.90640\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 21s 407ms/step - loss: 0.0298 - accuracy: 0.9915 - val_loss: 0.7239 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.90640\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0104 - accuracy: 0.9957 - val_loss: 0.6666 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.90640\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.7359 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.90640\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.6619 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.90640\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0076 - accuracy: 0.9963 - val_loss: 0.6841 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.90640\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.6483 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.90640\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.5711 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.90640\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0187 - accuracy: 0.9927 - val_loss: 1.0075 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.90640\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.6614 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.90640\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.6344 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.90640\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.6519 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.90640\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.5896 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.90640\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.5203 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.90640\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.5245 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00314: val_accuracy improved from 0.90640 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5985 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.90887\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5885 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.90887\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.5937 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.90887\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.6034 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.90887\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 2.0884 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.90887\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 0.9816 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.90887\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 0.8849 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.90887\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0561 - accuracy: 0.9854 - val_loss: 0.8022 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.90887\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0366 - accuracy: 0.9884 - val_loss: 0.8117 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.90887\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.7353 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.90887\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 0.8379 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.90887\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0272 - accuracy: 0.9884 - val_loss: 1.6081 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.90887\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0624 - accuracy: 0.9799 - val_loss: 0.8982 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.90887\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0239 - accuracy: 0.9939 - val_loss: 0.6137 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.90887\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.5013 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.90887\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.7268 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.90887\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.5095 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.90887\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.8400 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.90887\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.4717 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.90887\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.5423 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.90887\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.5874 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.90887\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.5326 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.90887\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.5618 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.90887\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.5068 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.90887\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.5260 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.90887\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.4958 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.90887\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.6347 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.90887\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0103 - accuracy: 0.9957 - val_loss: 0.6505 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.90887\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.6532 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.90887\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0114 - accuracy: 0.9951 - val_loss: 0.5513 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.90887\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0197 - accuracy: 0.9951 - val_loss: 0.9336 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.90887\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0216 - accuracy: 0.9957 - val_loss: 0.7260 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.90887\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.6047 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.90887\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.5601 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.90887\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.6337 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.90887\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.6254 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.90887\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.5819 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.90887\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 1.0065 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.90887\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0151 - accuracy: 0.9927 - val_loss: 0.6553 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.90887\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.4990 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.90887\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5664 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.90887\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0401 - accuracy: 0.9872 - val_loss: 0.6155 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.90887\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0428 - accuracy: 0.9848 - val_loss: 0.8515 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.90887\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.5906 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.90887\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0104 - accuracy: 0.9951 - val_loss: 0.4467 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.90887\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.5779 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.90887\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0146 - accuracy: 0.9939 - val_loss: 0.6611 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.90887\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.7455 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.90887\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.8112 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.90887\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.6810 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.90887\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.5957 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.90887\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.6230 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.90887\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.6681 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.90887\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.6547 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.90887\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0125 - accuracy: 0.9945 - val_loss: 0.5300 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.90887\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.6389 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.90887\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.5352 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.90887\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.7224 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.90887\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0484 - accuracy: 0.9866 - val_loss: 0.8070 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.90887\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0230 - accuracy: 0.9903 - val_loss: 0.6269 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.90887\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0227 - accuracy: 0.9945 - val_loss: 0.6693 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.90887\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.5613 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.90887\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0159 - accuracy: 0.9927 - val_loss: 0.8057 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.90887\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.4523 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.90887\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5083 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.90887\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.5754 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.90887\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.5657 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.90887\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0109 - accuracy: 0.9951 - val_loss: 0.5936 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.90887\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.5890 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.90887\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.6971 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.90887\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.5390 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.90887\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.5565 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.90887\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4872 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.90887\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6176 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.90887\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.4864 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.90887\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.4883 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.90887\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.5511 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.90887\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.6319 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.90887\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.4943 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.90887\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.6505 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.90887\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0160 - accuracy: 0.9927 - val_loss: 0.8079 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.90887\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0146 - accuracy: 0.9927 - val_loss: 1.1888 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.90887\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0729 - accuracy: 0.9762 - val_loss: 1.1183 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.90887\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0565 - accuracy: 0.9866 - val_loss: 0.6047 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.90887\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0224 - accuracy: 0.9915 - val_loss: 0.7989 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.90887\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.7747 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.90887\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.7637 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.90887\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0203 - accuracy: 0.9915 - val_loss: 0.8863 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.90887\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0194 - accuracy: 0.9909 - val_loss: 0.7583 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.90887\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0309 - accuracy: 0.9884 - val_loss: 0.8898 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.90887\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0273 - accuracy: 0.9927 - val_loss: 0.8951 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.90887\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.6184 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.90887\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0166 - accuracy: 0.9970 - val_loss: 0.5712 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.90887\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.5729 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.90887\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0206 - accuracy: 0.9921 - val_loss: 0.6419 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.90887\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.9796 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.90887\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0105 - accuracy: 0.9957 - val_loss: 0.7428 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.90887\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0180 - accuracy: 0.9933 - val_loss: 0.7693 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.90887\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0174 - accuracy: 0.9927 - val_loss: 0.7305 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.90887\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.6117 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.90887\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.8059 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.90887\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.7603 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.90887\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.5471 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.90887\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.6016 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.90887\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.5314 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.90887\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.6844 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.90887\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0284 - accuracy: 0.9921 - val_loss: 0.5833 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.90887\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.6539 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.90887\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0200 - accuracy: 0.9915 - val_loss: 0.7121 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.90887\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.6741 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.90887\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.8040 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.90887\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.7271 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.90887\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.7263 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.90887\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.7861 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.90887\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.7224 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.90887\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.6285 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.90887\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.6821 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.90887\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.5429 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.90887\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.6190 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.90887\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.5378 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.90887\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0172 - accuracy: 0.9927 - val_loss: 0.6878 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.90887\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0210 - accuracy: 0.9921 - val_loss: 0.7884 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.90887\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.8289 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.90887\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.5640 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.90887\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0116 - accuracy: 0.9951 - val_loss: 0.6682 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.90887\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.5724 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.90887\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.6533 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.90887\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.5139 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.90887\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0160 - accuracy: 0.9970 - val_loss: 0.6668 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.90887\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.90887\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.6011 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.90887\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0218 - accuracy: 0.9951 - val_loss: 3.1341 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.90887\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.1435 - accuracy: 0.9714 - val_loss: 0.7868 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.90887\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0361 - accuracy: 0.9884 - val_loss: 0.8938 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.90887\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.5756 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.90887\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.5306 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.90887\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 1.4314 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.90887\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0191 - accuracy: 0.9921 - val_loss: 0.7153 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.90887\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.6205 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.90887\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.6088 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.90887\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.5329 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.90887\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.5371 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.90887\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0143 - accuracy: 0.9982 - val_loss: 0.5102 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.90887\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.5157 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.90887\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.5545 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.90887\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.5113 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.90887\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5715 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.90887\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.6069 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.90887\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5201 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.90887\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5709 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.90887\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.5749 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.90887\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.6583 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.90887\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5470 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.90887\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.6445 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.90887\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.5767 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.90887\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.6639 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.90887\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.6608 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.90887\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.7774 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.90887\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.7202 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.90887\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.7978 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.90887\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0497 - accuracy: 0.9909 - val_loss: 1.6259 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.90887\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 0.7466 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.90887\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0374 - accuracy: 0.9909 - val_loss: 1.1118 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.90887\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 20s 396ms/step - loss: 0.0236 - accuracy: 0.9896 - val_loss: 0.7444 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.90887\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0310 - accuracy: 0.9903 - val_loss: 0.7430 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.90887\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.5955 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.90887\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5731 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.90887\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5489 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.90887\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.5763 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.90887\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.5805 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.90887\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.7157 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.90887\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.6447 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.90887\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.6243 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.90887\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.7240 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.90887\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.5912 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.90887\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.7137 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.90887\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.6294 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.90887\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.7278 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.90887\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.6838 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.90887\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.7337 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.90887\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.6616 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.90887\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.7109 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.90887\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.7924 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.90887\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0282 - accuracy: 0.9927 - val_loss: 0.7547 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.90887\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.5368 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.90887\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5379 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.90887\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f99886f8e10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "bb5a32e6-18a7-4140-c231-0c3f1987f68f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_5_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "950edf4f-c8b6-47e1-8aed-dc4fe9d1322e"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f4d7a4-4ca2-434c-a310-9dccc7e62ef9"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b8fec7bf-c4b7-4413-e0b3-915af86769e0"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "27e68548-2105-46e1-acd6-680eaba29288"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_030_5_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_030_5_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0b635d19-67f9-488c-81df-3aab6d64aa18\", \"HeightShiftRange_030_5_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}