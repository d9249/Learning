{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rotation_range_30_1_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOnh00YVQIta1qOyhzXQZlo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/Rotation_range_30_1_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11eeea3d-7a1f-46fc-ace5-f9a9f68b8a3f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug 25 16:27:24 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13defef6-a4c5-470a-c7dc-a3f462585c69"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc98cc4-375e-4462-8584-7daad59d0579"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ae09718-bbee-4ddd-b9dc-9a8edbdda648"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=30,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28f915f-a616-46ac-8363-173596e8a7a6"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 53s 473ms/step - loss: 2.0182 - accuracy: 0.2808 - val_loss: 9.5033 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 19s 372ms/step - loss: 1.5406 - accuracy: 0.4671 - val_loss: 5.1308 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10099\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 19s 373ms/step - loss: 1.1956 - accuracy: 0.5968 - val_loss: 6.2366 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.10099\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 20s 376ms/step - loss: 1.0648 - accuracy: 0.6504 - val_loss: 3.4142 - val_accuracy: 0.0911\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.10099\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.9213 - accuracy: 0.6864 - val_loss: 8.5188 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.10099\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.8176 - accuracy: 0.7491 - val_loss: 17.5678 - val_accuracy: 0.1108\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.10099 to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.7346 - accuracy: 0.7680 - val_loss: 5.7160 - val_accuracy: 0.2241\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.11084 to 0.22414, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.7101 - accuracy: 0.7637 - val_loss: 3.5240 - val_accuracy: 0.2808\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.22414 to 0.28079, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.6352 - accuracy: 0.7917 - val_loss: 1.4293 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.28079 to 0.61084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.6101 - accuracy: 0.8015 - val_loss: 2.9623 - val_accuracy: 0.3966\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.61084\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.5829 - accuracy: 0.7996 - val_loss: 4.8956 - val_accuracy: 0.2956\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.61084\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.5437 - accuracy: 0.8094 - val_loss: 2.2387 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.61084\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.5433 - accuracy: 0.8124 - val_loss: 1.4139 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.61084\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.4649 - accuracy: 0.8551 - val_loss: 1.9795 - val_accuracy: 0.5369\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.61084\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.4477 - accuracy: 0.8544 - val_loss: 0.5560 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.61084 to 0.83498, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.4633 - accuracy: 0.8441 - val_loss: 0.8883 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.83498\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.4375 - accuracy: 0.8520 - val_loss: 1.3103 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.83498\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.3754 - accuracy: 0.8715 - val_loss: 0.5913 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.83498\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 20s 395ms/step - loss: 0.3921 - accuracy: 0.8691 - val_loss: 0.9960 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.83498\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.3457 - accuracy: 0.8806 - val_loss: 0.7317 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.83498\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.3403 - accuracy: 0.8837 - val_loss: 2.8860 - val_accuracy: 0.5123\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.83498\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.3595 - accuracy: 0.8709 - val_loss: 0.7282 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.83498\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.2870 - accuracy: 0.9068 - val_loss: 0.6963 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.83498\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.3078 - accuracy: 0.8995 - val_loss: 0.7089 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.83498\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.3017 - accuracy: 0.8946 - val_loss: 0.8124 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.83498\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.2992 - accuracy: 0.8989 - val_loss: 0.6437 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.83498\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.2628 - accuracy: 0.9026 - val_loss: 0.5570 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.83498\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 20s 396ms/step - loss: 0.2735 - accuracy: 0.9093 - val_loss: 0.6103 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.83498\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.3102 - accuracy: 0.8922 - val_loss: 1.5538 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.83498\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.3120 - accuracy: 0.8946 - val_loss: 2.1625 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.83498\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.2608 - accuracy: 0.9184 - val_loss: 0.7526 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.83498\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.2268 - accuracy: 0.9245 - val_loss: 0.7123 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.83498\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1853 - accuracy: 0.9336 - val_loss: 0.7026 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.83498\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.2519 - accuracy: 0.9074 - val_loss: 0.9122 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.83498\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.2123 - accuracy: 0.9300 - val_loss: 0.4437 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.83498 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.1847 - accuracy: 0.9409 - val_loss: 0.5604 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.86946\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.3069 - accuracy: 0.8910 - val_loss: 0.9229 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.86946\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.2210 - accuracy: 0.9239 - val_loss: 0.4437 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.86946\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1819 - accuracy: 0.9348 - val_loss: 0.4880 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.86946\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1733 - accuracy: 0.9385 - val_loss: 0.9594 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.86946\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.2074 - accuracy: 0.9342 - val_loss: 0.5732 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.86946\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1430 - accuracy: 0.9513 - val_loss: 0.7206 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.86946\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1518 - accuracy: 0.9440 - val_loss: 0.5407 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.86946\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1430 - accuracy: 0.9470 - val_loss: 0.4909 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.86946\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.2003 - accuracy: 0.9397 - val_loss: 0.5839 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.86946\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1726 - accuracy: 0.9385 - val_loss: 0.4091 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.86946 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1456 - accuracy: 0.9476 - val_loss: 0.7234 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.88670\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.1425 - accuracy: 0.9495 - val_loss: 0.4517 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.88670\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1376 - accuracy: 0.9513 - val_loss: 1.1549 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.88670\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1549 - accuracy: 0.9525 - val_loss: 0.5743 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.88670\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1303 - accuracy: 0.9580 - val_loss: 0.7468 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.88670\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1136 - accuracy: 0.9622 - val_loss: 0.5144 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.88670\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1350 - accuracy: 0.9537 - val_loss: 0.6062 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.88670\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1281 - accuracy: 0.9488 - val_loss: 0.6794 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.88670\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1551 - accuracy: 0.9476 - val_loss: 1.2934 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.88670\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1387 - accuracy: 0.9525 - val_loss: 0.7136 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.88670\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1302 - accuracy: 0.9543 - val_loss: 0.5928 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.88670\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.1187 - accuracy: 0.9604 - val_loss: 0.4289 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.88670\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1344 - accuracy: 0.9537 - val_loss: 0.8990 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.88670\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1263 - accuracy: 0.9555 - val_loss: 0.5001 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.88670\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1365 - accuracy: 0.9513 - val_loss: 0.5391 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.88670\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1241 - accuracy: 0.9580 - val_loss: 0.7045 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.88670\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1124 - accuracy: 0.9635 - val_loss: 0.4433 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.88670\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1112 - accuracy: 0.9610 - val_loss: 0.4964 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.88670\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0812 - accuracy: 0.9732 - val_loss: 0.4840 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.88670\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0915 - accuracy: 0.9714 - val_loss: 0.7123 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.88670\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1186 - accuracy: 0.9610 - val_loss: 0.4304 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.88670\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1341 - accuracy: 0.9586 - val_loss: 0.5629 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.88670\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0978 - accuracy: 0.9647 - val_loss: 0.5189 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.88670\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.1027 - accuracy: 0.9635 - val_loss: 0.9745 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.88670\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0724 - accuracy: 0.9744 - val_loss: 0.7844 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.88670\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0813 - accuracy: 0.9750 - val_loss: 0.4979 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.88670\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0864 - accuracy: 0.9726 - val_loss: 0.7332 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.88670\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.1274 - accuracy: 0.9519 - val_loss: 0.8810 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.88670\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0705 - accuracy: 0.9750 - val_loss: 0.9266 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.88670\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1104 - accuracy: 0.9622 - val_loss: 1.0941 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.88670\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0865 - accuracy: 0.9708 - val_loss: 0.6210 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.88670\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0453 - accuracy: 0.9848 - val_loss: 0.4833 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.88670\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0562 - accuracy: 0.9775 - val_loss: 0.5026 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.88670\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0702 - accuracy: 0.9708 - val_loss: 0.6061 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.88670\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0825 - accuracy: 0.9726 - val_loss: 0.6619 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.88670\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0992 - accuracy: 0.9653 - val_loss: 0.6153 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.88670\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0627 - accuracy: 0.9805 - val_loss: 0.5712 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.88670\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0559 - accuracy: 0.9781 - val_loss: 0.4737 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.88670\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0643 - accuracy: 0.9805 - val_loss: 0.4341 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00085: val_accuracy improved from 0.88670 to 0.89901, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1197 - accuracy: 0.9622 - val_loss: 0.9898 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.89901\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0994 - accuracy: 0.9702 - val_loss: 0.5994 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.89901\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 20s 395ms/step - loss: 0.0728 - accuracy: 0.9781 - val_loss: 0.6729 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.89901\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0351 - accuracy: 0.9854 - val_loss: 0.5280 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.89901\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0566 - accuracy: 0.9762 - val_loss: 0.9273 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.89901\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1784 - accuracy: 0.9440 - val_loss: 1.4229 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.89901\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.2923 - accuracy: 0.9214 - val_loss: 2.0909 - val_accuracy: 0.6084\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.89901\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1020 - accuracy: 0.9671 - val_loss: 0.5167 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.89901\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0534 - accuracy: 0.9860 - val_loss: 0.4675 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.89901\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0476 - accuracy: 0.9866 - val_loss: 0.5061 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.89901\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 20s 395ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.5291 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.89901\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0251 - accuracy: 0.9927 - val_loss: 0.6016 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.89901\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.4322 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.89901\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0469 - accuracy: 0.9860 - val_loss: 0.7472 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.89901\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0417 - accuracy: 0.9872 - val_loss: 0.5409 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.89901\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0388 - accuracy: 0.9842 - val_loss: 0.5807 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.89901\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0612 - accuracy: 0.9756 - val_loss: 0.6527 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.89901\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0562 - accuracy: 0.9799 - val_loss: 0.5227 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.89901\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0527 - accuracy: 0.9805 - val_loss: 1.2472 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.89901\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0466 - accuracy: 0.9811 - val_loss: 0.4711 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.89901\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0303 - accuracy: 0.9927 - val_loss: 0.4958 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.89901\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0313 - accuracy: 0.9878 - val_loss: 0.5714 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.89901\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0820 - accuracy: 0.9726 - val_loss: 0.9926 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.89901\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0638 - accuracy: 0.9762 - val_loss: 0.8192 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.89901\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0613 - accuracy: 0.9769 - val_loss: 0.5926 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.89901\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 20s 394ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.4244 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.89901\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0415 - accuracy: 0.9842 - val_loss: 0.4303 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.89901\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0696 - accuracy: 0.9775 - val_loss: 1.7179 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.89901\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0879 - accuracy: 0.9689 - val_loss: 0.9042 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.89901\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0591 - accuracy: 0.9799 - val_loss: 2.1151 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.89901\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0653 - accuracy: 0.9829 - val_loss: 1.1717 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.89901\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0602 - accuracy: 0.9787 - val_loss: 1.4667 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.89901\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0499 - accuracy: 0.9793 - val_loss: 0.8067 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.89901\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0870 - accuracy: 0.9744 - val_loss: 0.5854 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.89901\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0558 - accuracy: 0.9836 - val_loss: 0.5423 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.89901\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0337 - accuracy: 0.9878 - val_loss: 0.5740 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.89901\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0506 - accuracy: 0.9860 - val_loss: 0.6539 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.89901\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 0.5741 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.89901\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0426 - accuracy: 0.9848 - val_loss: 0.4213 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00124: val_accuracy improved from 0.89901 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0394 - accuracy: 0.9890 - val_loss: 0.5843 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.90148\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0402 - accuracy: 0.9854 - val_loss: 1.0998 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.90148\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0438 - accuracy: 0.9848 - val_loss: 0.6824 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.90148\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 0.9566 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.90148\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0740 - accuracy: 0.9744 - val_loss: 0.9441 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.90148\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0449 - accuracy: 0.9842 - val_loss: 0.6226 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.90148\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0608 - accuracy: 0.9756 - val_loss: 0.5636 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.90148\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0451 - accuracy: 0.9842 - val_loss: 0.5843 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.90148\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0696 - accuracy: 0.9762 - val_loss: 0.5350 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.90148\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0235 - accuracy: 0.9939 - val_loss: 0.5459 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.90148\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.4576 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.90148\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.4562 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.90148\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0580 - accuracy: 0.9823 - val_loss: 0.8529 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.90148\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1615 - accuracy: 0.9555 - val_loss: 0.9846 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.90148\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1203 - accuracy: 0.9635 - val_loss: 0.9882 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.90148\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0533 - accuracy: 0.9836 - val_loss: 0.9461 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.90148\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.8691 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.90148\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0254 - accuracy: 0.9921 - val_loss: 0.7723 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.90148\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.5449 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.90148\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0246 - accuracy: 0.9896 - val_loss: 0.5666 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.90148\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.4922 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.90148\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0156 - accuracy: 0.9939 - val_loss: 0.8073 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.90148\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.4192 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.90148\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0221 - accuracy: 0.9951 - val_loss: 0.6188 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.90148\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.4507 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.90148\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0270 - accuracy: 0.9903 - val_loss: 0.5807 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.90148\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0272 - accuracy: 0.9878 - val_loss: 0.8220 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.90148\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0362 - accuracy: 0.9872 - val_loss: 1.3514 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.90148\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0396 - accuracy: 0.9903 - val_loss: 1.0321 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.90148\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0390 - accuracy: 0.9890 - val_loss: 0.8254 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.90148\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0542 - accuracy: 0.9860 - val_loss: 0.6554 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.90148\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0286 - accuracy: 0.9927 - val_loss: 0.8408 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.90148\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0569 - accuracy: 0.9799 - val_loss: 1.2408 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.90148\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 20s 396ms/step - loss: 0.0638 - accuracy: 0.9781 - val_loss: 0.8236 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.90148\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0955 - accuracy: 0.9695 - val_loss: 1.2822 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.90148\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0498 - accuracy: 0.9866 - val_loss: 0.5268 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.90148\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0482 - accuracy: 0.9829 - val_loss: 1.2807 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.90148\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0413 - accuracy: 0.9829 - val_loss: 1.5887 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.90148\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0336 - accuracy: 0.9903 - val_loss: 0.3801 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00163: val_accuracy improved from 0.90148 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.6498 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.91626\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.5761 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.91626\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.4976 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.91626\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.5650 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.91626\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 0.6573 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.91626\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 0.6904 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.91626\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0340 - accuracy: 0.9866 - val_loss: 0.8316 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.91626\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.8340 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.91626\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0328 - accuracy: 0.9884 - val_loss: 0.6242 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.91626\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1587 - accuracy: 0.9501 - val_loss: 3.1508 - val_accuracy: 0.4778\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.91626\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0617 - accuracy: 0.9756 - val_loss: 1.2511 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.91626\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0861 - accuracy: 0.9738 - val_loss: 0.9452 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.91626\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0438 - accuracy: 0.9884 - val_loss: 0.8579 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.91626\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 0.6648 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.91626\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.6046 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.91626\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0323 - accuracy: 0.9915 - val_loss: 1.3239 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.91626\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0190 - accuracy: 0.9909 - val_loss: 0.7556 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.91626\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0231 - accuracy: 0.9909 - val_loss: 0.5576 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.91626\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.7962 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.91626\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0420 - accuracy: 0.9842 - val_loss: 2.0944 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.91626\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0378 - accuracy: 0.9866 - val_loss: 1.2815 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.91626\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0412 - accuracy: 0.9854 - val_loss: 0.3852 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.91626\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.7895 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.91626\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.6199 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.91626\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 1.2465 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.91626\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 0.5635 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.91626\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.4464 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.91626\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.4477 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.91626\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.6879 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.91626\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.5258 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.91626\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 20s 396ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.6394 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.91626\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.6005 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.91626\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.4928 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.91626\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0112 - accuracy: 0.9939 - val_loss: 0.4902 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.91626\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0212 - accuracy: 0.9915 - val_loss: 0.5816 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.91626\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0846 - accuracy: 0.9787 - val_loss: 2.3920 - val_accuracy: 0.5862\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.91626\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0395 - accuracy: 0.9884 - val_loss: 1.0102 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.91626\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0407 - accuracy: 0.9866 - val_loss: 0.8233 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.91626\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.7977 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.91626\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0305 - accuracy: 0.9890 - val_loss: 1.1148 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.91626\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 1.0875 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.91626\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 1.1998 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.91626\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0166 - accuracy: 0.9957 - val_loss: 1.7794 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.91626\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.7043 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.91626\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.6063 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.91626\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0479 - accuracy: 0.9866 - val_loss: 0.7355 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.91626\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.8038 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.91626\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.5754 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.91626\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0204 - accuracy: 0.9951 - val_loss: 0.5108 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.91626\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.7272 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.91626\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0430 - accuracy: 0.9878 - val_loss: 2.0131 - val_accuracy: 0.5813\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.91626\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0646 - accuracy: 0.9799 - val_loss: 1.0406 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.91626\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0502 - accuracy: 0.9805 - val_loss: 1.9156 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.91626\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0736 - accuracy: 0.9775 - val_loss: 2.1300 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.91626\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 1.5590 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.91626\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0310 - accuracy: 0.9896 - val_loss: 1.0578 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.91626\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0393 - accuracy: 0.9872 - val_loss: 1.7409 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.91626\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.4396 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.91626\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.4259 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.91626\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.4465 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.91626\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.5525 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.91626\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0090 - accuracy: 0.9957 - val_loss: 0.5603 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.91626\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.5567 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.91626\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0150 - accuracy: 0.9939 - val_loss: 0.4848 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.91626\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.6224 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.91626\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5261 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.91626\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.6109 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.91626\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0418 - accuracy: 0.9872 - val_loss: 1.3299 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.91626\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0624 - accuracy: 0.9811 - val_loss: 0.7303 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.91626\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0621 - accuracy: 0.9836 - val_loss: 0.9716 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.91626\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 0.5255 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.91626\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.4907 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.91626\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.4972 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.91626\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.4993 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.91626\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.5451 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.91626\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 1.2187 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.91626\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0498 - accuracy: 0.9829 - val_loss: 1.3177 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.91626\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0356 - accuracy: 0.9866 - val_loss: 2.3466 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.91626\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0441 - accuracy: 0.9860 - val_loss: 0.7824 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.91626\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0526 - accuracy: 0.9829 - val_loss: 0.7641 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.91626\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0354 - accuracy: 0.9896 - val_loss: 0.6147 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.91626\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.4248 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.91626\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.4779 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.91626\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0279 - accuracy: 0.9939 - val_loss: 0.9116 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.91626\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.6497 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.91626\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.4435 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.91626\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.3877 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00250: val_accuracy improved from 0.91626 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.6984 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.92118\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.6269 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92118\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 20s 397ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4940 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.92118\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0111 - accuracy: 0.9939 - val_loss: 0.4407 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.92118\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.6780 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.92118\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4593 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.92118\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.92118\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4583 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.92118\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 1.5425 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.92118\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0224 - accuracy: 0.9909 - val_loss: 0.6469 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.92118\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0336 - accuracy: 0.9884 - val_loss: 0.8495 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.92118\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0385 - accuracy: 0.9890 - val_loss: 0.9391 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.92118\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.9466 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.92118\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0238 - accuracy: 0.9909 - val_loss: 0.5351 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.92118\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.4735 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.92118\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.8424 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.92118\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.5773 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.92118\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0112 - accuracy: 0.9951 - val_loss: 0.5128 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.92118\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.9285 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.92118\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.4785 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.92118\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.6981 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.92118\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 1.7326 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.92118\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4905 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.92118\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.6473 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.92118\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0401 - accuracy: 0.9884 - val_loss: 0.5462 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.92118\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 1.1533 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.92118\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.9704 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.92118\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 10.9047 - val_accuracy: 0.3054\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.92118\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0741 - accuracy: 0.9823 - val_loss: 0.6096 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.92118\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0407 - accuracy: 0.9903 - val_loss: 4.0892 - val_accuracy: 0.4606\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.92118\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 2.1066 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.92118\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.5374 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.92118\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.4458 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.92118\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5243 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.92118\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.4299 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.92118\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 20s 395ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.6462 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.92118\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.6186 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.92118\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.6117 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.92118\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0138 - accuracy: 0.9970 - val_loss: 0.6181 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.92118\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 1.1295 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.92118\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4712 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.92118\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0356 - accuracy: 0.9896 - val_loss: 2.5961 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.92118\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 0.7458 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.92118\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0192 - accuracy: 0.9921 - val_loss: 0.6124 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.92118\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0273 - accuracy: 0.9896 - val_loss: 0.6304 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.92118\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0316 - accuracy: 0.9909 - val_loss: 3.2148 - val_accuracy: 0.4507\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.92118\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0280 - accuracy: 0.9896 - val_loss: 3.5417 - val_accuracy: 0.4261\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.92118\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 1.1491 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.92118\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.7278 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.92118\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.4764 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.92118\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.6031 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.92118\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0130 - accuracy: 0.9945 - val_loss: 0.7269 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.92118\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.9520 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.92118\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 0.7751 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.92118\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.5867 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.92118\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.5316 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.92118\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0145 - accuracy: 0.9982 - val_loss: 0.4658 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.92118\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.8510 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.92118\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4404 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.92118\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5257 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.92118\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.8000 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.92118\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.7627 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.92118\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0298 - accuracy: 0.9933 - val_loss: 5.4527 - val_accuracy: 0.4310\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.92118\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 20s 394ms/step - loss: 0.0328 - accuracy: 0.9890 - val_loss: 1.1893 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.92118\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 1.0192 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.92118\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.5543 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.92118\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.5702 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.92118\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.6826 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.92118\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.5466 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.92118\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.7683 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.92118\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 1.1268 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.92118\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.4647 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.92118\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0106 - accuracy: 0.9945 - val_loss: 0.6188 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.92118\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0142 - accuracy: 0.9939 - val_loss: 0.6520 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.92118\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.7927 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.92118\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0281 - accuracy: 0.9890 - val_loss: 7.9336 - val_accuracy: 0.4015\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.92118\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 2.0166 - val_accuracy: 0.5320\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.92118\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 1.6881 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.92118\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0342 - accuracy: 0.9909 - val_loss: 0.8018 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.92118\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 1.3302 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.92118\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 1.5144 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.92118\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5213 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.92118\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.4143 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.92118\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0194 - accuracy: 0.9951 - val_loss: 1.3064 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.92118\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0456 - accuracy: 0.9884 - val_loss: 1.2719 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.92118\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.5784 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.92118\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 1.9809 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.92118\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.7115 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.92118\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 1.4555 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.92118\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.7781 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.92118\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.5512 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.92118\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 20s 395ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.4271 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.92118\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6199 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.92118\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4898 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.92118\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.5615 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.92118\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5498 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.92118\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6388 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.92118\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.92118\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 3.9646e-04 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.92118\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.92118\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.3779 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00351: val_accuracy improved from 0.92118 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5100 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.92611\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.5784 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.92611\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.8752 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.92611\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.4341 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.92611\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.92611\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4306 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.92611\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4551 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.92611\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.6103 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.92611\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0313 - accuracy: 0.9927 - val_loss: 3.5337 - val_accuracy: 0.5222\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.92611\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0535 - accuracy: 0.9793 - val_loss: 1.2790 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.92611\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0807 - accuracy: 0.9756 - val_loss: 2.2634 - val_accuracy: 0.5665\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.92611\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0716 - accuracy: 0.9811 - val_loss: 1.2150 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.92611\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.7317 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.92611\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.6745 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.92611\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.6454 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.92611\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.3972 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.92611\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.4974 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.92611\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.6674 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.92611\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.4786 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.92611\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.5487 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.92611\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0272 - accuracy: 0.9927 - val_loss: 0.8513 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.92611\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 1.2145 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.92611\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.9393 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.92611\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0227 - accuracy: 0.9921 - val_loss: 0.7971 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.92611\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 1.3794 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.92611\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0305 - accuracy: 0.9933 - val_loss: 0.9080 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.92611\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0363 - accuracy: 0.9909 - val_loss: 0.8700 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.92611\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 20s 396ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.8474 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.92611\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.6944 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.92611\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.6101 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.92611\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.5840 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.92611\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.6241 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.92611\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.7670 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.92611\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.5394 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.92611\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5499 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.92611\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 5.8821 - val_accuracy: 0.3473\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.92611\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 2.7386 - val_accuracy: 0.5099\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.92611\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.9762 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.92611\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 1.3027 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.92611\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8325 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.92611\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5834 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.92611\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.9568 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.92611\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.9031 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.92611\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5265 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.92611\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 9.2108e-04 - accuracy: 1.0000 - val_loss: 0.5904 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.92611\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 7.2301e-04 - accuracy: 1.0000 - val_loss: 0.5940 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.92611\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4566 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.92611\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 9.9974e-04 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.92611\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.92611\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 1.0173 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.92611\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.9779 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.92611\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 1.0105 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.92611\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0166 - accuracy: 0.9933 - val_loss: 0.7584 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.92611\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0314 - accuracy: 0.9884 - val_loss: 0.8418 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.92611\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.8232 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.92611\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 8.1127 - val_accuracy: 0.3473\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.92611\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0381 - accuracy: 0.9854 - val_loss: 2.4964 - val_accuracy: 0.4877\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.92611\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0382 - accuracy: 0.9842 - val_loss: 7.8024 - val_accuracy: 0.2365\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.92611\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 0.9790 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.92611\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 1.0360 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.92611\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0556 - accuracy: 0.9848 - val_loss: 1.1993 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.92611\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0192 - accuracy: 0.9921 - val_loss: 0.8928 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.92611\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 0.7966 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.92611\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.6373 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.92611\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0109 - accuracy: 0.9951 - val_loss: 0.8510 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.92611\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.9304 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.92611\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.6121 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.92611\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5535 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.92611\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.6172 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.92611\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4518 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.92611\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.92611\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.92611\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 7.5185e-04 - accuracy: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.92611\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 7.9902e-04 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.92611\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 5.5912e-04 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.92611\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 4.0243e-04 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.92611\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 7.2868e-04 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.92611\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 6.7097e-04 - accuracy: 1.0000 - val_loss: 0.6620 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.92611\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 9.6038e-04 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.92611\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.9724 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.92611\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.6905 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.92611\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5505 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.92611\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 1.2024 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.92611\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.7319 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.92611\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 3.8761e-04 - accuracy: 1.0000 - val_loss: 0.5140 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.92611\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 4.9736e-04 - accuracy: 1.0000 - val_loss: 0.5406 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.92611\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 5.7252e-04 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.92611\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5606 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.92611\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.9638 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.92611\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 1.2293 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.92611\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5704 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.92611\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 3.5511 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.92611\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0408 - accuracy: 0.9842 - val_loss: 1.2216 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.92611\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0555 - accuracy: 0.9793 - val_loss: 1.4648 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.92611\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0375 - accuracy: 0.9848 - val_loss: 1.4122 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.92611\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0413 - accuracy: 0.9872 - val_loss: 0.9965 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.92611\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0671 - accuracy: 0.9787 - val_loss: 1.0930 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.92611\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0309 - accuracy: 0.9878 - val_loss: 1.4914 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.92611\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 1.0313 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.92611\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 20s 396ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.7553 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.92611\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.5699 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.92611\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.5932 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.92611\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.8844 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.92611\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.5647 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.92611\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.8594 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.92611\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5522 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.92611\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 21s 405ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4311 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.92611\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4689 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.92611\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4762 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.92611\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5754 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.92611\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5841 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.92611\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4610 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.92611\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.5266 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.92611\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4981 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.92611\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5323 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.92611\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4687 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.92611\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 7.1089e-04 - accuracy: 1.0000 - val_loss: 0.6585 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.92611\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.4812 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.92611\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5680 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.92611\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5803 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.92611\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 7.3072e-04 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.92611\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4747 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.92611\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 6.6378e-04 - accuracy: 1.0000 - val_loss: 0.4384 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.92611\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5282 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.92611\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 4.9851e-04 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.92611\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 1.1847 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.92611\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 20s 396ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.9600 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.92611\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.7870 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.92611\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.7601 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.92611\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 1.0516 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.92611\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 3.8258 - val_accuracy: 0.4335\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.92611\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.7272 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.92611\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.6610 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.92611\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.6373 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.92611\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 1.3999 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.92611\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0211 - accuracy: 0.9951 - val_loss: 1.7939 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.92611\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 3.9418 - val_accuracy: 0.4433\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.92611\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.9831 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.92611\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.5407 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.92611\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.6651 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.92611\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0219 - accuracy: 0.9951 - val_loss: 0.5607 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.92611\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.7096 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.92611\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 1.0975 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.92611\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 0.9226 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.92611\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0259 - accuracy: 0.9903 - val_loss: 0.8577 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.92611\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.7261 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.92611\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0100 - accuracy: 0.9957 - val_loss: 0.8654 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.92611\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.7508 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.92611\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5611 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.92611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f80c006f150>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "09b05bdb-d395-481a-ef6b-344bbcd93d9c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_30_1_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c05a83c6-5077-49b9-c047-043169ecd61c"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81de6c46-f166-45e4-a8aa-4fed9f554286"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ed29cc32-a407-4268-f309-c85120b463ee"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0e16a761-050e-43dd-9e27-9edc8570c6bb"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_30_1_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_30_1_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_60955c61-e994-4d93-911e-82a8aae29121\", \"Rotation_range_30_1_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}